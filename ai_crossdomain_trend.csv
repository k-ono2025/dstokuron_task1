title,summary,published,year,month,category
"Use of semantic technologies for the development of a dynamic
  trajectories generator in a Semantic Chemistry eLearning platform","ChemgaPedia is a multimedia, webbased eLearning service platform that
currently contains about 18.000 pages organized in 1.700 chapters covering the
complete bachelor studies in chemistry and related topics of chemistry,
pharmacy, and life sciences. The eLearning encyclopedia contains some 25.000
media objects and the eLearning platform provides services such as virtual and
remote labs for experiments. With up to 350.000 users per month the platform is
the most frequently used scientific educational service in the German spoken
Internet. In this demo we show the benefit of mapping the static eLearning
contents of ChemgaPedia to a Linked Data representation for Semantic Chemistry
which allows for generating dynamic eLearning paths tailored to the semantic
profiles of the users.",2010-12-07,2010,2010-12,chemistry
Local Optima Networks of the Quadratic Assignment Problem,"Using a recently proposed model for combinatorial landscapes, Local Optima
Networks (LON), we conduct a thorough analysis of two types of instances of the
Quadratic Assignment Problem (QAP). This network model is a reduction of the
landscape in which the nodes correspond to the local optima, and the edges
account for the notion of adjacency between their basins of attraction. The
model was inspired by the notion of 'inherent network' of potential energy
surfaces proposed in physical-chemistry. The local optima networks extracted
from the so called uniform and real-like QAP instances, show features clearly
distinguishing these two types of instances. Apart from a clear confirmation
that the search difficulty increases with the problem dimension, the analysis
provides new confirming evidence explaining why the real-like instances are
easier to solve exactly using heuristic search, while the uniform instances are
easier to solve approximately. Although the local optima network model is still
under development, we argue that it provides a novel view of combinatorial
landscapes, opening up the possibilities for new analytical tools and
understanding of problem difficulty in combinatorial optimization.",2011-07-21,2011,2011-07,chemistry
Ontologies for the Integration of Air Quality Models and 3D City Models,"The holistic approach to sustainable urban planning implies using different
models in an integrated way that is capable of simulating the urban system. As
the interconnection of such models is not a trivial task, one of the key
elements that may be applied is the description of the urban geometric
properties in an ""interoperable"" way. Focusing on air quality as one of the
most pronounced urban problems, the geometric aspects of a city may be
described by objects such as those defined in CityGML, so that an appropriate
air quality model can be applied for estimating the quality of the urban air on
the basis of atmospheric flow and chemistry equations.
  In this paper we first present theoretical background and motivations for the
interconnection of 3D city models and other models related to sustainable
development and urban planning. Then we present a practical experiment based on
the interconnection of CityGML with an air quality model. Our approach is based
on the creation of an ontology of air quality models and on the extension of an
ontology of urban planning process (OUPP) that acts as an ontology mediator.",2012-01-31,2012,2012-01,chemistry
"What's in an `is about' link? Chemical diagrams and the Information
  Artifact Ontology","The Information Artifact Ontology is an ontology in the domain of information
entities. Core to the definition of what it is to be an information entity is
the claim that an information entity must be `about' something, which is
encoded in an axiom expressing that all information entities are about some
entity. This axiom comes into conflict with ontological realism, since many
information entities seem to be about non-existing entities, such as
hypothetical molecules. We discuss this problem in the context of diagrams of
molecules, a kind of information entity pervasively used throughout
computational chemistry. We then propose a solution that recognizes that
information entities such as diagrams are expressions of diagrammatic
languages. In so doing, we not only address the problem of classifying diagrams
that seem to be about non-existing entities but also allow a more sophisticated
categorisation of information entities.",2012-04-21,2012,2012-04,chemistry
Design for a Darwinian Brain: Part 1. Philosophy and Neuroscience,"Physical symbol systems are needed for open-ended cognition. A good way to
understand physical symbol systems is by comparison of thought to chemistry.
Both have systematicity, productivity and compositionality. The state of the
art in cognitive architectures for open-ended cognition is critically assessed.
I conclude that a cognitive architecture that evolves symbol structures in the
brain is a promising candidate to explain open-ended cognition. Part 2 of the
paper presents such a cognitive architecture.",2013-03-28,2013,2013-03,chemistry
"Chemlambda, universality and self-multiplication","We present chemlambda (or the chemical concrete machine), an artificial
chemistry with the following properties: (a) is Turing complete, (b) has a
model of decentralized, distributed computing associated to it, (c) works at
the level of individual (artificial) molecules, subject of reversible, but
otherwise deterministic interactions with a small number of enzymes, (d)
encodes information in the geometrical structure of the molecules and not in
their numbers, (e) all interactions are purely local in space and time. This is
part of a larger project to create computing, artificial chemistry and
artificial life in a distributed context, using topological and graphical
languages.",2014-03-31,2014,2014-03,chemistry
Prediction of Radiation Fog by DNA Computing,"In this paper we propose a wet lab algorithm for prediction of radiation fog
by DNA computing. The concept of DNA computing is essentially exploited for
generating the classifier algorithm in the wet lab. The classifier is based on
a new concept of similarity based fuzzy reasoning suitable for wet lab
implementation. This new concept of similarity based fuzzy reasoning is
different from conventional approach to fuzzy reasoning based on similarity
measure and also replaces the logical aspect of classical fuzzy reasoning by
DNA chemistry. Thus, we add a new dimension to existing forms of fuzzy
reasoning by bringing it down to nanoscale. We exploit the concept of massive
parallelism of DNA computing by designing this new classifier in the wet lab.
This newly designed classifier is very much generalized in nature and apart
from prediction of radiation fog this methodology can be applied to other types
of data also. To achieve our goal we first fuzzify the given observed
parameters in a form of synthetic DNA sequence which is called fuzzy DNA and
which handles the vague concept of human reasoning.",2015-07-07,2015,2015-07,chemistry
"Enacting textual entailment and ontologies for automated essay grading
  in chemical domain","We propose a system for automated essay grading using ontologies and textual
entailment. The process of textual entailment is guided by hypotheses, which
are extracted from a domain ontology. Textual entailment checks if the truth of
the hypothesis follows from a given text. We enact textual entailment to
compare students answer to a model answer obtained from ontology. We validated
the solution against various essays written by students in the chemistry
domain.",2015-11-09,2015,2015-11,chemistry
Gated Graph Sequence Neural Networks,"Graph-structured data appears frequently in domains including chemistry,
natural language semantics, social networks, and knowledge bases. In this work,
we study feature learning techniques for graph-structured inputs. Our starting
point is previous work on Graph Neural Networks (Scarselli et al., 2009), which
we modify to use gated recurrent units and modern optimization techniques and
then extend to output sequences. The result is a flexible and broadly useful
class of neural network models that has favorable inductive biases relative to
purely sequence-based models (e.g., LSTMs) when the problem is
graph-structured. We demonstrate the capabilities on some simple AI (bAbI) and
graph algorithm learning tasks. We then show it achieves state-of-the-art
performance on a problem from program verification, in which subgraphs need to
be matched to abstract data structures.",2015-11-17,2015,2015-11,chemistry
A Chain-Detection Algorithm for Two-Dimensional Grids,"We describe a general method of detecting valid chains or links of pieces on
a two-dimensional grid. Specifically, using the example of the chess variant
known as Switch-Side Chain-Chess (SSCC). Presently, no foolproof method of
detecting such chains in any given chess position is known and existing graph
theory, to our knowledge, is unable to fully address this problem either. We
therefore propose a solution implemented and tested using the C++ programming
language. We have been unable to find an incorrect result and therefore offer
it as the most viable solution thus far to the chain-detection problem in this
chess variant. The algorithm is also scalable, in principle, to areas beyond
two-dimensional grids such as 3D analysis and molecular chemistry.",2016-10-12,2016,2016-10,chemistry
"Theory-guided Data Science: A New Paradigm for Scientific Discovery from
  Data","Data science models, although successful in a number of commercial domains,
have had limited applicability in scientific problems involving complex
physical phenomena. Theory-guided data science (TGDS) is an emerging paradigm
that aims to leverage the wealth of scientific knowledge for improving the
effectiveness of data science models in enabling scientific discovery. The
overarching vision of TGDS is to introduce scientific consistency as an
essential component for learning generalizable models. Further, by producing
scientifically interpretable models, TGDS aims to advance our scientific
understanding by discovering novel domain insights. Indeed, the paradigm of
TGDS has started to gain prominence in a number of scientific disciplines such
as turbulence modeling, material discovery, quantum chemistry, bio-medical
science, bio-marker discovery, climate science, and hydrology. In this paper,
we formally conceptualize the paradigm of TGDS and present a taxonomy of
research themes in TGDS. We describe several approaches for integrating domain
knowledge in different research themes using illustrative examples from
different disciplines. We also highlight some of the promising avenues of novel
research for realizing the full potential of theory-guided data science.",2016-12-27,2016,2016-12,chemistry
Deep Learning for Computational Chemistry,"The rise and fall of artificial neural networks is well documented in the
scientific literature of both computer science and computational chemistry. Yet
almost two decades later, we are now seeing a resurgence of interest in deep
learning, a machine learning algorithm based on multilayer neural networks.
Within the last few years, we have seen the transformative impact of deep
learning in many domains, particularly in speech recognition and computer
vision, to the extent that the majority of expert practitioners in those field
are now regularly eschewing prior established models in favor of deep learning
models. In this review, we provide an introductory overview into the theory of
deep neural networks and their unique properties that distinguish them from
traditional machine learning algorithms used in cheminformatics. By providing
an overview of the variety of emerging applications of deep neural networks, we
highlight its ubiquity and broad applicability to a wide range of challenges in
the field, including QSAR, virtual screening, protein structure prediction,
quantum chemistry, materials design and property prediction. In reviewing the
performance of deep neural networks, we observed a consistent outperformance
against non-neural networks state-of-the-art models across disparate research
topics, and deep neural network based models often exceeded the ""glass ceiling""
expectations of their respective tasks. Coupled with the maturity of
GPU-accelerated computing for training deep neural networks and the exponential
growth of chemical data on which to train these networks on, we anticipate that
deep learning algorithms will be a valuable tool for computational chemistry.",2017-01-17,2017,2017-01,chemistry
"Towards ""AlphaChem"": Chemical Synthesis Planning with Tree Search and
  Deep Neural Network Policies","Retrosynthesis is a technique to plan the chemical synthesis of organic
molecules, for example drugs, agro- and fine chemicals. In retrosynthesis, a
search tree is built by analysing molecules recursively and dissecting them
into simpler molecular building blocks until one obtains a set of known
building blocks. The search space is intractably large, and it is difficult to
determine the value of retrosynthetic positions. Here, we propose to model
retrosynthesis as a Markov Decision Process. In combination with a Deep Neural
Network policy learned from essentially the complete published knowledge of
chemistry, Monte Carlo Tree Search (MCTS) can be used to evaluate positions. In
exploratory studies, we demonstrate that MCTS with neural network policies
outperforms the traditionally used best-first search with hand-coded
heuristics.",2017-01-31,2017,2017-01,chemistry
CLBlast: A Tuned OpenCL BLAS Library,"This work introduces CLBlast, an open-source BLAS library providing optimized
OpenCL routines to accelerate dense linear algebra for a wide variety of
devices. It is targeted at machine learning and HPC applications and thus
provides a fast matrix-multiplication routine (GEMM) to accelerate the core of
many applications (e.g. deep learning, iterative solvers, astrophysics,
computational fluid dynamics, quantum chemistry). CLBlast has five main
advantages over other OpenCL BLAS libraries: 1) it is optimized for and tested
on a large variety of OpenCL devices including less commonly used devices such
as embedded and low-power GPUs, 2) it can be explicitly tuned for specific
problem-sizes on specific hardware platforms, 3) it can perform operations in
half-precision floating-point FP16 saving bandwidth, time and energy, 4) it has
an optional CUDA back-end, 5) and it can combine multiple operations in a
single batched routine, accelerating smaller problems significantly. This paper
describes the library and demonstrates the advantages of CLBlast experimentally
for different use-cases on a wide variety of OpenCL hardware.",2017-05-12,2017,2017-05,chemistry
"Chemception: A Deep Neural Network with Minimal Chemistry Knowledge
  Matches the Performance of Expert-developed QSAR/QSPR Models","In the last few years, we have seen the transformative impact of deep
learning in many applications, particularly in speech recognition and computer
vision. Inspired by Google's Inception-ResNet deep convolutional neural network
(CNN) for image classification, we have developed ""Chemception"", a deep CNN for
the prediction of chemical properties, using just the images of 2D drawings of
molecules. We develop Chemception without providing any additional explicit
chemistry knowledge, such as basic concepts like periodicity, or advanced
features like molecular descriptors and fingerprints. We then show how
Chemception can serve as a general-purpose neural network architecture for
predicting toxicity, activity, and solvation properties when trained on a
modest database of 600 to 40,000 compounds. When compared to multi-layer
perceptron (MLP) deep neural networks trained with ECFP fingerprints,
Chemception slightly outperforms in activity and solvation prediction and
slightly underperforms in toxicity prediction. Having matched the performance
of expert-developed QSAR/QSPR deep learning models, our work demonstrates the
plausibility of using deep neural networks to assist in computational chemistry
research, where the feature engineering process is performed primarily by a
deep learning algorithm.",2017-06-20,2017,2017-06,chemistry
Learning to Plan Chemical Syntheses,"From medicines to materials, small organic molecules are indispensable for
human well-being. To plan their syntheses, chemists employ a problem solving
technique called retrosynthesis. In retrosynthesis, target molecules are
recursively transformed into increasingly simpler precursor compounds until a
set of readily available starting materials is obtained. Computer-aided
retrosynthesis would be a highly valuable tool, however, past approaches were
slow and provided results of unsatisfactory quality. Here, we employ Monte
Carlo Tree Search (MCTS) to efficiently discover retrosynthetic routes. MCTS
was combined with an expansion policy network that guides the search, and an
""in-scope"" filter network to pre-select the most promising retrosynthetic
steps. These deep neural networks were trained on 12 million reactions, which
represents essentially all reactions ever published in organic chemistry. Our
system solves almost twice as many molecules and is 30 times faster in
comparison to the traditional search method based on extracted rules and
hand-coded heuristics. Finally after a 60 year history of computer-aided
synthesis planning, chemists can no longer distinguish between routes generated
by a computer system and real routes taken from the scientific literature. We
anticipate that our method will accelerate drug and materials discovery by
assisting chemists to plan better syntheses faster, and by enabling fully
automated robot synthesis.",2017-08-14,2017,2017-08,chemistry
Predicting Organic Reaction Outcomes with Weisfeiler-Lehman Network,"The prediction of organic reaction outcomes is a fundamental problem in
computational chemistry. Since a reaction may involve hundreds of atoms, fully
exploring the space of possible transformations is intractable. The current
solution utilizes reaction templates to limit the space, but it suffers from
coverage and efficiency issues. In this paper, we propose a template-free
approach to efficiently explore the space of product molecules by first
pinpointing the reaction center -- the set of nodes and edges where graph edits
occur. Since only a small number of atoms contribute to reaction center, we can
directly enumerate candidate products. The generated candidates are scored by a
Weisfeiler-Lehman Difference Network that models high-order interactions
between changes occurring at nodes across the molecule. Our framework
outperforms the top-performing template-based approach with a 10\% margin,
while running orders of magnitude faster. Finally, we demonstrate that the
model accuracy rivals the performance of domain experts.",2017-09-13,2017,2017-09,chemistry
"How Much Chemistry Does a Deep Neural Network Need to Know to Make
  Accurate Predictions?","The meteoric rise of deep learning models in computer vision research, having
achieved human-level accuracy in image recognition tasks is firm evidence of
the impact of representation learning of deep neural networks. In the chemistry
domain, recent advances have also led to the development of similar CNN models,
such as Chemception, that is trained to predict chemical properties using
images of molecular drawings. In this work, we investigate the effects of
systematically removing and adding localized domain-specific information to the
image channels of the training data. By augmenting images with only 3
additional basic information, and without introducing any architectural
changes, we demonstrate that an augmented Chemception (AugChemception)
outperforms the original model in the prediction of toxicity, activity, and
solvation free energy. Then, by altering the information content in the images,
and examining the resulting model's performance, we also identify two distinct
learning patterns in predicting toxicity/activity as compared to solvation free
energy. These patterns suggest that Chemception is learning about its tasks in
the manner that is consistent with established knowledge. Thus, our work
demonstrates that advanced chemical knowledge is not a pre-requisite for deep
learning models to accurately predict complex chemical properties.",2017-10-05,2017,2017-10,chemistry
Distributed Kernel K-Means for Large Scale Clustering,"Clustering samples according to an effective metric and/or vector space
representation is a challenging unsupervised learning task with a wide spectrum
of applications. Among several clustering algorithms, k-means and its
kernelized version have still a wide audience because of their conceptual
simplicity and efficacy. However, the systematic application of the kernelized
version of k-means is hampered by its inherent square scaling in memory with
the number of samples. In this contribution, we devise an approximate strategy
to minimize the kernel k-means cost function in which the trade-off between
accuracy and velocity is automatically ruled by the available system memory.
Moreover, we define an ad-hoc parallelization scheme well suited for hybrid
cpu-gpu state-of-the-art parallel architectures. We proved the effectiveness
both of the approximation scheme and of the parallelization method on standard
UCI datasets and on molecular dynamics (MD) data in the realm of computational
chemistry. In this applicative domain, clustering can play a key role for both
quantitively estimating kinetics rates via Markov State Models or to give
qualitatively a human compatible summarization of the underlying chemical
phenomenon under study. For these reasons, we selected it as a valuable
real-world application scenario.",2017-10-09,2017,2017-10,chemistry
"Using Rule-Based Labels for Weak Supervised Learning: A ChemNet for
  Transferable Chemical Property Prediction","With access to large datasets, deep neural networks (DNN) have achieved
human-level accuracy in image and speech recognition tasks. However, in
chemistry, data is inherently small and fragmented. In this work, we develop an
approach of using rule-based knowledge for training ChemNet, a transferable and
generalizable deep neural network for chemical property prediction that learns
in a weak-supervised manner from large unlabeled chemical databases. When
coupled with transfer learning approaches to predict other smaller datasets for
chemical properties that it was not originally trained on, we show that
ChemNet's accuracy outperforms contemporary DNN models that were trained using
conventional supervised learning. Furthermore, we demonstrate that the ChemNet
pre-training approach is equally effective on both CNN (Chemception) and RNN
(SMILES2vec) models, indicating that this approach is network architecture
agnostic and is effective across multiple data modalities. Our results indicate
a pre-trained ChemNet that incorporates chemistry domain knowledge, enables the
development of generalizable neural networks for more accurate prediction of
novel chemical properties.",2017-12-07,2017,2017-12,chemistry
A bright future for financial agent-based models,"The history of research in finance and economics has been widely impacted by
the field of Agent-based Computational Economics (ACE). While at the same time
being popular among natural science researchers for its proximity to the
successful methods of physics and chemistry for example, the field of ACE has
also received critics by a part of the social science community for its lack of
empiricism. Yet recent trends have shifted the weights of these general
arguments and potentially given ACE a whole new range of realism. At the base
of these trends are found two present-day major scientific breakthroughs: the
steady shift of psychology towards a hard science due to the advances of
neuropsychology, and the progress of artificial intelligence and more
specifically machine learning due to increasing computational power and big
data. These two have also found common fields of study in the form of
computational neuroscience, and human-computer interaction, among others. We
outline here the main lines of a computational research study of collective
economic behavior via Agent-Based Models (ABM) or Multi-Agent System (MAS),
where each agent would be endowed with specific cognitive and behavioral biases
known to the field of neuroeconomics, and at the same time autonomously
implement rational quantitative financial strategies updated by machine
learning. We postulate that such ABMs would offer a whole new range of realism.",2018-01-24,2018,2018-01,chemistry
"Tensor field networks: Rotation- and translation-equivariant neural
  networks for 3D point clouds","We introduce tensor field neural networks, which are locally equivariant to
3D rotations, translations, and permutations of points at every layer. 3D
rotation equivariance removes the need for data augmentation to identify
features in arbitrary orientations. Our network uses filters built from
spherical harmonics; due to the mathematical consequences of this filter
choice, each layer accepts as input (and guarantees as output) scalars,
vectors, and higher-order tensors, in the geometric sense of these terms. We
demonstrate the capabilities of tensor field networks with tasks in geometry,
physics, and chemistry.",2018-02-22,2018,2018-02,chemistry
Fractal AI: A fragile theory of intelligence,"Fractal AI is a theory for general artificial intelligence. It allows
deriving new mathematical tools that constitute the foundations for a new kind
of stochastic calculus, by modelling information using cellular automaton-like
structures instead of smooth functions. In the repository included we are
presenting a new Agent, derived from the first principles of the theory, which
is capable of solving Atari games several orders of magnitude more efficiently
than other similar techniques, like Monte Carlo Tree Search. The code provided
shows how it is now possible to beat some of the current State of The Art
benchmarks on Atari games, without previous learning and using less than 1000
samples to calculate each one of the actions when standard MCTS uses 3 Million
samples. Among other things, Fractal AI makes it possible to generate a huge
database of top performing examples with a very little amount of computation
required, transforming Reinforcement Learning into a supervised problem. The
algorithm presented is capable of solving the exploration vs exploitation
dilemma on both the discrete and continuous cases, while maintaining control
over any aspect of the behaviour of the Agent. From a general approach, new
techniques presented here have direct applications to other areas such as
Non-equilibrium thermodynamics, chemistry, quantum physics, economics,
information theory, and non-linear control theory.",2018-03-13,2018,2018-03,chemistry
"Unraveling Go gaming nature by Ising Hamiltonian and common fate graphs:
  tactics and statistics","Go gaming is a struggle between adversaries, black and white simple stones,
and aim to control the most Go board territory for success. Rules are simple
but Go game fighting is highly intricate. Stones placement and interaction on
board is random-appearance, likewise interaction phenomena among basic elements
in physics thermodynamics, chemistry, biology, or social issues. We model the
Go game dynamic employing an Ising model energy function, whose interaction
coefficients reflect the application of rules and tactics to build long-term
strategies. At any step of the game, the energy function of the model assesses
the control and strength of a player over the board. A close fit between
predictions of the model with actual game's scores is obtained. AlphaGo
computer is the current top Go player, but its behavior does not wholly reveal
the Go gaming nature. The Ising function allows for precisely model the
stochastic evolutions of Go gaming patterns, so, to advance the understanding
on Go own-dynamic -beyond the player`s abilities. The analysis of the frequency
and combination of tactics shows the formation of patterns in the groups of
stones during a game, regarding the turn of each player, or if human or
computer adversaries are confronted.",2018-03-15,2018,2018-03,chemistry
"Graph Convolutional Policy Network for Goal-Directed Molecular Graph
  Generation","Generating novel graph structures that optimize given objectives while
obeying some given underlying rules is fundamental for chemistry, biology and
social science research. This is especially important in the task of molecular
graph generation, whose goal is to discover novel molecules with desired
properties such as drug-likeness and synthetic accessibility, while obeying
physical laws such as chemical valency. However, designing models to find
molecules that optimize desired properties while incorporating highly complex
and non-differentiable rules remains to be a challenging task. Here we propose
Graph Convolutional Policy Network (GCPN), a general graph convolutional
network based model for goal-directed graph generation through reinforcement
learning. The model is trained to optimize domain-specific rewards and
adversarial loss through policy gradient, and acts in an environment that
incorporates domain-specific rules. Experimental results show that GCPN can
achieve 61% improvement on chemical property optimization over state-of-the-art
baselines while resembling known molecules, and achieve 184% improvement on the
constrained property optimization task.",2018-06-07,2018,2018-06,chemistry
"Jointly learning relevant subgraph patterns and nonlinear models of
  their indicators","Classification and regression in which the inputs are graphs of arbitrary
size and shape have been paid attention in various fields such as computational
chemistry and bioinformatics. Subgraph indicators are often used as the most
fundamental features, but the number of possible subgraph patterns are
intractably large due to the combinatorial explosion. We propose a novel
efficient algorithm to jointly learn relevant subgraph patterns and nonlinear
models of their indicators. Previous methods for such joint learning of
subgraph features and models are based on search for single best subgraph
features with specific pruning and boosting procedures of adding their
indicators one by one, which result in linear models of subgraph indicators. In
contrast, the proposed approach is based on directly learning regression trees
for graph inputs using a newly derived bound of the total sum of squares for
data partitions by a given subgraph feature, and thus can learn nonlinear
models through standard gradient boosting. An illustrative example we call the
Graph-XOR problem to consider nonlinearity, numerical experiments with real
datasets, and scalability comparisons to naive approaches using explicit
pattern enumeration are also presented.",2018-07-09,2018,2018-07,chemistry
"Evaluation as a Service architecture and crowdsourced problems solving
  implemented in Optil.io platform","Reliable and trustworthy evaluation of algorithms is a challenging process.
Firstly, each algorithm has its strengths and weaknesses, and the selection of
test instances can significantly influence the assessment process. Secondly,
the measured performance of the algorithm highly depends on the test
environment architecture, i.e., CPU model, available memory, cache
configuration, operating system's kernel, and even compilation flags. Finally,
it is often difficult to compare algorithm with software prepared by other
researchers. Evaluation as a Service (EaaS) is a cloud computing architecture
that tries to make assessment process more reliable by providing online tools
and test instances dedicated to the evaluation of algorithms. One of such
platforms is Optil.io which gives the possibility to define problems, store
evaluation data and evaluate solutions submitted by researchers in almost real
time. In this paper, we briefly present this platform together with four
challenges that were organized with its support.",2018-07-14,2018,2018-07,chemistry
Optimization of Molecules via Deep Reinforcement Learning,"We present a framework, which we call Molecule Deep $Q$-Networks (MolDQN),
for molecule optimization by combining domain knowledge of chemistry and
state-of-the-art reinforcement learning techniques (double $Q$-learning and
randomized value functions). We directly define modifications on molecules,
thereby ensuring 100\% chemical validity. Further, we operate without
pre-training on any dataset to avoid possible bias from the choice of that set.
Inspired by problems faced during medicinal chemistry lead optimization, we
extend our model with multi-objective reinforcement learning, which maximizes
drug-likeness while maintaining similarity to the original molecule. We further
show the path through chemical space to achieve optimization for a molecule to
understand how the model works.",2018-10-19,2018,2018-10,chemistry
"Physics Guided RNNs for Modeling Dynamical Systems: A Case Study in
  Simulating Lake Temperature Profiles","This paper proposes a physics-guided recurrent neural network model (PGRNN)
that combines RNNs and physics-based models to leverage their complementary
strengths and improve the modeling of physical processes. Specifically, we show
that a PGRNN can improve prediction accuracy over that of physical models,
while generating outputs consistent with physical laws, and achieving good
generalizability. Standard RNNs, even when producing superior prediction
accuracy, often produce physically inconsistent results and lack
generalizability. We further enhance this approach by using a pre-training
method that leverages the simulated data from a physics-based model to address
the scarcity of observed data. The PGRNN has the flexibility to incorporate
additional physical constraints and we incorporate a density-depth
relationship. Both enhancements further improve PGRNN performance. Although we
present and evaluate this methodology in the context of modeling the dynamics
of temperature in lakes, it is applicable more widely to a range of scientific
and engineering disciplines where mechanistic (also known as process-based)
models are used, e.g., power engineering, climate science, materials science,
computational chemistry, and biomedicine.",2018-10-31,2018,2018-10,chemistry
"Multi-Label Robust Factorization Autoencoder and its Application in
  Predicting Drug-Drug Interactions","Drug-drug interactions (DDIs) are a major cause of preventable
hospitalizations and deaths. Predicting the occurrence of DDIs helps drug
safety professionals allocate investigative resources and take appropriate
regulatory action promptly. Traditional DDI prediction methods predict DDIs
based on the similarity between drugs. Recently, researchers revealed that
predictive performance can be improved by better modeling the interactions
between drug pairs with bilinear forms. However, the shallow models leveraging
bilinear forms suffer from limitations on capturing complicated nonlinear
interactions between drug pairs. To this end, we propose Multi-Label Robust
Factorization Autoencoder (abbreviated to MuLFA) for DDI prediction, which
learns a representation of interactions between drug pairs and has the
capability of characterizing complicated nonlinear interactions more precisely.
Moreover, a novel loss called CuXCov is designed to effectively learn the
parameters of MuLFA. Furthermore, the decoder is able to generate high-risk
chemical structures of drug pairs for specific DDIs, assisting pharmacists to
better understand the relationship between drug chemistry and DDI. Experimental
results on real-world datasets demonstrate that MuLFA consistently outperforms
state-of-the-art methods; particularly, it increases 21:3% predictive
performance compared to the best baseline for top 50 frequent DDIs.We also
illustrate various case studies to demonstrate the efficacy of the chemical
structures generated by MuLFA in DDI diagnosis.",2018-11-01,2018,2018-11,chemistry
"Linear and Nonlinear Identification of Dryer System Using Artificial
  Intelligence and Neural Networks","As you read these words you are using a complex biological neural network.
You have a highly interconnected set of some neurons to facilitate your
reading, breathing, motion and thinking. Each of your biological neurons, a
rich assembly of tissue and chemistry, has the complexity, if not the speed, of
a microprocessor. Some of your neural structure was with you at birth. Other
parts have been established by experience.",2018-11-16,2018,2018-11,chemistry
"ParsRec: A Novel Meta-Learning Approach to Recommending Bibliographic
  Reference Parsers","Bibliographic reference parsers extract machine-readable metadata such as
author names, title, journal, and year from bibliographic reference strings. To
extract the metadata, the parsers apply heuristics or machine learning.
However, no reference parser, and no algorithm, consistently gives the best
results in every scenario. For instance, one tool may be best in extracting
titles in ACM citation style, but only third best when APA is used. Another
tool may be best in extracting English author names, while another one is best
for noisy data (i.e. inconsistent citation styles). In this paper, which is an
extended version of our recent RecSys poster, we address the problem of
reference parsing from a recommender-systems and meta-learning perspective. We
propose ParsRec, a meta-learning based recommender-system that recommends the
potentially most effective parser for a given reference string. ParsRec
recommends one out of 10 open-source parsers: Anystyle-Parser, Biblio, CERMINE,
Citation, Citation-Parser, GROBID, ParsCit, PDFSSA4MET, Reference Tagger, and
Science Parse. We evaluate ParsRec on 105k references from chemistry. We
propose two approaches to meta-learning recommendations. The first approach
learns the best parser for an entire reference string. The second approach
learns the best parser for each metadata type in a reference string. The second
approach achieved a 2.6% increase in F1 (0.909 vs. 0.886) over the best single
parser (GROBID), reducing the false positive rate by 20.2% (0.075 vs. 0.094),
and the false negative rate by 18.9% (0.107 vs. 0.132).",2018-11-26,2018,2018-11,chemistry
"Molecular Sets (MOSES): A Benchmarking Platform for Molecular Generation
  Models","Generative models are becoming a tool of choice for exploring the molecular
space. These models learn on a large training dataset and produce novel
molecular structures with similar properties. Generated structures can be
utilized for virtual screening or training semi-supervised predictive models in
the downstream tasks. While there are plenty of generative models, it is
unclear how to compare and rank them. In this work, we introduce a benchmarking
platform called Molecular Sets (MOSES) to standardize training and comparison
of molecular generative models. MOSES provides a training and testing datasets,
and a set of metrics to evaluate the quality and diversity of generated
structures. We have implemented and compared several molecular generation
models and suggest to use our results as reference points for further
advancements in generative chemistry research. The platform and source code are
available at https://github.com/molecularsets/moses.",2018-11-29,2018,2018-11,chemistry
Tensor networks for complex quantum systems,"Tensor network states and methods have erupted in recent years. Originally
developed in the context of condensed matter physics and based on
renormalization group ideas, tensor networks lived a revival thanks to quantum
information theory and the understanding of entanglement in quantum many-body
systems. Moreover, it has been not-so-long realized that tensor network states
play a key role in other scientific disciplines, such as quantum gravity and
artificial intelligence. In this context, here we provide an overview of basic
concepts and key developments in the field. In particular, we briefly discuss
the most important tensor network structures and algorithms, together with a
sketch on advances related to global and gauge symmetries, fermions,
topological order, classification of phases, entanglement Hamiltonians,
AdS/CFT, artificial intelligence, the 2d Hubbard model, 2d quantum
antiferromagnets, conformal field theory, quantum chemistry, disordered
systems, and many-body localization.",2018-12-10,2018,2018-12,chemistry
"Design of materials properties and device performance in memristive
  systems","Future development of the modern nanoelectronics and its flagships internet
of things and artificial intelligence as well as many related applications is
largely associated with memristive elements. This technology offers a broad
spectrum of functionalities, however, it follows predominantly a
phenomenological approach and crucial challenge/limit for further development
remains variability and lack of fundamental materials' design strategy. Here we
demonstrate the vital importance of materials' purity for determining
memristors' functionalities, showing that part per million foreign elements
significantly change the performance. By appropriate choice of chemistry and
amount of doping material we can selectively enhance desired operation mode. We
highlight how dopant dependent structure and charge/potential distribution in
the space charge layers and the cell capacitance determine the device kinetics
and functions. We evidence for first time experimentally the relation between
materials properties and switching/neuromorphic performance, thus providing
rules and directions for a rational design of memristive devices.",2019-02-05,2019,2019-02,chemistry
Atomistic structure learning,"One endeavour of modern physical chemistry is to use bottom-up approaches to
design materials and drugs with desired properties. Here we introduce an
atomistic structure learning algorithm (ASLA) that utilizes a convolutional
neural network to build 2D compounds and layered structures atom by atom. The
algorithm takes no prior data or knowledge on atomic interactions but inquires
a first-principles quantum mechanical program for physical properties. Using
reinforcement learning, the algorithm accumulates knowledge of chemical
compound space for a given number and type of atoms and stores this in the
neural network, ultimately learning the blueprint for the optimal structural
arrangement of the atoms for a given target property. ASLA is demonstrated to
work on diverse problems, including grain boundaries in graphene sheets,
organic compound formation and a surface oxide structure. This approach to
structure prediction is a first step toward direct manipulation of atoms with
artificially intelligent first principles computer codes.",2019-02-27,2019,2019-02,chemistry
Accelerated Nuclear Magnetic Resonance Spectroscopy with Deep Learning,"Nuclear magnetic resonance (NMR) spectroscopy serves as an indispensable tool
in chemistry and biology but often suffers from long experimental time. We
present a proof-of-concept of application of deep learning and neural network
for high-quality, reliable, and very fast NMR spectra reconstruction from
limited experimental data. We show that the neural network training can be
achieved using solely synthetic NMR signal, which lifts the prohibiting demand
for a large volume of realistic training data usually required in the deep
learning approach.",2019-04-09,2019,2019-04,chemistry
"Exploration of Self-Propelling Droplets Using a Curiosity Driven Robotic
  Assistant","We describe a chemical robotic assistant equipped with a curiosity algorithm
(CA) that can efficiently explore the state a complex chemical system can
exhibit. The CA-robot is designed to explore formulations in an open-ended way
with no explicit optimization target. By applying the CA-robot to the study of
self-propelling multicomponent oil-in-water droplets, we are able to observe an
order of magnitude more variety of droplet behaviours than possible with a
random parameter search and given the same budget. We demonstrate that the
CA-robot enabled the discovery of a sudden and highly specific response of
droplets to slight temperature changes. Six modes of self-propelled droplets
motion were identified and classified using a time-temperature phase diagram
and probed using a variety of techniques including NMR. This work illustrates
how target free search can significantly increase the rate of unpredictable
observations leading to new discoveries with potential applications in
formulation chemistry.",2019-04-22,2019,2019-04,chemistry
From Ans√§tze to Z-gates: a NASA View of Quantum Computing,"For the last few years, the NASA Quantum Artificial Intelligence Laboratory
(QuAIL) has been performing research to assess the potential impact of quantum
computers on challenging computational problems relevant to future NASA
missions. A key aspect of this research is devising methods to most effectively
utilize emerging quantum computing hardware. Research questions include what
experiments on early quantum hardware would give the most insight into the
potential impact of quantum computing, the design of algorithms to explore on
such hardware, and the development of tools to minimize the quantum resource
requirements. We survey work relevant to these questions, with a particular
emphasis on our recent work in quantum algorithms and applications, in
elucidating mechanisms of quantum mechanics and their uses for quantum
computational purposes, and in simulation, compilation, and physics-inspired
classical algorithms. To our early application thrusts in planning and
scheduling, fault diagnosis, and machine learning, we add thrusts related to
robustness of communication networks and the simulation of many-body systems
for material science and chemistry. We provide a brief update on quantum
annealing work, but concentrate on gate-model quantum computing research
advances within the last couple of years.",2019-05-08,2019,2019-05,chemistry
Explainability Techniques for Graph Convolutional Networks,"Graph Networks are used to make decisions in potentially complex scenarios
but it is usually not obvious how or why they made them. In this work, we study
the explainability of Graph Network decisions using two main classes of
techniques, gradient-based and decomposition-based, on a toy dataset and a
chemistry task. Our study sets the ground for future development as well as
application to real-world problems.",2019-05-31,2019,2019-05,chemistry
"Molecular Property Prediction: A Multilevel Quantum Interactions
  Modeling Perspective","Predicting molecular properties (e.g., atomization energy) is an essential
issue in quantum chemistry, which could speed up much research progress, such
as drug designing and substance discovery. Traditional studies based on density
functional theory (DFT) in physics are proved to be time-consuming for
predicting large number of molecules. Recently, the machine learning methods,
which consider much rule-based information, have also shown potentials for this
issue. However, the complex inherent quantum interactions of molecules are
still largely underexplored by existing solutions. In this paper, we propose a
generalizable and transferable Multilevel Graph Convolutional neural Network
(MGCN) for molecular property prediction. Specifically, we represent each
molecule as a graph to preserve its internal structure. Moreover, the
well-designed hierarchical graph neural network directly extracts features from
the conformation and spatial information followed by the multilevel
interactions. As a consequence, the multilevel overall representations can be
utilized to make the prediction. Extensive experiments on both datasets of
equilibrium and off-equilibrium molecules demonstrate the effectiveness of our
model. Furthermore, the detailed results also prove that MGCN is generalizable
and transferable for the prediction.",2019-06-25,2019,2019-06,chemistry
"The Ramanujan Machine: Automatically Generated Conjectures on
  Fundamental Constants","Fundamental mathematical constants like $e$ and $\pi$ are ubiquitous in
diverse fields of science, from abstract mathematics to physics, biology and
chemistry. For centuries, new formulas relating fundamental constants have been
scarce and usually discovered sporadically. Here we propose a novel and
systematic approach that leverages algorithms for deriving mathematical
formulas for fundamental constants and help reveal their underlying structure.
Our algorithms find dozens of well-known as well as previously unknown
continued fraction representations of $\pi$, $e$, Catalan's constant, and
values of the Riemann zeta function. Two example conjectures found by our
algorithm and so far unproven are: \begin{equation*} \frac{24}{\pi^2} = 2 +
7\cdot 0\cdot 1+ \frac{8\cdot1^4}{2 + 7\cdot 1\cdot 2 + \frac{8\cdot2^4}{2 +
7\cdot 2\cdot 3 + \frac{8\cdot3^4}{2 + 7\cdot 3\cdot 4 +
\frac{8\cdot4^4}{..}}}} \quad\quad,\quad\quad \frac{8}{7 \zeta(3)} = 1\cdot 1 -
\frac{1^6}{3\cdot 7 - \frac{2^6}{5\cdot 19 - \frac{3^6}{7\cdot 37 -
\frac{4^6}{..}}}} \end{equation*} We present two algorithms that proved useful
in finding conjectures: a Meet-In-The-Middle (MITM) algorithm and a Gradient
Descent (GD) tailored to the recurrent structure of continued fractions. Both
algorithms are based on matching numerical values and thus they conjecture
formulas without providing proofs and without requiring prior knowledge on any
underlying mathematical structure. This approach is especially attractive for
constants for which no mathematical structure is known, as it reverses the
conventional approach of sequential logic in formal proofs. Instead, our work
supports a different approach for research: algorithms utilizing numerical data
to unveil mathematical structures, thus trying to play the role of intuition of
great mathematicians of the past, providing leads to new mathematical research.",2019-06-29,2019,2019-06,chemistry
"Multiple-objective Reinforcement Learning for Inverse Design and
  Identification","The aim of the inverse chemical design is to develop new molecules with given
optimized molecular properties or objectives. Recently, generative deep
learning (DL) networks are considered as the state-of-the-art in inverse
chemical design and have achieved early success in generating molecular
structures with desired properties in the pharmaceutical and material chemistry
fields. However, satisfying a large number (larger than 10 objectives) of
molecular objectives is a limitation of current generative models. To improve
the model's ability to handle a large number of molecule design objectives, we
developed a Reinforcement Learning (RL) based generative framework to optimize
chemical molecule generation. Our use of Curriculum Learning (CL) to fine-tune
the pre-trained generative network allowed the model to satisfy up to 21
objectives and increase the generative network's robustness. The experiments
show that the proposed multiple-objective RL-based generative model can
correctly identify unknown molecules with an 83 to 100 percent success rate,
compared to the baseline approach of 0 percent. Additionally, this proposed
generative model is not limited to just chemistry research challenges; we
anticipate that problems that utilize RL with multiple-objectives will benefit
from this framework.",2019-10-09,2019,2019-10,chemistry
"DEFT-FUNNEL: an open-source global optimization solver for constrained
  grey-box and black-box problems","The fast-growing need for grey-box and black-box optimization methods for
constrained global optimization problems in fields such as medicine, chemistry,
engineering and artificial intelligence, has contributed for the design of new
efficient algorithms for finding the best possible solution. In this work, we
present DEFT-FUNNEL, an open-source global optimization algorithm for general
constrained grey-box and black-box problems that belongs to the class of
trust-region sequential quadratic optimization algorithms. It extends the
previous works by Sampaio and Toint (2015, 2016) to a global optimization
solver that is able to exploit information from closed-form functions.
Polynomial interpolation models are used as surrogates for the black-box
functions and a clustering-based multistart strategy is applied for searching
for the global minima. Numerical experiments show that DEFT-FUNNEL compares
favorably with other state-of-the-art methods on two sets of benchmark
problems: one set containing problems where every function is a black box and
another set with problems where some of the functions and their derivatives are
known to the solver. The code as well as the test sets used for experiments are
available at the Github repository http://github.com/phrsampaio/deft-funnel.",2019-12-29,2019,2019-12,chemistry
"Emo-CNN for Perceiving Stress from Audio Signals: A Brain Chemistry
  Approach","Emotion plays a key role in many applications like healthcare, to gather
patients emotional behavior. There are certain emotions which are given more
importance due to their effectiveness in understanding human feelings. In this
paper, we propose an approach that models human stress from audio signals. The
research challenge in speech emotion detection is defining the very meaning of
stress and being able to categorize it in a precise manner. Supervised Machine
Learning models, including state of the art Deep Learning classification
methods, rely on the availability of clean and labelled data. One of the
problems in affective computation and emotion detection is the limited amount
of annotated data of stress. The existing labelled stress emotion datasets are
highly subjective to the perception of the annotator.
  We address the first issue of feature selection by exploiting the use of
traditional MFCC features in Convolutional Neural Network. Our experiments show
that Emo-CNN consistently and significantly outperforms the popular existing
methods over multiple datasets. It achieves 90.2% categorical accuracy on the
Emo-DB dataset. To tackle the second and the more significant problem of
subjectivity in stress labels, we use Lovheim's cube, which is a 3-dimensional
projection of emotions. The cube aims at explaining the relationship between
these neurotransmitters and the positions of emotions in 3D space. The learnt
emotion representations from the Emo-CNN are mapped to the cube using three
component PCA (Principal Component Analysis) which is then used to model human
stress. This proposed approach not only circumvents the need for labelled
stress data but also complies with the psychological theory of emotions given
by Lovheim's cube. We believe that this work is the first step towards creating
a connection between Artificial Intelligence and the chemistry of human
emotions.",2020-01-08,2020,2020-01,chemistry
"Scientific AI in materials science: a path to a sustainable and scalable
  paradigm","Recently there has been an ever-increasing trend in the use of machine
learning (ML) and artificial intelligence (AI) methods by the materials
science, condensed matter physics, and chemistry communities. This perspective
article identifies key scientific, technical, and social opportunities that the
materials community must prioritize to consistently develop and leverage
Scientific AI to provide a credible path towards the advancement of current
materials-limited technologies. Here we highlight the intersections of these
opportunities with a series of proposed paths forward. The opportunities are
roughly sorted from scientific/technical (e.g., development of robust,
physically meaningful multiscale material representations) to social (e.g.,
promoting an AI-ready workforce). The proposed paths forward range from
developing new infrastructure and capabilities to deploying them in industry
and academia. We provide a brief introduction to AI in materials science and
engineering, followed by detailed discussions of each of the opportunities and
paths forward.",2020-03-18,2020,2020-03,chemistry
Autonomous discovery in the chemical sciences part I: Progress,"This two-part review examines how automation has contributed to different
aspects of discovery in the chemical sciences. In this first part, we describe
a classification for discoveries of physical matter (molecules, materials,
devices), processes, and models and how they are unified as search problems. We
then introduce a set of questions and considerations relevant to assessing the
extent of autonomy. Finally, we describe many case studies of discoveries
accelerated by or resulting from computer assistance and automation from the
domains of synthetic chemistry, drug discovery, inorganic chemistry, and
materials science. These illustrate how rapid advancements in hardware
automation and machine learning continue to transform the nature of
experimentation and modelling.
  Part two reflects on these case studies and identifies a set of open
challenges for the field.",2020-03-30,2020,2020-03,chemistry
"Artificial chemistry experiments with chemlambda, lambda calculus,
  interaction combinators","Given a graph rewrite system, a graph G is a quine graph if it has a non-void
maximal collection of non-conflicting matches of left patterns of graphs
rewrites, such that after the parallel application of the rewrites we obtain a
graph isomorphic with G. Such graphs exhibit a metabolism, they can multiply or
they can die, when reduced by a random rewriting algorithm.
  These are introductory notes to the pages of artificial chemistry experiments
with chemlambda, lambda calculus or interaction combinators, available from the
entry page https://chemlambda.github.io/index.html . The experiments are
bundled into pages, all of them based on a library of programs, on a database
which contains hundreds of graphs and on a database of about 150 pages of text
comments and a collection of more than 200 animations, most of them which can
be re-done live, via the programs. There are links to public repositories of
other contributors to these experiments, with versions of these programs in
python, haskell, awk or javascript.",2020-03-31,2020,2020-03,chemistry
"Artificial life properties of directed interaction combinators vs.
  chemlambda","We provide a framework for experimentation at
https://mbuliga.github.io/quinegraphs/ic-vs-chem.html#icvschem with two
artificial chemistries: directed interaction combinators (dirIC, defined in
section 2) and chemlambda. We are interested if these chemistries allow for
artificial life behaviour: replication, metabolism and death.
  The main conclusion of these experiments is that graph rewrites systems which
allow conflicting rewrites are better than those which don't, as concerns their
artificial life properties. This is in contradiction with the search for good
graph rewrite systems for decentralized computing, where non-conflicting graph
rewrite systems are historically preferred.
  This continues the artificial chemistry experiments with chemlambda, lambda
calculus or interaction combinators, available from the entry page at
https://chemlambda.github.io/index.html and described in arXiv:2003.14332.",2020-05-12,2020,2020-05,chemistry
Higher-Order Explanations of Graph Neural Networks via Relevant Walks,"Graph Neural Networks (GNNs) are a popular approach for predicting graph
structured data. As GNNs tightly entangle the input graph into the neural
network structure, common explainable AI approaches are not applicable. To a
large extent, GNNs have remained black-boxes for the user so far. In this
paper, we show that GNNs can in fact be naturally explained using higher-order
expansions, i.e. by identifying groups of edges that jointly contribute to the
prediction. Practically, we find that such explanations can be extracted using
a nested attribution scheme, where existing techniques such as layer-wise
relevance propagation (LRP) can be applied at each step. The output is a
collection of walks into the input graph that are relevant for the prediction.
Our novel explanation method, which we denote by GNN-LRP, is applicable to a
broad range of graph neural networks and lets us extract practically relevant
insights on sentiment analysis of text data, structure-property relationships
in quantum chemistry, and image classification.",2020-06-05,2020,2020-06,chemistry
Retro*: Learning Retrosynthetic Planning with Neural Guided A* Search,"Retrosynthetic planning is a critical task in organic chemistry which
identifies a series of reactions that can lead to the synthesis of a target
product. The vast number of possible chemical transformations makes the size of
the search space very big, and retrosynthetic planning is challenging even for
experienced chemists. However, existing methods either require expensive return
estimation by rollout with high variance, or optimize for search speed rather
than the quality. In this paper, we propose Retro*, a neural-based A*-like
algorithm that finds high-quality synthetic routes efficiently. It maintains
the search as an AND-OR tree, and learns a neural search bias with off-policy
data. Then guided by this neural network, it performs best-first search
efficiently during new planning episodes. Experiments on benchmark USPTO
datasets show that, our proposed method outperforms existing state-of-the-art
with respect to both the success rate and solution quality, while being more
efficient at the same time.",2020-06-29,2020,2020-06,chemistry
Machine learning for electronically excited states of molecules,"Electronically excited states of molecules are at the heart of
photochemistry, photophysics, as well as photobiology and also play a role in
material science. Their theoretical description requires highly accurate
quantum chemical calculations, which are computationally expensive. In this
review, we focus on how machine learning is employed not only to speed up such
excited-state simulations but also how this branch of artificial intelligence
can be used to advance this exciting research field in all its aspects.
Discussed applications of machine learning for excited states include
excited-state dynamics simulations, static calculations of absorption spectra,
as well as many others. In order to put these studies into context, we discuss
the promises and pitfalls of the involved machine learning techniques. Since
the latter are mostly based on quantum chemistry calculations, we also provide
a short introduction into excited-state electronic structure methods,
approaches for nonadiabatic dynamics simulations and describe tricks and
problems when using them in machine learning for excited states of molecules.",2020-07-10,2020,2020-07,chemistry
Toward the quantification of cognition,"The machinery of the human brain -- analog, probabilistic, embodied -- can be
characterized computationally, but what machinery confers what computational
powers? Any such system can be abstractly cast in terms of two computational
components: a finite state machine carrying out computational steps, whether
via currents, chemistry, or mechanics; plus a set of allowable memory
operations, typically formulated in terms of an information store that can be
read from and written to, whether via synaptic change, state transition, or
recurrent activity. Probing these mechanisms for their information content, we
can capture the difference in computational power that various systems are
capable of. Most human cognitive abilities, from perception to action to
memory, are shared with other species; we seek to characterize those (few)
capabilities that are ubiquitously present among humans and absent from other
species. Three realms of formidable constraints -- a) measurable human
cognitive abilities, b) measurable allometric anatomic brain characteristics,
and c) measurable features of specific automata and formal grammars --
illustrate remarkably sharp restrictions on human abilities, unexpectedly
confining human cognition to a specific class of automata (""nested stack""),
which are markedly below Turing machines.",2020-08-12,2020,2020-08,chemistry
"Generative chemistry: drug discovery with deep learning generative
  models","The de novo design of molecular structures using deep learning generative
models introduces an encouraging solution to drug discovery in the face of the
continuously increased cost of new drug development. From the generation of
original texts, images, and videos, to the scratching of novel molecular
structures, the incredible creativity of deep learning generative models
surprised us about the height machine intelligence can achieve. The purpose of
this paper is to review the latest advances in generative chemistry which
relies on generative modeling to expedite the drug discovery process. This
review starts with a brief history of artificial intelligence in drug discovery
to outline this emerging paradigm. Commonly used chemical databases, molecular
representations, and tools in cheminformatics and machine learning are covered
as the infrastructure for the generative chemistry. The detailed discussions on
utilizing cutting-edge generative architectures, including recurrent neural
network, variational autoencoder, adversarial autoencoder, and generative
adversarial network for compound generation are focused. Challenges and future
perspectives follow.",2020-08-20,2020,2020-08,chemistry
Shannon Entropy Rate of Hidden Markov Processes,"Hidden Markov chains are widely applied statistical models of stochastic
processes, from fundamental physics and chemistry to finance, health, and
artificial intelligence. The hidden Markov processes they generate are
notoriously complicated, however, even if the chain is finite state: no finite
expression for their Shannon entropy rate exists, as the set of their
predictive features is generically infinite. As such, to date one cannot make
general statements about how random they are nor how structured. Here, we
address the first part of this challenge by showing how to efficiently and
accurately calculate their entropy rates. We also show how this method gives
the minimal set of infinite predictive features. A sequel addresses the
challenge's second part on structure.",2020-08-29,2020,2020-08,chemistry
"On Open and Strong-Scaling Tools for Atom Probe Crystallography:
  High-Throughput Methods for Indexing Crystal Structure and Orientation","Volumetric crystal structure indexing and orientation mapping are key data
processing steps for virtually any quantitative study of spatial correlations
between the local chemistry and the microstructure of a material. For electron
and X-ray diffraction methods it is possible to develop indexing tools which
compare measured and analytically computed patterns to decode the structure and
relative orientation within local regions of interest. Consequently, a number
of numerically efficient and automated software tools exist to solve the above
characterisation tasks.
  For atom probe tomography (APT) experiments, however, the strategy of making
comparisons between measured and analytically computed patterns is less robust
because many APT datasets may contain substantial noise. Given that general
enough predictive models for such noise remain elusive, crystallography tools
for APT face several limitations: Their robustness to noise, and therefore,
their capability to identify and distinguish different crystal structures and
orientation is limited. In addition, the tools are sequential and demand
substantial manual interaction. In combination, this makes robust uncertainty
quantifying with automated high-throughput studies of the latent
crystallographic information a difficult task with APT data.
  To improve the situation, we review the existent methods and discuss how they
link to those in the diffraction communities. With this we modify some of the
APT methods to yield more robust descriptors of the atomic arrangement. We
report how this enables the development of an open-source software tool for
strong-scaling and automated identifying of crystal structure and mapping
crystal orientation in nanocrystalline APT datasets with multiple phases.",2020-09-01,2020,2020-09,chemistry
"Testing the Quantitative Spacetime Hypothesis using Artificial Narrative
  Comprehension (II) : Establishing the Geometry of Invariant Concepts, Themes,
  and Namespaces","Given a pool of observations selected from a sensor stream, input data can be
robustly represented, via a multiscale process, in terms of invariant concepts,
and themes. Applying this to episodic natural language data, one may obtain a
graph geometry associated with the decomposition, which is a direct encoding of
spacetime relationships for the events. This study contributes to an ongoing
application of the Semantic Spacetime Hypothesis, and demonstrates the
unsupervised analysis of narrative texts using inexpensive computational
methods without knowledge of linguistics. Data streams are parsed and
fractionated into small constituents, by multiscale interferometry, in the
manner of bioinformatic analysis. Fragments may then be recombined to construct
original sensory episodes---or form new narratives by a chemistry of
association and pattern reconstruction, based only on the four fundamental
spacetime relationships. There is a straightforward correspondence between
bioinformatic processes and this cognitive representation of natural language.
Features identifiable as `concepts' and `narrative themes' span three main
scales (micro, meso, and macro). Fragments of the input act as symbols in a
hierarchy of alphabets that define new effective languages at each scale.",2020-09-23,2020,2020-09,chemistry
Information Obfuscation of Graph Neural Networks,"While the advent of Graph Neural Networks (GNNs) has greatly improved node
and graph representation learning in many applications, the neighborhood
aggregation scheme exposes additional vulnerabilities to adversaries seeking to
extract node-level information about sensitive attributes. In this paper, we
study the problem of protecting sensitive attributes by information obfuscation
when learning with graph structured data. We propose a framework to locally
filter out pre-determined sensitive attributes via adversarial training with
the total variation and the Wasserstein distance. Our method creates a strong
defense against inference attacks, while only suffering small loss in task
performance. Theoretically, we analyze the effectiveness of our framework
against a worst-case adversary, and characterize an inherent trade-off between
maximizing predictive accuracy and minimizing information leakage. Experiments
across multiple datasets from recommender systems, knowledge graphs and quantum
chemistry demonstrate that the proposed approach provides a robust defense
across various graph structures and tasks, while producing competitive GNN
encoders for downstream tasks.",2020-09-28,2020,2020-09,chemistry
End-to-End Differentiable Molecular Mechanics Force Field Construction,"Molecular mechanics (MM) potentials have long been a workhorse of
computational chemistry. Leveraging accuracy and speed, these functional forms
find use in a wide variety of applications in biomolecular modeling and drug
discovery, from rapid virtual screening to detailed free energy calculations.
Traditionally, MM potentials have relied on human-curated, inflexible, and
poorly extensible discrete chemical perception rules or applying parameters to
small molecules or biopolymers, making it difficult to optimize both types and
parameters to fit quantum chemical or physical property data. Here, we propose
an alternative approach that uses graph neural networks to perceive chemical
environments, producing continuous atom embeddings from which valence and
nonbonded parameters can be predicted using invariance-preserving layers. Since
all stages are built from smooth neural functions, the entire process is
modular and end-to-end differentiable with respect to model parameters,
allowing new force fields to be easily constructed, extended, and applied to
arbitrary molecules. We show that this approach is not only sufficiently
expressive to reproduce legacy atom types, but that it can learn to accurately
reproduce and extend existing molecular mechanics force fields. Trained with
arbitrary loss functions, it can construct entirely new force fields
self-consistently applicable to both biopolymers and small molecules directly
from quantum chemical calculations, with superior fidelity than traditional
atom or parameter typing schemes. When trained on the same quantum chemical
small molecule dataset used to parameterize the openff-1.2.0 small molecule
force field augmented with a peptide dataset, the resulting espaloma model
shows superior accuracy vis-\`a-vis experiments in computing relative
alchemical free energy calculations for a popular benchmark set.",2020-10-02,2020,2020-10,chemistry
Scientific intuition inspired by machine learning generated hypotheses,"Machine learning with application to questions in the physical sciences has
become a widely used tool, successfully applied to classification, regression
and optimization tasks in many areas. Research focus mostly lies in improving
the accuracy of the machine learning models in numerical predictions, while
scientific understanding is still almost exclusively generated by human
researchers analysing numerical results and drawing conclusions. In this work,
we shift the focus on the insights and the knowledge obtained by the machine
learning models themselves. In particular, we study how it can be extracted and
used to inspire human scientists to increase their intuitions and understanding
of natural systems. We apply gradient boosting in decision trees to extract
human interpretable insights from big data sets from chemistry and physics. In
chemistry, we not only rediscover widely know rules of thumb but also find new
interesting motifs that tell us how to control solubility and energy levels of
organic molecules. At the same time, in quantum physics, we gain new
understanding on experiments for quantum entanglement. The ability to go beyond
numerics and to enter the realm of scientific insight and hypothesis generation
opens the door to use machine learning to accelerate the discovery of
conceptual understanding in some of the most challenging domains of science.",2020-10-27,2020,2020-10,chemistry
Social Chemistry 101: Learning to Reason about Social and Moral Norms,"Social norms -- the unspoken commonsense rules about acceptable social
behavior -- are crucial in understanding the underlying causes and intents of
people's actions in narratives. For example, underlying an action such as
""wanting to call cops on my neighbors"" are social norms that inform our
conduct, such as ""It is expected that you report crimes.""
  We present Social Chemistry, a new conceptual formalism to study people's
everyday social norms and moral judgments over a rich spectrum of real life
situations described in natural language. We introduce Social-Chem-101, a
large-scale corpus that catalogs 292k rules-of-thumb such as ""it is rude to run
a blender at 5am"" as the basic conceptual units. Each rule-of-thumb is further
broken down with 12 different dimensions of people's judgments, including
social judgments of good and bad, moral foundations, expected cultural
pressure, and assumed legality, which together amount to over 4.5 million
annotations of categorical labels and free-text descriptions.
  Comprehensive empirical results based on state-of-the-art neural models
demonstrate that computational modeling of social norms is a promising research
direction. Our model framework, Neural Norm Transformer, learns and generalizes
Social-Chem-101 to successfully reason about previously unseen situations,
generating relevant (and potentially novel) attribute-aware social
rules-of-thumb.",2020-11-01,2020,2020-11,chemistry
"Molecular representation learning with language models and
  domain-relevant auxiliary tasks","We apply a Transformer architecture, specifically BERT, to learn flexible and
high quality molecular representations for drug discovery problems. We study
the impact of using different combinations of self-supervised tasks for
pre-training, and present our results for the established Virtual Screening and
QSAR benchmarks. We show that: i) The selection of appropriate self-supervised
task(s) for pre-training has a significant impact on performance in subsequent
downstream tasks such as Virtual Screening. ii) Using auxiliary tasks with more
domain relevance for Chemistry, such as learning to predict calculated
molecular properties, increases the fidelity of our learnt representations.
iii) Finally, we show that molecular representations learnt by our model
`MolBert' improve upon the current state of the art on the benchmark datasets.",2020-11-26,2020,2020-11,chemistry
"Data-driven equation for drug-membrane permeability across drugs and
  membranes","Drug efficacy depends on its capacity to permeate across the cell membrane.
We consider the prediction of passive drug-membrane permeability coefficients.
Beyond the widely recognized correlation with hydrophobicity, we additionally
consider the functional relationship between passive permeation and acidity. To
discover easily interpretable equations that explain the data well, we use the
recently proposed sure-independence screening and sparsifying operator (SISSO),
an artificial-intelligence technique that combines symbolic regression with
compressed sensing. Our study is based on a large in silico dataset of 0.4
million small molecules extracted from coarse-grained simulations. We
rationalize the equation suggested by SISSO via an analysis of the
inhomogeneous solubility-diffusion model in several asymptotic acidity regimes.
We further extend our analysis to the dependence on lipid-membrane composition.
Lipid-tail unsaturation plays a key role, but surprisingly contributes stepwise
rather than proportionally. Our results are in line with previously observed
changes in permeability, suggesting the distinction between liquid-disordered
(Ld) and liquid-ordered (Lo) permeation. Together, compressed sensing with
analytically derived asymptotes establish and validate an accurate, broadly
applicable, and interpretable equation for passive permeability across both
drug and lipid-tail chemistry.",2020-12-03,2020,2020-12,chemistry
"Domain Adaptation of NMT models for English-Hindi Machine Translation
  Task at AdapMT ICON 2020","Recent advancements in Neural Machine Translation (NMT) models have proved to
produce a state of the art results on machine translation for low resource
Indian languages. This paper describes the neural machine translation systems
for the English-Hindi language presented in AdapMT Shared Task ICON 2020. The
shared task aims to build a translation system for Indian languages in specific
domains like Artificial Intelligence (AI) and Chemistry using a small in-domain
parallel corpus. We evaluated the effectiveness of two popular NMT models i.e,
LSTM, and Transformer architectures for the English-Hindi machine translation
task based on BLEU scores. We train these models primarily using the out of
domain data and employ simple domain adaptation techniques based on the
characteristics of the in-domain dataset. The fine-tuning and mixed-domain data
approaches are used for domain adaptation. Our team was ranked first in the
chemistry and general domain En-Hi translation task and second in the AI domain
En-Hi translation task.",2020-12-22,2020,2020-12,chemistry
Constraining chemical networks inAstrochemistry,"Databases of gas and surface chemical reactions are a key tool for scientists
working in a wide range of physical sciences. In Astrochemistry, databases of
chemical reactions are used as inputs to chemical models to determine the
abundances of the interstellar medium. Gas chemistry and, in particular, grain
surface chemistry and its treatment in gas-grain chemical models are however
areas of large uncertainty. Many reactions - especially on the dust grains -
have not been systematically experimentally studied. Moreover, experimental
measurements are often not easily translated to the rate equation approach most
commonly used in astrochemical modelling. Reducing the degree of uncertainty
intrinsic in these databases is therefore a prime problem, but has so far been
approached mainly by ad hoc procedures of essentially trial and error. In this
chapter we review the problem of the determination of accurate and complete
chemical networks in the wider context of Astrochemistry and explore the
possibility of using statistical methods and machine learning (ML) techniques
to reduce the uncertainty in chemical networks.",2021-01-13,2021,2021-01,chemistry
Noisy intermediate-scale quantum (NISQ) algorithms,"A universal fault-tolerant quantum computer that can solve efficiently
problems such as integer factorization and unstructured database search
requires millions of qubits with low error rates and long coherence times.
While the experimental advancement towards realizing such devices will
potentially take decades of research, noisy intermediate-scale quantum (NISQ)
computers already exist. These computers are composed of hundreds of noisy
qubits, i.e. qubits that are not error-corrected, and therefore perform
imperfect operations in a limited coherence time. In the search for quantum
advantage with these devices, algorithms have been proposed for applications in
various disciplines spanning physics, machine learning, quantum chemistry and
combinatorial optimization. The goal of such algorithms is to leverage the
limited available resources to perform classically challenging tasks. In this
review, we provide a thorough summary of NISQ computational paradigms and
algorithms. We discuss the key structure of these algorithms, their
limitations, and advantages. We additionally provide a comprehensive overview
of various benchmarking and software tools useful for programming and testing
NISQ devices.",2021-01-21,2021,2021-01,chemistry
Chemistry42: An AI-based platform for de novo molecular design,"Chemistry42 is a software platform for de novo small molecule design that
integrates Artificial Intelligence (AI) techniques with computational and
medicinal chemistry methods. Chemistry42 is unique in its ability to generate
novel molecular structures with predefined properties validated through in
vitro and in vivo studies. Chemistry42 is a core component of Insilico Medicine
Pharma.ai drug discovery suite that also includes target discovery and
multi-omics data analysis (PandaOmics) and clinical trial outcomes predictions
(InClinico).",2021-01-22,2021,2021-01,chemistry
"The 4th International Workshop on Smart Simulation and Modelling for
  Complex Systems","Computer-based modelling and simulation have become useful tools to
facilitate humans to understand systems in different domains, such as physics,
astrophysics, chemistry, biology, economics, engineering and social science. A
complex system is featured with a large number of interacting components
(agents, processes, etc.), whose aggregate activities are nonlinear and
self-organized. Complex systems are hard to be simulated or modelled by using
traditional computational approaches due to complex relationships among system
components, distributed features of resources, and dynamics of environments.
Meanwhile, smart systems such as multi-agent systems have demonstrated
advantages and great potentials in modelling and simulating complex systems.",2021-02-01,2021,2021-02,chemistry
Unassisted Noise Reduction of Chemical Reaction Data Sets,"Existing deep learning models applied to reaction prediction in organic
chemistry can reach high levels of accuracy (> 90% for Natural Language
Processing-based ones). With no chemical knowledge embedded than the
information learnt from reaction data, the quality of the data sets plays a
crucial role in the performance of the prediction models. While human curation
is prohibitively expensive, the need for unaided approaches to remove
chemically incorrect entries from existing data sets is essential to improve
artificial intelligence models' performance in synthetic chemistry tasks. Here
we propose a machine learning-based, unassisted approach to remove chemically
wrong entries from chemical reaction collections. We applied this method to the
collection of chemical reactions Pistachio and to an open data set, both
extracted from USPTO (United States Patent Office) patents. Our results show an
improved prediction quality for models trained on the cleaned and balanced data
sets. For the retrosynthetic models, the round-trip accuracy metric grows by 13
percentage points and the value of the cumulative Jensen Shannon divergence
decreases by 30% compared to its original record. The coverage remains high
with 97%, and the value of the class-diversity is not affected by the cleaning.
The proposed strategy is the first unassisted rule-free technique to address
automatic noise reduction in chemical data sets.",2021-02-02,2021,2021-02,chemistry
"A Possible Artificial Intelligence Ecosystem Avatar: the Moorea case
  (IDEA)","High-throughput data collection techniques and largescale (cloud) computing
are transforming our understanding of ecosystems at all scales by allowing the
integration of multimodal data such as physics, chemistry, biology, ecology,
fishing, economics and other social sciences in a common computational
framework. We focus in this paper on a large scale data assimilation and
prediction backbone based on Deep Stacking Networks (DSN) in the frame of the
IDEA (Island Digital Ecosystem Avatars) project (Moorea Island), based on the
subdivision of the island in watersheds and lagoon units. We also describe
several kinds of raw data that can train and constrain such an ecosystem avatar
model, as well as second level data such as ecological or physical indexes /
indicators.",2021-02-04,2021,2021-02,chemistry
Few-shot Conformal Prediction with Auxiliary Tasks,"We develop a novel approach to conformal prediction when the target task has
limited data available for training. Conformal prediction identifies a small
set of promising output candidates in place of a single prediction, with
guarantees that the set contains the correct answer with high probability. When
training data is limited, however, the predicted set can easily become unusably
large. In this work, we obtain substantially tighter prediction sets while
maintaining desirable marginal guarantees by casting conformal prediction as a
meta-learning paradigm over exchangeable collections of auxiliary tasks. Our
conformalization algorithm is simple, fast, and agnostic to the choice of
underlying model, learning algorithm, or dataset. We demonstrate the
effectiveness of this approach across a number of few-shot classification and
regression tasks in natural language processing, computer vision, and
computational chemistry for drug discovery.",2021-02-17,2021,2021-02,chemistry
Full Page Handwriting Recognition via Image to Sequence Extraction,"We present a Neural Network based Handwritten Text Recognition (HTR) model
architecture that can be trained to recognize full pages of handwritten or
printed text without image segmentation. Being based on Image to Sequence
architecture, it can extract text present in an image and then sequence it
correctly without imposing any constraints regarding orientation, layout and
size of text and non-text. Further, it can also be trained to generate
auxiliary markup related to formatting, layout and content. We use character
level vocabulary, thereby enabling language and terminology of any subject. The
model achieves a new state-of-art in paragraph level recognition on the IAM
dataset. When evaluated on scans of real world handwritten free form test
answers - beset with curved and slanted lines, drawings, tables, math,
chemistry and other symbols - it performs better than all commercially
available HTR cloud APIs. It is deployed in production as part of a commercial
web application.",2021-03-11,2021,2021-03,chemistry
"Graph Entropy Guided Node Embedding Dimension Selection for Graph Neural
  Networks","Graph representation learning has achieved great success in many areas,
including e-commerce, chemistry, biology, etc. However, the fundamental problem
of choosing the appropriate dimension of node embedding for a given graph still
remains unsolved. The commonly used strategies for Node Embedding Dimension
Selection (NEDS) based on grid search or empirical knowledge suffer from heavy
computation and poor model performance. In this paper, we revisit NEDS from the
perspective of minimum entropy principle. Subsequently, we propose a novel
Minimum Graph Entropy (MinGE) algorithm for NEDS with graph data. To be
specific, MinGE considers both feature entropy and structure entropy on graphs,
which are carefully designed according to the characteristics of the rich
information in them. The feature entropy, which assumes the embeddings of
adjacent nodes to be more similar, connects node features and link topology on
graphs. The structure entropy takes the normalized degree as basic unit to
further measure the higher-order structure of graphs. Based on them, we design
MinGE to directly calculate the ideal node embedding dimension for any graph.
Finally, comprehensive experiments with popular Graph Neural Networks (GNNs) on
benchmark datasets demonstrate the effectiveness and generalizability of our
proposed MinGE.",2021-05-07,2021,2021-05,chemistry
Neural Error Mitigation of Near-Term Quantum Simulations,"Near-term quantum computers provide a promising platform for finding ground
states of quantum systems, which is an essential task in physics, chemistry,
and materials science. Near-term approaches, however, are constrained by the
effects of noise as well as the limited resources of near-term quantum
hardware. We introduce ""neural error mitigation,"" which uses neural networks to
improve estimates of ground states and ground-state observables obtained using
near-term quantum simulations. To demonstrate our method's broad applicability,
we employ neural error mitigation to find the ground states of the H$_2$ and
LiH molecular Hamiltonians, as well as the lattice Schwinger model, prepared
via the variational quantum eigensolver (VQE). Our results show that neural
error mitigation improves numerical and experimental VQE computations to yield
low energy errors, high fidelities, and accurate estimations of more-complex
observables like order parameters and entanglement entropy, without requiring
additional quantum resources. Furthermore, neural error mitigation is agnostic
with respect to the quantum state preparation algorithm used, the quantum
hardware it is implemented on, and the particular noise channel affecting the
experiment, contributing to its versatility as a tool for quantum simulation.",2021-05-17,2021,2021-05,chemistry
"Communication is the universal solvent: atreya bot -- an interactive bot
  for chemical scientists","Conversational agents are a recent trend in human-computer interaction,
deployed in multidisciplinary applications to assist the users. In this paper,
we introduce ""Atreya"", an interactive bot for chemistry enthusiasts,
researchers, and students to study the ChEMBL database. Atreya is hosted by
Telegram, a popular cloud-based instant messaging application. This
user-friendly bot queries the ChEMBL database, retrieves the drug details for a
particular disease, targets associated with that drug, etc. This paper explores
the potential of using a conversational agent to assist chemistry students and
chemical scientist in complex information seeking process.",2021-06-14,2021,2021-06,chemistry
"NG+ : A Multi-Step Matrix-Product Natural Gradient Method for Deep
  Learning","In this paper, a novel second-order method called NG+ is proposed. By
following the rule ``the shape of the gradient equals the shape of the
parameter"", we define a generalized fisher information matrix (GFIM) using the
products of gradients in the matrix form rather than the traditional
vectorization. Then, our generalized natural gradient direction is simply the
inverse of the GFIM multiplies the gradient in the matrix form. Moreover, the
GFIM and its inverse keeps the same for multiple steps so that the
computational cost can be controlled and is comparable with the first-order
methods. A global convergence is established under some mild conditions and a
regret bound is also given for the online learning setting. Numerical results
on image classification with ResNet50, quantum chemistry modeling with Schnet,
neural machine translation with Transformer and recommendation system with DLRM
illustrate that GN+ is competitive with the state-of-the-art methods.",2021-06-14,2021,2021-06,chemistry
"Total Nitrogen Estimation in Agricultural Soils via Aerial Multispectral
  Imaging and LIBS","Measuring soil health indicators is an important and challenging task that
affects farmers' decisions on timing, placement, and quantity of fertilizers
applied in the farms. Most existing methods to measure soil health indicators
(SHIs) are in-lab wet chemistry or spectroscopy-based methods, which require
significant human input and effort, time-consuming, costly, and are
low-throughput in nature. To address this challenge, we develop an artificial
intelligence (AI)-driven near real-time unmanned aerial vehicle (UAV)-based
multispectral sensing (UMS) solution to estimate total nitrogen (TN) of the
soil, an important macro-nutrient or SHI that directly affects the crop health.
Accurate prediction of soil TN can significantly increase crop yield through
informed decision making on the timing of seed planting, and fertilizer
quantity and timing. We train two machine learning models including multi-layer
perceptron and support vector machine to predict the soil nitrogen using a
suite of data classes including multispectral characteristics of the soil and
crops in red, near-infrared, and green spectral bands, computed vegetation
indices, and environmental variables including air temperature and relative
humidity. To generate the ground-truth data or the training data for the
machine learning models, we measure the total nitrogen of the soil samples
(collected from a farm) using laser-induced breakdown spectroscopy (LIBS).",2021-07-06,2021,2021-07,chemistry
"A Point Cloud-Based Deep Learning Strategy for Protein-Ligand Binding
  Affinity Prediction","There is great interest to develop artificial intelligence-based
protein-ligand affinity models due to their immense applications in drug
discovery. In this paper, PointNet and PointTransformer, two pointwise
multi-layer perceptrons have been applied for protein-ligand affinity
prediction for the first time. Three-dimensional point clouds could be rapidly
generated from the data sets in PDBbind-2016, which contain 3 772 and 11 327
individual point clouds derived from the refined or/and general sets,
respectively. These point clouds were used to train PointNet or
PointTransformer, resulting in protein-ligand affinity prediction models with
Pearson correlation coefficients R = 0.831 or 0.859 from the larger point
clouds respectively, based on the CASF-2016 benchmark test. The analysis of the
parameters suggests that the two deep learning models were capable to learn
many interactions between proteins and their ligands, and these key atoms for
the interaction could be visualized in point clouds. The protein-ligand
interaction features learned by PointTransformer could be further adapted for
the XGBoost-based machine learning algorithm, resulting in prediction models
with an average Rp of 0.831, which is on par with the state-of-the-art machine
learning models based on PDBbind database. These results suggest that point
clouds derived from the PDBbind datasets are useful to evaluate the performance
of 3D point clouds-centered deep learning algorithms, which could learn
critical protein-ligand interactions from natural evolution or medicinal
chemistry and have wide applications in studying protein-ligand interactions.",2021-07-09,2021,2021-07,chemistry
"From data to noise to data: mixing physics across temperatures with
  generative artificial intelligence","Using simulations or experiments performed at some set of temperatures to
learn about the physics or chemistry at some other arbitrary temperature is a
problem of immense practical and theoretical relevance. Here we develop a
framework based on statistical mechanics and generative Artificial Intelligence
that allows solving this problem. Specifically, we work with denoising
diffusion probabilistic models, and show how these models in combination with
replica exchange molecular dynamics achieve superior sampling of the
biomolecular energy landscape at temperatures that were never even simulated
without assuming any particular slow degrees of freedom. The key idea is to
treat the temperature as a fluctuating random variable and not a control
parameter as is usually done. This allows us to directly sample from the joint
probability distribution in configuration and temperature space. The results
here are demonstrated for a chirally symmetric peptide and single-strand
ribonucleic acid undergoing conformational transitions in all-atom water. We
demonstrate how we can discover transition states and metastable states that
were previously unseen at the temperature of interest, and even bypass the need
to perform further simulations for wide range of temperatures. At the same
time, any unphysical states are easily identifiable through very low Boltzmann
weights. The procedure while shown here for a class of molecular simulations
should be more generally applicable to mixing information across simulations
and experiments with varying control parameters.",2021-07-15,2021,2021-07,chemistry
"Learning Attributed Graph Representations with Communicative Message
  Passing Transformer","Constructing appropriate representations of molecules lies at the core of
numerous tasks such as material science, chemistry and drug designs. Recent
researches abstract molecules as attributed graphs and employ graph neural
networks (GNN) for molecular representation learning, which have made
remarkable achievements in molecular graph modeling. Albeit powerful, current
models either are based on local aggregation operations and thus miss
higher-order graph properties or focus on only node information without fully
using the edge information. For this sake, we propose a Communicative Message
Passing Transformer (CoMPT) neural network to improve the molecular graph
representation by reinforcing message interactions between nodes and edges
based on the Transformer architecture. Unlike the previous transformer-style
GNNs that treat molecules as fully connected graphs, we introduce a message
diffusion mechanism to leverage the graph connectivity inductive bias and
reduce the message enrichment explosion. Extensive experiments demonstrated
that the proposed model obtained superior performances (around 4$\%$ on
average) against state-of-the-art baselines on seven chemical property datasets
(graph-level tasks) and two chemical shift datasets (node-level tasks). Further
visualization studies also indicated a better representation capacity achieved
by our model.",2021-07-19,2021,2021-07,chemistry
"Multiple Query Optimization using a Hybrid Approach of Classical and
  Quantum Computing","Quantum computing promises to solve difficult optimization problems in
chemistry, physics and mathematics more efficiently than classical computers,
but requires fault-tolerant quantum computers with millions of qubits. To
overcome errors introduced by today's quantum computers, hybrid algorithms
combining classical and quantum computers are used. In this paper we tackle the
multiple query optimization problem (MQO) which is an important NP-hard problem
in the area of data-intensive problems. We propose a novel hybrid
classical-quantum algorithm to solve the MQO on a gate-based quantum computer.
We perform a detailed experimental evaluation of our algorithm and compare its
performance against a competing approach that employs a quantum annealer --
another type of quantum computer. Our experimental results demonstrate that our
algorithm currently can only handle small problem sizes due to the limited
number of qubits available on a gate-based quantum computer compared to a
quantum computer based on quantum annealing. However, our algorithm shows a
qubit efficiency of close to 99% which is almost a factor of 2 higher compared
to the state of the art implementation. Finally, we analyze how our algorithm
scales with larger problem sizes and conclude that our approach shows promising
results for near-term quantum computers.",2021-07-22,2021,2021-07,chemistry
Geometric Deep Learning on Molecular Representations,"Geometric deep learning (GDL), which is based on neural network architectures
that incorporate and process symmetry information, has emerged as a recent
paradigm in artificial intelligence. GDL bears particular promise in molecular
modeling applications, in which various molecular representations with
different symmetry properties and levels of abstraction exist. This review
provides a structured and harmonized overview of molecular GDL, highlighting
its applications in drug discovery, chemical synthesis prediction, and quantum
chemistry. Emphasis is placed on the relevance of the learned molecular
features and their complementarity to well-established molecular descriptors.
This review provides an overview of current challenges and opportunities, and
presents a forecast of the future of GDL for molecular sciences.",2021-07-26,2021,2021-07,chemistry
"Natural Language Processing Models That Automate Programming Will
  Transform Chemistry Research and Teaching","Natural language processing models have emerged that can generate usable
software and automate a number of programming tasks with high fidelity. These
tools have yet to have an impact on the chemistry community. Yet, our initial
testing demonstrates that this form of Artificial Intelligence is poised to
transform chemistry and chemical engineering research. Here, we review
developments that brought us to this point, examine applications in chemistry,
and give our perspective on how this may fundamentally alter research and
teaching.",2021-08-30,2021,2021-08,chemistry
"IGNNITION: Bridging the Gap Between Graph Neural Networks and Networking
  Systems","Recent years have seen the vast potential of Graph Neural Networks (GNN) in
many fields where data is structured as graphs (e.g., chemistry, recommender
systems). In particular, GNNs are becoming increasingly popular in the field of
networking, as graphs are intrinsically present at many levels (e.g., topology,
routing). The main novelty of GNNs is their ability to generalize to other
networks unseen during training, which is an essential feature for developing
practical Machine Learning (ML) solutions for networking. However, implementing
a functional GNN prototype is currently a cumbersome task that requires strong
skills in neural network programming. This poses an important barrier to
network engineers that often do not have the necessary ML expertise. In this
article, we present IGNNITION, a novel open-source framework that enables fast
prototyping of GNNs for networking systems. IGNNITION is based on an intuitive
high-level abstraction that hides the complexity behind GNNs, while still
offering great flexibility to build custom GNN architectures. To showcase the
versatility and performance of this framework, we implement two
state-of-the-art GNN models applied to different networking use cases. Our
results show that the GNN models produced by IGNNITION are equivalent in terms
of accuracy and performance to their native implementations in TensorFlow.",2021-09-14,2021,2021-09,chemistry
"Automated and Explainable Ontology Extension Based on Deep Learning: A
  Case Study in the Chemical Domain","Reference ontologies provide a shared vocabulary and knowledge resource for
their domain. Manual construction enables them to maintain a high quality,
allowing them to be widely accepted across their community. However, the manual
development process does not scale for large domains. We present a new
methodology for automatic ontology extension and apply it to the ChEBI
ontology, a prominent reference ontology for life sciences chemistry. We
trained a Transformer-based deep learning model on the leaf node structures
from the ChEBI ontology and the classes to which they belong. The model is then
capable of automatically classifying previously unseen chemical structures. The
proposed model achieved an overall F1 score of 0.80, an improvement of 6
percentage points over our previous results on the same dataset. Additionally,
we demonstrate how visualizing the model's attention weights can help to
explain the results by providing insight into how the model made its decisions.",2021-09-19,2021,2021-09,chemistry
Loop-Free Tensor Networks for High-Energy Physics,"This brief review introduces the reader to tensor network methods, a powerful
theoretical and numerical paradigm spawning from condensed matter physics and
quantum information science and increasingly exploited in different fields of
research, from artificial intelligence to quantum chemistry. Here, we
specialise our presentation on the application of loop-free tensor network
methods to the study of High-Energy Physics (HEP) problems and, in particular,
to the study of lattice gauge theories where tensor networks can be applied in
regimes where Monte Carlo methods are hindered by the sign problem.",2021-09-24,2021,2021-09,chemistry
Natural Computational Architectures for Cognitive Info-Communication,"Recent comprehensive overview of 40 years of research in cognitive
architectures, (Kotseruba and Tsotsos 2020), evaluates modelling of the core
cognitive abilities in humans, but only marginally addresses biologically
plausible approaches based on natural computation. This mini review presents a
set of perspectives and approaches which have shaped the development of
biologically inspired computational models in the recent past that can lead to
the development of biologically more realistic cognitive architectures. For
describing continuum of natural cognitive architectures, from basal cellular to
human-level cognition, we use evolutionary info-computational framework, where
natural/ physical/ morphological computation leads to evolution of increasingly
complex cognitive systems. Forty years ago, when the first cognitive
architectures have been proposed, understanding of cognition, embodiment and
evolution was different. So was the state of the art of information physics,
bioinformatics, information chemistry, computational neuroscience, complexity
theory, self-organization, theory of evolution, information and computation.
Novel developments support a constructive interdisciplinary framework for
cognitive architectures in the context of computing nature, where interactions
between constituents at different levels of organization lead to
complexification of agency and increased cognitive capacities. We identify
several important research questions for further investigation that can
increase understanding of cognition in nature and inspire new developments of
cognitive technologies. Recently, basal cell cognition attracted a lot of
interest for its possible applications in medicine, new computing technologies,
as well as micro- and nanorobotics.",2021-10-01,2021,2021-10,chemistry
"A Deep Dive into Machine Learning Density Functional Theory for
  Materials Science and Chemistry","With the growth of computational resources, the scope of electronic structure
simulations has increased greatly. Artificial intelligence and robust data
analysis hold the promise to accelerate large-scale simulations and their
analysis to hitherto unattainable scales. Machine learning is a rapidly growing
field for the processing of such complex datasets. It has recently gained
traction in the domain of electronic structure simulations, where density
functional theory takes the prominent role of the most widely used electronic
structure method. Thus, DFT calculations represent one of the largest loads on
academic high-performance computing systems across the world. Accelerating
these with machine learning can reduce the resources required and enables
simulations of larger systems. Hence, the combination of density functional
theory and machine learning has the potential to rapidly advance electronic
structure applications such as in-silico materials discovery and the search for
new chemical reaction pathways. We provide the theoretical background of both
density functional theory and machine learning on a generally accessible level.
This serves as the basis of our comprehensive review including research
articles up to December 2020 in chemistry and materials science that employ
machine-learning techniques. In our analysis, we categorize the body of
research into main threads and extract impactful results. We conclude our
review with an outlook on exciting research directions in terms of a citation
analysis.",2021-10-03,2021,2021-10,chemistry
"Geometric and Physical Quantities Improve E(3) Equivariant Message
  Passing","Including covariant information, such as position, force, velocity or spin is
important in many tasks in computational physics and chemistry. We introduce
Steerable E(3) Equivariant Graph Neural Networks (SEGNNs) that generalise
equivariant graph networks, such that node and edge attributes are not
restricted to invariant scalars, but can contain covariant information, such as
vectors or tensors. This model, composed of steerable MLPs, is able to
incorporate geometric and physical information in both the message and update
functions. Through the definition of steerable node attributes, the MLPs
provide a new class of activation functions for general use with steerable
feature fields. We discuss ours and related work through the lens of
equivariant non-linear convolutions, which further allows us to pin-point the
successful components of SEGNNs: non-linear message aggregation improves upon
classic linear (steerable) point convolutions; steerable messages improve upon
recent equivariant graph networks that send invariant messages. We demonstrate
the effectiveness of our method on several tasks in computational physics and
chemistry and provide extensive ablation studies.",2021-10-06,2021,2021-10,chemistry
"The AI Triplet: Computational, Conceptual, and Mathematical Knowledge in
  AI Education","Efforts to enhance education and broaden participation in AI will benefit
from a systematic understanding of the competencies underlying AI expertise. In
this paper, we observe that AI expertise requires integrating computational,
conceptual, and mathematical knowledge and representations. We call this the
``AI triplet,'' similar in spirit to the ``chemistry triplet'' that has heavily
influenced the past four decades of chemistry education research. We describe a
theoretical foundation for this triplet and show how it maps onto two sample AI
topics: tree search and gradient descent. Finally, just as the chemistry
triplet has impacted chemistry education in concrete ways, we suggest two
initial hypotheses for how the AI triplet might impact AI education: 1) how we
can help AI students gain proficiency in moving between the corners of the
triplet; and 2) how all corners of the AI triplet highlight the need for
supporting students' spatial cognitive skills.",2021-10-14,2021,2021-10,chemistry
Geometric Transformer for End-to-End Molecule Properties Prediction,"Transformers have become methods of choice in many applications thanks to
their ability to represent complex interactions between elements. However,
extending the Transformer architecture to non-sequential data such as molecules
and enabling its training on small datasets remains a challenge. In this work,
we introduce a Transformer-based architecture for molecule property prediction,
which is able to capture the geometry of the molecule. We modify the classical
positional encoder by an initial encoding of the molecule geometry, as well as
a learned gated self-attention mechanism. We further suggest an augmentation
scheme for molecular data capable of avoiding the overfitting induced by the
overparameterized architecture. The proposed framework outperforms the
state-of-the-art methods while being based on pure machine learning solely,
i.e. the method does not incorporate domain knowledge from quantum chemistry
and does not use extended geometric inputs besides the pairwise atomic
distances.",2021-10-26,2021,2021-10,chemistry
"Scientific Discovery and the Cost of Measurement -- Balancing
  Information and Cost in Reinforcement Learning","The use of reinforcement learning (RL) in scientific applications, such as
materials design and automated chemistry, is increasing. A major challenge,
however, lies in fact that measuring the state of the system is often costly
and time consuming in scientific applications, whereas policy learning with RL
requires a measurement after each time step. In this work, we make the
measurement costs explicit in the form of a costed reward and propose a
framework that enables off-the-shelf deep RL algorithms to learn a policy for
both selecting actions and determining whether or not to measure the current
state of the system at each time step. In this way, the agents learn to balance
the need for information with the cost of information. Our results show that
when trained under this regime, the Dueling DQN and PPO agents can learn
optimal action policies whilst making up to 50\% fewer state measurements, and
recurrent neural networks can produce a greater than 50\% reduction in
measurements. We postulate the these reduction can help to lower the barrier to
applying RL to real-world scientific applications.",2021-12-14,2021,2021-12,chemistry
"Beyond Low Earth Orbit: Biomonitoring, Artificial Intelligence, and
  Precision Space Health","Human space exploration beyond low Earth orbit will involve missions of
significant distance and duration. To effectively mitigate myriad space health
hazards, paradigm shifts in data and space health systems are necessary to
enable Earth-independence, rather than Earth-reliance. Promising developments
in the fields of artificial intelligence and machine learning for biology and
health can address these needs. We propose an appropriately autonomous and
intelligent Precision Space Health system that will monitor, aggregate, and
assess biomedical statuses; analyze and predict personalized adverse health
outcomes; adapt and respond to newly accumulated data; and provide preventive,
actionable, and timely insights to individual deep space crew members and
iterative decision support to their crew medical officer. Here we present a
summary of recommendations from a workshop organized by the National
Aeronautics and Space Administration, on future applications of artificial
intelligence in space biology and health. In the next decade, biomonitoring
technology, biomarker science, spacecraft hardware, intelligent software, and
streamlined data management must mature and be woven together into a Precision
Space Health system to enable humanity to thrive in deep space.",2021-12-22,2021,2021-12,chemistry
"Beyond Low Earth Orbit: Biological Research, Artificial Intelligence,
  and Self-Driving Labs","Space biology research aims to understand fundamental effects of spaceflight
on organisms, develop foundational knowledge to support deep space exploration,
and ultimately bioengineer spacecraft and habitats to stabilize the ecosystem
of plants, crops, microbes, animals, and humans for sustained multi-planetary
life. To advance these aims, the field leverages experiments, platforms, data,
and model organisms from both spaceborne and ground-analog studies. As research
is extended beyond low Earth orbit, experiments and platforms must be maximally
autonomous, light, agile, and intelligent to expedite knowledge discovery. Here
we present a summary of recommendations from a workshop organized by the
National Aeronautics and Space Administration on artificial intelligence,
machine learning, and modeling applications which offer key solutions toward
these space biology challenges. In the next decade, the synthesis of artificial
intelligence into the field of space biology will deepen the biological
understanding of spaceflight effects, facilitate predictive modeling and
analytics, support maximally autonomous and reproducible experiments, and
efficiently manage spaceborne data and metadata, all with the goal to enable
life to thrive in deep space.",2021-12-22,2021,2021-12,chemistry
"AlphaFold Accelerates Artificial Intelligence Powered Drug Discovery:
  Efficient Discovery of a Novel Cyclin-dependent Kinase 20 (CDK20) Small
  Molecule Inhibitor","The AlphaFold computer program predicted protein structures for the whole
human genome, which has been considered as a remarkable breakthrough both in
artificial intelligence (AI) application and structural biology. Despite the
varying confidence level, these predicted structures still could significantly
contribute to structure-based drug design of novel targets, especially the ones
with no or limited structural information. In this work, we successfully
applied AlphaFold in our end-to-end AI-powered drug discovery engines
constituted of a biocomputational platform PandaOmics and a generative
chemistry platform Chemistry42, to identify a first-in-class hit molecule of a
novel target without an experimental structure starting from target selection
towards hit identification in a cost- and time-efficient manner. PandaOmics
provided the targets of interest and Chemistry42 generated the molecules based
on the AlphaFold predicted structure, and the selected molecules were
synthesized and tested in biological assays. Through this approach, we
identified a small molecule hit compound for CDK20 with a Kd value of 8.9 +/-
1.6 uM (n = 4) within 30 days from target selection and after only synthesizing
7 compounds. Based on the available data, the second round of AI-powered
compound generation was conducted and through which, a more potent hit
molecule, ISM042-2 048, was discovered with a Kd value of 210.0 +/- 42.4 nM (n
= 2), within 30 days and after synthesizing 6 compounds from the discovery of
the first hit ISM042-2-001. To the best of our knowledge, this is the first
reported small molecule targeting CDK20 and more importantly, this work is the
first demonstration of AlphaFold application in the hit identification process
in early drug discovery.",2022-01-21,2022,2022-01,chemistry
"DrugOOD: Out-of-Distribution (OOD) Dataset Curator and Benchmark for
  AI-aided Drug Discovery -- A Focus on Affinity Prediction Problems with Noise
  Annotations","AI-aided drug discovery (AIDD) is gaining increasing popularity due to its
promise of making the search for new pharmaceuticals quicker, cheaper and more
efficient. In spite of its extensive use in many fields, such as ADMET
prediction, virtual screening, protein folding and generative chemistry, little
has been explored in terms of the out-of-distribution (OOD) learning problem
with \emph{noise}, which is inevitable in real world AIDD applications.
  In this work, we present DrugOOD, a systematic OOD dataset curator and
benchmark for AI-aided drug discovery, which comes with an open-source Python
package that fully automates the data curation and OOD benchmarking processes.
We focus on one of the most crucial problems in AIDD: drug target binding
affinity prediction, which involves both macromolecule (protein target) and
small-molecule (drug compound). In contrast to only providing fixed datasets,
DrugOOD offers automated dataset curator with user-friendly customization
scripts, rich domain annotations aligned with biochemistry knowledge, realistic
noise annotations and rigorous benchmarking of state-of-the-art OOD algorithms.
Since the molecular data is often modeled as irregular graphs using graph
neural network (GNN) backbones, DrugOOD also serves as a valuable testbed for
\emph{graph OOD learning} problems. Extensive empirical studies have shown a
significant performance gap between in-distribution and out-of-distribution
experiments, which highlights the need to develop better schemes that can allow
for OOD generalization under noise for AIDD.",2022-01-24,2022,2022-01,chemistry
"Semi-Supervised GCN for learning Molecular Structure-Activity
  Relationships","Since the introduction of artificial intelligence in medicinal chemistry, the
necessity has emerged to analyse how molecular property variation is modulated
by either single atoms or chemical groups. In this paper, we propose to train
graph-to-graph neural network using semi-supervised learning for attributing
structure-property relationships. As initial case studies we apply the method
to solubility and molecular acidity while checking its consistency in
comparison with known experimental chemical data. As final goal, our approach
could represent a valuable tool to deal with problems such as activity cliffs,
lead optimization and de-novo drug design.",2022-01-25,2022,2022-01,chemistry
"MolNet: A Chemically Intuitive Graph Neural Network for Prediction of
  Molecular Properties","The graph neural network (GNN) has been a powerful deep-learning tool in
chemistry domain, due to its close connection with molecular graphs. Most GNN
models collect and update atom and molecule features from the fed atom (and, in
some cases, bond) features, which are basically based on the two-dimensional
(2D) graph representation of 3D molecules. Correspondingly, the adjacency
matrix, containing the information on covalent bonds, or equivalent data
structures (e.g., lists) have been the main core in the feature-updating
processes, such as graph convolution. However, the 2D-based models do not
faithfully represent 3D molecules and their physicochemical properties,
exemplified by the overlooked field effect that is a ""through-space"" effect,
not a ""through-bond"" effect. The GNN model proposed herein, denoted as MolNet,
is chemically intuitive, accommodating the 3D non-bond information in a
molecule, with a noncovalent adjacency matrix $\bf{\bar A}$, and also
bond-strength information from a weighted bond matrix $\bf{B}$. The noncovalent
atoms, not directly bonded to a given atom in a molecule, are identified within
5 $\unicode{x212B}$ of cut-off range for the construction of $\bf{\bar A}$, and
$\bf{B}$ has edge weights of 1, 1.5, 2, and 3 for single, aromatic, double, and
triple bonds, respectively. Comparative studies show that MolNet outperforms
various baseline GNN models and gives a state-of-the-art performance in the
classification task of BACE dataset and regression task of ESOL dataset. This
work suggests a future direction of deep-learning chemistry in the construction
of deep-learning models that are chemically intuitive and comparable with the
existing chemistry concepts and tools.",2022-02-01,2022,2022-02,chemistry
Target-aware Molecular Graph Generation,"Generating molecules with desired biological activities has attracted growing
attention in drug discovery. Previous molecular generation models are designed
as chemocentric methods that hardly consider the drug-target interaction,
limiting their practical applications. In this paper, we aim to generate
molecular drugs in a target-aware manner that bridges biological activity and
molecular design. To solve this problem, we compile a benchmark dataset from
several publicly available datasets and build baselines in a unified framework.
Building on the recent advantages of flow-based molecular generation models, we
propose SiamFlow, which forces the flow to fit the distribution of target
sequence embeddings in latent space. Specifically, we employ an alignment loss
and a uniform loss to bring target sequence embeddings and drug graph
embeddings into agreements while avoiding collapse. Furthermore, we formulate
the alignment into a one-to-many problem by learning spaces of target sequence
embeddings. Experiments quantitatively show that our proposed method learns
meaningful representations in the latent space toward the target-aware
molecular graph generation and provides an alternative approach to bridge
biology and chemistry in drug discovery.",2022-02-10,2022,2022-02,chemistry
ChemicalX: A Deep Learning Library for Drug Pair Scoring,"In this paper, we introduce ChemicalX, a PyTorch-based deep learning library
designed for providing a range of state of the art models to solve the drug
pair scoring task. The primary objective of the library is to make deep drug
pair scoring models accessible to machine learning researchers and
practitioners in a streamlined framework.The design of ChemicalX reuses
existing high level model training utilities, geometric deep learning, and deep
chemistry layers from the PyTorch ecosystem. Our system provides neural network
layers, custom pair scoring architectures, data loaders, and batch iterators
for end users. We showcase these features with example code snippets and case
studies to highlight the characteristics of ChemicalX. A range of experiments
on real world drug-drug interaction, polypharmacy side effect, and combination
synergy prediction tasks demonstrate that the models available in ChemicalX are
effective at solving the pair scoring task. Finally, we show that ChemicalX
could be used to train and score machine learning models on large drug pair
datasets with hundreds of thousands of compounds on commodity hardware.",2022-02-10,2022,2022-02,chemistry
"Improving Molecular Representation Learning with Metric
  Learning-enhanced Optimal Transport","Training data are usually limited or heterogeneous in many chemical and
biological applications. Existing machine learning models for chemistry and
materials science fail to consider generalizing beyond training domains. In
this article, we develop a novel optimal transport-based algorithm termed MROT
to enhance their generalization capability for molecular regression problems.
MROT learns a continuous label of the data by measuring a new metric of domain
distances and a posterior variance regularization over the transport plan to
bridge the chemical domain gap. Among downstream tasks, we consider basic
chemical regression tasks in unsupervised and semi-supervised settings,
including chemical property prediction and materials adsorption selection.
Extensive experiments show that MROT significantly outperforms state-of-the-art
models, showing promising potential in accelerating the discovery of new
substances with desired properties.",2022-02-13,2022,2022-02,chemistry
"Fast and Accurate Linear Fitting for Incompletely Sampled Gaussian
  Function With a Long Tail","Fitting experiment data onto a curve is a common signal processing technique
to extract data features and establish the relationship between variables.
Often, we expect the curve to comply with some analytical function and then
turn data fitting into estimating the unknown parameters of a function. Among
analytical functions for data fitting, Gaussian function is the most widely
used one due to its extensive applications in numerous science and engineering
fields. To name just a few, Gaussian function is highly popular in statistical
signal processing and analysis, thanks to the central limit theorem [1];
Gaussian function frequently appears in the quantum harmonic oscillator,
quantum field theory, optics, lasers, and many other theories and models in
Physics [2]; moreover, Gaussian function is widely applied in chemistry for
depicting molecular orbitals, in computer science for imaging processing and in
artificial intelligence for defining neural networks.",2022-03-15,2022,2022-03,chemistry
SELFIES and the future of molecular string representations,"Artificial intelligence (AI) and machine learning (ML) are expanding in
popularity for broad applications to challenging tasks in chemistry and
materials science. Examples include the prediction of properties, the discovery
of new reaction pathways, or the design of new molecules. The machine needs to
read and write fluently in a chemical language for each of these tasks. Strings
are a common tool to represent molecular graphs, and the most popular molecular
string representation, SMILES, has powered cheminformatics since the late
1980s. However, in the context of AI and ML in chemistry, SMILES has several
shortcomings -- most pertinently, most combinations of symbols lead to invalid
results with no valid chemical interpretation. To overcome this issue, a new
language for molecules was introduced in 2020 that guarantees 100\% robustness:
SELFIES (SELF-referencIng Embedded Strings). SELFIES has since simplified and
enabled numerous new applications in chemistry. In this manuscript, we look to
the future and discuss molecular string representations, along with their
respective opportunities and challenges. We propose 16 concrete Future Projects
for robust molecular representations. These involve the extension toward new
chemical domains, exciting questions at the interface of AI and robust
languages and interpretability for both humans and machines. We hope that these
proposals will inspire several follow-up works exploiting the full potential of
molecular string representations for the future of AI in chemistry and
materials science.",2022-03-31,2022,2022-03,chemistry
Translation between Molecules and Natural Language,"We present $\textbf{MolT5}$ $-$ a self-supervised learning framework for
pretraining models on a vast amount of unlabeled natural language text and
molecule strings. $\textbf{MolT5}$ allows for new, useful, and challenging
analogs of traditional vision-language tasks, such as molecule captioning and
text-based de novo molecule generation (altogether: translation between
molecules and language), which we explore for the first time. Since
$\textbf{MolT5}$ pretrains models on single-modal data, it helps overcome the
chemistry domain shortcoming of data scarcity. Furthermore, we consider several
metrics, including a new cross-modal embedding-based metric, to evaluate the
tasks of molecule captioning and text-based molecule generation. Our results
show that $\textbf{MolT5}$-based models are able to generate outputs, both
molecules and captions, which in many cases are high quality.",2022-04-25,2022,2022-04,chemistry
"Crystal Transformer: Self-learning neural language model for Generative
  and Tinkering Design of Materials","Self-supervised neural language models have recently achieved unprecedented
success, from natural language processing to learning the languages of
biological sequences and organic molecules. These models have demonstrated
superior performance in the generation, structure classification, and
functional predictions for proteins and molecules with learned representations.
However, most of the masking-based pre-trained language models are not designed
for generative design, and their black-box nature makes it difficult to
interpret their design logic. Here we propose BLMM Crystal Transformer, a
neural network based probabilistic generative model for generative and
tinkering design of inorganic materials. Our model is built on the blank
filling language model for text generation and has demonstrated unique
advantages in learning the ""materials grammars"" together with high-quality
generation, interpretability, and data efficiency. It can generate chemically
valid materials compositions with as high as 89.7\% charge neutrality and
84.8\% balanced electronegativity, which are more than 4 and 8 times higher
compared to a pseudo random sampling baseline. The probabilistic generation
process of BLMM allows it to recommend tinkering operations based on learned
materials chemistry and makes it useful for materials doping. Combined with the
TCSP crysal structure prediction algorithm, We have applied our model to
discover a set of new materials as validated using DFT calculations. Our work
thus brings the unsupervised transformer language models based generative
artificial intelligence to inorganic materials. A user-friendly web app has
been developed for computational materials doping and can be accessed freely at
\url{www.materialsatlas.org/blmtinker}.",2022-04-25,2022,2022-04,chemistry
"Multimodal Transformer-based Model for Buchwald-Hartwig and
  Suzuki-Miyaura Reaction Yield Prediction","Predicting the yield percentage of a chemical reaction is useful in many
aspects such as reducing wet-lab experimentation by giving the priority to the
reactions with a high predicted yield. In this work we investigated the use of
multiple type inputs to predict chemical reaction yield. We used simplified
molecular-input line-entry system (SMILES) as well as calculated chemical
descriptors as model inputs. The model consists of a pre-trained bidirectional
transformer-based encoder (BERT) and a multi-layer perceptron (MLP) with a
regression head to predict the yield. We experimented on two high throughput
experimentation (HTE) datasets for Buchwald-Hartwig and Suzuki-Miyaura
reactions. The experiments show improvements in the prediction on both datasets
compared to systems using only SMILES or chemical descriptors as input. We also
tested the model's performance on out-of-sample dataset splits of
Buchwald-Hartwig and achieved comparable results with the state-of-the-art. In
addition to predicting the yield, we demonstrated the model's ability to
suggest the optimum (highest yield) reaction conditions. The model was able to
suggest conditions that achieves 94% of the optimum reported yields. This
proves the model to be useful in achieving the best results in the wet lab
without expensive experimentation.",2022-04-27,2022,2022-04,chemistry
FAIR data enabling new horizons for materials research,"The prosperity and lifestyle of our society are very much governed by
achievements in condensed matter physics, chemistry and materials science,
because new products for sectors such as energy, the environment, health,
mobility and information technology (IT) rely largely on improved or even new
materials. Examples include solid-state lighting, touchscreens, batteries,
implants, drug delivery and many more. The enormous amount of research data
produced every day in these fields represents a gold mine of the twenty-first
century. This gold mine is, however, of little value if these data are not
comprehensively characterized and made available. How can we refine this
feedstock; that is, turn data into knowledge and value? For this, a FAIR
(findable, accessible, interoperable and reusable) data infrastructure is a
must. Only then can data be readily shared and explored using data analytics
and artificial intelligence (AI) methods. Making data 'findable and AI ready'
(a forward-looking interpretation of the acronym) will change the way in which
science is carried out today. In this Perspective, we discuss how we can
prepare to make this happen for the field of materials science.",2022-04-28,2022,2022-04,chemistry
Power and limitations of single-qubit native quantum neural networks,"Quantum neural networks (QNNs) have emerged as a leading strategy to
establish applications in machine learning, chemistry, and optimization. While
the applications of QNN have been widely investigated, its theoretical
foundation remains less understood. In this paper, we formulate a theoretical
framework for the expressive ability of data re-uploading quantum neural
networks that consist of interleaved encoding circuit blocks and trainable
circuit blocks. First, we prove that single-qubit quantum neural networks can
approximate any univariate function by mapping the model to a partial Fourier
series. We in particular establish the exact correlations between the
parameters of the trainable gates and the Fourier coefficients, resolving an
open problem on the universal approximation property of QNN. Second, we discuss
the limitations of single-qubit native QNNs on approximating multivariate
functions by analyzing the frequency spectrum and the flexibility of Fourier
coefficients. We further demonstrate the expressivity and limitations of
single-qubit native QNNs via numerical experiments. We believe these results
would improve our understanding of QNNs and provide a helpful guideline for
designing powerful QNNs for machine learning tasks.",2022-05-16,2022,2022-05,chemistry
"Overview of STEM Science as Process, Method, Material, and Data Named
  Entities","We are faced with an unprecedented production in scholarly publications
worldwide. Stakeholders in the digital libraries posit that the document-based
publishing paradigm has reached the limits of adequacy. Instead, structured,
machine-interpretable, fine-grained scholarly knowledge publishing as Knowledge
Graphs (KG) is strongly advocated. In this work, we develop and analyze a
large-scale structured dataset of STEM articles across 10 different
disciplines, viz. Agriculture, Astronomy, Biology, Chemistry, Computer Science,
Earth Science, Engineering, Material Science, Mathematics, and Medicine. Our
analysis is defined over a large-scale corpus comprising 60K abstracts
structured as four scientific entities process, method, material, and data.
Thus our study presents, for the first-time, an analysis of a large-scale
multidisciplinary corpus under the construct of four named entity labels that
are specifically defined and selected to be domain-independent as opposed to
domain-specific. The work is then inadvertently a feasibility test of
characterizing multidisciplinary science with domain-independent concepts.
Further, to summarize the distinct facets of scientific knowledge per concept
per discipline, a set of word cloud visualizations are offered. The
STEM-NER-60k corpus, created in this work, comprises over 1M extracted entities
from 60k STEM articles obtained from a major publishing platform and is
publicly released https://github.com/jd-coderepos/stem-ner-60k.",2022-05-24,2022,2022-05,chemistry
"MolScribe: Robust Molecular Structure Recognition with Image-To-Graph
  Generation","Molecular structure recognition is the task of translating a molecular image
into its graph structure. Significant variation in drawing styles and
conventions exhibited in chemical literature poses a significant challenge for
automating this task. In this paper, we propose MolScribe, a novel
image-to-graph generation model that explicitly predicts atoms and bonds, along
with their geometric layouts, to construct the molecular structure. Our model
flexibly incorporates symbolic chemistry constraints to recognize chirality and
expand abbreviated structures. We further develop data augmentation strategies
to enhance the model robustness against domain shifts. In experiments on both
synthetic and realistic molecular images, MolScribe significantly outperforms
previous models, achieving 76-93% accuracy on public benchmarks. Chemists can
also easily verify MolScribe's prediction, informed by its confidence
estimation and atom-level alignment with the input image. MolScribe is publicly
available through Python and web interfaces:
https://github.com/thomas0809/MolScribe.",2022-05-28,2022,2022-05,chemistry
"Machine vision for vial positioning detection toward the safe automation
  of material synthesis","Although robot-based automation in chemistry laboratories can accelerate the
material development process, surveillance-free environments may lead to
dangerous accidents primarily due to machine control errors. Object detection
techniques can play vital roles in addressing these safety issues; however,
state-of-the-art detectors, including single-shot detector (SSD) models, suffer
from insufficient accuracy in environments involving complex and noisy scenes.
With the aim of improving safety in a surveillance-free laboratory, we report a
novel deep learning (DL)-based object detector, namely, DenseSSD. For the
foremost and frequent problem of detecting vial positions, DenseSSD achieved a
mean average precision (mAP) over 95% based on a complex dataset involving both
empty and solution-filled vials, greatly exceeding those of conventional
detectors; such high precision is critical to minimizing failure-induced
accidents. Additionally, DenseSSD was observed to be highly insensitive to the
environmental changes, maintaining its high precision under the variations of
solution colors or testing view angles. The robustness of DenseSSD would allow
the utilized equipment settings to be more flexible. This work demonstrates
that DenseSSD is useful for enhancing safety in an automated material synthesis
environment, and it can be extended to various applications where high
detection accuracy and speed are both needed.",2022-06-15,2022,2022-06,chemistry
Approximate Equivariance SO(3) Needlet Convolution,"This paper develops a rotation-invariant needlet convolution for rotation
group SO(3) to distill multiscale information of spherical signals. The
spherical needlet transform is generalized from $\mathbb{S}^2$ onto the SO(3)
group, which decomposes a spherical signal to approximate and detailed spectral
coefficients by a set of tight framelet operators. The spherical signal during
the decomposition and reconstruction achieves rotation invariance. Based on
needlet transforms, we form a Needlet approximate Equivariance Spherical CNN
(NES) with multiple SO(3) needlet convolutional layers. The network establishes
a powerful tool to extract geometric-invariant features of spherical signals.
The model allows sufficient network scalability with multi-resolution
representation. A robust signal embedding is learned with wavelet shrinkage
activation function, which filters out redundant high-pass representation while
maintaining approximate rotation invariance. The NES achieves state-of-the-art
performance for quantum chemistry regression and Cosmic Microwave Background
(CMB) delensing reconstruction, which shows great potential for solving
scientific challenges with high-resolution and multi-scale spherical signal
representation.",2022-06-17,2022,2022-06,chemistry
RetroGraph: Retrosynthetic Planning with Graph Search,"Retrosynthetic planning, which aims to find a reaction pathway to synthesize
a target molecule, plays an important role in chemistry and drug discovery.
This task is usually modeled as a search problem. Recently, data-driven methods
have attracted many research interests and shown promising results for
retrosynthetic planning. We observe that the same intermediate molecules are
visited many times in the searching process, and they are usually independently
treated in previous tree-based methods (e.g., AND-OR tree search, Monte Carlo
tree search). Such redundancies make the search process inefficient. We propose
a graph-based search policy that eliminates the redundant explorations of any
intermediate molecules. As searching over a graph is more complicated than over
a tree, we further adopt a graph neural network to guide the search over
graphs. Meanwhile, our method can search a batch of targets together in the
graph and remove the inter-target duplication in the tree-based search methods.
Experimental results on two datasets demonstrate the effectiveness of our
method. Especially on the widely used USPTO benchmark, we improve the search
success rate to 99.47%, advancing previous state-of-the-art performance for 2.6
points.",2022-06-23,2022,2022-06,chemistry
Solving Quantitative Reasoning Problems with Language Models,"Language models have achieved remarkable performance on a wide range of tasks
that require natural language understanding. Nevertheless, state-of-the-art
models have generally struggled with tasks that require quantitative reasoning,
such as solving mathematics, science, and engineering problems at the college
level. To help close this gap, we introduce Minerva, a large language model
pretrained on general natural language data and further trained on technical
content. The model achieves state-of-the-art performance on technical
benchmarks without the use of external tools. We also evaluate our model on
over two hundred undergraduate-level problems in physics, biology, chemistry,
economics, and other sciences that require quantitative reasoning, and find
that the model can correctly answer nearly a third of them.",2022-06-29,2022,2022-06,chemistry
"Multiscale Neural Operator: Learning Fast and Grid-independent PDE
  Solvers","Numerical simulations in climate, chemistry, or astrophysics are
computationally too expensive for uncertainty quantification or
parameter-exploration at high-resolution. Reduced-order or surrogate models are
multiple orders of magnitude faster, but traditional surrogates are inflexible
or inaccurate and pure machine learning (ML)-based surrogates too data-hungry.
We propose a hybrid, flexible surrogate model that exploits known physics for
simulating large-scale dynamics and limits learning to the hard-to-model term,
which is called parametrization or closure and captures the effect of fine-
onto large-scale dynamics. Leveraging neural operators, we are the first to
learn grid-independent, non-local, and flexible parametrizations. Our
\textit{multiscale neural operator} is motivated by a rich literature in
multiscale modeling, has quasilinear runtime complexity, is more accurate or
flexible than state-of-the-art parametrizations and demonstrated on the chaotic
equation multiscale Lorenz96.",2022-07-23,2022,2022-07,chemistry
"AI-driven Hypergraph Network of Organic Chemistry: Network Statistics
  and Applications in Reaction Classification","Rapid discovery of new reactions and molecules in recent years has been
facilitated by the advancements in high throughput screening, accessibility to
a much more complex chemical design space, and the development of accurate
molecular modeling frameworks. A holistic study of the growing chemistry
literature is, therefore, required that focuses on understanding the recent
trends and extrapolating them into possible future trajectories. To this end,
several network theory-based studies have been reported that use a directed
graph representation of chemical reactions. Here, we perform a study based on
representing chemical reactions as hypergraphs where the hyperedges represent
chemical reactions and nodes represent the participating molecules. We use a
standard reactions dataset to construct a hypernetwork and report its
statistics such as degree distributions, average path length, assortativity or
degree correlations, PageRank centrality, and graph-based clusters (or
communities). We also compute each statistic for an equivalent directed graph
representation of reactions to draw parallels and highlight differences between
the two. To demonstrate the AI applicability of hypergraph reaction
representation, we generate dense hypergraph embeddings and use them in the
reaction classification problem. We conclude that the hypernetwork
representation is flexible, preserves reaction context, and uncovers hidden
insights that are otherwise not apparent in a traditional directed graph
representation of chemical reactions.",2022-08-02,2022,2022-08,chemistry
"MetaRF: Differentiable Random Forest for Reaction Yield Prediction with
  a Few Trails","Artificial intelligence has deeply revolutionized the field of medicinal
chemistry with many impressive applications, but the success of these
applications requires a massive amount of training samples with high-quality
annotations, which seriously limits the wide usage of data-driven methods. In
this paper, we focus on the reaction yield prediction problem, which assists
chemists in selecting high-yield reactions in a new chemical space only with a
few experimental trials. To attack this challenge, we first put forth MetaRF,
an attention-based differentiable random forest model specially designed for
the few-shot yield prediction, where the attention weight of a random forest is
automatically optimized by the meta-learning framework and can be quickly
adapted to predict the performance of new reagents while given a few additional
samples. To improve the few-shot learning performance, we further introduce a
dimension-reduction based sampling method to determine valuable samples to be
experimentally tested and then learned. Our methodology is evaluated on three
different datasets and acquires satisfactory performance on few-shot
prediction. In high-throughput experimentation (HTE) datasets, the average
yield of our methodology's top 10 high-yield reactions is relatively close to
the results of ideal yield selection.",2022-08-22,2022,2022-08,chemistry
"A Molecular Multimodal Foundation Model Associating Molecule Graphs with
  Natural Language","Although artificial intelligence (AI) has made significant progress in
understanding molecules in a wide range of fields, existing models generally
acquire the single cognitive ability from the single molecular modality. Since
the hierarchy of molecular knowledge is profound, even humans learn from
different modalities including both intuitive diagrams and professional texts
to assist their understanding. Inspired by this, we propose a molecular
multimodal foundation model which is pretrained from molecular graphs and their
semantically related textual data (crawled from published Scientific Citation
Index papers) via contrastive learning. This AI model represents a critical
attempt that directly bridges molecular graphs and natural language.
Importantly, through capturing the specific and complementary information of
the two modalities, our proposed model can better grasp molecular expertise.
Experimental results show that our model not only exhibits promising
performance in cross-modal tasks such as cross-modal retrieval and molecule
caption, but also enhances molecular property prediction and possesses
capability to generate meaningful molecular graphs from natural language
descriptions. We believe that our model would have a broad impact on
AI-empowered fields across disciplines such as biology, chemistry, materials,
environment, and medicine, among others.",2022-09-12,2022,2022-09,chemistry
"Tartarus: A Benchmarking Platform for Realistic And Practical Inverse
  Molecular Design","The efficient exploration of chemical space to design molecules with intended
properties enables the accelerated discovery of drugs, materials, and
catalysts, and is one of the most important outstanding challenges in
chemistry. Encouraged by the recent surge in computer power and artificial
intelligence development, many algorithms have been developed to tackle this
problem. However, despite the emergence of many new approaches in recent years,
comparatively little progress has been made in developing realistic benchmarks
that reflect the complexity of molecular design for real-world applications. In
this work, we develop a set of practical benchmark tasks relying on physical
simulation of molecular systems mimicking real-life molecular design problems
for materials, drugs, and chemical reactions. Additionally, we demonstrate the
utility and ease of use of our new benchmark set by demonstrating how to
compare the performance of several well-established families of algorithms.
Surprisingly, we find that model performance can strongly depend on the
benchmark domain. We believe that our benchmark suite will help move the field
towards more realistic molecular design benchmarks, and move the development of
inverse molecular design algorithms closer to designing molecules that solve
existing problems in both academia and industry alike.",2022-09-26,2022,2022-09,chemistry
"Provenance of Lyfe: Chemical Autonomous Agents Surviving through
  Associative Learning","We present a benchmark study of autonomous, chemical agents exhibiting
associative learning of an environmental feature. Associative learning has been
widely studied in cognitive science and artificial intelligence, but are most
commonly implemented in highly complex or carefully engineered systems such as
animal brains, artificial neural networks, DNA computing systems and gene
regulatory networks. The ability to encode environmental correlations and use
them to make predictions is a benchmark of biological resilience, and underpins
a plethora of adaptive responses in the living hierarchy, spanning prey animal
species anticipating the arrival of predators, to epigenetic systems in
microorganisms learning environmental correlations. Given the ubiquitous and
essential presence of learning behaviours in the biosphere, we aimed to explore
whether simple, non-living dissipative structures could also exhibit
associative learning. Inspired by previous modeling of associative learning in
chemical networks, we simulated simple systems composed of long and short term
memory chemical species that could encode the presence or absence of temporal
correlations between two external species. The ability to learn this
association was implemented in Gray-Scott reaction-diffusion spots, emergent
chemical patterns that exhibit self-replication and homeostasis. With the novel
ability of associative learning, we demonstrate that simple chemical patterns
can exhibit a broad repertoire of life-like behaviour, paving the way for in
vitro studies of autonomous chemical learning systems, with potential relevance
to artificial life, origins of life, and systems chemistry. The experimental
realisation of these learning behaviours in protocell systems could advance a
novel research direction in astrobiology, since our system significantly
reduces the lower bound on the required complexity for emergent learning.",2022-10-11,2022,2022-10,chemistry
Perspectives for self-driving labs in synthetic biology,"Self-driving labs (SDLs) combine fully automated experiments with artificial
intelligence (AI) that decides the next set of experiments. Taken to their
ultimate expression, SDLs could usher a new paradigm of scientific research,
where the world is probed, interpreted, and explained by machines for human
benefit. While there are functioning SDLs in the fields of chemistry and
materials science, we contend that synthetic biology provides a unique
opportunity since the genome provides a single target for affecting the
incredibly wide repertoire of biological cell behavior. However, the level of
investment required for the creation of biological SDLs is only warranted if
directed towards solving difficult and enabling biological questions. Here, we
discuss challenges and opportunities in creating SDLs for synthetic biology.",2022-10-14,2022,2022-10,chemistry
"PEMP: Leveraging Physics Properties to Enhance Molecular Property
  Prediction","Molecular property prediction is essential for drug discovery. In recent
years, deep learning methods have been introduced to this area and achieved
state-of-the-art performances. However, most of existing methods ignore the
intrinsic relations between molecular properties which can be utilized to
improve the performances of corresponding prediction tasks. In this paper, we
propose a new approach, namely Physics properties Enhanced Molecular Property
prediction (PEMP), to utilize relations between molecular properties revealed
by previous physics theory and physical chemistry studies. Specifically, we
enhance the training of the chemical and physiological property predictors with
related physics property prediction tasks. We design two different methods for
PEMP, respectively based on multi-task learning and transfer learning. Both
methods include a model-agnostic molecule representation module and a property
prediction module. In our implementation, we adopt both the state-of-the-art
molecule embedding models under the supervised learning paradigm and the
pretraining paradigm as the molecule representation module of PEMP,
respectively. Experimental results on public benchmark MoleculeNet show that
the proposed methods have the ability to outperform corresponding
state-of-the-art models.",2022-10-18,2022,2022-10,chemistry
"Solving the Schrodinger equation with genetic algorithms: a practical
  approach","The Schrodinger equation is one of the most important equations in physics
and chemistry and can be solved in the simplest cases by computer numerical
methods. Since the beginning of the 70s of the last century the computer began
to be used to solve this equation in elementary quantum systems, e.g. and in
the most complex case a hydrogen-like system. Obtaining the solution means
finding the wave function, which allows predicting the physical and chemical
properties of the quantum system. However, when a quantum system is more
complex than a hydrogen-like system then we must be satisfied with an
approximate solution of the equation. During the last decade the application of
algorithms and principles of quantum computation in disciplines other than
physics and chemistry, such as biology and artificial intelligence, has led to
the search for alternative techniques with which to obtain approximate
solutions of the Schrodinger equation. In this paper, we review and illustrate
the application of genetic algorithms, i.e. stochastic optimization procedures
inspired by Darwinian evolution, in elementary quantum systems and in quantum
models of artificial intelligence. In this last field, we illustrate with two
toy models how to solve the Schrodinger equation in an elementary model of a
quantum neuron and in the synthesis of quantum circuits controlling the
behavior of a Braitenberg vehicle.",2022-10-27,2022,2022-10,chemistry
"Exploring the Advantages of Quantum Generative Adversarial Networks in
  Generative Chemistry","De novo drug design with desired biological activities is crucial for
developing novel therapeutics for patients. The drug development process is
time and resource-consuming, and it has a low probability of success. Recent
advances in machine learning and deep learning technology have reduced the time
and cost of the discovery process and therefore, improved pharmaceutical
research and development. In this paper, we explore the combination of two
rapidly-developing fields with lead candidate discovery in the drug development
process. First, Artificial intelligence has already been demonstrated to
successfully accelerate conventional drug design approaches. Second, quantum
computing has demonstrated promising potential in different applications, such
as quantum chemistry, combinatorial optimizations, and machine learning. This
manuscript explores hybrid quantum-classical generative adversarial networks
(GAN) for small molecule discovery. We substituted each element of GAN with a
variational quantum circuit (VQC) and demonstrated the quantum advantages in
the small drug discovery. Utilizing a VQC in the noise generator of a GAN to
generate small molecules achieves better physicochemical properties and
performance in the goal-directed benchmark than the classical counterpart.
Moreover, we demonstrate the potential of a VQC with only tens of learnable
parameters in the generator of GAN to generate small molecules. We also
demonstrate the quantum advantage of a VQC in the discriminator of GAN. In this
hybrid model, the number of learnable parameters is significantly less than the
classical ones, and it can still generate valid molecules. The hybrid model
with only tens of training parameters in the quantum discriminator outperforms
the MLP-based one in terms of both generated molecule properties and the
achieved KL divergence.",2022-10-30,2022,2022-10,chemistry
"QuACK: Accelerating Gradient-Based Quantum Optimization with Koopman
  Operator Learning","Quantum optimization, a key application of quantum computing, has
traditionally been stymied by the linearly increasing complexity of gradient
calculations with an increasing number of parameters. This work bridges the gap
between Koopman operator theory, which has found utility in applications
because it allows for a linear representation of nonlinear dynamical systems,
and natural gradient methods in quantum optimization, leading to a significant
acceleration of gradient-based quantum optimization. We present Quantum-circuit
Alternating Controlled Koopman learning (QuACK), a novel framework that
leverages an alternating algorithm for efficient prediction of gradient
dynamics on quantum computers. We demonstrate QuACK's remarkable ability to
accelerate gradient-based optimization across a range of applications in
quantum optimization and machine learning. In fact, our empirical studies,
spanning quantum chemistry, quantum condensed matter, quantum machine learning,
and noisy environments, have shown accelerations of more than 200x speedup in
the overparameterized regime, 10x speedup in the smooth regime, and 3x speedup
in the non-smooth regime. With QuACK, we offer a robust advancement that
harnesses the advantage of gradient-based quantum optimization for practical
benefits.",2022-11-02,2022,2022-11,chemistry
Quantum Deep Dreaming: A Novel Approach for Quantum Circuit Design,"One of the challenges currently facing the quantum computing community is the
design of quantum circuits which can efficiently run on near-term quantum
computers, known as the quantum compiling problem. Algorithms such as the
Variational Quantum Eigensolver (VQE), Quantum Approximate Optimization
Algorithm (QAOA), and Quantum Architecture Search (QAS) have been shown to
generate or find optimal near-term quantum circuits. However, these methods are
computationally expensive and yield little insight into the circuit design
process. In this paper, we propose Quantum Deep Dreaming (QDD), an algorithm
that generates optimal quantum circuit architectures for specified objectives,
such as ground state preparation, while providing insight into the circuit
design process. In QDD, we first train a neural network to predict some
property of a quantum circuit (such as VQE energy). Then, we employ the Deep
Dreaming technique on the trained network to iteratively update an initial
circuit to achieve a target property value (such as ground state VQE energy).
Importantly, this iterative updating allows us to analyze the intermediate
circuits of the dreaming process and gain insights into the circuit features
that the network is modifying during dreaming. We demonstrate that QDD
successfully generates, or 'dreams', circuits of six qubits close to ground
state energy (Transverse Field Ising Model VQE energy) and that dreaming
analysis yields circuit design insights. QDD is designed to optimize circuits
with any target property and can be applied to circuit design problems both
within and outside of quantum chemistry. Hence, QDD lays the foundation for the
future discovery of optimized quantum circuits and for increased
interpretability of automated quantum algorithm design.",2022-11-05,2022,2022-11,chemistry
Toward Human-AI Co-creation to Accelerate Material Discovery,"There is an increasing need in our society to achieve faster advances in
Science to tackle urgent problems, such as climate changes, environmental
hazards, sustainable energy systems, pandemics, among others. In certain
domains like chemistry, scientific discovery carries the extra burden of
assessing risks of the proposed novel solutions before moving to the
experimental stage. Despite several recent advances in Machine Learning and AI
to address some of these challenges, there is still a gap in technologies to
support end-to-end discovery applications, integrating the myriad of available
technologies into a coherent, orchestrated, yet flexible discovery process.
Such applications need to handle complex knowledge management at scale,
enabling knowledge consumption and production in a timely and efficient way for
subject matter experts (SMEs). Furthermore, the discovery of novel functional
materials strongly relies on the development of exploration strategies in the
chemical space. For instance, generative models have gained attention within
the scientific community due to their ability to generate enormous volumes of
novel molecules across material domains. These models exhibit extreme
creativity that often translates in low viability of the generated candidates.
In this work, we propose a workbench framework that aims at enabling the
human-AI co-creation to reduce the time until the first discovery and the
opportunity costs involved. This framework relies on a knowledge base with
domain and process knowledge, and user-interaction components to acquire
knowledge and advise the SMEs. Currently,the framework supports four main
activities: generative modeling, dataset triage, molecule adjudication, and
risk assessment.",2022-11-05,2022,2022-11,chemistry
Model free variable importance for high dimensional data,"A model-agnostic variable importance method can be used with arbitrary
prediction functions. Here we present some model-free methods that do not
require access to the prediction function. This is useful when that function is
proprietary and not available, or just extremely expensive. It is also useful
when studying residuals from a model. The cohort Shapley (CS) method is
model-free but has exponential cost in the dimension of the input space. A
supervised on-manifold Shapley method from Frye et al. (2020) is also model
free but requires as input a second black box model that has to be trained for
the Shapley value problem. We introduce an integrated gradient (IG) version of
cohort Shapley, called IGCS, with cost $\mathcal{O}(nd)$. We show that over the
vast majority of the relevant unit cube that the IGCS value function is close
to a multilinear function for which IGCS matches CS. Another benefit of IGCS is
that is allows IG methods to be used with binary predictors. We use some area
between curves (ABC) measures to quantify the performance of IGCS. On a problem
from high energy physics we verify that IGCS has nearly the same ABCs as CS
does. We also use it on a problem from computational chemistry in 1024
variables. We see there that IGCS attains much higher ABCs than we get from
Monte Carlo sampling. The code is publicly available at
https://github.com/cohortshapley/cohortintgrad",2022-11-15,2022,2022-11,chemistry
"Near-Term Quantum Computing Techniques: Variational Quantum Algorithms,
  Error Mitigation, Circuit Compilation, Benchmarking and Classical Simulation","Quantum computing is a game-changing technology for global academia, research
centers and industries including computational science, mathematics, finance,
pharmaceutical, materials science, chemistry and cryptography. Although it has
seen a major boost in the last decade, we are still a long way from reaching
the maturity of a full-fledged quantum computer. That said, we will be in the
Noisy-Intermediate Scale Quantum (NISQ) era for a long time, working on dozens
or even thousands of qubits quantum computing systems. An outstanding
challenge, then, is to come up with an application that can reliably carry out
a nontrivial task of interest on the near-term quantum devices with
non-negligible quantum noise. To address this challenge, several near-term
quantum computing techniques, including variational quantum algorithms, error
mitigation, quantum circuit compilation and benchmarking protocols, have been
proposed to characterize and mitigate errors, and to implement algorithms with
a certain resistance to noise, so as to enhance the capabilities of near-term
quantum devices and explore the boundaries of their ability to realize useful
applications. Besides, the development of near-term quantum devices is
inseparable from the efficient classical simulation, which plays a vital role
in quantum algorithm design and verification, error-tolerant verification and
other applications. This review will provide a thorough introduction of these
near-term quantum computing techniques, report on their progress, and finally
discuss the future prospect of these techniques, which we hope will motivate
researchers to undertake additional studies in this field.",2022-11-16,2022,2022-11,chemistry
"SnCQA: A hardware-efficient equivariant quantum convolutional circuit
  architecture","We propose SnCQA, a set of hardware-efficient variational circuits of
equivariant quantum convolutional circuits respective to permutation symmetries
and spatial lattice symmetries with the number of qubits $n$. By exploiting
permutation symmetries of the system, such as lattice Hamiltonians common to
many quantum many-body and quantum chemistry problems, Our quantum neural
networks are suitable for solving machine learning problems where permutation
symmetries are present, which could lead to significant savings of
computational costs. Aside from its theoretical novelty, we find our
simulations perform well in practical instances of learning ground states in
quantum computational chemistry, where we could achieve comparable performances
to traditional methods with few tens of parameters. Compared to other
traditional variational quantum circuits, such as the pure hardware-efficient
ansatz (pHEA), we show that SnCQA is more scalable, accurate, and noise
resilient (with $20\times$ better performance on $3 \times 4$ square lattice
and $200\% - 1000\%$ resource savings in various lattice sizes and key
criterions such as the number of layers, parameters, and times to converge in
our cases), suggesting a potentially favorable experiment on near-time quantum
devices.",2022-11-23,2022,2022-11,chemistry
"Accelerating Inverse Learning via Intelligent Localization with
  Exploratory Sampling","In the scope of ""AI for Science"", solving inverse problems is a longstanding
challenge in materials and drug discovery, where the goal is to determine the
hidden structures given a set of desirable properties. Deep generative models
are recently proposed to solve inverse problems, but these currently use
expensive forward operators and struggle in precisely localizing the exact
solutions and fully exploring the parameter spaces without missing solutions.
In this work, we propose a novel approach (called iPage) to accelerate the
inverse learning process by leveraging probabilistic inference from deep
invertible models and deterministic optimization via fast gradient descent.
Given a target property, the learned invertible model provides a posterior over
the parameter space; we identify these posterior samples as an intelligent
prior initialization which enables us to narrow down the search space. We then
perform gradient descent to calibrate the inverse solutions within a local
region. Meanwhile, a space-filling sampling is imposed on the latent space to
better explore and capture all possible solutions. We evaluate our approach on
three benchmark tasks and two created datasets with real-world applications
from quantum chemistry and additive manufacturing, and find our method achieves
superior performance compared to several state-of-the-art baseline methods. The
iPage code is available at https://github.com/jxzhangjhu/MatDesINNe.",2022-12-02,2022,2022-12,chemistry
"Multi-modal Molecule Structure-text Model for Text-based Retrieval and
  Editing","There is increasing adoption of artificial intelligence in drug discovery.
However, existing studies use machine learning to mainly utilize the chemical
structures of molecules but ignore the vast textual knowledge available in
chemistry. Incorporating textual knowledge enables us to realize new drug
design objectives, adapt to text-based instructions and predict complex
biological activities. Here we present a multi-modal molecule structure-text
model, MoleculeSTM, by jointly learning molecules' chemical structures and
textual descriptions via a contrastive learning strategy. To train MoleculeSTM,
we construct a large multi-modal dataset, namely, PubChemSTM, with over 280,000
chemical structure-text pairs. To demonstrate the effectiveness and utility of
MoleculeSTM, we design two challenging zero-shot tasks based on text
instructions, including structure-text retrieval and molecule editing.
MoleculeSTM has two main properties: open vocabulary and compositionality via
natural language. In experiments, MoleculeSTM obtains the state-of-the-art
generalization ability to novel biochemical concepts across various benchmarks.",2022-12-21,2022,2022-12,chemistry
"ACE, a generic constraint solver","Constraint Programming (CP) is a useful technology for modeling and solving
combinatorial constrained problems. On the one hand, on can use a library like
PyCSP3 for easily modeling problems arising in various application fields
(e.g., scheduling, planning, data-mining, cryptography, bio-informatics,
organic chemistry, etc.). Problem instances can then be directly generated from
specific models and data. On the other hand, for solving instances (notably,
represented in XCSP3 format), one can use a constraint solver like ACE, which
is presented in this paper. ACE is an open-source constraint solver, developed
in Java, which focuses on integer variables (including 0/1-Boolean variables),
state-of-the-art table constraints, popular global constraints, search
heuristics and (mono-criterion) optimization.",2023-01-06,2023,2023-01,chemistry
Recent advances in artificial intelligence for retrosynthesis,"Retrosynthesis is the cornerstone of organic chemistry, providing chemists in
material and drug manufacturing access to poorly available and brand-new
molecules. Conventional rule-based or expert-based computer-aided synthesis has
obvious limitations, such as high labor costs and limited search space. In
recent years, dramatic breakthroughs driven by artificial intelligence have
revolutionized retrosynthesis. Here we aim to present a comprehensive review of
recent advances in AI-based retrosynthesis. For single-step and multi-step
retrosynthesis both, we first list their goal and provide a thorough taxonomy
of existing methods. Afterwards, we analyze these methods in terms of their
mechanism and performance, and introduce popular evaluation metrics for them,
in which we also provide a detailed comparison among representative methods on
several public datasets. In the next part we introduce popular databases and
established platforms for retrosynthesis. Finally, this review concludes with a
discussion about promising research directions in this field.",2023-01-14,2023,2023-01,chemistry
Ontology Pre-training for Poison Prediction,"Integrating human knowledge into neural networks has the potential to improve
their robustness and interpretability. We have developed a novel approach to
integrate knowledge from ontologies into the structure of a Transformer network
which we call ontology pre-training: we train the network to predict membership
in ontology classes as a way to embed the structure of the ontology into the
network, and subsequently fine-tune the network for the particular prediction
task. We apply this approach to a case study in predicting the potential
toxicity of a small molecule based on its molecular structure, a challenging
task for machine learning in life sciences chemistry. Our approach improves on
the state of the art, and moreover has several additional benefits. First, we
are able to show that the model learns to focus attention on more meaningful
chemical groups when making predictions with ontology pre-training than
without, paving a path towards greater robustness and interpretability. Second,
the training time is reduced after ontology pre-training, indicating that the
model is better placed to learn what matters for toxicity prediction with the
ontology pre-training than without. This strategy has general applicability as
a neuro-symbolic approach to embed meaningful semantics into neural networks.",2023-01-20,2023,2023-01,chemistry
"Can an AI Win Ghana's National Science and Maths Quiz? An AI Grand
  Challenge for Education","There is a lack of enough qualified teachers across Africa which hampers
efforts to provide adequate learning support such as educational question
answering (EQA) to students. An AI system that can enable students to ask
questions via text or voice and get instant answers will make high-quality
education accessible. Despite advances in the field of AI, there exists no
robust benchmark or challenge to enable building such an (EQA) AI within the
African context. Ghana's National Science and Maths Quiz competition (NSMQ) is
the perfect competition to evaluate the potential of such an AI due to its wide
coverage of scientific fields, variety of question types, highly competitive
nature, and live, real-world format. The NSMQ is a Jeopardy-style annual live
quiz competition in which 3 teams of 2 students compete by answering questions
across biology, chemistry, physics, and math in 5 rounds over 5 progressive
stages until a winning team is crowned for that year. In this position paper,
we propose the NSMQ AI Grand Challenge, an AI Grand Challenge for Education
using Ghana's National Science and Maths Quiz competition (NSMQ) as a case
study. Our proposed grand challenge is to ""Build an AI to compete live in
Ghana's National Science and Maths Quiz (NSMQ) competition and win - performing
better than the best contestants in all rounds and stages of the competition.""
We describe the competition, and key technical challenges to address along with
ideas from recent advances in machine learning that could be leveraged to solve
this challenge. This position paper is a first step towards conquering such a
challenge and importantly, making advances in AI for education in the African
context towards democratizing high-quality education across Africa.",2023-01-30,2023,2023-01,chemistry
"HOAX: A Hyperparameter Optimization Algorithm Explorer for Neural
  Networks","Computational chemistry has become an important tool to predict and
understand molecular properties and reactions. Even though recent years have
seen a significant growth in new algorithms and computational methods that
speed up quantum chemical calculations, the bottleneck for trajectory-based
methods to study photoinduced processes is still the huge number of electronic
structure calculations. In this work, we present an innovative solution, in
which the amount of electronic structure calculations is drastically reduced,
by employing machine learning algorithms and methods borrowed from the realm of
artificial intelligence. However, applying these algorithms effectively
requires finding optimal hyperparameters, which remains a challenge itself.
Here we present an automated user-friendly framework, HOAX, to perform the
hyperparameter optimization for neural networks, which bypasses the need for a
lengthy manual process. The neural network generated potential energy surfaces
(PESs) reduces the computational costs compared to the ab initio-based PESs. We
perform a comparative investigation on the performance of different
hyperparameter optimiziation algorithms, namely grid search, simulated
annealing, genetic algorithm, and bayesian optimizer in finding the optimal
hyperparameters necessary for constructing the well-performing neural network
in order to fit the PESs of small organic molecules. Our results show that this
automated toolkit not only facilitate a straightforward way to perform the
hyperparameter optimization but also the resulting neural networks-based
generated PESs are in reasonable agreement with the ab initio-based PESs.",2023-02-01,2023,2023-02,chemistry
"Molecular Geometry-aware Transformer for accurate 3D Atomic System
  modeling","Molecular dynamic simulations are important in computational physics,
chemistry, material, and biology. Machine learning-based methods have shown
strong abilities in predicting molecular energy and properties and are much
faster than DFT calculations. Molecular energy is at least related to atoms,
bonds, bond angles, torsion angles, and nonbonding atom pairs. Previous
Transformer models only use atoms as inputs which lack explicit modeling of the
aforementioned factors. To alleviate this limitation, we propose Moleformer, a
novel Transformer architecture that takes nodes (atoms) and edges (bonds and
nonbonding atom pairs) as inputs and models the interactions among them using
rotational and translational invariant geometry-aware spatial encoding.
Proposed spatial encoding calculates relative position information including
distances and angles among nodes and edges. We benchmark Moleformer on OC20 and
QM9 datasets, and our model achieves state-of-the-art on the initial state to
relaxed energy prediction of OC20 and is very competitive in QM9 on predicting
quantum chemical properties compared to other Transformer and Graph Neural
Network (GNN) methods which proves the effectiveness of the proposed
geometry-aware spatial encoding in Moleformer.",2023-02-02,2023,2023-02,chemistry
"Diversity Through Exclusion (DTE): Niche Identification for
  Reinforcement Learning through Value-Decomposition","Many environments contain numerous available niches of variable value, each
associated with a different local optimum in the space of behaviors (policy
space). In such situations it is often difficult to design a learning process
capable of evading distraction by poor local optima long enough to stumble upon
the best available niche. In this work we propose a generic reinforcement
learning (RL) algorithm that performs better than baseline deep Q-learning
algorithms in such environments with multiple variably-valued niches. The
algorithm we propose consists of two parts: an agent architecture and a
learning rule. The agent architecture contains multiple sub-policies. The
learning rule is inspired by fitness sharing in evolutionary computation and
applied in reinforcement learning using Value-Decomposition-Networks in a novel
manner for a single-agent's internal population. It can concretely be
understood as adding an extra loss term where one policy's experience is also
used to update all the other policies in a manner that decreases their value
estimates for the visited states. In particular, when one sub-policy visits a
particular state frequently this decreases the value predicted for other
sub-policies for going to that state. Further, we introduce an artificial
chemistry inspired platform where it is easy to create tasks with multiple
rewarding strategies utilizing different resources (i.e. multiple niches). We
show that agents trained this way can escape poor-but-attractive local optima
to instead converge to harder-to-discover higher value strategies in both the
artificial chemistry environments and in simpler illustrative environments.",2023-02-02,2023,2023-02,chemistry
"Dynamical Equations With Bottom-up Self-Organizing Properties Learn
  Accurate Dynamical Hierarchies Without Any Loss Function","Self-organization is ubiquitous in nature and mind. However, machine learning
and theories of cognition still barely touch the subject. The hurdle is that
general patterns are difficult to define in terms of dynamical equations and
designing a system that could learn by reordering itself is still to be seen.
Here, we propose a learning system, where patterns are defined within the realm
of nonlinear dynamics with positive and negative feedback loops, allowing
attractor-repeller pairs to emerge for each pattern observed. Experiments
reveal that such a system can map temporal to spatial correlation, enabling
hierarchical structures to be learned from sequential data. The results are
accurate enough to surpass state-of-the-art unsupervised learning algorithms in
seven out of eight experiments as well as two real-world problems.
Interestingly, the dynamic nature of the system makes it inherently adaptive,
giving rise to phenomena similar to phase transitions in
chemistry/thermodynamics when the input structure changes. Thus, the work here
sheds light on how self-organization can allow for pattern recognition and
hints at how intelligent behavior might emerge from simple dynamic equations
without any objective/loss function.",2023-02-04,2023,2023-02,chemistry
"Orders-of-coupling representation with a single neural network with
  optimal neuron activation functions and without nonlinear parameter
  optimization","Representations of multivariate functions with low-dimensional functions that
depend on subsets of original coordinates (corresponding of different orders of
coupling) are useful in quantum dynamics and other applications, especially
where integration is needed. Such representations can be conveniently built
with machine learning methods, and previously, methods building the
lower-dimensional terms of such representations with neural networks [e.g.
Comput. Phys. Comm. 180 (2009) 2002] and Gaussian process regressions [e.g.
Mach. Learn. Sci. Technol. 3 (2022) 01LT02] were proposed. Here, we show that
neural network models of orders-of-coupling representations can be easily built
by using a recently proposed neural network with optimal neuron activation
functions computed with a first-order additive Gaussian process regression
[arXiv:2301.05567] and avoiding non-linear parameter optimization. Examples are
given of representations of molecular potential energy surfaces.",2023-02-11,2023,2023-02,chemistry
"PrefixMol: Target- and Chemistry-aware Molecule Design via Prefix
  Embedding","Is there a unified model for generating molecules considering different
conditions, such as binding pockets and chemical properties? Although
target-aware generative models have made significant advances in drug design,
they do not consider chemistry conditions and cannot guarantee the desired
chemical properties. Unfortunately, merging the target-aware and chemical-aware
models into a unified model to meet customized requirements may lead to the
problem of negative transfer. Inspired by the success of multi-task learning in
the NLP area, we use prefix embeddings to provide a novel generative model that
considers both the targeted pocket's circumstances and a variety of chemical
properties. All conditional information is represented as learnable features,
which the generative model subsequently employs as a contextual prompt.
Experiments show that our model exhibits good controllability in both single
and multi-conditional molecular generation. The controllability enables us to
outperform previous structure-based drug design methods. More interestingly, we
open up the attention mechanism and reveal coupling relationships between
conditions, providing guidance for multi-conditional molecule generation.",2023-02-14,2023,2023-02,chemistry
"CHA2: CHemistry Aware Convex Hull Autoencoder Towards Inverse Molecular
  Design","Optimizing molecular design and discovering novel chemical structures to meet
certain objectives, such as quantitative estimates of the drug-likeness score
(QEDs), is NP-hard due to the vast combinatorial design space of discrete
molecular structures, which makes it near impossible to explore the entire
search space comprehensively to exploit de novo structures with properties of
interest. To address this challenge, reducing the intractable search space into
a lower-dimensional latent volume helps examine molecular candidates more
feasibly via inverse design. Autoencoders are suitable deep learning
techniques, equipped with an encoder that reduces the discrete molecular
structure into a latent space and a decoder that inverts the search space back
to the molecular design. The continuous property of the latent space, which
characterizes the discrete chemical structures, provides a flexible
representation for inverse design in order to discover novel molecules.
However, exploring this latent space requires certain insights to generate new
structures. We propose using a convex hall surrounding the top molecules in
terms of high QEDs to ensnare a tight subspace in the latent representation as
an efficient way to reveal novel molecules with high QEDs. We demonstrate the
effectiveness of our suggested method by using the QM9 as a training dataset
along with the Self- Referencing Embedded Strings (SELFIES) representation to
calibrate the autoencoder in order to carry out the Inverse molecular design
that leads to unfold novel chemical structure.",2023-02-21,2023,2023-02,chemistry
Neuro-symbolic Commonsense Social Reasoning,"Social norms underlie all human social interactions, yet formalizing and
reasoning with them remains a major challenge for AI systems. We present a
novel system for taking social rules of thumb (ROTs) in natural language from
the Social Chemistry 101 dataset and converting them to first-order logic where
reasoning is performed using a neuro-symbolic theorem prover. We accomplish
this in several steps. First, ROTs are converted into Abstract Meaning
Representation (AMR), which is a graphical representation of the concepts in a
sentence, and align the AMR with RoBERTa embeddings. We then generate alternate
simplified versions of the AMR via a novel algorithm, recombining and merging
embeddings for added robustness against different wordings of text, and
incorrect AMR parses. The AMR is then converted into first-order logic, and is
queried with a neuro-symbolic theorem prover. The goal of this paper is to
develop and evaluate a neuro-symbolic method which performs explicit reasoning
about social situations in a logical form.",2023-03-14,2023,2023-03,chemistry
"HomPINNs: homotopy physics-informed neural networks for solving the
  inverse problems of nonlinear differential equations with multiple solutions","Due to the complex behavior arising from non-uniqueness, symmetry, and
bifurcations in the solution space, solving inverse problems of nonlinear
differential equations (DEs) with multiple solutions is a challenging task. To
address this, we propose homotopy physics-informed neural networks (HomPINNs),
a novel framework that leverages homotopy continuation and neural networks
(NNs) to solve inverse problems. The proposed framework begins with the use of
NNs to simultaneously approximate unlabeled observations across diverse
solutions while adhering to DE constraints. Through homotopy continuation, the
proposed method solves the inverse problem by tracing the observations and
identifying multiple solutions. The experiments involve testing the performance
of the proposed method on one-dimensional DEs and applying it to solve a
two-dimensional Gray-Scott simulation. Our findings demonstrate that the
proposed method is scalable and adaptable, providing an effective solution for
solving DEs with multiple solutions and unknown parameters. Moreover, it has
significant potential for various applications in scientific computing, such as
modeling complex systems and solving inverse problems in physics, chemistry,
biology, etc.",2023-04-06,2023,2023-04,chemistry
"Deep learning of experimental electrochemistry for battery cathodes
  across diverse compositions","Artificial intelligence (AI) has emerged as a tool for discovering and
optimizing novel battery materials. However, the adoption of AI in battery
cathode representation and discovery is still limited due to the complexity of
optimizing multiple performance properties and the scarcity of high-fidelity
data. In this study, we present a machine-learning model (DRXNet) for battery
informatics and demonstrate the application in the discovery and optimization
of disordered rocksalt (DRX) cathode materials. We have compiled the
electrochemistry data of DRX cathodes over the past five years, resulting in a
dataset of more than 19,000 discharge voltage profiles on diverse chemistries
spanning 14 different metal species. Learning from this extensive dataset, our
DRXNet model can automatically capture critical features in the cycling curves
of DRX cathodes under various conditions. Illustratively, the model gives
rational predictions of the discharge capacity for diverse compositions in the
Li--Mn--O--F chemical space as well as for high-entropy systems. As a universal
model trained on diverse chemistries, our approach offers a data-driven
solution to facilitate the rapid identification of novel cathode materials,
accelerating the development of next-generation batteries for carbon
neutralization.",2023-04-11,2023,2023-04,chemistry
"Cluster Flow: how a hierarchical clustering layer make allows deep-NNs
  more resilient to hacking, more human-like and easily implements relational
  reasoning","Despite the huge recent breakthroughs in neural networks (NNs) for artificial
intelligence (specifically deep convolutional networks) such NNs do not achieve
human-level performance: they can be hacked by images that would fool no human
and lack `common sense'. It has been argued that a basis of human-level
intelligence is mankind's ability to perform relational reasoning: the
comparison of different objects, measuring similarity, grasping of relations
between objects and the converse, figuring out the odd one out in a set of
objects. Mankind can even do this with objects they have never seen before.
Here we show how ClusterFlow, a semi-supervised hierarchical clustering
framework can operate on trained NNs utilising the rich multi-dimensional class
and feature data found at the pre-SoftMax layer to build a hyperspacial map of
classes/features and this adds more human-like functionality to modern deep
convolutional neural networks. We demonstrate this with 3 tasks. 1. the
statistical learning based `mistakes' made by infants when attending to images
of cats and dogs. 2. improving both the resilience to hacking images and the
accurate measure of certainty in deep-NNs. 3. Relational reasoning over sets of
images, including those not known to the NN nor seen before. We also
demonstrate that ClusterFlow can work on non-NN data and deal with missing data
by testing it on a Chemistry dataset. This work suggests that modern deep NNs
can be made more human-like without re-training of the NNs. As it is known that
some methods used in deep and convolutional NNs are not biologically plausible
or perhaps even the best approach: the ClusterFlow framework can sit on top of
any NN and will be a useful tool to add as NNs are improved in this regard.",2023-04-27,2023,2023-04,chemistry
An Exploration of Conditioning Methods in Graph Neural Networks,"The flexibility and effectiveness of message passing based graph neural
networks (GNNs) induced considerable advances in deep learning on
graph-structured data. In such approaches, GNNs recursively update node
representations based on their neighbors and they gain expressivity through the
use of node and edge attribute vectors. E.g., in computational tasks such as
physics and chemistry usage of edge attributes such as relative position or
distance proved to be essential. In this work, we address not what kind of
attributes to use, but how to condition on this information to improve model
performance. We consider three types of conditioning; weak, strong, and pure,
which respectively relate to concatenation-based conditioning, gating, and
transformations that are causally dependent on the attributes. This
categorization provides a unifying viewpoint on different classes of GNNs, from
separable convolutions to various forms of message passing networks. We provide
an empirical study on the effect of conditioning methods in several tasks in
computational chemistry.",2023-05-03,2023,2023-05,chemistry
"G-MATT: Single-step Retrosynthesis Prediction using Molecular Grammar
  Tree Transformer","Various template-based and template-free approaches have been proposed for
single-step retrosynthesis prediction in recent years. While these approaches
demonstrate strong performance from a data-driven metrics standpoint, many
model architectures do not incorporate underlying chemistry principles. Here,
we propose a novel chemistry-aware retrosynthesis prediction framework that
combines powerful data-driven models with prior domain knowledge. We present a
tree-to-sequence transformer architecture that utilizes hierarchical SMILES
grammar-based trees, incorporating crucial chemistry information that is often
overlooked by SMILES text-based representations, such as local structures and
functional groups. The proposed framework, grammar-based molecular attention
tree transformer (G-MATT), achieves significant performance improvements
compared to baseline retrosynthesis models. G-MATT achieves a promising top-1
accuracy of 51% (top-10 accuracy of 79.1%), invalid rate of 1.5%, and bioactive
similarity rate of 74.8% on the USPTO- 50K dataset. Additional analyses of
G-MATT attention maps demonstrate the ability to retain chemistry knowledge
without relying on excessively complex model architectures.",2023-05-04,2023,2023-05,chemistry
RxnScribe: A Sequence Generation Model for Reaction Diagram Parsing,"Reaction diagram parsing is the task of extracting reaction schemes from a
diagram in the chemistry literature. The reaction diagrams can be arbitrarily
complex, thus robustly parsing them into structured data is an open challenge.
In this paper, we present RxnScribe, a machine learning model for parsing
reaction diagrams of varying styles. We formulate this structured prediction
task with a sequence generation approach, which condenses the traditional
pipeline into an end-to-end model. We train RxnScribe on a dataset of 1,378
diagrams and evaluate it with cross validation, achieving an 80.0% soft match
F1 score, with significant improvements over previous models. Our code and data
are publicly available at https://github.com/thomas0809/RxnScribe.",2023-05-19,2023,2023-05,chemistry
"Automated Feedback Generation for a Chemistry Database and Abstracting
  Exercise","Timely feedback is an important part of teaching and learning. Here we
describe how a readily available neural network transformer (machine-learning)
model (BERT) can be used to give feedback on the structure of the response to
an abstracting exercise where students are asked to summarise the contents of a
published article after finding it from a publication database. The dataset
contained 207 submissions from two consecutive years of the course, summarising
a total of 21 different papers from the primary literature. The model was
pre-trained using an available dataset (approx. 15,000 samples) and then
fine-tuned on 80% of the submitted dataset. This fine tuning was seen to be
important. The sentences in the student submissions are characterised into
three classes - background, technique and observation - which allows a
comparison of how each submission is structured. Comparing the structure of the
students' abstract a large collection of those from the PubMed database shows
that students in this exercise concentrate more on the background to the paper
and less on the techniques and results than the abstracts to papers themselves.
The results allowed feedback for each submitted assignment to be automatically
generated.",2023-05-22,2023,2023-05,chemistry
"Have LLMs Advanced Enough? A Challenging Problem Solving Benchmark For
  Large Language Models","The performance of large language models (LLMs) on existing reasoning
benchmarks has significantly improved over the past years. In response, we
present JEEBench, a considerably more challenging benchmark dataset for
evaluating the problem solving abilities of LLMs. We curate 515 challenging
pre-engineering mathematics, physics and chemistry problems from the highly
competitive IIT JEE-Advanced exam. Long-horizon reasoning on top of deep
in-domain knowledge is essential for solving problems in this benchmark. Our
evaluation on various open-source and proprietary models reveals that the
highest performance, even after using techniques like self-consistency,
self-refinement and chain-of-thought prompting, is less than 40%. The typical
failure modes of GPT-4, the best model, are errors in algebraic manipulation,
difficulty in grounding abstract concepts into mathematical equations
accurately and failure in retrieving relevant domain-specific concepts. We also
observe that by mere prompting, GPT-4 is unable to assess risk introduced by
negative marking for incorrect answers. For this, we develop a post-hoc
confidence-thresholding method over self-consistency, which enables effective
response selection. We hope that our challenging benchmark will guide future
re-search in problem-solving using LLMs.",2023-05-24,2023,2023-05,chemistry
"Metrics for quantifying isotropy in high dimensional unsupervised
  clustering tasks in a materials context","Clustering is a common task in machine learning, but clusters of unlabelled
data can be hard to quantify. The application of clustering algorithms in
chemistry is often dependant on material representation. Ascertaining the
effects of different representations, clustering algorithms, or data
transformations on the resulting clusters is difficult due to the
dimensionality of these data. We present a thorough analysis of measures for
isotropy of a cluster, including a novel implantation based on an existing
derivation. Using fractional anisotropy, a common method used in medical
imaging for comparison, we then expand these measures to examine the average
isotropy of a set of clusters. A use case for such measures is demonstrated by
quantifying the effects of kernel approximation functions on different
representations of the Inorganic Crystal Structure Database. Broader
applicability of these methods is demonstrated in analysing learnt embedding of
the MNIST dataset. Random clusters are explored to examine the differences
between isotropy measures presented, and to see how each method scales with the
dimensionality. Python implementations of these measures are provided for use
by the community.",2023-05-25,2023,2023-05,chemistry
"What can Large Language Models do in chemistry? A comprehensive
  benchmark on eight tasks","Large Language Models (LLMs) with strong abilities in natural language
processing tasks have emerged and have been applied in various kinds of areas
such as science, finance and software engineering. However, the capability of
LLMs to advance the field of chemistry remains unclear. In this paper, rather
than pursuing state-of-the-art performance, we aim to evaluate capabilities of
LLMs in a wide range of tasks across the chemistry domain. We identify three
key chemistry-related capabilities including understanding, reasoning and
explaining to explore in LLMs and establish a benchmark containing eight
chemistry tasks. Our analysis draws on widely recognized datasets facilitating
a broad exploration of the capacities of LLMs within the context of practical
chemistry. Five LLMs (GPT-4, GPT-3.5, Davinci-003, Llama and Galactica) are
evaluated for each chemistry task in zero-shot and few-shot in-context learning
settings with carefully selected demonstration examples and specially crafted
prompts. Our investigation found that GPT-4 outperformed other models and LLMs
exhibit different competitive levels in eight chemistry tasks. In addition to
the key findings from the comprehensive benchmark analysis, our work provides
insights into the limitation of current LLMs and the impact of in-context
learning settings on LLMs' performance across various chemistry tasks. The code
and datasets used in this study are available at
https://github.com/ChemFoundationModels/ChemLLMBench.",2023-05-27,2023,2023-05,chemistry
"Catalysis distillation neural network for the few shot open catalyst
  challenge","The integration of artificial intelligence and science has resulted in
substantial progress in computational chemistry methods for the design and
discovery of novel catalysts. Nonetheless, the challenges of electrocatalytic
reactions and developing a large-scale language model in catalysis persist, and
the recent success of ChatGPT's (Chat Generative Pre-trained Transformer)
few-shot methods surpassing BERT (Bidirectional Encoder Representation from
Transformers) underscores the importance of addressing limited data, expensive
computations, time constraints and structure-activity relationship in research.
Hence, the development of few-shot techniques for catalysis is critical and
essential, regardless of present and future requirements. This paper introduces
the Few-Shot Open Catalyst Challenge 2023, a competition aimed at advancing the
application of machine learning technology for predicting catalytic reactions
on catalytic surfaces, with a specific focus on dual-atom catalysts in hydrogen
peroxide electrocatalysis. To address the challenge of limited data in
catalysis, we propose a machine learning approach based on MLP-Like and a
framework called Catalysis Distillation Graph Neural Network (CDGNN). Our
results demonstrate that CDGNN effectively learns embeddings from catalytic
structures, enabling the capture of structure-adsorption relationships. This
accomplishment has resulted in the utmost advanced and efficient determination
of the reaction pathway for hydrogen peroxide, surpassing the current graph
neural network approach by 16.1%.. Consequently, CDGNN presents a promising
approach for few-shot learning in catalysis.",2023-05-31,2023,2023-05,chemistry
chemSKI with tokens: world building and economy in the SKI universe,"chemSKI with tokens is a confluent graph rewrite system where all rewrites
are local, which moreover can be used to do SKI calculus reductions. The graph
rewrites of chemSKI are made conservative by the use of tokens. We thus achieve
several goals: conservative rewrites in a chemical style, a solution to the
problem of new edge names in a distributed, decentralized graphical reduction
and a new estimation of the cost of a combinatory calculus computation. This
formalism can be used either as an artificial chemistry or as a model of a
virtual decentralized machine which performs only local reductions. A programs
repository and the same article with simulations are available at github at
https://mbuliga.github.io/chemski/chemski-with-tokens.html",2023-06-01,2023,2023-06,chemistry
CIN++: Enhancing Topological Message Passing,"Graph Neural Networks (GNNs) have demonstrated remarkable success in learning
from graph-structured data. However, they face significant limitations in
expressive power, struggling with long-range interactions and lacking a
principled approach to modeling higher-order structures and group interactions.
Cellular Isomorphism Networks (CINs) recently addressed most of these
challenges with a message passing scheme based on cell complexes. Despite their
advantages, CINs make use only of boundary and upper messages which do not
consider a direct interaction between the rings present in the underlying
complex. Accounting for these interactions might be crucial for learning
representations of many real-world complex phenomena such as the dynamics of
supramolecular assemblies, neural activity within the brain, and gene
regulation processes. In this work, we propose CIN++, an enhancement of the
topological message passing scheme introduced in CINs. Our message passing
scheme accounts for the aforementioned limitations by letting the cells to
receive also lower messages within each layer. By providing a more
comprehensive representation of higher-order and long-range interactions, our
enhanced topological message passing scheme achieves state-of-the-art results
on large-scale and long-range chemistry benchmarks.",2023-06-06,2023,2023-06,chemistry
"A generative artificial intelligence framework based on a molecular
  diffusion model for the design of metal-organic frameworks for carbon capture","Metal-organic frameworks (MOFs) exhibit great promise for CO2 capture.
However, finding the best performing materials poses computational and
experimental grand challenges in view of the vast chemical space of potential
building blocks. Here, we introduce GHP-MOFassemble, a generative artificial
intelligence (AI), high performance framework for the rational and accelerated
design of MOFs with high CO2 adsorption capacity and synthesizable linkers.
GHP-MOFassemble generates novel linkers, assembled with one of three
pre-selected metal nodes (Cu paddlewheel, Zn paddlewheel, Zn tetramer) into
MOFs in a primitive cubic topology. GHP-MOFassemble screens and validates
AI-generated MOFs for uniqueness, synthesizability, structural validity, uses
molecular dynamics simulations to study their stability and chemical
consistency, and crystal graph neural networks and Grand Canonical Monte Carlo
simulations to quantify their CO2 adsorption capacities. We present the top six
AI-generated MOFs with CO2 capacities greater than 2 $m mol/g$, i.e., higher
than 96.9% of structures in the hypothetical MOF dataset.",2023-06-14,2023,2023-06,chemistry
"Symmetry-Informed Geometric Representation for Molecules, Proteins, and
  Crystalline Materials","Artificial intelligence for scientific discovery has recently generated
significant interest within the machine learning and scientific communities,
particularly in the domains of chemistry, biology, and material discovery. For
these scientific problems, molecules serve as the fundamental building blocks,
and machine learning has emerged as a highly effective and powerful tool for
modeling their geometric structures. Nevertheless, due to the rapidly evolving
process of the field and the knowledge gap between science (e.g., physics,
chemistry, & biology) and machine learning communities, a benchmarking study on
geometrical representation for such data has not been conducted. To address
such an issue, in this paper, we first provide a unified view of the current
symmetry-informed geometric methods, classifying them into three main
categories: invariance, equivariance with spherical frame basis, and
equivariance with vector frame basis. Then we propose a platform, coined
Geom3D, which enables benchmarking the effectiveness of geometric strategies.
Geom3D contains 16 advanced symmetry-informed geometric representation models
and 14 geometric pretraining methods over 46 diverse datasets, including small
molecules, proteins, and crystalline materials. We hope that Geom3D can, on the
one hand, eliminate barriers for machine learning researchers interested in
exploring scientific problems; and, on the other hand, provide valuable
guidance for researchers in computational chemistry, structural biology, and
materials science, aiding in the informed selection of representation
techniques for specific applications.",2023-06-15,2023,2023-06,chemistry
QH9: A Quantum Hamiltonian Prediction Benchmark for QM9 Molecules,"Supervised machine learning approaches have been increasingly used in
accelerating electronic structure prediction as surrogates of first-principle
computational methods, such as density functional theory (DFT). While numerous
quantum chemistry datasets focus on chemical properties and atomic forces, the
ability to achieve accurate and efficient prediction of the Hamiltonian matrix
is highly desired, as it is the most important and fundamental physical
quantity that determines the quantum states of physical systems and chemical
properties. In this work, we generate a new Quantum Hamiltonian dataset, named
as QH9, to provide precise Hamiltonian matrices for 999 or 2998 molecular
dynamics trajectories and 130,831 stable molecular geometries, based on the QM9
dataset. By designing benchmark tasks with various molecules, we show that
current machine learning models have the capacity to predict Hamiltonian
matrices for arbitrary molecules. Both the QH9 dataset and the baseline models
are provided to the community through an open-source benchmark, which can be
highly valuable for developing machine learning methods and accelerating
molecular and materials design for scientific and technological applications.
Our benchmark is publicly available at
https://github.com/divelab/AIRS/tree/main/OpenDFT/QHBench.",2023-06-15,2023,2023-06,chemistry
On the Interplay of Subset Selection and Informed Graph Neural Networks,"Machine learning techniques paired with the availability of massive datasets
dramatically enhance our ability to explore the chemical compound space by
providing fast and accurate predictions of molecular properties. However,
learning on large datasets is strongly limited by the availability of
computational resources and can be infeasible in some scenarios. Moreover, the
instances in the datasets may not yet be labelled and generating the labels can
be costly, as in the case of quantum chemistry computations. Thus, there is a
need to select small training subsets from large pools of unlabelled data
points and to develop reliable ML methods that can effectively learn from small
training sets. This work focuses on predicting the molecules atomization energy
in the QM9 dataset. We investigate the advantages of employing domain
knowledge-based data sampling methods for an efficient training set selection
combined with informed ML techniques. In particular, we show how maximizing
molecular diversity in the training set selection process increases the
robustness of linear and nonlinear regression techniques such as kernel methods
and graph neural networks. We also check the reliability of the predictions
made by the graph neural network with a model-agnostic explainer based on the
rate distortion explanation framework.",2023-06-15,2023,2023-06,chemistry
"Matrix Diagonalization as a Board Game: Teaching an Eigensolver the
  Fastest Path to Solution","Matrix diagonalization is at the cornerstone of numerous fields of scientific
computing. Diagonalizing a matrix to solve an eigenvalue problem requires a
sequential path of iterations that eventually reaches a sufficiently converged
and accurate solution for all the eigenvalues and eigenvectors. This typically
translates into a high computational cost. Here we demonstrate how
reinforcement learning, using the AlphaZero framework, can accelerate Jacobi
matrix diagonalizations by viewing the selection of the fastest path to
solution as a board game. To demonstrate the viability of our approach we apply
the Jacobi diagonalization algorithm to symmetric Hamiltonian matrices that
appear in quantum chemistry calculations. We find that a significant
acceleration can often be achieved. Our findings highlight the opportunity to
use machine learning as a promising tool to improve the performance of
numerical linear algebra.",2023-06-16,2023,2023-06,chemistry
A GPT-4 Reticular Chemist for Guiding MOF Discovery,"We present a new framework integrating the AI model GPT-4 into the iterative
process of reticular chemistry experimentation, leveraging a cooperative
workflow of interaction between AI and a human researcher. This GPT-4 Reticular
Chemist is an integrated system composed of three phases. Each of these
utilizes GPT-4 in various capacities, wherein GPT-4 provides detailed
instructions for chemical experimentation and the human provides feedback on
the experimental outcomes, including both success and failures, for the
in-context learning of AI in the next iteration. This iterative human-AI
interaction enabled GPT-4 to learn from the outcomes, much like an experienced
chemist, by a prompt-learning strategy. Importantly, the system is based on
natural language for both development and operation, eliminating the need for
coding skills, and thus, make it accessible to all chemists. Our collaboration
with GPT-4 Reticular Chemist guided the discovery of an isoreticular series of
MOFs, with each synthesis fine-tuned through iterative feedback and expert
suggestions. This workflow presents a potential for broader applications in
scientific research by harnessing the capability of large language models like
GPT-4 to enhance the feasibility and efficiency of research activities.",2023-06-20,2023,2023-06,chemistry
"NNQS-Transformer: an Efficient and Scalable Neural Network Quantum
  States Approach for Ab initio Quantum Chemistry","Neural network quantum state (NNQS) has emerged as a promising candidate for
quantum many-body problems, but its practical applications are often hindered
by the high cost of sampling and local energy calculation. We develop a
high-performance NNQS method for \textit{ab initio} electronic structure
calculations. The major innovations include: (1) A transformer based
architecture as the quantum wave function ansatz; (2) A data-centric
parallelization scheme for the variational Monte Carlo (VMC) algorithm which
preserves data locality and well adapts for different computing architectures;
(3) A parallel batch sampling strategy which reduces the sampling cost and
achieves good load balance; (4) A parallel local energy evaluation scheme which
is both memory and computationally efficient; (5) Study of real chemical
systems demonstrates both the superior accuracy of our method compared to
state-of-the-art and the strong and weak scalability for large molecular
systems with up to $120$ spin orbitals.",2023-06-29,2023,2023-06,chemistry
Artificial Intelligence for Drug Discovery: Are We There Yet?,"Drug discovery is adapting to novel technologies such as data science,
informatics, and artificial intelligence (AI) to accelerate effective treatment
development while reducing costs and animal experiments. AI is transforming
drug discovery, as indicated by increasing interest from investors, industrial
and academic scientists, and legislators. Successful drug discovery requires
optimizing properties related to pharmacodynamics, pharmacokinetics, and
clinical outcomes. This review discusses the use of AI in the three pillars of
drug discovery: diseases, targets, and therapeutic modalities, with a focus on
small molecule drugs. AI technologies, such as generative chemistry, machine
learning, and multi-property optimization, have enabled several compounds to
enter clinical trials. The scientific community must carefully vet known
information to address the reproducibility crisis. The full potential of AI in
drug discovery can only be realized with sufficient ground truth and
appropriate human intervention at later pipeline stages.",2023-07-13,2023,2023-07,chemistry
"SciBench: Evaluating College-Level Scientific Problem-Solving Abilities
  of Large Language Models","Most of the existing Large Language Model (LLM) benchmarks on scientific
problem reasoning focus on problems grounded in high-school subjects and are
confined to elementary algebraic operations. To systematically examine the
reasoning capabilities required for solving complex scientific problems, we
introduce an expansive benchmark suite SciBench for LLMs. SciBench contains a
carefully curated dataset featuring a range of collegiate-level scientific
problems from mathematics, chemistry, and physics domains. Based on the
dataset, we conduct an in-depth benchmarking study of representative
open-source and proprietary LLMs with various prompting strategies. The results
reveal that the current LLMs fall short of delivering satisfactory performance,
with the best overall score of merely 43.22%. Furthermore, through a detailed
user study, we categorize the errors made by LLMs into ten problem-solving
abilities. Our analysis indicates that no single prompting strategy
significantly outperforms the others and some strategies that demonstrate
improvements in certain problem-solving skills could result in declines in
other skills. We envision that SciBench will catalyze further developments in
the reasoning abilities of LLMs, thereby ultimately contributing to scientific
research and discovery.",2023-07-20,2023,2023-07,chemistry
"Rotation-Invariant Random Features Provide a Strong Baseline for Machine
  Learning on 3D Point Clouds","Rotational invariance is a popular inductive bias used by many fields in
machine learning, such as computer vision and machine learning for quantum
chemistry. Rotation-invariant machine learning methods set the state of the art
for many tasks, including molecular property prediction and 3D shape
classification. These methods generally either rely on task-specific
rotation-invariant features, or they use general-purpose deep neural networks
which are complicated to design and train. However, it is unclear whether the
success of these methods is primarily due to the rotation invariance or the
deep neural networks. To address this question, we suggest a simple and
general-purpose method for learning rotation-invariant functions of
three-dimensional point cloud data using a random features approach.
Specifically, we extend the random features method of Rahimi & Recht 2007 by
deriving a version that is invariant to three-dimensional rotations and showing
that it is fast to evaluate on point cloud data. We show through experiments
that our method matches or outperforms the performance of general-purpose
rotation-invariant neural networks on standard molecular property prediction
benchmark datasets QM7 and QM9. We also show that our method is general-purpose
and provides a rotation-invariant baseline on the ModelNet40 shape
classification task. Finally, we show that our method has an order of magnitude
smaller prediction latency than competing kernel methods.",2023-07-27,2023,2023-07,chemistry
"Ultrafast Radiographic Imaging and Tracking: An overview of instruments,
  methods, data, and applications","Ultrafast radiographic imaging and tracking (U-RadIT) use state-of-the-art
ionizing particle and light sources to experimentally study sub-nanosecond
dynamic processes in physics, chemistry, biology, geology, materials science
and other fields. These processes, fundamental to nuclear fusion energy,
advanced manufacturing, green transportation and others, often involve one mole
or more atoms, and thus are challenging to compute by using the first
principles of quantum physics or other forward models. One of the central
problems in U-RadIT is to optimize information yield through, e.g.
high-luminosity X-ray and particle sources, efficient imaging and tracking
detectors, novel methods to collect data, and large-bandwidth online and
offline data processing, regulated by the underlying physics, statistics, and
computing power. We review and highlight recent progress in: a.) Detectors; b.)
U-RadIT modalities; c.) Data and algorithms; and d.) Applications.
Hardware-centric approaches to U-RadIT optimization are constrained by detector
material properties, low signal-to-noise ratio, high cost and long development
cycles of critical hardware components such as ASICs. Interpretation of
experimental data, including comparisons with forward models, is frequently
hindered by sparse measurements, model and measurement uncertainties, and
noise. Alternatively, U-RadIT make increasing use of data science and machine
learning algorithms, including experimental implementations of compressed
sensing. Machine learning and artificial intelligence approaches, refined by
physics and materials information, may also contribute significantly to data
interpretation, uncertainty quantification, and U-RadIT optimization.",2023-08-21,2023,2023-08,chemistry
Beyond MD17: the reactive xxMD dataset,"System specific neural force fields (NFFs) have gained popularity in
computational chemistry. One of the most popular datasets as a bencharmk to
develop NFFs models is the MD17 dataset and its subsequent extension. These
datasets comprise geometries from the equilibrium region of the ground
electronic state potential energy surface, sampled from direct adiabatic
dynamics. However, many chemical reactions involve significant molecular
geometrical deformations, for example, bond breaking. Therefore, MD17 is
inadequate to represent a chemical reaction. To address this limitation in
MD17, we introduce a new dataset, called Extended Excited-state Molecular
Dynamics (xxMD) dataset. The xxMD dataset involves geometries sampled from
direct non-adiabatic dynamics, and the energies are computed at both
multireference wavefunction theory and density functional theory. We show that
the xxMD dataset involves diverse geometries which represent chemical
reactions. Assessment of NFF models on xxMD dataset reveals significantly
higher predictive errors than those reported for MD17 and its variants. This
work underscores the challenges faced in crafting a generalizable NFF model
with extrapolation capability.",2023-08-22,2023,2023-08,chemistry
DARWIN Series: Domain Specific Large Language Models for Natural Science,"Emerging tools bring forth fresh approaches to work, and the field of natural
science is no different. In natural science, traditional manual, serial, and
labour-intensive work is being augmented by automated, parallel, and iterative
processes driven by artificial intelligence-based experimental automation and
more. To add new capabilities in natural science, enabling the acceleration and
enrichment of automation of the discovery process, we present DARWIN, a series
of tailored LLMs for natural science, mainly in physics, chemistry, and
material science. This series relies on open-source LLM, incorporating
structured and unstructured scientific knowledge from public datasets and
literature. We fine-tuned the models using over 60,000 instruction data points,
emphasizing factual correctness. During the fine-tuning, we introduce the
Scientific Instruction Generation (SIG) model, automating instruction
generation from scientific texts. This eliminates the need for manual
extraction or domain-specific knowledge graphs and efficiently injects
scientific knowledge into the model. We also explore multi-task training
strategies, revealing interconnections between scientific tasks. DARWIN series
not only achieves state-of-the-art results on various scientific tasks but also
diminishes reliance on closed-source AI models. Our research showcases the
ability of LLM in the scientific domain, with the overarching goal of fostering
prosperity within the broader AI for science community.",2023-08-25,2023,2023-08,chemistry
"Enabling Inverse Design in Chemical Compound Space: Mapping Quantum
  Properties to Structures for Small Organic Molecules","Computer-driven molecular design combines the principles of chemistry,
physics, and artificial intelligence to identify novel chemical compounds and
materials with desired properties for a specific application. In particular,
quantum-mechanical (QM) methods combined with machine learning (ML) techniques
have accelerated the estimation of accurate molecular properties, providing a
direct mapping from 3D molecular structures to their properties. However, the
development of reliable and efficient methodologies to enable \emph{inverse
mapping} in chemical space is a long-standing challenge that has not been
accomplished yet. Here, we address this challenge by demonstrating the
possibility of parametrizing a given chemical space with a finite set of
extensive and intensive QM properties. In doing so, we develop a
proof-of-concept implementation that combines a Variational Auto-Encoder (VAE)
trained on molecular structures with a property encoder designed to learn the
latent representation from a set of QM properties. The result of this joint
architecture is a common latent space representation for both structures and
properties, which enables property-to-structure mapping for small drug-like
molecules contained in the QM7-X dataset. We illustrate the capabilities of our
approach by conditional generation of \emph{de novo} molecular structures with
targeted properties, transition path interpolation for chemical reactions as
well as insights into property-structure relationships. Our findings thus
provide a proof-of-principle demonstration aiming to enable the inverse
property-to-structure design in diverse chemical spaces.",2023-09-01,2023,2023-09,chemistry
"Gramian Angular Fields for leveraging pretrained computer vision models
  with anomalous diffusion trajectories","Anomalous diffusion is present at all scales, from atomic to large scales.
Some exemplary systems are; ultra-cold atoms, telomeres in the nucleus of
cells, moisture transport in cement-based materials, the free movement of
arthropods, and the migration patterns of birds. The characterization of the
diffusion gives critical information about the dynamics of these systems and
provides an interdisciplinary framework with which to study diffusive
transport. Thus, the problem of identifying underlying diffusive regimes and
inferring the anomalous diffusion exponent {$\alpha$} with high confidence is
critical to physics, chemistry, biology, and ecology. Classification and
analysis of raw trajectories combining machine learning techniques with
statistics extracted from them have widely been studied in the Anomalous
Diffusion Challenge ge (Munoz-Gil et al., 2021). Here we present a new
data-driven method for working with diffusive trajectories. This method
utilizes Gramian Angular Fields (GAF) to encode one-dimensional trajectories as
images (Gramian Matrices), while preserving their spatiotemporal structure for
input to computer-vision models. This allows us to leverage two
well-established pre-trained computer-vision models, ResNet and MobileNet, to
characterize the underlying diffusive regime, and infer the anomalous diffusion
exponent {$\alpha$}. Short raw trajectories, of lengths between 10 and 50, are
commonly encountered in single-particle tracking experiments and are the most
difficult to characterize. We show that by using GAF images, we can outperform
the current state-of-the-art while increasing accessibility to machine learning
methods in an applied setting.",2023-09-02,2023,2023-09,chemistry
"Insights Into the Inner Workings of Transformer Models for Protein
  Function Prediction","Motivation: We explored how explainable artificial intelligence (XAI) can
help to shed light into the inner workings of neural networks for protein
function prediction, by extending the widely used XAI method of integrated
gradients such that latent representations inside of transformer models, which
were finetuned to Gene Ontology term and Enzyme Commission number prediction,
can be inspected too. Results: The approach enabled us to identify amino acids
in the sequences that the transformers pay particular attention to, and to show
that these relevant sequence parts reflect expectations from biology and
chemistry, both in the embedding layer and inside of the model, where we
identified transformer heads with a statistically significant correspondence of
attribution maps with ground truth sequence annotations (e.g. transmembrane
regions, active sites) across many proteins. Availability and Implementation:
Source code can be accessed at https://github.com/markuswenzel/xai-proteins .",2023-09-07,2023,2023-09,chemistry
"CloudBrain-NMR: An Intelligent Cloud Computing Platform for NMR
  Spectroscopy Processing, Reconstruction and Analysis","Nuclear Magnetic Resonance (NMR) spectroscopy has served as a powerful
analytical tool for studying molecular structure and dynamics in chemistry and
biology. However, the processing of raw data acquired from NMR spectrometers
and subsequent quantitative analysis involves various specialized tools, which
necessitates comprehensive knowledge in programming and NMR. Particularly, the
emerging deep learning tools is hard to be widely used in NMR due to the
sophisticated setup of computation. Thus, NMR processing is not an easy task
for chemist and biologists. In this work, we present CloudBrain-NMR, an
intelligent online cloud computing platform designed for NMR data reading,
processing, reconstruction, and quantitative analysis. The platform is
conveniently accessed through a web browser, eliminating the need for any
program installation on the user side. CloudBrain-NMR uses parallel computing
with graphics processing units and central processing units, resulting in
significantly shortened computation time. Furthermore, it incorporates
state-of-the-art deep learning-based algorithms offering comprehensive
functionalities that allow users to complete the entire processing procedure
without relying on additional software. This platform has empowered NMR
applications with advanced artificial intelligence processing. CloudBrain-NMR
is openly accessible for free usage at https://csrc.xmu.edu.cn/CloudBrain.html",2023-09-12,2023,2023-09,chemistry
Molecular Conformation Generation via Shifting Scores,"Molecular conformation generation, a critical aspect of computational
chemistry, involves producing the three-dimensional conformer geometry for a
given molecule. Generating molecular conformation via diffusion requires
learning to reverse a noising process. Diffusion on inter-atomic distances
instead of conformation preserves SE(3)-equivalence and shows superior
performance compared to alternative techniques, whereas related generative
modelings are predominantly based upon heuristical assumptions. In response to
this, we propose a novel molecular conformation generation approach driven by
the observation that the disintegration of a molecule can be viewed as casting
increasing force fields to its composing atoms, such that the distribution of
the change of inter-atomic distance shifts from Gaussian to Maxwell-Boltzmann
distribution. The corresponding generative modeling ensures a feasible
inter-atomic distance geometry and exhibits time reversibility. Experimental
results on molecular datasets demonstrate the advantages of the proposed
shifting distribution compared to the state-of-the-art.",2023-09-12,2023,2023-09,chemistry
"GPT-Lab: Next Generation Of Optimal Chemistry Discovery By GPT Driven
  Robotic Lab","The integration of robots in chemical experiments has enhanced experimental
efficiency, but lacking the human intelligence to comprehend literature, they
seldom provide assistance in experimental design. Therefore, achieving
full-process autonomy from experiment design to validation in self-driven
laboratories (SDL) remains a challenge. The introduction of Generative
Pre-trained Transformers (GPT), particularly GPT-4, into robotic
experimentation offers a solution. We introduce GPT-Lab, a paradigm that
employs GPT models to give robots human-like intelligence. With our robotic
experimentation platform, GPT-Lab mines literature for materials and methods
and validates findings through high-throughput synthesis. As a demonstration,
GPT-Lab analyzed 500 articles, identified 18 potential reagents, and
successfully produced an accurate humidity colorimetric sensor with a root mean
square error (RMSE) of 2.68%. This showcases the rapid materials discovery and
validation potential of our system.",2023-09-15,2023,2023-09,chemistry
"Machine Learning Data Suitability and Performance Testing Using Fault
  Injection Testing Framework","Creating resilient machine learning (ML) systems has become necessary to
ensure production-ready ML systems that acquire user confidence seamlessly. The
quality of the input data and the model highly influence the successful
end-to-end testing in data-sensitive systems. However, the testing approaches
of input data are not as systematic and are few compared to model testing. To
address this gap, this paper presents the Fault Injection for Undesirable
Learning in input Data (FIUL-Data) testing framework that tests the resilience
of ML models to multiple intentionally-triggered data faults. Data mutators
explore vulnerabilities of ML systems against the effects of different fault
injections. The proposed framework is designed based on three main ideas: The
mutators are not random; one data mutator is applied at an instance of time,
and the selected ML models are optimized beforehand. This paper evaluates the
FIUL-Data framework using data from analytical chemistry, comprising retention
time measurements of anti-sense oligonucleotide. Empirical evaluation is
carried out in a two-step process in which the responses of selected ML models
to data mutation are analyzed individually and then compared with each other.
The results show that the FIUL-Data framework allows the evaluation of the
resilience of ML models. In most experiments cases, ML models show higher
resilience at larger training datasets, where gradient boost performed better
than support vector regression in smaller training sets. Overall, the mean
squared error metric is useful in evaluating the resilience of models due to
its higher sensitivity to data mutation.",2023-09-20,2023,2023-09,chemistry
"Morphological Computing as Logic Underlying Cognition in Human, Animal,
  and Intelligent Machine","This work examines the interconnections between logic, epistemology, and
sciences within the Naturalist tradition. It presents a scheme that connects
logic, mathematics, physics, chemistry, biology, and cognition, emphasizing
scale-invariant, self-organizing dynamics across organizational tiers of
nature. The inherent logic of agency exists in natural processes at various
levels, under information exchanges. It applies to humans, animals, and
artifactual agents. The common human-centric, natural language-based logic is
an example of complex logic evolved by living organisms that already appears in
the simplest form at the level of basal cognition of unicellular organisms.
Thus, cognitive logic stems from the evolution of physical, chemical, and
biological logic. In a computing nature framework with a self-organizing
agency, innovative computational frameworks grounded in
morphological/physical/natural computation can be used to explain the genesis
of human-centered logic through the steps of naturalized logical processes at
lower levels of organization. The Extended Evolutionary Synthesis of living
agents is essential for understanding the emergence of human-level logic and
the relationship between logic and information processing/computational
epistemology. We conclude that more research is needed to elucidate the details
of the mechanisms linking natural phenomena with the logic of agency in nature.",2023-09-25,2023,2023-09,chemistry
"C3Net: interatomic potential neural network for prediction of
  physicochemical properties in heterogenous systems","Understanding the interactions of a solute with its environment is of
fundamental importance in chemistry and biology. In this work, we propose a
deep neural network architecture for atom type embeddings in its molecular
context and interatomic potential that follows fundamental physical laws. The
architecture is applied to predict physicochemical properties in heterogeneous
systems including solvation in diverse solvents, 1-octanol-water partitioning,
and PAMPA with a single set of network weights. We show that our architecture
is generalized well to the physicochemical properties and outperforms
state-of-the-art approaches based on quantum mechanics and neural networks in
the task of solvation free energy prediction. The interatomic potentials at
each atom in a solute obtained from the model allow quantitative analysis of
the physicochemical properties at atomic resolution consistent with chemical
and physical reasoning. The software is available at
https://github.com/SehanLee/C3Net.",2023-09-27,2023,2023-09,chemistry
Language models in molecular discovery,"The success of language models, especially transformer-based architectures,
has trickled into other domains giving rise to ""scientific language models""
that operate on small molecules, proteins or polymers. In chemistry, language
models contribute to accelerating the molecule discovery cycle as evidenced by
promising recent findings in early-stage drug discovery. Here, we review the
role of language models in molecular discovery, underlining their strength in
de novo drug design, property prediction and reaction chemistry. We highlight
valuable open-source software assets thus lowering the entry barrier to the
field of scientific language modeling. Last, we sketch a vision for future
molecular design that combines a chatbot interface with access to computational
chemistry tools. Our contribution serves as a valuable resource for
researchers, chemists, and AI enthusiasts interested in understanding how
language models can and will be used to accelerate chemical discovery.",2023-09-28,2023,2023-09,chemistry
Neural scaling laws for phenotypic drug discovery,"Recent breakthroughs by deep neural networks (DNNs) in natural language
processing (NLP) and computer vision have been driven by a scale-up of models
and data rather than the discovery of novel computing paradigms. Here, we
investigate if scale can have a similar impact for models designed to aid small
molecule drug discovery. We address this question through a large-scale and
systematic analysis of how DNN size, data diet, and learning routines interact
to impact accuracy on our Phenotypic Chemistry Arena (Pheno-CA) benchmark: a
diverse set of drug development tasks posed on image-based high content
screening data. Surprisingly, we find that DNNs explicitly supervised to solve
tasks in the Pheno-CA do not continuously improve as their data and model size
is scaled-up. To address this issue, we introduce a novel precursor task, the
Inverse Biological Process (IBP), which is designed to resemble the causal
objective functions that have proven successful for NLP. We indeed find that
DNNs first trained with IBP then probed for performance on the Pheno-CA
significantly outperform task-supervised DNNs. More importantly, the
performance of these IBP-trained DNNs monotonically improves with data and
model scale. Our findings reveal that the DNN ingredients needed to accurately
solve small molecule drug development tasks are already in our hands, and
project how much more experimental data is needed to achieve any desired level
of improvement. We release our Pheno-CA benchmark and code to encourage further
study of neural scaling laws for small molecule drug discovery.",2023-09-28,2023,2023-09,chemistry
"Knowledge Graphs for the Life Sciences: Recent Developments, Challenges
  and Opportunities","The term life sciences refers to the disciplines that study living organisms
and life processes, and include chemistry, biology, medicine, and a range of
other related disciplines. Research efforts in life sciences are heavily
data-driven, as they produce and consume vast amounts of scientific data, much
of which is intrinsically relational and graph-structured.
  The volume of data and the complexity of scientific concepts and relations
referred to therein promote the application of advanced knowledge-driven
technologies for managing and interpreting data, with the ultimate aim to
advance scientific discovery.
  In this survey and position paper, we discuss recent developments and
advances in the use of graph-based technologies in life sciences and set out a
vision for how these technologies will impact these fields into the future. We
focus on three broad topics: the construction and management of Knowledge
Graphs (KGs), the use of KGs and associated technologies in the discovery of
new knowledge, and the use of KGs in artificial intelligence applications to
support explanations (explainable AI). We select a few exemplary use cases for
each topic, discuss the challenges and open research questions within these
topics, and conclude with a perspective and outlook that summarizes the
overarching challenges and their potential solutions as a guide for future
research.",2023-09-29,2023,2023-09,chemistry
"UPAR: A Kantian-Inspired Prompting Framework for Enhancing Large
  Language Model Capabilities","Large Language Models (LLMs) have demonstrated impressive inferential
capabilities, with numerous research endeavors devoted to enhancing this
capacity through prompting. Despite these efforts, a unified epistemological
foundation is still conspicuously absent. Drawing inspiration from Kant's a
priori philosophy, we propose the UPAR prompting framework, designed to emulate
the structure of human cognition within LLMs. The UPAR framework is delineated
into four phases: ""Understand"", ""Plan"", ""Act"", and ""Reflect"", enabling the
extraction of structured information from complex contexts, prior planning of
solutions, execution according to plan, and self-reflection. This structure
significantly augments the explainability and accuracy of LLM inference,
producing a human-understandable and inspectable inferential trajectory.
Furthermore, our work offers an epistemological foundation for existing
prompting techniques, allowing for a possible systematic integration of these
methods. With GPT-4, our approach elevates the accuracy from COT baseline of
22.92% to 58.33% in a challenging subset of GSM8K, and from 67.91% to 75.40% in
the causal judgment task. Without using few-shot examples or external tools,
UPAR significantly outperforms existing prompting methods on SCIBENCH, a
challenging dataset containing collegiate-level mathematics, chemistry, and
physics scientific problems.",2023-09-30,2023,2023-09,chemistry
On Training Derivative-Constrained Neural Networks,"We refer to the setting where the (partial) derivatives of a neural network's
(NN's) predictions with respect to its inputs are used as additional training
signal as a derivative-constrained (DC) NN. This situation is common in
physics-informed settings in the natural sciences. We propose an integrated
RELU (IReLU) activation function to improve training of DC NNs. We also
investigate denormalization and label rescaling to help stabilize DC training.
We evaluate our methods on physics-informed settings including quantum
chemistry and Scientific Machine Learning (SciML) tasks. We demonstrate that
existing architectures with IReLU activations combined with denormalization and
label rescaling better incorporate training signal provided by derivative
constraints.",2023-10-02,2023,2023-10,chemistry
MapperGPT: Large Language Models for Linking and Mapping Entities,"Aligning terminological resources, including ontologies, controlled
vocabularies, taxonomies, and value sets is a critical part of data integration
in many domains such as healthcare, chemistry, and biomedical research. Entity
mapping is the process of determining correspondences between entities across
these resources, such as gene identifiers, disease concepts, or chemical entity
identifiers. Many tools have been developed to compute such mappings based on
common structural features and lexical information such as labels and synonyms.
Lexical approaches in particular often provide very high recall, but low
precision, due to lexical ambiguity. As a consequence of this, mapping efforts
often resort to a labor intensive manual mapping refinement through a human
curator.
  Large Language Models (LLMs), such as the ones employed by ChatGPT, have
generalizable abilities to perform a wide range of tasks, including
question-answering and information extraction. Here we present MapperGPT, an
approach that uses LLMs to review and refine mapping relationships as a
post-processing step, in concert with existing high-recall methods that are
based on lexical and structural heuristics.
  We evaluated MapperGPT on a series of alignment tasks from different domains,
including anatomy, developmental biology, and renal diseases. We devised a
collection of tasks that are designed to be particularly challenging for
lexical methods. We show that when used in combination with high-recall
methods, MapperGPT can provide a substantial improvement in accuracy, beating
state-of-the-art (SOTA) methods such as LogMap.",2023-10-05,2023,2023-10,chemistry
Evolutionary Retrosynthetic Route Planning,"Molecular retrosynthesis is a significant and complex problem in the field of
chemistry, however, traditional manual synthesis methods not only need
well-trained experts but also are time-consuming. With the development of big
data and machine learning, artificial intelligence (AI) based retrosynthesis is
attracting more attention and has become a valuable tool for molecular
retrosynthesis. At present, Monte Carlo tree search is a mainstream search
framework employed to address this problem. Nevertheless, its search efficiency
is compromised by its large search space. Therefore, this paper proposes a
novel approach for retrosynthetic route planning based on evolutionary
optimization, marking the first use of Evolutionary Algorithm (EA) in the field
of multi-step retrosynthesis. The proposed method involves modeling the
retrosynthetic problem into an optimization problem, defining the search space
and operators. Additionally, to improve the search efficiency, a parallel
strategy is implemented. The new approach is applied to four case products and
compared with Monte Carlo tree search. The experimental results show that, in
comparison to the Monte Carlo tree search algorithm, EA significantly reduces
the number of calling single-step model by an average of 53.9%. The time
required to search three solutions decreases by an average of 83.9%, and the
number of feasible search routes increases by 1.38 times. The source code is
available at https://github.com/ilog-ecnu/EvoRRP.",2023-10-08,2023,2023-10,chemistry
"Take a Step Back: Evoking Reasoning via Abstraction in Large Language
  Models","We present Step-Back Prompting, a simple prompting technique that enables
LLMs to do abstractions to derive high-level concepts and first principles from
instances containing specific details. Using the concepts and principles to
guide reasoning, LLMs significantly improve their abilities in following a
correct reasoning path towards the solution. We conduct experiments of
Step-Back Prompting with PaLM-2L, GPT-4 and Llama2-70B models, and observe
substantial performance gains on various challenging reasoning-intensive tasks
including STEM, Knowledge QA, and Multi-Hop Reasoning. For instance, Step-Back
Prompting improves PaLM-2L performance on MMLU (Physics and Chemistry) by 7%
and 11% respectively, TimeQA by 27%, and MuSiQue by 7%.",2023-10-09,2023,2023-10,chemistry
"Cousins Of The Vendi Score: A Family Of Similarity-Based Diversity
  Metrics For Science And Machine Learning","Measuring diversity accurately is important for many scientific fields,
including machine learning (ML), ecology, and chemistry. The Vendi Score was
introduced as a generic similarity-based diversity metric that extends the Hill
number of order q=1 by leveraging ideas from quantum statistical mechanics.
Contrary to many diversity metrics in ecology, the Vendi Score accounts for
similarity and does not require knowledge of the prevalence of the categories
in the collection to be evaluated for diversity. However, the Vendi Score
treats each item in a given collection with a level of sensitivity proportional
to the item's prevalence. This is undesirable in settings where there is a
significant imbalance in item prevalence. In this paper, we extend the other
Hill numbers using similarity to provide flexibility in allocating sensitivity
to rare or common items. This leads to a family of diversity metrics -- Vendi
scores with different levels of sensitivity -- that can be used in a variety of
applications. We study the properties of the scores in a synthetic controlled
setting where the ground truth diversity is known. We then test their utility
in improving molecular simulations via Vendi Sampling. Finally, we use the
Vendi scores to better understand the behavior of image generative models in
terms of memorization, duplication, diversity, and sample quality.",2023-10-19,2023,2023-10,chemistry
"ReLM: Leveraging Language Models for Enhanced Chemical Reaction
  Prediction","Predicting chemical reactions, a fundamental challenge in chemistry, involves
forecasting the resulting products from a given reaction process. Conventional
techniques, notably those employing Graph Neural Networks (GNNs), are often
limited by insufficient training data and their inability to utilize textual
information, undermining their applicability in real-world applications. In
this work, we propose ReLM, a novel framework that leverages the chemical
knowledge encoded in language models (LMs) to assist GNNs, thereby enhancing
the accuracy of real-world chemical reaction predictions. To further enhance
the model's robustness and interpretability, we incorporate the confidence
score strategy, enabling the LMs to self-assess the reliability of their
predictions. Our experimental results demonstrate that ReLM improves the
performance of state-of-the-art GNN-based methods across various chemical
reaction datasets, especially in out-of-distribution settings. Codes are
available at https://github.com/syr-cn/ReLM.",2023-10-20,2023,2023-10,chemistry
"Monte Carlo Thought Search: Large Language Model Querying for Complex
  Scientific Reasoning in Catalyst Design","Discovering novel catalysts requires complex reasoning involving multiple
chemical properties and resultant trade-offs, leading to a combinatorial growth
in the search space. While large language models (LLM) have demonstrated novel
capabilities for chemistry through complex instruction following capabilities
and high quality reasoning, a goal-driven combinatorial search using LLMs has
not been explored in detail. In this work, we present a Monte Carlo Tree
Search-based approach that improves beyond state-of-the-art chain-of-thought
prompting variants to augment scientific reasoning. We introduce two new
reasoning datasets: 1) a curation of computational chemistry simulations, and
2) diverse questions written by catalysis researchers for reasoning about novel
chemical conversion processes. We improve over the best baseline by 25.8\% and
find that our approach can augment scientist's reasoning and discovery process
with novel insights.",2023-10-22,2023,2023-10,chemistry
Using Slisemap to interpret physical data,"Manifold visualisation techniques are commonly used to visualise
high-dimensional datasets in physical sciences. In this paper we apply a
recently introduced manifold visualisation method, called Slise, on datasets
from physics and chemistry. Slisemap combines manifold visualisation with
explainable artificial intelligence. Explainable artificial intelligence is
used to investigate the decision processes of black box machine learning models
and complex simulators. With Slisemap we find an embedding such that data items
with similar local explanations are grouped together. Hence, Slisemap gives us
an overview of the different behaviours of a black box model. This makes
Slisemap into a supervised manifold visualisation method, where the patterns in
the embedding reflect a target property. In this paper we show how Slisemap can
be used and evaluated on physical data and that Slisemap is helpful in finding
meaningful information on classification and regression models trained on these
datasets.",2023-10-24,2023,2023-10,chemistry
Re-evaluating Retrosynthesis Algorithms with Syntheseus,"Automated Synthesis Planning has recently re-emerged as a research area at
the intersection of chemistry and machine learning. Despite the appearance of
steady progress, we argue that imperfect benchmarks and inconsistent
comparisons mask systematic shortcomings of existing techniques, and
unnecessarily hamper progress. To remedy this, we present a synthesis planning
library with an extensive benchmarking framework, called syntheseus, which
promotes best practice by default, enabling consistent meaningful evaluation of
single-step models and multi-step planning algorithms. We demonstrate the
capabilities of syntheseus by re-evaluating several previous retrosynthesis
algorithms, and find that the ranking of state-of-the-art models changes in
controlled evaluation experiments. We end with guidance for future works in
this area, and call the community to engage in the discussion on how to improve
benchmarks for synthesis planning.",2023-10-30,2023,2023-10,chemistry
"MLatom 3: Platform for machine learning-enhanced computational chemistry
  simulations and workflows","Machine learning (ML) is increasingly becoming a common tool in computational
chemistry. At the same time, the rapid development of ML methods requires a
flexible software framework for designing custom workflows. MLatom 3 is a
program package designed to leverage the power of ML to enhance typical
computational chemistry simulations and to create complex workflows. This
open-source package provides plenty of choice to the users who can run
simulations with the command line options, input files, or with scripts using
MLatom as a Python package, both on their computers and on the online XACS
cloud computing at XACScloud.com. Computational chemists can calculate energies
and thermochemical properties, optimize geometries, run molecular and quantum
dynamics, and simulate (ro)vibrational, one-photon UV/vis absorption, and
two-photon absorption spectra with ML, quantum mechanical, and combined models.
The users can choose from an extensive library of methods containing
pre-trained ML models and quantum mechanical approximations such as AIQM1
approaching coupled-cluster accuracy. The developers can build their own models
using various ML algorithms. The great flexibility of MLatom is largely due to
the extensive use of the interfaces to many state-of-the-art software packages
and libraries.",2023-10-31,2023,2023-10,chemistry
"Extracting human interpretable structure-property relationships in
  chemistry using XAI and large language models","Explainable Artificial Intelligence (XAI) is an emerging field in AI that
aims to address the opaque nature of machine learning models. Furthermore, it
has been shown that XAI can be used to extract input-output relationships,
making them a useful tool in chemistry to understand structure-property
relationships. However, one of the main limitations of XAI methods is that they
are developed for technically oriented users. We propose the XpertAI framework
that integrates XAI methods with large language models (LLMs) accessing
scientific literature to generate accessible natural language explanations of
raw chemical data automatically. We conducted 5 case studies to evaluate the
performance of XpertAI. Our results show that XpertAI combines the strengths of
LLMs and XAI tools in generating specific, scientific, and interpretable
explanations.",2023-11-07,2023,2023-11,chemistry
"The Impact of Large Language Models on Scientific Discovery: a
  Preliminary Study using GPT-4","In recent years, groundbreaking advancements in natural language processing
have culminated in the emergence of powerful large language models (LLMs),
which have showcased remarkable capabilities across a vast array of domains,
including the understanding, generation, and translation of natural language,
and even tasks that extend beyond language processing. In this report, we delve
into the performance of LLMs within the context of scientific discovery,
focusing on GPT-4, the state-of-the-art language model. Our investigation spans
a diverse range of scientific areas encompassing drug discovery, biology,
computational chemistry (density functional theory (DFT) and molecular dynamics
(MD)), materials design, and partial differential equations (PDE). Evaluating
GPT-4 on scientific tasks is crucial for uncovering its potential across
various research domains, validating its domain-specific expertise,
accelerating scientific progress, optimizing resource allocation, guiding
future model development, and fostering interdisciplinary research. Our
exploration methodology primarily consists of expert-driven case assessments,
which offer qualitative insights into the model's comprehension of intricate
scientific concepts and relationships, and occasionally benchmark testing,
which quantitatively evaluates the model's capacity to solve well-defined
domain-specific problems. Our preliminary exploration indicates that GPT-4
exhibits promising potential for a variety of scientific applications,
demonstrating its aptitude for handling complex problem-solving and knowledge
integration tasks. Broadly speaking, we evaluate GPT-4's knowledge base,
scientific understanding, scientific numerical calculation abilities, and
various scientific prediction capabilities.",2023-11-13,2023,2023-11,chemistry
"A Proposed Artificial Neural Network based Approach for Molecules Bitter
  Prediction","In recent years, the development of Artificial Intelligence (AI) has offered
the possibility to tackle many interdisciplinary problems, and the field of
chemistry is not an exception. Drug analysis is crucial in drug discovery,
playing an important role in human life. However, this task encounters many
difficulties due to the wide range of computational chemistry methods. Drug
analysis also involves a massive amount of work, including determining taste.
Thus, applying deep learning to predict a molecule's bitterness is inevitable
to accelerate innovation in drug analysis by reducing the time spent. This
paper proposes an artificial neural network (ANN) based approach (EC-ANN) for
the molecule's bitter prediction. Our approach took the SMILE (Simplified
molecular-input line-entry system) string of a molecule as the input data for
the prediction, and the 256-bit ECFP descriptor is the input vector for our
network. It showed impressive results compared to state-of-the-art, with a
higher performance on two out of three test sets according to the experiences
on three popular test sets: Phyto-Dictionary, Unimi, and Bitter-new set [1].
For the Phyto-Dictionary test set, our model recorded 0.95 and 0.983 in
F1-score and AUPR, respectively, depicted as the highest score in F1-score. For
the Unimi test set, our model achieved 0.88 in F1-score and 0.88 in AUPR, which
is roughly 12.3% higher than the peak of previous models [1, 2, 3, 4, 5].",2023-11-15,2023,2023-11,chemistry
Structured Chemistry Reasoning with Large Language Models,"Large Language Models (LLMs) excel in diverse areas, yet struggle with
complex scientific reasoning, especially in the field of chemistry. Different
from the simple chemistry tasks (e.g., molecule classification) addressed in
previous studies, complex chemistry problems require not only vast knowledge
and precise calculation, but also compositional reasoning about rich dynamic
interactions of different concepts (e.g., temperature changes). Our study shows
that even advanced LLMs, like GPT-4, can fail easily in different ways.
Interestingly, the errors often stem not from a lack of domain knowledge within
the LLMs, but rather from the absence of an effective reasoning structure that
guides the LLMs to elicit the right knowledge, incorporate the knowledge in
step-by-step reasoning, and iteratively refine results for further improved
quality. On this basis, we introduce StructChem, a simple yet effective
prompting strategy that offers the desired guidance and substantially boosts
the LLMs' chemical reasoning capability. Testing across four chemistry areas --
quantum chemistry, mechanics, physical chemistry, and kinetics -- StructChem
substantially enhances GPT-4's performance, with up to 30\% peak improvement.
Our analysis also underscores the unique difficulties of precise grounded
reasoning in science with LLMs, highlighting a need for more research in this
area. Code is available at \url{https://github.com/ozyyshr/StructChem}.",2023-11-16,2023,2023-11,chemistry
"Chemist-X: Large Language Model-empowered Agent for Reaction Condition
  Recommendation in Chemical Synthesis","Recent AI research plots a promising future of automatic chemical reactions
within the chemistry society. This study proposes Chemist-X, a comprehensive AI
agent that automates the reaction condition optimization (RCO) task in chemical
synthesis with retrieval-augmented generation (RAG) technology and
AI-controlled wet-lab experiment executions. To begin with, as an emulation on
how chemical experts solve the RCO task, Chemist-X utilizes a novel RAG scheme
to interrogate available molecular and literature databases to narrow the
searching space for later processing. The agent then leverages a computer-aided
design (CAD) tool we have developed through a large language model (LLM)
supervised programming interface. With updated chemical knowledge obtained via
RAG, as well as the ability in using CAD tools, our agent significantly
outperforms conventional RCO AIs confined to the fixed knowledge within its
training data. Finally, Chemist-X interacts with the physical world through an
automated robotic system, which can validate the suggested chemical reaction
condition without human interventions. The control of the robotic system was
achieved with a novel algorithm we have developed for the equipment, which
relies on LLMs for reliable script generation. Results of our automatic wet-lab
experiments, achieved by fully LLM-supervised end-to-end operation with no
human in the lope, prove Chemist-X's ability in self-driving laboratories.",2023-11-16,2023,2023-11,chemistry
Decoding the Molecular Universe -- Workshop Report,"On August 9-10, 2023, a workshop was convened at the Pacific Northwest
National Laboratory (PNNL) in Richland, WA that brought together a group of
internationally recognized experts in metabolomics, natural products discovery,
chemical ecology, chemical and biological threat assessment, cheminformatics,
computational chemistry, cloud computing, artificial intelligence, and novel
technology development. These experts were invited to assess the value and
feasibility of a grand-scale project to create new technologies that would
allow the identification and quantification of all small molecules, or to
decode the molecular universe. The Decoding the Molecular Universe project
would extend and complement the success of the Human Genome Project by
developing new capabilities and technologies to measure small molecules
(defined as non-protein, non-polymer molecules less than 1500 Daltons) of any
origin and generated in biological systems or produced abiotically. Workshop
attendees 1) explored what new understanding of biological and environmental
systems could be revealed through the lens of small molecules; 2) characterized
the similarities in current needs and technical challenges between each science
or mission area for unambiguous and comprehensive determination of the
composition and quantities of small molecules of any sample; 3) determined the
extent to which technologies or methods currently exist for unambiguously and
comprehensively determining the small molecule composition of any sample and in
a reasonable time; and 4) identified the attributes of the ideal technology or
approach for universal small molecule measurement and identification. The
workshop concluded with a discussion of how a project of this scale could be
undertaken, possible thrusts for the project, early proof-of-principle
applications, and similar efforts upon which the project could be modeled.",2023-11-19,2023,2023-11,chemistry
"Coarse-Grained Configurational Polymer Fingerprints for Property
  Prediction using Machine Learning","In this work, we present a method to generate a configurational level
fingerprint for polymers using the Bead-Spring-Model. Unlike some of the
previous fingerprinting approaches that employ monomer-level information where
atomistic descriptors are computed using quantum chemistry calculations, this
approach incorporates configurational information from a coarse-grained model
of a long polymer chain. The proposed approach may be advantageous for the
study of behavior resulting from large molecular weights. To create this
fingerprint, we make use of two kinds of descriptors. First, we calculate
certain geometric descriptors like Re2, Rg2 etc. and label them as Calculated
Descriptors. Second, we generate a set of data-driven descriptors using an
unsupervised autoencoder model and call them Learnt Descriptors. Using a
combination of both of them, we are able to learn mappings from the structure
to various properties of the polymer chain by training ML models. We test our
fingerprint to predict the probability of occurrence of a configuration at
equilibrium, which is approximated by a simple linear relationship between the
instantaneous internal energy and equilibrium average internal energy.",2023-11-20,2023,2023-11,chemistry
GPQA: A Graduate-Level Google-Proof Q&A Benchmark,"We present GPQA, a challenging dataset of 448 multiple-choice questions
written by domain experts in biology, physics, and chemistry. We ensure that
the questions are high-quality and extremely difficult: experts who have or are
pursuing PhDs in the corresponding domains reach 65% accuracy (74% when
discounting clear mistakes the experts identified in retrospect), while highly
skilled non-expert validators only reach 34% accuracy, despite spending on
average over 30 minutes with unrestricted access to the web (i.e., the
questions are ""Google-proof""). The questions are also difficult for
state-of-the-art AI systems, with our strongest GPT-4 based baseline achieving
39% accuracy. If we are to use future AI systems to help us answer very hard
questions, for example, when developing new scientific knowledge, we need to
develop scalable oversight methods that enable humans to supervise their
outputs, which may be difficult even if the supervisors are themselves skilled
and knowledgeable. The difficulty of GPQA both for skilled non-experts and
frontier AI systems should enable realistic scalable oversight experiments,
which we hope can help devise ways for human experts to reliably get truthful
information from AI systems that surpass human capabilities.",2023-11-20,2023,2023-11,chemistry
GAIA: a benchmark for General AI Assistants,"We introduce GAIA, a benchmark for General AI Assistants that, if solved,
would represent a milestone in AI research. GAIA proposes real-world questions
that require a set of fundamental abilities such as reasoning, multi-modality
handling, web browsing, and generally tool-use proficiency. GAIA questions are
conceptually simple for humans yet challenging for most advanced AIs: we show
that human respondents obtain 92\% vs. 15\% for GPT-4 equipped with plugins.
This notable performance disparity contrasts with the recent trend of LLMs
outperforming humans on tasks requiring professional skills in e.g. law or
chemistry. GAIA's philosophy departs from the current trend in AI benchmarks
suggesting to target tasks that are ever more difficult for humans. We posit
that the advent of Artificial General Intelligence (AGI) hinges on a system's
capability to exhibit similar robustness as the average human does on such
questions. Using GAIA's methodology, we devise 466 questions and their answer.
We release our questions while retaining answers to 300 of them to power a
leader-board available at https://huggingface.co/gaia-benchmark.",2023-11-21,2023,2023-11,chemistry
"ATLANTIC: Structure-Aware Retrieval-Augmented Language Model for
  Interdisciplinary Science","Large language models record impressive performance on many natural language
processing tasks. However, their knowledge capacity is limited to the
pretraining corpus. Retrieval augmentation offers an effective solution by
retrieving context from external knowledge sources to complement the language
model. However, existing retrieval augmentation techniques ignore the
structural relationships between these documents. Furthermore, retrieval models
are not explored much in scientific tasks, especially in regard to the
faithfulness of retrieved documents. In this paper, we propose a novel
structure-aware retrieval augmented language model that accommodates document
structure during retrieval augmentation. We create a heterogeneous document
graph capturing multiple types of relationships (e.g., citation, co-authorship,
etc.) that connect documents from more than 15 scientific disciplines (e.g.,
Physics, Medicine, Chemistry, etc.). We train a graph neural network on the
curated document graph to act as a structural encoder for the corresponding
passages retrieved during the model pretraining. Particularly, along with text
embeddings of the retrieved passages, we obtain structural embeddings of the
documents (passages) and fuse them together before feeding them to the language
model. We evaluate our model extensively on various scientific benchmarks that
include science question-answering and scientific document classification
tasks. Experimental results demonstrate that structure-aware retrieval improves
retrieving more coherent, faithful and contextually relevant passages, while
showing a comparable performance in the overall accuracy.",2023-11-21,2023,2023-11,chemistry
"Everybody Needs a Little HELP: Explaining Graphs via Hierarchical
  Concepts","Graph neural networks (GNNs) have led to major breakthroughs in a variety of
domains such as drug discovery, social network analysis, and travel time
estimation. However, they lack interpretability which hinders human trust and
thereby deployment to settings with high-stakes decisions. A line of
interpretable methods approach this by discovering a small set of relevant
concepts as subgraphs in the last GNN layer that together explain the
prediction. This can yield oversimplified explanations, failing to explain the
interaction between GNN layers. To address this oversight, we provide HELP
(Hierarchical Explainable Latent Pooling), a novel, inherently interpretable
graph pooling approach that reveals how concepts from different GNN layers
compose to new ones in later steps. HELP is more than 1-WL expressive and is
the first non-spectral, end-to-end-learnable, hierarchical graph pooling method
that can learn to pool a variable number of arbitrary connected components. We
empirically demonstrate that it performs on-par with standard GCNs and popular
pooling methods in terms of accuracy while yielding explanations that are
aligned with expert knowledge in the domains of chemistry and social networks.
In addition to a qualitative analysis, we employ concept completeness scores as
well as concept conformity, a novel metric to measure the noise in discovered
concepts, quantitatively verifying that the discovered concepts are
significantly easier to fully understand than those from previous work. Our
work represents a first step towards an understanding of graph neural networks
that goes beyond a set of concepts from the final layer and instead explains
the complex interplay of concepts on different levels.",2023-11-25,2023,2023-11,chemistry
"Transforming organic chemistry research paradigms: moving from manual
  efforts to the intersection of automation and artificial intelligence","Organic chemistry is undergoing a major paradigm shift, moving from a
labor-intensive approach to a new era dominated by automation and artificial
intelligence (AI). This transformative shift is being driven by technological
advances, the ever-increasing demand for greater research efficiency and
accuracy, and the burgeoning growth of interdisciplinary research. AI models,
supported by computational power and algorithms, are drastically reshaping
synthetic planning and introducing groundbreaking ways to tackle complex
molecular synthesis. In addition, autonomous robotic systems are rapidly
accelerating the pace of discovery by performing tedious tasks with
unprecedented speed and precision. This article examines the multiple
opportunities and challenges presented by this paradigm shift and explores its
far-reaching implications. It provides valuable insights into the future
trajectory of organic chemistry research, which is increasingly defined by the
synergistic interaction of automation and AI.",2023-11-26,2023,2023-11,chemistry
"Meta-Diversity Search in Complex Systems, A Recipe for Artificial
  Open-Endedness ?","Can we build an artificial system that would be able to generate endless
surprises if ran ""forever"" in Minecraft? While there is not a single path
toward solving that grand challenge, this article presents what we believe to
be some working ingredients for the endless generation of novel increasingly
complex artifacts in Minecraft. Our framework for an open-ended system includes
two components: a complex system used to recursively grow and complexify
artifacts over time, and a discovery algorithm that leverages the concept of
meta-diversity search. Since complex systems have shown to enable the emergence
of considerable complexity from set of simple rules, we believe them to be
great candidates to generate all sort of artifacts in Minecraft. Yet, the space
of possible artifacts that can be generated by these systems is often unknown,
challenging to characterize and explore. Therefore automating the long-term
discovery of novel and increasingly complex artifacts in these systems is an
exciting research field. To approach these challenges, we formulate the problem
of meta-diversity search where an artificial ""discovery assistant""
incrementally learns a diverse set of representations to characterize behaviors
and searches to discover diverse patterns within each of them. A successful
discovery assistant should continuously seek for novel sources of diversities
while being able to quickly specialize the search toward a new unknown type of
diversity. To implement those ideas in the Minecraft environment, we simulate
an artificial ""chemistry"" system based on Lenia continuous cellular automaton
for generating artifacts, as well as an artificial ""discovery assistant""
(called Holmes) for the artifact-discovery process. Holmes incrementally learns
a hierarchy of modular representations to characterize divergent sources of
diversity and uses a goal-based intrinsically-motivated exploration as the
diversity search strategy.",2023-12-01,2023,2023-12,chemistry
"AdsorbRL: Deep Multi-Objective Reinforcement Learning for Inverse
  Catalysts Design","A central challenge of the clean energy transition is the development of
catalysts for low-emissions technologies. Recent advances in Machine Learning
for quantum chemistry drastically accelerate the computation of catalytic
activity descriptors such as adsorption energies. Here we introduce AdsorbRL, a
Deep Reinforcement Learning agent aiming to identify potential catalysts given
a multi-objective binding energy target, trained using offline learning on the
Open Catalyst 2020 and Materials Project data sets. We experiment with Deep
Q-Network agents to traverse the space of all ~160,000 possible unary, binary
and ternary compounds of 55 chemical elements, with very sparse rewards based
on adsorption energy known for only between 2,000 and 3,000 catalysts per
adsorbate. To constrain the actions space, we introduce Random Edge Traversal
and train a single-objective DQN agent on the known states subgraph, which we
find strengthens target binding energy by an average of 4.1 eV. We extend this
approach to multi-objective, goal-conditioned learning, and train a DQN agent
to identify materials with the highest (respectively lowest) adsorption
energies for multiple simultaneous target adsorbates. We experiment with
Objective Sub-Sampling, a novel training scheme aimed at encouraging
exploration in the multi-objective setup, and demonstrate simultaneous
adsorption energy improvement across all target adsorbates, by an average of
0.8 eV. Overall, our results suggest strong potential for Deep Reinforcement
Learning applied to the inverse catalysts design problem.",2023-12-04,2023,2023-12,chemistry
"AI-driven emergence of frequency information non-uniform distribution
  via THz metasurface spectrum prediction","Recently, artificial intelligence has been extensively deployed across
various scientific disciplines, optimizing and guiding the progression of
experiments through the integration of abundant datasets, whilst continuously
probing the vast theoretical space encapsulated within the data. Particularly,
deep learning models, due to their end-to-end adaptive learning capabilities,
are capable of autonomously learning intrinsic data features, thereby
transcending the limitations of traditional experience to a certain extent.
Here, we unveil previously unreported information characteristics pertaining to
different frequencies emerged during our work on predicting the terahertz
spectral modulation effects of metasurfaces based on AI-prediction. Moreover,
we have substantiated that our proposed methodology of simply adding
supplementary multi-frequency inputs to the existing dataset during the target
spectral prediction process can significantly enhance the predictive accuracy
of the network. This approach effectively optimizes the utilization of existing
datasets and paves the way for interdisciplinary research and applications in
artificial intelligence, chemistry, composite material design, biomedicine, and
other fields.",2023-12-05,2023,2023-12,chemistry
"Molecule Joint Auto-Encoding: Trajectory Pretraining with 2D and 3D
  Diffusion","Recently, artificial intelligence for drug discovery has raised increasing
interest in both machine learning and chemistry domains. The fundamental
building block for drug discovery is molecule geometry and thus, the molecule's
geometrical representation is the main bottleneck to better utilize machine
learning techniques for drug discovery. In this work, we propose a pretraining
method for molecule joint auto-encoding (MoleculeJAE). MoleculeJAE can learn
both the 2D bond (topology) and 3D conformation (geometry) information, and a
diffusion process model is applied to mimic the augmented trajectories of such
two modalities, based on which, MoleculeJAE will learn the inherent chemical
structure in a self-supervised manner. Thus, the pretrained geometrical
representation in MoleculeJAE is expected to benefit downstream
geometry-related tasks. Empirically, MoleculeJAE proves its effectiveness by
reaching state-of-the-art performance on 15 out of 20 tasks by comparing it
with 12 competitive baselines.",2023-12-06,2023,2023-12,chemistry
MatterGen: a generative model for inorganic materials design,"The design of functional materials with desired properties is essential in
driving technological advances in areas like energy storage, catalysis, and
carbon capture. Generative models provide a new paradigm for materials design
by directly generating entirely novel materials given desired property
constraints. Despite recent progress, current generative models have low
success rate in proposing stable crystals, or can only satisfy a very limited
set of property constraints. Here, we present MatterGen, a model that generates
stable, diverse inorganic materials across the periodic table and can further
be fine-tuned to steer the generation towards a broad range of property
constraints. To enable this, we introduce a new diffusion-based generative
process that produces crystalline structures by gradually refining atom types,
coordinates, and the periodic lattice. We further introduce adapter modules to
enable fine-tuning towards any given property constraints with a labeled
dataset. Compared to prior generative models, structures produced by MatterGen
are more than twice as likely to be novel and stable, and more than 15 times
closer to the local energy minimum. After fine-tuning, MatterGen successfully
generates stable, novel materials with desired chemistry, symmetry, as well as
mechanical, electronic and magnetic properties. Finally, we demonstrate
multi-property materials design capabilities by proposing structures that have
both high magnetic density and a chemical composition with low supply-chain
risk. We believe that the quality of generated materials and the breadth of
MatterGen's capabilities represent a major advancement towards creating a
universal generative model for materials design.",2023-12-06,2023,2023-12,chemistry
Predictive Chemistry Augmented with Text Retrieval,"This paper focuses on using natural language descriptions to enhance
predictive models in the chemistry field. Conventionally, chemoinformatics
models are trained with extensive structured data manually extracted from the
literature. In this paper, we introduce TextReact, a novel method that directly
augments predictive chemistry with texts retrieved from the literature.
TextReact retrieves text descriptions relevant for a given chemical reaction,
and then aligns them with the molecular representation of the reaction. This
alignment is enhanced via an auxiliary masked LM objective incorporated in the
predictor training. We empirically validate the framework on two chemistry
tasks: reaction condition recommendation and one-step retrosynthesis. By
leveraging text retrieval, TextReact significantly outperforms state-of-the-art
chemoinformatics models trained solely on molecular data.",2023-12-08,2023,2023-12,chemistry
Image and Data Mining in Reticular Chemistry Using GPT-4V,"The integration of artificial intelligence into scientific research has
reached a new pinnacle with GPT-4V, a large language model featuring enhanced
vision capabilities, accessible through ChatGPT or an API. This study
demonstrates the remarkable ability of GPT-4V to navigate and obtain complex
data for metal-organic frameworks, especially from graphical sources. Our
approach involved an automated process of converting 346 scholarly articles
into 6240 images, which represents a benchmark dataset in this task, followed
by deploying GPT-4V to categorize and analyze these images using natural
language prompts. This methodology enabled GPT-4V to accurately identify and
interpret key plots integral to MOF characterization, such as nitrogen
isotherms, PXRD patterns, and TGA curves, among others, with accuracy and
recall above 93%. The model's proficiency in extracting critical information
from these plots not only underscores its capability in data mining but also
highlights its potential in aiding the creation of comprehensive digital
databases for reticular chemistry. In addition, the extracted nitrogen isotherm
data from the selected literature allowed for a comparison between theoretical
and experimental porosity values for over 200 compounds, highlighting certain
discrepancies and underscoring the importance of integrating computational and
experimental data. This work highlights the potential of AI in accelerating
scientific discovery and innovation, bridging the gap between computational
tools and experimental research, and paving the way for more efficient,
inclusive, and comprehensive scientific inquiry.",2023-12-09,2023,2023-12,chemistry
"Using Think-Aloud Data to Understand Relations between Self-Regulation
  Cycle Characteristics and Student Performance in Intelligent Tutoring Systems","Numerous studies demonstrate the importance of self-regulation during
learning by problem-solving. Recent work in learning analytics has largely
examined students' use of SRL concerning overall learning gains. Limited
research has related SRL to in-the-moment performance differences among
learners. The present study investigates SRL behaviors in relationship to
learners' moment-by-moment performance while working with intelligent tutoring
systems for stoichiometry chemistry. We demonstrate the feasibility of labeling
SRL behaviors based on AI-generated think-aloud transcripts, identifying the
presence or absence of four SRL categories (processing information, planning,
enacting, and realizing errors) in each utterance. Using the SRL codes, we
conducted regression analyses to examine how the use of SRL in terms of
presence, frequency, cyclical characteristics, and recency relate to student
performance on subsequent steps in multi-step problems. A model considering
students' SRL cycle characteristics outperformed a model only using
in-the-moment SRL assessment. In line with theoretical predictions, students'
actions during earlier, process-heavy stages of SRL cycles exhibited lower
moment-by-moment correctness during problem-solving than later SRL cycle
stages. We discuss system re-design opportunities to add SRL support during
stages of processing and paths forward for using machine learning to speed
research depending on the assessment of SRL based on transcription of
think-aloud data.",2023-12-09,2023,2023-12,chemistry
Drivers and Barriers of AI Adoption and Use in Scientific Research,"New technologies have the power to revolutionize science. It has happened in
the past and is happening again with the emergence of new computational tools,
such as artificial intelligence and machine learning. Despite the documented
impact of these technologies, there remains a significant gap in understanding
the process of their adoption within the scientific community. In this paper,
we draw on theories of scientific and technical human capital to study the
integration of AI in scientific research, focusing on the human capital of
scientists and the external resources available within their network of
collaborators and institutions. We validate our hypotheses on a large sample of
publications from OpenAlex, covering all sciences from 1980 to 2020, and
identify a set key drivers and inhibitors of AI adoption and use in science.
Our results suggest that AI is pioneered by domain scientists with a `taste for
exploration' and who are embedded in a network rich of computer scientists,
experienced AI scientists and early-career researchers; they come from
institutions with high citation impact and a relatively strong publication
history on AI. The access to computing resources only matters for a few
scientific disciplines, such as chemistry and medical sciences. Once AI is
integrated into research, most adoption factors continue to influence its
subsequent reuse. Implications for the organization and management of science
in the evolving era of AI-driven discovery are discussed.",2023-12-15,2023,2023-12,chemistry
Enabling Accelerators for Graph Computing,"The advent of Graph Neural Networks (GNNs) has revolutionized the field of
machine learning, offering a novel paradigm for learning on graph-structured
data. Unlike traditional neural networks, GNNs are capable of capturing complex
relationships and dependencies inherent in graph data, making them particularly
suited for a wide range of applications including social network analysis,
molecular chemistry, and network security. GNNs, with their unique structure
and operation, present new computational challenges compared to conventional
neural networks. This requires comprehensive benchmarking and a thorough
characterization of GNNs to obtain insight into their computational
requirements and to identify potential performance bottlenecks. In this thesis,
we aim to develop a better understanding of how GNNs interact with the
underlying hardware and will leverage this knowledge as we design specialized
accelerators and develop new optimizations, leading to more efficient and
faster GNN computations. A pivotal component within GNNs is the Sparse General
Matrix-Matrix Multiplication (SpGEMM) kernel, known for its computational
intensity and irregular memory access patterns. In this thesis, we address the
challenges posed by SpGEMM by implementing a highly optimized hashing-based
SpGEMM kernel tailored for a custom accelerator. Synthesizing these insights
and optimizations, we design state-of-the-art hardware accelerators capable of
efficiently handling various GNN workloads. Our accelerator architectures are
built on our characterization of GNN computational demands, providing clear
motivation for our approaches. This exploration into novel models underlines
our comprehensive approach, as we strive to enable accelerators that are not
just performant, but also versatile, able to adapt to the evolving landscape of
graph computing.",2023-12-16,2023,2023-12,chemistry
Continuous-time Graph Representation with Sequential Survival Process,"Over the past two decades, there has been a tremendous increase in the growth
of representation learning methods for graphs, with numerous applications
across various fields, including bioinformatics, chemistry, and the social
sciences. However, current dynamic network approaches focus on discrete-time
networks or treat links in continuous-time networks as instantaneous events.
Therefore, these approaches have limitations in capturing the persistence or
absence of links that continuously emerge and disappear over time for
particular durations. To address this, we propose a novel stochastic process
relying on survival functions to model the durations of links and their
absences over time. This forms a generic new likelihood specification
explicitly accounting for intermittent edge-persistent networks, namely GraSSP:
Graph Representation with Sequential Survival Process. We apply the developed
framework to a recent continuous time dynamic latent distance model
characterizing network dynamics in terms of a sequence of piecewise linear
movements of nodes in latent space. We quantitatively assess the developed
framework in various downstream tasks, such as link prediction and network
completion, demonstrating that the developed modeling framework accounting for
link persistence and absence well tracks the intrinsic trajectories of nodes in
a latent space and captures the underlying characteristics of evolving network
structure.",2023-12-20,2023,2023-12,chemistry
"An integrated framework for accelerating reactive flow simulation using
  GPU and machine learning models","Recent progress in artificial intelligence (AI) and high-performance
computing (HPC) have brought potentially game-changing opportunities in
accelerating reactive flow simulations. In this study, we introduce an
open-source computational fluid dynamics (CFD) framework that integrates the
strengths of machine learning (ML) and graphics processing unit (GPU) to
demonstrate their combined capability. Within this framework, all computational
operations are solely executed on GPU, including ML-accelerated chemistry
integration, fully-implicit solving of PDEs, and computation of thermal and
transport properties, thereby eliminating the CPU-GPU memory copy overhead.
Optimisations both within the kernel functions and during the kernel launch
process are conducted to enhance computational performance. Strategies such as
static data reorganisation and dynamic data allocation are adopted to reduce
the GPU memory footprint. The computational performance is evaluated in two
turbulent flame benchmarks using quasi-DNS and LES modelling, respectively.
Remarkably, while maintaining a similar level of accuracy to the conventional
CPU/CVODE-based solver, the GPU/ML-accelerated approach shows an overall
speedup of over two orders of magnitude for both cases. This result highlights
that high-fidelity turbulent combustion simulation with finite-rate chemistry
that requires normally hundreds of CPUs can now be performed on portable
devices such as laptops with a medium-end GPU.",2023-12-21,2023,2023-12,chemistry
"Diffusion-Driven Generative Framework for Molecular Conformation
  Prediction","The task of deducing three-dimensional molecular configurations from their
two-dimensional graph representations holds paramount importance in the fields
of computational chemistry and pharmaceutical development. The rapid
advancement of machine learning, particularly within the domain of deep
generative networks, has revolutionized the precision of predictive modeling in
this context. Traditional approaches often adopt a two-step strategy: initially
estimating interatomic distances and subsequently refining the spatial
molecular structure by solving a distance geometry problem. However, this
sequential approach occasionally falls short in accurately capturing the
intricacies of local atomic arrangements, thereby compromising the fidelity of
the resulting structural models. Addressing these limitations, this research
introduces a cutting-edge generative framework named DDGF. This framework is
grounded in the principles of diffusion observed in classical non-equilibrium
thermodynamics. DDGF views atoms as discrete entities and excels in guiding the
reversal of diffusion, transforming a distribution of stochastic noise back
into coherent molecular structures through a process akin to a Markov chain.
This transformation commences with the initial representation of a molecular
graph in an abstract latent space, culminating in the realization of
three-dimensional structures via a sophisticated bilevel optimization scheme
meticulously tailored to meet the specific requirements of the task. One of the
formidable challenges in this modeling endeavor involves preserving
roto-translational invariance to ensure that the generated molecular
conformations adhere to the laws of physics. Extensive experimental evaluations
confirm the efficacy of the proposed DDGF in comparison to state-of-the-art
methods.",2023-12-22,2023,2023-12,chemistry
"Towards End-to-End Structure Solutions from Information-Compromised
  Diffraction Data via Generative Deep Learning","The revolution in materials in the past century was built on a knowledge of
the atomic arrangements and the structure-property relationship. The sine qua
non for obtaining quantitative structural information is single crystal
crystallography. However, increasingly we need to solve structures in cases
where the information content in our input signal is significantly degraded,
for example, due to orientational averaging of grains, finite size effects due
to nanostructure, and mixed signals due to sample heterogeneity. Understanding
the structure property relationships in such situations is, if anything, more
important and insightful, yet we do not have robust approaches for
accomplishing it. In principle, machine learning (ML) and deep learning (DL)
are promising approaches since they augment information in the degraded input
signal with prior knowledge learned from large databases of already known
structures. Here we present a novel ML approach, a variational query-based
multi-branch deep neural network that has the promise to be a robust but
general tool to address this problem end-to-end. We demonstrate the approach on
computed powder x-ray diffraction (PXRD), along with partial chemical
composition information, as input. We choose as a structural representation a
modified electron density we call the Cartesian mapped electron density (CMED),
that straightforwardly allows our ML model to learn material structures across
different chemistries, symmetries and crystal systems. When evaluated on
theoretically simulated data for the cubic and trigonal crystal systems, the
system achieves up to $93.4\%$ average similarity with the ground truth on
unseen materials, both with known and partially-known chemical composition
information, showing great promise for successful structure solution even from
degraded and incomplete input data.",2023-12-23,2023,2023-12,chemistry
"Generating High-Precision Force Fields for Molecular Dynamics
  Simulations to Study Chemical Reaction Mechanisms using Molecular
  Configuration Transformer","Theoretical studies on chemical reaction mechanisms have been crucial in
organic chemistry. Traditionally, calculating the manually constructed
molecular conformations of transition states for chemical reactions using
quantum chemical calculations is the most commonly used method. However, this
way is heavily dependent on individual experience and chemical intuition. In
our previous study, we proposed a research paradigm that uses enhanced sampling
in molecular dynamics simulations to study chemical reactions. This approach
can directly simulate the entire process of a chemical reaction. However, the
computational speed limits the use of high-precision potential energy functions
for simulations. To address this issue, we present a scheme for training
high-precision force fields for molecular modeling using a previously developed
graph-neural-network-based molecular model, molecular configuration
transformer. This potential energy function allows for highly accurate
simulations at a low computational cost, leading to more precise calculations
of the mechanism of chemical reactions. We applied this approach to study a
Claisen rearrangement reaction and a Carbonyl insertion reaction catalyzed by
Manganese.",2023-12-31,2023,2023-12,chemistry
GraphGPT: Generative Pre-trained Graph Eulerian Transformer,"We introduceGraphGPT, a novel self-supervised generative pre-trained model
for graph learning based on the Graph Eulerian Transformer (GET). First, we
propose GET, which combines a standard transformer encoder or decoder
architecture with an innovative graph-to-sequence transformation method. This
method converts graphs or sampled subgraphs into sequences of tokens
representing nodes, edges, and attributes in a reversible manner using Eulerian
paths. We pre-train GET using either of the two self-supervised tasks:
next-token prediction (NTP) and scheduled masked-token prediction (SMTP). The
pre-trained model is then fine-tuned for downstream tasks such as graph-,
edge-, and node-level prediction. Despite its simplicity, GraphGPT achieves
performance comparable to or surpassing state-of-the-art methods on multiple
large-scale Open Graph Benchmark (OGB) datasets. It demonstrates exceptional
results on the molecular property prediction dataset PCQM4Mv2 and the
protein-protein interaction dataset ogbl-ppa. Notably, generative pre-training
enables scaling GraphGPT to 2 billion parameters while maintaining performance
gains - a breakthrough that overcomes the scalability limitations of
traditional Graph Neural Networks (GNNs) and prior graph transformers (GTs). To
advance research in graph foundation models and facilitate scientific discovery
in chemistry, materials science, and related fields, we will release the source
code (https://github.com/alibaba/graph-gpt) and pre-trained checkpoints.",2023-12-31,2023,2023-12,chemistry
On the Expressive Power of Graph Neural Networks,"The study of Graph Neural Networks has received considerable interest in the
past few years. By extending deep learning to graph-structured data, GNNs can
solve a diverse set of tasks in fields including social science, chemistry, and
medicine. The development of GNN architectures has largely been focused on
improving empirical performance on tasks like node or graph classification.
However, a line of recent work has instead sought to find GNN architectures
that have desirable theoretical properties - by studying their expressive power
and designing architectures that maximize this expressiveness.
  While there is no consensus on the best way to define the expressiveness of a
GNN, it can be viewed from several well-motivated perspectives. Perhaps the
most natural approach is to study the universal approximation properties of
GNNs, much in the way that this has been studied extensively for MLPs. Another
direction focuses on the extent to which GNNs can distinguish between different
graph structures, relating this to the graph isomorphism test. Besides, a GNN's
ability to compute graph properties such as graph moments has been suggested as
another form of expressiveness. All of these different definitions are
complementary and have yielded different recommendations for GNN architecture
choices. In this paper, we would like to give an overview of the notion of
""expressive power"" of GNNs and provide some valuable insights regarding the
design choices of GNNs.",2024-01-03,2024,2024-01,chemistry
"ORGANA: A Robotic Assistant for Automated Chemistry Experimentation and
  Characterization","Chemistry experiments can be resource- and labor-intensive, often requiring
manual tasks like polishing electrodes in electrochemistry. Traditional lab
automation infrastructure faces challenges adapting to new experiments. To
address this, we introduce ORGANA, an assistive robotic system that automates
diverse chemistry experiments using decision-making and perception tools. It
makes decisions with chemists in the loop to control robots and lab devices.
ORGANA interacts with chemists using Large Language Models (LLMs) to derive
experiment goals, handle disambiguation, and provide experiment logs. ORGANA
plans and executes complex tasks with visual feedback, while supporting
scheduling and parallel task execution. We demonstrate ORGANA's capabilities in
solubility, pH measurement, recrystallization, and electrochemistry
experiments. In electrochemistry, it executes a 19-step plan in parallel to
characterize quinone derivatives for flow batteries. Our user study shows
ORGANA reduces frustration and physical demand by over 50%, with users saving
an average of 80.3% of their time when using it.",2024-01-13,2024,2024-01,chemistry
ChemDFM: A Large Language Foundation Model for Chemistry,"Artificial intelligence (AI) has played an increasingly important role in
chemical research. However, most models currently used in chemistry are
specialist models that require training and tuning for specific tasks. A more
generic and efficient solution would be an AI model that could address many
tasks and support free-form dialogue in the broad field of chemistry. In its
utmost form, such a generalist AI chemist could be referred to as Chemical
General Intelligence. Large language models (LLMs) have recently logged
tremendous success in the general domain of natural language processing,
showing emerging task generalization and free-form dialogue capabilities.
However, domain knowledge of chemistry is largely missing when training
general-domain LLMs. The lack of such knowledge greatly hinders the performance
of generalist LLMs in the field of chemistry. To this end, we develop ChemDFM,
a pioneering LLM for chemistry trained on 34B tokens from chemical literature
and textbooks, and fine-tuned using 2.7M instructions. As a result, it can
understand and reason with chemical knowledge in free-form dialogue.
Quantitative evaluations show that ChemDFM significantly surpasses most
representative open-source LLMs. It outperforms GPT-4 on a great portion of
chemical tasks, despite the substantial size difference. We have open-sourced
the inference codes, evaluation datasets, and model weights of ChemDFM on
Huggingface (https://huggingface.co/OpenDFM/ChemDFM-v1.0-13B).",2024-01-26,2024,2024-01,chemistry
"LLaMP: Large Language Model Made Powerful for High-fidelity Materials
  Knowledge Retrieval and Distillation","Reducing hallucination of Large Language Models (LLMs) is imperative for use
in the sciences, where reliability and reproducibility are crucial. However,
LLMs inherently lack long-term memory, making it a nontrivial, ad hoc, and
inevitably biased task to fine-tune them on domain-specific literature and
data. Here we introduce LLaMP, a multimodal retrieval-augmented generation
(RAG) framework of hierarchical reasoning-and-acting (ReAct) agents that can
dynamically and recursively interact with computational and experimental data
on Materials Project (MP) and run atomistic simulations via high-throughput
workflow interface. Without fine-tuning, LLaMP demonstrates strong tool usage
ability to comprehend and integrate various modalities of materials science
concepts, fetch relevant data stores on the fly, process higher-order data
(such as crystal structure and elastic tensor), and streamline complex tasks in
computational materials and chemistry. We propose a simple metric combining
uncertainty and confidence estimates to evaluate the self-consistency of
responses by LLaMP and vanilla LLMs. Our benchmark shows that LLaMP effectively
mitigates the intrinsic bias in LLMs, counteracting the errors on bulk moduli,
electronic bandgaps, and formation energies that seem to derive from mixed data
sources. We also demonstrate LLaMP's capability to edit crystal structures and
run annealing molecular dynamics simulations using pre-trained machine-learning
force fields. The framework offers an intuitive and nearly hallucination-free
approach to exploring and scaling materials informatics, and establishes a
pathway for knowledge distillation and fine-tuning other language models. Code
and live demo are available at https://github.com/chiang-yuan/llamp",2024-01-30,2024,2024-01,chemistry
From Words to Molecules: A Survey of Large Language Models in Chemistry,"In recent years, Large Language Models (LLMs) have achieved significant
success in natural language processing (NLP) and various interdisciplinary
areas. However, applying LLMs to chemistry is a complex task that requires
specialized domain knowledge. This paper provides a thorough exploration of the
nuanced methodologies employed in integrating LLMs into the field of chemistry,
delving into the complexities and innovations at this interdisciplinary
juncture. Specifically, our analysis begins with examining how molecular
information is fed into LLMs through various representation and tokenization
methods. We then categorize chemical LLMs into three distinct groups based on
the domain and modality of their input data, and discuss approaches for
integrating these inputs for LLMs. Furthermore, this paper delves into the
pretraining objectives with adaptations to chemical LLMs. After that, we
explore the diverse applications of LLMs in chemistry, including novel
paradigms for their application in chemistry tasks. Finally, we identify
promising research directions, including further integration with chemical
knowledge, advancements in continual learning, and improvements in model
interpretability, paving the way for groundbreaking developments in the field.",2024-02-02,2024,2024-02,chemistry
"Curriculum reinforcement learning for quantum architecture search under
  hardware errors","The key challenge in the noisy intermediate-scale quantum era is finding
useful circuits compatible with current device limitations. Variational quantum
algorithms (VQAs) offer a potential solution by fixing the circuit architecture
and optimizing individual gate parameters in an external loop. However,
parameter optimization can become intractable, and the overall performance of
the algorithm depends heavily on the initially chosen circuit architecture.
Several quantum architecture search (QAS) algorithms have been developed to
design useful circuit architectures automatically. In the case of parameter
optimization alone, noise effects have been observed to dramatically influence
the performance of the optimizer and final outcomes, which is a key line of
study. However, the effects of noise on the architecture search, which could be
just as critical, are poorly understood. This work addresses this gap by
introducing a curriculum-based reinforcement learning QAS (CRLQAS) algorithm
designed to tackle challenges in realistic VQA deployment. The algorithm
incorporates (i) a 3D architecture encoding and restrictions on environment
dynamics to explore the search space of possible circuits efficiently, (ii) an
episode halting scheme to steer the agent to find shorter circuits, and (iii) a
novel variant of simultaneous perturbation stochastic approximation as an
optimizer for faster convergence. To facilitate studies, we developed an
optimized simulator for our algorithm, significantly improving computational
efficiency in simulating noisy quantum circuits by employing the Pauli-transfer
matrix formalism in the Pauli-Liouville basis. Numerical experiments focusing
on quantum chemistry tasks demonstrate that CRLQAS outperforms existing QAS
algorithms across several metrics in both noiseless and noisy environments.",2024-02-05,2024,2024-02,chemistry
"SceMQA: A Scientific College Entrance Level Multimodal Question
  Answering Benchmark","The paper introduces SceMQA, a novel benchmark for scientific multimodal
question answering at the college entrance level. It addresses a critical
educational phase often overlooked in existing benchmarks, spanning high school
to pre-college levels. SceMQA focuses on core science subjects including
Mathematics, Physics, Chemistry, and Biology. It features a blend of
multiple-choice and free-response formats, ensuring a comprehensive evaluation
of AI models' abilities. Additionally, our benchmark provides specific
knowledge points for each problem and detailed explanations for each answer.
SceMQA also uniquely presents problems with identical contexts but varied
questions to facilitate a more thorough and accurate assessment of reasoning
capabilities. In the experiment, we evaluate both open-source and close-source
state-of-the-art Multimodal Large Language Models (MLLMs), across various
experimental settings. The results show that further research and development
are needed in developing more capable MLLM, as highlighted by only 50% to 60%
accuracy achieved by the strongest models. Our benchmark and analysis will be
available at https://scemqa.github.io/",2024-02-06,2024,2024-02,chemistry
"cecilia: A Machine Learning-Based Pipeline for Measuring Metal
  Abundances of Helium-rich Polluted White Dwarfs","Over the past several decades, conventional spectral analysis techniques of
polluted white dwarfs have become powerful tools to learn about the geology and
chemistry of extrasolar bodies. Despite their proven capabilities and extensive
legacy of scientific discoveries, these techniques are however still limited by
their manual, time-intensive, and iterative nature. As a result, they are
susceptible to human errors and are difficult to scale up to population-wide
studies of metal pollution. This paper seeks to address this problem by
presenting cecilia, the first Machine Learning (ML)-powered spectral modeling
code designed to measure the metal abundances of intermediate-temperature
(10,000$\leq T_{\rm eff} \leq$20,000 K), Helium-rich polluted white dwarfs.
Trained with more than 22,000 randomly drawn atmosphere models and stellar
parameters, our pipeline aims to overcome the limitations of classical methods
by replacing the generation of synthetic spectra from computationally expensive
codes and uniformly spaced model grids, with a fast, automated, and efficient
neural-network-based interpolator. More specifically, cecilia combines
state-of-the-art atmosphere models, powerful artificial intelligence tools, and
robust statistical techniques to rapidly generate synthetic spectra of polluted
white dwarfs in high-dimensional space, and enable accurate ($\lesssim$0.1 dex)
and simultaneous measurements of 14 stellar parameters -- including 11
elemental abundances -- from real spectroscopic observations. As massively
multiplexed astronomical surveys begin scientific operations, cecilia's
performance has the potential to unlock large-scale studies of extrasolar
geochemistry and propel the field of white dwarf science into the era of Big
Data. In doing so, we aspire to uncover new statistical insights that were
previously impractical with traditional white dwarf characterisation
techniques.",2024-02-07,2024,2024-02,chemistry
ChemLLM: A Chemical Large Language Model,"Large language models (LLMs) have made impressive progress in chemistry
applications. However, the community lacks an LLM specifically designed for
chemistry. The main challenges are two-fold: firstly, most chemical data and
scientific knowledge are stored in structured databases, which limits the
model's ability to sustain coherent dialogue when used directly. Secondly,
there is an absence of objective and fair benchmark that encompass most
chemistry tasks. Here, we introduce ChemLLM, a comprehensive framework that
features the first LLM dedicated to chemistry. It also includes ChemData, a
dataset specifically designed for instruction tuning, and ChemBench, a robust
benchmark covering nine essential chemistry tasks. ChemLLM is adept at
performing various tasks across chemical disciplines with fluid dialogue
interaction. Notably, ChemLLM achieves results comparable to GPT-4 on the core
chemical tasks and demonstrates competitive performance with LLMs of similar
size in general scenarios. ChemLLM paves a new path for exploration in chemical
studies, and our method of incorporating structured chemical knowledge into
dialogue systems sets a new standard for developing LLMs in various scientific
fields. Codes, Datasets, and Model weights are publicly accessible at
https://hf.co/AI4Chem",2024-02-10,2024,2024-02,chemistry
"X-LoRA: Mixture of Low-Rank Adapter Experts, a Flexible Framework for
  Large Language Models with Applications in Protein Mechanics and Molecular
  Design","We report a mixture of expert strategy to create fine-tuned large language
models using a deep layer-wise token-level approach based on low-rank
adaptation (LoRA). Starting with a set of pre-trained LoRA adapters, our gating
strategy uses the hidden states to dynamically mix adapted layers, allowing the
resulting X-LoRA model to draw upon different capabilities and create
never-before-used deep layer-wise combinations to solve tasks. The design is
inspired by the biological principles of universality and diversity, where
neural network building blocks are reused in different hierarchical
manifestations. Hence, the X-LoRA model can be easily implemented for any
existing large language model (LLM) without a need for modifications of the
underlying structure. We develop a tailored X-LoRA model that offers scientific
capabilities including forward/inverse analysis tasks and enhanced reasoning
capability, focused on biomaterial analysis, protein mechanics and design. The
impact of this work include access to readily expandable and adaptable models
with strong domain knowledge and the capability to integrate across areas of
knowledge. Featuring experts in biology, mathematics, reasoning, bio-inspired
materials, mechanics and materials, chemistry, protein biophysics, mechanics
and quantum-mechanics based molecular properties, we conduct a series of
physics-focused case studies. We examine knowledge recall, protein mechanics
forward/inverse tasks, protein design, adversarial agentic modeling including
ontological knowledge graph construction, as well as molecular design. The
model is capable not only of making quantitative predictions of nanomechanical
properties of proteins or quantum mechanical molecular properties, but also
reasons over the results and correctly predicts likely mechanisms that explain
distinct molecular behaviors.",2024-02-11,2024,2024-02,chemistry
ChatCell: Facilitating Single-Cell Analysis with Natural Language,"As Large Language Models (LLMs) rapidly evolve, their influence in science is
becoming increasingly prominent. The emerging capabilities of LLMs in task
generalization and free-form dialogue can significantly advance fields like
chemistry and biology. However, the field of single-cell biology, which forms
the foundational building blocks of living organisms, still faces several
challenges. High knowledge barriers and limited scalability in current methods
restrict the full exploitation of LLMs in mastering single-cell data, impeding
direct accessibility and rapid iteration. To this end, we introduce ChatCell,
which signifies a paradigm shift by facilitating single-cell analysis with
natural language. Leveraging vocabulary adaptation and unified sequence
generation, ChatCell has acquired profound expertise in single-cell biology and
the capability to accommodate a diverse range of analysis tasks. Extensive
experiments further demonstrate ChatCell's robust performance and potential to
deepen single-cell insights, paving the way for more accessible and intuitive
exploration in this pivotal field. Our project homepage is available at
https://zjunlp.github.io/project/ChatCell.",2024-02-13,2024,2024-02,chemistry
"LlaSMol: Advancing Large Language Models for Chemistry with a
  Large-Scale, Comprehensive, High-Quality Instruction Tuning Dataset","Chemistry plays a crucial role in many domains, such as drug discovery and
material science. While large language models (LLMs) such as GPT-4 exhibit
remarkable capabilities on natural language processing tasks, existing research
indicates that their performance on chemistry tasks is discouragingly low. In
this paper, however, we demonstrate that our developed LLMs can achieve very
strong results on a comprehensive set of chemistry tasks, outperforming the
most advanced GPT-4 and Claude 3 Opus by a substantial margin. To accomplish
this, we propose SMolInstruct, a large-scale, comprehensive, and high-quality
dataset for instruction tuning. It contains 14 selected chemistry tasks and
over three million samples, laying a solid foundation for training and
evaluating LLMs for chemistry. Using SMolInstruct, we fine-tune a set of
open-source LLMs, among which, we find that Mistral serves as the best base
model for chemistry tasks. Our analysis further demonstrates the critical role
of the proposed dataset in driving the performance improvements.",2024-02-14,2024,2024-02,chemistry
"ChemReasoner: Heuristic Search over a Large Language Model's Knowledge
  Space using Quantum-Chemical Feedback","The discovery of new catalysts is essential for the design of new and more
efficient chemical processes in order to transition to a sustainable future. We
introduce an AI-guided computational screening framework unifying linguistic
reasoning with quantum-chemistry based feedback from 3D atomistic
representations. Our approach formulates catalyst discovery as an uncertain
environment where an agent actively searches for highly effective catalysts via
the iterative combination of large language model (LLM)-derived hypotheses and
atomistic graph neural network (GNN)-derived feedback. Identified catalysts in
intermediate search steps undergo structural evaluation based on spatial
orientation, reaction pathways, and stability. Scoring functions based on
adsorption energies and reaction energy barriers steer the exploration in the
LLM's knowledge space toward energetically favorable, high-efficiency
catalysts. We introduce planning methods that automatically guide the
exploration without human input, providing competitive performance against
expert-enumerated chemical descriptor-based implementations. By integrating
language-guided reasoning with computational chemistry feedback, our work
pioneers AI-accelerated, trustworthy catalyst discovery.",2024-02-15,2024,2024-02,chemistry
"Revealing the Relationship Between Publication Bias and Chemical
  Reactivity with Contrastive Learning","A synthetic method's substrate tolerance and generality are often showcased
in a ""substrate scope"" table. However, substrate selection exhibits a
frequently discussed publication bias: unsuccessful experiments or low-yielding
results are rarely reported. In this work, we explore more deeply the
relationship between such publication bias and chemical reactivity beyond the
simple analysis of yield distributions using a novel neural network training
strategy, substrate scope contrastive learning. By treating reported substrates
as positive samples and non-reported substrates as negative samples, our
contrastive learning strategy teaches a model to group molecules within a
numerical embedding space, based on historical trends in published substrate
scope tables. Training on 20,798 aryl halides in the CAS Content
Collection$^{\text{TM}}$, spanning thousands of publications from 2010-2015, we
demonstrate that the learned embeddings exhibit a correlation with physical
organic reactivity descriptors through both intuitive visualizations and
quantitative regression analyses. Additionally, these embeddings are applicable
to various reaction modeling tasks like yield prediction and regioselectivity
prediction, underscoring the potential to use historical reaction data as a
pre-training task. This work not only presents a chemistry-specific machine
learning training strategy to learn from literature data in a new way, but also
represents a unique approach to uncover trends in chemical reactivity reflected
by trends in substrate selection in publications.",2024-02-19,2024,2024-02,chemistry
"An Autonomous Large Language Model Agent for Chemical Literature Data
  Mining","Chemical synthesis, which is crucial for advancing material synthesis and
drug discovery, impacts various sectors including environmental science and
healthcare. The rise of technology in chemistry has generated extensive
chemical data, challenging researchers to discern patterns and refine synthesis
processes. Artificial intelligence (AI) helps by analyzing data to optimize
synthesis and increase yields. However, AI faces challenges in processing
literature data due to the unstructured format and diverse writing style of
chemical literature. To overcome these difficulties, we introduce an end-to-end
AI agent framework capable of high-fidelity extraction from extensive chemical
literature. This AI agent employs large language models (LLMs) for prompt
generation and iterative optimization. It functions as a chemistry assistant,
automating data collection and analysis, thereby saving manpower and enhancing
performance. Our framework's efficacy is evaluated using accuracy, recall, and
F1 score of reaction condition data, and we compared our method with human
experts in terms of content correctness and time efficiency. The proposed
approach marks a significant advancement in automating chemical literature
extraction and demonstrates the potential for AI to revolutionize data
management and utilization in chemistry.",2024-02-20,2024,2024-02,chemistry
"Contextual Molecule Representation Learning from Chemical Reaction
  Knowledge","In recent years, self-supervised learning has emerged as a powerful tool to
harness abundant unlabelled data for representation learning and has been
broadly adopted in diverse areas. However, when applied to molecular
representation learning (MRL), prevailing techniques such as masked sub-unit
reconstruction often fall short, due to the high degree of freedom in the
possible combinations of atoms within molecules, which brings insurmountable
complexity to the masking-reconstruction paradigm. To tackle this challenge, we
introduce REMO, a self-supervised learning framework that takes advantage of
well-defined atom-combination rules in common chemistry. Specifically, REMO
pre-trains graph/Transformer encoders on 1.7 million known chemical reactions
in the literature. We propose two pre-training objectives: Masked Reaction
Centre Reconstruction (MRCR) and Reaction Centre Identification (RCI). REMO
offers a novel solution to MRL by exploiting the underlying shared patterns in
chemical reactions as \textit{context} for pre-training, which effectively
infers meaningful representations of common chemistry knowledge. Such
contextual representations can then be utilized to support diverse downstream
molecular tasks with minimum finetuning, such as affinity prediction and
drug-drug interaction prediction. Extensive experimental results on
MoleculeACE, ACNet, drug-drug interaction (DDI), and reaction type
classification show that across all tested downstream tasks, REMO outperforms
the standard baseline of single-molecule masked modeling used in current MRL.
Remarkably, REMO is the pioneering deep learning model surpassing
fingerprint-based methods in activity cliff benchmarks.",2024-02-21,2024,2024-02,chemistry
"TaxDiff: Taxonomic-Guided Diffusion Model for Protein Sequence
  Generation","Designing protein sequences with specific biological functions and structural
stability is crucial in biology and chemistry. Generative models already
demonstrated their capabilities for reliable protein design. However, previous
models are limited to the unconditional generation of protein sequences and
lack the controllable generation ability that is vital to biological tasks. In
this work, we propose TaxDiff, a taxonomic-guided diffusion model for
controllable protein sequence generation that combines biological species
information with the generative capabilities of diffusion models to generate
structurally stable proteins within the sequence space. Specifically, taxonomic
control information is inserted into each layer of the transformer block to
achieve fine-grained control. The combination of global and local attention
ensures the sequence consistency and structural foldability of
taxonomic-specific proteins. Extensive experiments demonstrate that TaxDiff can
consistently achieve better performance on multiple protein sequence generation
benchmarks in both taxonomic-guided controllable generation and unconditional
generation. Remarkably, the sequences generated by TaxDiff even surpass those
produced by direct-structure-generation models in terms of confidence based on
predicted structures and require only a quarter of the time of models based on
the diffusion model. The code for generating proteins and training new versions
of TaxDiff is available at:https://github.com/Linzy19/TaxDiff.",2024-02-27,2024,2024-02,chemistry
"Leveraging Biomolecule and Natural Language through Multi-Modal
  Learning: A Survey","The integration of biomolecular modeling with natural language (BL) has
emerged as a promising interdisciplinary area at the intersection of artificial
intelligence, chemistry and biology. This approach leverages the rich,
multifaceted descriptions of biomolecules contained within textual data sources
to enhance our fundamental understanding and enable downstream computational
tasks such as biomolecule property prediction. The fusion of the nuanced
narratives expressed through natural language with the structural and
functional specifics of biomolecules described via various molecular modeling
techniques opens new avenues for comprehensively representing and analyzing
biomolecules. By incorporating the contextual language data that surrounds
biomolecules into their modeling, BL aims to capture a holistic view
encompassing both the symbolic qualities conveyed through language as well as
quantitative structural characteristics. In this review, we provide an
extensive analysis of recent advancements achieved through cross modeling of
biomolecules and natural language. (1) We begin by outlining the technical
representations of biomolecules employed, including sequences, 2D graphs, and
3D structures. (2) We then examine in depth the rationale and key objectives
underlying effective multi-modal integration of language and molecular data
sources. (3) We subsequently survey the practical applications enabled to date
in this developing research area. (4) We also compile and summarize the
available resources and datasets to facilitate future work. (5) Looking ahead,
we identify several promising research directions worthy of further exploration
and investment to continue advancing the field. The related resources and
contents are updating in
\url{https://github.com/QizhiPei/Awesome-Biomolecule-Language-Cross-Modeling}.",2024-03-03,2024,2024-03,chemistry
Brilla AI: AI Contestant for the National Science and Maths Quiz,"The African continent lacks enough qualified teachers which hampers the
provision of adequate learning support. An AI could potentially augment the
efforts of the limited number of teachers, leading to better learning outcomes.
Towards that end, this work describes and evaluates the first key output for
the NSMQ AI Grand Challenge, which proposes a robust, real-world benchmark for
such an AI: ""Build an AI to compete live in Ghana's National Science and Maths
Quiz (NSMQ) competition and win - performing better than the best contestants
in all rounds and stages of the competition"". The NSMQ is an annual live
science and mathematics competition for senior secondary school students in
Ghana in which 3 teams of 2 students compete by answering questions across
biology, chemistry, physics, and math in 5 rounds over 5 progressive stages
until a winning team is crowned for that year. In this work, we built Brilla
AI, an AI contestant that we deployed to unofficially compete remotely and live
in the Riddles round of the 2023 NSMQ Grand Finale, the first of its kind in
the 30-year history of the competition. Brilla AI is currently available as a
web app that livestreams the Riddles round of the contest, and runs 4 machine
learning systems: (1) speech to text (2) question extraction (3) question
answering and (4) text to speech that work together in real-time to quickly and
accurately provide an answer, and then say it with a Ghanaian accent. In its
debut, our AI answered one of the 4 riddles ahead of the 3 human contesting
teams, unofficially placing second (tied). Improvements and extensions of this
AI could potentially be deployed to offer science tutoring to students and
eventually enable millions across Africa to have one-on-one learning
interactions, democratizing science education.",2024-03-04,2024,2024-03,chemistry
"MolNexTR: A Generalized Deep Learning Model for Molecular Image
  Recognition","In the field of chemical structure recognition, the task of converting
molecular images into machine-readable data formats such as SMILES string
stands as a significant challenge, primarily due to the varied drawing styles
and conventions prevalent in chemical literature. To bridge this gap, we
proposed MolNexTR, a novel image-to-graph deep learning model that collaborates
to fuse the strengths of ConvNext, a powerful Convolutional Neural Network
variant, and Vision-TRansformer. This integration facilitates a more detailed
extraction of both local and global features from molecular images. MolNexTR
can predict atoms and bonds simultaneously and understand their layout rules.
It also excels at flexibly integrating symbolic chemistry principles to discern
chirality and decipher abbreviated structures. We further incorporate a series
of advanced algorithms, including an improved data augmentation module, an
image contamination module, and a post-processing module for getting the final
SMILES output. These modules cooperate to enhance the model's robustness to
diverse styles of molecular images found in real literature. In our test sets,
MolNexTR has demonstrated superior performance, achieving an accuracy rate of
81-97%, marking a significant advancement in the domain of molecular structure
recognition.",2024-03-06,2024,2024-03,chemistry
"KIF: A Wikidata-Based Framework for Integrating Heterogeneous Knowledge
  Sources","We present a Wikidata-based framework, called KIF, for virtually integrating
heterogeneous knowledge sources. KIF is written in Python and is released as
open-source. It leverages Wikidata's data model and vocabulary plus
user-defined mappings to construct a unified view of the underlying sources
while keeping track of the context and provenance of their statements. The
underlying sources can be triplestores, relational databases, CSV files, etc.,
which may or may not use the vocabulary and RDF encoding of Wikidata. The end
result is a virtual knowledge base which behaves like an ""extended Wikidata""
and which can be queried using a simple but expressive pattern language,
defined in terms of Wikidata's data model. In this paper, we present the design
and implementation of KIF, discuss how we have used it to solve a real
integration problem in the domain of chemistry (involving Wikidata, PubChem,
and IBM CIRCA), and present experimental results on the performance and
overhead of KIF",2024-03-15,2024,2024-03,chemistry
"TransPeakNet: Solvent-Aware 2D NMR Prediction via Multi-Task
  Pre-Training and Unsupervised Learning","Nuclear Magnetic Resonance (NMR) spectroscopy is essential for revealing
molecular structure, electronic environment, and dynamics. Accurate NMR shift
prediction allows researchers to validate structures by comparing predicted and
observed shifts. While Machine Learning (ML) has improved one-dimensional (1D)
NMR shift prediction, predicting 2D NMR remains challenging due to limited
annotated data. To address this, we introduce an unsupervised training
framework for predicting cross-peaks in 2D NMR, specifically Heteronuclear
Single Quantum Coherence (HSQC).Our approach pretrains an ML model on an
annotated 1D dataset of 1H and 13C shifts, then finetunes it in an unsupervised
manner using unlabeled HSQC data, which simultaneously generates cross-peak
annotations. Our model also adjusts for solvent effects. Evaluation on 479
expert-annotated HSQC spectra demonstrates our model's superiority over
traditional methods (ChemDraw and Mestrenova), achieving Mean Absolute Errors
(MAEs) of 2.05 ppm and 0.165 ppm for 13C shifts and 1H shifts respectively. Our
algorithmic annotations show a 95.21% concordance with experts' assignments,
underscoring the approach's potential for structural elucidation in fields like
organic chemistry, pharmaceuticals, and natural products.",2024-03-17,2024,2024-03,chemistry
"PEaCE: A Chemistry-Oriented Dataset for Optical Character Recognition on
  Scientific Documents","Optical Character Recognition (OCR) is an established task with the objective
of identifying the text present in an image. While many off-the-shelf OCR
models exist, they are often trained for either scientific (e.g., formulae) or
generic printed English text. Extracting text from chemistry publications
requires an OCR model that is capable in both realms. Nougat, a recent tool,
exhibits strong ability to parse academic documents, but is unable to parse
tables in PubMed articles, which comprises a significant part of the academic
community and is the focus of this work. To mitigate this gap, we present the
Printed English and Chemical Equations (PEaCE) dataset, containing both
synthetic and real-world records, and evaluate the efficacy of
transformer-based OCR models when trained on this resource. Given that
real-world records contain artifacts not present in synthetic records, we
propose transformations that mimic such qualities. We perform a suite of
experiments to explore the impact of patch size, multi-domain training, and our
proposed transformations, ultimately finding that models with a small patch
size trained on multiple domains using the proposed transformations yield the
best performance. Our dataset and code is available at
https://github.com/ZN1010/PEaCE.",2024-03-23,2024,2024-03,chemistry
"On machine learning analysis of atomic force microscopy images for image
  classification, sample surface recognition","Atomic force microscopy (AFM or SPM) imaging is one of the best matches with
machine learning (ML) analysis among microscopy techniques. The digital format
of AFM images allows for direct utilization in ML algorithms without the need
for additional processing. Additionally, AFM enables the simultaneous imaging
of distributions of over a dozen different physicochemical properties of sample
surfaces, a process known as multidimensional imaging. While this wealth of
information can be challenging to analyze using traditional methods, ML
provides a seamless approach to this task. However, the relatively slow speed
of AFM imaging poses a challenge in applying deep learning methods broadly used
in image recognition. This Prospective is focused on ML
recognition/classification when using a relatively small number of AFM images,
small database. We discuss ML methods other than popular deep-learning neural
networks. The described approach has already been successfully used to analyze
and classify the surfaces of biological cells. It can be applied to recognize
medical images, specific material processing, in forensic studies, even to
identify the authenticity of arts. A general template for ML analysis specific
to AFM is suggested, with a specific example of the identification of cell
phenotype. Special attention is given to the analysis of the statistical
significance of the obtained results, an important feature that is often
overlooked in papers dealing with machine learning. A simple method for finding
statistical significance is also described.",2024-03-24,2024,2024-03,chemistry
Are large language models superhuman chemists?,"Large language models (LLMs) have gained widespread interest due to their
ability to process human language and perform tasks on which they have not been
explicitly trained.
  However, we possess only a limited systematic understanding of the chemical
capabilities of LLMs, which would be required to improve models and mitigate
potential harm. Here, we introduce ""ChemBench,"" an automated framework for
evaluating the chemical knowledge and reasoning abilities of state-of-the-art
LLMs against the expertise of chemists.
  We curated more than 2,700 question-answer pairs, evaluated leading open- and
closed-source LLMs, and found that the best models outperformed the best human
chemists in our study on average. However, the models struggle with some basic
tasks and provide overconfident predictions.
  These findings reveal LLMs' impressive chemical capabilities while
emphasizing the need for further research to improve their safety and
usefulness. They also suggest adapting chemistry education and show the value
of benchmarking frameworks for evaluating LLMs in specific domains.",2024-04-01,2024,2024-04,chemistry
"Graph Reinforcement Learning for Combinatorial Optimization: A Survey
  and Unifying Perspective","Graphs are a natural representation for systems based on relations between
connected entities. Combinatorial optimization problems, which arise when
considering an objective function related to a process of interest on discrete
structures, are often challenging due to the rapid growth of the solution
space. The trial-and-error paradigm of Reinforcement Learning has recently
emerged as a promising alternative to traditional methods, such as exact
algorithms and (meta)heuristics, for discovering better decision-making
strategies in a variety of disciplines including chemistry, computer science,
and statistics. Despite the fact that they arose in markedly different fields,
these techniques share significant commonalities. Therefore, we set out to
synthesize this work in a unifying perspective that we term Graph Reinforcement
Learning, interpreting it as a constructive decision-making method for graph
problems. After covering the relevant technical background, we review works
along the dividing line of whether the goal is to optimize graph structure
given a process of interest, or to optimize the outcome of the process itself
under fixed graph structure. Finally, we discuss the common challenges facing
the field and open research questions. In contrast with other surveys, the
present work focuses on non-canonical graph problems for which performant
algorithms are typically not known and Reinforcement Learning is able to
provide efficient and effective solutions.",2024-04-09,2024,2024-04,chemistry
"Shape Arithmetic Expressions: Advancing Scientific Discovery Beyond
  Closed-Form Equations","Symbolic regression has excelled in uncovering equations from physics,
chemistry, biology, and related disciplines. However, its effectiveness becomes
less certain when applied to experimental data lacking inherent closed-form
expressions. Empirically derived relationships, such as entire stress-strain
curves, may defy concise closed-form representation, compelling us to explore
more adaptive modeling approaches that balance flexibility with
interpretability. In our pursuit, we turn to Generalized Additive Models
(GAMs), a widely used class of models known for their versatility across
various domains. Although GAMs can capture non-linear relationships between
variables and targets, they cannot capture intricate feature interactions. In
this work, we investigate both of these challenges and propose a novel class of
models, Shape Arithmetic Expressions (SHAREs), that fuses GAM's flexible shape
functions with the complex feature interactions found in mathematical
expressions. SHAREs also provide a unifying framework for both of these
approaches. We also design a set of rules for constructing SHAREs that
guarantee transparency of the found expressions beyond the standard constraints
based on the model's size.",2024-04-15,2024,2024-04,chemistry
"Integrating Chemistry Knowledge in Large Language Models via Prompt
  Engineering","This paper presents a study on the integration of domain-specific knowledge
in prompt engineering to enhance the performance of large language models
(LLMs) in scientific domains. A benchmark dataset is curated to encapsulate the
intricate physical-chemical properties of small molecules, their drugability
for pharmacology, alongside the functional attributes of enzymes and crystal
materials, underscoring the relevance and applicability across biological and
chemical domains.The proposed domain-knowledge embedded prompt engineering
method outperforms traditional prompt engineering strategies on various
metrics, including capability, accuracy, F1 score, and hallucination drop. The
effectiveness of the method is demonstrated through case studies on complex
materials including the MacMillan catalyst, paclitaxel, and lithium cobalt
oxide. The results suggest that domain-knowledge prompts can guide LLMs to
generate more accurate and relevant responses, highlighting the potential of
LLMs as powerful tools for scientific discovery and innovation when equipped
with domain-specific prompts. The study also discusses limitations and future
directions for domain-specific prompt engineering development.",2024-04-22,2024,2024-04,chemistry
"Delayed Bottlenecking: Alleviating Forgetting in Pre-trained Graph
  Neural Networks","Pre-training GNNs to extract transferable knowledge and apply it to
downstream tasks has become the de facto standard of graph representation
learning. Recent works focused on designing self-supervised pre-training tasks
to extract useful and universal transferable knowledge from large-scale
unlabeled data. However, they have to face an inevitable question: traditional
pre-training strategies that aim at extracting useful information about
pre-training tasks, may not extract all useful information about the downstream
task. In this paper, we reexamine the pre-training process within traditional
pre-training and fine-tuning frameworks from the perspective of Information
Bottleneck (IB) and confirm that the forgetting phenomenon in pre-training
phase may cause detrimental effects on downstream tasks. Therefore, we propose
a novel \underline{D}elayed \underline{B}ottlenecking \underline{P}re-training
(DBP) framework which maintains as much as possible mutual information between
latent representations and training data during pre-training phase by
suppressing the compression operation and delays the compression operation to
fine-tuning phase to make sure the compression can be guided with labeled
fine-tuning data and downstream tasks. To achieve this, we design two
information control objectives that can be directly optimized and further
integrate them into the actual model design. Extensive experiments on both
chemistry and biology domains demonstrate the effectiveness of DBP.",2024-04-23,2024,2024-04,chemistry
Global Concept Explanations for Graphs by Contrastive Learning,"Beyond improving trust and validating model fairness, xAI practices also have
the potential to recover valuable scientific insights in application domains
where little to no prior human intuition exists. To that end, we propose a
method to extract global concept explanations from the predictions of graph
neural networks to develop a deeper understanding of the tasks underlying
structure-property relationships. We identify concept explanations as dense
clusters in the self-explaining Megan models subgraph latent space. For each
concept, we optimize a representative prototype graph and optionally use GPT-4
to provide hypotheses about why each structure has a certain effect on the
prediction. We conduct computational experiments on synthetic and real-world
graph property prediction tasks. For the synthetic tasks we find that our
method correctly reproduces the structural rules by which they were created.
For real-world molecular property regression and classification tasks, we find
that our method rediscovers established rules of thumb. More specifically, our
results for molecular mutagenicity prediction indicate more fine-grained
resolution of structural details than existing explainability methods,
consistent with previous results from chemistry literature. Overall, our
results show promising capability to extract the underlying structure-property
relationships for complex graph property prediction tasks.",2024-04-25,2024,2024-04,chemistry
"Non-Spatial Hash Chemistry as a Minimalistic Open-Ended Evolutionary
  System","There is an increasing level of interest in open-endedness in the recent
literature of Artificial Life and Artificial Intelligence. We previously
proposed the cardinality leap of possibility spaces as a promising mechanism to
facilitate open-endedness in artificial evolutionary systems, and demonstrated
its effectiveness using Hash Chemistry, an artificial chemistry model that used
a hash function as a universal fitness evaluator. However, the spatial nature
of Hash Chemistry came with extensive computational costs involved in its
simulation, and the particle density limit imposed to prevent explosion of
computational costs prevented unbounded growth in complexity of higher-order
entities. To address these limitations, here we propose a simpler non-spatial
variant of Hash Chemistry in which spatial proximity of particles are
represented explicitly in the form of multisets. This model modification
achieved a significant reduction of computational costs in simulating the
model. Results of numerical simulations showed much more significant unbounded
growth in both maximal and average sizes of replicating higher-order entities
than the original model, demonstrating the effectiveness of this non-spatial
model as a minimalistic example of open-ended evolutionary systems.",2024-04-27,2024,2024-04,chemistry
"AI for Manufacturing and Healthcare: a chemistry and engineering
  perspective","Artificial Intelligence (AI) approaches are increasingly being applied to
more and more domains of Science, Engineering, Chemistry, and Industries to not
only improve efficiencies and enhance productivity, but also enable new
capabilities. The new opportunities range from automated molecule design and
screening, properties prediction, gaining insights of chemical reactions, to
computer-aided design, predictive maintenance of systems, robotics, and
autonomous vehicles. This review focuses on the new applications of AI in
manufacturing and healthcare. For the Manufacturing Industries, we focus on AI
and algorithms for (1) Battery, (2) Flow Chemistry, (3) Additive Manufacturing,
(4) Sensors, and (5) Machine Vision. For Healthcare applications, we focus on:
(1) Medical Vision (2) Diagnosis, (3) Protein Design, and (4) Drug Discovery.
In the end, related topics are discussed, including physics integrated machine
learning, model explainability, security, and governance during model
deployment.",2024-05-02,2024,2024-05,chemistry
CACTUS: Chemistry Agent Connecting Tool-Usage to Science,"Large language models (LLMs) have shown remarkable potential in various
domains, but they often lack the ability to access and reason over
domain-specific knowledge and tools. In this paper, we introduced CACTUS
(Chemistry Agent Connecting Tool-Usage to Science), an LLM-based agent that
integrates cheminformatics tools to enable advanced reasoning and
problem-solving in chemistry and molecular discovery. We evaluate the
performance of CACTUS using a diverse set of open-source LLMs, including
Gemma-7b, Falcon-7b, MPT-7b, Llama2-7b, and Mistral-7b, on a benchmark of
thousands of chemistry questions. Our results demonstrate that CACTUS
significantly outperforms baseline LLMs, with the Gemma-7b and Mistral-7b
models achieving the highest accuracy regardless of the prompting strategy
used. Moreover, we explore the impact of domain-specific prompting and hardware
configurations on model performance, highlighting the importance of prompt
engineering and the potential for deploying smaller models on consumer-grade
hardware without significant loss in accuracy. By combining the cognitive
capabilities of open-source LLMs with domain-specific tools, CACTUS can assist
researchers in tasks such as molecular property prediction, similarity
searching, and drug-likeness assessment. Furthermore, CACTUS represents a
significant milestone in the field of cheminformatics, offering an adaptable
tool for researchers engaged in chemistry and molecular discovery. By
integrating the strengths of open-source LLMs with domain-specific tools,
CACTUS has the potential to accelerate scientific advancement and unlock new
frontiers in the exploration of novel, effective, and safe therapeutic
candidates, catalysts, and materials. Moreover, CACTUS's ability to integrate
with automated experimentation platforms and make data-driven decisions in real
time opens up new possibilities for autonomous discovery.",2024-05-02,2024,2024-05,chemistry
"Single and Multi-Hop Question-Answering Datasets for Reticular Chemistry
  with GPT-4-Turbo","The rapid advancement in artificial intelligence and natural language
processing has led to the development of large-scale datasets aimed at
benchmarking the performance of machine learning models. Herein, we introduce
'RetChemQA,' a comprehensive benchmark dataset designed to evaluate the
capabilities of such models in the domain of reticular chemistry. This dataset
includes both single-hop and multi-hop question-answer pairs, encompassing
approximately 45,000 Q&As for each type. The questions have been extracted from
an extensive corpus of literature containing about 2,530 research papers from
publishers including NAS, ACS, RSC, Elsevier, and Nature Publishing Group,
among others. The dataset has been generated using OpenAI's GPT-4 Turbo, a
cutting-edge model known for its exceptional language understanding and
generation capabilities. In addition to the Q&A dataset, we also release a
dataset of synthesis conditions extracted from the corpus of literature used in
this study. The aim of RetChemQA is to provide a robust platform for the
development and evaluation of advanced machine learning algorithms,
particularly for the reticular chemistry community. The dataset is structured
to reflect the complexities and nuances of real-world scientific discourse,
thereby enabling nuanced performance assessments across a variety of tasks. The
dataset is available at the following link:
https://github.com/nakulrampal/RetChemQA",2024-05-03,2024,2024-05,chemistry
"CVTGAD: Simplified Transformer with Cross-View Attention for
  Unsupervised Graph-level Anomaly Detection","Unsupervised graph-level anomaly detection (UGAD) has received remarkable
performance in various critical disciplines, such as chemistry analysis and
bioinformatics. Existing UGAD paradigms often adopt data augmentation
techniques to construct multiple views, and then employ different strategies to
obtain representations from different views for jointly conducting UGAD.
However, most previous works only considered the relationship between
nodes/graphs from a limited receptive field, resulting in some key structure
patterns and feature information being neglected. In addition, most existing
methods consider different views separately in a parallel manner, which is not
able to explore the inter-relationship across different views directly. Thus, a
method with a larger receptive field that can explore the inter-relationship
across different views directly is in need. In this paper, we propose a novel
Simplified Transformer with Cross-View Attention for Unsupervised Graph-level
Anomaly Detection, namely, CVTGAD. To increase the receptive field, we
construct a simplified transformer-based module, exploiting the relationship
between nodes/graphs from both intra-graph and inter-graph perspectives.
Furthermore, we design a cross-view attention mechanism to directly exploit the
view co-occurrence between different views, bridging the inter-view gap at node
level and graph level. To the best of our knowledge, this is the first work to
apply transformer and cross attention to UGAD, which realizes graph neural
network and transformer working collaboratively. Extensive experiments on 15
real-world datasets of 3 fields demonstrate the superiority of CVTGAD on the
UGAD task. The code is available at
\url{https://github.com/jindongli-Ai/CVTGAD}.",2024-05-03,2024,2024-05,chemistry
"Multi-task learning for molecular electronic structure approaching
  coupled-cluster accuracy","Machine learning (ML) plays an important role in quantum chemistry, providing
fast-to-evaluate predictive models for various properties of molecules.
However, most existing ML models for molecular electronic properties use
density functional theory (DFT) databases as ground truth in training, and
their prediction accuracy cannot surpass that of DFT. In this work, we
developed a unified ML method for electronic structures of organic molecules
using the gold-standard CCSD(T) calculations as training data. Tested on
hydrocarbon molecules, our model outperforms DFT with the widely-used hybrid
and double hybrid functionals in computational costs and prediction accuracy of
various quantum chemical properties. As case studies, we apply the model to
aromatic compounds and semiconducting polymers on both ground state and excited
state properties, demonstrating its accuracy and generalization capability to
complex systems that are hard to calculate using CCSD(T)-level methods.",2024-05-09,2024,2024-05,chemistry
"Beyond traditional Magnetic Resonance processing with Artificial
  Intelligence","Smart signal processing approaches using Artificial Intelligence are gaining
momentum in NMR applications. In this study, we demonstrate that AI offers new
opportunities beyond tasks addressed by traditional techniques. We developed
and trained several artificial neural networks in our new toolbox Magnetic
Resonance with Artificial intelligence (MR-Ai) to solve three ""impossible""
problems: quadrature detection using only Echo (or Anti-Echo) modulation from
the traditional Echo/Anti-Echo scheme; accessing uncertainty of signal
intensity at each point in a spectrum processed by any given method; and
defining a reference-free score for quantitative access of NMR spectrum
quality. Our findings highlight the potential of AI techniques to revolutionize
NMR processing and analysis.",2024-05-13,2024,2024-05,chemistry
"ALMol: Aligned Language-Molecule Translation LLMs through Offline
  Preference Contrastive Optimisation","The field of chemistry and Artificial Intelligence (AI) intersection is an
area of active research that aims to accelerate scientific discovery. The
integration of large language models (LLMs) with scientific modalities has
shown significant promise in this endeavour. However, challenges persist in
effectively addressing training efficacy and the out-of-distribution problem,
particularly as existing approaches rely on larger models and datasets. In this
context, we focus on machine language-molecule translation and deploy a novel
training approach called contrastive preference optimisation, which avoids
generating translations that are merely adequate but not perfect. To ensure
generalisability and mitigate memorisation effects, we conduct experiments
using only 10% of the data. Our results demonstrate that our models achieve up
to a 32% improvement compared to counterpart models. Finally, we introduce a
fine-grained, domain-agnostic evaluation method to assess hallucination in LLMs
and promote responsible use.",2024-05-14,2024,2024-05,chemistry
"Specialising and Analysing Instruction-Tuned and Byte-Level Language
  Models for Organic Reaction Prediction","Transformer-based encoder-decoder models have demonstrated impressive results
in chemical reaction prediction tasks. However, these models typically rely on
pretraining using tens of millions of unlabelled molecules, which can be
time-consuming and GPU-intensive. One of the central questions we aim to answer
in this work is: Can FlanT5 and ByT5, the encode-decoder models pretrained
solely on language data, be effectively specialised for organic reaction
prediction through task-specific fine-tuning? We conduct a systematic empirical
study on several key issues of the process, including tokenisation, the impact
of (SMILES-oriented) pretraining, fine-tuning sample efficiency, and decoding
algorithms at inference. Our key findings indicate that although being
pretrained only on language tasks, FlanT5 and ByT5 provide a solid foundation
to fine-tune for reaction prediction, and thus become `chemistry domain
compatible' in the process. This suggests that GPU-intensive and expensive
pretraining on a large dataset of unlabelled molecules may be useful yet not
essential to leverage the power of language models for chemistry. All our
models achieve comparable Top-1 and Top-5 accuracy although some variation
across different models does exist. Notably, tokenisation and vocabulary
trimming slightly affect final performance but can speed up training and
inference; The most efficient greedy decoding strategy is very competitive
while only marginal gains can be achieved from more sophisticated decoding
algorithms. In summary, we evaluate FlanT5 and ByT5 across several dimensions
and benchmark their impact on organic reaction prediction, which may guide more
effective use of these state-of-the-art language models for chemistry-related
tasks in the future.",2024-05-17,2024,2024-05,chemistry
Retro-prob: Retrosynthetic Planning Based on a Probabilistic Model,"Retrosynthesis is a fundamental but challenging task in organic chemistry,
with broad applications in fields such as drug design and synthesis. Given a
target molecule, the goal of retrosynthesis is to find out a series of
reactions which could be assembled into a synthetic route which starts from
purchasable molecules and ends at the target molecule. The uncertainty of
reactions used in retrosynthetic planning, which is caused by hallucinations of
backward models, has recently been noticed. In this paper we propose a succinct
probabilistic model to describe such uncertainty. Based on the model, we
propose a new retrosynthesis planning algorithm called retro-prob to maximize
the successful synthesis probability of target molecules, which acquires high
efficiency by utilizing the chain rule of derivatives. Experiments on the
Paroutes benchmark show that retro-prob outperforms previous algorithms, retro*
and retro-fallback, both in speed and in the quality of synthesis plans.",2024-05-25,2024,2024-05,chemistry
"SE3Set: Harnessing equivariant hypergraph neural networks for molecular
  representation learning","In this paper, we develop SE3Set, an SE(3) equivariant hypergraph neural
network architecture tailored for advanced molecular representation learning.
Hypergraphs are not merely an extension of traditional graphs; they are pivotal
for modeling high-order relationships, a capability that conventional
equivariant graph-based methods lack due to their inherent limitations in
representing intricate many-body interactions. To achieve this, we first
construct hypergraphs via proposing a new fragmentation method that considers
both chemical and three-dimensional spatial information of molecular system. We
then design SE3Set, which incorporates equivariance into the hypergragh neural
network. This ensures that the learned molecular representations are invariant
to spatial transformations, thereby providing robustness essential for accurate
prediction of molecular properties. SE3Set has shown performance on par with
state-of-the-art (SOTA) models for small molecule datasets like QM9 and MD17.
It excels on the MD22 dataset, achieving a notable improvement of approximately
20% in accuracy across all molecules, which highlights the prevalence of
complex many-body interactions in larger molecules. This exceptional
performance of SE3Set across diverse molecular structures underscores its
transformative potential in computational chemistry, offering a route to more
accurate and physically nuanced modeling.",2024-05-26,2024,2024-05,chemistry
RLSF: Reinforcement Learning via Symbolic Feedback,"Reinforcement Learning with Human Feedback (RLHF) is considered a standard
approach to fine-tuning Large Language Models (LLMs). However, such methods
often face limitations such as unsound black-box reward models, difficulties in
collecting human preference data, and the reliance on sparse scalar rewards.
These methods often fall short when applied to tasks that require complex
domain-specific understanding.
  To address these challenges, we propose a new fine-tuning paradigm we refer
to as Reinforcement Learning via Symbolic Feedback (RLSF), which aims to
improve domain-specific understanding of LLMs more effectively than traditional
reward signals. In the RLSF setting, the LLM being fine-tuned is considered an
RL agent, while the environment is allowed access to reasoning or domain
knowledge tools (e.g., solvers, provers, algebra systems, or knowledge bases).
Crucially, in RLSF, these reasoning tools can provide feedback to the LLMs via
poly-sized certificates (e.g., proofs), that characterize errors in the
LLM-generated object with respect to some correctness specification. As a
bonus, our RLSF approach does not require the reasoning systems we use to be
differentiable. The ability of RLSF-based fine-tuning to leverage
certificate-generating symbolic tools enables sound fine-grained (token-level)
reward signals to LLMs, and thus addresses the limitations of traditional
reward models mentioned above.
  Via extensive evaluations, we show that our RLSF-based fine-tuning of LLMs
outperforms traditional approaches on five different applications, namely,
program synthesis from natural language pseudo-code to programming language,
three chemistry tasks, and solving the Game of 24. A takeaway is that
fine-tuning via RLSF enables relatively smaller LLMs to significantly
outperform closed-source models that are orders of magnitude larger (e.g.,
GPT-4).",2024-05-26,2024,2024-05,chemistry
UniIF: Unified Molecule Inverse Folding,"Molecule inverse folding has been a long-standing challenge in chemistry and
biology, with the potential to revolutionize drug discovery and material
science. Despite specified models have been proposed for different small- or
macro-molecules, few have attempted to unify the learning process, resulting in
redundant efforts. Complementary to recent advancements in molecular structure
prediction, such as RoseTTAFold All-Atom and AlphaFold3, we propose the unified
model UniIF for the inverse folding of all molecules. We do such unification in
two levels: 1) Data-Level: We propose a unified block graph data form for all
molecules, including the local frame building and geometric feature
initialization. 2) Model-Level: We introduce a geometric block attention
network, comprising a geometric interaction, interactive attention and virtual
long-term dependency modules, to capture the 3D interactions of all molecules.
Through comprehensive evaluations across various tasks such as protein design,
RNA design, and material design, we demonstrate that our proposed method
surpasses state-of-the-art methods on all tasks. UniIF offers a versatile and
effective solution for general molecule inverse folding.",2024-05-29,2024,2024-05,chemistry
Quo Vadis ChatGPT? From Large Language Models to Large Knowledge Models,"The startling success of ChatGPT and other large language models (LLMs) using
transformer-based generative neural network architecture in applications such
as natural language processing and image synthesis has many researchers excited
about potential opportunities in process systems engineering (PSE). The almost
human-like performance of LLMs in these areas is indeed very impressive,
surprising, and a major breakthrough. Their capabilities are very useful in
certain tasks, such as writing first drafts of documents, code writing
assistance, text summarization, etc. However, their success is limited in
highly scientific domains as they cannot yet reason, plan, or explain due to
their lack of in-depth domain knowledge. This is a problem in domains such as
chemical engineering as they are governed by fundamental laws of physics and
chemistry (and biology), constitutive relations, and highly technical knowledge
about materials, processes, and systems. Although purely data-driven machine
learning has its immediate uses, the long-term success of AI in scientific and
engineering domains would depend on developing hybrid AI systems that use first
principles and technical knowledge effectively. We call these hybrid AI systems
Large Knowledge Models (LKMs), as they will not be limited to only NLP-based
techniques or NLP-like applications. In this paper, we discuss the challenges
and opportunities in developing such systems in chemical engineering.",2024-05-29,2024,2024-05,chemistry
An Automatic Question Usability Evaluation Toolkit,"Evaluating multiple-choice questions (MCQs) involves either labor intensive
human assessments or automated methods that prioritize readability, often
overlooking deeper question design flaws. To address this issue, we introduce
the Scalable Automatic Question Usability Evaluation Toolkit (SAQUET), an
open-source tool that leverages the Item-Writing Flaws (IWF) rubric for a
comprehensive and automated quality evaluation of MCQs. By harnessing the
latest in large language models such as GPT-4, advanced word embeddings, and
Transformers designed to analyze textual complexity, SAQUET effectively
pinpoints and assesses a wide array of flaws in MCQs. We first demonstrate the
discrepancy between commonly used automated evaluation metrics and the human
assessment of MCQ quality. Then we evaluate SAQUET on a diverse dataset of MCQs
across the five domains of Chemistry, Statistics, Computer Science, Humanities,
and Healthcare, showing how it effectively distinguishes between flawed and
flawless questions, providing a level of analysis beyond what is achievable
with traditional metrics. With an accuracy rate of over 94% in detecting the
presence of flaws identified by human evaluators, our findings emphasize the
limitations of existing evaluation methods and showcase potential in improving
the quality of educational assessments.",2024-05-30,2024,2024-05,chemistry
"Automated Generation and Tagging of Knowledge Components from
  Multiple-Choice Questions","Knowledge Components (KCs) linked to assessments enhance the measurement of
student learning, enrich analytics, and facilitate adaptivity. However,
generating and linking KCs to assessment items requires significant effort and
domain-specific knowledge. To streamline this process for higher-education
courses, we employed GPT-4 to generate KCs for multiple-choice questions (MCQs)
in Chemistry and E-Learning. We analyzed discrepancies between the KCs
generated by the Large Language Model (LLM) and those made by humans through
evaluation from three domain experts in each subject area. This evaluation
aimed to determine whether, in instances of non-matching KCs, evaluators showed
a preference for the LLM-generated KCs over their human-created counterparts.
We also developed an ontology induction algorithm to cluster questions that
assess similar KCs based on their content. Our most effective LLM strategy
accurately matched KCs for 56% of Chemistry and 35% of E-Learning MCQs, with
even higher success when considering the top five KC suggestions. Human
evaluators favored LLM-generated KCs, choosing them over human-assigned ones
approximately two-thirds of the time, a preference that was statistically
significant across both domains. Our clustering algorithm successfully grouped
questions by their underlying KCs without needing explicit labels or contextual
information. This research advances the automation of KC generation and
classification for assessment items, alleviating the need for student data or
predefined KC labels.",2024-05-30,2024,2024-05,chemistry
Molecular Modelling of Aqueous Batteries,"Aqueous batteries play an increasingly important role for the development of
sustainable and safety-prioritised energy storage solutions. Compared to
conventional lithium-ion batteries, the cell chemistry in aqueous batteries
share many common features with those of electrolyzer and pseudo-capacitor
systems because of the involvement of aqueous electrolyte and proton activity.
This imposes the needs for a better understanding of the corresponding ion
solvation, intercalation and electron transfer processes at atomistic scale.
Therefore, this chapter provides an up-to-date overview of molecular modelling
techniques and their applications in aqueous batteries. In particular, we
emphasize on the dynamical and reactive description of aqueous battery systems
brought in by density functional theory-based molecular dynamics simulation
(DFTMD) and its machine-learning (ML) accelerated counterpart. Moreover, we
also cover the recent advancement of generative artificial intelligence (AI) in
molecular and materials design of aqueous batteries. Case studies presented
here include popular aqueous battery systems, such as water-in-salt
electrolytes, proton-coupled cathode materials, Zn-ion batteries as well as
organic redox flow batteries.",2024-06-01,2024,2024-06,chemistry
Evaluating the World Model Implicit in a Generative Model,"Recent work suggests that large language models may implicitly learn world
models. How should we assess this possibility? We formalize this question for
the case where the underlying reality is governed by a deterministic finite
automaton. This includes problems as diverse as simple logical reasoning,
geographic navigation, game-playing, and chemistry. We propose new evaluation
metrics for world model recovery inspired by the classic Myhill-Nerode theorem
from language theory. We illustrate their utility in three domains: game
playing, logic puzzles, and navigation. In all domains, the generative models
we consider do well on existing diagnostics for assessing world models, but our
evaluation metrics reveal their world models to be far less coherent than they
appear. Such incoherence creates fragility: using a generative model to solve
related but subtly different tasks can lead to failures. Building generative
models that meaningfully capture the underlying logic of the domains they model
would be immensely valuable; our results suggest new ways to assess how close a
given model is to that goal.",2024-06-06,2024,2024-06,chemistry
FlowMM: Generating Materials with Riemannian Flow Matching,"Crystalline materials are a fundamental component in next-generation
technologies, yet modeling their distribution presents unique computational
challenges. Of the plausible arrangements of atoms in a periodic lattice only a
vanishingly small percentage are thermodynamically stable, which is a key
indicator of the materials that can be experimentally realized. Two fundamental
tasks in this area are to (a) predict the stable crystal structure of a known
composition of elements and (b) propose novel compositions along with their
stable structures. We present FlowMM, a pair of generative models that achieve
state-of-the-art performance on both tasks while being more efficient and more
flexible than competing methods. We generalize Riemannian Flow Matching to suit
the symmetries inherent to crystals: translation, rotation, permutation, and
periodic boundary conditions. Our framework enables the freedom to choose the
flow base distributions, drastically simplifying the problem of learning
crystal structures compared with diffusion models. In addition to standard
benchmarks, we validate FlowMM's generated structures with quantum chemistry
calculations, demonstrating that it is about 3x more efficient, in terms of
integration steps, at finding stable materials compared to previous open
methods.",2024-06-07,2024,2024-06,chemistry
"MolX: Enhancing Large Language Models for Molecular Learning with A
  Multi-Modal Extension","Large Language Models (LLMs) with their strong task-handling capabilities
have shown remarkable advancements across a spectrum of fields, moving beyond
natural language understanding. However, their proficiency within the chemistry
domain remains restricted, especially in solving professional molecule-related
tasks. This challenge is attributed to their inherent limitations in
comprehending molecules using only common textual representations, i.e., SMILES
strings. In this study, we seek to enhance the ability of LLMs to comprehend
molecules by equipping them with a multi-modal external module, namely MolX. In
particular, instead of directly using a SMILES string to represent a molecule,
we utilize specific encoders to extract fine-grained features from both SMILES
string and 2D molecular graph representations for feeding into an LLM.
Moreover, a handcrafted molecular fingerprint is incorporated to leverage its
embedded domain knowledge. Then, to establish an alignment between MolX and the
LLM's textual input space, the whole model in which the LLM is frozen, is
pre-trained with a versatile strategy including a diverse set of tasks.
Experimental evaluations show that our proposed method outperforms baselines
across 4 downstream molecule-related tasks ranging from molecule-to-text
translation to retrosynthesis, with and without fine-tuning the LLM, while only
introducing a small number of trainable parameters 0.53% and 0.82%,
respectively.",2024-06-10,2024,2024-06,chemistry
"SciRIFF: A Resource to Enhance Language Model Instruction-Following over
  Scientific Literature","We present SciRIFF (Scientific Resource for Instruction-Following and
Finetuning), a dataset of 137K instruction-following demonstrations for 54
tasks covering five essential scientific literature understanding capabilities:
information extraction, summarization, question answering, claim verification,
and classification. SciRIFF demonstrations are notable for their long input
contexts, detailed task specifications, and complex structured outputs. While
instruction-following resources are available in specific domains such as
clinical medicine and chemistry, SciRIFF is the first dataset focused on
extracting and synthesizing information from research literature across a wide
range of scientific fields. To demonstrate the utility of SciRIFF, we develop a
sample-efficient strategy to adapt a general instruction-following model for
science by performing additional finetuning on a mix of general-domain and
SciRIFF demonstrations. In evaluations on nine held-out scientific tasks, our
model -- called SciTulu -- improves over a strong LLM baseline by 28.1% and
6.5% at the 7B and 70B scales respectively, while maintaining general
instruction-following performance within 2% of the baseline. We are optimistic
that SciRIFF will facilitate the development and evaluation of LLMs to help
researchers navigate the ever-growing body of scientific literature. We release
our dataset, model checkpoints, and data processing and evaluation code to
enable further research.",2024-06-10,2024,2024-06,chemistry
Are Large Language Models Good Statisticians?,"Large Language Models (LLMs) have demonstrated impressive capabilities across
a range of scientific tasks including mathematics, physics, and chemistry.
Despite their successes, the effectiveness of LLMs in handling complex
statistical tasks remains systematically under-explored. To bridge this gap, we
introduce StatQA, a new benchmark designed for statistical analysis tasks.
StatQA comprises 11,623 examples tailored to evaluate LLMs' proficiency in
specialized statistical tasks and their applicability assessment capabilities,
particularly for hypothesis testing methods. We systematically experiment with
representative LLMs using various prompting strategies and show that even
state-of-the-art models such as GPT-4o achieve a best performance of only
64.83%, indicating significant room for improvement. Notably, while open-source
LLMs (e.g. LLaMA-3) show limited capability, those fine-tuned ones exhibit
marked improvements, outperforming all in-context learning-based methods (e.g.
GPT-4o). Moreover, our comparative human experiments highlight a striking
contrast in error types between LLMs and humans: LLMs primarily make
applicability errors, whereas humans mostly make statistical task confusion
errors. This divergence highlights distinct areas of proficiency and
deficiency, suggesting that combining LLM and human expertise could lead to
complementary strengths, inviting further investigation into their
collaborative potential. Our source code and data are available at
https://statqa.github.io/.",2024-06-12,2024,2024-06,chemistry
"Deep Learning Domain Adaptation to Understand Physico-Chemical Processes
  from Fluorescence Spectroscopy Small Datasets: Application to Ageing of Olive
  Oil","Fluorescence spectroscopy is a fundamental tool in life sciences and
chemistry, widely used for applications such as environmental monitoring, food
quality control, and biomedical diagnostics. However, analysis of spectroscopic
data with deep learning, in particular of fluorescence excitation-emission
matrices (EEMs), presents significant challenges due to the typically small and
sparse datasets available. Furthermore, the analysis of EEMs is difficult due
to their high dimensionality and overlapping spectral features. This study
proposes a new approach that exploits domain adaptation with pretrained vision
models, alongside a novel interpretability algorithm to address these
challenges. Thanks to specialised feature engineering of the neural networks
described in this work, we are now able to provide deeper insights into the
physico-chemical processes underlying the data. The proposed approach is
demonstrated through the analysis of the oxidation process in extra virgin
olive oil (EVOO) during ageing, showing its effectiveness in predicting quality
indicators and identifying the spectral bands, and thus the molecules involved
in the process. This work describes a significantly innovative approach in the
use of deep learning for spectroscopy, transforming it from a black box into a
tool for understanding complex biological and chemical processes.",2024-06-14,2024,2024-06,chemistry
PRESTO: Progressive Pretraining Enhances Synthetic Chemistry Outcomes,"Multimodal Large Language Models (MLLMs) have seen growing adoption across
various scientific disciplines. These advancements encourage the investigation
of molecule-text modeling within synthetic chemistry, a field dedicated to
designing and conducting chemical reactions to synthesize new compounds with
desired properties and applications. Current approaches, however, often neglect
the critical role of multiple molecule graph interaction in understanding
chemical reactions, leading to suboptimal performance in synthetic chemistry
tasks. This study introduces PRESTO(Progressive Pretraining Enhances Synthetic
Chemistry Outcomes), a new framework that bridges the molecule-text modality
gap by integrating a comprehensive benchmark of pretraining strategies and
dataset configurations. It progressively improves multimodal LLMs through
cross-modal alignment and multi-graph understanding. Our extensive experiments
demonstrate that PRESTO offers competitive results in downstream synthetic
chemistry tasks. The code can be found at https://github.com/IDEA-XL/PRESTO.",2024-06-19,2024,2024-06,chemistry
"MR-Ben: A Meta-Reasoning Benchmark for Evaluating System-2 Thinking in
  LLMs","Large language models (LLMs) have shown increasing capability in
problem-solving and decision-making, largely based on the step-by-step
chain-of-thought reasoning processes. However, evaluating these reasoning
abilities has become increasingly challenging. Existing outcome-based
benchmarks are beginning to saturate, becoming less effective in tracking
meaningful progress. To address this, we present a process-based benchmark
MR-Ben that demands a meta-reasoning skill, where LMs are asked to locate and
analyse potential errors in automatically generated reasoning steps. Our
meta-reasoning paradigm is especially suited for system-2 slow thinking,
mirroring the human cognitive process of carefully examining assumptions,
conditions, calculations, and logic to identify mistakes.MR-Ben comprises 5,975
questions curated by human experts across a wide range of subjects, including
physics, chemistry, logic, coding, and more. Through our designed metrics for
assessing meta-reasoning on this benchmark, we identify interesting limitations
and weaknesses of current LLMs (open-source and closed-source models). For
example, with models like the o1 series from OpenAI demonstrating strong
performance by effectively scrutinizing the solution space, many other
state-of-the-art models fall significantly behind on MR-Ben, exposing potential
shortcomings in their training strategies and inference methodologies.",2024-06-20,2024,2024-06,chemistry
"From Text to Test: AI-Generated Control Software for Materials Science
  Instruments","Large language models (LLMs) are transforming the landscape of chemistry and
materials science. Recent examples of LLM-accelerated experimental research
include virtual assistants for parsing synthesis recipes from the literature,
or using the extracted knowledge to guide synthesis and characterization.
Despite these advancements, their application is constrained to labs with
automated instruments and control software, leaving much of materials science
reliant on manual processes. Here, we demonstrate the rapid deployment of a
Python-based control module for a Keithley 2400 electrical source measure unit
using ChatGPT-4. Through iterative refinement, we achieved effective instrument
management with minimal human intervention. Additionally, a user-friendly
graphical user interface (GUI) was created, effectively linking all instrument
controls to interactive screen elements. Finally, we integrated this AI-crafted
instrument control software with a high-performance stochastic optimization
algorithm to facilitate rapid and automated extraction of electronic device
parameters related to semiconductor charge transport mechanisms from
current-voltage (IV) measurement data. This integration resulted in a
comprehensive open-source toolkit for semiconductor device characterization and
analysis using IV curve measurements. We demonstrate the application of these
tools by acquiring, analyzing, and parameterizing IV data from a
Pt/Cr$_2$O$_3$:Mg/$\beta$-Ga$_2$O$_3$ heterojunction diode, a novel stack for
high-power and high-temperature electronic devices. This approach underscores
the powerful synergy between LLMs and the development of instruments for
scientific inquiry, showcasing a path for further acceleration in materials
science.",2024-06-23,2024,2024-06,chemistry
"Efficient Evolutionary Search Over Chemical Space with Large Language
  Models","Molecular discovery, when formulated as an optimization problem, presents
significant computational challenges because optimization objectives can be
non-differentiable. Evolutionary Algorithms (EAs), often used to optimize
black-box objectives in molecular discovery, traverse chemical space by
performing random mutations and crossovers, leading to a large number of
expensive objective evaluations. In this work, we ameliorate this shortcoming
by incorporating chemistry-aware Large Language Models (LLMs) into EAs. Namely,
we redesign crossover and mutation operations in EAs using LLMs trained on
large corpora of chemical information. We perform extensive empirical studies
on both commercial and open-source models on multiple tasks involving property
optimization, molecular rediscovery, and structure-based drug design,
demonstrating that the joint usage of LLMs with EAs yields superior performance
over all baseline models across single- and multi-objective settings. We
demonstrate that our algorithm improves both the quality of the final solution
and convergence speed, thereby reducing the number of required objective
evaluations. Our code is available at http://github.com/zoom-wang112358/MOLLEO",2024-06-23,2024,2024-06,chemistry
OlympicArena Medal Ranks: Who Is the Most Intelligent AI So Far?,"In this report, we pose the following question: Who is the most intelligent
AI model to date, as measured by the OlympicArena (an Olympic-level,
multi-discipline, multi-modal benchmark for superintelligent AI)? We
specifically focus on the most recently released models: Claude-3.5-Sonnet,
Gemini-1.5-Pro, and GPT-4o. For the first time, we propose using an Olympic
medal Table approach to rank AI models based on their comprehensive performance
across various disciplines. Empirical results reveal: (1) Claude-3.5-Sonnet
shows highly competitive overall performance over GPT-4o, even surpassing
GPT-4o on a few subjects (i.e., Physics, Chemistry, and Biology). (2)
Gemini-1.5-Pro and GPT-4V are ranked consecutively just behind GPT-4o and
Claude-3.5-Sonnet, but with a clear performance gap between them. (3) The
performance of AI models from the open-source community significantly lags
behind these proprietary models. (4) The performance of these models on this
benchmark has been less than satisfactory, indicating that we still have a long
way to go before achieving superintelligence. We remain committed to
continuously tracking and evaluating the performance of the latest powerful
models on this benchmark (available at
https://github.com/GAIR-NLP/OlympicArena).",2024-06-24,2024,2024-06,chemistry
KANQAS: Kolmogorov-Arnold Network for Quantum Architecture Search,"Quantum architecture Search (QAS) is a promising direction for optimization
and automated design of quantum circuits towards quantum advantage. Recent
techniques in QAS emphasize Multi-Layer Perceptron (MLP)-based deep Q-networks.
However, their interpretability remains challenging due to the large number of
learnable parameters and the complexities involved in selecting appropriate
activation functions. In this work, to overcome these challenges, we utilize
the Kolmogorov-Arnold Network (KAN) in the QAS algorithm, analyzing their
efficiency in the task of quantum state preparation and quantum chemistry. In
quantum state preparation, our results show that in a noiseless scenario, the
probability of success is 2 to 5 times higher than MLPs. In noisy environments,
KAN outperforms MLPs in fidelity when approximating these states, showcasing
its robustness against noise. In tackling quantum chemistry problems, we
enhance the recently proposed QAS algorithm by integrating curriculum
reinforcement learning with a KAN structure. This facilitates a more efficient
design of parameterized quantum circuits by reducing the number of required
2-qubit gates and circuit depth. Further investigation reveals that KAN
requires a significantly smaller number of learnable parameters compared to
MLPs; however, the average time of executing each episode for KAN is higher.",2024-06-25,2024,2024-06,chemistry
A Review of Large Language Models and Autonomous Agents in Chemistry,"Large language models (LLMs) have emerged as powerful tools in chemistry,
significantly impacting molecule design, property prediction, and synthesis
optimization. This review highlights LLM capabilities in these domains and
their potential to accelerate scientific discovery through automation. We also
review LLM-based autonomous agents: LLMs with a broader set of tools to
interact with their surrounding environment. These agents perform diverse tasks
such as paper scraping, interfacing with automated laboratories, and synthesis
planning. As agents are an emerging topic, we extend the scope of our review of
agents beyond chemistry and discuss across any scientific domains. This review
covers the recent history, current capabilities, and design of LLMs and
autonomous agents, addressing specific challenges, opportunities, and future
directions in chemistry. Key challenges include data quality and integration,
model interpretability, and the need for standard benchmarks, while future
directions point towards more sophisticated multi-modal agents and enhanced
collaboration between agents and experimental methods. Due to the quick pace of
this field, a repository has been built to keep track of the latest studies:
https://github.com/ur-whitelab/LLMs-in-science.",2024-06-26,2024,2024-06,chemistry
"PharmaGPT: Domain-Specific Large Language Models for Bio-Pharmaceutical
  and Chemistry","Large language models (LLMs) have revolutionized Natural Language Processing
(NLP) by minimizing the need for complex feature engineering. However, the
application of LLMs in specialized domains like biopharmaceuticals and
chemistry remains largely unexplored. These fields are characterized by
intricate terminologies, specialized knowledge, and a high demand for precision
areas where general purpose LLMs often fall short. In this study, we introduce
PharmaGPT, a suite of domain specilized LLMs with 13 billion and 70 billion
parameters, specifically trained on a comprehensive corpus tailored to the
Bio-Pharmaceutical and Chemical domains. Our evaluation shows that PharmaGPT
surpasses existing general models on specific-domain benchmarks such as NAPLEX,
demonstrating its exceptional capability in domain-specific tasks. Remarkably,
this performance is achieved with a model that has only a fraction, sometimes
just one-tenth-of the parameters of general-purpose large models. This
advancement establishes a new benchmark for LLMs in the bio-pharmaceutical and
chemical fields, addressing the existing gap in specialized language modeling.
It also suggests a promising path for enhanced research and development, paving
the way for more precise and effective NLP applications in these areas.",2024-06-26,2024,2024-06,chemistry
Machine learning meets mass spectrometry: a focused perspective,"Mass spectrometry is a widely used method to study molecules and processes in
medicine, life sciences, chemistry, catalysis, and industrial product quality
control, among many other applications. One of the main features of some mass
spectrometry techniques is the extensive level of characterization (especially
when coupled with chromatography and ion mobility methods, or a part of tandem
mass spectrometry experiment) and a large amount of generated data per
measurement. Terabyte scales can be easily reached with mass spectrometry
studies. Consequently, mass spectrometry has faced the challenge of a high
level of data disappearance. Researchers often neglect and then altogether lose
access to the rich information mass spectrometry experiments could provide.
With the development of machine learning methods, the opportunity arises to
unlock the potential of these data, enabling previously inaccessible
discoveries. The present perspective highlights reevaluation of mass
spectrometry data analysis in the new generation of methods and describes
significant challenges in the field, particularly related to problems involving
the use of electrospray ionization. We argue that further applications of
machine learning raise new requirements for instrumentation (increasing
throughput and information density, decreasing pricing, and making more
automation-friendly software), and once met, the field may experience
significant transformation.",2024-06-27,2024,2024-06,chemistry
On the Expressive Power of Sparse Geometric MPNNs,"Motivated by applications in chemistry and other sciences, we study the
expressive power of message-passing neural networks for geometric graphs, whose
node features correspond to 3-dimensional positions. Recent work has shown that
such models can separate generic pairs of non-isomorphic geometric graphs,
though they may fail to separate some rare and complicated instances. However,
these results assume a fully connected graph, where each node possesses
complete knowledge of all other nodes. In contrast, often, in application,
every node only possesses knowledge of a small number of nearest neighbors.
  This paper shows that generic pairs of non-isomorphic geometric graphs can be
separated by message-passing networks with rotation equivariant features as
long as the underlying graph is connected. When only invariant intermediate
features are allowed, generic separation is guaranteed for generically globally
rigid graphs. We introduce a simple architecture, EGENNET, which achieves our
theoretical guarantees and compares favorably with alternative architecture on
synthetic and chemical benchmarks. Our code is available at
https://github.com/yonatansverdlov/E-GenNet.",2024-07-02,2024,2024-07,chemistry
"Unraveling Molecular Structure: A Multimodal Spectroscopic Dataset for
  Chemistry","Spectroscopic techniques are essential tools for determining the structure of
molecules. Different spectroscopic techniques, such as Nuclear magnetic
resonance (NMR), Infrared spectroscopy, and Mass Spectrometry, provide insight
into the molecular structure, including the presence or absence of functional
groups. Chemists leverage the complementary nature of the different methods to
their advantage. However, the lack of a comprehensive multimodal dataset,
containing spectra from a variety of spectroscopic techniques, has limited
machine-learning approaches mostly to single-modality tasks for predicting
molecular structures from spectra. Here we introduce a dataset comprising
simulated $^1$H-NMR, $^{13}$C-NMR, HSQC-NMR, Infrared, and Mass spectra
(positive and negative ion modes) for 790k molecules extracted from chemical
reactions in patent data. This dataset enables the development of foundation
models for integrating information from multiple spectroscopic modalities,
emulating the approach employed by human experts. Additionally, we provide
benchmarks for evaluating single-modality tasks such as structure elucidation,
predicting the spectra for a target molecule, and functional group predictions.
This dataset has the potential automate structure elucidation, streamlining the
molecular discovery pipeline from synthesis to structure determination. The
dataset and code for the benchmarks can be found at
https://rxn4chemistry.github.io/multimodal-spectroscopic-dataset.",2024-07-04,2024,2024-07,chemistry
"ArcaNN: automated enhanced sampling generation of training sets for
  chemically reactive machine learning interatomic potentials","The emergence of artificial intelligence has profoundly impacted
computational chemistry, particularly through machine-learned potentials
(MLPs), which offer a balance of accuracy and efficiency in calculating atomic
energies and forces to be used in molecular dynamics simulations. These MLPs
have significantly advanced molecular dynamics simulations across various
applications, including large-scale simulations of materials, interfaces, and
chemical reactions. Despite these advances, the construction of training
datasets - a critical component for the accuracy of MLPs - has not received
proportional attention. This is particularly critical for chemical reactivity
which depends on rare barrier-crossing events. Here we address this gap by
introducing ArcaNN, a comprehensive framework designed for generating training
datasets for reactive MLPs. ArcaNN employs a concurrent learning approach
combined with advanced sampling techniques to ensure accurate representation of
high-energy geometries. The framework integrates automated processes for
iterative training, exploration, new configuration selection, and energy and
force labeling, while ensuring reproducibility and documentation. We
demonstrate ArcaNN's capabilities through a paradigm nucleophilic substitution
reaction in solution, showcasing its effectiveness, the uniformly low error of
the resulting MLP everywhere along the chemical reaction coordinate, and its
potential for broad applications in reactive molecular dynamics. We also
provide guidelines on how to assess the quality of a NNP for a reactive system.",2024-07-10,2024,2024-07,chemistry
"Show, Don't Tell: Evaluating Large Language Models Beyond Textual
  Understanding with ChildPlay","We developed a benchmark set to assess the generalization of state-of-the-art
large language models on problems beyond linguistic tasks and evaluate it on a
systematic progression of GPT models (GPT-3.5, GPT-4, GPT-4o, GPT-4o-mini).
Using simple games like Tic-Tac-Toe, Connect Four, Battleship, and a Shape
Recognition Game, all encoded in ASCII, we test strategic capabilities and
spatial reasoning, core abilities any artificial intelligence would need to
master for solving problems in chemistry. To probe generalization, we introduce
two new games for spatial logic: LEGO Connect Language (LCL) and
Guess-the-SMILES (GtS), a operationally simple chemistry benchmark. Our results
show that GPT models provide meaningful responses for several tasks but,
generally, perform poorly. A systematic performance progression with increased
model capabilities (GPT-3.5, GPT-4, GPT-4o) is only observed for 4 out of the 7
benchmark tasks. All models consistently struggle with Battleship, LCL, and
GtS. This suggests that while GPT models can emulate conversational proficiency
and basic rule comprehension, they have limited generalization with respect to
strategy and spatial reasoning. Particularly poor performance is observed for
interpreting molecular graphs when encoded in ASCII. The results provided by
our open-source benchmark suite
(\href{https://github.com/BlueVelvetSackOfGoldPotatoes/child-play}{\texttt{ChildPlay}
GitHub Repository}) caution against claims of emergent intelligence in GPT
models, which appear more specialized than general.",2024-07-12,2024,2024-07,chemistry
"Automated essay scoring in Arabic: a dataset and analysis of a
  BERT-based system","Automated Essay Scoring (AES) holds significant promise in the field of
education, helping educators to mark larger volumes of essays and provide
timely feedback. However, Arabic AES research has been limited by the lack of
publicly available essay data. This study introduces AR-AES, an Arabic AES
benchmark dataset comprising 2046 undergraduate essays, including gender
information, scores, and transparent rubric-based evaluation guidelines,
providing comprehensive insights into the scoring process. These essays come
from four diverse courses, covering both traditional and online exams.
Additionally, we pioneer the use of AraBERT for AES, exploring its performance
on different question types. We find encouraging results, particularly for
Environmental Chemistry and source-dependent essay questions. For the first
time, we examine the scale of errors made by a BERT-based AES system, observing
that 96.15 percent of the errors are within one point of the first human
marker's prediction, on a scale of one to five, with 79.49 percent of
predictions matching exactly. In contrast, additional human markers did not
exceed 30 percent exact matches with the first marker, with 62.9 percent within
one mark. These findings highlight the subjectivity inherent in essay grading,
and underscore the potential for current AES technology to assist human markers
to grade consistently across large classes.",2024-07-15,2024,2024-07,chemistry
SciCode: A Research Coding Benchmark Curated by Scientists,"Since language models (LMs) now outperform average humans on many challenging
tasks, it has become increasingly difficult to develop challenging,
high-quality, and realistic evaluations. We address this issue by examining
LMs' capabilities to generate code for solving real scientific research
problems. Incorporating input from scientists and AI researchers in 16 diverse
natural science sub-fields, including mathematics, physics, chemistry, biology,
and materials science, we created a scientist-curated coding benchmark,
SciCode. The problems in SciCode naturally factorize into multiple subproblems,
each involving knowledge recall, reasoning, and code synthesis. In total,
SciCode contains 338 subproblems decomposed from 80 challenging main problems.
It offers optional descriptions specifying useful scientific background
information and scientist-annotated gold-standard solutions and test cases for
evaluation. Claude3.5-Sonnet, the best-performing model among those tested, can
solve only 4.6% of the problems in the most realistic setting. We believe that
SciCode demonstrates both contemporary LMs' progress towards becoming helpful
scientific assistants and sheds light on the development and evaluation of
scientific AI in the future.",2024-07-18,2024,2024-07,chemistry
"Text-Augmented Multimodal LLMs for Chemical Reaction Condition
  Recommendation","High-throughput reaction condition (RC) screening is fundamental to chemical
synthesis. However, current RC screening suffers from laborious and costly
trial-and-error workflows. Traditional computer-aided synthesis planning (CASP)
tools fail to find suitable RCs due to data sparsity and inadequate reaction
representations. Nowadays, large language models (LLMs) are capable of tackling
chemistry-related problems, such as molecule design, and chemical logic Q\&A
tasks. However, LLMs have not yet achieved accurate predictions of chemical
reaction conditions. Here, we present MM-RCR, a text-augmented multimodal LLM
that learns a unified reaction representation from SMILES, reaction graphs, and
textual corpus for chemical reaction recommendation (RCR). To train MM-RCR, we
construct 1.2 million pair-wised Q\&A instruction datasets. Our experimental
results demonstrate that MM-RCR achieves state-of-the-art performance on two
open benchmark datasets and exhibits strong generalization capabilities on
out-of-domain (OOD) and High-Throughput Experimentation (HTE) datasets. MM-RCR
has the potential to accelerate high-throughput condition screening in chemical
synthesis.",2024-07-21,2024,2024-07,chemistry
Exploring Quantum Active Learning for Materials Design and Discovery,"The meeting of artificial intelligence (AI) and quantum computing is already
a reality; quantum machine learning (QML) promises the design of better
regression models. In this work, we extend our previous studies of materials
discovery using classical active learning (AL), which showed remarkable economy
of data, to explore the use of quantum algorithms within the AL framework (QAL)
as implemented in the MLChem4D and QMLMaterials codes. The proposed QAL uses
quantum support vector regressor (QSVR) or a quantum Gaussian process regressor
(QGPR) with various quantum kernels and different feature maps. Data sets
include perovskite properties (piezoelectric coefficient, band gap, energy
storage) and the structure optimization of a doped nanoparticle (3Al@Si11)
chosen to compare with classical AL results. Our results revealed that the QAL
method improved the searches in most cases, but not all, seemingly correlated
with the roughness of the data. QAL has the potential of finding optimum
solutions, within chemical space, in materials science and elsewhere in
chemistry.",2024-07-26,2024,2024-07,chemistry
A Bayesian Flow Network Framework for Chemistry Tasks,"In this work, we introduce ChemBFN, a language model that handles chemistry
tasks based on Bayesian flow networks working on discrete data. A new accuracy
schedule is proposed to improve the sampling quality by significantly reducing
the reconstruction loss. We show evidence that our method is appropriate for
generating molecules with satisfied diversity even when a smaller number of
sampling steps is used. A classifier-free guidance method is adapted for
conditional generation. It is also worthwhile to point out that after
generative training, our model can be fine-tuned on regression and
classification tasks with the state-of-the-art performance, which opens the
gate of building all-in-one models in a single module style. Our model has been
open sourced at
https://github.com/Augus1999/bayesian-flow-network-for-chemistry.",2024-07-28,2024,2024-07,chemistry
"A Tutorial on the Use of Physics-Informed Neural Networks to Compute the
  Spectrum of Quantum Systems","Quantum many-body systems are of great interest for many research areas,
including physics, biology and chemistry. However, their simulation is
extremely challenging, due to the exponential growth of the Hilbert space with
the system size, making it exceedingly difficult to parameterize the wave
functions of large systems by using exact methods. Neural networks and machine
learning in general are a way to face this challenge. For instance, methods
like Tensor networks and Neural Quantum States are being investigated as
promising tools to obtain the wave function of a quantum mechanical system. In
this tutorial, we focus on a particularly promising class of deep learning
algorithms. We explain how to construct a Physics-Informed Neural Network
(PINN) able to solve the Schr\""odinger equation for a given potential, by
finding its eigenvalues and eigenfunctions. This technique is unsupervised, and
utilizes a novel computational method in a manner that is barely explored.
PINNs are a deep learning method that exploits Automatic Differentiation to
solve Integro-Differential Equations in a mesh-free way. We show how to find
both the ground and the excited states. The method discovers the states
progressively by starting from the ground state. We explain how to introduce
inductive biases in the loss to exploit further knowledge of the physical
system. Such additional constraints allow for a faster and more accurate
convergence. This technique can then be enhanced by a smart choice of
collocation points in order to take advantage of the mesh-free nature of the
PINN. The methods are made explicit by applying them to the infinite potential
well and the particle in a ring, a challenging problem to be learned by an
Artificial Intelligence agent due to the presence of complex-valued
eigenfunctions and degenerate states.",2024-07-30,2024,2024-07,chemistry
"CEAR: Automatic construction of a knowledge graph of chemical entities
  and roles from scientific literature","Ontologies are formal representations of knowledge in specific domains that
provide a structured framework for organizing and understanding complex
information. Creating ontologies, however, is a complex and time-consuming
endeavor. ChEBI is a well-known ontology in the field of chemistry, which
provides a comprehensive resource for defining chemical entities and their
properties. However, it covers only a small fraction of the rapidly growing
knowledge in chemistry and does not provide references to the scientific
literature. To address this, we propose a methodology that involves augmenting
existing annotated text corpora with knowledge from Chebi and fine-tuning a
large language model (LLM) to recognize chemical entities and their roles in
scientific text. Our experiments demonstrate the effectiveness of our approach.
By combining ontological knowledge and the language understanding capabilities
of LLMs, we achieve high precision and recall rates in identifying both the
chemical entities and roles in scientific literature. Furthermore, we extract
them from a set of 8,000 ChemRxiv articles, and apply a second LLM to create a
knowledge graph (KG) of chemical entities and roles (CEAR), which provides
complementary information to ChEBI, and can help to extend it.",2024-07-31,2024,2024-07,chemistry
Open-Source Molecular Processing Pipeline for Generating Molecules,"Generative models for molecules have shown considerable promise for use in
computational chemistry, but remain difficult to use for non-experts. For this
reason, we introduce open-source infrastructure for easily building generative
molecular models into the widely used DeepChem [Ramsundar et al., 2019] library
with the aim of creating a robust and reusable molecular generation pipeline.
In particular, we add high quality PyTorch [Paszke et al., 2019]
implementations of the Molecular Generative Adversarial Networks (MolGAN) [Cao
and Kipf, 2022] and Normalizing Flows [Papamakarios et al., 2021]. Our
implementations show strong performance comparable with past work [Kuznetsov
and Polykovskiy, 2021, Cao and Kipf, 2022].",2024-08-12,2024,2024-08,chemistry
"Plasmonic Particle Integration into Near-Infrared Photodetectors and
  Photoactivated Gas Sensors: Towards Sustainable Next-Generation Ubiquitous
  Sensing","Current challenges in environmental science, medicine, food chemistry as well
as the emerging use of artificial intelligence for solving problems in these
fields require distributed, local sensing. Such ubiquitous sensing requires
components with (1) high sensitivity, (2) power efficiency, (3)
miniaturizability and (4) the ability to directly interface with electronic
circuitry, i.e., electronic readout of sensing signals. Over the recent years,
several nanoparticle-based approaches have found their way into this field and
have demonstrated high performance. However, challenges remain, such as the
toxicity of many of today's narrow bandgap semiconductors for NIR detection and
the high energy consumption as well as low selectivity of state-of-the-art
commercialized gas sensors. With their unique light-matter interaction and
ink-based fabrication schemes, plasmonic nanostructures provide potential
technological solutions to these challenges, leading also to better
environmental performance. In this perspective we discuss recent approaches of
using plasmonic nanoparticles for the fabrication of NIR photodetectors and
light-activated, energy-efficient gas sensing devices. In addition, we point
out new strategies implying computational approaches for miniaturizable
spectrometers, exploiting the wide spectral tunability of plasmonic
nanocomposites, and for selective gas sensors, utilizing dynamic light
activation. The benefits of colloidal approaches for device fabrication are
discussed with regard to technological advantages and environmental aspects,
which have been barely considered so far.",2024-08-14,2024,2024-08,chemistry
"The Dawn of KAN in Image-to-Image (I2I) Translation: Integrating
  Kolmogorov-Arnold Networks with GANs for Unpaired I2I Translation","Image-to-Image translation in Generative Artificial Intelligence (Generative
AI) has been a central focus of research, with applications spanning
healthcare, remote sensing, physics, chemistry, photography, and more. Among
the numerous methodologies, Generative Adversarial Networks (GANs) with
contrastive learning have been particularly successful. This study aims to
demonstrate that the Kolmogorov-Arnold Network (KAN) can effectively replace
the Multi-layer Perceptron (MLP) method in generative AI, particularly in the
subdomain of image-to-image translation, to achieve better generative quality.
Our novel approach replaces the two-layer MLP with a two-layer KAN in the
existing Contrastive Unpaired Image-to-Image Translation (CUT) model,
developing the KAN-CUT model. This substitution favors the generation of more
informative features in low-dimensional vector representations, which
contrastive learning can utilize more effectively to produce high-quality
images in the target domain. Extensive experiments, detailed in the results
section, demonstrate the applicability of KAN in conjunction with contrastive
learning and GANs in Generative AI, particularly for image-to-image
translation. This work suggests that KAN could be a valuable component in the
broader generative AI domain.",2024-08-15,2024,2024-08,chemistry
"Advancements in Molecular Property Prediction: A Survey of Single and
  Multimodal Approaches","Molecular Property Prediction (MPP) plays a pivotal role across diverse
domains, spanning drug discovery, material science, and environmental
chemistry. Fueled by the exponential growth of chemical data and the evolution
of artificial intelligence, recent years have witnessed remarkable strides in
MPP. However, the multifaceted nature of molecular data, such as molecular
structures, SMILES notation, and molecular images, continues to pose a
fundamental challenge in its effective representation. To address this,
representation learning techniques are instrumental as they acquire informative
and interpretable representations of molecular data. This article explores
recent AI/-based approaches in MPP, focusing on both single and multiple
modality representation techniques. It provides an overview of various molecule
representations and encoding schemes, categorizes MPP methods by their use of
modalities, and outlines datasets and tools available for feature generation.
The article also analyzes the performance of recent methods and suggests future
research directions to advance the field of MPP.",2024-08-18,2024,2024-08,chemistry
BatGPT-Chem: A Foundation Large Model For Retrosynthesis Prediction,"Retrosynthesis analysis is pivotal yet challenging in drug discovery and
organic chemistry. Despite the proliferation of computational tools over the
past decade, AI-based systems often fall short in generalizing across diverse
reaction types and exploring alternative synthetic pathways. This paper
presents BatGPT-Chem, a large language model with 15 billion parameters,
tailored for enhanced retrosynthesis prediction. Integrating chemical tasks via
a unified framework of natural language and SMILES notation, this approach
synthesizes extensive instructional data from an expansive chemical database.
Employing both autoregressive and bidirectional training techniques across over
one hundred million instances, BatGPT-Chem captures a broad spectrum of
chemical knowledge, enabling precise prediction of reaction conditions and
exhibiting strong zero-shot capabilities. Superior to existing AI methods, our
model demonstrates significant advancements in generating effective strategies
for complex molecules, as validated by stringent benchmark tests. BatGPT-Chem
not only boosts the efficiency and creativity of retrosynthetic analysis but
also establishes a new standard for computational tools in synthetic design.
This development empowers chemists to adeptly address the synthesis of novel
compounds, potentially expediting the innovation cycle in drug manufacturing
and materials science. We release our trial platform at
\url{https://www.batgpt.net/dapp/chem}.",2024-08-19,2024,2024-08,chemistry
"Leveraging Chemistry Foundation Models to Facilitate Structure Focused
  Retrieval Augmented Generation in Multi-Agent Workflows for Catalyst and
  Materials Design","Molecular property prediction and generative design via deep learning models
has been the subject of intense research given its potential to accelerate
development of new, high-performance materials. More recently, these workflows
have been significantly augmented with the advent of large language models
(LLMs) and systems of autonomous agents capable of utilizing pre-trained models
to make predictions in the context of more complex research tasks. While
effective, there is still room for substantial improvement within agentic
systems on the retrieval of salient information for material design tasks.
Within this context, alternative uses of predictive deep learning models, such
as leveraging their latent representations to facilitate cross-modal retrieval
augmented generation within agentic systems for task-specific materials design,
has remained unexplored. Herein, we demonstrate that large, pre-trained
chemistry foundation models can serve as a basis for enabling
structure-focused, semantic chemistry information retrieval for both
small-molecules, complex polymeric materials, and reactions. Additionally, we
show the use of chemistry foundation models in conjunction with multi-modal
models such as OpenCLIP facilitate unprecedented queries and information
retrieval across multiple characterization data domains. Finally, we
demonstrate the integration of these models within multi-agent systems to
facilitate structure and topological-based natural language queries and
information retrieval for different research tasks.",2024-08-21,2024,2024-08,chemistry
"Employing Artificial Intelligence to Steer Exascale Workflows with
  Colmena","Computational workflows are a common class of application on supercomputers,
yet the loosely coupled and heterogeneous nature of workflows often fails to
take full advantage of their capabilities. We created Colmena to leverage the
massive parallelism of a supercomputer by using Artificial Intelligence (AI) to
learn from and adapt a workflow as it executes. Colmena allows scientists to
define how their application should respond to events (e.g., task completion)
as a series of cooperative agents. In this paper, we describe the design of
Colmena, the challenges we overcame while deploying applications on exascale
systems, and the science workflows we have enhanced through interweaving AI.
The scaling challenges we discuss include developing steering strategies that
maximize node utilization, introducing data fabrics that reduce communication
overhead of data-intensive tasks, and implementing workflow tasks that cache
costly operations between invocations. These innovations coupled with a variety
of application patterns accessible through our agent-based steering model have
enabled science advances in chemistry, biophysics, and materials science using
different types of AI. Our vision is that Colmena will spur creative solutions
that harness AI across many domains of scientific computing.",2024-08-26,2024,2024-08,chemistry
Integrating Quantum Computing Resources into Scientific HPC Ecosystems,"Quantum Computing (QC) offers significant potential to enhance scientific
discovery in fields such as quantum chemistry, optimization, and artificial
intelligence. Yet QC faces challenges due to the noisy intermediate-scale
quantum era's inherent external noise issues. This paper discusses the
integration of QC as a computational accelerator within classical scientific
high-performance computing (HPC) systems. By leveraging a broad spectrum of
simulators and hardware technologies, we propose a hardware-agnostic framework
for augmenting classical HPC with QC capabilities. Drawing on the HPC expertise
of the Oak Ridge National Laboratory (ORNL) and the HPC lifecycle management of
the Department of Energy (DOE), our approach focuses on the strategic
incorporation of QC capabilities and acceleration into existing scientific HPC
workflows. This includes detailed analyses, benchmarks, and code optimization
driven by the needs of the DOE and ORNL missions. Our comprehensive framework
integrates hardware, software, workflows, and user interfaces to foster a
synergistic environment for quantum and classical computing research. This
paper outlines plans to unlock new computational possibilities, driving forward
scientific inquiry and innovation in a wide array of research domains.",2024-08-28,2024,2024-08,chemistry
"Towards Symbolic XAI -- Explanation Through Human Understandable Logical
  Relationships Between Features","Explainable Artificial Intelligence (XAI) plays a crucial role in fostering
transparency and trust in AI systems, where traditional XAI approaches
typically offer one level of abstraction for explanations, often in the form of
heatmaps highlighting single or multiple input features. However, we ask
whether abstract reasoning or problem-solving strategies of a model may also be
relevant, as these align more closely with how humans approach solutions to
problems. We propose a framework, called Symbolic XAI, that attributes
relevance to symbolic queries expressing logical relationships between input
features, thereby capturing the abstract reasoning behind a model's
predictions. The methodology is built upon a simple yet general multi-order
decomposition of model predictions. This decomposition can be specified using
higher-order propagation-based relevance methods, such as GNN-LRP, or
perturbation-based explanation methods commonly used in XAI. The effectiveness
of our framework is demonstrated in the domains of natural language processing
(NLP), vision, and quantum chemistry (QC), where abstract symbolic domain
knowledge is abundant and of significant interest to users. The Symbolic XAI
framework provides an understanding of the model's decision-making process that
is both flexible for customization by the user and human-readable through
logical formulas.",2024-08-30,2024,2024-08,chemistry
JaxLife: An Open-Ended Agentic Simulator,"Human intelligence emerged through the process of natural selection and
evolution on Earth. We investigate what it would take to re-create this process
in silico. While past work has often focused on low-level processes (such as
simulating physics or chemistry), we instead take a more targeted approach,
aiming to evolve agents that can accumulate open-ended culture and technologies
across generations. Towards this, we present JaxLife: an artificial life
simulator in which embodied agents, parameterized by deep neural networks, must
learn to survive in an expressive world containing programmable systems. First,
we describe the environment and show that it can facilitate meaningful
Turing-complete computation. We then analyze the evolved emergent agents'
behavior, such as rudimentary communication protocols, agriculture, and tool
use. Finally, we investigate how complexity scales with the amount of compute
used. We believe JaxLife takes a step towards studying evolved behavior in more
open-ended simulations. Our code is available at
https://github.com/luchris429/JaxLife",2024-09-01,2024,2024-09,chemistry
"Generative artificial intelligence for computational chemistry: a
  roadmap to predicting emergent phenomena","The recent surge in Generative Artificial Intelligence (AI) has introduced
exciting possibilities for computational chemistry. Generative AI methods have
made significant progress in sampling molecular structures across chemical
species, developing force fields, and speeding up simulations. This Perspective
offers a structured overview, beginning with the fundamental theoretical
concepts in both Generative AI and computational chemistry. It then covers
widely used Generative AI methods, including autoencoders, generative
adversarial networks, reinforcement learning, flow models and language models,
and highlights their selected applications in diverse areas including force
field development, and protein/RNA structure prediction. A key focus is on the
challenges these methods face before they become truly predictive, particularly
in predicting emergent chemical phenomena. We believe that the ultimate goal of
a simulation method or theory is to predict phenomena not seen before, and that
Generative AI should be subject to these same standards before it is deemed
useful for chemistry. We suggest that to overcome these challenges, future AI
models need to integrate core chemical principles, especially from statistical
mechanics.",2024-09-04,2024,2024-09,chemistry
"AI and Machine Learning Approaches for Predicting Nanoparticles Toxicity
  The Critical Role of Physiochemical Properties","This research investigates the use of artificial intelligence and machine
learning techniques to predict the toxicity of nanoparticles, a pressing
concern due to their pervasive use in various industries and the inherent
challenges in assessing their biological interactions. Employing models such as
Decision Trees, Random Forests, and XGBoost, the study focuses on analyzing
physicochemical properties like size, shape, surface charge, and chemical
composition to determine their influence on toxicity. Our findings highlight
the significant role of oxygen atoms, particle size, surface area, dosage, and
exposure duration in affecting toxicity levels. The use of machine learning
allows for a nuanced understanding of the intricate patterns these properties
form in biological contexts, surpassing traditional analysis methods in
efficiency and predictive power. These advancements aid in developing safer
nanomaterials through computational chemistry, reducing reliance on costly and
time-consuming experimental methods. This approach not only enhances our
understanding of nanoparticle behavior in biological systems but also
streamlines the safety assessment process, marking a significant stride towards
integrating computational techniques in nanotoxicology.",2024-09-06,2024,2024-09,chemistry
"Elsevier Arena: Human Evaluation of Chemistry/Biology/Health
  Foundational Large Language Models","arXiv admin comment: This version has been removed by arXiv administrators as
the submitter did not have the rights to agree to the license at the time of
submission",2024-09-09,2024,2024-09,chemistry
Can Large Language Models Unlock Novel Scientific Research Ideas?,"""An idea is nothing more nor less than a new combination of old elements""
(Young, J.W.). The widespread adoption of Large Language Models (LLMs) and
publicly available ChatGPT have marked a significant turning point in the
integration of Artificial Intelligence (AI) into people's everyday lives. This
study explores the capability of LLMs in generating novel research ideas based
on information from research papers. We conduct a thorough examination of 4
LLMs in five domains (e.g., Chemistry, Computer, Economics, Medical, and
Physics). We found that the future research ideas generated by Claude-2 and
GPT-4 are more aligned with the author's perspective than GPT-3.5 and Gemini.
We also found that Claude-2 generates more diverse future research ideas than
GPT-4, GPT-3.5, and Gemini 1.0. We further performed a human evaluation of the
novelty, relevancy, and feasibility of the generated future research ideas.
This investigation offers insights into the evolving role of LLMs in idea
generation, highlighting both its capability and limitations. Our work
contributes to the ongoing efforts in evaluating and utilizing language models
for generating future research ideas. We make our datasets and codes publicly
available.",2024-09-10,2024,2024-09,chemistry
"VisScience: An Extensive Benchmark for Evaluating K12 Educational
  Multi-modal Scientific Reasoning","Multi-modal large language models (MLLMs) have demonstrated promising
capabilities across various tasks by integrating textual and visual information
to achieve visual understanding in complex scenarios. Despite the availability
of several benchmarks aims to evaluating MLLMs in tasks from visual question
answering to complex problem-solving, most focus predominantly on mathematics
or general visual understanding tasks. This reveals a critical gap in current
benchmarks, which often overlook the inclusion of other key scientific
disciplines such as physics and chemistry. To address this gap, we meticulously
construct a comprehensive benchmark, named VisScience, which is utilized to
assess the multi-modal scientific reasoning across the three disciplines of
mathematics, physics, and chemistry. This benchmark comprises 3,000 questions
drawn from K12 education - spanning elementary school through high school -
equally distributed across three disciplines, with 1,000 questions per
discipline. The questions within VisScience span 21 distinct subjects and are
categorized into five difficulty levels, offering a broad spectrum of topics
within each discipline. With VisScience, we present a detailed evaluation of
the performance of 25 representative MLLMs in scientific reasoning.
Experimental results demonstrate that closed-source MLLMs generally outperform
open-source models. The best performance observed include a 53.4\% accuracy in
mathematics by Claude3.5-Sonnet, 38.2\% in physics by GPT-4o, and 47.0\% in
chemistry by Gemini-1.5-Pro. These results underscore the strengths and
limitations of MLLMs, suggesting areas for future improvement and highlighting
the importance of developing models that can effectively handle the diverse
demands of multi-modal scientific reasoning.",2024-09-10,2024,2024-09,chemistry
"Spiers Memorial Lecture: How to do impactful research in artificial
  intelligence for chemistry and materials science","Machine learning has been pervasively touching many fields of science.
Chemistry and materials science are no exception. While machine learning has
been making a great impact, it is still not reaching its full potential or
maturity. In this perspective, we first outline current applications across a
diversity of problems in chemistry. Then, we discuss how machine learning
researchers view and approach problems in the field. Finally, we provide our
considerations for maximizing impact when researching machine learning for
chemistry.",2024-09-16,2024,2024-09,chemistry
Machine Learning and Theory Ladenness -- A Phenomenological Account,"In recent years, the dissemination of machine learning (ML) methodologies in
scientific research has prompted discussions on theory ladenness. More
specifically, the issue of theory ladenness has remerged as questions about
whether and how ML models (MLMs) and ML modelling strategies are impacted by
the domain theory of the scientific field in which ML is used and implemented
(e.g., physics, chemistry, biology, etc). On the one hand, some have argued
that there is no difference between traditional (pre ML) and ML assisted
science. In both cases, theory plays an essential and unavoidable role in the
analysis of phenomena and the construction and use of models. Others have
argued instead that ML methodologies and models are theory independent and, in
some cases, even theory free. In this article, we argue that both positions are
overly simplistic and do not advance our understanding of the interplay between
ML methods and domain theories. Specifically, we provide an analysis of theory
ladenness in ML assisted science. Our analysis reveals that, while the
construction of MLMs can be relatively independent of domain theory, the
practical implementation and interpretation of these models within a given
specific domain still relies on fundamental theoretical assumptions and
background knowledge.",2024-09-17,2024,2024-09,chemistry
Smirk: An Atomically Complete Tokenizer for Molecular Foundation Models,"Text-based foundation models have become an important part of scientific
discovery, with molecular foundation models accelerating advancements in
molecular design and materials science. However, existing models are
constrained by closed-vocabulary tokenizers which capture only a fraction of
molecular space. In this work, we systematically evaluate thirty tokenizers,
including 19 chemistry-specific ones, for their coverage of the SMILES
molecular representation language, revealing significant gaps. To assess the
impact of tokenizer choice, we introduce n-gram language models as a low-cost
proxy and validate their effectiveness by training and fine-tuning 18
RoBERTa-style encoders for molecular property prediction. To overcome the
limitations of existing tokenizers, we propose two new tokenizers -- Smirk and
Smirk-GPE -- with full coverage of the OpenSMILES specification. Our results
highlight the need for open-vocabulary modeling and chemically diverse
benchmarks in cheminformatics. The proposed tokenizer framework systematically
integrates nuclear, electronic, and geometric degrees of freedom; this
facilitates applications in pharmacology, agriculture, biology, and energy
storage.",2024-09-19,2024,2024-09,chemistry
"What Would You Ask When You First Saw $a^2+b^2=c^2$? Evaluating LLM on
  Curiosity-Driven Questioning","Large language models (LLMs) can store a massive amount of knowledge, yet
their potential to acquire new knowledge remains unknown. We propose a novel
evaluation framework that evaluates this capability. This framework prompts
LLMs to generate questions about a statement introducing scientific knowledge,
simulating a curious person when facing the statement for the first time. We
score the qualities of the generated questions, thereby evaluating the
knowledge acquisition potential of the LLM. We apply controlled ablation
studies to validate our scoring procedures. Additionally, we created a
synthetic dataset consisting of 1101 statements in physics, chemistry, and
maths with distinct levels of difficulties, 300 general knowledge statements,
and 567 incorrect statements. Human evaluations were conducted to validate our
model assessments, achieving an approximate weighted Cohen's kappa of 0.7 on
all three metrics considered. We find that while large models like GPT-4 and
Mistral 8x7b are adept at generating coherent and relevant questions, the
smaller Phi-2 model is equally or more effective. This indicates that size does
not solely determine a model's knowledge acquisition potential. The proposed
framework quantifies a critical model capability that was commonly overlooked
and opens up research opportunities for developing more knowledgeable AI
systems",2024-09-19,2024,2024-09,chemistry
"ChemEval: A Comprehensive Multi-Level Chemical Evaluation for Large
  Language Models","There is a growing interest in the role that LLMs play in chemistry which
lead to an increased focus on the development of LLMs benchmarks tailored to
chemical domains to assess the performance of LLMs across a spectrum of
chemical tasks varying in type and complexity. However, existing benchmarks in
this domain fail to adequately meet the specific requirements of chemical
research professionals. To this end, we propose \textbf{\textit{ChemEval}},
which provides a comprehensive assessment of the capabilities of LLMs across a
wide range of chemical domain tasks. Specifically, ChemEval identified 4
crucial progressive levels in chemistry, assessing 12 dimensions of LLMs across
42 distinct chemical tasks which are informed by open-source data and the data
meticulously crafted by chemical experts, ensuring that the tasks have
practical value and can effectively evaluate the capabilities of LLMs. In the
experiment, we evaluate 12 mainstream LLMs on ChemEval under zero-shot and
few-shot learning contexts, which included carefully selected demonstration
examples and carefully designed prompts. The results show that while general
LLMs like GPT-4 and Claude-3.5 excel in literature understanding and
instruction following, they fall short in tasks demanding advanced chemical
knowledge. Conversely, specialized LLMs exhibit enhanced chemical competencies,
albeit with reduced literary comprehension. This suggests that LLMs have
significant potential for enhancement when tackling sophisticated tasks in the
field of chemistry. We believe our work will facilitate the exploration of
their potential to drive progress in chemistry. Our benchmark and analysis will
be available at {\color{blue} \url{https://github.com/USTC-StarTeam/ChemEval}}.",2024-09-21,2024,2024-09,chemistry
"Mitigating Exposure Bias in Score-Based Generation of Molecular
  Conformations","Molecular conformation generation poses a significant challenge in the field
of computational chemistry. Recently, Diffusion Probabilistic Models (DPMs) and
Score-Based Generative Models (SGMs) are effectively used due to their capacity
for generating accurate conformations far beyond conventional physics-based
approaches. However, the discrepancy between training and inference rises a
critical problem known as the exposure bias. While this issue has been
extensively investigated in DPMs, the existence of exposure bias in SGMs and
its effective measurement remain unsolved, which hinders the use of
compensation methods for SGMs, including ConfGF and Torsional Diffusion as the
representatives. In this work, we first propose a method for measuring exposure
bias in SGMs used for molecular conformation generation, which confirms the
significant existence of exposure bias in these models and measures its value.
We design a new compensation algorithm Input Perturbation (IP), which is
adapted from a method originally designed for DPMs only. Experimental results
show that by introducing IP, SGM-based molecular conformation models can
significantly improve both the accuracy and diversity of the generated
conformations. Especially by using the IP-enhanced Torsional Diffusion model,
we achieve new state-of-the-art performance on the GEOM-Drugs dataset and are
on par on GEOM-QM9. We provide the code publicly at
https://github.com/jia-975/torsionalDiff-ip.",2024-09-21,2024,2024-09,chemistry
PepINVENT: Generative peptide design beyond the natural amino acids,"Peptides play a crucial role in the drug design and discovery whether as a
therapeutic modality or a delivery agent. Non-natural amino acids (NNAAs) have
been used to enhance the peptide properties from binding affinity, plasma
stability to permeability. Incorporating novel NNAAs facilitates the design of
more effective peptides with improved properties. The generative models used in
the field, have focused on navigating the peptide sequence space. The sequence
space is formed by combinations of a predefined set of amino acids. However,
there is still a need for a tool to explore the peptide landscape beyond this
enumerated space to unlock and effectively incorporate de novo design of new
amino acids. To thoroughly explore the theoretical chemical space of the
peptides, we present PepINVENT, a novel generative AI-based tool as an
extension to the small molecule molecular design platform, REINVENT. PepINVENT
navigates the vast space of natural and non-natural amino acids to propose
valid, novel, and diverse peptide designs. The generative model can serve as a
central tool for peptide-related tasks, as it was not trained on peptides with
specific properties or topologies. The prior was trained to understand the
granularity of peptides and to design amino acids for filling the masked
positions within a peptide. PepINVENT coupled with reinforcement learning
enables the goal-oriented design of peptides using its chemistry-informed
generative capabilities. This study demonstrates PepINVENT's ability to explore
the peptide space with unique and novel designs, and its capacity for property
optimization in the context of therapeutically relevant peptides. Our tool can
be employed for multi-parameter learning objectives, peptidomimetics, lead
optimization, and variety of other tasks within the peptide domain.",2024-09-21,2024,2024-09,chemistry
Susceptibility Formulation of Density Matrix Perturbation Theory,"Density matrix perturbation theory based on recursive Fermi-operator
expansions provides a computationally efficient framework for time-independent
response calculations in quantum chemistry and materials science. From a
perturbation in the Hamiltonian we can calculate the first-order perturbation
in the density matrix, which then gives us the linear response in the
expectation values for some chosen set of observables. Here we present an
alternative, {\it dual} formulation, where we instead calculate the static
susceptibility of an observable, which then gives us the linear response in the
expectation values for any number of different Hamiltonian perturbations. We
show how the calculation of the susceptibility can be performed with the same
expansion schemes used in recursive density matrix perturbation theory,
including generalizations to fractional occupation numbers and self-consistent
linear response calculations, i.e. similar to density functional perturbation
theory. As with recursive density matrix perturbation theory, the dual
susceptibility formulation is well suited for numerically thresholded sparse
matrix algebra, which has linear scaling complexity for sufficiently large
sparse systems. Similarly, the recursive computation of the susceptibility also
seamlessly integrates with the computational framework of deep neural networks
used in artificial intelligence (AI) applications. This integration enables the
calculation of quantum response properties that can leverage cutting-edge
AI-hardware, such as Nvidia Tensor cores or Google Tensor Processing Units. We
demonstrate performance for recursive susceptibility calculations using Nvidia
Graphics Processing Units and Tensor cores.",2024-09-25,2024,2024-09,chemistry
"KALE-LM: Unleash The Power Of AI For Science Via Knowledge And Logic
  Enhanced Large Model","Artificial intelligence is gradually demonstrating its immense potential, and
increasing attention is being given to how AI can be harnessed to advance
scientific research. In this vision paper, we present our perspectives on how
AI can better assist scientific inquiry and explore corresponding technical
approach. We have proposed and open-sourced two large models of our KALE-LM
model series, KALE-LM-Chem(-1.5), which have achieved outstanding performance
in tasks related to the field of chemistry. We hope that our work serves as a
strong starting point, helping to realize more intelligent AI and promoting the
advancement of human science and technology, as well as societal development.",2024-09-27,2024,2024-09,chemistry
"Discrete Diffusion Schr√∂dinger Bridge Matching for Graph
  Transformation","Transporting between arbitrary distributions is a fundamental goal in
generative modeling. Recently proposed diffusion bridge models provide a
potential solution, but they rely on a joint distribution that is difficult to
obtain in practice. Furthermore, formulations based on continuous domains limit
their applicability to discrete domains such as graphs. To overcome these
limitations, we propose Discrete Diffusion Schr\""odinger Bridge Matching
(DDSBM), a novel framework that utilizes continuous-time Markov chains to solve
the SB problem in a high-dimensional discrete state space. Our approach extends
Iterative Markovian Fitting to discrete domains, and we have proved its
convergence to the SB. Furthermore, we adapt our framework for the graph
transformation, and show that our design choice of underlying dynamics
characterized by independent modifications of nodes and edges can be
interpreted as the entropy-regularized version of optimal transport with a cost
function described by the graph edit distance. To demonstrate the effectiveness
of our framework, we have applied DDSBM to molecular optimization in the field
of chemistry. Experimental results demonstrate that DDSBM effectively optimizes
molecules' property-of-interest with minimal graph transformation, successfully
retaining other features. Source code is available
$\href{https://github.com/junhkim1226/DDSBM}{here}$.",2024-10-02,2024,2024-10,chemistry
"SciSafeEval: A Comprehensive Benchmark for Safety Alignment of Large
  Language Models in Scientific Tasks","Large language models (LLMs) have a transformative impact on a variety of
scientific tasks across disciplines including biology, chemistry, medicine, and
physics. However, ensuring the safety alignment of these models in scientific
research remains an underexplored area, with existing benchmarks primarily
focusing on textual content and overlooking key scientific representations such
as molecular, protein, and genomic languages. Moreover, the safety mechanisms
of LLMs in scientific tasks are insufficiently studied. To address these
limitations, we introduce SciSafeEval, a comprehensive benchmark designed to
evaluate the safety alignment of LLMs across a range of scientific tasks.
SciSafeEval spans multiple scientific languages-including textual, molecular,
protein, and genomic-and covers a wide range of scientific domains. We evaluate
LLMs in zero-shot, few-shot and chain-of-thought settings, and introduce a
""jailbreak"" enhancement feature that challenges LLMs equipped with safety
guardrails, rigorously testing their defenses against malicious intention. Our
benchmark surpasses existing safety datasets in both scale and scope, providing
a robust platform for assessing the safety and performance of LLMs in
scientific contexts. This work aims to facilitate the responsible development
and deployment of LLMs, promoting alignment with safety and ethical standards
in scientific research.",2024-10-02,2024,2024-10,chemistry
"SymmetricDiffusers: Learning Discrete Diffusion on Finite Symmetric
  Groups","Finite symmetric groups $S_n$ are essential in fields such as combinatorics,
physics, and chemistry. However, learning a probability distribution over $S_n$
poses significant challenges due to its intractable size and discrete nature.
In this paper, we introduce SymmetricDiffusers, a novel discrete diffusion
model that simplifies the task of learning a complicated distribution over
$S_n$ by decomposing it into learning simpler transitions of the reverse
diffusion using deep neural networks. We identify the riffle shuffle as an
effective forward transition and provide empirical guidelines for selecting the
diffusion length based on the theory of random walks on finite groups.
Additionally, we propose a generalized Plackett-Luce (PL) distribution for the
reverse transition, which is provably more expressive than the PL distribution.
We further introduce a theoretically grounded ""denoising schedule"" to improve
sampling and learning efficiency. Extensive experiments show that our model
achieves state-of-the-art or comparable performances on solving tasks including
sorting 4-digit MNIST images, jigsaw puzzles, and traveling salesman problems.
Our code is released at https://github.com/DSL-Lab/SymmetricDiffusers.",2024-10-03,2024,2024-10,chemistry
Text-guided Diffusion Model for 3D Molecule Generation,"The de novo generation of molecules with targeted properties is crucial in
biology, chemistry, and drug discovery. Current generative models are limited
to using single property values as conditions, struggling with complex
customizations described in detailed human language. To address this, we
propose the text guidance instead, and introduce TextSMOG, a new Text-guided
Small Molecule Generation Approach via 3D Diffusion Model which integrates
language and diffusion models for text-guided small molecule generation. This
method uses textual conditions to guide molecule generation, enhancing both
stability and diversity. Experimental results show TextSMOG's proficiency in
capturing and utilizing information from textual descriptions, making it a
powerful tool for generating 3D molecular structures in response to complex
textual customizations.",2024-10-04,2024,2024-10,chemistry
"REBIND: Enhancing ground-state molecular conformation via force-based
  graph rewiring","Predicting the ground-state 3D molecular conformations from 2D molecular
graphs is critical in computational chemistry due to its profound impact on
molecular properties. Deep learning (DL) approaches have recently emerged as
promising alternatives to computationally-heavy classical methods such as
density functional theory (DFT). However, we discover that existing DL methods
inadequately model inter-atomic forces, particularly for non-bonded atomic
pairs, due to their naive usage of bonds and pairwise distances. Consequently,
significant prediction errors occur for atoms with low degree (i.e., low
coordination numbers) whose conformations are primarily influenced by
non-bonded interactions. To address this, we propose REBIND, a novel framework
that rewires molecular graphs by adding edges based on the Lennard-Jones
potential to capture non-bonded interactions for low-degree atoms. Experimental
results demonstrate that REBIND significantly outperforms state-of-the-art
methods across various molecular sizes, achieving up to a 20\% reduction in
prediction error.",2024-10-04,2024,2024-10,chemistry
"How Do Large Language Models Understand Graph Patterns? A Benchmark for
  Graph Pattern Comprehension","Benchmarking the capabilities and limitations of large language models (LLMs)
in graph-related tasks is becoming an increasingly popular and crucial area of
research. Recent studies have shown that LLMs exhibit a preliminary ability to
understand graph structures and node features. However, the potential of LLMs
in graph pattern mining remains largely unexplored. This is a key component in
fields such as computational chemistry, biology, and social network analysis.
To bridge this gap, this work introduces a comprehensive benchmark to assess
LLMs' capabilities in graph pattern tasks. We have developed a benchmark that
evaluates whether LLMs can understand graph patterns based on either
terminological or topological descriptions. Additionally, our benchmark tests
the LLMs' capacity to autonomously discover graph patterns from data. The
benchmark encompasses both synthetic and real datasets, and a variety of
models, with a total of 11 tasks and 7 models. Our experimental framework is
designed for easy expansion to accommodate new models and datasets. Our
findings reveal that: (1) LLMs have preliminary abilities to understand graph
patterns, with O1-mini outperforming in the majority of tasks; (2) Formatting
input data to align with the knowledge acquired during pretraining can enhance
performance; (3) The strategies employed by LLMs may differ from those used in
conventional algorithms.",2024-10-04,2024,2024-10,chemistry
"Validation of the Scientific Literature via Chemputation Augmented by
  Large Language Models","Chemputation is the process of programming chemical robots to do experiments
using a universal symbolic language, but the literature can be error prone and
hard to read due to ambiguities. Large Language Models (LLMs) have demonstrated
remarkable capabilities in various domains, including natural language
processing, robotic control, and more recently, chemistry. Despite significant
advancements in standardizing the reporting and collection of synthetic
chemistry data, the automatic reproduction of reported syntheses remains a
labour-intensive task. In this work, we introduce an LLM-based chemical
research agent workflow designed for the automatic validation of synthetic
literature procedures. Our workflow can autonomously extract synthetic
procedures and analytical data from extensive documents, translate these
procedures into universal XDL code, simulate the execution of the procedure in
a hardware-specific setup, and ultimately execute the procedure on an
XDL-controlled robotic system for synthetic chemistry. This demonstrates the
potential of LLM-based workflows for autonomous chemical synthesis with
Chemputers. Due to the abstraction of XDL this approach is safe, secure, and
scalable since hallucinations will not be chemputable and the XDL can be both
verified and encrypted. Unlike previous efforts, which either addressed only a
limited portion of the workflow, relied on inflexible hard-coded rules, or
lacked validation in physical systems, our approach provides four realistic
examples of syntheses directly executed from synthetic literature. We
anticipate that our workflow will significantly enhance automation in
robotically driven synthetic chemistry research, streamline data extraction,
improve the reproducibility, scalability, and safety of synthetic and
experimental chemistry.",2024-10-08,2024,2024-10,chemistry
Chain-of-Thoughts for Molecular Understanding,"The adaptation of large language models (LLMs) to chemistry has shown
promising performance in molecular understanding tasks, such as generating a
text description from a molecule. However, proper reasoning based on molecular
structural information remains a significant challenge, e.g., even advanced
LLMs such as GPT-4o struggle to identify functional groups which are crucial
for inferring the molecular property of interest. To address this limitation,
we propose StructCoT, a structure-aware chain-of-thought (CoT) that enhances
LLMs' understanding of molecular structures by explicitly injecting the key
structural features of molecules. Moreover, we introduce two fine-tuning
frameworks for adapting the existing LLMs to use our StructCoT. Our experiments
demonstrate that incorporating StructCoT with our fine-tuning frameworks leads
to consistent improvements in both molecular understanding tasks.",2024-10-08,2024,2024-10,chemistry
"MOOSE-Chem: Large Language Models for Rediscovering Unseen Chemistry
  Scientific Hypotheses","Scientific discovery contributes largely to human society's prosperity, and
recent progress shows that LLMs could potentially catalyze this process.
However, it is still unclear whether LLMs can discover novel and valid
hypotheses in chemistry. In this work, we investigate this central research
question: Can LLMs automatically discover novel and valid chemistry research
hypotheses given only a chemistry research background (consisting of a research
question and/or a background survey), without limitation on the domain of the
research question? After extensive discussions with chemistry experts, we
propose an assumption that a majority of chemistry hypotheses can be resulted
from a research background and several inspirations. With this key insight, we
break the central question into three smaller fundamental questions. In brief,
they are: (1) given a background question, whether LLMs can retrieve good
inspirations; (2) with background and inspirations, whether LLMs can lead to
hypothesis; and (3) whether LLMs can identify good hypotheses to rank them
higher. To investigate these questions, we construct a benchmark consisting of
51 chemistry papers published in Nature, Science, or a similar level in 2024
(all papers are only available online since 2024). Every paper is divided by
chemistry PhD students into three components: background, inspirations, and
hypothesis. The goal is to rediscover the hypothesis, given only the background
and a large randomly selected chemistry literature corpus consisting the ground
truth inspiration papers, with LLMs trained with data up to 2023. We also
develop an LLM-based multi-agent framework that leverages the assumption,
consisting of three stages reflecting the three smaller questions. The proposed
method can rediscover many hypotheses with very high similarity with the ground
truth ones, covering the main innovations.",2024-10-09,2024,2024-10,chemistry
Chemistry-Inspired Diffusion with Non-Differentiable Guidance,"Recent advances in diffusion models have shown remarkable potential in the
conditional generation of novel molecules. These models can be guided in two
ways: (i) explicitly, through additional features representing the condition,
or (ii) implicitly, using a property predictor. However, training property
predictors or conditional diffusion models requires an abundance of labeled
data and is inherently challenging in real-world applications. We propose a
novel approach that attenuates the limitations of acquiring large labeled
datasets by leveraging domain knowledge from quantum chemistry as a
non-differentiable oracle to guide an unconditional diffusion model. Instead of
relying on neural networks, the oracle provides accurate guidance in the form
of estimated gradients, allowing the diffusion process to sample from a
conditional distribution specified by quantum chemistry. We show that this
results in more precise conditional generation of novel and stable molecular
structures. Our experiments demonstrate that our method: (1) significantly
reduces atomic forces, enhancing the validity of generated molecules when used
for stability optimization; (2) is compatible with both explicit and implicit
guidance in diffusion models, enabling joint optimization of molecular
properties and stability; and (3) generalizes effectively to molecular
optimization tasks beyond stability optimization.",2024-10-09,2024,2024-10,chemistry
"DLGNet: Hyperedge Classification through Directed Line Graphs for
  Chemical Reactions","Graphs and hypergraphs provide powerful abstractions for modeling
interactions among a set of entities of interest and have been attracting a
growing interest in the literature thanks to many successful applications in
several fields. In particular, they are rapidly expanding in domains such as
chemistry and biology, especially in the areas of drug discovery and molecule
generation. One of the areas witnessing the fasted growth is the chemical
reactions field, where chemical reactions can be naturally encoded as directed
hyperedges of a hypergraph. In this paper, we address the chemical reaction
classification problem by introducing the notation of a Directed Line Graph
(DGL) associated with a given directed hypergraph. On top of it, we build the
Directed Line Graph Network (DLGNet), the first spectral-based Graph Neural
Network (GNN) expressly designed to operate on a hypergraph via its DLG
transformation. The foundation of DLGNet is a novel Hermitian matrix, the
Directed Line Graph Laplacian, which compactly encodes the directionality of
the interactions taking place within the directed hyperedges of the hypergraph
thanks to the DLG representation. The Directed Line Graph Laplacian enjoys many
desirable properties, including admitting an eigenvalue decomposition and being
positive semidefinite, which make it well-suited for its adoption within a
spectral-based GNN. Through extensive experiments on chemical reaction
datasets, we show that DGLNet significantly outperforms the existing
approaches, achieving on a collection of real-world datasets an average
relative-percentage-difference improvement of 33.01%, with a maximum
improvement of 37.71%.",2024-10-09,2024,2024-10,chemistry
"PEAR: A Robust and Flexible Automation Framework for Ptychography
  Enabled by Multiple Large Language Model Agents","Ptychography is an advanced computational imaging technique in X-ray and
electron microscopy. It has been widely adopted across scientific research
fields, including physics, chemistry, biology, and materials science, as well
as in industrial applications such as semiconductor characterization. In
practice, obtaining high-quality ptychographic images requires simultaneous
optimization of numerous experimental and algorithmic parameters.
Traditionally, parameter selection often relies on trial and error, leading to
low-throughput workflows and potential human bias. In this work, we develop the
""Ptychographic Experiment and Analysis Robot"" (PEAR), a framework that
leverages large language models (LLMs) to automate data analysis in
ptychography. To ensure high robustness and accuracy, PEAR employs multiple LLM
agents for tasks including knowledge retrieval, code generation, parameter
recommendation, and image reasoning. Our study demonstrates that PEAR's
multi-agent design significantly improves the workflow success rate, even with
smaller open-weight models such as LLaMA 3.1 8B. PEAR also supports various
automation levels and is designed to work with customized local knowledge
bases, ensuring flexibility and adaptability across different research
environments.",2024-10-11,2024,2024-10,chemistry
Analyzing Atomic Interactions in Molecules as Learned by Neural Networks,"While machine learning (ML) models have been able to achieve unprecedented
accuracies across various prediction tasks in quantum chemistry, it is now
apparent that accuracy on a test set alone is not a guarantee for robust
chemical modeling such as stable molecular dynamics (MD). To go beyond
accuracy, we use explainable artificial intelligence (XAI) techniques to
develop a general analysis framework for atomic interactions and apply it to
the SchNet and PaiNN neural network models. We compare these interactions with
a set of fundamental chemical principles to understand how well the models have
learned the underlying physicochemical concepts from the data. We focus on the
strength of the interactions for different atomic species, how predictions for
intensive and extensive quantum molecular properties are made, and analyze the
decay and many-body nature of the interactions with interatomic distance.
Models that deviate too far from known physical principles produce unstable MD
trajectories, even when they have very high energy and force prediction
accuracy. We also suggest further improvements to the ML architectures to
better account for the polynomial decay of atomic interactions.",2024-10-17,2024,2024-10,chemistry
"Dynamic Guided and Domain Applicable Safeguards for Enhanced Security in
  Large Language Models","With the extensive deployment of Large Language Models (LLMs), ensuring their
safety has become increasingly critical. However, existing defense methods
often struggle with two key issues: (i) inadequate defense capabilities,
particularly in domain-specific scenarios like chemistry, where a lack of
specialized knowledge can lead to the generation of harmful responses to
malicious queries. (ii) over-defensiveness, which compromises the general
utility and responsiveness of LLMs. To mitigate these issues, we introduce a
multi-agents-based defense framework, Guide for Defense (G4D), which leverages
accurate external information to provide an unbiased summary of user intentions
and analytically grounded safety response guidance. Extensive experiments on
popular jailbreak attacks and benign datasets show that our G4D can enhance
LLM's robustness against jailbreak attacks on general and domain-specific
scenarios without compromising the model's general functionality.",2024-10-23,2024,2024-10,chemistry
"An Open Quantum Chemistry Property Database of 120 Kilo Molecules with
  20 Million Conformers","Artificial intelligence is revolutionizing computational chemistry, bringing
unprecedented innovation and efficiency to the field. To further advance
research and expedite progress, we introduce the Quantum Open Organic Molecular
(QO2Mol) database -- a large-scale quantum chemistry dataset designed for
professional and transformative research in organic molecular sciences under an
open-source license. The database comprises 120,000 organic molecules and
approximately 20 million conformers, encompassing 10 different elements (C, H,
O, N, S, P, F, Cl, Br, I), with heavy atom counts exceeding 40. Utilizing the
high-precision B3LYP/def2-SVP quantum mechanical level, each conformation was
meticulously computed for quantum mechanical properties, including potential
energy and forces. These molecules are derived from fragments of compounds in
ChEMBL, ensuring their structural relevance to real-world compounds. Its
extensive coverage of molecular structures and diverse elemental composition
enables comprehensive studies of structure-property relationships, enhancing
the accuracy and applicability of machine learning models in predicting
molecular behaviors. The QO2Mol database and benchmark codes are available at
https://github.com/saiscn/QO2Mol/ .",2024-10-25,2024,2024-10,chemistry
"Can Stories Help LLMs Reason? Curating Information Space Through
  Narrative","Narratives are widely recognized as a powerful tool for structuring
information and facilitating comprehension of complex ideas in various domains
such as science communication. This paper investigates whether incorporating
narrative elements can assist Large Language Models (LLMs) in solving complex
problems more effectively. We propose a novel approach, Story of Thought (SoT),
integrating narrative structures into prompting techniques for problem-solving.
This approach involves constructing narratives around problem statements and
creating a framework to identify and organize relevant information. Our
experiments show that using various LLMs with SoT consistently surpasses using
them with other techniques on physics, chemistry, math, and biology questions
in both the GPQA and JEEBench datasets. The narrative-based information
curation process in SoT enhances problem comprehension by contextualizing
critical in-domain information and highlighting causal relationships within the
problem space.",2024-10-25,2024,2024-10,chemistry
A Foundation Model for Chemical Design and Property Prediction,"Artificial intelligence (AI) has significantly advanced computational
chemistry research in various tasks. However, traditional AI methods often rely
on task-specific model designs and training, which constrain both the
scalability of model size and generalization across different tasks. Here, we
introduce ChemFM, a large foundation model specifically developed for
chemicals. ChemFM comprises 3 billion parameters and is pre-trained on 178
million molecules using self-supervised causal language modeling to extract
generalizable molecular representations. This model can be adapted to diverse
downstream chemical applications using either full-parameter or
parameter-efficient fine-tuning methods. ChemFM consistently outperforms
state-of-the-art task-specific AI models across all tested tasks. Notably, it
achieves up to 67.48% performance improvement across 34 property prediction
benchmarks, up to 33.80% reduction in mean average deviation between
conditioned and actual properties of generated molecules in conditional
molecular generation tasks, and up to 3.7% top-1 accuracy improvement across 4
reaction prediction datasets. Moreover, ChemFM demonstrates its superior
performance in predicting antibiotic activity and cytotoxicity, highlighting
its potential to advance the discovery of novel antibiotics. We anticipate that
ChemFM will significantly advance chemistry research by providing a foundation
model capable of effectively generalizing across a broad range of tasks with
minimal additional training.",2024-10-28,2024,2024-10,chemistry
Bridging Geometric States via Geometric Diffusion Bridge,"The accurate prediction of geometric state evolution in complex systems is
critical for advancing scientific domains such as quantum chemistry and
material modeling. Traditional experimental and computational methods face
challenges in terms of environmental constraints and computational demands,
while current deep learning approaches still fall short in terms of precision
and generality. In this work, we introduce the Geometric Diffusion Bridge
(GDB), a novel generative modeling framework that accurately bridges initial
and target geometric states. GDB leverages a probabilistic approach to evolve
geometric state distributions, employing an equivariant diffusion bridge
derived by a modified version of Doob's $h$-transform for connecting geometric
states. This tailored diffusion process is anchored by initial and target
geometric states as fixed endpoints and governed by equivariant transition
kernels. Moreover, trajectory data can be seamlessly leveraged in our GDB
framework by using a chain of equivariant diffusion bridges, providing a more
detailed and accurate characterization of evolution dynamics. Theoretically, we
conduct a thorough examination to confirm our framework's ability to preserve
joint distributions of geometric states and capability to completely model the
underlying dynamics inducing trajectory distributions with negligible error.
Experimental evaluations across various real-world scenarios show that GDB
surpasses existing state-of-the-art approaches, opening up a new pathway for
accurately bridging geometric states and tackling crucial scientific challenges
with improved accuracy and applicability.",2024-10-31,2024,2024-10,chemistry
"Pre-trained Molecular Language Models with Random Functional Group
  Masking","Recent advancements in computational chemistry have leveraged the power of
trans-former-based language models, such as MoLFormer, pre-trained using a vast
amount of simplified molecular-input line-entry system (SMILES) sequences, to
understand and predict molecular properties and activities, a critical step in
fields like drug discovery and materials science. To further improve
performance, researchers have introduced graph neural networks with graph-based
molecular representations, such as GEM, incorporating the topology, geometry,
2D or even 3D structures of molecules into pre-training. While most of
molecular graphs in existing studies were automatically converted from SMILES
sequences, it is to assume that transformer-based language models might be able
to implicitly learn structure-aware representations from SMILES sequences. In
this paper, we propose \ours{} -- a SMILES-based \underline{\em M}olecular
\underline{\em L}anguage \underline{\em M}odel, which randomly masking SMILES
subsequences corresponding to specific molecular \underline{\em F}unctional
\underline{\em G}roups to incorporate structure information of atoms during the
pre-training phase. This technique aims to compel the model to better infer
molecular structures and properties, thus enhancing its predictive
capabilities. Extensive experimental evaluations across 11 benchmark
classification and regression tasks in the chemical domain demonstrate the
robustness and superiority of \ours{}. Our findings reveal that \ours{}
outperforms existing pre-training models, either based on SMILES or graphs, in
9 out of the 11 downstream tasks, ranking as a close second in the remaining
ones.",2024-11-03,2024,2024-11,chemistry
"Exploring the Benefits of Domain-Pretraining of Generative Large
  Language Models for Chemistry","A proliferation of Large Language Models (the GPT series, BLOOM, LLaMA, and
more) are driving forward novel development of multipurpose AI for a variety of
tasks, particularly natural language processing (NLP) tasks. These models
demonstrate strong performance on a range of tasks; however, there has been
evidence of brittleness when applied to more niche or narrow domains where
hallucinations or fluent but incorrect responses reduce performance. Given the
complex nature of scientific domains, it is prudent to investigate the
trade-offs of leveraging off-the-shelf versus more targeted foundation models
for scientific domains. In this work, we examine the benefits of in-domain
pre-training for a given scientific domain, chemistry, and compare these to
open-source, off-the-shelf models with zero-shot and few-shot prompting. Our
results show that not only do in-domain base models perform reasonably well on
in-domain tasks in a zero-shot setting but that further adaptation using
instruction fine-tuning yields impressive performance on chemistry-specific
tasks such as named entity recognition and molecular formula generation.",2024-11-05,2024,2024-11,chemistry
"Bio-xLSTM: Generative modeling, representation and in-context learning
  of biological and chemical sequences","Language models for biological and chemical sequences enable crucial
applications such as drug discovery, protein engineering, and precision
medicine. Currently, these language models are predominantly based on
Transformer architectures. While Transformers have yielded impressive results,
their quadratic runtime dependency on the sequence length complicates their use
for long genomic sequences and in-context learning on proteins and chemical
sequences. Recently, the recurrent xLSTM architecture has been shown to perform
favorably compared to Transformers and modern state-space model (SSM)
architectures in the natural language domain. Similar to SSMs, xLSTMs have a
linear runtime dependency on the sequence length and allow for constant-memory
decoding at inference time, which makes them prime candidates for modeling
long-range dependencies in biological and chemical sequences. In this work, we
tailor xLSTM towards these domains and propose a suite of architectural
variants called Bio-xLSTM. Extensive experiments in three large domains,
genomics, proteins, and chemistry, were performed to assess xLSTM's ability to
model biological and chemical sequences. The results show that models based on
Bio-xLSTM a) can serve as proficient generative models for DNA, protein, and
chemical sequences, b) learn rich representations for those modalities, and c)
can perform in-context learning for proteins and small molecules.",2024-11-06,2024,2024-11,chemistry
"ChemToolAgent: The Impact of Tools on Language Agents for Chemistry
  Problem Solving","To enhance large language models (LLMs) for chemistry problem solving,
several LLM-based agents augmented with tools have been proposed, such as
ChemCrow and Coscientist. However, their evaluations are narrow in scope,
leaving a large gap in understanding the benefits of tools across diverse
chemistry tasks. To bridge this gap, we develop ChemToolAgent, an enhanced
chemistry agent over ChemCrow, and conduct a comprehensive evaluation of its
performance on both specialized chemistry tasks and general chemistry
questions. Surprisingly, ChemToolAgent does not consistently outperform its
base LLMs without tools. Our error analysis with a chemistry expert suggests
that: For specialized chemistry tasks, such as synthesis prediction, we should
augment agents with specialized tools; however, for general chemistry questions
like those in exams, agents' ability to reason correctly with chemistry
knowledge matters more, and tool augmentation does not always help.",2024-11-11,2024,2024-11,chemistry
Polymetis:Large Language Modeling for Multiple Material Domains,"As the application of large language models in various fields continues to
expand, materials science also ushers in opportunities for AI-driven
innovation. The traditional way of relying on manual search for materials
science-related information is now using artificial intelligence technology as
an auxiliary tool to improve the efficiency of materials science research. To
accelerate researchers' knowledge acquisition and intelligent decision-making
support in materials science research, this paper proposes a large language
model Polymetis model for a variety of materials fields, aiming to provide
highly professional knowledge answers in the field of materials, covering
energy materials, functional materials, alloy materials, physical chemistry,
biology, and other material directions. The model uses a dataset of about 2
million material knowledge instructions, and in the process of building the
dataset, we developed the Intelligent Extraction Large Model (IELM), which is
specially used to extract and form structured knowledge from scientific texts,
avoiding a large number of costs that need to be manually annotated, and
improving efficiency. We inject this data into the GLM4-9B model for learning
to enhance its inference capabilities in a variety of material domains. In
addition, we have introduced enhanced prompt strategies to ensure that the
answers to the model are more organized and comprehensive, providing efficient
and comprehensive intelligent support for the diverse needs of materials
science exploration, and promoting the development of material science.",2024-11-13,2024,2024-11,chemistry
"Energy-GNoME: A Living Database of Selected Materials for Energy
  Applications","Artificial Intelligence (AI) in materials science is driving significant
advancements in the discovery of advanced materials for energy applications.
The recent GNoME protocol identifies over 380,000 novel stable crystals. From
this, we identify over 33,000 materials with potential as energy materials
forming the Energy-GNoME database. Leveraging Machine Learning (ML) and Deep
Learning (DL) tools, our protocol mitigates cross-domain data bias using
feature spaces to identify potential candidates for thermoelectric materials,
novel battery cathodes, and novel perovskites. Classifiers with both structural
and compositional features identify domains of applicability, where we expect
enhanced accuracy of the regressors. Such regressors are trained to predict key
materials properties like, thermoelectric figure of merit (zT), band gap (Eg),
and cathode voltage ($\Delta V_c$). This method significantly narrows the pool
of potential candidates, serving as an efficient guide for experimental and
computational chemistry investigations and accelerating the discovery of
materials suited for electricity generation, energy storage and conversion.",2024-11-15,2024,2024-11,chemistry
"BioNeMo Framework: a modular, high-performance library for AI model
  development in drug discovery","Artificial Intelligence models encoding biology and chemistry are opening new
routes to high-throughput and high-quality in-silico drug development. However,
their training increasingly relies on computational scale, with recent protein
language models (pLM) training on hundreds of graphical processing units
(GPUs). We introduce the BioNeMo Framework to facilitate the training of
computational biology and chemistry AI models across hundreds of GPUs. Its
modular design allows the integration of individual components, such as data
loaders, into existing workflows and is open to community contributions. We
detail technical features of the BioNeMo Framework through use cases such as
pLM pre-training and fine-tuning. On 256 NVIDIA A100s, BioNeMo Framework trains
a three billion parameter BERT-based pLM on over one trillion tokens in 4.2
days. The BioNeMo Framework is open-source and free for everyone to use.",2024-11-15,2024,2024-11,chemistry
"How to Build a Quantum Supercomputer: Scaling from Hundreds to Millions
  of Qubits","In the span of four decades, quantum computation has evolved from an
intellectual curiosity to a potentially realizable technology. Today,
small-scale demonstrations have become possible for quantum algorithmic
primitives on hundreds of physical qubits and proof-of-principle
error-correction on a single logical qubit. Nevertheless, despite significant
progress and excitement, the path toward a full-stack scalable technology is
largely unknown. There are significant outstanding quantum hardware,
fabrication, software architecture, and algorithmic challenges that are either
unresolved or overlooked. These issues could seriously undermine the arrival of
utility-scale quantum computers for the foreseeable future. Here, we provide a
comprehensive review of these scaling challenges. We show how the road to
scaling could be paved by adopting existing semiconductor technology to build
much higher-quality qubits, employing system engineering approaches, and
performing distributed quantum computation within heterogeneous
high-performance computing infrastructures. These opportunities for research
and development could unlock certain promising applications, in particular,
efficient quantum simulation/learning of quantum data generated by natural or
engineered quantum systems. To estimate the true cost of such promises, we
provide a detailed resource and sensitivity analysis for classically hard
quantum chemistry calculations on surface-code error-corrected quantum
computers given current, target, and desired hardware specifications based on
superconducting qubits, accounting for a realistic distribution of errors.
Furthermore, we argue that, to tackle industry-scale classical optimization and
machine learning problems in a cost-effective manner, heterogeneous
quantum-probabilistic computing with custom-designed accelerators should be
considered as a complementary path toward scalability.",2024-11-15,2024,2024-11,chemistry
"Umbrella Reinforcement Learning -- computationally efficient tool for
  hard non-linear problems","We report a novel, computationally efficient approach for solving hard
nonlinear problems of reinforcement learning (RL). Here we combine umbrella
sampling, from computational physics/chemistry, with optimal control methods.
The approach is realized on the basis of neural networks, with the use of
policy gradient. It outperforms, by computational efficiency and implementation
universality, all available state-of-the-art algorithms, in application to hard
RL problems with sparse reward, state traps and lack of terminal states. The
proposed approach uses an ensemble of simultaneously acting agents, with a
modified reward which includes the ensemble entropy, yielding an optimal
exploration-exploitation balance.",2024-11-21,2024,2024-11,chemistry
ChemSafetyBench: Benchmarking LLM Safety on Chemistry Domain,"The advancement and extensive application of large language models (LLMs)
have been remarkable, including their use in scientific research assistance.
However, these models often generate scientifically incorrect or unsafe
responses, and in some cases, they may encourage users to engage in dangerous
behavior. To address this issue in the field of chemistry, we introduce
ChemSafetyBench, a benchmark designed to evaluate the accuracy and safety of
LLM responses. ChemSafetyBench encompasses three key tasks: querying chemical
properties, assessing the legality of chemical uses, and describing synthesis
methods, each requiring increasingly deeper chemical knowledge. Our dataset has
more than 30K samples across various chemical materials. We incorporate
handcrafted templates and advanced jailbreaking scenarios to enhance task
diversity. Our automated evaluation framework thoroughly assesses the safety,
accuracy, and appropriateness of LLM responses. Extensive experiments with
state-of-the-art LLMs reveal notable strengths and critical vulnerabilities,
underscoring the need for robust safety measures. ChemSafetyBench aims to be a
pivotal tool in developing safer AI technologies in chemistry. Our code and
dataset are available at https://github.com/HaochenZhao/SafeAgent4Chem.
Warning: this paper contains discussions on the synthesis of controlled
chemicals using AI models.",2024-11-23,2024,2024-11,chemistry
"Probing the limitations of multimodal language models for chemistry and
  materials research","Recent advancements in artificial intelligence have sparked interest in
scientific assistants that could support researchers across the full spectrum
of scientific workflows, from literature review to experimental design and data
analysis. A key capability for such systems is the ability to process and
reason about scientific information in both visual and textual forms - from
interpreting spectroscopic data to understanding laboratory setups. Here, we
introduce MaCBench, a comprehensive benchmark for evaluating how
vision-language models handle real-world chemistry and materials science tasks
across three core aspects: data extraction, experimental understanding, and
results interpretation. Through a systematic evaluation of leading models, we
find that while these systems show promising capabilities in basic perception
tasks - achieving near-perfect performance in equipment identification and
standardized data extraction - they exhibit fundamental limitations in spatial
reasoning, cross-modal information synthesis, and multi-step logical inference.
Our insights have important implications beyond chemistry and materials
science, suggesting that developing reliable multimodal AI scientific
assistants may require advances in curating suitable training data and
approaches to training those models.",2024-11-25,2024,2024-11,chemistry
"Uni-Electrolyte: An Artificial Intelligence Platform for Designing
  Electrolyte Molecules for Rechargeable Batteries","Electrolyte is a very important part of rechargeable batteries such as
lithium batteries. However, the electrolyte innovation is facing grand
challenges due to the complicated solution chemistry and infinite molecular
space (>1060 for small molecules). This work reported an artificial
intelligence (AI) platform, namely Uni-Electrolyte, for designing advanced
electrolyte molecules, which mainly includes three parts, i.e. EMolCurator,
EMolForger, and EMolNetKnittor. New molecules can be designed by combining
high-throughput screening and generative AI models from more than 100 million
alternative molecules in the EMolCurator module. The molecule properties
including frontier molecular orbital information, formation energy, binding
energy with a Li ion, viscosity, and dielectric constant, can be adopted as the
screening parameters. The EMolForger, and EMolNetKnittor module can predict the
retrosynthesis pathway and reaction pathway with electrodes for a given
molecule, respectively. With the assist of advanced AI methods, the
Uni-Electrolyte is strongly supposed to discover new electrolyte molecules and
chemical principles, promoting the practical application of next-generation
rechargeable batteries.",2024-11-30,2024,2024-11,chemistry
"ActPC-Chem: Discrete Active Predictive Coding for Goal-Guided
  Algorithmic Chemistry as a Potential Cognitive Kernel for Hyperon &
  PRIMUS-Based AGI","We explore a novel paradigm (labeled ActPC-Chem) for biologically inspired,
goal-guided artificial intelligence (AI) centered on a form of Discrete Active
Predictive Coding (ActPC) operating within an algorithmic chemistry of rewrite
rules. ActPC-Chem is envisioned as a foundational ""cognitive kernel"" for
advanced cognitive architectures, such as the OpenCog Hyperon system,
incorporating essential elements of the PRIMUS cognitive architecture. The
central thesis is that general-intelligence-capable cognitive structures and
dynamics can emerge in a system where both data and models are represented as
evolving patterns of metagraph rewrite rules, and where prediction errors,
intrinsic and extrinsic rewards, and semantic constraints guide the continual
reorganization and refinement of these rules. Using a virtual ""robot bug""
thought experiment, we illustrate how such a system might self-organize to
handle challenging tasks involving delayed and context-dependent rewards,
integrating causal rule inference (AIRIS) and probabilistic logical abstraction
(PLN) to discover and exploit conceptual patterns and causal constraints. Next,
we describe how continuous predictive coding neural networks, which excel at
handling noisy sensory data and motor control signals, can be coherently merged
with the discrete ActPC substrate. Finally, we outline how these ideas might be
extended to create a transformer-like architecture that foregoes traditional
backpropagation in favor of rule-based transformations guided by ActPC. This
layered architecture, supplemented with AIRIS and PLN, promises structured,
multi-modal, and logically consistent next-token predictions and narrative
sequences.",2024-12-21,2024,2024-12,chemistry
"""Did my figure do justice to the answer?"" : Towards Multimodal Short
  Answer Grading with Feedback (MMSAF)","Assessments play a vital role in a student's learning process by providing
feedback on a student's proficiency level in a subject. While assessments often
make use of short answer questions, it is often difficult to grade such
questions at a large scale. Moreover, such questions often involve students
drawing supporting diagrams along with their textual explanations. Such
questions often promote multimodal literacy and are aligned with
competency-based questions, which demand a deeper cognitive processing ability
from students. However, existing literature does not deal with the automatic
grading of such answers. Thus, to bridge this gap, we propose the Multimodal
Short Answer Grading with Feedback (MMSAF) problem along with a dataset of 2197
data points. Additionally, we provide an automated framework for generating
such datasets. Our evaluations on existing Large Language Models (LLMs) over
this dataset achieved an overall accuracy of 55% on the Level of Correctness
labels and 75% on Image Relevance labels. As per human experts, Pixtral was
more aligned towards human judgement and values for biology and ChatGPT for
physics and chemistry and achieved a score of 4 or more out of 5 in most
parameters.",2024-12-27,2024,2024-12,chemistry
"From Generalist to Specialist: A Survey of Large Language Models for
  Chemistry","Large Language Models (LLMs) have significantly transformed our daily life
and established a new paradigm in natural language processing (NLP). However,
the predominant pretraining of LLMs on extensive web-based texts remains
insufficient for advanced scientific discovery, particularly in chemistry. The
scarcity of specialized chemistry data, coupled with the complexity of
multi-modal data such as 2D graph, 3D structure and spectrum, present distinct
challenges. Although several studies have reviewed Pretrained Language Models
(PLMs) in chemistry, there is a conspicuous absence of a systematic survey
specifically focused on chemistry-oriented LLMs. In this paper, we outline
methodologies for incorporating domain-specific chemistry knowledge and
multi-modal information into LLMs, we also conceptualize chemistry LLMs as
agents using chemistry tools and investigate their potential to accelerate
scientific research. Additionally, we conclude the existing benchmarks to
evaluate chemistry ability of LLMs. Finally, we critically examine the current
challenges and identify promising directions for future research. Through this
comprehensive survey, we aim to assist researchers in staying at the forefront
of developments in chemistry LLMs and to inspire innovative applications in the
field.",2024-12-28,2024,2024-12,chemistry
MiBoard: Multiplayer Interactive Board Game,"Serious games have recently emerged as an avenue for curriculum delivery.
Serious games incorporate motivation and entertainment while providing pointed
curriculum for the user. This paper presents a serious game, called MiBoard,
currently being developed from the iSTART Intelligent Tutoring System. MiBoard
incorporates a multiplayer interaction that iSTART was previously unable to
provide. This multiplayer interaction produces a wide variation across game
trials, while also increasing the repeat playability for users. This paper
presents a demonstration of the MiBoard system and the expectations for its
application.",2010-09-12,2010,2010-09,education
Steepest Ascent Hill Climbing For A Mathematical Problem,"The paper proposes artificial intelligence technique called hill climbing to
find numerical solutions of Diophantine Equations. Such equations are important
as they have many applications in fields like public key cryptography, integer
factorization, algebraic curves, projective curves and data dependency in super
computers. Importantly, it has been proved that there is no general method to
find solutions of such equations. This paper is an attempt to find numerical
solutions of Diophantine equations using steepest ascent version of Hill
Climbing. The method, which uses tree representation to depict possible
solutions of Diophantine equations, adopts a novel methodology to generate
successors. The heuristic function used help to make the process of finding
solution as a minimization process. The work illustrates the effectiveness of
the proposed methodology using a class of Diophantine equations given by a1. x1
p1 + a2. x2 p2 + ...... + an . xn pn = N where ai and N are integers. The
experimental results validate that the procedure proposed is successful in
finding solutions of Diophantine Equations with sufficiently large powers and
large number of variables.",2010-10-02,2010,2010-10,education
Fundamentals of Mathematical Theory of Emotional Robots,"In this book we introduce a mathematically formalized concept of emotion,
robot's education and other psychological parameters of intelligent robots. We
also introduce unitless coefficients characterizing an emotional memory of a
robot. Besides, the effect of a robot's memory upon its emotional behavior is
studied, and theorems defining fellowship and conflicts in groups of robots are
proved. Also unitless parameters describing emotional states of those groups
are introduced, and a rule of making alternative (binary) decisions based on
emotional selection is given. We introduce a concept of equivalent educational
process for robots and a concept of efficiency coefficient of an educational
process, and suggest an algorithm of emotional contacts within a group of
robots. And generally, we present and describe a model of a virtual reality
with emotional robots. The book is meant for mathematical modeling specialists
and emotional robot software developers.",2010-10-17,2010,2010-10,education
Promoting scientific thinking with robots,"This article describes an exemplary robot exercise which was conducted in a
class for mechatronics students. The goal of this exercise was to engage
students in scientific thinking and reasoning, activities which do not always
play an important role in their curriculum. The robotic platform presented here
is simple in its construction and is customizable to the needs of the teacher.
Therefore, it can be used for exercises in many different fields of science,
not necessarily related to robotics. Here we present a situation where the
robot is used like an alien creature from which we want to understand its
behavior, resembling an ethological research activity. This robot exercise is
suited for a wide range of courses, from general introduction to science, to
hardware oriented lectures.",2011-08-22,2011,2011-08,education
Unfair items detection in educational measurement,"Measurement professionals cannot come to an agreement on the definition of
the term 'item fairness'. In this paper a continuous measure of item unfairness
is proposed. The more the unfairness measure deviates from zero, the less fair
the item is. If the measure exceeds the cutoff value, the item is identified as
definitely unfair. The new approach can identify unfair items that would not be
identified with conventional procedures. The results are in accord with
experts' judgments on the item qualities. Since no assumptions about scores
distributions and/or correlations are assumed, the method is applicable to any
educational test. Its performance is illustrated through application to scores
of a real test.",2012-02-11,2012,2012-02,education
Recommender System Based on Algorithm of Bicluster Analysis RecBi,"In this paper we propose two new algorithms based on biclustering analysis,
which can be used at the basis of a recommender system for educational
orientation of Russian School graduates. The first algorithm was designed to
help students make a choice between different university faculties when some of
their preferences are known. The second algorithm was developed for the special
situation when nothing is known about their preferences. The final version of
this recommender system will be used by Higher School of Economics.",2012-02-13,2012,2012-02,education
Isabelle/PIDE as Platform for Educational Tools,"The Isabelle/PIDE platform addresses the question whether proof assistants of
the LCF family are suitable as technological basis for educational tools. The
traditionally strong logical foundations of systems like HOL, Coq, or Isabelle
have so far been counter-balanced by somewhat inaccessible interaction via the
TTY (or minor variations like the well-known Proof General / Emacs interface).
Thus the fundamental question of math education tools with fully-formal
background theories has often been answered negatively due to accidental
weaknesses of existing proof engines.
  The idea of ""PIDE"" (which means ""Prover IDE"") is to integrate existing
provers like Isabelle into a larger environment, that facilitates access by
end-users and other tools. We use Scala to expose the proof engine in ML to the
JVM world, where many user-interfaces, editor frameworks, and educational tools
already exist. This shall ultimately lead to combined mathematical assistants,
where the logical engine is in the background, without obstructing the view on
applications of formal methods, formalized mathematics, and math education in
particular.",2012-02-22,2012,2012-02,education
RAPID: A Reachable Anytime Planner for Imprecisely-sensed Domains,"Despite the intractability of generic optimal partially observable Markov
decision process planning, there exist important problems that have highly
structured models. Previous researchers have used this insight to construct
more efficient algorithms for factored domains, and for domains with
topological structure in the flat state dynamics model. In our work, motivated
by findings from the education community relevant to automated tutoring, we
consider problems that exhibit a form of topological structure in the factored
dynamics model. Our Reachable Anytime Planner for Imprecisely-sensed Domains
(RAPID) leverages this structure to efficiently compute a good initial envelope
of reachable states under the optimal MDP policy in time linear in the number
of state variables. RAPID performs partially-observable planning over the
limited envelope of states, and slowly expands the state space considered as
time allows. RAPID performs well on a large tutoring-inspired problem
simulation with 122 state variables, corresponding to a flat state space of
over 10^30 states.",2012-03-15,2012,2012-03,education
Effects of Treatment on the Treated: Identification and Generalization,"Many applications of causal analysis call for assessing, retrospectively, the
effect of withholding an action that has in fact been implemented. This
counterfactual quantity, sometimes called ""effect of treatment on the treated,""
(ETT) have been used to to evaluate educational programs, critic public
policies, and justify individual decision making. In this paper we explore the
conditions under which ETT can be estimated from (i.e., identified in)
experimental and/or observational studies. We show that, when the action
invokes a singleton variable, the conditions for ETT identification have simple
characterizations in terms of causal diagrams. We further give a graphical
characterization of the conditions under which the effects of multiple
treatments on the treated can be identified, as well as ways in which the ETT
estimand can be constructed from both interventional and observational
distributions.",2012-05-09,2012,2012-05,education
Arabic CALL system based on pedagogically indexed text,"This article introduces the benefits of using computer as a tool for foreign
language teaching and learning. It describes the effect of using Natural
Language Processing (NLP) tools for learning Arabic. The technique explored in
this particular case is the employment of pedagogically indexed corpora. This
text-based method provides the teacher the advantage of building activities
based on texts adapted to a particular pedagogical situation. This paper also
presents ARAC: a Platform dedicated to language educators allowing them to
create activities within their own pedagogical area of interest.",2012-07-10,2012,2012-07,education
Bayes Nets in Educational Assessment: Where Do the Numbers Come From?,"As observations and student models become complex, educational assessments
that exploit advances in technology and cognitive psychology can outstrip
familiar testing models and analytic methods. Within the Portal conceptual
framework for assessment design, Bayesian inference networks (BINs) record
beliefs about students' knowledge and skills, in light of what they say and do.
Joining evidence model BIN fragments- which contain observable variables and
pointers to student model variables - to the student model allows one to update
belief about knowledge and skills as observations arrive. Markov Chain Monte
Carlo (MCMC) techniques can estimate the required conditional probabilities
from empirical data, supplemented by expert judgment or substantive theory.
Details for the special cases of item response theory (IRT) and multivariate
latent class modeling are given, with a numerical example of the latter.",2013-01-23,2013,2013-01,education
"A Rough Computing based Performance Evaluation Approach for Educational
  Institutions","Performance evaluation of various organizations especially educational
institutions is a very important area of research and needs to be cultivated
more. In this paper, we propose a performance evaluation for educational
institutions using rough set on fuzzy approximation spaces with ordering rules
and information entropy. In order to measure the performance of educational
institutions, we construct an evaluation index system. Rough set on fuzzy
approximation spaces with ordering is applied to explore the evaluation index
data of each level. Furthermore, the concept of information entropy is used to
determine the weighting coefficients of evaluation indexes. Also, we find the
most important indexes that influence the weighting coefficients. The proposed
approach is validated and shows the practical viability. Moreover, the proposed
approach can be applicable to any organizations.",2013-08-03,2013,2013-08,education
"Querying Geometric Figures Using a Controlled Language, Ontological
  Graphs and Dependency Lattices","Dynamic geometry systems (DGS) have become basic tools in many areas of
geometry as, for example, in education. Geometry Automated Theorem Provers
(GATP) are an active area of research and are considered as being basic tools
in future enhanced educational software as well as in a next generation of
mechanized mathematics assistants. Recently emerged Web repositories of
geometric knowledge, like TGTP and Intergeo, are an attempt to make the already
vast data set of geometric knowledge widely available. Considering the large
amount of geometric information already available, we face the need of a query
mechanism for descriptions of geometric constructions.
  In this paper we discuss two approaches for describing geometric figures
(declarative and procedural), and present algorithms for querying geometric
figures in declaratively and procedurally described corpora, by using a DGS or
a dedicated controlled natural language for queries.",2014-03-10,2014,2014-03,education
"Building a Classification Model for Enrollment In Higher Educational
  Courses using Data Mining Techniques","Data Mining is the process of extracting useful patterns from the huge amount
of database and many data mining techniques are used for mining these patterns.
Recently, one of the remarkable facts in higher educational institute is the
rapid growth data and this educational data is expanding quickly without any
advantage to the educational management. The main aim of the management is to
refine the education standard; therefore by applying the various data mining
techniques on this data one can get valuable information. This research study
proposed the ""classification model for the student's enrollment process in
higher educational courses using data mining techniques"". Additionally, this
study contributes to finding some patterns that are meaningful to management.",2014-05-15,2014,2014-05,education
Automated Generation of Geometric Theorems from Images of Diagrams,"We propose an approach to generate geometric theorems from electronic images
of diagrams automatically. The approach makes use of techniques of Hough
transform to recognize geometric objects and their labels and of numeric
verification to mine basic geometric relations. Candidate propositions are
generated from the retrieved information by using six strategies and geometric
theorems are obtained from the candidates via algebraic computation.
Experiments with a preliminary implementation illustrate the effectiveness and
efficiency of the proposed approach for generating nontrivial theorems from
images of diagrams. This work demonstrates the feasibility of automated
discovery of profound geometric knowledge from simple image data and has
potential applications in geometric knowledge management and education.",2014-06-06,2014,2014-06,education
$OntoMath^{PRO}$ Ontology: A Linked Data Hub for Mathematics,"In this paper, we present an ontology of mathematical knowledge concepts that
covers a wide range of the fields of mathematics and introduces a balanced
representation between comprehensive and sensible models. We demonstrate the
applications of this representation in information extraction, semantic search,
and education. We argue that the ontology can be a core of future integration
of math-aware data sets in the Web of Data and, therefore, provide mappings
onto relevant datasets, such as DBpedia and ScienceWISE.",2014-07-17,2014,2014-07,education
eTutor: Online Learning for Personalized Education,"Given recent advances in information technology and artificial intelligence,
web-based education systems have became complementary and, in some cases,
viable alternatives to traditional classroom teaching. The popularity of these
systems stems from their ability to make education available to a large
demographics (see MOOCs). However, existing systems do not take advantage of
the personalization which becomes possible when web-based education is offered:
they continue to be one-size-fits-all. In this paper, we aim to provide a first
systematic method for designing a personalized web-based education system.
Personalizing education is challenging: (i) students need to be provided
personalized teaching and training depending on their contexts (e.g. classes
already taken, methods of learning preferred, etc.), (ii) for each specific
context, the best teaching and training method (e.g type and order of teaching
materials to be shown) must be learned, (iii) teaching and training should be
adapted online, based on the scores/feedback (e.g. tests, quizzes, final exam,
likes/dislikes etc.) of the students. Our personalized online system, e-Tutor,
is able to address these challenges by learning how to adapt the teaching
methodology (in this case what sequence of teaching material to present to a
student) to maximize her performance in the final exam, while minimizing the
time spent by the students to learn the course (and possibly dropouts). We
illustrate the efficiency of the proposed method on a real-world eTutor
platform which is used for remedial training for a Digital Signal Processing
(DSP) course.",2014-10-14,2014,2014-10,education
Deep Knowledge Tracing,"Knowledge tracing---where a machine models the knowledge of a student as they
interact with coursework---is a well established problem in computer supported
education. Though effectively modeling student knowledge would have high
educational impact, the task has many inherent challenges. In this paper we
explore the utility of using Recurrent Neural Networks (RNNs) to model student
learning. The RNN family of models have important advantages over previous
methods in that they do not require the explicit encoding of human domain
knowledge, and can capture more complex representations of student knowledge.
Using neural networks results in substantial improvements in prediction
performance on a range of knowledge tracing datasets. Moreover the learned
model can be used for intelligent curriculum design and allows straightforward
interpretation and discovery of structure in student tasks. These results
suggest a promising new line of research for knowledge tracing and an exemplary
application task for RNNs.",2015-06-19,2015,2015-06,education
"Automated Matchmaking to Improve Accuracy of Applicant Selection for
  University Education System","The accurate applicant selection for university education is imperative to
ensure fairness and optimal use of institutional resources. Although various
approaches are operational in tertiary educational institutions for selecting
applicants, a novel method of automated matchmaking is explored in the current
study. The method functions by matching a prospective students skills profile
to a programmes requisites profile.
  Empirical comparisons of the results, calculated by automated matchmaking and
two other selection methods, show matchmaking to be a viable alternative for
accurate selection of applicants. Matchmaking offers a unique advantage that it
neither requires data from other applicants nor compares applicants with each
other. Instead, it emphasises norms that define admissibility to a programme.
  We have proposed the use of technology to minimize the gap between students
aspirations, skill sets and course requirements. It is a solution to minimize
the number of students who get frustrated because of mismatched course
selection.",2015-07-09,2015,2015-07,education
Philosophical Fictionalism and Problem of Artificial Intelligence,"The artificial intelligence received broad interpretation as a literary
image. This approach did not have unambiguous refering to the scopes of logical
studies and mathematical investigations. An author applied methods peculiar to
the semiotic approach, offered by Boris Uspensky and Yury Lotman. In addition,
the article presented the criticism of modern versions of educational
technologies, which led to the unconditional expectations for possibilities of
information and telecommunication technologies. Methodological culture's
growth, which was described on the base of semiotics and functional approach to
word formation of new meanings for the description of the studied subjects,
provided the development of pupils' thought. As a result, the research opened
new prospects on understanding of artificial intelligence within educational
practice.",2016-02-23,2016,2016-02,education
Latent Skill Embedding for Personalized Lesson Sequence Recommendation,"Students in online courses generate large amounts of data that can be used to
personalize the learning process and improve quality of education. In this
paper, we present the Latent Skill Embedding (LSE), a probabilistic model of
students and educational content that can be used to recommend personalized
sequences of lessons with the goal of helping students prepare for specific
assessments. Akin to collaborative filtering for recommender systems, the
algorithm does not require students or content to be described by features, but
it learns a representation using access traces. We formulate this problem as a
regularized maximum-likelihood embedding of students, lessons, and assessments
from historical student-content interactions. An empirical evaluation on
large-scale data from Knewton, an adaptive learning technology company, shows
that this approach predicts assessment results competitively with benchmark
models and is able to discriminate between lesson sequences that lead to
mastery and failure.",2016-02-23,2016,2016-02,education
"An artificial intelligence tool for heterogeneous team formation in the
  classroom","Nowadays, there is increasing interest in the development of teamwork skills
in the educational context. This growing interest is motivated by its
pedagogical effectiveness and the fact that, in labour contexts, enterprises
organize their employees in teams to carry out complex projects. Despite its
crucial importance in the classroom and industry, there is a lack of support
for the team formation process. Not only do many factors influence team
performance, but the problem becomes exponentially costly if teams are to be
optimized. In this article, we propose a tool whose aim it is to cover such a
gap. It combines artificial intelligence techniques such as coalition structure
generation, Bayesian learning, and Belbin's role theory to facilitate the
generation of working groups in an educational context. This tool improves
current state of the art proposals in three ways: i) it takes into account the
feedback of other teammates in order to establish the most predominant role of
a student instead of self-perception questionnaires; ii) it handles uncertainty
with regard to each student's predominant team role; iii) it is iterative since
it considers information from several interactions in order to improve the
estimation of role assignments. We tested the performance of the proposed tool
in an experiment involving students that took part in three different team
activities. The experiments suggest that the proposed tool is able to improve
different teamwork aspects such as team dynamics and student satisfaction.",2016-04-16,2016,2016-04,education
Human vs. Computer Go: Review and Prospect,"The Google DeepMind challenge match in March 2016 was a historic achievement
for computer Go development. This article discusses the development of
computational intelligence (CI) and its relative strength in comparison with
human intelligence for the game of Go. We first summarize the milestones
achieved for computer Go from 1998 to 2016. Then, the computer Go programs that
have participated in previous IEEE CIS competitions as well as methods and
techniques used in AlphaGo are briefly introduced. Commentaries from three
high-level professional Go players on the five AlphaGo versus Lee Sedol games
are also included. We conclude that AlphaGo beating Lee Sedol is a huge
achievement in artificial intelligence (AI) based largely on CI methods. In the
future, powerful computer Go programs such as AlphaGo are expected to be
instrumental in promoting Go education and AI real-world applications.",2016-06-07,2016,2016-06,education
"Deploying learning materials to game content for serious education game
  development: A case study","The ultimate goals of serious education games (SEG) are to facilitate
learning and maximizing enjoyment during playing SEGs. In SEG development,
there are normally two spaces to be taken into account: knowledge space
regarding learning materials and content space regarding games to be used to
convey learning materials. How to deploy the learning materials seamlessly and
effectively into game content becomes one of the most challenging problems in
SEG development. Unlike previous work where experts in education have to be
used heavily, we proposed a novel approach that works toward minimizing the
efforts of education experts in mapping learning materials to content space.
For a proof-of-concept, we apply the proposed approach in developing an SEG
game, named \emph{Chem Dungeon}, as a case study in order to demonstrate the
effectiveness of our proposed approach. This SEG game has been tested with a
number of users, and the user survey suggests our method works reasonably well.",2016-08-04,2016,2016-08,education
Multi Exit Configuration of Mesoscopic Pedestrian Simulation,"A mesoscopic approach to modeling pedestrian simulation with multiple exits
is proposed in this paper. A floor field based on Qlearning Algorithm is used.
Attractiveness of exits to pedestrian typically is based on shortest path.
However, several factors may influence pedestrian choice of exits. Scenarios
with multiple exits are presented and effect of Q-learning rewards system on
navigation is investigated",2016-09-06,2016,2016-09,education
Equilibrium Graphs,"In this paper we present an extension of Peirce's existential graphs to
provide a diagrammatic representation of expressions in Quantified Equilibrium
Logic (QEL). Using this formalisation, logical connectives are replaced by
encircled regions (circles and squares) and quantified variables are
represented as ""identity"" lines. Although the expressive power is equivalent to
that of QEL, the new representation can be useful for illustrative or
educational purposes.",2016-09-07,2016,2016-09,education
Long-Term Trends in the Public Perception of Artificial Intelligence,"Analyses of text corpora over time can reveal trends in beliefs, interest,
and sentiment about a topic. We focus on views expressed about artificial
intelligence (AI) in the New York Times over a 30-year period. General
interest, awareness, and discussion about AI has waxed and waned since the
field was founded in 1956. We present a set of measures that captures levels of
engagement, measures of pessimism and optimism, the prevalence of specific
hopes and concerns, and topics that are linked to discussions about AI over
decades. We find that discussion of AI has increased sharply since 2009, and
that these discussions have been consistently more optimistic than pessimistic.
However, when we examine specific concerns, we find that worries of loss of
control of AI, ethical concerns for AI, and the negative impact of AI on work
have grown in recent years. We also find that hopes for AI in healthcare and
education have increased over time.",2016-09-16,2016,2016-09,education
A Fuzzy Logic System to Analyze a Student's Lifestyle,"A college student's life can be primarily categorized into domains such as
education, health, social and other activities which may include daily chores
and travelling time. Time management is crucial for every student. A self
realisation of one's daily time expenditure in various domains is therefore
essential to maximize one's effective output. This paper presents how a mobile
application using Fuzzy Logic and Global Positioning System (GPS) analyzes a
student's lifestyle and provides recommendations and suggestions based on the
results.",2016-10-13,2016,2016-10,education
An Evolving Neuro-Fuzzy System with Online Learning/Self-learning,"An architecture of a new neuro-fuzzy system is proposed. The basic idea of
this approach is to tune both synaptic weights and membership functions with
the help of the supervised learning and self-learning paradigms. The approach
to solving the problem has to do with evolving online neuro-fuzzy systems that
can process data under uncertainty conditions. The results prove the
effectiveness of the developed architecture and the learning procedure.",2016-10-20,2016,2016-10,education
"An Ensemble of Adaptive Neuro-Fuzzy Kohonen Networks for Online Data
  Stream Fuzzy Clustering","A new approach to data stream clustering with the help of an ensemble of
adaptive neuro-fuzzy systems is proposed. The proposed ensemble is formed with
adaptive neuro-fuzzy self-organizing Kohonen maps in a parallel processing
mode. A final result is chosen by the best neuro-fuzzy self-organizing Kohonen
map.",2016-10-20,2016,2016-10,education
"Analysis of the Human-Computer Interaction on the Example of Image-based
  CAPTCHA by Association Rule Mining","The paper analyzes the interaction between humans and computers in terms of
response time in solving the image-based CAPTCHA. In particular, the analysis
focuses on the attitude of the different Internet users in easily solving four
different types of image-based CAPTCHAs which include facial expressions like:
animated character, old woman, surprised face, worried face. To pursue this
goal, an experiment is realized involving 100 Internet users in solving the
four types of CAPTCHAs, differentiated by age, Internet experience, and
education level. The response times are collected for each user. Then,
association rules are extracted from user data, for evaluating the dependence
of the response time in solving the CAPTCHA from age, education level and
experience in internet usage by statistical analysis. The results implicitly
capture the users' psychological states showing in what states the users are
more sensible. It reveals to be a novelty and a meaningful analysis in the
state-of-the-art.",2016-12-01,2016,2016-12,education
Ontology based system to guide internship assignment process,"Internship assignment is a complicated process for universities since it is
necessary to take into account a multiplicity of variables to establish a
compromise between companies' requirements and student competencies acquired
during the university training. These variables build up a complex relations
map that requires the formulation of an exhaustive and rigorous conceptual
scheme. In this research a domain ontological model is presented as support to
the student's decision making for opportunities of University studies level of
the University Lumiere Lyon 2 (ULL) education system. The ontology is designed
and created using methodological approach offering the possibility of improving
the progressive creation, capture and knowledge articulation. In this paper, we
draw a balance taking the demands of the companies across the capabilities of
the students. This will be done through the establishment of an ontological
model of an educational learners' profile and the internship postings which are
written in a free text and using uncontrolled vocabulary. Furthermore, we
outline the process of semantic matching which improves the quality of query
results.",2017-01-18,2017,2017-01,education
Ethical Considerations in Artificial Intelligence Courses,"The recent surge in interest in ethics in artificial intelligence may leave
many educators wondering how to address moral, ethical, and philosophical
issues in their AI courses. As instructors we want to develop curriculum that
not only prepares students to be artificial intelligence practitioners, but
also to understand the moral, ethical, and philosophical impacts that
artificial intelligence will have on society. In this article we provide
practical case studies and links to resources for use by AI educators. We also
provide concrete suggestions on how to integrate AI ethics into a general
artificial intelligence course and how to teach a stand-alone artificial
intelligence ethics course.",2017-01-26,2017,2017-01,education
"Blue Sky Ideas in Artificial Intelligence Education from the EAAI 2017
  New and Future AI Educator Program","The 7th Symposium on Educational Advances in Artificial Intelligence
(EAAI'17, co-chaired by Sven Koenig and Eric Eaton) launched the EAAI New and
Future AI Educator Program to support the training of early-career university
faculty, secondary school faculty, and future educators (PhD candidates or
postdocs who intend a career in academia). As part of the program, awardees
were asked to address one of the following ""blue sky"" questions:
  * How could/should Artificial Intelligence (AI) courses incorporate ethics
into the curriculum?
  * How could we teach AI topics at an early undergraduate or a secondary
school level?
  * AI has the potential for broad impact to numerous disciplines. How could we
make AI education more interdisciplinary, specifically to benefit
non-engineering fields?
  This paper is a collection of their responses, intended to help motivate
discussion around these issues in AI education.",2017-02-01,2017,2017-02,education
"T-SKIRT: Online Estimation of Student Proficiency in an Adaptive
  Learning System","We develop T-SKIRT: a temporal, structured-knowledge, IRT-based method for
predicting student responses online. By explicitly accounting for student
learning and employing a structured, multidimensional representation of student
proficiencies, the model outperforms standard IRT-based methods on an online
response prediction task when applied to real responses collected from students
interacting with diverse pools of educational content.",2017-02-14,2017,2017-02,education
Implications of the Fourth Industrial Age on Higher Education,"Higher education in the fourth industrial revolution, HE 4.0, is a complex,
dialectical and exciting opportunity which can potentially transform society
for the better. The fourth industrial revolution is powered by artificial
intelligence and it will transform the workplace from tasks based
characteristics to the human centred characteristics. Because of the
convergence of man and machine, it will reduce the subject distance between
humanities and social science as well as science and technology. This will
necessarily require much more interdisciplinary teaching, research and
innovation. This paper explores the impact of HE 4.0 on the mission of a
university which is teaching, research (including innovation) and service.",2017-03-17,2017,2017-03,education
"Team Formation for Scheduling Educational Material in Massive Online
  Classes","Whether teaching in a classroom or a Massive Online Open Course it is crucial
to present the material in a way that benefits the audience as a whole. We
identify two important tasks to solve towards this objective, 1 group students
so that they can maximally benefit from peer interaction and 2 find an optimal
schedule of the educational material for each group. Thus, in this paper, we
solve the problem of team formation and content scheduling for education. Given
a time frame d, a set of students S with their required need to learn different
activities T and given k as the number of desired groups, we study the problem
of finding k group of students. The goal is to teach students within time frame
d such that their potential for learning is maximized and find the best
schedule for each group. We show this problem to be NP-hard and develop a
polynomial algorithm for it. We show our algorithm to be effective both on
synthetic as well as a real data set. For our experiments, we use real data on
students' grades in a Computer Science department. As part of our contribution,
we release a semi-synthetic dataset that mimics the properties of the real
data.",2017-03-26,2017,2017-03,education
Probabilistic Models for Computerized Adaptive Testing,"In this paper we follow our previous research in the area of Computerized
Adaptive Testing (CAT). We present three different methods for CAT. One of
them, the item response theory, is a well established method, while the other
two, Bayesian and neural networks, are new in the area of educational testing.
In the first part of this paper, we present the concept of CAT and its
advantages and disadvantages. We collected data from paper tests performed with
grammar school students. We provide the summary of data used for our
experiments in the second part. Next, we present three different model types
for CAT. They are based on the item response theory, Bayesian networks, and
neural networks. The general theory associated with each type is briefly
explained and the utilization of these models for CAT is analyzed. Future
research is outlined in the concluding part of the paper. It shows many
interesting research paths that are important not only for CAT but also for
other areas of artificial intelligence.",2017-03-26,2017,2017-03,education
Kiwi - A Minimalist CP Solver,"Kiwi is a minimalist and extendable Constraint Programming (CP) solver
specifically designed for education. The particularities of Kiwi stand in its
generic trailing state restoration mechanism and its modulable use of
variables. By developing Kiwi, the author does not aim to provide an
alternative to full featured constraint solvers but rather to provide readers
with a basic architecture that will (hopefully) help them to understand the
core mechanisms hidden under the hood of constraint solvers, to develop their
own extended constraint solver, or to test innovative ideas.",2017-04-28,2017,2017-04,education
"Finding Bottlenecks: Predicting Student Attrition with Unsupervised
  Classifier","With pressure to increase graduation rates and reduce time to degree in
higher education, it is important to identify at-risk students early. Automated
early warning systems are therefore highly desirable. In this paper, we use
unsupervised clustering techniques to predict the graduation status of declared
majors in five departments at California State University Northridge (CSUN),
based on a minimal number of lower division courses in each major. In addition,
we use the detected clusters to identify hidden bottleneck courses.",2017-05-07,2017,2017-05,education
"Applying Artificial Intelligence and Internet Techniques in Rural
  Tourism Domain","Society has become more dependent on automated intelligent systems, at the
same time, these systems have become more and more complicated. Society's
expectation regarding the capabilities and intelligence of such systems has
also grown. We have become a more complicated society with more complicated
problems. As the expectation of intelligent systems rises, we discover many
more applications for artificial intelligence. Additionally, as the difficulty
level and computational requirements of such problems rise, there is a need to
distribute the problem solving. Although the field of multiagent systems (MAS)
and distributed artificial intelligence (DAI) is relatively young, the
importance and applicability of this technology for solving today's problems
continue to grow. In multiagent systems, the main goal is to provide fruitful
cooperation among agents in order to enrich the support given to all user
activities. This paper deals with the development of a multiagent system aimed
at solving the reservation problems encountered in rural tourism. Due to their
benefits over the last few years, online travel agencies have become a very
useful instrument in planning vacations. A MAS concept (which is based on the
Internet exploitation) can improve this activity and provide clients with a
new, rapid and efficient way of making accommodation arrangements.",2017-05-27,2017,2017-05,education
"A Framework for Easing the Development of Applications Embedding Answer
  Set Programming","Answer Set Programming (ASP) is a well-established declarative problem
solving paradigm which became widely used in AI and recognized as a powerful
tool for knowledge representation and reasoning (KRR), especially for its high
expressiveness and the ability to deal also with incomplete knowledge.
  Recently, thanks to the availability of a number of robust and efficient
implementations, ASP has been increasingly employed in a number of different
domains, and used for the development of industrial-level and enterprise
applications. This made clear the need for proper development tools and
interoperability mechanisms for easing interaction and integration with
external systems in the widest range of real-world scenarios, including mobile
applications and educational contexts.
  In this work we present a framework for integrating the KRR capabilities of
ASP into generic applications. We show the use of the framework by illustrating
proper specializations for some relevant ASP systems over different platforms,
including the mobile setting; furthermore, the potential of the framework for
educational purposes is illustrated by means of the development of several
ASP-based applications.",2017-07-21,2017,2017-07,education
"Object-Oriented Sokoban Solver: A Serious Game Project for OOAD and AI
  Education","Serious games are beneficial for education in various computer science areas.
Numerous works have reported the experiences of using games (not only playing
but also development) in teaching and learning. Considering it could be
difficult for teachers/students to prepare/develop a game from scratch during
one semester, assistant educational materials would be crucial in the
corresponding courses. Unfortunately, the literature shows that not many
materials from educational game projects are shared. To help different
educators identify suitable courseware and help students implement game
development, it is worth further investigating and accumulating the educational
resources from individual game projects. Following such an idea, this paper
proposes a game development project of an object-oriented Sokoban solver, and
exposes relevant educational materials. The documented system design can be
viewed as a ready-to-use resource for education in object-oriented analysis and
design (OOAD), while the Sokoban solver itself may be used as an assignment
platform for teaching artificial intelligence (AI). Further documentation,
platform, and APIs will be realized and shared in the future to facilitate
others' educational activities. Overall, this work is supposed to inspire and
encourage other researchers and educators to post available materials of more
game projects for the purpose of sharing and reuse.",2017-08-04,2017,2017-08,education
Enriching Information Technology Course Materials by Using Youtube,"IT offers some benefits and collaborations in various sectors. This research
focuses on exploring higher education subjects via social technology, YouTube.
YouTube is the world largest video based contents application in the world.
Current learning materials are not only in text and images, but included video
contents. This research enriching students learning materials may involving
YouTube as learning sources. The study observed 118 sophomore students in
computer science faculty. The results show that, involving YouTube in enriching
students course material able to create conductive learning environment. This
strategy increases students understanding in their field of study.",2017-08-08,2017,2017-08,education
Pros and cons gamification and gaming in classroom,"The aim of the current work is to assess the challenges that gamification in
education are facing nowadays. Benefits and disadvantages of using gamification
in classroom are both discussed to offer a clearer view on the impact of using
gamification within learning process. Exploratory study cases are provided to
investigate the relation between motivation and engagement of the students and
gamification in training. Following this idea, a survey was conducted to assess
how students behavior and motivation is affected by introducing a single,
specific gamification element during a semester learning process. To stimulate
competition among students, a ranking type plugin was introduced within the
university learning management system used for extramural education. The
results prove that motivation decreases by comparison to the previous semester.",2017-08-08,2017,2017-08,education
"Role of Secondary Attributes to Boost the Prediction Accuracy of
  Students Employability Via Data Mining","Data Mining is best-known for its analytical and prediction capabilities. It
is used in several areas such as fraud detection, predicting client behavior,
money market behavior, bankruptcy prediction. It can also help in establishing
an educational ecosystem, which discovers useful knowledge, and assist
educators to take proactive decisions to boost student performance and
employability. This paper presents an empirical study that compares varied
classification algorithms on two datasets of MCA (Masters in Computer
Applications) students collected from various affiliated colleges of a reputed
state university in India. One dataset includes only primary attributes,
whereas other dataset is feeded with secondary psychometric attributes in it.
The results showcase that solely primary academic attributes do not lead to
smart prediction accuracy of students employability, once they square measure
within the initial year of their education. The study analyzes and stresses the
role of secondary psychometric attributes for better prediction accuracy and
analysis of students performance. Timely prediction and analysis of students
performance can help Management, Teachers and Students to work on their gray
areas for better results and employment opportunities.",2017-08-09,2017,2017-08,education
Difficulty-level Modeling of Ontology-based Factual Questions,"Semantics based knowledge representations such as ontologies are found to be
very useful in automatically generating meaningful factual questions.
Determining the difficulty level of these system generated questions is helpful
to effectively utilize them in various educational and professional
applications. The existing approaches for finding the difficulty level of
factual questions are very simple and are limited to a few basic principles. We
propose a new methodology for this problem by considering an educational theory
called Item Response Theory (IRT). In the IRT, knowledge proficiency of end
users (learners) are considered for assigning difficulty levels, because of the
assumptions that a given question is perceived differently by learners of
various proficiencies. We have done a detailed study on the features (factors)
of a question statement which could possibly determine its difficulty level for
three learner categories (experts, intermediates and beginners). We formulate
ontology based metrics for the same. We then train three logistic regression
models to predict the difficulty level corresponding to the three learner
categories.",2017-09-03,2017,2017-09,education
"First Results from Using Game Refinement Measure and Learning
  Coefficient in Scrabble","This paper explores the entertainment experience and learning experience in
Scrabble. It proposes a new measure from the educational point of view, which
we call learning coefficient, based on the balance between the learner's skill
and the challenge in Scrabble. Scrabble variants, generated using different
size of board and dictionary, are analyzed with two measures of game refinement
and learning coefficient. The results show that 13x13 Scrabble yields the best
entertainment experience and 15x15 (standard) Scrabble with 4% of original
dictionary size yields the most effective environment for language learners.
Moreover, 15x15 Scrabble with 10% of original dictionary size has a good
balance between entertainment and learning experience.",2017-11-07,2017,2017-11,education
"How linguistic descriptions of data can help to the teaching-learning
  process in higher education, case of study: artificial intelligence","Artificial Intelligence is a central topic in the computer science
curriculum. From the year 2011 a project-based learning methodology based on
computer games has been designed and implemented into the intelligence
artificial course at the University of the Bio-Bio. The project aims to develop
software-controlled agents (bots) which are programmed by using heuristic
algorithms seen during the course. This methodology allows us to obtain good
learning results, however several challenges have been founded during its
implementation.
  In this paper we show how linguistic descriptions of data can help to provide
students and teachers with technical and personalized feedback about the
learned algorithms. Algorithm behavior profile and a new Turing test for
computer games bots based on linguistic modelling of complex phenomena are also
proposed in order to deal with such challenges.
  In order to show and explore the possibilities of this new technology, a web
platform has been designed and implemented by one of authors and its
incorporation in the process of assessment allows us to improve the teaching
learning process.",2017-11-27,2017,2017-11,education
Learning to Rank based on Analogical Reasoning,"Object ranking or ""learning to rank"" is an important problem in the realm of
preference learning. On the basis of training data in the form of a set of
rankings of objects represented as feature vectors, the goal is to learn a
ranking function that predicts a linear order of any new set of objects. In
this paper, we propose a new approach to object ranking based on principles of
analogical reasoning. More specifically, our inference pattern is formalized in
terms of so-called analogical proportions and can be summarized as follows:
Given objects $A,B,C,D$, if object $A$ is known to be preferred to $B$, and $C$
relates to $D$ as $A$ relates to $B$, then $C$ is (supposedly) preferred to
$D$. Our method applies this pattern as a main building block and combines it
with ideas and techniques from instance-based learning and rank aggregation.
Based on first experimental results for data sets from various domains (sports,
education, tourism, etc.), we conclude that our approach is highly competitive.
It appears to be specifically interesting in situations in which the objects
are coming from different subdomains, and which hence require a kind of
knowledge transfer.",2017-11-28,2017,2017-11,education
Happiness Pursuit: Personality Learning in a Society of Agents,"Modeling personality is a challenging problem with applications spanning
computer games, virtual assistants, online shopping and education. Many
techniques have been tried, ranging from neural networks to computational
cognitive architectures. However, most approaches rely on examples with
hand-crafted features and scenarios. Here, we approach learning a personality
by training agents using a Deep Q-Network (DQN) model on rewards based on
psychoanalysis, against hand-coded AI in the game of Pong. As a result, we
obtain 4 agents, each with its own personality. Then, we define happiness of an
agent, which can be seen as a measure of alignment with agent's objective
function, and study it when agents play both against hand-coded AI, and against
each other. We find that the agents that achieve higher happiness during
testing against hand-coded AI, have lower happiness when competing against each
other. This suggests that higher happiness in testing is a sign of overfitting
in learning to interact with hand-coded AI, and leads to worse performance
against agents with different personalities.",2017-11-29,2017,2017-11,education
"Towards the Augmented Pathologist: Challenges of Explainable-AI in
  Digital Pathology","Digital pathology is not only one of the most promising fields of diagnostic
medicine, but at the same time a hot topic for fundamental research. Digital
pathology is not just the transfer of histopathological slides into digital
representations. The combination of different data sources (images, patient
records, and *omics data) together with current advances in artificial
intelligence/machine learning enable to make novel information accessible and
quantifiable to a human expert, which is not yet available and not exploited in
current medical settings. The grand goal is to reach a level of usable
intelligence to understand the data in the context of an application task,
thereby making machine decisions transparent, interpretable and explainable.
The foundation of such an ""augmented pathologist"" needs an integrated approach:
While machine learning algorithms require many thousands of training examples,
a human expert is often confronted with only a few data points. Interestingly,
humans can learn from such few examples and are able to instantly interpret
complex patterns. Consequently, the grand goal is to combine the possibilities
of artificial intelligence with human intelligence and to find a well-suited
balance between them to enable what neither of them could do on their own. This
can raise the quality of education, diagnosis, prognosis and prediction of
cancer and other diseases. In this paper we describe some (incomplete) research
issues which we believe should be addressed in an integrated and concerted
effort for paving the way towards the augmented pathologist.",2017-12-18,2017,2017-12,education
"An Ontology Based Modeling Framework for Design of Educational
  Technologies","Despite rapid progress, most of the educational technologies today lack a
strong instructional design knowledge basis leading to questionable quality of
instruction. In addition, a major challenge is to customize these educational
technologies for a wide range of instructional designs. Ontologies are one of
the pertinent mechanisms to represent instructional design in the literature.
However, existing approaches do not support modeling of flexible instructional
designs. To address this problem, in this paper, we propose an ontology based
framework for systematic modeling of different aspects of instructional design
knowledge based on domain patterns. As part of the framework, we present
ontologies for modeling goals, instructional processes and instructional
materials. We demonstrate the ontology framework by presenting instances of the
ontology for the large scale case study of adult literacy in India (287 million
learners spread across 22 Indian Languages), which requires creation of 1000
similar but varied eLearning Systems based on flexible instructional designs.
The implemented framework is available at http://rice.iiit.ac.in and is
transferred to National Literacy Mission of Government of India. This framework
could be used for modeling instructional design knowledge of systems for
skills, school education and beyond.",2018-02-07,2018,2018-02,education
"PSO-based Fuzzy Markup Language for Student Learning Performance
  Evaluation and Educational Application","This paper proposes an agent with particle swarm optimization (PSO) based on
a Fuzzy Markup Language (FML) for students learning performance evaluation and
educational applications, and the proposed agent is according to the response
data from a conventional test and an item response theory. First, we apply a
GS-based parameter estimation mechanism to estimate the items parameters
according to the response data, and then to compare its results with those of
an IRT-based Bayesian parameter estimation mechanism. In addition, we propose a
static-IRT test assembly mechanism to assemble a form for the conventional
test. The presented FML-based dynamic assessment mechanism infers the
probability of making a correct response to the item for a student with various
abilities. Moreover, this paper also proposes a novel PFML learning mechanism
for optimizing the parameters between items and students. Finally, we adopt a
K-fold cross validation mechanism to evaluate the performance of the proposed
agent. Experimental results show that the novel PFML learning mechanism for the
parameter estimation and learning optimization performs favorably. We believe
the proposed PFML will be a reference for education research and pedagogy and
an important co-learning mechanism for future human-machine educational
applications.",2018-02-24,2018,2018-02,education
"Proceedings 6th International Workshop on Theorem proving components for
  Educational software","The 6th International Workshop on Theorem proving components for Educational
software (ThEdu'17) was held in Gothenburg, Sweden, on 6 Aug 2017. It was
associated to the conference CADE26. Topics of interest include: methods of
automated deduction applied to checking students' input; methods of automated
deduction applied to prove post-conditions for particular problem solutions;
combinations of deduction and computation enabling systems to propose next
steps; automated provers specific for dynamic geometry systems; proof and
proving in mathematics education.
  ThEdu'17 was a vibrant workshop, with one invited talk and eight
contributions. It triggered the post-proceedings at hand.",2018-03-02,2018,2018-03,education
An Application of HodgeRank to Online Peer Assessment,"Bias and heterogeneity in peer assessment can lead to the issue of unfair
scoring in the educational field. To deal with this problem, we propose a
reference ranking method for an online peer assessment system using HodgeRank.
Such a scheme provides instructors with an objective scoring reference based on
mathematics.",2018-03-07,2018,2018-03,education
"Toward modern educational IT-ecosystems: from learning management
  systems to digital platforms","The development of a learning management system (LMS) as a key service seems
to be very effective for creation of educational digital platforms. Such
platforms for both higher education institutions and various companies can
provide the opportunities for networked forms of educational communication,
improve the quality of the perception of innovative technologies and support
tools for progress of talented youth as well as knowledge transfer. An example
of such LMS is presented. The paper focuses on the demand for further
development of learning management systems, their integration with modern
digital platforms and potential exploitation as key services of such platforms
in the context of the current educational trends of Industry 4.0 and the global
trend towards a transition to a digital economy. The implementation of
artificial intelligence technologies into the educational process is mentioned
as an innovative way to form IT-ecosystems of modern education.",2018-06-28,2018,2018-06,education
"AI in Education needs interpretable machine learning: Lessons from Open
  Learner Modelling","Interpretability of the underlying AI representations is a key raison
d'\^{e}tre for Open Learner Modelling (OLM) -- a branch of Intelligent Tutoring
Systems (ITS) research. OLMs provide tools for 'opening' up the AI models of
learners' cognition and emotions for the purpose of supporting human learning
and teaching. Over thirty years of research in ITS (also known as AI in
Education) produced important work, which informs about how AI can be used in
Education to best effects and, through the OLM research, what are the necessary
considerations to make it interpretable and explainable for the benefit of
learning. We argue that this work can provide a valuable starting point for a
framework of interpretable AI, and as such is of relevance to the application
of both knowledge-based and machine learning systems in other high-stakes
contexts, beyond education.",2018-06-30,2018,2018-06,education
Web-STAR: A Visual Web-Based IDE for a Story Comprehension System,"We present Web-STAR, an online platform for story understanding built on top
of the STAR reasoning engine for STory comprehension through ARgumentation. The
platform includes a web-based IDE, integration with the STAR system, and a web
service infrastructure to support integration with other systems that rely on
story understanding functionality to complete their tasks. The platform also
delivers a number of ""social"" features, including a community repository for
public story sharing with a built-in commenting system, and tools for
collaborative story editing that can be used for team development projects and
for educational purposes.",2018-07-28,2018,2018-07,education
"A Century Long Commitment to Assessing Artificial Intelligence and its
  Impact on Society","In September 2016, Stanford's ""One Hundred Year Study on Artificial
Intelligence"" project (AI100) issued the first report of its planned long-term
periodic assessment of artificial intelligence (AI) and its impact on society.
The report, entitled ""Artificial Intelligence and Life in 2030,"" examines eight
domains of typical urban settings on which AI is likely to have impact over the
coming years: transportation, home and service robots, healthcare, education,
public safety and security, low-resource communities, employment and workplace,
and entertainment. It aims to provide the general public with a scientifically
and technologically accurate portrayal of the current state of AI and its
potential and to help guide decisions in industry and governments, as well as
to inform research and development in the field. This article by the chair of
the 2016 Study Panel and the inaugural chair of the AI100 Standing Committee
describes the origins of this ambitious longitudinal study, discusses the
framing of the inaugural report, and presents the report's main findings. It
concludes with a brief description of the AI100 project's ongoing efforts and
planned next steps.",2018-08-23,2018,2018-08,education
"The use of Virtual Reality in Enhancing Interdisciplinary Research and
  Education","Virtual Reality (VR) is increasingly being recognized for its educational
potential and as an effective way to convey new knowledge to people, it
supports interactive and collaborative activities. Affordable VR powered by
mobile technologies is opening a new world of opportunities that can transform
the ways in which we learn and engage with others. This paper reports our study
regarding the application of VR in stimulating interdisciplinary communication.
It investigates the promises of VR in interdisciplinary education and research.
The main contributions of this study are (i) literature review of theories of
learning underlying the justification of the use of VR systems in education,
(ii) taxonomy of the various types and implementations of VR systems and their
application in supporting education and research (iii) evaluation of
educational applications of VR from a broad range of disciplines, (iv)
investigation of how the learning process and learning outcomes are affected by
VR systems, and (v) comparative analysis of VR and traditional methods of
teaching in terms of quality of learning. This study seeks to inspire and
inform interdisciplinary researchers and learners about the ways in which VR
might support them and also VR software developers to push the limits of their
craft.",2018-09-23,2018,2018-09,education
Wikistat 2.0: Educational Resources for Artificial Intelligence,"Big data, data science, deep learning, artificial intelligence are the key
words of intense hype related with a job market in full evolution, that impose
to adapt the contents of our university professional trainings. Which
artificial intelligence is mostly concerned by the job offers? Which
methodologies and technologies should be favored in the training programs?
Which objectives, tools and educational resources do we needed to put in place
to meet these pressing needs? We answer these questions in describing the
contents and operational resources in the Data Science orientation of the
specialty Applied Mathematics at INSA Toulouse. We focus on basic mathematics
training (Optimization, Probability, Statistics), associated with the practical
implementation of the most performing statistical learning algorithms, with the
most appropriate technologies and on real examples. Considering the huge
volatility of the technologies, it is imperative to train students in
seft-training, this will be their technological watch tool when they will be in
professional activity. This explains the structuring of the educational site
github.com/wikistat into a set of tutorials. Finally, to motivate the thorough
practice of these tutorials, a serious game is organized each year in the form
of a prediction contest between students of Master degrees in Applied
Mathematics for IA.",2018-09-28,2018,2018-09,education
Deep Reinforcement Learning,"We discuss deep reinforcement learning in an overview style. We draw a big
picture, filled with details. We discuss six core elements, six important
mechanisms, and twelve applications, focusing on contemporary work, and in
historical contexts. We start with background of artificial intelligence,
machine learning, deep learning, and reinforcement learning (RL), with
resources. Next we discuss RL core elements, including value function, policy,
reward, model, exploration vs. exploitation, and representation. Then we
discuss important mechanisms for RL, including attention and memory,
unsupervised learning, hierarchical RL, multi-agent RL, relational RL, and
learning to learn. After that, we discuss RL applications, including games,
robotics, natural language processing (NLP), computer vision, finance, business
management, healthcare, education, energy, transportation, computer systems,
and, science, engineering, and art. Finally we summarize briefly, discuss
challenges and opportunities, and close with an epilogue.",2018-10-15,2018,2018-10,education
"A Scalable, Flexible Augmentation of the Student Education Process","We present a novel intelligent tutoring system which builds upon
well-established hypotheses in educational psychology and incorporates them
inside of a scalable software architecture. Specifically, we build upon the
known benefits of knowledge vocalization, parallel learning, and immediate
feedback in the context of student learning. We show that open-source data
combined with state-of-the-art techniques in deep learning and natural language
processing can apply the benefits of these three factors at scale, while still
operating at the granularity of individual student needs and recommendations.
Additionally, we allow teachers to retain full control of the outputs of the
algorithms, and provide student statistics to help better guide classroom
discussions towards topics that would benefit from more in-person review and
coverage. Our experiments and pilot programs show promising results, and cement
our hypothesis that the system is flexible enough to serve a wide variety of
purposes in both classroom and classroom-free settings.",2018-10-17,2018,2018-10,education
Knowledge Tracing Machines: Factorization Machines for Knowledge Tracing,"Knowledge tracing is a sequence prediction problem where the goal is to
predict the outcomes of students over questions as they are interacting with a
learning platform. By tracking the evolution of the knowledge of some student,
one can optimize instruction. Existing methods are either based on temporal
latent variable models, or factor analysis with temporal features. We here show
that factorization machines (FMs), a model for regression or classification,
encompasses several existing models in the educational literature as special
cases, notably additive factor model, performance factor model, and
multidimensional item response theory. We show, using several real datasets of
tens of thousands of users and items, that FMs can estimate student knowledge
accurately and fast even when student data is sparsely observed, and handle
side information such as multiple knowledge components and number of attempts
at item or skill level. Our approach allows to fit student models of higher
dimension than existing models, and provides a testbed to try new combinations
of features in order to improve existing models.",2018-11-08,2018,2018-11,education
50 Years of Test (Un)fairness: Lessons for Machine Learning,"Quantitative definitions of what is unfair and what is fair have been
introduced in multiple disciplines for well over 50 years, including in
education, hiring, and machine learning. We trace how the notion of fairness
has been defined within the testing communities of education and hiring over
the past half century, exploring the cultural and social context in which
different fairness definitions have emerged. In some cases, earlier definitions
of fairness are similar or identical to definitions of fairness in current
machine learning research, and foreshadow current formal work. In other cases,
insights into what fairness means and how to measure it have largely gone
overlooked. We compare past and current notions of fairness along several
dimensions, including the fairness criteria, the focus of the criteria (e.g., a
test, a model, or its use), the relationship of fairness to individuals,
groups, and subgroups, and the mathematical method for measuring fairness
(e.g., classification, regression). This work points the way towards future
research and measurement of (un)fairness that builds from our modern
understanding of fairness while incorporating insights from the past.",2018-11-25,2018,2018-11,education
"What Should I Learn First: Introducing LectureBank for NLP Education and
  Prerequisite Chain Learning","Recent years have witnessed the rising popularity of Natural Language
Processing (NLP) and related fields such as Artificial Intelligence (AI) and
Machine Learning (ML). Many online courses and resources are available even for
those without a strong background in the field. Often the student is curious
about a specific topic but does not quite know where to begin studying. To
answer the question of ""what should one learn first,"" we apply an
embedding-based method to learn prerequisite relations for course concepts in
the domain of NLP. We introduce LectureBank, a dataset containing 1,352 English
lecture files collected from university courses which are each classified
according to an existing taxonomy as well as 208 manually-labeled prerequisite
relation topics, which is publicly available. The dataset will be useful for
educational purposes such as lecture preparation and organization as well as
applications such as reading list generation. Additionally, we experiment with
neural graph-based networks and non-neural classifiers to learn these
prerequisite relations from our dataset.",2018-11-26,2018,2018-11,education
"Inferring Concept Prerequisite Relations from Online Educational
  Resources","The Internet has rich and rapidly increasing sources of high quality
educational content. Inferring prerequisite relations between educational
concepts is required for modern large-scale online educational technology
applications such as personalized recommendations and automatic curriculum
creation. We present PREREQ, a new supervised learning method for inferring
concept prerequisite relations. PREREQ is designed using latent representations
of concepts obtained from the Pairwise Latent Dirichlet Allocation model, and a
neural network based on the Siamese network architecture. PREREQ can learn
unknown concept prerequisites from course prerequisites and labeled concept
prerequisite data. It outperforms state-of-the-art approaches on benchmark
datasets and can effectively learn from very less training data. PREREQ can
also use unlabeled video playlists, a steadily growing source of training data,
to learn concept prerequisites, thus obviating the need for manual annotation
of course prerequisites.",2018-11-30,2018,2018-11,education
"Transparent Machine Education of Neural Networks for Swarm Shepherding
  Using Curriculum Design","Swarm control is a difficult problem due to the need to guide a large number
of agents simultaneously. We cast the problem as a shepherding problem, similar
to biological dogs guiding a group of sheep towards a goal. The shepherd needs
to deal with complex and dynamic environments and make decisions in order to
direct the swarm from one location to another. In this paper, we design a novel
curriculum to teach an artificial intelligence empowered agent to shepherd in
the presence of the large state space associated with the shepherding problem
and in a transparent manner. The results show that a properly designed
curriculum could indeed enhance the speed of learning and the complexity of
learnt behaviours.",2019-01-04,2019,2019-01,education
"Machine Teaching in Hierarchical Genetic Reinforcement Learning:
  Curriculum Design of Reward Functions for Swarm Shepherding","The design of reward functions in reinforcement learning is a human skill
that comes with experience. Unfortunately, there is not any methodology in the
literature that could guide a human to design the reward function or to allow a
human to transfer the skills developed in designing reward functions to another
human and in a systematic manner. In this paper, we use Systematic
Instructional Design, an approach in human education, to engineer a machine
education methodology to design reward functions for reinforcement learning. We
demonstrate the methodology in designing a hierarchical genetic reinforcement
learner that adopts a neural network representation to evolve a swarm
controller for an agent shepherding a boids-based swarm. The results reveal
that the methodology is able to guide the design of hierarchical reinforcement
learners, with each model in the hierarchy learning incrementally through a
multi-part reward function. The hierarchy acts as a decision fusion function
that combines the individual behaviours and skills learnt by each instruction
to create a smart shepherd to control the swarm.",2019-01-04,2019,2019-01,education
Analogy-Based Preference Learning with Kernels,"Building on a specific formalization of analogical relationships of the form
""A relates to B as C relates to D"", we establish a connection between two
important subfields of artificial intelligence, namely analogical reasoning and
kernel-based machine learning. More specifically, we show that so-called
analogical proportions are closely connected to kernel functions on pairs of
objects. Based on this result, we introduce the analogy kernel, which can be
seen as a measure of how strongly four objects are in analogical relationship.
As an application, we consider the problem of object ranking in the realm of
preference learning, for which we develop a new method based on support vector
machines trained with the analogy kernel. Our first experimental results for
data sets from different domains (sports, education, tourism, etc.) are
promising and suggest that our approach is competitive to state-of-the-art
algorithms in terms of predictive accuracy.",2019-01-07,2019,2019-01,education
"Solving The Exam Scheduling Problems in Central Exams With Genetic
  Algorithms","It is the efficient use of resources expected from an exam scheduling
application. There are various criteria for efficient use of resources and for
all tests to be carried out at minimum cost in the shortest possible time. It
is aimed that educational institutions with such criteria successfully carry
out central examination organizations. In the study, a two-stage genetic
algorithm was developed. In the first stage, the assignment of courses to
sessions was carried out. In the second stage, the students who participated in
the test session were assigned to examination rooms. Purposes of the study are
increasing the number of joint students participating in sessions, using the
minimum number of buildings in the same session, and reducing the number of
supervisors using the minimum number of classrooms possible. In this study, a
general purpose exam scheduling solution for educational institutions was
presented. The developed system can be used in different central examinations
to create originality. Given the results of the sample application, it is seen
that the proposed genetic algorithm gives successful results.1",2019-02-04,2019,2019-02,education
"Artificial Intelligence in Intelligent Tutoring Robots: A Systematic
  Review and Design Guidelines","This study provides a systematic review of the recent advances in designing
the intelligent tutoring robot (ITR), and summarises the status quo of applying
artificial intelligence (AI) techniques. We first analyse the environment of
the ITR and propose a relationship model for describing interactions of ITR
with the students, the social milieu and the curriculum. Then, we transform the
relationship model into the perception-planning-action model for exploring what
AI techniques are suitable to be applied in the ITR. This article provides
insights on promoting human-robot teaching-learning process and AI-assisted
educational techniques, illustrating the design guidelines and future research
perspectives in intelligent tutoring robots.",2019-02-26,2019,2019-02,education
"Deep recommender engine based on efficient product embeddings neural
  pipeline","Predictive analytics systems are currently one of the most important areas of
research and development within the Artificial Intelligence domain and
particularly in Machine Learning. One of the ""holy grails"" of predictive
analytics is the research and development of the ""perfect"" recommendation
system. In our paper, we propose an advanced pipeline model for the multi-task
objective of determining product complementarity, similarity and sales
prediction using deep neural models applied to big-data sequential transaction
systems. Our highly parallelized hybrid model pipeline consists of both
unsupervised and supervised models, used for the objectives of generating
semantic product embeddings and predicting sales, respectively. Our
experimentation and benchmarking processes have been done using pharma industry
retail real-life transactional Big-Data streams.",2019-03-24,2019,2019-03,education
"Proceedings 7th International Workshop on Theorem proving components for
  Educational software","The 7th International Workshop on Theorem proving components for Educational
software (ThEdu'18) was held in Oxford, United Kingdom, on 18 July 2018. It was
associated to the conference, Federated Logic Conference 2018 (FLoC2018).
  The major aim of the ThEdu workshop series was to link developers interested
in adapting Computer Theorem Proving (TP) to the needs of education and to
inform mathematicians and mathematics educators about TP's potential for
educational software. Topics of interest include: methods of automated
deduction applied to checking students' input; methods of automated deduction
applied to prove post-conditions for particular problem solutions; combinations
of deduction and computation enabling systems to propose next steps; automated
provers specific for dynamic geometry systems; proof and proving in mathematics
education.
  ThEdu'18 was a vibrant workshop, with one invited talk and six contributions.
It triggered the post-proceedings at hand.",2019-03-29,2019,2019-03,education
"Using Scratch to Teach Undergraduate Students' Skills on Artificial
  Intelligence","This paper presents a educational workshop in Scratch that is proposed for
the active participation of undergraduate students in contexts of Artificial
Intelligence. The main objective of the activity is to demystify the complexity
of Artificial Intelligence and its algorithms. For this purpose, students must
realize simple exercises of clustering and two neural networks, in Scratch. The
detailed methodology to get that is presented in the article.",2019-03-30,2019,2019-03,education
AI Meets Austen: Towards Human-Robot Discussions of Literary Metaphor,"Artificial intelligence is revolutionizing formal education, fueled by
innovations in learning assessment, content generation, and instructional
delivery. Informal, lifelong learning settings have been the subject of less
attention. We provide a proof-of-concept for an embodied book discussion
companion, designed to stimulate conversations with readers about particularly
creative metaphors in fiction literature. We collect ratings from 26
participants, each of whom discuss Jane Austen's ""Pride and Prejudice"" with the
robot across one or more sessions, and find that participants rate their
interactions highly. This suggests that companion robots could be an
interesting entryway for the promotion of lifelong learning and cognitive
exercise in future applications.",2019-04-07,2019,2019-04,education
"Emotion Recognition in Conversation: Research Challenges, Datasets, and
  Recent Advances","Emotion is intrinsic to humans and consequently emotion understanding is a
key part of human-like artificial intelligence (AI). Emotion recognition in
conversation (ERC) is becoming increasingly popular as a new research frontier
in natural language processing (NLP) due to its ability to mine opinions from
the plethora of publicly available conversational data in platforms such as
Facebook, Youtube, Reddit, Twitter, and others. Moreover, it has potential
applications in health-care systems (as a tool for psychological analysis),
education (understanding student frustration) and more. Additionally, ERC is
also extremely important for generating emotion-aware dialogues that require an
understanding of the user's emotions. Catering to these needs calls for
effective and scalable conversational emotion-recognition algorithms. However,
it is a strenuous problem to solve because of several research challenges. In
this paper, we discuss these challenges and shed light on the recent research
in this field. We also describe the drawbacks of these approaches and discuss
the reasons why they fail to successfully overcome the research challenges in
ERC.",2019-05-08,2019,2019-05,education
Ludii -- The Ludemic General Game System,"While current General Game Playing (GGP) systems facilitate useful research
in Artificial Intelligence (AI) for game-playing, they are often somewhat
specialised and computationally inefficient. In this paper, we describe the
""ludemic"" general game system Ludii, which has the potential to provide an
efficient tool for AI researchers as well as game designers, historians,
educators and practitioners in related fields. Ludii defines games as
structures of ludemes -- high-level, easily understandable game concepts --
which allows for concise and human-understandable game descriptions. We
formally describe Ludii and outline its main benefits: generality,
extensibility, understandability and efficiency. Experimentally, Ludii
outperforms one of the most efficient Game Description Language (GDL)
reasoners, based on a propositional network, in all games available in the
Tiltyard GGP repository. Moreover, Ludii is also competitive in terms of
performance with the more recently proposed Regular Boardgames (RBG) system,
and has various advantages in qualitative aspects such as generality.",2019-05-13,2019,2019-05,education
"Digital Normativity: A challenge for human subjectivization and free
  will","Over the past decade, artificial intelligence has demonstrated its efficiency
in many different applications and a huge number of algorithms have become
central and ubiquitous in our life. Their growing interest is essentially based
on their capability to synthesize and process large amounts of data, and to
help humans making decisions in a world of increasing complexity. Yet, the
effectiveness of algorithms in bringing more and more relevant recommendations
to humans may start to compete with human-alone decisions based on values other
than pure efficacy. Here, we examine this tension in light of the emergence of
several forms of digital normativity, and analyze how this normative role of AI
may influence the ability of humans to remain subject of their life. The advent
of AI technology imposes a need to achieve a balance between concrete material
progress and progress of the mind to avoid any form of servitude. It has become
essential that an ethical reflection accompany the current developments of
intelligent algorithms beyond the sole question of their social acceptability.
Such reflection should be anchored where AI technologies are being developed as
well as in educational programs where their implications can be explained.",2019-05-23,2019,2019-05,education
Adaptive Learning Material Recommendation in Online Language Education,"Recommending personalized learning materials for online language learning is
challenging because we typically lack data about the student's ability and the
relative difficulty of learning materials. This makes it hard to recommend
appropriate content that matches the student's prior knowledge. In this paper,
we propose a refined hierarchical knowledge structure to model vocabulary
knowledge, which enables us to automatically organize the authentic and
up-to-date learning materials collected from the internet. Based on this
knowledge structure, we then introduce a hybrid approach to recommend learning
materials that adapts to a student's language level. We evaluate our work with
an online Japanese learning tool and the results suggest adding adaptivity into
material recommendation significantly increases student engagement.",2019-05-26,2019,2019-05,education
"A Self-Attention Joint Model for Spoken Language Understanding in
  Situational Dialog Applications","Spoken language understanding (SLU) acts as a critical component in
goal-oriented dialog systems. It typically involves identifying the speakers
intent and extracting semantic slots from user utterances, which are known as
intent detection (ID) and slot filling (SF). SLU problem has been intensively
investigated in recent years. However, these methods just constrain SF results
grammatically, solve ID and SF independently, or do not fully utilize the
mutual impact of the two tasks. This paper proposes a multi-head self-attention
joint model with a conditional random field (CRF) layer and a prior mask. The
experiments show the effectiveness of our model, as compared with
state-of-the-art models. Meanwhile, online education in China has made great
progress in the last few years. But there are few intelligent educational
dialog applications for students to learn foreign languages. Hence, we design
an intelligent dialog robot equipped with different scenario settings to help
students learn communication skills.",2019-05-27,2019,2019-05,education
"General Board Game Playing for Education and Research in Generic AI Game
  Learning","We present a new general board game (GBG) playing and learning framework. GBG
defines the common interfaces for board games, game states and their AI agents.
It allows one to run competitions of different agents on different games. It
standardizes those parts of board game playing and learning that otherwise
would be tedious and repetitive parts in coding. GBG is suitable for arbitrary
1-, 2-, ..., N-player board games. It makes a generic TD($\lambda$)-n-tuple
agent for the first time available to arbitrary games. On various games,
TD($\lambda$)-n-tuple is found to be superior to other generic agents like
MCTS. GBG aims at the educational perspective, where it helps students to start
faster in the area of game learning. GBG aims as well at the research
perspective by collecting a growing set of games and AI agents to assess their
strengths and generalization capabilities in meaningful competitions. Initial
successful educational and research results are reported.",2019-07-11,2019,2019-07,education
"A Survey on Explainable Artificial Intelligence (XAI): Towards Medical
  XAI","Recently, artificial intelligence and machine learning in general have
demonstrated remarkable performances in many tasks, from image processing to
natural language processing, especially with the advent of deep learning. Along
with research progress, they have encroached upon many different fields and
disciplines. Some of them require high level of accountability and thus
transparency, for example the medical sector. Explanations for machine
decisions and predictions are thus needed to justify their reliability. This
requires greater interpretability, which often means we need to understand the
mechanism underlying the algorithms. Unfortunately, the blackbox nature of the
deep learning is still unresolved, and many machine decisions are still poorly
understood. We provide a review on interpretabilities suggested by different
research works and categorize them. The different categories show different
dimensions in interpretability research, from approaches that provide
""obviously"" interpretable information to the studies of complex patterns. By
applying the same categorization to interpretability in medical research, it is
hoped that (1) clinicians and practitioners can subsequently approach these
methods with caution, (2) insights into interpretability will be born with more
considerations for medical practices, and (3) initiatives to push forward
data-based, mathematically- and technically-grounded medical education are
encouraged.",2019-07-17,2019,2019-07,education
Co-Attention Based Neural Network for Source-Dependent Essay Scoring,"This paper presents an investigation of using a co-attention based neural
network for source-dependent essay scoring. We use a co-attention mechanism to
help the model learn the importance of each part of the essay more accurately.
Also, this paper shows that the co-attention based neural network model
provides reliable score prediction of source-dependent responses. We evaluate
our model on two source-dependent response corpora. Results show that our model
outperforms the baseline on both corpora. We also show that the attention of
the model is similar to the expert opinions with examples.",2019-08-06,2019,2019-08,education
Tracing Player Knowledge in a Parallel Programming Educational Game,"This paper focuses on ""tracing player knowledge"" in educational games.
Specifically, given a set of concepts or skills required to master a game, the
goal is to estimate the likelihood with which the current player has mastery of
each of those concepts or skills. The main contribution of the paper is an
approach that integrates machine learning and domain knowledge rules to find
when the player applied a certain skill and either succeeded or failed. This is
then given as input to a standard knowledge tracing module (such as those from
Intelligent Tutoring Systems) to perform knowledge tracing. We evaluate our
approach in the context of an educational game called ""Parallel"" to teach
parallel and concurrent programming with data collected from real users,
showing our approach can predict students skills with a low mean-squared error.",2019-08-15,2019,2019-08,education
A Survey of Automated Programming Hint Generation -- The HINTS Framework,"Automated tutoring systems offer the flexibility and scalability necessary to
facilitate the provision of high quality and universally accessible programming
education. In order to realise the full potential of these systems, recent work
has proposed a diverse range of techniques for automatically generating hints
to assist students with programming exercises. This paper integrates these
apparently disparate approaches into a coherent whole. Specifically, it
emphasises that all hint techniques can be understood as a series of simpler
components with similar properties. Using this insight, it presents a simple
framework for describing such techniques, the Hint Iteration by Narrow-down and
Transformation Steps (HINTS) framework, and it surveys recent work in the
context of this framework. It discusses important implications of the survey
and framework, including the need to further develop evaluation methods and the
importance of considering hint technique components when designing,
communicating and evaluating hint systems. Ultimately, this paper is designed
to facilitate future opportunities for the development, extension and
comparison of automated programming hint techniques in order to maximise their
educational potential.",2019-08-30,2019,2019-08,education
Deep Knowledge Tracing with Side Information,"Monitoring student knowledge states or skill acquisition levels known as
knowledge tracing, is a fundamental part of intelligent tutoring systems.
Despite its inherent challenges, recent deep neural networks based knowledge
tracing models have achieved great success, which is largely from models'
ability to learn sequential dependencies of questions in student exercise data.
However, in addition to sequential information, questions inherently exhibit
side relations, which can enrich our understandings about student knowledge
states and has great potentials to advance knowledge tracing. Thus, in this
paper, we exploit side relations to improve knowledge tracing and design a
novel framework DTKS. The experimental results on real education data validate
the effectiveness of the proposed framework and demonstrate the importance of
side information in knowledge tracing.",2019-09-01,2019,2019-09,education
A Multimodal Alerting System for Online Class Quality Assurance,"Online 1 on 1 class is created for more personalized learning experience. It
demands a large number of teaching resources, which are scarce in China. To
alleviate this problem, we build a platform (marketplace), i.e., \emph{Dahai}
to allow college students from top Chinese universities to register as
part-time instructors for the online 1 on 1 classes. To warn the unqualified
instructors and ensure the overall education quality, we build a monitoring and
alerting system by utilizing multimodal information from the online
environment. Our system mainly consists of two key components: banned word
detector and class quality predictor. The system performance is demonstrated
both offline and online. By conducting experimental evaluation of real-world
online courses, we are able to achieve 74.3\% alerting accuracy in our
production environment.",2019-09-01,2019,2019-09,education
"Identifying Editor Roles in Argumentative Writing from Student Revision
  Histories","We present a method for identifying editor roles from students' revision
behaviors during argumentative writing. We first develop a method for applying
a topic modeling algorithm to identify a set of editor roles from a vocabulary
capturing three aspects of student revision behaviors: operation, purpose, and
position. We validate the identified roles by showing that modeling the editor
roles that students take when revising a paper not only accounts for the
variance in revision purposes in our data, but also relates to writing
improvement.",2019-09-03,2019,2019-09,education
On educating machines,"Machine education is an emerging research field that focuses on the problem
which is inverse to machine learning. To date, the literature on educating
machines is still in its infancy. A fairly low number of methodology and method
papers are scattered throughout various formal and informal publication
avenues, mainly because the field is not yet well coalesced (with no well
established discussion forums or investigation pathways), but also due to the
breadth of its potential ramifications and research directions. In this study
we bring together the existing literature and organise the discussion into a
small number of research directions (out of many) which are to date
sufficiently explored to form a minimal critical mass that can push the machine
education concept further towards a standalone research field status.",2019-09-13,2019,2019-09,education
Automatic Short Answer Grading via Multiway Attention Networks,"Automatic short answer grading (ASAG), which autonomously score student
answers according to reference answers, provides a cost-effective and
consistent approach to teaching professionals and can reduce their monotonous
and tedious grading workloads. However, ASAG is a very challenging task due to
two reasons: (1) student answers are made up of free text which requires a deep
semantic understanding; and (2) the questions are usually open-ended and across
many domains in K-12 scenarios. In this paper, we propose a generalized
end-to-end ASAG learning framework which aims to (1) autonomously extract
linguistic information from both student and reference answers; and (2)
accurately model the semantic relations between free-text student and reference
answers in open-ended domain. The proposed ASAG model is evaluated on a large
real-world K-12 dataset and can outperform the state-of-the-art baselines in
terms of various evaluation metrics.",2019-09-23,2019,2019-09,education
"Occurence of A Cyber Security Eco-System: A Nature Oriented Project and
  Evaluation of An Indirect Social Experiment","Because of todays technological developments and the influence of digital
systems into every aspect of our lives, importance of cyber security improves
more and more day-by-day. Projects, educational processes and seminars realized
for this aim create and improve awareness among individuals and provide useful
tools for growing equipped generations. The aim of this study is to focus on a
cyber security eco-system, which was self-occurred within the interactive
educational environment designed under the scope of TUBITAK 4004 Nature
Education and Science Schools Projects (with the name of A Cyber Security
Adventure) with the use of important technologies such as virtual reality,
augmented reality, and artificial intelligence. The eco-system occurred within
the interactive educational process where high school students took place
caused both students and the project team to experience an indirect social
experiment environment. In this sense, it is thought that the findings and
comments presented in the study will give important ideas to everyone involved
in cyber security education, life-long learning processes, and the technology
use in software oriented educational tools.",2019-09-29,2019,2019-09,education
"Toward a Computational Theory of Evidence-Based Reasoning for
  Instructable Cognitive Agents","Evidence-based reasoning is at the core of many problem-solving and
decision-making tasks in a wide variety of domains. Generalizing from the
research and development of cognitive agents in several such domains, this
paper presents progress toward a computational theory for the development of
instructable cognitive agents for evidence-based reasoning tasks. The paper
also illustrates the application of this theory to the development of four
prototype cognitive agents in domains that are critical to the government and
the public sector. Two agents function as cognitive assistants, one in
intelligence analysis, and the other in science education. The other two agents
operate autonomously, one in cybersecurity and the other in intelligence,
surveillance, and reconnaissance. The paper concludes with the directions of
future research on the proposed computational theory.",2019-10-09,2019,2019-10,education
"NCI Workshop on Artificial Intelligence in Radiation Oncology: Training
  the Next Generation","Artificial intelligence (AI) is about to touch every aspect of radiotherapy
from consultation, treatment planning, quality assurance, therapy delivery, to
outcomes modeling. There is an urgent need to train radiation oncologists and
medical physicists in data science to help shepherd AI solutions into clinical
practice. Poorly trained personnel may do more harm than good when attempting
to apply rapidly developing and complex technologies. As the amount of AI
research expands in our field, the radiation oncology community needs to
discuss how to educate future generations in this area. The National Cancer
Institute (NCI) Workshop on AI in Radiation Oncology (Shady Grove, MD, April
4-5, 2019) was the first
(https://dctd.cancer.gov/NewsEvents/20190523_ai_in_radiation_oncology.htm) of
two data science workshops in radiation oncology hosted by the NCI in 2019.
During this workshop, the Training and Education Working Group was formed by
volunteers among the invited attendees. Its members represent radiation
oncology, medical physics, radiology, computer science, industry, and the NCI.
In this perspective article written by members of the Training and Education
Working Group, we provide and discuss Action Points relevant for future
trainees interested in radiation oncology AI: (1) creating AI awareness and
responsible conduct; (2) implementing a practical didactic curriculum; (3)
creating a publicly available database of training resources; and (4)
accelerate learning and funding opportunities. Together, these Action Points
can facilitate the translation of AI into clinical practice.",2019-10-18,2019,2019-10,education
"Response to NITRD, NCO, NSF Request for Information on ""Update to the
  2016 National Artificial Intelligence Research and Development Strategic
  Plan""","We present a response to the 2018 Request for Information (RFI) from the
NITRD, NCO, NSF regarding the ""Update to the 2016 National Artificial
Intelligence Research and Development Strategic Plan."" Through this document,
we provide a response to the question of whether and how the National
Artificial Intelligence Research and Development Strategic Plan (NAIRDSP)
should be updated from the perspective of Fermilab, America's premier national
laboratory for High Energy Physics (HEP). We believe the NAIRDSP should be
extended in light of the rapid pace of development and innovation in the field
of Artificial Intelligence (AI) since 2016, and present our recommendations
below. AI has profoundly impacted many areas of human life, promising to
dramatically reshape society --- e.g., economy, education, science --- in the
coming years. We are still early in this process. It is critical to invest now
in this technology to ensure it is safe and deployed ethically. Science and
society both have a strong need for accuracy, efficiency, transparency, and
accountability in algorithms, making investments in scientific AI particularly
valuable. Thus far the US has been a leader in AI technologies, and we believe
as a national Laboratory it is crucial to help maintain and extend this
leadership. Moreover, investments in AI will be important for maintaining US
leadership in the physical sciences.",2019-11-05,2019,2019-11,education
"EDUQA: Educational Domain Question Answering System using Conceptual
  Network Mapping","Most of the existing question answering models can be largely compiled into
two categories: i) open domain question answering models that answer generic
questions and use large-scale knowledge base along with the targeted web-corpus
retrieval and ii) closed domain question answering models that address focused
questioning area and use complex deep learning models. Both the above models
derive answers through textual comprehension methods. Due to their inability to
capture the pedagogical meaning of textual content, these models are not
appropriately suited to the educational field for pedagogy. In this paper, we
propose an on-the-fly conceptual network model that incorporates educational
semantics. The proposed model preserves correlations between conceptual
entities by applying intelligent indexing algorithms on the concept network so
as to improve answer generation. This model can be utilized for building
interactive conversational agents for aiding classroom learning.",2019-11-12,2019,2019-11,education
Joint Embedding Learning of Educational Knowledge Graphs,"As an efficient model for knowledge organization, the knowledge graph has
been widely adopted in several fields, e.g., biomedicine, sociology, and
education. And there is a steady trend of learning embedding representations of
knowledge graphs to facilitate knowledge graph construction and downstream
tasks. In general, knowledge graph embedding techniques aim to learn vectorized
representations which preserve the structural information of the graph. And
conventional embedding learning models rely on structural relationships among
entities and relations. However, in educational knowledge graphs, structural
relationships are not the focus. Instead, rich literals of the graphs are more
valuable. In this paper, we focus on this problem and propose a novel model for
embedding learning of educational knowledge graphs. Our model considers both
structural and literal information and jointly learns embedding
representations. Three experimental graphs were constructed based on an
educational knowledge graph which has been applied in real-world teaching. We
conducted two experiments on the three graphs and other common benchmark
graphs. The experimental results proved the effectiveness of our model and its
superiority over other baselines when processing educational knowledge graphs.",2019-11-20,2019,2019-11,education
"TrueLearn: A Family of Bayesian Algorithms to Match Lifelong Learners to
  Open Educational Resources","The recent advances in computer-assisted learning systems and the
availability of open educational resources today promise a pathway to providing
cost-efficient, high-quality education to large masses of learners. One of the
most ambitious use cases of computer-assisted learning is to build a lifelong
learning recommendation system. Unlike short-term courses, lifelong learning
presents unique challenges, requiring sophisticated recommendation models that
account for a wide range of factors such as background knowledge of learners or
novelty of the material while effectively maintaining knowledge states of
masses of learners for significantly longer periods of time (ideally, a
lifetime). This work presents the foundations towards building a dynamic,
scalable and transparent recommendation system for education, modelling
learner's knowledge from implicit data in the form of engagement with open
educational resources. We i) use a text ontology based on Wikipedia to
automatically extract knowledge components of educational resources and, ii)
propose a set of online Bayesian strategies inspired by the well-known areas of
item response theory and knowledge tracing. Our proposal, TrueLearn, focuses on
recommendations for which the learner has enough background knowledge (so they
are able to understand and learn from the material), and the material has
enough novelty that would help the learner improve their knowledge about the
subject and keep them engaged. We further construct a large open educational
video lectures dataset and test the performance of the proposed algorithms,
which show clear promise towards building an effective educational
recommendation system.",2019-11-21,2019,2019-11,education
Towards an Integrative Educational Recommender for Lifelong Learners,"One of the most ambitious use cases of computer-assisted learning is to build
a recommendation system for lifelong learning. Most recommender algorithms
exploit similarities between content and users, overseeing the necessity to
leverage sensible learning trajectories for the learner. Lifelong learning thus
presents unique challenges, requiring scalable and transparent models that can
account for learner knowledge and content novelty simultaneously, while also
retaining accurate learners representations for long periods of time. We
attempt to build a novel educational recommender, that relies on an integrative
approach combining multiple drivers of learners engagement. Our first step
towards this goal is TrueLearn, which models content novelty and background
knowledge of learners and achieves promising performance while retaining a
human interpretable learner model.",2019-12-03,2019,2019-12,education
EdNet: A Large-Scale Hierarchical Dataset in Education,"With advances in Artificial Intelligence in Education (AIEd) and the
ever-growing scale of Interactive Educational Systems (IESs), data-driven
approach has become a common recipe for various tasks such as knowledge tracing
and learning path recommendation. Unfortunately, collecting real students'
interaction data is often challenging, which results in the lack of public
large-scale benchmark dataset reflecting a wide variety of student behaviors in
modern IESs. Although several datasets, such as ASSISTments, Junyi Academy,
Synthetic and STATICS, are publicly available and widely used, they are not
large enough to leverage the full potential of state-of-the-art data-driven
models and limits the recorded behaviors to question-solving activities. To
this end, we introduce EdNet, a large-scale hierarchical dataset of diverse
student activities collected by Santa, a multi-platform self-study solution
equipped with artificial intelligence tutoring system. EdNet contains
131,441,538 interactions from 784,309 students collected over more than 2
years, which is the largest among the ITS datasets released to the public so
far. Unlike existing datasets, EdNet provides a wide variety of student actions
ranging from question-solving to lecture consumption and item purchasing. Also,
EdNet has a hierarchical structure where the student actions are divided into 4
different levels of abstractions. The features of EdNet are domain-agnostic,
allowing EdNet to be extended to different domains easily. The dataset is
publicly released under Creative Commons Attribution-NonCommercial 4.0
International license for research purposes. We plan to host challenges in
multiple AIEd tasks with EdNet to provide a common ground for the fair
comparison between different state of the art models and encourage the
development of practical and effective methods.",2019-12-06,2019,2019-12,education
"Assessment Modeling: Fundamental Pre-training Tasks for Interactive
  Educational Systems","Like many other domains in Artificial Intelligence (AI), there are specific
tasks in the field of AI in Education (AIEd) for which labels are scarce and
expensive, such as predicting exam score or review correctness. A common way of
circumventing label-scarce problems is pre-training a model to learn
representations of the contents of learning items. However, such methods fail
to utilize the full range of student interaction data available and do not
model student learning behavior. To this end, we propose Assessment Modeling, a
class of fundamental pre-training tasks for general interactive educational
systems. An assessment is a feature of student-system interactions which can
serve as a pedagogical evaluation. Examples include the correctness and
timeliness of a student's answer. Assessment Modeling is the prediction of
assessments conditioned on the surrounding context of interactions. Although it
is natural to pre-train on interactive features available in large amounts,
limiting the prediction targets to assessments focuses the tasks' relevance to
the label-scarce educational problems and reduces less-relevant noise. While
the effectiveness of different combinations of assessments is open for
exploration, we suggest Assessment Modeling as a first-order guiding principle
for selecting proper pre-training tasks for label-scarce educational problems.",2020-01-01,2020,2020-01,education
Algorithmic Fairness,"An increasing number of decisions regarding the daily lives of human beings
are being controlled by artificial intelligence (AI) algorithms in spheres
ranging from healthcare, transportation, and education to college admissions,
recruitment, provision of loans and many more realms. Since they now touch on
many aspects of our lives, it is crucial to develop AI algorithms that are not
only accurate but also objective and fair. Recent studies have shown that
algorithmic decision-making may be inherently prone to unfairness, even when
there is no intention for it. This paper presents an overview of the main
concepts of identifying, measuring and improving algorithmic fairness when
using AI algorithms. The paper begins by discussing the causes of algorithmic
bias and unfairness and the common definitions and measures for fairness.
Fairness-enhancing mechanisms are then reviewed and divided into pre-process,
in-process and post-process mechanisms. A comprehensive comparison of the
mechanisms is then conducted, towards a better understanding of which
mechanisms should be used in different scenarios. The paper then describes the
most commonly used fairness-related datasets in this field. Finally, the paper
ends by reviewing several emerging research sub-fields of algorithmic fairness.",2020-01-21,2020,2020-01,education
"What's happened in MOOC Posts Analysis, Knowledge Tracing and Peer
  Feedbacks? A Review","Learning Management Systems (LMS) and Educational Data Mining (EDM) are two
important parts of online educational environment with the former being a
centralised web-based information systems where the learning content is managed
and learning activities are organised (Stone and Zheng,2014) and latter
focusing on using data mining techniques for the analysis of data so generated.
As part of this work, we present a literature review of three major tasks of
EDM (See section 2), by identifying shortcomings and existing open problems,
and a Blumenfield chart (See section 3). The consolidated set of papers and
resources so used are released in
https://github.com/manikandan-ravikiran/cs6460-Survey. The coverage statistics
and review matrix of the survey are as shown in Figure 1 & Table 1
respectively. Acronym expansions are added in the Appendix Section 4.1.",2020-01-27,2020,2020-01,education
Agent-Based Proof Design via Lemma Flow Diagram,"We discuss an agent-based approach to proof design and implementation, which
we call {\it Lemma Flow Diagram} (LFD). This approach is based on the multicut
rule with $shared$ cuts. This approach is modular and easy to use, read and
automate. Thus, we consider LFD an appealing alternative to `flow proof' which
is popular in mathematical education. Some examples are provided.",2020-02-03,2020,2020-02,education
"Machine Education: Designing semantically ordered and ontologically
  guided modular neural networks","The literature on machine teaching, machine education, and curriculum design
for machines is in its infancy with sparse papers on the topic primarily
focusing on data and model engineering factors to improve machine learning. In
this paper, we first discuss selected attempts to date on machine teaching and
education. We then bring theories and methodologies together from human
education to structure and mathematically define the core problems in lesson
design for machine education and the modelling approaches required to support
the steps for machine education. Last, but not least, we offer an
ontology-based methodology to guide the development of lesson plans to produce
transparent and explainable modular learning machines, including neural
networks.",2020-02-07,2020,2020-02,education
"Combining high-performance hardware, cloud computing, and deep learning
  frameworks to accelerate physical simulations: probing the Hopfield network","The synthesis of high-performance computing (particularly graphics processing
units), cloud computing services (like Google Colab), and high-level deep
learning frameworks (such as PyTorch) has powered the burgeoning field of
artificial intelligence. While these technologies are popular in the computer
science discipline, the physics community is less aware of how such
innovations, freely available online, can improve research and education. In
this tutorial, we take the Hopfield network as an example to show how the
confluence of these fields can dramatically accelerate physics-based computer
simulations and remove technical barriers in implementing such programs,
thereby making physics experimentation and education faster and more
accessible. To do so, we introduce the cloud, the GPU, and AI frameworks that
can be easily repurposed for physics simulation. We then introduce the Hopfield
network and explain how to produce large-scale simulations and visualizations
for free in the cloud with very little code (fully self-contained in the text).
Finally, we suggest programming exercises throughout the paper, geared towards
advanced undergraduate students studying physics, biophysics, or computer
science.",2020-02-16,2020,2020-02,education
"Proceedings 8th International Workshop on Theorem Proving Components for
  Educational Software","This EPTCS volume contains the proceedings of the ThEdu'19 workshop, promoted
on August 25, 2019, as a satellite event of CADE-27, in Natal, Brazil.
Representing the eighth installment of the ThEdu series, ThEdu'19 was a vibrant
workshop, with an invited talk by Sarah Winkler, four contributions, and the
first edition of a Geometry Automated Provers Competition. After the workshop
an open call for papers was issued and attracted seven submissions, six of
which have been accepted by the reviewers, and collected in the present
post-proceedings volume.
  The ThEdu series pursues the smooth transition from an intuitive way of doing
mathematics at secondary school to a more formal approach to the subject in
STEM education, while favoring software support for this transition by
exploiting the power of theorem-proving technologies.
  The volume editors hope that this collection of papers will further promote
the development of theorem-proving-based software, and that it will collaborate
on improving mutual understanding between computer mathematicians and
stakeholders in education.",2020-02-27,2020,2020-02,education
Towards a Geometry Automated Provers Competition,"The geometry automated theorem proving area distinguishes itself by a large
number of specific methods and implementations, different approaches
(synthetic, algebraic, semi-synthetic) and different goals and applications
(from research in the area of artificial intelligence to applications in
education).
  Apart from the usual measures of efficiency (e.g. CPU time), the possibility
of visual and/or readable proofs is also an expected output against which the
geometry automated theorem provers (GATP) should be measured.
  The implementation of a competition between GATP would allow to create a test
bench for GATP developers to improve the existing ones and to propose new ones.
It would also allow to establish a ranking for GATP that could be used by
""clients"" (e.g. developers of educational e-learning systems) to choose the
best implementation for a given intended use.",2020-02-28,2020,2020-02,education
"Automating the Generation of High School Geometry Proofs using Prolog in
  an Educational Context","When working on intelligent tutor systems designed for mathematics education
and its specificities, an interesting objective is to provide relevant help to
the students by anticipating their next steps. This can only be done by
knowing, beforehand, the possible ways to solve a problem. Hence the need for
an automated theorem prover that provide proofs as they would be written by a
student. To achieve this objective, logic programming is a natural tool due to
the similarity of its reasoning with a mathematical proof by inference. In this
paper, we present the core ideas we used to implement such a prover, from its
encoding in Prolog to the generation of the complete set of proofs. However,
when dealing with educational aspects, there are many challenges to overcome.
We also present the main issues we encountered, as well as the chosen
solutions.",2020-02-28,2020,2020-02,education
"Beyond STEM, How Can Women Engage Big Data, Analytics, Robotics and
  Artificial Intelligence? An Exploratory Analysis of Confidence and
  Educational Factors in the Emerging Technology Waves Influencing the Role of,
  and Impact Upon, Women","In spite of the rapidly advancing global technological environment, the
professional participation of women in technology, big data, analytics,
artificial intelligence and information systems related domains remains
proportionately low. Furthermore, it is of no less concern that the number of
women in leadership in these domains are in even lower proportions. In spite of
numerous initiatives to improve the participation of women in technological
domains, there is an increasing need to gain additional insights into this
phenomenon especially since it occurs in nations and geographies which have
seen a sharp rise in overall female education, without such increase
translating into a corresponding spurt in information systems and technological
roles for women. The present paper presents findings from an exploratory
analysis and outlines a framework to gain insights into educational factors in
the emerging technology waves influencing the role of, and impact upon, women.
We specifically identify ways for learning and self-efficacy as key factors,
which together lead us to the Advancement of Women in Technology (AWT) insights
framework. Based on the AWT framework, we also proposition principles that can
be used to encourage higher professional engagement of women in emerging and
advanced technologies. Key Words- Women's Education, Technology, Artificial
Intelligence, Knowing, Confidence, Self-Efficacy, Learning.",2020-03-26,2020,2020-03,education
Combating The Machine Ethics Crisis: An Educational Approach,"In recent years, the availability of massive data sets and improved computing
power have driven the advent of cutting-edge machine learning algorithms.
However, this trend has triggered growing concerns associated with its ethical
issues. In response to such a phenomenon, this study proposes a feasible
solution that combines ethics and computer science materials in artificial
intelligent classrooms. In addition, the paper presents several arguments and
evidence in favor of the necessity and effectiveness of this integrated
approach.",2020-04-02,2020,2020-04,education
Neural Network-Based Collaborative Filtering for Question Sequencing,"E-Learning systems (ELS) and Intelligent Tutoring Systems (ITS) play a
significant part in today's education programs. Sequencing questions is the art
of generating a personalized quiz for a target learner. A personalized test
will enrich the learner's experience and will contribute to a more effective
and efficient learning process. In this paper, we used the Neural Collaborative
Filtering (NCF) model to generate question sequencing and compare it to a
pair-wise memory-based question sequencing algorithm - EduRank. The NCF model
showed significantly better ranking results than the EduRank model with an
Average precision correlation score of 0.85 compared to 0.8.",2020-04-25,2020,2020-04,education
"Automated Personalized Feedback Improves Learning Gains in an
  Intelligent Tutoring System","We investigate how automated, data-driven, personalized feedback in a
large-scale intelligent tutoring system (ITS) improves student learning
outcomes. We propose a machine learning approach to generate personalized
feedback, which takes individual needs of students into account. We utilize
state-of-the-art machine learning and natural language processing techniques to
provide the students with personalized hints, Wikipedia-based explanations, and
mathematical hints. Our model is used in Korbit, a large-scale dialogue-based
ITS with thousands of students launched in 2019, and we demonstrate that the
personalized feedback leads to considerable improvement in student learning
outcomes and in the subjective evaluation of the feedback.",2020-05-05,2020,2020-05,education
"Choose Your Own Question: Encouraging Self-Personalization in Learning
  Path Construction","Learning Path Recommendation is the heart of adaptive learning, the
educational paradigm of an Interactive Educational System (IES) providing a
personalized learning experience based on the student's history of learning
activities. In typical existing IESs, the student must fully consume a
recommended learning item to be provided a new recommendation. This workflow
comes with several limitations. For example, there is no opportunity for the
student to give feedback on the choice of learning items made by the IES.
Furthermore, the mechanism by which the choice is made is opaque to the
student, limiting the student's ability to track their learning. To this end,
we introduce Rocket, a Tinder-like User Interface for a general class of IESs.
Rocket provides a visual representation of Artificial Intelligence
(AI)-extracted features of learning materials, allowing the student to quickly
decide whether the material meets their needs. The student can choose between
engaging with the material and receiving a new recommendation by swiping or
tapping. Rocket offers the following potential improvements for IES User
Interfaces: First, Rocket enhances the explainability of IES recommendations by
showing students a visual summary of the meaningful AI-extracted features used
in the decision-making process. Second, Rocket enables self-personalization of
the learning experience by leveraging the students' knowledge of their own
abilities and needs. Finally, Rocket provides students with fine-grained
information on their learning path, giving them an avenue to assess their own
skills and track their learning progress. We present the source code of Rocket,
in which we emphasize the independence and extensibility of each component, and
make it publicly available for all purposes.",2020-05-08,2020,2020-05,education
Siamese Neural Networks for Class Activity Detection,"Classroom activity detection (CAD) aims at accurately recognizing speaker
roles (either teacher or student) in classrooms. A CAD solution helps teachers
get instant feedback on their pedagogical instructions. However, CAD is very
challenging because (1) classroom conversations contain many conversational
turn-taking overlaps between teachers and students; (2) the CAD model needs to
be generalized well enough for different teachers and students; and (3)
classroom recordings may be very noisy and low-quality. In this work, we
address the above challenges by building a Siamese neural framework to
automatically identify teacher and student utterances from classroom
recordings. The proposed model is evaluated on real-world educational datasets.
The results demonstrate that (1) our approach is superior on the prediction
tasks for both online and offline classroom environments; and (2) our framework
exhibits robustness and generalization ability on new teachers (i.e., teachers
never appear in training data).",2020-05-15,2020,2020-05,education
"Automatic Dialogic Instruction Detection for K-12 Online One-on-one
  Classes","Online one-on-one class is created for highly interactive and immersive
learning experience. It demands a large number of qualified online instructors.
In this work, we develop six dialogic instructions and help teachers achieve
the benefits of one-on-one learning paradigm. Moreover, we utilize neural
language models, i.e., long short-term memory (LSTM), to detect above six
instructions automatically. Experiments demonstrate that the LSTM approach
achieves AUC scores from 0.840 to 0.979 among all six types of instructions on
our real-world educational dataset.",2020-05-16,2020,2020-05,education
"Neural Multi-Task Learning for Teacher Question Detection in Online
  Classrooms","Asking questions is one of the most crucial pedagogical techniques used by
teachers in class. It not only offers open-ended discussions between teachers
and students to exchange ideas but also provokes deeper student thought and
critical analysis. Providing teachers with such pedagogical feedback will
remarkably help teachers improve their overall teaching quality over time in
classrooms. Therefore, in this work, we build an end-to-end neural framework
that automatically detects questions from teachers' audio recordings. Compared
with traditional methods, our approach not only avoids cumbersome feature
engineering, but also adapts to the task of multi-class question detection in
real education scenarios. By incorporating multi-task learning techniques, we
are able to strengthen the understanding of semantic relations among different
types of questions. We conducted extensive experiments on the question
detection tasks in a real-world online classroom dataset and the results
demonstrate the superiority of our model in terms of various evaluation
metrics.",2020-05-16,2020,2020-05,education
Predicting Engagement in Video Lectures,"The explosion of Open Educational Resources (OERs) in the recent years
creates the demand for scalable, automatic approaches to process and evaluate
OERs, with the end goal of identifying and recommending the most suitable
educational materials for learners. We focus on building models to find the
characteristics and features involved in context-agnostic engagement (i.e.
population-based), a seldom researched topic compared to other contextualised
and personalised approaches that focus more on individual learner engagement.
Learner engagement, is arguably a more reliable measure than popularity/number
of views, is more abundant than user ratings and has also been shown to be a
crucial component in achieving learning outcomes. In this work, we explore the
idea of building a predictive model for population-based engagement in
education. We introduce a novel, large dataset of video lectures for predicting
context-agnostic engagement and propose both cross-modal and modality-specific
feature sets to achieve this task. We further test different strategies for
quantifying learner engagement signals. We demonstrate the use of our approach
in the case of data scarcity. Additionally, we perform a sensitivity analysis
of the best performing model, which shows promising performance and can be
easily integrated into an educational recommender system for OERs.",2020-05-31,2020,2020-05,education
"AI-Powered Learning: Making Education Accessible, Affordable, and
  Achievable","We have developed an AI-powered socio-technical system for making online
learning in higher education more accessible, affordable and achievable. In
particular, we have developed four novel and intertwined AI technologies: (1)
VERA, a virtual experimentation research assistant for supporting inquiry-based
learning of scientific knowledge, (2) Jill Watson Q&A, a virtual teaching
assistant for answering questions based on educational documents including the
VERA user reference guide, (3) Jill Watson SA, a virtual social agent that
promotes online interactions, and (4) Agent Smith, that helps generate a Jill
Watson Q&A agent for new documents such as class syllabi. The results are
positive: (i) VERA enhances ecological knowledge and is freely available
online; (ii) Jill Watson Q&A has been used by >4,000 students in >12 online
classes and saved teachers >500 hours of work; (iii) Jill Q&A and Jill Watson
SA promote learner engagement, interaction, and community; and (iv). Agent
Smith helps generate Jill Watson Q&A for a new syllabus within ~25 hours. Put
together, these innovative technologies help make online learning
simultaneously more accessible (by making materials available online),
affordable (by saving teacher time), and achievable (by providing learning
assistance and fostering student engagement).",2020-06-02,2020,2020-06,education
"Disparate Impact of Artificial Intelligence Bias in Ridehailing
  Economy's Price Discrimination Algorithms","Ridehailing applications that collect mobility data from individuals to
inform smart city planning predict each trip's fare pricing with automated
algorithms that rely on artificial intelligence (AI). This type of AI
algorithm, namely a price discrimination algorithm, is widely used in the
industry's black box systems for dynamic individualized pricing. Lacking
transparency, studying such AI systems for fairness and disparate impact has
not been possible without access to data used in generating the outcomes of
price discrimination algorithms. Recently, in an effort to enhance transparency
in city planning, the city of Chicago regulation mandated that transportation
providers publish anonymized data on ridehailing. As a result, we present the
first large-scale measurement of the disparate impact of price discrimination
algorithms used by ridehailing applications.
  The application of random effects models from the meta-analysis literature
combines the city-level effects of AI bias on fare pricing from census tract
attributes, aggregated from the American Community Survey. An analysis of 100
million ridehailing samples from the city of Chicago indicates a significant
disparate impact in fare pricing of neighborhoods due to AI bias learned from
ridehailing utilization patterns associated with demographic attributes.
Neighborhoods with larger non-white populations, higher poverty levels, younger
residents, and high education levels are significantly associated with higher
fare prices, with combined effect sizes, measured in Cohen's d, of -0.32,
-0.28, 0.69, and 0.24 for each demographic, respectively. Further, our methods
hold promise for identifying and addressing the sources of disparate impact in
AI algorithms learning from datasets that contain U.S. geolocations.",2020-06-08,2020,2020-06,education
Algorithmic Fairness in Education,"Data-driven predictive models are increasingly used in education to support
students, instructors, and administrators. However, there are concerns about
the fairness of the predictions and uses of these algorithmic systems. In this
introduction to algorithmic fairness in education, we draw parallels to prior
literature on educational access, bias, and discrimination, and we examine core
components of algorithmic systems (measurement, model learning, and action) to
identify sources of bias and discrimination in the process of developing and
deploying these systems. Statistical, similarity-based, and causal notions of
fairness are reviewed and contrasted in the way they apply in educational
contexts. Recommendations for policy makers and developers of educational
technology offer guidance for how to promote algorithmic fairness in education.",2020-07-10,2020,2020-07,education
"Smart technology in the classroom: a systematic review.Prospects for
  algorithmic accountability","Artificial intelligence (AI) algorithms have emerged in the educational
domain as a tool to make learning more efficient. Different applications for
mastering particular skills, learning new languages, and tracking their
progress are used by children. What is the impact on children from using this
smart technology? We conducted a systematic review to understand the state of
the art. We explored the literature in several sub-disciplines: wearables,
child psychology, AI and education, school surveillance, and accountability.
Our review identified the need for more research for each established topic. We
managed to find both positive and negative effects of using wearables, but
cannot conclude if smart technology use leads to lowering the young children's
performance. Based on our insights we propose a framework to effectively
identify accountability for smart technology in education.",2020-07-13,2020,2020-07,education
"A Hybrid Adaptive Educational eLearning Project based on Ontologies
  Matching and Recommendation System","The implementation of teaching interventions in learning needs has received
considerable attention, as the provision of the same educational conditions to
all students, is pedagogically ineffective. In contrast, more effectively
considered the pedagogical strategies that adapt to the real individual skills
of the students. An important innovation in this direction is the Adaptive
Educational Systems (AES) that support automatic modeling study and adjust the
teaching content on educational needs and students' skills. Effective
utilization of these educational approaches can be enhanced with Artificial
Intelligence (AI) technologies in order to the substantive content of the web
acquires structure and the published information is perceived by the search
engines. This study proposes a novel Adaptive Educational eLearning System
(AEeLS) that has the capacity to gather and analyze data from learning
repositories and to adapt these to the educational curriculum according to the
student skills and experience. It is a novel hybrid machine learning system
that combines a Semi-Supervised Classification method for ontology matching and
a Recommendation Mechanism that uses a hybrid method from neighborhood-based
collaborative and content-based filtering techniques, in order to provide a
personalized educational environment for each student.",2020-07-29,2020,2020-07,education
"Trust and Medical AI: The challenges we face and the expertise needed to
  overcome them","Artificial intelligence (AI) is increasingly of tremendous interest in the
medical field. However, failures of medical AI could have serious consequences
for both clinical outcomes and the patient experience. These consequences could
erode public trust in AI, which could in turn undermine trust in our healthcare
institutions. This article makes two contributions. First, it describes the
major conceptual, technical, and humanistic challenges in medical AI. Second,
it proposes a solution that hinges on the education and accreditation of new
expert groups who specialize in the development, verification, and operation of
medical AI technologies. These groups will be required to maintain trust in our
healthcare institutions.",2020-08-18,2020,2020-08,education
Competence-Based Student Modelling with Dynamic Bayesian Networks,"We present a general method for using a competences map, created by defining
generalization/specialization and inclusion/part-of relationships between
competences, in order to build an overlay student model in the form of a
dynamic Bayesian network in which conditional probability distributions are
defined per relationship type. We have created a competences map for a subset
of the transversal competences defined as educational goals for the Mexican
high school system, then we have built a dynamic Bayesian student model as said
before, and we have use it to trace the development of the corresponding
competences by some hypothetical students exhibiting representative
performances along an online course (low to medium performance, medium to high
performance but with low final score, and two terms medium to high
performance). The results obtained suggest that the proposed way for
constructing dynamic Bayesian student models on the basis of competences maps
could be useful to monitor competence development by real students in online
course.",2020-08-21,2020,2020-08,education
"Measuring the Credibility of Student Attendance Data in Higher Education
  for Data Mining","Educational Data Mining (EDM) is a developing discipline, concerned with
expanding the classical Data Mining (DM) methods and developing new methods for
discovering the data that originate from educational systems. Student
attendance in higher education has always been dealt with in a classical way,
educators rely on counting the occurrence of attendance or absence building
their knowledge about students as well as modules based on this count. This
method is neither credible nor does it necessarily provide a real indication of
a student performance. This study tries to formulate the extracted knowledge in
a way that guarantees achieving accurate and credible results. Student
attendance data, gathered from the educational system, were first cleaned in
order to remove any randomness and noise, then various attributes were studied
so as to highlight the most significant ones that affect the real attendance of
students. The next step was to derive an equation that measures the Student
Attendance Credibility (SAC) considering the attributes chosen in the previous
step. The reliability of the newly developed measure was then evaluated in
order to examine its consistency. Finally, the J48 DM classification technique
was utilized in order to classify modules based on the strength of their SAC
values. Results of this study were promising, and credibility values achieved
using the newly derived formula gave accurate, credible, and real indicators of
student attendance, as well as accurate classification of modules based on the
credibility of student attendance on those modules.",2020-09-01,2020,2020-09,education
"Teaching Tech to Talk: K-12 Conversational Artificial Intelligence
  Literacy Curriculum and Development Tools","With children talking to smart-speakers, smart-phones and even
smart-microwaves daily, it is increasingly important to educate students on how
these agents work-from underlying mechanisms to societal implications.
Researchers are developing tools and curriculum to teach K-12 students broadly
about artificial intelligence (AI); however, few studies have evaluated these
tools with respect to AI-specific learning outcomes, and even fewer have
addressed student learning about AI-based conversational agents. We evaluate
our Conversational Agent Interface for MIT App Inventor and workshop curriculum
with respect to eight AI competencies from the literature. Furthermore, we
analyze teacher (n=9) and student (n=47) feedback from workshops with the
interface and recommend that future work leverages design considerations from
the literature to optimize engagement, collaborates with teachers, and
addresses a range of student abilities through pacing and opportunities for
extension. We found students struggled most with the concepts of AI ethics and
learning, and recommend emphasizing these topics when teaching.
  The appendix, including a demo video, can be found here:
https://gist.github.com/jessvb/1cd959e32415a6ad4389761c49b54bbf",2020-09-11,2020,2020-09,education
"Proceedings 36th International Conference on Logic Programming
  (Technical Communications)","Since the first conference held in Marseille in 1982, ICLP has been the
premier international event for presenting research in logic programming.
Contributions are solicited in all areas of logic programming and related
areas, including but not restricted to:
  - Foundations: Semantics, Formalisms, Answer-Set Programming, Non-monotonic
Reasoning, Knowledge Representation.
  - Declarative Programming: Inference engines, Analysis, Type and mode
inference, Partial evaluation, Abstract interpretation, Transformation,
Validation, Verification, Debugging, Profiling, Testing, Logic-based
domain-specific languages, constraint handling rules.
  - Related Paradigms and Synergies: Inductive and Co-inductive Logic
Programming, Constraint Logic Programming, Interaction with SAT, SMT and CSP
solvers, Logic programming techniques for type inference and theorem proving,
Argumentation, Probabilistic Logic Programming, Relations to object-oriented
and Functional programming, Description logics, Neural-Symbolic Machine
Learning, Hybrid Deep Learning and Symbolic Reasoning.
  - Implementation: Concurrency and distribution, Objects, Coordination,
Mobility, Virtual machines, Compilation, Higher Order, Type systems, Modules,
Constraint handling rules, Meta-programming, Foreign interfaces, User
interfaces.
  - Applications: Databases, Big Data, Data Integration and Federation,
Software Engineering, Natural Language Processing, Web and Semantic Web,
Agents, Artificial Intelligence, Bioinformatics, Education, Computational life
sciences, Education, Cybersecurity, and Robotics.",2020-09-19,2020,2020-09,education
"Designing AI Learning Experiences for K-12: Emerging Works, Future
  Opportunities and a Design Framework","Artificial intelligence (AI) literacy is a rapidly growing research area and
a critical addition to K-12 education. However, support for designing tools and
curriculum to teach K-12 AI literacy is still limited. There is a need for
additional interdisciplinary human-computer interaction and education research
investigating (1) how general AI literacy is currently implemented in learning
experiences and (2) what additional guidelines are required to teach AI
literacy in specifically K-12 learning contexts. In this paper, we analyze a
collection of K-12 AI and education literature to show how core competencies of
AI literacy are applied successfully and organize them into an
educator-friendly chart to enable educators to efficiently find appropriate
resources for their classrooms. We also identify future opportunities and K-12
specific design guidelines, which we synthesized into a conceptual framework to
support researchers, designers, and educators in creating K-12 AI learning
experiences.",2020-09-22,2020,2020-09,education
"Engaging Teachers to Co-Design Integrated AI Curriculum for K-12
  Classrooms","Artificial Intelligence (AI) education is an increasingly popular topic area
for K-12 teachers. However, little research has investigated how AI education
can be designed to be more accessible to all learners. We organized co-design
workshops with 15 K-12 teachers to identify opportunities to integrate AI
education into core curriculum to leverage learners' interests. During the
co-design workshops, teachers and researchers co-created lesson plans where AI
concepts were embedded into various core subjects. We found that K-12 teachers
need additional scaffolding in the curriculum to facilitate ethics and data
discussions, and value supports for learner engagement, collaboration, and
reflection. We identify opportunities for researchers and teachers to
collaborate to make AI education more accessible, and present an exemplar
lesson plan that shows entry points for teaching AI in non-computing subjects.
We also reflect on co-designing with K-12 teachers in a remote setting.",2020-09-22,2020,2020-09,education
Research and Education Towards Smart and Sustainable World,"We propose a vision for directing research and education in the ICT field.
Our Smart and Sustainable World vision targets at prosperity for the people and
the planet through better awareness and control of both human-made and natural
environment. The needs of the society, individuals, and industries are
fulfilled with intelligent systems that sense their environment, make proactive
decisions on actions advancing their goals, and perform the actions on the
environment. We emphasize artificial intelligence, feedback loops, human
acceptance and control, intelligent use of basic resources, performance
parameters, mission-oriented interdisciplinary research, and a holistic systems
view complementing the conventional analytical reductive view as a research
paradigm especially for complex problems. To serve a broad audience, we explain
these concepts and list the essential literature. We suggest planning research
and education by specifying, in a step-wise manner, scenarios, performance
criteria, system models, research problems and education content, resulting in
common goals and a coherent project portfolio as well as education curricula.
Research and education produce feedback to support evolutionary development and
encourage creativity in research. Finally, we propose concrete actions for
realizing this approach.",2020-09-29,2020,2020-09,education
"Meta-Heuristic Solutions to a Student Grouping Optimization Problem
  faced in Higher Education Institutions","Combinatorial problems which have been proven to be NP-hard are faced in
Higher Education Institutions and researches have extensively investigated some
of the well-known combinatorial problems such as the timetabling and student
project allocation problems. However, NP-hard problems faced in Higher
Education Institutions are not only confined to these categories of
combinatorial problems. The majority of NP-hard problems faced in institutions
involve grouping students and/or resources, albeit with each problem having its
own unique set of constraints. Thus, it can be argued that techniques to solve
NP-hard problems in Higher Education Institutions can be transferred across the
different problem categories. As no method is guaranteed to outperform all
others in all problems, it is necessary to investigate heuristic techniques for
solving lesser-known problems in order to guide stakeholders or software
developers to the most appropriate algorithm for each unique class of NP-hard
problems faced in Higher Education Institutions. To this end, this study
described an optimization problem faced in a real university that involved
grouping students for the presentation of semester results. Ordering based
heuristics, genetic algorithm and the ant colony optimization algorithm
implemented in Python programming language were used to find feasible solutions
to this problem, with the ant colony optimization algorithm performing better
or equal in 75% of the test instances and the genetic algorithm producing
better or equal results in 38% of the test instances.",2020-10-01,2020,2020-10,education
Aspect-Based Sentiment Analysis in Education Domain,"Analysis of a large amount of data has always brought value to institutions
and organizations. Lately, people's opinions expressed through text have become
a very important aspect of this analysis. In response to this challenge, a
natural language processing technique known as Aspect-Based Sentiment Analysis
(ABSA) has emerged. Having the ability to extract the polarity for each aspect
of opinions separately, ABSA has found itself useful in a wide range of
domains. Education is one of the domains in which ABSA can be successfully
utilized. Being able to understand and find out what students like and don't
like most about a course, professor, or teaching methodology can be of great
importance for the respective institutions. While this task represents a unique
NLP challenge, many studies have proposed different approaches to tackle the
problem. In this work, we present a comprehensive review of the existing work
in ABSA with a focus in the education domain. A wide range of methodologies are
discussed and conclusions are drawn.",2020-10-03,2020,2020-10,education
Kartta Labs: Collaborative Time Travel,"We introduce the modular and scalable design of Kartta Labs, an open source,
open data, and scalable system for virtually reconstructing cities from
historical maps and photos. Kartta Labs relies on crowdsourcing and artificial
intelligence consisting of two major modules: Maps and 3D models. Each module,
in turn, consists of sub-modules that enable the system to reconstruct a city
from historical maps and photos. The result is a spatiotemporal reference that
can be used to integrate various collected data (curated, sensed, or
crowdsourced) for research, education, and entertainment purposes. The system
empowers the users to experience collaborative time travel such that they work
together to reconstruct the past and experience it on an open source and open
data platform.",2020-10-07,2020,2020-10,education
Exercise Hierarchical Feature Enhanced Knowledge Tracing,"Knowledge tracing is a fundamental task in the computer-aid educational
system. In this paper, we propose a hierarchical exercise feature enhanced
knowledge tracing framework, which could enhance the ability of knowledge
tracing by incorporating knowledge distribution, semantic features, and
difficulty features from exercise text. Extensive experiments show the high
performance of our framework.",2020-10-23,2020,2020-10,education
"Proceedings 9th International Workshop on Theorem Proving Components for
  Educational Software","The 9th International Workshop on Theorem-Proving Components for Educational
Software (ThEdu'20) was scheduled to happen on June 29 as a satellite of the
IJCAR-FSCD 2020 joint meeting, in Paris. The COVID-19 pandemic came by
surprise, though, and the main conference was virtualised. Fearing that an
online meeting would not allow our community to fully reproduce the usual
face-to-face networking opportunities of the ThEdu initiative, the Steering
Committee of ThEdu decided to cancel our workshop. Given that many of us had
already planned and worked for that moment, we decided that ThEdu'20 could
still live in the form of an EPTCS volume. The EPTCS concurred with us,
recognising this very singular situation, and accepted our proposal of
organising a special issue with papers submitted to ThEdu'20. An open call for
papers was then issued, and attracted five submissions, all of which have been
accepted by our reviewers, who produced three careful reports on each of the
contributions. The resulting revised papers are collected in the present
volume. We, the volume editors, hope that this collection of papers will help
further promoting the development of theorem-proving-based software, and that
it will collaborate to improve the mutual understanding between computer
mathematicians and stakeholders in education. With some luck, we would actually
expect that the very special circumstances set up by the worst sanitary crisis
in a century will happen to reinforce the need for the application of certified
components and of verification methods for the production of educational
software that would be available even when the traditional on-site learning
experiences turn out not to be recommendable.",2020-10-28,2020,2020-10,education
Teaching Programming for Mathematical Scientists,"Over the past thirty years or so the authors have been teaching various
programming for mathematics courses at our respective Universities, as well as
incorporating computer algebra and numerical computation into traditional
mathematics courses. These activities are, in some important ways, natural
precursors to the use of Artificial Intelligence in Mathematics Education. This
paper reflects on some of our course designs and experiences and is therefore a
mix of theory and practice. Underlying both is a clear recognition of the value
of computer programming for mathematics education. We use this theory and
practice to suggest good techniques for and to raise questions about the use of
AI in Mathematics Education.",2020-10-30,2020,2020-10,education
Personalized Multimodal Feedback Generation in Education,"The automatic evaluation for school assignments is an important application
of AI in the education field. In this work, we focus on the task of
personalized multimodal feedback generation, which aims to generate
personalized feedback for various teachers to evaluate students' assignments
involving multimodal inputs such as images, audios, and texts. This task
involves the representation and fusion of multimodal information and natural
language generation, which presents the challenges from three aspects: 1) how
to encode and integrate multimodal inputs; 2) how to generate feedback specific
to each modality; and 3) how to realize personalized feedback generation. In
this paper, we propose a novel Personalized Multimodal Feedback Generation
Network (PMFGN) armed with a modality gate mechanism and a personalized bias
mechanism to address these challenges. The extensive experiments on real-world
K-12 education data show that our model significantly outperforms several
baselines by generating more accurate and diverse feedback. In addition,
detailed ablation experiments are conducted to deepen our understanding of the
proposed framework.",2020-10-31,2020,2020-10,education
Turning Software Engineers into AI Engineers,"In industry as well as education as well as academics we see a growing need
for knowledge on how to apply machine learning in software applications. With
the educational programme ICT & AI at Fontys UAS we had to find an answer to
the question: ""How should we educate software engineers to become AI
engineers?"" This paper describes our educational programme, the open source
tools we use, and the literature it is based on. After three years of
experience, we present our lessons learned for both educational institutions
and software engineers in practice.",2020-11-03,2020,2020-11,education
"RealAnt: An Open-Source Low-Cost Quadruped for Education and Research in
  Real-World Reinforcement Learning","Current robot platforms available for research are either very expensive or
unable to handle the abuse of exploratory controls in reinforcement learning.
We develop RealAnt, a minimal low-cost physical version of the popular `Ant'
benchmark used in reinforcement learning. RealAnt costs only $\sim$350 EUR
(\$410) in materials and can be assembled in less than an hour. We validate the
platform with reinforcement learning experiments and provide baseline results
on a set of benchmark tasks. We demonstrate that the RealAnt robot can learn to
walk from scratch from less than 10 minutes of experience. We also provide
simulator versions of the robot (with the same dimensions, state-action spaces,
and delayed noisy observations) in the MuJoCo and PyBullet simulators. We
open-source hardware designs, supporting software, and baseline results for
educational use and reproducible research.",2020-11-05,2020,2020-11,education
"Good proctor or ""Big Brother""? AI Ethics and Online Exam Supervision
  Technologies","This article philosophically analyzes online exam supervision technologies,
which have been thrust into the public spotlight due to campus lockdowns during
the COVID-19 pandemic and the growing demand for online courses. Online exam
proctoring technologies purport to provide effective oversight of students
sitting online exams, using artificial intelligence (AI) systems and human
invigilators to supplement and review those systems. Such technologies have
alarmed some students who see them as `Big Brother-like', yet some universities
defend their judicious use. Critical ethical appraisal of online proctoring
technologies is overdue. This article philosophically analyzes these
technologies, focusing on the ethical concepts of academic integrity, fairness,
non-maleficence, transparency, privacy, respect for autonomy, liberty, and
trust. Most of these concepts are prominent in the new field of AI ethics and
all are relevant to the education context. The essay provides ethical
considerations that educational institutions will need to carefully review
before electing to deploy and govern specific online proctoring technologies.",2020-11-15,2020,2020-11,education
Automated Large-scale Class Scheduling in MiniZinc,"Class Scheduling is a highly constrained task. Educational institutes spend a
lot of resources, in the form of time and manual computation, to find a
satisficing schedule that fulfills all the requirements. A satisficing class
schedule accommodates all the students to all their desired courses at
convenient timing. The scheduler also needs to take into account the
availability of course teachers on the given slots. With the added limitation
of available classrooms, the number of solutions satisfying all constraints in
this huge search-space, further decreases.
  This paper proposes an efficient system to generate class schedules that can
fulfill every possible need of a typical university. Though it is primarily a
fixed-credit scheduler, it can be adjusted for open-credit systems as well. The
model is designed in MiniZinc and solved using various off-the-shelf solvers.
The proposed scheduling system can find a balanced schedule for a
moderate-sized educational institute in less than a minute.",2020-11-15,2020,2020-11,education
"Generate Your Counterfactuals: Towards Controlled Counterfactual
  Generation for Text","Machine Learning has seen tremendous growth recently, which has led to larger
adoption of ML systems for educational assessments, credit risk, healthcare,
employment, criminal justice, to name a few. The trustworthiness of ML and NLP
systems is a crucial aspect and requires a guarantee that the decisions they
make are fair and robust. Aligned with this, we propose a framework GYC, to
generate a set of counterfactual text samples, which are crucial for testing
these ML systems. Our main contributions include a) We introduce GYC, a
framework to generate counterfactual samples such that the generation is
plausible, diverse, goal-oriented, and effective, b) We generate counterfactual
samples, that can direct the generation towards a corresponding condition such
as named-entity tag, semantic role label, or sentiment. Our experimental
results on various domains show that GYC generates counterfactual text samples
exhibiting the above four properties. GYC generates counterfactuals that can
act as test cases to evaluate a model and any text debiasing algorithm.",2020-12-08,2020,2020-12,education
Artificial Intelligence at the Edge,"The Internet of Things (IoT) and edge computing applications aim to support a
variety of societal needs, including the global pandemic situation that the
entire world is currently experiencing and responses to natural disasters.
  The need for real-time interactive applications such as immersive video
conferencing, augmented/virtual reality, and autonomous vehicles, in education,
healthcare, disaster recovery and other domains, has never been higher. At the
same time, there have been recent technological breakthroughs in highly
relevant fields such as artificial intelligence (AI)/machine learning (ML),
advanced communication systems (5G and beyond), privacy-preserving
computations, and hardware accelerators. 5G mobile communication networks
increase communication capacity, reduce transmission latency and error, and
save energy -- capabilities that are essential for new applications. The
envisioned future 6G technology will integrate many more technologies,
including for example visible light communication, to support groundbreaking
applications, such as holographic communications and high precision
manufacturing. Many of these applications require computations and analytics
close to application end-points: that is, at the edge of the network, rather
than in a centralized cloud. AI techniques applied at the edge have tremendous
potential both to power new applications and to need more efficient operation
of edge infrastructure. However, it is critical to understand where to deploy
AI systems within complex ecosystems consisting of advanced applications and
the specific real-time requirements towards AI systems.",2020-12-10,2020,2020-12,education
ColorShapeLinks: A board game AI competition for educators and students,"ColorShapeLinks is an AI board game competition framework specially designed
for students and educators in videogame development, with openness and
accessibility in mind. The competition is based on an arbitrarily-sized version
of the Simplexity board game, the motto of which, ""simple to learn, complex to
master"", is curiously also applicable to AI agents. ColorShapeLinks offers
graphical and text-based frontends and a completely open and documented
development framework built using industry standard tools and following
software engineering best practices. ColorShapeLinks is not only a competition,
but both a game and a framework which educators and students can extend and use
to host their own competitions. It has been successfully used for running
internal competitions in AI classes, as well as for hosting an international AI
competition at the IEEE Conference on Games.",2020-12-16,2020,2020-12,education
The Last State of Artificial Intelligence in Project Management,"Artificial intelligence (AI) has been used to advance different fields, such
as education, healthcare, and finance. However, the application of AI in the
field of project management (PM) has not progressed equally. This paper reports
on a systematic review of the published studies used to investigate the
application of AI in PM. This systematic review identified relevant papers
using Web of Science, Science Direct, and Google Scholar databases. Of the 652
articles found, 58 met the predefined criteria and were included in the review.
Included papers were classified per the following dimensions: PM knowledge
areas, PM processes, and AI techniques. The results indicated that the
application of AI in PM was in its early stages and AI models have not applied
for multiple PM processes especially in processes groups of project stakeholder
management, project procurements management, and project communication
management. However, the most popular PM processes among included papers were
project effort prediction and cost estimation, and the most popular AI
techniques were support vector machines, neural networks, and genetic
algorithms.",2020-12-16,2020,2020-12,education
Towards Continual Reinforcement Learning: A Review and Perspectives,"In this article, we aim to provide a literature review of different
formulations and approaches to continual reinforcement learning (RL), also
known as lifelong or non-stationary RL. We begin by discussing our perspective
on why RL is a natural fit for studying continual learning. We then provide a
taxonomy of different continual RL formulations by mathematically
characterizing two key properties of non-stationarity, namely, the scope and
driver non-stationarity. This offers a unified view of various formulations.
Next, we review and present a taxonomy of continual RL approaches. We go on to
discuss evaluation of continual RL agents, providing an overview of benchmarks
used in the literature and important metrics for understanding agent
performance. Finally, we highlight open problems and challenges in bridging the
gap between the current state of continual RL and findings in neuroscience.
While still in its early days, the study of continual RL has the promise to
develop better incremental reinforcement learners that can function in
increasingly realistic applications where non-stationarity plays a vital role.
These include applications such as those in the fields of healthcare,
education, logistics, and robotics.",2020-12-25,2020,2020-12,education
Artificial Intelligence enabled Smart Learning,"Artificial Intelligence (AI) is a discipline of computer science that deals
with machine intelligence. It is essential to bring AI into the context of
learning because it helps in analysing the enormous amounts of data that is
collected from individual students, teachers and academic staff. The major
priorities of implementing AI in education are making innovative use of
existing digital technologies for learning, and teaching practices that
significantly improve traditional educational methods. The main problem with
traditional learning is that it cannot be suited to every student in class.
Some students may grasp the concepts well, while some may have difficulties in
understanding them and some may be more auditory or visual learners. The World
Bank report on education has indicated that the learning gap created by this
problem causes many students to drop out (World Development Report, 2018).
Personalised learning has been able to solve this grave problem.",2021-01-08,2021,2021-01,education
"An Empirical Comparison of Deep Learning Models for Knowledge Tracing on
  Large-Scale Dataset","Knowledge tracing (KT) is the problem of modeling each student's mastery of
knowledge concepts (KCs) as (s)he engages with a sequence of learning
activities. It is an active research area to help provide learners with
personalized feedback and materials. Various deep learning techniques have been
proposed for solving KT. Recent release of large-scale student performance
dataset \cite{choi2019ednet} motivates the analysis of performance of deep
learning approaches that have been proposed to solve KT. Our analysis can help
understand which method to adopt when large dataset related to student
performance is available. We also show that incorporating contextual
information such as relation between exercises and student forget behavior
further improves the performance of deep learning models.",2021-01-16,2021,2021-01,education
Personalized Education in the AI Era: What to Expect Next?,"The objective of personalized learning is to design an effective knowledge
acquisition track that matches the learner's strengths and bypasses her
weaknesses to ultimately meet her desired goal. This concept emerged several
years ago and is being adopted by a rapidly-growing number of educational
institutions around the globe. In recent years, the boost of artificial
intelligence (AI) and machine learning (ML), together with the advances in big
data analysis, has unfolded novel perspectives to enhance personalized
education in numerous dimensions. By taking advantage of AI/ML methods, the
educational platform precisely acquires the student's characteristics. This is
done, in part, by observing the past experiences as well as analyzing the
available big data through exploring the learners' features and similarities.
It can, for example, recommend the most appropriate content among numerous
accessible ones, advise a well-designed long-term curriculum, connect
appropriate learners by suggestion, accurate performance evaluation, and the
like. Still, several aspects of AI-based personalized education remain
unexplored. These include, among others, compensating for the adverse effects
of the absence of peers, creating and maintaining motivations for learning,
increasing diversity, removing the biases induced by the data and algorithms,
and the like. In this paper, while providing a brief review of state-of-the-art
research, we investigate the challenges of AI/ML-based personalized education
and discuss potential solutions.",2021-01-19,2021,2021-01,education
"Creation and Evaluation of a Pre-tertiary Artificial Intelligence (AI)
  Curriculum","Contributions: The Chinese University of Hong Kong (CUHK)-Jockey Club AI for
the Future Project (AI4Future) co-created an AI curriculum for pre-tertiary
education and evaluated its efficacy. While AI is conventionally taught in
tertiary level education, our co-creation process successfully developed the
curriculum that has been used in secondary school teaching in Hong Kong and
received positive feedback. Background: AI4Future is a cross-sector project
that engages five major partners - CUHK Faculty of Engineering and Faculty of
Education, Hong Kong secondary schools, the government and the AI industry. A
team of 14 professors with expertise in engineering and education collaborated
with 17 principals and teachers from 6 secondary schools to co-create the
curriculum. This team formation bridges the gap between researchers in
engineering and education, together with practitioners in education context.
Research Questions: What are the main features of the curriculum content
developed through the co-creation process? Would the curriculum significantly
improve the students perceived competence in, as well as attitude and
motivation towards AI? What are the teachers perceptions of the co-creation
process that aims to accommodate and foster teacher autonomy? Methodology: This
study adopted a mix of quantitative and qualitative methods and involved 335
student participants. Findings: 1) two main features of learning resources, 2)
the students perceived greater competence, and developed more positive attitude
to learn AI, and 3) the co-creation process generated a variety of resources
which enhanced the teachers knowledge in AI, as well as fostered teachers
autonomy in bringing the subject matter into their classrooms.",2021-01-19,2021,2021-01,education
Do we need to go Deep? Knowledge Tracing with Big Data,"Interactive Educational Systems (IES) enabled researchers to trace student
knowledge in different skills and provide recommendations for a better learning
path. To estimate the student knowledge and further predict their future
performance, the interest in utilizing the student interaction data captured by
IES to develop learner performance models is increasing rapidly. Moreover, with
the advances in computing systems, the amount of data captured by these IES
systems is also increasing that enables deep learning models to compete with
traditional logistic models and Markov processes. However, it is still not
empirically evident if these deep models outperform traditional models on the
current scale of datasets with millions of student interactions. In this work,
we adopt EdNet, the largest student interaction dataset publicly available in
the education domain, to understand how accurately both deep and traditional
models predict future student performances. Our work observes that logistic
regression models with carefully engineered features outperformed deep models
from extensive experimentation. We follow this analysis with interpretation
studies based on Locally Interpretable Model-agnostic Explanation (LIME) to
understand the impact of various features on best performing model
pre-dictions.",2021-01-20,2021,2021-01,education
"Evolution of artificial intelligence languages, a systematic literature
  review","The field of Artificial Intelligence (AI) has undoubtedly received
significant attention in recent years. AI is being adopted to provide solutions
to problems in fields such as medicine, engineering, education, government and
several other domains. In order to analyze the state of the art of research in
the field of AI, we present a systematic literature review focusing on the
Evolution of AI programming languages. We followed the systematic literature
review method by searching relevant databases like SCOPUS, IEEE Xplore and
Google Scholar. EndNote reference manager was used to catalog the relevant
extracted papers. Our search returned a total of 6565 documents, whereof 69
studies were retained. Of the 69 retained studies, 15 documents discussed LISP
programming language, another 34 discussed PROLOG programming language, the
remaining 20 documents were spread between Logic and Object Oriented
Programming (LOOP), ARCHLOG, Epistemic Ontology Language with Constraints
(EOLC), Python, C++, ADA and JAVA programming languages. This review provides
information on the year of implementation, development team, capabilities,
limitations and applications of each of the AI programming languages discussed.
The information in this review could guide practitioners and researchers in AI
to make the right choice of languages to implement their novel AI methods.",2021-01-27,2021,2021-01,education
MUSE: Multi-Scale Temporal Features Evolution for Knowledge Tracing,"Transformer based knowledge tracing model is an extensively studied problem
in the field of computer-aided education. By integrating temporal features into
the encoder-decoder structure, transformers can processes the exercise
information and student response information in a natural way. However, current
state-of-the-art transformer-based variants still share two limitations. First,
extremely long temporal features cannot well handled as the complexity of
self-attention mechanism is O(n2). Second, existing approaches track the
knowledge drifts under fixed a window size, without considering different
temporal-ranges. To conquer these problems, we propose MUSE, which is equipped
with multi-scale temporal sensor unit, that takes either local or global
temporal features into consideration. The proposed model is capable to capture
the dynamic changes in users knowledge states at different temporal-ranges, and
provides an efficient and powerful way to combine local and global features to
make predictions. Our method won the 5-th place over 3,395 teams in the Riiid
AIEd Challenge 2020.",2021-01-30,2021,2021-01,education
"Student sentiment Analysis Using Classification With Feature Extraction
  Techniques","Technical growths have empowered, numerous revolutions in the educational
system by acquainting with technology into the classroom and by elevating the
learning experience. Nowadays Web-based learning is getting much popularity.
This paper describes the web-based learning and their effectiveness towards
students. One of the prime factors in education or learning system is feedback;
it is beneficial to learning if it must be used effectively. In this paper, we
worked on how machine learning techniques like Logistic Regression (LR),
Support Vector Machine (SVM), Naive Bayes (NB), Decision Tree (DT) can be
applied over Web-based learning, emphasis given on sentiment present in the
feedback students. We also work on two types of Feature Extraction Technique
(FETs) namely Count Vector (CVr) or Bag of Words) (BoW) and Term Frequency and
Inverse Document Frequency (TF-IDF) Vector. In the research study, it is our
goal for our proposed LR, SVM, NB, and DT models to classify the presence of
Student Feedback Dataset (SFB) with improved accuracy with cleaned dataset and
feature extraction techniques. The SFB is one of the significant concerns among
the student sentimental analysis.",2021-02-01,2021,2021-02,education
"""Alexa, Can I Program You?"": Student Perceptions of Conversational
  Artificial Intelligence Before and After Programming Alexa","Growing up in an artificial intelligence-filled world, with Siri and Amazon
Alexa often within arm's - or speech's - reach, could have significant impact
on children. Conversational agents could influence how students
anthropomorphize computer systems or develop a theory of mind. Previous
research has explored how conversational agents are used and perceived by
children within and outside of learning contexts. This study investigates how
middle and high school students' perceptions of Alexa change through
programming their own conversational agents in week-long AI education
workshops. Specifically, we investigate the workshops' influence on student
perceptions of Alexa's intelligence, friendliness, aliveness, safeness,
trustworthiness, human-likeness, and feelings of closeness. We found that
students felt Alexa was more intelligent and felt closer to Alexa after the
workshops. We also found strong correlations between students' perceptions of
Alexa's friendliness and trustworthiness, and safeness and trustworthiness.
Finally, we explored how students tended to more frequently use computer
science-related diction and ideas after the workshops. Based on our findings,
we recommend designers carefully consider personification, transparency,
playfulness and utility when designing CAs for learning contexts.",2021-02-02,2021,2021-02,education
"Artificial Intelligence Technologies in Education: Benefits, Challenges
  and Strategies of Implementation","Since the education sector is associated with highly dynamic business
environments which are controlled and maintained by information systems, recent
technological advancements and the increasing pace of adopting artificial
intelligence (AI) technologies constitute a need to identify and analyze the
issues regarding their implementation in education sector. However, a study of
the contemporary literature reveled that relatively little research has been
undertaken in this area. To fill this void, we have identified the benefits and
challenges of implementing artificial intelligence in the education sector,
preceded by a short discussion on the concepts of AI and its evolution over
time. Moreover, we have also reviewed modern AI technologies for learners and
educators, currently available on the software market, evaluating their
usefulness. Last but not least, we have developed a strategy implementation
model, described by a five-stage, generic process, along with the corresponding
configuration guide. To verify and validate their design, we separately
developed three implementation strategies for three different higher education
organizations. We believe that the obtained results will contribute to better
understanding the specificities of AI systems, services and tools, and
afterwards pave a smooth way in their implementation.",2021-02-11,2021,2021-02,education
Engineering Education in the Age of Autonomous Machines,"In the past few years, we have observed a huge supply-demand gap for
autonomous driving engineers. The core problem is that autonomous driving is
not one single technology but rather a complex system integrating many
technologies, and no one single academic department can provide comprehensive
education in this field. We advocate to create a cross-disciplinary program to
expose students with technical background in computer science, computer
engineering, electrical engineering, as well as mechanical engineering. On top
of the cross-disciplinary technical foundation, a capstone project that
provides students with hands-on experiences of working with a real autonomous
vehicle is required to consolidate the technical foundation.",2021-02-16,2021,2021-02,education
"Testing Lotka's Law and Pattern of Author Productivity in the Scholarly
  Publications of Artificial Intelligence","Artificial intelligence has changed our day to day life in multitude ways. AI
technology is rearing itself as a driving force to be reckoned with in the
largest industries in the world. AI has already engulfed our educational
system, our businesses and our financial establishments. The future is definite
that machines with artificial intelligence will soon be captivating over
trained manual work that now is mostly cared by humans. Machines can carry out
human-like tasks by new inputs as artificial intelligence makes it possible for
machines to learn from experience. AI data from web of science database from
2008 to 2017 have been mapped to depict the average growth rate, relative
growth rate, contribution made by authors in the view of research productivity,
authorship pattern and collaboration of AI literature. The Lotka's law on
authorship productivity of AI literature has been tested to confirm the
applicability of the law to the present data set. A K-S test was applied to
measure the degree of agreement between the distribution of the observed set of
data against the inverse general power relationship and the theoretical value
of {\alpha} =2. It is found that the inverse square law of Lotka follow as
such.",2021-02-18,2021,2021-02,education
"Low-level cognitive skill transfer between two individuals' minds via
  computer game-based framework","The novel technique introduced here aims to accomplish the first stage of
transferring low-level cognitive skills between two individuals (e.g. from
expert to learner) to ease the consecutive higher level declarative learning
process for the target ""learner"" individual in a game environment. Such
low-level cognitive skill is associated with the procedural knowledge and
established at low-level of mind which can be unveiled and transferred by only
a novel technique (rather than by a traditional educational environment ) like
a highly interactive computer game domain in which a user exposes his/her
unconscious mind behaviors via the game-hero non-deliberately during the game
sessions. The cognitive data exposed by the game-hero would be recorded, and
then be modelled by the artificial intelligence technique like Bayesian
networks for an early stage of cognitive skill transfer and the cognitive
stimuli are also generated to be used as game agents to train the learner.",2021-03-03,2021,2021-03,education
"Monte Carlo Tree Search: A Review of Recent Modifications and
  Applications","Monte Carlo Tree Search (MCTS) is a powerful approach to designing
game-playing bots or solving sequential decision problems. The method relies on
intelligent tree search that balances exploration and exploitation. MCTS
performs random sampling in the form of simulations and stores statistics of
actions to make more educated choices in each subsequent iteration. The method
has become a state-of-the-art technique for combinatorial games, however, in
more complex games (e.g. those with high branching factor or real-time ones),
as well as in various practical domains (e.g. transportation, scheduling or
security) an efficient MCTS application often requires its problem-dependent
modification or integration with other techniques. Such domain-specific
modifications and hybrid approaches are the main focus of this survey. The last
major MCTS survey has been published in 2012. Contributions that appeared since
its release are of particular interest for this review.",2021-03-08,2021,2021-03,education
AIR4Children: Artificial Intelligence and Robotics for Children,"We introduce AIR4Children, Artificial Intelligence for Children, as a way to
(a) tackle aspects for inclusion, accessibility, transparency, equity, fairness
and participation and (b) to create affordable child-centred materials in AI
and Robotics (AIR). We present current challenges and opportunities for a
child-centred approaches for AIR. Similarly, we touch on open-sourced software
and hardware technologies to make a more inclusive, affordable and fair
participation of children in areas of AIR. Then, we describe the avenues that
AIR4Children can take with the development of open-sourced software and
hardware based on our initial pilots and experiences. Similarly, we propose to
follow the philosophy of Montessori education to help children to not only
develop computational thinking but also to internalise new concepts and
learning skills through activities of movement and repetition. Finally, we
conclude with the opportunities of our work and mainly we pose the future work
of putting in practice what is proposed here to evaluate the potential impact
on AIR to children, instructors, parents and their community.",2021-03-13,2021,2021-03,education
Lessons Learned from Educating AI Engineers,"Over the past three years we have built a practice-oriented, bachelor level,
educational programme for software engineers to specialize as AI engineers. The
experience with this programme and the practical assignments our students
execute in industry has given us valuable insights on the profession of AI
engineer. In this paper we discuss our programme and the lessons learned for
industry and research.",2021-03-19,2021,2021-03,education
Designing for human-AI complementarity in K-12 education,"Recent work has explored how complementary strengths of humans and artificial
intelligence (AI) systems might be productively combined. However, successful
forms of human-AI partnership have rarely been demonstrated in real-world
settings. We present the iterative design and evaluation of Lumilo, smart
glasses that help teachers help their students in AI-supported classrooms by
presenting real-time analytics about students' learning, metacognition, and
behavior. Results from a field study conducted in K-12 classrooms indicate that
students learn more when teachers and AI tutors work together during class. We
discuss implications of this research for the design of human-AI partnerships.
We argue for more participatory approaches to research and design in this area,
in which practitioners and other stakeholders are deeply, meaningfully involved
throughout the process. Furthermore, we advocate for theory-building and for
principled approaches to the study of human-AI decision-making in real-world
contexts.",2021-04-02,2021,2021-04,education
A Framework for Ethical AI at the United Nations,"This paper aims to provide an overview of the ethical concerns in artificial
intelligence (AI) and the framework that is needed to mitigate those risks, and
to suggest a practical path to ensure the development and use of AI at the
United Nations (UN) aligns with our ethical values. The overview discusses how
AI is an increasingly powerful tool with potential for good, albeit one with a
high risk of negative side-effects that go against fundamental human rights and
UN values. It explains the need for ethical principles for AI aligned with
principles for data governance, as data and AI are tightly interwoven. It
explores different ethical frameworks that exist and tools such as assessment
lists. It recommends that the UN develop a framework consisting of ethical
principles, architectural standards, assessment methods, tools and
methodologies, and a policy to govern the implementation and adherence to this
framework, accompanied by an education program for staff.",2021-04-09,2021,2021-04,education
Accelerating science with human versus alien artificial intelligences,"Data-driven artificial intelligence models fed with published scientific
findings have been used to create powerful prediction engines for scientific
and technological advance, such as the discovery of novel materials with
desired properties and the targeted invention of new therapies and vaccines.
These AI approaches typically ignore the distribution of human prediction
engines -- scientists and inventor -- who continuously alter the landscape of
discovery and invention. As a result, AI hypotheses are designed to substitute
for human experts, failing to complement them for punctuated collective
advance. Here we show that incorporating the distribution of human expertise
into self-supervised models by training on inferences cognitively available to
experts dramatically improves AI prediction of future human discoveries and
inventions. Including expert-awareness into models that propose (a) valuable
energy-relevant materials increases the precision of materials predictions by
~100%, (b) repurposing thousands of drugs to treat new diseases increases
precision by 43%, and (c) COVID-19 vaccine candidates examined in clinical
trials by 260%. These models succeed by predicting human predictions and the
scientists who will make them. By tuning AI to avoid the crowd, however, it
generates scientifically promising ""alien"" hypotheses unlikely to be imagined
or pursued without intervention, not only accelerating but punctuating
scientific advance. By identifying and correcting for collective human bias,
these models also suggest opportunities to improve human prediction by
reformulating science education for discovery.",2021-04-12,2021,2021-04,education
"Classifications of the Summative Assessment for Revised Blooms Taxonomy
  by using Deep Learning","Education is the basic step of understanding the truth and the preparation of
the intelligence to reflect. Focused on the rational capacity of the human
being the Cognitive process and knowledge dimensions of Revised Blooms Taxonomy
helps to differentiate the procedure of studying into six types of various
cognitive processes and four types of knowledge dimensions. These types are
synchronized in the increasing level of difficulty. In this paper Software
Engineering courses of B.Tech Computer Engineering and Information Technology
offered by various Universities and Educational Institutes have been
investigated for Revised Blooms Taxonomy RBT. Questions are a very useful
constituent. Knowledge intelligence and strength of the learners can be tested
by applying questions.The fundamental goal of this paper is to create a
relative study of the classification of the summative assessment based on
Revised Blooms Taxonomy using the Convolutional Neural Networks CNN Long
Short-Term Memory LSTM of Deep Learning techniques in an endeavor to attain
significant accomplishment and elevated precision levels.",2021-04-18,2021,2021-04,education
"Equity and Artificial Intelligence in Education: Will ""AIEd"" Amplify or
  Alleviate Inequities in Education?","The development of educational AI (AIEd) systems has often been motivated by
their potential to promote educational equity and reduce achievement gaps
across different groups of learners -- for example, by scaling up the benefits
of one-on-one human tutoring to a broader audience, or by filling gaps in
existing educational services. Given these noble intentions, why might AIEd
systems have inequitable impacts in practice? In this chapter, we discuss four
lenses that can be used to examine how and why AIEd systems risk amplifying
existing inequities. Building from these lenses, we then outline possible paths
towards more equitable futures for AIEd, while highlighting debates surrounding
each proposal. In doing so, we hope to provoke new conversations around the
design of equitable AIEd, and to push ongoing conversations in the field
forward.",2021-04-27,2021,2021-04,education
Towards Equity and Algorithmic Fairness in Student Grade Prediction,"Equity of educational outcome and fairness of AI with respect to race have
been topics of increasing importance in education. In this work, we address
both with empirical evaluations of grade prediction in higher education, an
important task to improve curriculum design, plan interventions for academic
support, and offer course guidance to students. With fairness as the aim, we
trial several strategies for both label and instance balancing to attempt to
minimize differences in algorithm performance with respect to race. We find
that an adversarial learning approach, combined with grade label balancing,
achieved by far the fairest results. With equity of educational outcome as the
aim, we trial strategies for boosting predictive performance on historically
underserved groups and find success in sampling those groups in inverse
proportion to their historic outcomes. With AI-infused technology supports
increasingly prevalent on campuses, our methodologies fill a need for
frameworks to consider performance trade-offs with respect to sensitive student
attributes and allow institutions to instrument their AI resources in ways that
are attentive to equity and fairness.",2021-05-14,2021,2021-05,education
Modeling the EdNet Dataset with Logistic Regression,"Many of these challenges are won by neural network models created by
full-time artificial intelligence scientists. Due to this origin, they have a
black-box character that makes their use and application less clear to learning
scientists. We describe our experience with competition from the perspective of
educational data mining, a field founded in the learning sciences and connected
with roots in psychology and statistics. We describe our efforts from the
perspectives of learning scientists and the challenges to our methods, some
real and some imagined. We also discuss some basic results in the Kaggle system
and our thoughts on how those results may have been improved. Finally, we
describe how learner model predictions are used to make pedagogical decisions
for students. Their practical use entails a) model predictions and b) a
decision rule (based on the predictions). We point out how increased model
accuracy can be of limited practical utility, especially when paired with
simple decision rules and argue instead for the need to further investigate
optimal decision rules.",2021-05-17,2021,2021-05,education
"Beyond ""Fairness:"" Structural (In)justice Lenses on AI for Education","Educational technologies, and the systems of schooling in which they are
deployed, enact particular ideologies about what is important to know and how
learners should learn. As artificial intelligence technologies -- in education
and beyond -- may contribute to inequitable outcomes for marginalized
communities, various approaches have been developed to evaluate and mitigate
the harmful impacts of AI. However, we argue in this paper that the dominant
paradigm of evaluating fairness on the basis of performance disparities in AI
models is inadequate for confronting the systemic inequities that educational
AI systems (re)produce. We draw on a lens of structural injustice informed by
critical theory and Black feminist scholarship to critically interrogate
several widely-studied and widely-adopted categories of educational AI and
explore how they are bound up in and reproduce historical legacies of
structural injustice and inequity, regardless of the parity of their models'
performance. We close with alternative visions for a more equitable future for
educational AI.",2021-05-18,2021,2021-05,education
Classifying Math KCs via Task-Adaptive Pre-Trained BERT,"Educational content labeled with proper knowledge components (KCs) are
particularly useful to teachers or content organizers. However, manually
labeling educational content is labor intensive and error-prone. To address
this challenge, prior research proposed machine learning based solutions to
auto-label educational content with limited success. In this work, we
significantly improve prior research by (1) expanding the input types to
include KC descriptions, instructional video titles, and problem descriptions
(i.e., three types of prediction task), (2) doubling the granularity of the
prediction from 198 to 385 KC labels (i.e., more practical setting but much
harder multinomial classification problem), (3) improving the prediction
accuracies by 0.5-2.3% using Task-adaptive Pre-trained BERT, outperforming six
baselines, and (4) proposing a simple evaluation measure by which we can
recover 56-73% of mispredicted KC labels. All codes and data sets in the
experiments are available at:https://github.com/tbs17/TAPT-BERT",2021-05-24,2021,2021-05,education
Towards Teachable Autotelic Agents,"Autonomous discovery and direct instruction are two distinct sources of
learning in children but education sciences demonstrate that mixed approaches
such as assisted discovery or guided play result in improved skill acquisition.
In the field of Artificial Intelligence, these extremes respectively map to
autonomous agents learning from their own signals and interactive learning
agents fully taught by their teachers. In between should stand teachable
autotelic agents (TAA): agents that learn from both internal and teaching
signals to benefit from the higher efficiency of assisted discovery. Designing
such agents will enable real-world non-expert users to orient the learning
trajectories of agents towards their expectations. More fundamentally, this may
also be a key step to build agents with human-level intelligence. This paper
presents a roadmap towards the design of teachable autonomous agents. Building
on developmental psychology and education sciences, we start by identifying key
features enabling assisted discovery processes in child-tutor interactions.
This leads to the production of a checklist of features that future TAA will
need to demonstrate. The checklist allows us to precisely pinpoint the various
limitations of current reinforcement learning agents and to identify the
promising first steps towards TAA. It also shows the way forward by
highlighting key research directions towards the design or autonomous agents
that can be taught by ordinary people via natural pedagogy.",2021-05-25,2021,2021-05,education
"Automating Visualization Quality Assessment: a Case Study in Higher
  Education","We present a case study in the use of machine+human mixed intelligence for
visualization quality assessment, applying automated visualization quality
metrics to support the human assessment of data visualizations produced as
coursework by students taking higher education courses. A set of image
informatics algorithms including edge congestion, visual saliency and colour
analysis generate machine analysis of student visualizations. The insight from
the image informatics outputs has proved helpful for the marker in assessing
the work and is also provided to the students as part of a written report on
their work. Student and external reviewer comments suggest that the addition of
the image informatics outputs to the standard feedback document was a positive
step. We review the ethical challenges of working with assessment data and of
automating assessment processes.",2021-05-31,2021,2021-05,education
"Teaching Machine Learning in K-12 Computing Education: Potential and
  Pitfalls","Over the past decades, numerous practical applications of machine learning
techniques have shown the potential of data-driven approaches in a large number
of computing fields. Machine learning is increasingly included in computing
curricula in higher education, and a quickly growing number of initiatives are
expanding it in K-12 computing education, too. As machine learning enters K-12
computing education, understanding how intuition and agency in the context of
such systems is developed becomes a key research area. But as schools and
teachers are already struggling with integrating traditional computational
thinking and traditional artificial intelligence into school curricula,
understanding the challenges behind teaching machine learning in K-12 is an
even more daunting challenge for computing education research. Despite the
central position of machine learning in the field of modern computing, the
computing education research body of literature contains remarkably few studies
of how people learn to train, test, improve, and deploy machine learning
systems. This is especially true of the K-12 curriculum space. This article
charts the emerging trajectories in educational practice, theory, and
technology related to teaching machine learning in K-12 education. The article
situates the existing work in the context of computing education in general,
and describes some differences that K-12 computing educators should take into
account when facing this challenge. The article focuses on key aspects of the
paradigm shift that will be required in order to successfully integrate machine
learning into the broader K-12 computing curricula. A crucial step is
abandoning the belief that rule-based ""traditional"" programming is a central
aspect and building block in developing next generation computational thinking.",2021-06-02,2021,2021-06,education
"Uncertainty Quantification 360: A Holistic Toolkit for Quantifying and
  Communicating the Uncertainty of AI","In this paper, we describe an open source Python toolkit named Uncertainty
Quantification 360 (UQ360) for the uncertainty quantification of AI models. The
goal of this toolkit is twofold: first, to provide a broad range of
capabilities to streamline as well as foster the common practices of
quantifying, evaluating, improving, and communicating uncertainty in the AI
application development lifecycle; second, to encourage further exploration of
UQ's connections to other pillars of trustworthy AI such as fairness and
transparency through the dissemination of latest research and education
materials. Beyond the Python package (\url{https://github.com/IBM/UQ360}), we
have developed an interactive experience (\url{http://uq360.mybluemix.net}) and
guidance materials as educational tools to aid researchers and developers in
producing and communicating high-quality uncertainties in an effective manner.",2021-06-02,2021,2021-06,education
Towards Fairness Certification in Artificial Intelligence,"Thanks to the great progress of machine learning in the last years, several
Artificial Intelligence (AI) techniques have been increasingly moving from the
controlled research laboratory settings to our everyday life. AI is clearly
supportive in many decision-making scenarios, but when it comes to sensitive
areas such as health care, hiring policies, education, banking or justice, with
major impact on individuals and society, it becomes crucial to establish
guidelines on how to design, develop, deploy and monitor this technology.
Indeed the decision rules elaborated by machine learning models are data-driven
and there are multiple ways in which discriminatory biases can seep into data.
Algorithms trained on those data incur the risk of amplifying prejudices and
societal stereotypes by over associating protected attributes such as gender,
ethnicity or disabilities with the prediction task. Starting from the extensive
experience of the National Metrology Institute on measurement standards and
certification roadmaps, and of Politecnico di Torino on machine learning as
well as methods for domain bias evaluation and mastering, we propose a first
joint effort to define the operational steps needed for AI fairness
certification. Specifically we will overview the criteria that should be met by
an AI system before coming into official service and the conformity assessment
procedures useful to monitor its functioning for fair decisions.",2021-06-04,2021,2021-06,education
Question Generation for Adaptive Education,"Intelligent and adaptive online education systems aim to make high-quality
education available for a diverse range of students. However, existing systems
usually depend on a pool of hand-made questions, limiting how fine-grained and
open-ended they can be in adapting to individual students. We explore targeted
question generation as a controllable sequence generation task. We first show
how to fine-tune pre-trained language models for deep knowledge tracing
(LM-KT). This model accurately predicts the probability of a student answering
a question correctly, and generalizes to questions not seen in training. We
then use LM-KT to specify the objective and data for training a model to
generate questions conditioned on the student and target difficulty. Our
results show we succeed at generating novel, well-calibrated language
translation questions for second language learners from a real online education
platform.",2021-06-08,2021,2021-06,education
Building Bridges: Generative Artworks to Explore AI Ethics,"In recent years, there has been an increased emphasis on understanding and
mitigating adverse impacts of artificial intelligence (AI) technologies on
society. Across academia, industry, and government bodies, a variety of
endeavours are being pursued towards enhancing AI ethics. A significant
challenge in the design of ethical AI systems is that there are multiple
stakeholders in the AI pipeline, each with their own set of constraints and
interests. These different perspectives are often not understood, due in part
to communication gaps.For example, AI researchers who design and develop AI
models are not necessarily aware of the instability induced in consumers' lives
by the compounded effects of AI decisions. Educating different stakeholders
about their roles and responsibilities in the broader context becomes
necessary. In this position paper, we outline some potential ways in which
generative artworks can play this role by serving as accessible and powerful
educational tools for surfacing different perspectives. We hope to spark
interdisciplinary discussions about computational creativity broadly as a tool
for enhancing AI ethics.",2021-06-25,2021,2021-06,education
"Evaluation of Automated Image Descriptions for Visually Impaired
  Students","Illustrations are widely used in education, and sometimes, alternatives are
not available for visually impaired students. Therefore, those students would
benefit greatly from an automatic illustration description system, but only if
those descriptions were complete, correct, and easily understandable using a
screenreader. In this paper, we report on a study for the assessment of
automated image descriptions. We interviewed experts to establish evaluation
criteria, which we then used to create an evaluation questionnaire for sighted
non-expert raters, and description templates. We used this questionnaire to
evaluate the quality of descriptions which could be generated with a
template-based automatic image describer. We present evidence that these
templates have the potential to generate useful descriptions, and that the
questionnaire identifies problems with description templates.",2021-06-29,2021,2021-06,education
"RoboCup@Home Education 2020 Best Performance: RoboBreizh, a modular
  approach","Every year, the Robocup@Home competition challenges teams and robots'
abilities. In 2020, the RoboCup@Home Education challenge was organized online,
altering the usual competition rules. In this paper, we present the latest
developments that lead the RoboBreizh team to win the contest. These
developments include several modules linked to each other allowing the Pepper
robot to understand, act and adapt itself to a local environment. Up-to-date
available technologies have been used for navigation and dialogue. First
contribution includes combining object detection and pose estimation techniques
to detect user's intention. Second contribution involves using Learning by
Demonstrations to easily learn new movements that improve the Pepper robot's
skills. This proposal won the best performance award of the 2020 RoboCup@Home
Education challenge.",2021-07-07,2021,2021-07,education
"A Classification of Artificial Intelligence Systems for Mathematics
  Education","This chapter provides an overview of the different Artificial Intelligence
(AI) systems that are being used in contemporary digital tools for Mathematics
Education (ME). It is aimed at researchers in AI and Machine Learning (ML), for
whom we shed some light on the specific technologies that are being used in
educational applications; and at researchers in ME, for whom we clarify: i)
what the possibilities of the current AI technologies are, ii) what is still
out of reach and iii) what is to be expected in the near future. We start our
analysis by establishing a high-level taxonomy of AI tools that are found as
components in digital ME applications. Then, we describe in detail how these AI
tools, and in particular ML, are being used in two key applications,
specifically AI-based calculators and intelligent tutoring systems. We finish
the chapter with a discussion about student modeling systems and their
relationship to artificial general intelligence.",2021-07-13,2021,2021-07,education
Reinforcement Learning for Education: Opportunities and Challenges,"This survey article has grown out of the RL4ED workshop organized by the
authors at the Educational Data Mining (EDM) 2021 conference. We organized this
workshop as part of a community-building effort to bring together researchers
and practitioners interested in the broad areas of reinforcement learning (RL)
and education (ED). This article aims to provide an overview of the workshop
activities and summarize the main research directions in the area of RL for ED.",2021-07-15,2021,2021-07,education
"An Educational System for Personalized Teacher Recommendation in K-12
  Online Classrooms","In this paper, we propose a simple yet effective solution to build practical
teacher recommender systems for online one-on-one classes. Our system consists
of (1) a pseudo matching score module that provides reliable training labels;
(2) a ranking model that scores every candidate teacher; (3) a novelty boosting
module that gives additional opportunities to new teachers; and (4) a diversity
metric that guardrails the recommended results to reduce the chance of
collision. Offline experimental results show that our approach outperforms a
wide range of baselines. Furthermore, we show that our approach is able to
reduce the number of student-teacher matching attempts from 7.22 to 3.09 in a
five-month observation on a third-party online education platform.",2021-07-15,2021,2021-07,education
"Multi-Task Learning based Online Dialogic Instruction Detection with
  Pre-trained Language Models","In this work, we study computational approaches to detect online dialogic
instructions, which are widely used to help students understand learning
materials, and build effective study habits. This task is rather challenging
due to the widely-varying quality and pedagogical styles of dialogic
instructions. To address these challenges, we utilize pre-trained language
models, and propose a multi-task paradigm which enhances the ability to
distinguish instances of different classes by enlarging the margin between
categories via contrastive loss. Furthermore, we design a strategy to fully
exploit the misclassified examples during the training stage. Extensive
experiments on a real-world online educational data set demonstrate that our
approach achieves superior performance compared to representative baselines. To
encourage reproducible results, we make our implementation online available at
\url{https://github.com/AIED2021/multitask-dialogic-instruction}.",2021-07-15,2021,2021-07,education
"Automatic Task Requirements Writing Evaluation via Machine Reading
  Comprehension","Task requirements (TRs) writing is an important question type in Key English
Test and Preliminary English Test. A TR writing question may include multiple
requirements and a high-quality essay must respond to each requirement
thoroughly and accurately. However, the limited teacher resources prevent
students from getting detailed grading instantly. The majority of existing
automatic essay scoring systems focus on giving a holistic score but rarely
provide reasons to support it. In this paper, we proposed an end-to-end
framework based on machine reading comprehension (MRC) to address this problem
to some extent. The framework not only detects whether an essay responds to a
requirement question, but clearly marks where the essay answers the question.
Our framework consists of three modules: question normalization module, ELECTRA
based MRC module and response locating module. We extensively explore
state-of-the-art MRC methods. Our approach achieves 0.93 accuracy score and
0.85 F1 score on a real-world educational dataset. To encourage reproducible
results, we make our code publicly available at
\url{https://github.com/aied2021TRMRC/AIED_2021_TRMRC_code}.",2021-07-15,2021,2021-07,education
"Solving ESL Sentence Completion Questions via Pre-trained Neural
  Language Models","Sentence completion (SC) questions present a sentence with one or more blanks
that need to be filled in, three to five possible words or phrases as options.
SC questions are widely used for students learning English as a Second Language
(ESL) and building computational approaches to automatically solve such
questions is beneficial to language learners. In this work, we propose a neural
framework to solve SC questions in English examinations by utilizing
pre-trained language models. We conduct extensive experiments on a real-world
K-12 ESL SC question dataset and the results demonstrate the superiority of our
model in terms of prediction accuracy. Furthermore, we run precision-recall
trade-off analysis to discuss the practical issues when deploying it in
real-life scenarios. To encourage reproducible results, we make our code
publicly available at \url{https://github.com/AIED2021/ESL-SentenceCompletion}.",2021-07-15,2021,2021-07,education
"A Multimodal Machine Learning Framework for Teacher Vocal Delivery
  Evaluation","The quality of vocal delivery is one of the key indicators for evaluating
teacher enthusiasm, which has been widely accepted to be connected to the
overall course qualities. However, existing evaluation for vocal delivery is
mainly conducted with manual ratings, which faces two core challenges:
subjectivity and time-consuming. In this paper, we present a novel machine
learning approach that utilizes pairwise comparisons and a multimodal
orthogonal fusing algorithm to generate large-scale objective evaluation
results of the teacher vocal delivery in terms of fluency and passion. We
collect two datasets from real-world education scenarios and the experiment
results demonstrate the effectiveness of our algorithm. To encourage
reproducible results, we make our code public available at
\url{https://github.com/tal-ai/ML4VocalDelivery.git}.",2021-07-15,2021,2021-07,education
"Accuracy analysis of Educational Data Mining using Feature Selection
  Algorithm","Gathering relevant information to predict student academic progress is a
tedious task. Due to the large amount of irrelevant data present in databases
which provides inaccurate results. Currently, it is not possible to accurately
measure and analyze student data because there are too many irrelevant
attributes and features in the data. With the help of Educational Data Mining
(EDM), the quality of information can be improved. This research demonstrates
how EDM helps to measure the accuracy of data using relevant attributes and
machine learning algorithms performed. With EDM, irrelevant features are
removed without changing the original data. The data set used in this study was
taken from Kaggle.com. The results compared on the basis of recall, precision
and f-measure to check the accuracy of the student data. The importance of this
research is to help improve the quality of educational research by providing
more accurate results for researchers.",2021-07-21,2021,2021-07,education
"Developing Open Source Educational Resources for Machine Learning and
  Data Science","Education should not be a privilege but a common good. It should be openly
accessible to everyone, with as few barriers as possible; even more so for key
technologies such as Machine Learning (ML) and Data Science (DS). Open
Educational Resources (OER) are a crucial factor for greater educational
equity. In this paper, we describe the specific requirements for OER in ML and
DS and argue that it is especially important for these fields to make source
files publicly available, leading to Open Source Educational Resources (OSER).
We present our view on the collaborative development of OSER, the challenges
this poses, and first steps towards their solutions. We outline how OSER can be
used for blended learning scenarios and share our experiences in university
education. Finally, we discuss additional challenges such as credit assignment
or granting certificates.",2021-07-28,2021,2021-07,education
Demonstrating REACT: a Real-time Educational AI-powered Classroom Tool,"We present a demonstration of REACT, a new Real-time Educational AI-powered
Classroom Tool that employs EDM techniques for supporting the decision-making
process of educators. REACT is a data-driven tool with a user-friendly
graphical interface. It analyzes students' performance data and provides
context-based alerts as well as recommendations to educators for course
planning. Furthermore, it incorporates model-agnostic explanations for bringing
explainability and interpretability in the process of decision making. This
paper demonstrates a use case scenario of our proposed tool using a real-world
dataset and presents the design of its architecture and user interface. This
demonstration focuses on the agglomerative clustering of students based on
their performance (i.e., incorrect responses and hints used) during an in-class
activity. This formation of clusters of students with similar strengths and
weaknesses may help educators to improve their course planning by identifying
at-risk students, forming study groups, or encouraging tutoring between
students of different strengths.",2021-07-30,2021,2021-07,education
"Towards Understanding the Impact of Real-Time AI-Powered Educational
  Dashboards (RAED) on Providing Guidance to Instructors","The objectives of this ongoing research are to build Real-Time AI-Powered
Educational Dashboard (RAED) as a decision support tool for instructors, and to
measure its impact on them while making decisions. Current developments in AI
can be combined with the educational dashboards to make them AI-Powered. Thus,
AI can help in providing recommendations based on the students' performances.
AI-Powered educational dashboards can also assist instructors in tracking
real-time student activities. In this ongoing research, our aim is to develop
the AI component as well as improve the existing design component of the RAED.
Further, we will conduct experiments to study its impact on instructors, and
understand how much they trust RAED to guide them while making decisions. This
paper elaborates on the ongoing research and future direction.",2021-07-30,2021,2021-07,education
"Competency Model Approach to AI Literacy: Research-based Path from
  Initial Framework to Model","The recent developments in Artificial Intelligence (AI) technologies
challenge educators and educational institutions to respond with curriculum and
resources that prepare students of all ages with the foundational knowledge and
skills for success in the AI workplace. Research on AI Literacy could lead to
an effective and practical platform for developing these skills. We propose and
advocate for a pathway for developing AI Literacy as a pragmatic and useful
tool for AI education. Such a discipline requires moving beyond a conceptual
framework to a multi-level competency model with associated competency
assessments. This approach to an AI Literacy could guide future development of
instructional content as we prepare a range of groups (i.e., consumers,
co-workers, collaborators, and creators). We propose here a research matrix as
an initial step in the development of a roadmap for AI Literacy research, which
requires a systematic and coordinated effort with the support of publication
outlets and research funding, to expand the areas of competency and
assessments.",2021-08-12,2021,2021-08,education
"Readying Medical Students for Medical AI: The Need to Embed AI Ethics
  Education","Medical students will almost inevitably encounter powerful medical AI systems
early in their careers. Yet, contemporary medical education does not adequately
equip students with the basic clinical proficiency in medical AI needed to use
these tools safely and effectively. Education reform is urgently needed, but
not easily implemented, largely due to an already jam-packed medical curricula.
In this article, we propose an education reform framework as an effective and
efficient solution, which we call the Embedded AI Ethics Education Framework.
Unlike other calls for education reform to accommodate AI teaching that are
more radical in scope, our framework is modest and incremental. It leverages
existing bioethics or medical ethics curricula to develop and deliver content
on the ethical issues associated with medical AI, especially the harms of
technology misuse, disuse, and abuse that affect the risk-benefit analyses at
the heart of healthcare. In doing so, the framework provides a simple tool for
going beyond the ""What?"" and the ""Why?"" of medical AI ethics education, to
answer the ""How?"", giving universities, course directors, and/or professors a
broad road-map for equipping their students with the necessary clinical
proficiency in medical AI.",2021-09-07,2021,2021-09,education
"It is AI's Turn to Ask Humans a Question: Question-Answer Pair
  Generation for Children's Story Books","Existing question answering (QA) techniques are created mainly to answer
questions asked by humans. But in educational applications, teachers often need
to decide what questions they should ask, in order to help students to improve
their narrative understanding capabilities. We design an automated
question-answer generation (QAG) system for this education scenario: given a
story book at the kindergarten to eighth-grade level as input, our system can
automatically generate QA pairs that are capable of testing a variety of
dimensions of a student's comprehension skills. Our proposed QAG model
architecture is demonstrated using a new expert-annotated FairytaleQA dataset,
which has 278 child-friendly storybooks with 10,580 QA pairs. Automatic and
human evaluations show that our model outperforms state-of-the-art QAG baseline
systems. On top of our QAG system, we also start to build an interactive
story-telling application for the future real-world deployment in this
educational scenario.",2021-09-08,2021,2021-09,education
"College Student Retention Risk Analysis From Educational Database using
  Multi-Task Multi-Modal Neural Fusion","We develop a Multimodal Spatiotemporal Neural Fusion network for Multi-Task
Learning (MSNF-MTCL) to predict 5 important students' retention risks: future
dropout, next semester dropout, type of dropout, duration of dropout and cause
of dropout. First, we develop a general purpose multi-modal neural fusion
network model MSNF for learning students' academic information representation
by fusing spatial and temporal unstructured advising notes with spatiotemporal
structured data. MSNF combines a Bidirectional Encoder Representations from
Transformers (BERT)-based document embedding framework to represent each
advising note, Long-Short Term Memory (LSTM) network to model temporal advising
note embeddings, LSTM network to model students' temporal performance variables
and students' static demographics altogether. The final fused representation
from MSNF has been utilized on a Multi-Task Cascade Learning (MTCL) model
towards building MSNF-MTCL for predicting 5 student retention risks. We
evaluate MSNFMTCL on a large educational database consists of 36,445 college
students over 18 years period of time that provides promising performances
comparing with the nearest state-of-art models. Additionally, we test the
fairness of such model given the existence of biases.",2021-09-11,2021,2021-09,education
"Proceedings 37th International Conference on Logic Programming
  (Technical Communications)","ICLP is the premier international event for presenting research in logic
programming.
  Contributions to ICLP 2021 were sought in all areas of logic programming,
including but not limited to:
  Foundations: Semantics, Formalisms, Nonmonotonic reasoning, Knowledge
representation.
  Languages issues: Concurrency, Objects, Coordination, Mobility, Higher order,
Types, Modes, Assertions, Modules, Meta-programming, Logic-based
domain-specific languages, Programming techniques.
  Programming support: Program analysis, Transformation, Validation,
Verification, Debugging, Profiling, Testing, Execution visualization.
  Implementation: Compilation, Virtual machines, Memory management, Parallel
and Distributed execution, Constraint handling rules, Tabling, Foreign
interfaces, User interfaces.
  Related Paradigms and Synergies: Inductive and coinductive logic programming,
Constraint logic programming, Answer set programming, Interaction with SAT, SMT
and CSP solvers, Theorem proving, Argumentation, Probabilistic programming,
Machine learning.
  Applications: Databases, Big data, Data integration and federation, Software
engineering, Natural language processing, Web and semantic web, Agents,
Artificial intelligence, Computational life sciences, Cyber-security, Robotics,
Education.",2021-09-15,2021,2021-09,education
"Some Critical and Ethical Perspectives on the Empirical Turn of AI
  Interpretability","We consider two fundamental and related issues currently faced by Artificial
Intelligence (AI) development: the lack of ethics and interpretability of AI
decisions. Can interpretable AI decisions help to address ethics in AI? Using a
randomized study, we experimentally show that the empirical and liberal turn of
the production of explanations tends to select AI explanations with a low
denunciatory power. Under certain conditions, interpretability tools are
therefore not means but, paradoxically, obstacles to the production of ethical
AI since they can give the illusion of being sensitive to ethical incidents. We
also show that the denunciatory power of AI explanations is highly dependent on
the context in which the explanation takes place, such as the gender or
education level of the person to whom the explication is intended for. AI
ethics tools are therefore sometimes too flexible and self-regulation through
the liberal production of explanations do not seem to be enough to address
ethical issues. We then propose two scenarios for the future development of
ethical AI: more external regulation or more liberalization of AI explanations.
These two opposite paths will play a major role on the future development of
ethical AI.",2021-09-20,2021,2021-09,education
"Artificial intelligence for Sustainable Energy: A Contextual Topic
  Modeling and Content Analysis","Parallel to the rising debates over sustainable energy and artificial
intelligence solutions, the world is currently discussing the ethics of
artificial intelligence and its possible negative effects on society and the
environment. In these arguments, sustainable AI is proposed, which aims at
advancing the pathway toward sustainability, such as sustainable energy. In
this paper, we offered a novel contextual topic modeling combining LDA, BERT,
and Clustering. We then combined these computational analyses with content
analysis of related scientific publications to identify the main scholarly
topics, sub-themes, and cross-topic themes within scientific research on
sustainable AI in energy. Our research identified eight dominant topics
including sustainable buildings, AI-based DSSs for urban water management,
climate artificial intelligence, Agriculture 4, the convergence of AI with IoT,
AI-based evaluation of renewable technologies, smart campus and engineering
education, and AI-based optimization. We then recommended 14 potential future
research strands based on the observed theoretical gaps. Theoretically, this
analysis contributes to the existing literature on sustainable AI and
sustainable energy, and practically, it intends to act as a general guide for
energy engineers and scientists, AI scientists, and social scientists to widen
their knowledge of sustainability in AI and energy convergence research.",2021-10-02,2021,2021-10,education
"Perceptions and attitudes of Children and Young People to Artificial
  Intelligence in Medicine","There is increasing interest in Artificial Intelligence and its application
to medicine. Perceptions are less well-known, notably amongst children and
young people. 21 members of a Young Persons Advisory Group for research,
recommend creating an enabling environment with children and young people,
through educational workshops with practical examples that use Artificial
Intelligence to help, but not replace humans, address issues, build trust, and
effectively communicate about potential opportunities.",2021-10-10,2021,2021-10,education
"The AI Triplet: Computational, Conceptual, and Mathematical Knowledge in
  AI Education","Efforts to enhance education and broaden participation in AI will benefit
from a systematic understanding of the competencies underlying AI expertise. In
this paper, we observe that AI expertise requires integrating computational,
conceptual, and mathematical knowledge and representations. We call this the
``AI triplet,'' similar in spirit to the ``chemistry triplet'' that has heavily
influenced the past four decades of chemistry education research. We describe a
theoretical foundation for this triplet and show how it maps onto two sample AI
topics: tree search and gradient descent. Finally, just as the chemistry
triplet has impacted chemistry education in concrete ways, we suggest two
initial hypotheses for how the AI triplet might impact AI education: 1) how we
can help AI students gain proficiency in moving between the corners of the
triplet; and 2) how all corners of the AI triplet highlight the need for
supporting students' spatial cognitive skills.",2021-10-14,2021,2021-10,education
"Explainable Student Performance Prediction With Personalized Attention
  for Explaining Why A Student Fails","As student failure rates continue to increase in higher education, predicting
student performance in the following semester has become a significant demand.
Personalized student performance prediction helps educators gain a
comprehensive view of student status and effectively intervene in advance.
However, existing works scarcely consider the explainability of student
performance prediction, which educators are most concerned about. In this
paper, we propose a novel Explainable Student performance prediction method
with Personalized Attention (ESPA) by utilizing relationships in student
profiles and prior knowledge of related courses. The designed Bidirectional
Long Short-Term Memory (BiLSTM) architecture extracts the semantic information
in the paths with specific patterns. As for leveraging similar paths' internal
relations, a local and global-level attention mechanism is proposed to
distinguish the influence of different students or courses for making
predictions. Hence, valid reasoning on paths can be applied to predict the
performance of students. The ESPA consistently outperforms the other
state-of-the-art models for student performance prediction, and the results are
intuitively explainable. This work can help educators better understand the
different impacts of behavior on students' studies.",2021-10-15,2021,2021-10,education
Risks of AI Foundation Models in Education,"If the authors of a recent Stanford report (Bommasani et al., 2021) on the
opportunities and risks of ""foundation models"" are to be believed, these models
represent a paradigm shift for AI and for the domains in which they will
supposedly be used, including education. Although the name is new (and
contested (Field, 2021)), the term describes existing types of algorithmic
models that are ""trained on broad data at scale"" and ""fine-tuned"" (i.e.,
adapted) for particular downstream tasks, and is intended to encompass large
language models such as BERT or GPT-3 and computer vision models such as CLIP.
Such technologies have the potential for harm broadly speaking (e.g., Bender et
al., 2021), but their use in the educational domain is particularly fraught,
despite the potential benefits for learners claimed by the authors. In section
3.3 of the Stanford report, Malik et al. argue that achieving the goal of
providing education for all learners requires more efficient computational
approaches that can rapidly scale across educational domains and across
educational contexts, for which they argue foundation models are uniquely
well-suited. However, evidence suggests that not only are foundation models not
likely to achieve the stated benefits for learners, but their use may also
introduce new risks for harm.",2021-10-19,2021,2021-10,education
"Explainable Artificial Intelligence for Smart City Application: A Secure
  and Trusted Platform","Artificial Intelligence (AI) is one of the disruptive technologies that is
shaping the future. It has growing applications for data-driven decisions in
major smart city solutions, including transportation, education, healthcare,
public governance, and power systems. At the same time, it is gaining
popularity in protecting critical cyber infrastructure from cyber threats,
attacks, damages, or unauthorized access. However, one of the significant
issues of those traditional AI technologies (e.g., deep learning) is that the
rapid progress in complexity and sophistication propelled and turned out to be
uninterpretable black boxes. On many occasions, it is very challenging to
understand the decision and bias to control and trust systems' unexpected or
seemingly unpredictable outputs. It is acknowledged that the loss of control
over interpretability of decision-making becomes a critical issue for many
data-driven automated applications. But how may it affect the system's security
and trustworthiness? This chapter conducts a comprehensive study of machine
learning applications in cybersecurity to indicate the need for explainability
to address this question. While doing that, this chapter first discusses the
black-box problems of AI technologies for Cybersecurity applications in smart
city-based solutions. Later, considering the new technological paradigm,
Explainable Artificial Intelligence (XAI), this chapter discusses the
transition from black-box to white-box. This chapter also discusses the
transition requirements concerning the interpretability, transparency,
understandability, and Explainability of AI-based technologies in applying
different autonomous systems in smart cities. Finally, it has presented some
commercial XAI platforms that offer explainability over traditional AI
technologies before presenting future challenges and opportunities.",2021-10-31,2021,2021-10,education
Interpreting Deep Knowledge Tracing Model on EdNet Dataset,"With more deep learning techniques being introduced into the knowledge
tracing domain, the interpretability issue of the knowledge tracing models has
aroused researchers' attention. Our previous study(Lu et al. 2020) on building
and interpreting the KT model mainly adopts the ASSISTment dataset(Feng,
Heffernan, and Koedinger 2009),, whose size is relatively small. In this work,
we perform the similar tasks but on a large and newly available dataset, called
EdNet(Choi et al. 2020). The preliminary experiment results show the
effectiveness of the interpreting techniques, while more questions and tasks
are worthy to be further explored and accomplished.",2021-10-31,2021,2021-10,education
JEDAI: A System for Skill-Aligned Explainable Robot Planning,"This paper presents JEDAI, an AI system designed for outreach and educational
efforts aimed at non-AI experts. JEDAI features a novel synthesis of research
ideas from integrated task and motion planning and explainable AI. JEDAI helps
users create high-level, intuitive plans while ensuring that they will be
executable by the robot. It also provides users customized explanations about
errors and helps improve their understanding of AI planning as well as the
limits and capabilities of the underlying robot system.",2021-10-31,2021,2021-10,education
"Reproducibility as a Mechanism for Teaching Fairness, Accountability,
  Confidentiality, and Transparency in Artificial Intelligence","In this work, we explain the setup for a technical, graduate-level course on
Fairness, Accountability, Confidentiality, and Transparency in Artificial
Intelligence (FACT-AI) at the University of Amsterdam, which teaches FACT-AI
concepts through the lens of reproducibility. The focal point of the course is
a group project based on reproducing existing FACT-AI algorithms from top AI
conferences and writing a corresponding report. In the first iteration of the
course, we created an open source repository with the code implementations from
the group projects. In the second iteration, we encouraged students to submit
their group projects to the Machine Learning Reproducibility Challenge,
resulting in 9 reports from our course being accepted for publication in the
ReScience journal. We reflect on our experience teaching the course over two
years, where one year coincided with a global pandemic, and propose guidelines
for teaching FACT-AI through reproducibility in graduate-level AI study
programs. We hope this can be a useful resource for instructors who want to set
up similar courses in the future.",2021-11-01,2021,2021-11,education
"Artificial Intelligence Technology analysis using Artificial
  Intelligence patent through Deep Learning model and vector space model","Thanks to rapid development of artificial intelligence technology in recent
years, the current artificial intelligence technology is contributing to many
part of society. Education, environment, medical care, military, tourism,
economy, politics, etc. are having a very large impact on society as a whole.
For example, in the field of education, there is an artificial intelligence
tutoring system that automatically assigns tutors based on student's level. In
the field of economics, there are quantitative investment methods that
automatically analyze large amounts of data to find investment laws to create
investment models or predict changes in financial markets. As such, artificial
intelligence technology is being used in various fields. So, it is very
important to know exactly what factors have an important influence on each
field of artificial intelligence technology and how the relationship between
each field is connected. Therefore, it is necessary to analyze artificial
intelligence technology in each field. In this paper, we analyze patent
documents related to artificial intelligence technology. We propose a method
for keyword analysis within factors using artificial intelligence patent data
sets for artificial intelligence technology analysis. This is a model that
relies on feature engineering based on deep learning model named KeyBERT, and
using vector space model. A case study of collecting and analyzing artificial
intelligence patent data was conducted to show how the proposed model can be
applied to real world problems.",2021-11-08,2021,2021-11,education
"An AI-based Solution for Enhancing Delivery of Digital Learning for
  Future Teachers","There has been a recent and rapid shift to digital learning hastened by the
pandemic but also influenced by ubiquitous availability of digital tools and
platforms now, making digital learning ever more accessible. An integral and
one of the most difficult part of scaling digital learning and teaching is to
be able to assess learner's knowledge and competency. An educator can record a
lecture or create digital content that can be delivered to thousands of
learners but assessing learners is extremely time consuming. In the paper, we
propose an Artificial Intelligence (AI)-based solution namely VidVersityQG for
generating questions automatically from pre-recorded video lectures. The
solution can automatically generate different types of assessment questions
(including short answer, multiple choice, true/false and fill in the blank
questions) based on contextual and semantic information inferred from the
videos. The proposed solution takes a human-centred approach, wherein teachers
are provided the ability to modify/edit any AI generated questions. This
approach encourages trust and engagement of teachers in the use and
implementation of AI in education. The AI-based solution was evaluated for its
accuracy in generating questions by 7 experienced teaching professionals and
117 education videos from multiple domains provided to us by our industry
partner VidVersity. VidVersityQG solution showed promising results in
generating high-quality questions automatically from video thereby
significantly reducing the time and effort for educators in manual question
generation.",2021-11-09,2021,2021-11,education
Introducing Variational Autoencoders to High School Students,"Generative Artificial Intelligence (AI) models are a compelling way to
introduce K-12 students to AI education using an artistic medium, and hence
have drawn attention from K-12 AI educators. Previous Creative AI curricula
mainly focus on Generative Adversarial Networks (GANs) while paying less
attention to Autoregressive Models, Variational Autoencoders (VAEs), or other
generative models, which have since become common in the field of generative
AI. VAEs' latent-space structure and interpolation ability could effectively
ground the interdisciplinary learning of AI, creative arts, and philosophy.
Thus, we designed a lesson to teach high school students about VAEs. We
developed a web-based game and used Plato's cave, a philosophical metaphor, to
introduce how VAEs work. We used a Google Colab notebook for students to
re-train VAEs with their hand-written digits to consolidate their
understandings. Finally, we guided the exploration of creative VAE tools such
as SketchRNN and MusicVAE to draw the connection between what they learned and
real-world applications. This paper describes the lesson design and shares
insights from the pilot studies with 22 students. We found that our approach
was effective in teaching students about a novel AI concept.",2021-11-13,2021,2021-11,education
"An AI-based Learning Companion Promoting Lifelong Learning Opportunities
  for All","Artifical Intelligence (AI) in Education has great potential for building
more personalised curricula, as well as democratising education worldwide and
creating a Renaissance of new ways of teaching and learning. We believe this is
a crucial moment for setting the foundations of AI in education in the
beginning of this Fourth Industrial Revolution. This report aims to synthesize
how AI might change (and is already changing) how we learn, as well as what
technological features are crucial for these AI systems in education, with the
end goal of starting this pressing dialogue of how the future of AI in
education should unfold, engaging policy makers, engineers, researchers and
obviously, teachers and learners. This report also presents the advances within
the X5GON project, a European H2020 project aimed at building and deploying a
cross-modal, cross-lingual, cross-cultural, cross-domain and cross-site
personalised learning platform for Open Educational Resources (OER).",2021-11-16,2021,2021-11,education
An Empirical Study of Finding Similar Exercises,"Education artificial intelligence aims to profit tasks in the education
domain such as intelligent test paper generation and consolidation exercises
where the main technique behind is how to match the exercises, known as the
finding similar exercises(FSE) problem. Most of these approaches emphasized
their model abilities to represent the exercise, unfortunately there are still
many challenges such as the scarcity of data, insufficient understanding of
exercises and high label noises. We release a Chinese education pre-trained
language model BERT$_{Edu}$ for the label-scarce dataset and introduce the
exercise normalization to overcome the diversity of mathematical formulas and
terms in exercise. We discover new auxiliary tasks in an innovative way depends
on problem-solving ideas and propose a very effective MoE enhanced multi-task
model for FSE task to attain better understanding of exercises. In addition,
confidence learning was utilized to prune train-set and overcome high noises in
labeling data. Experiments show that these methods proposed in this paper are
very effective.",2021-11-16,2021,2021-11,education
"Words of Wisdom: Representational Harms in Learning From AI
  Communication","Many educational technologies use artificial intelligence (AI) that presents
generated or produced language to the learner. We contend that all language,
including all AI communication, encodes information about the identity of the
human or humans who contributed to crafting the language. With AI
communication, however, the user may index identity information that does not
match the source. This can lead to representational harms if language
associated with one cultural group is presented as ""standard"" or ""neutral"", if
the language advantages one group over another, or if the language reinforces
negative stereotypes. In this work, we discuss a case study using a Visual
Question Generation (VQG) task involving gathering crowdsourced data from
targeted demographic groups. Generated questions will be presented to human
evaluators to understand how they index the identity behind the language,
whether and how they perceive any representational harms, and how they would
ideally address any such harms caused by AI communication. We reflect on the
educational applications of this work as well as the implications for equality,
diversity, and inclusion (EDI).",2021-11-16,2021,2021-11,education
"Improving Controllability of Educational Question Generation by Keyword
  Provision","Question Generation (QG) receives increasing research attention in NLP
community. One motivation for QG is that QG significantly facilitates the
preparation of educational reading practice and assessments. While the
significant advancement of QG techniques was reported, current QG results are
not ideal for educational reading practice assessment in terms of
\textit{controllability} and \textit{question difficulty}. This paper reports
our results toward the two issues. First, we report a state-of-the-art
exam-like QG model by advancing the current best model from 11.96 to 20.19 (in
terms of BLEU 4 score). Second, we propose to investigate a variant of QG
setting by allowing users to provide keywords for guiding QG direction. We also
present a simple but effective model toward the QG controllability task.
Experiments are also performed and the results demonstrate the feasibility and
potentials of improving QG diversity and controllability by the proposed
keyword provision QG model.",2021-12-02,2021,2021-12,education
"Could AI Democratise Education? Socio-Technical Imaginaries of an EdTech
  Revolution","Artificial Intelligence (AI) in Education has been said to have the potential
for building more personalised curricula, as well as democratising education
worldwide and creating a Renaissance of new ways of teaching and learning.
Millions of students are already starting to benefit from the use of these
technologies, but millions more around the world are not. If this trend
continues, the first delivery of AI in Education could be greater educational
inequality, along with a global misallocation of educational resources
motivated by the current technological determinism narrative. In this paper, we
focus on speculating and posing questions around the future of AI in Education,
with the aim of starting the pressing conversation that would set the right
foundations for the new generation of education that is permeated by
technology. This paper starts by synthesising how AI might change how we learn
and teach, focusing specifically on the case of personalised learning
companions, and then move to discuss some socio-technical features that will be
crucial for avoiding the perils of these AI systems worldwide (and perhaps
ensuring their success). This paper also discusses the potential of using AI
together with free, participatory and democratic resources, such as Wikipedia,
Open Educational Resources and open-source tools. We also emphasise the need
for collectively designing human-centered, transparent, interactive and
collaborative AI-based algorithms that empower and give complete agency to
stakeholders, as well as support new emerging pedagogies. Finally, we ask what
would it take for this educational revolution to provide egalitarian and
empowering access to education, beyond any political, cultural, language,
geographical and learning ability barriers.",2021-12-03,2021,2021-12,education
"Application of Artificial Intelligence and Machine Learning in
  Libraries: A Systematic Review","As the concept and implementation of cutting-edge technologies like
artificial intelligence and machine learning has become relevant, academics,
researchers and information professionals involve research in this area. The
objective of this systematic literature review is to provide a synthesis of
empirical studies exploring application of artificial intelligence and machine
learning in libraries. To achieve the objectives of the study, a systematic
literature review was conducted based on the original guidelines proposed by
Kitchenham et al. (2009). Data was collected from Web of Science, Scopus, LISA
and LISTA databases. Following the rigorous/ established selection process, a
total of thirty-two articles were finally selected, reviewed and analyzed to
summarize on the application of AI and ML domain and techniques which are most
often used in libraries. Findings show that the current state of the AI and ML
research that is relevant with the LIS domain mainly focuses on theoretical
works. However, some researchers also emphasized on implementation projects or
case studies. This study will provide a panoramic view of AI and ML in
libraries for researchers, practitioners and educators for furthering the more
technology-oriented approaches, and anticipating future innovation pathways.",2021-12-06,2021,2021-12,education
"Semantic TrueLearn: Using Semantic Knowledge Graphs in Recommendation
  Systems","In informational recommenders, many challenges arise from the need to handle
the semantic and hierarchical structure between knowledge areas. This work aims
to advance towards building a state-aware educational recommendation system
that incorporates semantic relatedness between knowledge topics, propagating
latent information across semantically related topics. We introduce a novel
learner model that exploits this semantic relatedness between knowledge
components in learning resources using the Wikipedia link graph, with the aim
to better predict learner engagement and latent knowledge in a lifelong
learning scenario. In this sense, Semantic TrueLearn builds a humanly intuitive
knowledge representation while leveraging Bayesian machine learning to improve
the predictive performance of the educational engagement. Our experiments with
a large dataset demonstrate that this new semantic version of TrueLearn
algorithm achieves statistically significant improvements in terms of
predictive performance with a simple extension that adds semantic awareness to
the model.",2021-12-08,2021,2021-12,education
"Interpretable Knowledge Tracing: Simple and Efficient Student Modeling
  with Causal Relations","Intelligent Tutoring Systems have become critically important in future
learning environments. Knowledge Tracing (KT) is a crucial part of that system.
It is about inferring the skill mastery of students and predicting their
performance to adjust the curriculum accordingly. Deep Learning-based KT models
have shown significant predictive performance compared with traditional models.
However, it is difficult to extract psychologically meaningful explanations
from the tens of thousands of parameters in neural networks, that would relate
to cognitive theory. There are several ways to achieve high accuracy in student
performance prediction but diagnostic and prognostic reasoning is more critical
in learning sciences. Since KT problem has few observable features (problem ID
and student's correctness at each practice), we extract meaningful latent
features from students' response data by using machine learning and data mining
techniques. In this work, we present Interpretable Knowledge Tracing (IKT), a
simple model that relies on three meaningful latent features: individual skill
mastery, ability profile (learning transfer across skills), and problem
difficulty. IKT's prediction of future student performance is made using a
Tree-Augmented Naive Bayes Classifier (TAN), therefore its predictions are
easier to explain than deep learning-based student models. IKT also shows
better student performance prediction than deep learning-based student models
without requiring a huge amount of parameters. We conduct ablation studies on
each feature to examine their contribution to student performance prediction.
Thus, IKT has great potential for providing adaptive and personalized
instructions with causal reasoning in real-world educational systems.",2021-12-15,2021,2021-12,education
"ADAPQUEST: A Software for Web-Based Adaptive Questionnaires based on
  Bayesian Networks","We introduce ADAPQUEST, a software tool written in Java for the development
of adaptive questionnaires based on Bayesian networks. Adaptiveness is intended
here as the dynamical choice of the question sequence on the basis of an
evolving model of the skill level of the test taker. Bayesian networks offer a
flexible and highly interpretable framework to describe such testing process,
especially when coping with multiple skills. ADAPQUEST embeds dedicated
elicitation strategies to simplify the elicitation of the questionnaire
parameters. An application of this tool for the diagnosis of mental disorders
is also discussed together with some implementation details.",2021-12-29,2021,2021-12,education
"Integrating Artificial Intelligence and Augmented Reality in Robotic
  Surgery: An Initial dVRK Study Using a Surgical Education Scenario","Robot-assisted surgery has become progressively more and more popular due to
its clinical advantages. In the meanwhile, the artificial intelligence and
augmented reality in robotic surgery are developing rapidly and receive lots of
attention. However, current methods have not discussed the coherent integration
of AI and AR in robotic surgery. In this paper, we develop a novel system by
seamlessly merging artificial intelligence module and augmented reality
visualization to automatically generate the surgical guidance for robotic
surgery education. Specifically, we first leverage reinforcement leaning to
learn from expert demonstration and then generate 3D guidance trajectory,
providing prior context information of the surgical procedure. Along with other
information such as text hint, the 3D trajectory is then overlaid in the stereo
view of dVRK, where the user can perceive the 3D guidance and learn the
procedure. The proposed system is evaluated through a preliminary experiment on
surgical education task peg-transfer, which proves its feasibility and
potential as the next generation of robot-assisted surgery education solution.",2022-01-02,2022,2022-01,education
Automated Theorem Proving in the Classroom,"We report on several scenarios of using automated theorem proving software in
university education. In particular, we focus on using the Theorema system in a
software-enhanced logic-course for students in computer science or artificial
intelligence. The purpose of using logic-software in our teaching is not to
teach students the proper use of a particular piece of software. In contrast,
we try to employ certain software in order to spark students' motivation and to
support their understanding of logic principles they are supposed to understand
after having passed the course. In a sense, we try to let the software act as a
logic-tutor, the software is not an additional subject we teach.",2022-01-03,2022,2022-01,education
"Deep Reinforcement Learning, a textbook","Deep reinforcement learning has gathered much attention recently. Impressive
results were achieved in activities as diverse as autonomous driving, game
playing, molecular recombination, and robotics. In all these fields, computer
programs have taught themselves to solve difficult problems. They have learned
to fly model helicopters and perform aerobatic manoeuvers such as loops and
rolls. In some applications they have even become better than the best humans,
such as in Atari, Go, poker and StarCraft. The way in which deep reinforcement
learning explores complex environments reminds us of how children learn, by
playfully trying out things, getting feedback, and trying again. The computer
seems to truly possess aspects of human learning; this goes to the heart of the
dream of artificial intelligence. The successes in research have not gone
unnoticed by educators, and universities have started to offer courses on the
subject. The aim of this book is to provide a comprehensive overview of the
field of deep reinforcement learning. The book is written for graduate students
of artificial intelligence, and for researchers and practitioners who wish to
better understand deep reinforcement learning methods and their challenges. We
assume an undergraduate-level of understanding of computer science and
artificial intelligence; the programming language of this book is Python. We
describe the foundations, the algorithms and the applications of deep
reinforcement learning. We cover the established model-free and model-based
methods that form the basis of the field. Developments go quickly, and we also
cover advanced topics: deep multi-agent reinforcement learning, deep
hierarchical reinforcement learning, and deep meta learning.",2022-01-04,2022,2022-01,education
"Challenges of Artificial Intelligence -- From Machine Learning and
  Computer Vision to Emotional Intelligence","Artificial intelligence (AI) has become a part of everyday conversation and
our lives. It is considered as the new electricity that is revolutionizing the
world. AI is heavily invested in both industry and academy. However, there is
also a lot of hype in the current AI debate. AI based on so-called deep
learning has achieved impressive results in many problems, but its limits are
already visible. AI has been under research since the 1940s, and the industry
has seen many ups and downs due to over-expectations and related
disappointments that have followed.
  The purpose of this book is to give a realistic picture of AI, its history,
its potential and limitations. We believe that AI is a helper, not a ruler of
humans. We begin by describing what AI is and how it has evolved over the
decades. After fundamentals, we explain the importance of massive data for the
current mainstream of artificial intelligence. The most common representations
for AI, methods, and machine learning are covered. In addition, the main
application areas are introduced. Computer vision has been central to the
development of AI. The book provides a general introduction to computer vision,
and includes an exposure to the results and applications of our own research.
Emotions are central to human intelligence, but little use has been made in AI.
We present the basics of emotional intelligence and our own research on the
topic. We discuss super-intelligence that transcends human understanding,
explaining why such achievement seems impossible on the basis of present
knowledge,and how AI could be improved. Finally, a summary is made of the
current state of AI and what to do in the future. In the appendix, we look at
the development of AI education, especially from the perspective of contents at
our own university.",2022-01-05,2022,2022-01,education
"A Transfer Learning Pipeline for Educational Resource Discovery with
  Application in Leading Paragraph Generation","Effective human learning depends on a wide selection of educational materials
that align with the learner's current understanding of the topic. While the
Internet has revolutionized human learning or education, a substantial resource
accessibility barrier still exists. Namely, the excess of online information
can make it challenging to navigate and discover high-quality learning
materials. In this paper, we propose the educational resource discovery (ERD)
pipeline that automates web resource discovery for novel domains. The pipeline
consists of three main steps: data collection, feature extraction, and resource
classification. We start with a known source domain and conduct resource
discovery on two unseen target domains via transfer learning. We first collect
frequent queries from a set of seed documents and search on the web to obtain
candidate resources, such as lecture slides and introductory blog posts. Then
we introduce a novel pretrained information retrieval deep neural network
model, query-document masked language modeling (QD-MLM), to extract deep
features of these candidate resources. We apply a tree-based classifier to
decide whether the candidate is a positive learning resource. The pipeline
achieves F1 scores of 0.94 and 0.82 when evaluated on two similar but novel
target domains. Finally, we demonstrate how this pipeline can benefit an
application: leading paragraph generation for surveys. This is the first study
that considers various web resources for survey generation, to the best of our
knowledge. We also release a corpus of 39,728 manually labeled web resources
and 659 queries from NLP, Computer Vision (CV), and Statistics (STATS).",2022-01-07,2022,2022-01,education
"A conceptual framework of Intelligent Management Control System for
  Higher Education","The utilization of management control systems in university management poses
a considerable challenge because university's strategic goals are not identical
to those applied in profit-oriented management. A university's management
control system should take into account the processing of management
information for management purposes, allowing for the relationships between
different groups of stakeholders. The specificity of the university operation
assumes conducting long-term scientific research and educational programmes.
Therefore, the controlling approach to university management should considerat
long-term performance measurement as well as management in key areas such as
research, provision of education to students, and interaction with the tertiary
institution's socioeconomic environment.This paper aims to develop a conceptual
framework of the Intelligent Management Control System for Higher Education
(IMCSHE) based on cognitive agents. The main findings are related to developing
the assumption, model, and technological basis including the artificial
intelligence method.",2022-01-12,2022,2022-01,education
Revelation of Task Difficulty in AI-aided Education,"When a student is asked to perform a given task, her subjective estimate of
the difficulty of that task has a strong influence on her performance. There
exists a rich literature on the impact of perceived task difficulty on
performance and motivation. Yet, there is another topic that is closely related
to the subject of the influence of perceived task difficulty that did not
receive any attention in previous research - the influence of revealing the
true difficulty of a task to the student. This paper investigates the impact of
revealing the task difficulty on the student's performance, motivation,
self-efficacy and subjective task value via an experiment in which workers are
asked to solve matchstick riddles. Furthermore, we discuss how the experiment
results might be relevant for AI-aided education. Specifically, we elaborate on
the question of how a student's learning experience might be improved by
supporting her with two types of AI systems: an AI system that predicts task
difficulty and an AI system that determines when task difficulty should be
revealed and when not.",2022-01-12,2022,2022-01,education
EXSeQETIC: Expert System to Support the Implementation of eQETIC Model,"The digital educational solutions are increasingly used demanding high
quality functionalities. In this sense, standards and models are made available
by governments, associations, and researchers being most used in quality
control and assessment sessions. The eQETIC model was built according to the
approach of continuous process improvement favoring the quality management for
development and maintenance of digital educational solutions. This article
presents two expert systems to support the implementation of eQETIC model and
demonstrates that such systems are able to support users during the model
implementation. Developed according to two types of shells (SINTA/UFC and
e2gLite/eXpertise2go), the systems were used by a professional who develops
these type of solutions and showed positive results regarding the support
offered by them in implementing the rules proposed by eQETIC model.",2022-01-15,2022,2022-01,education
"Educational Timetabling: Problems, Benchmarks, and State-of-the-Art
  Results","We propose a survey of the research contributions on the field of Educational
Timetabling with a specific focus on ""standard"" formulations and the
corresponding benchmark instances. We identify six of such formulations and we
discuss their features, pointing out their relevance and usability. Other
available formulations and datasets are also reviewed and briefly discussed.
Subsequently, we report the main state-of-the-art results on the selected
benchmarks, in terms of solution quality (upper and lower bounds), search
techniques, running times, statistical distributions, and other side settings.",2022-01-19,2022,2022-01,education
Fooling MOSS Detection with Pretrained Language Models,"As artificial intelligence (AI) technologies become increasingly powerful and
prominent in society, their misuse is a growing concern. In educational
settings, AI technologies could be used by students to cheat on assignments and
exams. In this paper we explore whether transformers can be used to solve
introductory level programming assignments while bypassing commonly used AI
tools to detect similarities between pieces of software. We find that a student
using GPT-J [Wang and Komatsuzaki, 2021] can complete introductory level
programming assignments without triggering suspicion from MOSS [Aiken, 2000], a
widely used software similarity and plagiarism detection tool. This holds
despite the fact that GPT-J was not trained on the problems in question and is
not provided with any examples to work from. We further find that the code
written by GPT-J is diverse in structure, lacking any particular tells that
future plagiarism detection techniques may use to try to identify
algorithmically generated code. We conclude with a discussion of the ethical
and educational implications of large language models and directions for future
research.",2022-01-19,2022,2022-01,education
Leaf: Multiple-Choice Question Generation,"Testing with quiz questions has proven to be an effective way to assess and
improve the educational process. However, manually creating quizzes is tedious
and time-consuming. To address this challenge, we present Leaf, a system for
generating multiple-choice questions from factual text. In addition to being
very well suited for the classroom, Leaf could also be used in an industrial
setting, e.g., to facilitate onboarding and knowledge sharing, or as a
component of chatbots, question answering systems, or Massive Open Online
Courses (MOOCs). The code and the demo are available on
https://github.com/KristiyanVachev/Leaf-Question-Generation.",2022-01-22,2022,2022-01,education
"An Experience Report of Executive-Level Artificial Intelligence
  Education in the United Arab Emirates","Teaching artificial intelligence (AI) is challenging. It is a fast moving
field and therefore difficult to keep people updated with the state-of-the-art.
Educational offerings for students are ever increasing, beyond university
degree programs where AI education traditionally lay. In this paper, we present
an experience report of teaching an AI course to business executives in the
United Arab Emirates (UAE). Rather than focusing only on theoretical and
technical aspects, we developed a course that teaches AI with a view to
enabling students to understand how to incorporate it into existing business
processes. We present an overview of our course, curriculum and teaching
methods, and we discuss our reflections on teaching adult learners, and to
students in the UAE.",2022-02-02,2022,2022-02,education
"Proceedings 10th International Workshop on Theorem Proving Components
  for Educational Software","This EPTCS volume contains the proceedings of the ThEdu'21 workshop, promoted
on 11 July 2021, as a satellite event of CADE-28. Due to the COVID-19 pandemic,
CADE-28 and all its co-located events happened as virtual events. ThEdu'21 was
a vibrant workshop, with an invited talk by Gilles Dowek (ENS Paris-Saclay),
eleven contributions, and one demonstration. After the workshop an open call
for papers was issued and attracted 10 submissions, 7 of which have been
accepted by the reviewers, and collected in the present post-proceedings
volume.
  The ThEdu series pursues the smooth transition from an intuitive way of doing
mathematics at secondary school to a more formal approach to the subject in
STEM education, while favouring software support for this transition by
exploiting the power of theorem-proving technologies.
  The volume editors hope that this collection of papers will further promote
the development of theorem-proving based software, and that it will collaborate
on improving mutual understanding between computer scientists, mathematicians
and stakeholders in education.",2022-02-02,2022,2022-02,education
"Trustworthy Autonomous Systems (TAS): Engaging TAS experts in curriculum
  design","Recent advances in artificial intelligence, specifically machine learning,
contributed positively to enhancing the autonomous systems industry, along with
introducing social, technical, legal and ethical challenges to make them
trustworthy. Although Trustworthy Autonomous Systems (TAS) is an established
and growing research direction that has been discussed in multiple disciplines,
e.g., Artificial Intelligence, Human-Computer Interaction, Law, and Psychology.
The impact of TAS on education curricula and required skills for future TAS
engineers has rarely been discussed in the literature. This study brings
together the collective insights from a number of TAS leading experts to
highlight significant challenges for curriculum design and potential TAS
required skills posed by the rapid emergence of TAS. Our analysis is of
interest not only to the TAS education community but also to other researchers,
as it offers ways to guide future research toward operationalising TAS
education.",2022-02-04,2022,2022-02,education
"Artificial Intelligence-Based Analytics for Impacts of COVID-19 and
  Online Learning on College Students' Mental Health","COVID-19, the disease caused by the novel coronavirus (SARS-CoV-2), first
emerged in Wuhan, China late in December 2019. Not long after, the virus spread
worldwide and was declared a pandemic by the World Health Organization in March
2020. This caused many changes around the world and in the United States,
including an educational shift towards online learning. In this paper, we seek
to understand how the COVID-19 pandemic and increase in online learning impact
college students' emotional wellbeing. We use several machine learning and
statistical models to analyze data collected by the Faculty of Public
Administration at the University of Ljubljana, Slovenia in conjunction with an
international consortium of universities, other higher education institutions,
and students' associations. Our results indicate that features related to
students' academic life have the largest impact on their emotional wellbeing.
Other important factors include students' satisfaction with their university's
and government's handling of the pandemic as well as students' financial
security.",2022-02-07,2022,2022-02,education
"A Survey on Artificial Intelligence for Source Code: A Dialogue Systems
  Perspective","In this survey paper, we overview major deep learning methods used in Natural
Language Processing (NLP) and source code over the last 35 years. Next, we
present a survey of the applications of Artificial Intelligence (AI) for source
code, also known as Code Intelligence (CI) and Programming Language Processing
(PLP). We survey over 287 publications and present a software-engineering
centered taxonomy for CI placing each of the works into one category describing
how it best assists the software development cycle. Then, we overview the field
of conversational assistants and their applications in software engineering and
education. Lastly, we highlight research opportunities at the intersection of
AI for code and conversational assistants and provide future directions for
researching conversational assistants with CI capabilities.",2022-02-10,2022,2022-02,education
Surf or sleep? Understanding the influence of bedtime patterns on campus,"Poor sleep habits may cause serious problems of mind and body, and it is a
commonly observed issue for college students due to study workload as well as
peer and social influence. Understanding its impact and identifying students
with poor sleep habits matters a lot in educational management. Most of the
current research is either based on self-reports and questionnaires, suffering
from a small sample size and social desirability bias, or the methods used are
not suitable for the education system. In this paper, we develop a general
data-driven method for identifying students' sleep patterns according to their
Internet access pattern stored in the education management system and explore
its influence from various aspects. First, we design a Possion-based
probabilistic mixture model to cluster students according to the distribution
of bedtime and identify students who are used to staying up late. Second, we
profile students from five aspects (including eight dimensions) based on
campus-behavior data and build Bayesian networks to explore the relationship
between behavioral characteristics and sleeping habits. Finally, we test the
predictability of sleeping habits. This paper not only contributes to the
understanding of student sleep from a cognitive and behavioral perspective but
also presents a new approach that provides an effective framework for various
educational institutions to detect the sleeping patterns of students.",2022-02-18,2022,2022-02,education
Social Network Extraction Unsupervised,"In the era of information technology, the two developing sides are data
science and artificial intelligence. In terms of scientific data, one of the
tasks is the extraction of social networks from information sources that have
the nature of big data. Meanwhile, in terms of artificial intelligence, the
presence of contradictory methods has an impact on knowledge. This article
describes an unsupervised as a stream of methods for extracting social networks
from information sources. There are a variety of possible approaches and
strategies to superficial methods as a starting concept. Each method has its
advantages, but in general, it contributes to the integration of each other,
namely simplifying, enriching, and emphasizing the results.",2022-02-24,2022,2022-02,education
"A Perspective on Robotic Telepresence and Teleoperation using Cognition:
  Are we there yet?","Telepresence and teleoperation robotics have attracted a great amount of
attention in the last 10 years. With the Artificial Intelligence (AI)
revolution already being started, we can see a wide range of robotic
applications being realized. Intelligent robotic systems are being deployed
both in industrial and domestic environments. Telepresence is the idea of being
present in a remote location virtually or via robotic avatars. Similarly, the
idea of operating a robot from a remote location for various tasks is called
teleoperation. These technologies find significant application in health care,
education, surveillance, disaster recovery, and corporate/government sectors.
But question still remains about their maturity, security and safety levels. We
also need to think about enhancing the user experience and trust in such
technologies going into the next generation of computing.",2022-03-06,2022,2022-03,education
"Piloting Diversity and Inclusion Workshops in Artificial Intelligence
  and Robotics for Children","In this paper, we present preliminary work from a pilot workshop that aimed
to promote diversity and inclusion for fundamentals of Artificial Intelligence
and Robotics for Children (air4children) in the context of developing
countries. Considering the scarcity of funding and the little to none
availability of specialised professionals to teach AI and robotics in
developing countries, we present resources based on free open-source hardware
and software, open educational resources, and alternative education programs.
That said, the contribution of this work is the pilot workshop of four lessons
that promote diversity and inclusion on teaching AI and Robotics for children
to a small gender-balanced sample of 14 children of an average age of 7.64
years old. We conclude that participant, instructors, coordinators and parents
engaged well in the pilot workshop noting the various challenges of having the
right resources for the workshops in developing countries and posing future
work. The resources to reproduce this work are available at
https://github.com/air4children/hri2022.",2022-03-07,2022,2022-03,education
Toward Ethical AIED,"This paper presents the key conclusions to the forthcoming edited book on The
Ethics of Artificial Intelligence in Education: Practices, Challenges and
Debates (August 2022, Routlege). As well as highlighting the key contributions
to the book, it discusses the key questions and the grand challenges for the
field of AI in Education (AIED)in the context of ethics and ethical practices
within the field. The book itself presents diverse perspectives from outside
and from within the AIED as a way of achieving a broad perspective in the key
ethical issues for AIED and a deep understanding of work conducted to date by
the AIED community.",2022-03-11,2022,2022-03,education
"A Survey of Surface Defect Detection of Industrial Products Based on A
  Small Number of Labeled Data","The surface defect detection method based on visual perception has been
widely used in industrial quality inspection. Because defect data are not easy
to obtain and the annotation of a large number of defect data will waste a lot
of manpower and material resources. Therefore, this paper reviews the methods
of surface defect detection of industrial products based on a small number of
labeled data, and this method is divided into traditional image
processing-based industrial product surface defect detection methods and deep
learning-based industrial product surface defect detection methods suitable for
a small number of labeled data. The traditional image processing-based
industrial product surface defect detection methods are divided into
statistical methods, spectral methods and model methods. Deep learning-based
industrial product surface defect detection methods suitable for a small number
of labeled data are divided into based on data augmentation, based on transfer
learning, model-based fine-tuning, semi-supervised, weak supervised and
unsupervised.",2022-03-11,2022,2022-03,education
A Systematic Review on Interactive Virtual Reality Laboratory,"Virtual Reality has become a significant element of education throughout the
years. To understand the quality and advantages of these techniques, it is
important to understand how they were developed and evaluated. Since COVID-19,
the education system has drastically changed a lot. It has shifted from being
in a classroom with a whiteboard and projectors to having your own room in
front of your laptop in a virtual meeting. In this respect, virtual reality in
the laboratory or Virtual Laboratory is the main focus of this research, which
is intended to comprehend the work done in quality education from a distance
using VR. As per the findings of the study, adopting virtual reality in
education can help students learn more effectively and also help them increase
perspective, enthusiasm, and knowledge of complex notions by offering them an
interactive experience in which they can engage and learn more effectively.
This highlights the importance of a significant expansion of VR use in
learning, the majority of which employ scientific comparison approaches to
compare students who use VR to those who use the traditional method for
learning.",2022-03-26,2022,2022-03,education
"Software Testing, AI and Robotics (STAIR) Learning Lab","In this paper we presented the Software Testing, AI and Robotics (STAIR)
Learning Lab. STAIR is an initiative started at the University of Innsbruck to
bring robotics, Artificial Intelligence (AI) and software testing into schools.
In the lab physical and virtual learning units are developed in parallel and in
sync with each other. Its core learning approach is based the develop of both a
physical and simulated robotics environment. In both environments AI scenarios
(like traffic sign recognition) are deployed and tested. We present and focus
on our newly designed MiniBot that are both built on hardware which was
designed for educational and research purposes as well as the simulation
environment. Additionally, we describe first learning design concepts and a
showcase scenario (i.e., AI-based traffic sign recognition) with different
exercises which can easily be extended.",2022-04-06,2022,2022-04,education
"Improving Students' Academic Performance with AI and Semantic
  Technologies","Artificial intelligence and semantic technologies are evolving and have been
applied in various research areas, including the education domain. Higher
Education institutions strive to improve students' academic performance. Early
intervention to at-risk students and a reasonable curriculum is vital for
students' success. Prior research opted for deploying traditional machine
learning models to predict students' performance. In terms of curriculum
semantic analysis, after conducting a comprehensive systematic review regarding
the use of semantic technologies in the Computer Science curriculum, a major
finding of the study is that technologies used to measure similarity have
limitations in terms of accuracy and ambiguity in the representation of
concepts, courses, etc. To fill these gaps, in this study, three
implementations were developed, that is, to predict students' performance using
marks from the previous semester, to model a course representation in a
semantic way and compute the similarity, and to identify the prerequisite
between two similar courses. Regarding performance prediction, we used the
combination of Genetic Algorithm and Long-Short Term Memory (LSTM) on a dataset
from a Brazilian university containing 248730 records. As for similarity
measurement, we deployed BERT to encode the sentences and used cosine
similarity to obtain the distance between courses. With respect to prerequisite
identification, TextRazor was applied to extract concepts from course
description, followed by employing SemRefD to measure the degree of
prerequisite between two concepts. The outcomes of this study can be summarized
as: (i) a breakthrough result improves Manrique's work by 2.5% in terms of
accuracy in dropout prediction; (ii) uncover the similarity between courses
based on course description; (iii) identify the prerequisite over three
compulsory courses of School of Computing at ANU.",2022-05-02,2022,2022-05,education
A Perspective on K-12 AI Education,"Artificial intelligence (AI), which enables machines to learn to perform a
task by training on diverse datasets, is one of the most revolutionary
developments in scientific history. Although AI and especially deep learning is
relatively new, it has already had transformative impact on medicine, biology,
transportation, entertainment, and beyond. As AI changes our daily lives at an
increasingly fast pace, we are challenged with preparing our society for an
AI-driven future. To this end, a critical step is to ensure an AI-ready
workforce through education. Advocates of beginning instruction of AI basics at
the K-12 level typically note benefits to the workforce, economy, and national
security. In this complementary perspective, we discuss why learning AI is
beneficial for motivating students and promoting creative thinking, and how to
develop a module-based approach that optimizes learning outcomes. We hope to
excite and engage more members of the education community to join the effort to
advance K-12 AI education in the USA and worldwide.",2022-05-04,2022,2022-05,education
Math-KG: Construction and Applications of Mathematical Knowledge Graph,"Recently, the explosion of online education platforms makes a success in
encouraging us to easily access online education resources. However, most of
them ignore the integration of massive unstructured information, which
inevitably brings the problem of \textit{information overload} and
\textit{knowledge trek}. In this paper, we proposed a mathematical knowledge
graph named Math-KG, which automatically constructed by the pipeline method
with the natural language processing technology to integrate the resources of
the mathematics. It is built from the corpora of Baidu Baike, Wikipedia. We
implement a simple application system to validate the proposed Math-KG can make
contributions on a series of scenes, including faults analysis and semantic
search. The system is publicly available at GitHub
\footnote{\url{https://github.com/wjn1996/Mathematical-Knowledge-Entity-Recognition}.}.",2022-05-08,2022,2022-05,education
A Transparency Index Framework for AI in Education,"Numerous AI ethics checklists and frameworks have been proposed focusing on
different dimensions of ethical AI such as fairness, explainability, and
safety. Yet, no such work has been done on developing transparent AI systems
for real-world educational scenarios. This paper presents a Transparency Index
framework that has been iteratively co-designed with different stakeholders of
AI in education, including educators, ed-tech experts, and AI practitioners. We
map the requirements of transparency for different categories of stakeholders
of AI in education and demonstrate that transparency considerations are
embedded in the entire AI development process from the data collection stage
until the AI system is deployed in the real world and iteratively improved. We
also demonstrate how transparency enables the implementation of other ethical
AI dimensions in Education like interpretability, accountability, and safety.
In conclusion, we discuss the directions for future research in this newly
emerging field. The main contribution of this study is that it highlights the
importance of transparency in developing AI-powered educational technologies
and proposes an index framework for its conceptualization for AI in education.",2022-05-09,2022,2022-05,education
"The AI Teacher Test: Measuring the Pedagogical Ability of Blender and
  GPT-3 in Educational Dialogues","How can we test whether state-of-the-art generative models, such as Blender
and GPT-3, are good AI teachers, capable of replying to a student in an
educational dialogue? Designing an AI teacher test is challenging: although
evaluation methods are much-needed, there is no off-the-shelf solution to
measuring pedagogical ability. This paper reports on a first attempt at an AI
teacher test. We built a solution around the insight that you can run
conversational agents in parallel to human teachers in real-world dialogues,
simulate how different agents would respond to a student, and compare these
counterpart responses in terms of three abilities: speak like a teacher,
understand a student, help a student. Our method builds on the reliability of
comparative judgments in education and uses a probabilistic model and Bayesian
sampling to infer estimates of pedagogical ability. We find that, even though
conversational agents (Blender in particular) perform well on conversational
uptake, they are quantifiably worse than real teachers on several pedagogical
dimensions, especially with regard to helpfulness (Blender: {\Delta} ability =
-0.75; GPT-3: {\Delta} ability = -0.93).",2022-05-16,2022,2022-05,education
"A Deep Learning Approach for Automatic Detection of Qualitative Features
  of Lecturing","Artificial Intelligence in higher education opens new possibilities for
improving the lecturing process, such as enriching didactic materials, helping
in assessing students' works or even providing directions to the teachers on
how to enhance the lectures. We follow this research path, and in this work, we
explore how an academic lecture can be assessed automatically by quantitative
features. First, we prepare a set of qualitative features based on teaching
practices and then annotate the dataset of academic lecture videos collected
for this purpose. We then show how these features could be detected
automatically using machine learning and computer vision techniques. Our
results show the potential usefulness of our work.",2022-05-30,2022,2022-05,education
"Fair Classification via Transformer Neural Networks: Case Study of an
  Educational Domain","Educational technologies nowadays increasingly use data and Machine Learning
(ML) models. This gives the students, instructors, and administrators support
and insights for the optimum policy. However, it is well acknowledged that ML
models are subject to bias, which raises concerns about the fairness, bias, and
discrimination of using these automated ML algorithms in education and its
unintended and unforeseen negative consequences. The contribution of bias
during the decision-making comes from datasets used for training ML models and
the model architecture. This paper presents a preliminary investigation of the
fairness of transformer neural networks on the two tabular datasets: Law School
and Student-Mathematics. In contrast to classical ML models, the
transformer-based models transform these tabular datasets into a richer
representation while solving the classification task. We use different fairness
metrics for evaluation and check the trade-off between fairness and accuracy of
the transformer-based models over the tabular datasets. Empirically, our
approach shows impressive results regarding the trade-off between fairness and
performance on the Law School dataset.",2022-06-03,2022,2022-06,education
ArgRewrite V.2: an Annotated Argumentative Revisions Corpus,"Analyzing how humans revise their writings is an interesting research
question, not only from an educational perspective but also in terms of
artificial intelligence. Better understanding of this process could facilitate
many NLP applications, from intelligent tutoring systems to supportive and
collaborative writing environments. Developing these applications, however,
requires revision corpora, which are not widely available. In this work, we
present ArgRewrite V.2, a corpus of annotated argumentative revisions,
collected from two cycles of revisions to argumentative essays about
self-driving cars. Annotations are provided at different levels of purpose
granularity (coarse and fine) and scope (sentential and subsentential). In
addition, the corpus includes the revision goal given to each writer, essay
scores, annotation verification, pre- and post-study surveys collected from
participants as meta-data. The variety of revision unit scope and purpose
granularity levels in ArgRewrite, along with the inclusion of new types of
meta-data, can make it a useful resource for research and applications that
involve revision analysis. We demonstrate some potential applications of
ArgRewrite V.2 in the development of automatic revision purpose predictors, as
a training source and benchmark.",2022-06-03,2022,2022-06,education
"Towards Systems Education for Artificial Intelligence: A Course Practice
  in Intelligent Computing Architectures","With the rapid development of artificial intelligence (AI) community,
education in AI is receiving more and more attentions. There have been many AI
related courses in the respects of algorithms and applications, while not many
courses in system level are seriously taken into considerations. In order to
bridge the gap between AI and computing systems, we are trying to explore how
to conduct AI education from the perspective of computing systems. In this
paper, a course practice in intelligent computing architectures are provided to
demonstrate the system education in AI era. The motivation for this course
practice is first introduced as well as the learning orientations. The main
goal of this course aims to teach students for designing AI accelerators on
FPGA platforms. The elaborated course contents include lecture notes and
related technical materials. Especially several practical labs and projects are
detailed illustrated. Finally, some teaching experiences and effects are
discussed as well as some potential improvements in the future.",2022-06-22,2022,2022-06,education
"Can Population-based Engagement Improve Personalisation? A Novel Dataset
  and Experiments","This work explores how population-based engagement prediction can address
cold-start at scale in large learning resource collections. The paper
introduces i) VLE, a novel dataset that consists of content and video based
features extracted from publicly available scientific video lectures coupled
with implicit and explicit signals related to learner engagement, ii) two
standard tasks related to predicting and ranking context-agnostic engagement in
video lectures with preliminary baselines and iii) a set of experiments that
validate the usefulness of the proposed dataset. Our experimental results
indicate that the newly proposed VLE dataset leads to building context-agnostic
engagement prediction models that are significantly performant than ones based
on previous datasets, mainly attributing to the increase of training examples.
VLE dataset's suitability in building models towards Computer Science/
Artificial Intelligence education focused on e-learning/ MOOC use-cases is also
evidenced. Further experiments in combining the built model with a
personalising algorithm show promising improvements in addressing the
cold-start problem encountered in educational recommenders. This is the largest
and most diverse publicly available dataset to our knowledge that deals with
learner engagement prediction tasks. The dataset, helper tools, descriptive
statistics and example code snippets are available publicly.",2022-06-22,2022,2022-06,education
"Human-AI communication for human-human communication: Applying
  interpretable unsupervised anomaly detection to executive coaching","In this paper, we discuss the potential of applying unsupervised anomaly
detection in constructing AI-based interactive systems that deal with highly
contextual situations, i.e., human-human communication, in collaboration with
domain experts. We reached this approach of utilizing unsupervised anomaly
detection through our experience of developing a computational support tool for
executive coaching, which taught us the importance of providing interpretable
results so that expert coaches can take both the results and contexts into
account. The key idea behind this approach is to leave room for expert coaches
to unleash their open-ended interpretations, rather than simplifying the nature
of social interactions to well-defined problems that are tractable by
conventional supervised algorithms. In addition, we found that this approach
can be extended to nurturing novice coaches; by prompting them to interpret the
results from the system, it can provide the coaches with educational
opportunities. Although the applicability of this approach should be validated
in other domains, we believe that the idea of leveraging unsupervised anomaly
detection to construct AI-based interactive systems would shed light on another
direction of human-AI communication.",2022-06-22,2022,2022-06,education
"Experts' View on Challenges and Needs for Fairness in Artificial
  Intelligence for Education","In recent years, there has been a stimulating discussion on how artificial
intelligence (AI) can support the science and engineering of intelligent
educational applications. Many studies in the field are proposing actionable
data mining pipelines and machine-learning models driven by learning-related
data. The potential of these pipelines and models to amplify unfairness for
certain categories of students is however receiving increasing attention. If AI
applications are to have a positive impact on education, it is crucial that
their design considers fairness at every step. Through anonymous surveys and
interviews with experts (researchers and practitioners) who have published
their research at top-tier educational conferences in the last year, we
conducted the first expert-driven systematic investigation on the challenges
and needs for addressing fairness throughout the development of educational
systems based on AI. We identified common and diverging views about the
challenges and the needs faced by educational technologies experts in practice,
that lead the community to have a clear understanding on the main questions
raising doubts in this topic. Based on these findings, we highlighted
directions that will facilitate the ongoing research towards fairer AI for
education.",2022-06-23,2022,2022-06,education
"A Design of A Simple Yet Effective Exercise Recommendation System in
  K-12 Online Learning","We propose a simple but effective method to recommend exercises with high
quality and diversity for students. Our method is made up of three key
components: (1) candidate generation module; (2) diversity-promoting module;
and (3) scope restriction module. The proposed method improves the overall
recommendation performance in terms of recall, and increases the diversity of
the recommended candidates by 0.81\% compared to the baselines.",2022-06-23,2022,2022-06,education
"DialogID: A Dialogic Instruction Dataset for Improving Teaching
  Effectiveness in Online Environments","Online dialogic instructions are a set of pedagogical instructions used in
real-world online educational contexts to motivate students, help understand
learning materials, and build effective study habits. In spite of the
popularity and advantages of online learning, the education technology and
educational data mining communities still suffer from the lack of large-scale,
high-quality, and well-annotated teaching instruction datasets to study
computational approaches to automatically detect online dialogic instructions
and further improve the online teaching effectiveness. Therefore, in this
paper, we present a dataset of online dialogic instruction detection,
\textsc{DialogID}, which contains 30,431 effective dialogic instructions. These
teaching instructions are well annotated into 8 categories. Furthermore, we
utilize the prevalent pre-trained language models (PLMs) and propose a simple
yet effective adversarial training learning paradigm to improve the quality and
generalization of dialogic instruction detection. Extensive experiments
demonstrate that our approach outperforms a wide range of baseline methods. The
data and our code are available for research purposes from:
https://github.com/ai4ed/DialogID.",2022-06-24,2022,2022-06,education
Implementing a Chatbot Solution for Learning Management System,"Innovation is a key component in trying new solutions for the students to
learn efficiently and in ways that correspond to their own experience, where
chatbots are one of these new solutions. One of the main problem that chatbots
face today is to mimic human language, where they try to find the best answer
to an input, which is not how a human conversation usually works, rather taking
into account the previous messages and building onto them. Extreme programming
methodology was chosen to use integrate ChatterBot, Pyside2, web scraping and
Tampermonkey into Blackboard as a test case. Problems occurred with the bot and
more training was needed for the bot to work perfectly, but the integration and
web scraping worked, giving us a chatbot that was able to talk with. We showed
the plausibility of integrating an AI bot in an educational setting.",2022-06-27,2022,2022-06,education
"Kwame for Science: An AI Teaching Assistant Based on Sentence-BERT for
  Science Education in West Africa","Africa has a high student-to-teacher ratio which limits students' access to
teachers. Consequently, students struggle to get answers to their questions. In
this work, we extended Kwame, our previous AI teaching assistant, adapted it
for science education, and deployed it as a web app. Kwame for Science answers
questions of students based on the Integrated Science subject of the West
African Senior Secondary Certificate Examination (WASSCE). Kwame for Science is
a Sentence-BERT-based question-answering web app that displays 3 paragraphs as
answers along with a confidence score in response to science questions.
Additionally, it displays the top 5 related past exam questions and their
answers in addition to the 3 paragraphs. Our preliminary evaluation of the
Kwame for Science with a 2.5-week real-world deployment showed a top 3 accuracy
of 87.5% (n=56) with 190 users across 11 countries. Kwame for Science will
enable the delivery of scalable, cost-effective, and quality remote education
to millions of people across Africa.",2022-06-28,2022,2022-06,education
"Complementary artificial intelligence designed to augment human
  discovery","Neither artificial intelligence designed to play Turing's imitation game, nor
augmented intelligence built to maximize the human manipulation of information
are tuned to accelerate innovation and improve humanity's collective advance
against its greatest challenges. We reconceptualize and pilot beneficial AI to
radically augment human understanding by complementing rather than competing
with human cognitive capacity. Our approach to complementary intelligence
builds on insights underlying the wisdom of crowds, which hinges on the
independence and diversity of crowd members' information and approach. By
programmatically incorporating information on the evolving distribution of
scientific expertise from research papers, our approach follows the
distribution of content in the literature while avoiding the scientific crowd
and the hypotheses cognitively available to it. We use this approach to
generate valuable predictions for what materials possess valuable
energy-related properties (e.g., thermoelectricity), and what compounds possess
valuable medical properties (e.g., asthma) that complement the human scientific
crowd. We demonstrate that our complementary predictions, if identified by
human scientists and inventors at all, are only discovered years further into
the future. When we evaluate the promise of our predictions with
first-principles equations, we demonstrate that increased complementarity of
our predictions does not decrease and in some cases increases the probability
that the predictions possess the targeted properties. In summary, by tuning AI
to avoid the crowd, we can generate hypotheses unlikely to be imagined or
pursued until the distant future and promise to punctuate scientific advance.
By identifying and correcting for collective human bias, these models also
suggest opportunities to improve human prediction by reformulating science
education for discovery.",2022-07-02,2022,2022-07,education
Privacy-Preserving Synthetic Educational Data Generation,"Institutions collect massive learning traces but they may not disclose it for
privacy issues. Synthetic data generation opens new opportunities for research
in education. In this paper we present a generative model for educational data
that can preserve the privacy of participants, and an evaluation framework for
comparing synthetic data generators. We show how naive pseudonymization can
lead to re-identification threats and suggest techniques to guarantee privacy.
We evaluate our method on existing massive educational open datasets.",2022-07-07,2022,2022-07,education
Reflections on the Evolution of Computer Science Education,"Computer Science education has been evolving over the years to reflect
applied realities. Until about a decade ago, theory of computation, algorithm
design and system software dominated the curricula. Most courses were
considered core and were hence mandatory; the programme structure did not allow
much of a choice or variety. This column analyses why this changed Circa 2010
when elective subjects across scores of topics become part of mainstream
education to reflect the on-going lateral acceleration of Computer Science.
Fundamental discoveries in artificial intelligence, machine learning,
virtualization and cloud computing are several decades old. Many core theories
in data science are centuries old. Yet their leverage exploded only after Circa
2010, when the stage got set for people-centric problem solving in massive
scale. This was due in part to the rush of innovative real-world applications
that reached the common man through the ubiquitous smart phone. AI/ML modules
arrived in popular programming languages; they could be used to build and train
models on powerful - yet affordable - compute on public clouds reachable
through high-speed Internet connectivity. Academia responded by adapting
Computer Science curricula to align it with the changing technology landscape.
The goal of this experiential piece is to trigger a lively discussion on the
past and future of Computer Science education.",2022-07-09,2022,2022-07,education
"Wide & Deep Learning for Judging Student Performance in Online
  One-on-one Math Classes","In this paper, we investigate the opportunities of automating the judgment
process in online one-on-one math classes. We build a Wide & Deep framework to
learn fine-grained predictive representations from a limited amount of noisy
classroom conversation data that perform better student judgments. We conducted
experiments on the task of predicting students' levels of mastery of example
questions and the results demonstrate the superiority and availability of our
model in terms of various evaluation metrics.",2022-07-13,2022,2022-07,education
"Forecasting the Short-Term Energy Consumption Using Random Forests and
  Gradient Boosting","This paper analyzes comparatively the performance of Random Forests and
Gradient Boosting algorithms in the field of forecasting the energy consumption
based on historical data. The two algorithms are applied in order to forecast
the energy consumption individually, and then combined together by using a
Weighted Average Ensemble Method. The comparison among the achieved
experimental results proves that the Weighted Average Ensemble Method provides
more accurate results than each of the two algorithms applied alone.",2022-07-25,2022,2022-07,education
"Raising Student Completion Rates with Adaptive Curriculum and Contextual
  Bandits","We present an adaptive learning Intelligent Tutoring System, which uses
model-based reinforcement learning in the form of contextual bandits to assign
learning activities to students. The model is trained on the trajectories of
thousands of students in order to maximize their exercise completion rates and
continues to learn online, automatically adjusting itself to new activities. A
randomized controlled trial with students shows that our model leads to
superior completion rates and significantly improved student engagement when
compared to other approaches. Our approach is fully-automated unlocking new
opportunities for learning experience personalization.",2022-07-28,2022,2022-07,education
"Big Data and Analytics Implementation in Tertiary Institutions to
  Predict Students Performance in Nigeria","The term Big Data has been coined to refer to the gargantuan bulk of data
that cannot be dealt with by traditional data-handling techniques. Big Data is
still a novel concept, and in the following literature, we intend to elaborate
on it in a palpable fashion. It commences with the concept of the subject in
itself, along with its properties and the two general approaches to dealing
with it. Big Data provides an opportunity for educational Institutions to use
their Information Technology resources strategically to improve educational
quality, guide students to higher completion rates and improve student
persistence and outcomes. This paper explores the attributes of big data that
are relevant to educational institutions, investigates the factors influencing
the adoption of big data and analytics in learning institutions, and seeks to
establish the limiting factors hindering the use of big data in Institutions of
higher learning. A survey research design was adopted in conducting this
research, and Questionnaires were the instrument employed for data collection.",2022-07-29,2022,2022-07,education
Proceedings 38th International Conference on Logic Programming,"ICLP is the premier international event for presenting research in logic
programming. Contributions to ICLP 2022 were sought in all areas of logic
programming, including but not limited to: Foundations: Semantics, Formalisms,
Nonmonotonic reasoning, Knowledge representation. Languages issues:
Concurrency, Objects, Coordination, Mobility, Higher order, Types, Modes,
Assertions, Modules, Meta-programming, Logic-based domain-specific languages,
Programming techniques. Programming support: Program analysis, Transformation,
Validation, Verification, Debugging, Profiling, Testing, Execution
visualization. Implementation: Compilation, Virtual machines, Memory
management, Parallel and Distributed execution, Constraint handling rules,
Tabling, Foreign interfaces, User interfaces. Related Paradigms and Synergies:
Inductive and coinductive logic programming, Constraint logic programming,
Answer set programming, Interaction with SAT, SMT and CSP solvers, Theorem
proving, Argumentation, Probabilistic programming, Machine learning.
Applications: Databases, Big data, Data integration and federation, Software
engineering, Natural language processing, Web and semantic web, Agents,
Artificial intelligence, Computational life sciences, Cyber-security, Robotics,
Education.",2022-08-04,2022,2022-08,education
Using Adaptive Experiments to Rapidly Help Students,"Adaptive experiments can increase the chance that current students obtain
better outcomes from a field experiment of an instructional intervention. In
such experiments, the probability of assigning students to conditions changes
while more data is being collected, so students can be assigned to
interventions that are likely to perform better. Digital educational
environments lower the barrier to conducting such adaptive experiments, but
they are rarely applied in education. One reason might be that researchers have
access to few real-world case studies that illustrate the advantages and
disadvantages of these experiments in a specific context. We evaluate the
effect of homework email reminders in students by conducting an adaptive
experiment using the Thompson Sampling algorithm and compare it to a
traditional uniform random experiment. We present this as a case study on how
to conduct such experiments, and we raise a range of open questions about the
conditions under which adaptive randomized experiments may be more or less
useful.",2022-08-10,2022,2022-08,education
"Simply Logical -- Intelligent Reasoning by Example (Fully Interactive
  Online Edition)","""Simply Logical -- Intelligent Reasoning by Example"" by Peter Flach was first
published by John Wiley in 1994. It could be purchased as book-only or with a
3.5 inch diskette containing the SWI-Prolog programmes printed in the book (for
various operating systems). In 2007 the copyright reverted back to the author
at which point the book and programmes were made freely available online; the
print version is no longer distributed through John Wiley publishers. In 2015,
as a pilot, we ported most of the original book into an online, interactive
website using SWI-Prolog's SWISH platform. Since then, we launched the Simply
Logical open source organisation committed to maintaining a suite of freely
available interactive online educational resources about Artificial
Intelligence and Logic Programming with Prolog. With the advent of new
educational technologies we were inspired to rebuild the book from the ground
up using the Jupyter Book platform enhanced with a collection of bespoke
plugins that implement, among other things, interactive SWI-Prolog code blocks
that can be executed directly in a web browser. This new version is more
modular, easier to maintain, and can be split into custom teaching modules, in
addition to being modern-looking, visually appealing, and compatible with a
range of (mobile) devices of varying screen sizes.",2022-08-14,2022,2022-08,education
"Multimodal Lecture Presentations Dataset: Understanding Multimodality in
  Educational Slides","Lecture slide presentations, a sequence of pages that contain text and
figures accompanied by speech, are constructed and presented carefully in order
to optimally transfer knowledge to students. Previous studies in multimedia and
psychology attribute the effectiveness of lecture presentations to their
multimodal nature. As a step toward developing AI to aid in student learning as
intelligent teacher assistants, we introduce the Multimodal Lecture
Presentations dataset as a large-scale benchmark testing the capabilities of
machine learning models in multimodal understanding of educational content. Our
dataset contains aligned slides and spoken language, for 180+ hours of video
and 9000+ slides, with 10 lecturers from various subjects (e.g., computer
science, dentistry, biology). We introduce two research tasks which are
designed as stepping stones towards AI agents that can explain (automatically
captioning a lecture presentation) and illustrate (synthesizing visual figures
to accompany spoken explanations) educational content. We provide manual
annotations to help implement these two research tasks and evaluate
state-of-the-art models on them. Comparing baselines and human student
performances, we find that current models struggle in (1) weak crossmodal
alignment between slides and spoken text, (2) learning novel visual mediums,
(3) technical language, and (4) long-range sequences. Towards addressing this
issue, we also introduce PolyViLT, a multimodal transformer trained with a
multi-instance learning loss that is more effective than current approaches. We
conclude by shedding light on the challenges and opportunities in multimodal
understanding of educational presentations.",2022-08-17,2022,2022-08,education
"NeurIPS Competition Instructions and Guide: Causal Insights for Learning
  Paths in Education","In this competition, participants will address two fundamental causal
challenges in machine learning in the context of education using time-series
data. The first is to identify the causal relationships between different
constructs, where a construct is defined as the smallest element of learning.
The second challenge is to predict the impact of learning one construct on the
ability to answer questions on other constructs. Addressing these challenges
will enable optimisation of students' knowledge acquisition, which can be
deployed in a real edtech solution impacting millions of students. Participants
will run these tasks in an idealised environment with synthetic data and a
real-world scenario with evaluation data collected from a series of A/B tests.",2022-08-17,2022,2022-08,education
DBE-KT22: A Knowledge Tracing Dataset Based on Online Student Evaluation,"Online education has gained an increasing importance over the last decade for
providing affordable high-quality education to students worldwide. This has
been further magnified during the global pandemic as more students switched to
study online. The majority of online education tasks, e.g., course
recommendation, exercise recommendation, or automated evaluation, depends on
tracking students' knowledge progress. This is known as the \emph{Knowledge
Tracing} problem in the literature. Addressing this problem requires collecting
student evaluation data that can reflect their knowledge evolution over time.
In this paper, we propose a new knowledge tracing dataset named Database
Exercises for Knowledge Tracing (DBE-KT22) that is collected from an online
student exercise system in a course taught at the Australian National
University in Australia. We discuss the characteristics of the DBE-KT22 dataset
and contrast it with the existing datasets in the knowledge tracing literature.
Our dataset is available for public access through the Australian Data Archive
platform.",2022-08-19,2022,2022-08,education
"A systematic review of research on the use and impact of technology for
  learning Chinese","In light of technological development enforced by the pandemic, learning
Chinese has become more digitalised. Confucius institutes went online and now
follow 2021 to 2025 Action Plans for the Construction of Teaching Resources for
International Chinese Education and International Chinese Online Education. New
ways of learning Chinese emerged, such as educational games and intelligent
tutoring systems ITS, some of them based on artificial intelligence. The aim of
this systematic review is to examine recent research published in ScienceDirect
and Scopus databases on the use and impact of educational games and ITS in
Chinese language learning. A total of 29 selected studies were analysed.",2022-08-29,2022,2022-08,education
"A Dataset and Baseline Approach for Identifying Usage States from
  Non-Intrusive Power Sensing With MiDAS IoT-based Sensors","The state identification problem seeks to identify power usage patterns of
any system, like buildings or factories, of interest. In this challenge paper,
we make power usage dataset available from 8 institutions in manufacturing,
education and medical institutions from the US and India, and an initial
un-supervised machine learning based solution as a baseline for the community
to accelerate research in this area.",2022-08-30,2022,2022-08,education
"Why Are Some Online Educational Programs Successful? Student Cognition
  and Success","Massive Open Online Courses (MOOCs) once offered the promise of accessibility
and affordability. However, MOOCs typically lack expert feedback and social
interaction, and have low student engagement and retention. Thus, alternative
programs for online education have emerged including an online graduate program
in computer science at a major public university in USA. This program is
considered a success with over 9000 students now enrolled in the program. We
adopt the perspective of cognitive science to answer the question why do only
some online educational courses succeed? We measure learner motivation and
self-regulation in one course in the program, specifically a course on
artificial intelligence (AI). Surveys of students indicate that students
self-reported assessments of self-efficacy, cognitive strategy use, and
intrinsic value of the course are not only fairly high, but also generally
increase over the course of learning. This data suggests that the online AI
course might be a success because the students have high self-efficacy and the
class fosters self-regulated learning.",2022-09-04,2022,2022-09,education
"Lost in Translation: Reimagining the Machine Learning Life Cycle in
  Education","Machine learning (ML) techniques are increasingly prevalent in education,
from their use in predicting student dropout, to assisting in university
admissions, and facilitating the rise of MOOCs. Given the rapid growth of these
novel uses, there is a pressing need to investigate how ML techniques support
long-standing education principles and goals. In this work, we shed light on
this complex landscape drawing on qualitative insights from interviews with
education experts. These interviews comprise in-depth evaluations of ML for
education (ML4Ed) papers published in preeminent applied ML conferences over
the past decade. Our central research goal is to critically examine how the
stated or implied education and societal objectives of these papers are aligned
with the ML problems they tackle. That is, to what extent does the technical
problem formulation, objectives, approach, and interpretation of results align
with the education problem at hand. We find that a cross-disciplinary gap
exists and is particularly salient in two parts of the ML life cycle: the
formulation of an ML problem from education goals and the translation of
predictions to interventions. We use these insights to propose an extended ML
life cycle, which may also apply to the use of ML in other domains. Our work
joins a growing number of meta-analytical studies across education and ML
research, as well as critical analyses of the societal impact of ML.
Specifically, it fills a gap between the prevailing technical understanding of
machine learning and the perspective of education researchers working with
students and in policy.",2022-09-08,2022,2022-09,education
"Artificial Intelligence for Scientific Research: Authentic Research
  Education Framework","We report a framework that enables the wide adoption of authentic research
educational methodology at various schools by addressing common barriers. The
guiding principles we present were applied to implement a program in which
teams of students with complementary skills develop useful artificial
intelligence (AI) solutions for researchers in natural sciences. To accomplish
this, we work with research laboratories that reveal/specify their needs, and
then our student teams work on the discovery, design, and development of an AI
solution for unique problems using a consulting-like arrangement. To date, our
group has been operating at New York University (NYU) for seven consecutive
semesters, has engaged more than a hundred students, ranging from first-year
college students to master's candidates, and has worked with more than twenty
projects and collaborators. While creating education benefits for students, our
approach also directly benefits scientists, who get an opportunity to evaluate
the usefulness of machine learning for their specific needs.",2022-09-19,2022,2022-09,education
Social Assistive Robotics for Autistic Children,"This paper introduces the project Social Assistive Robotics for Autistic
Children aimed at using robotic therapy for autism. The goal of the project is
testing autistic children's interactions with the social robot NAO. In
particular the robot will support the operators (psychologists, educators,
speech therapists etc.) in their work. The innovative aspect of the project is
that the children robot interaction will consider the children's emotions and
specific features and the robot will adapt its behavior accordingly.",2022-09-25,2022,2022-09,education
"Mitigating Attacks on Artificial Intelligence-based Spectrum Sensing for
  Cellular Network Signals","Cellular networks (LTE, 5G, and beyond) are dramatically growing with high
demand from consumers and more promising than the other wireless networks with
advanced telecommunication technologies. The main goal of these networks is to
connect billions of devices, systems, and users with high-speed data
transmission, high cell capacity, and low latency, as well as to support a wide
range of new applications, such as virtual reality, metaverse, telehealth,
online education, autonomous and flying vehicles, advanced manufacturing, and
many more. To achieve these goals, spectrum sensing has been paid more
attention, along with new approaches using artificial intelligence (AI) methods
for spectrum management in cellular networks. This paper provides a
vulnerability analysis of spectrum sensing approaches using AI-based semantic
segmentation models for identifying cellular network signals under adversarial
attacks with and without defensive distillation methods. The results showed
that mitigation methods can significantly reduce the vulnerabilities of
AI-based spectrum sensing models against adversarial attacks.",2022-09-27,2022,2022-09,education
Real-Time Automated Answer Scoring,"In recent years, the role of big data analytics has exponentially grown and
is now slowly making its way into the education industry. Several attempts are
being made in this sphere in order to improve the quality of education being
provided to students and while many collaborations have been carried out
before, automated scoring of answers has been explored to a rather limited
extent. One of the biggest hurdles to choosing constructed-response assessments
over multiple-choice assessments is the effort and large cost that comes with
their evaluation and this is precisely the issue that this project aims to
solve. The aim is to accept raw-input from the student in the form of their
answer, preprocess the answer, and automatically score the answer. In addition,
we have made this a real-time system that captures ""snapshots"" of the writer's
progress with respect to the answer, allowing us to unearth trends with respect
to the way a student thinks, and how the student has arrived at their final
answer.",2022-10-13,2022,2022-10,education
"A Framework for Undergraduate Data Collection Strategies for Student
  Support Recommendation Systems in Higher Education","Understanding which student support strategies mitigate dropout and improve
student retention is an important part of modern higher educational research.
One of the largest challenges institutions of higher learning currently face is
the scalability of student support. Part of this is due to the shortage of
staff addressing the needs of students, and the subsequent referral pathways
associated to provide timeous student support strategies. This is further
complicated by the difficulty of these referrals, especially as students are
often faced with a combination of administrative, academic, social, and
socio-economic challenges. A possible solution to this problem can be a
combination of student outcome predictions and applying algorithmic recommender
systems within the context of higher education. While much effort and detail
has gone into the expansion of explaining algorithmic decision making in this
context, there is still a need to develop data collection strategies Therefore,
the purpose of this paper is to outline a data collection framework specific to
recommender systems within this context in order to reduce collection biases,
understand student characteristics, and find an ideal way to infer optimal
influences on the student journey. If confirmation biases, challenges in data
sparsity and the type of information to collect from students are not
addressed, it will have detrimental effects on attempts to assess and evaluate
the effects of these systems within higher education.",2022-10-16,2022,2022-10,education
EDUKG: a Heterogeneous Sustainable K-12 Educational Knowledge Graph,"Web and artificial intelligence technologies, especially semantic web and
knowledge graph (KG), have recently raised significant attention in educational
scenarios. Nevertheless, subject-specific KGs for K-12 education still lack
sufficiency and sustainability from knowledge and data perspectives. To tackle
these issues, we propose EDUKG, a heterogeneous sustainable K-12 Educational
Knowledge Graph. We first design an interdisciplinary and fine-grained ontology
for uniformly modeling knowledge and resource in K-12 education, where we
define 635 classes, 445 object properties, and 1314 datatype properties in
total. Guided by this ontology, we propose a flexible methodology for
interactively extracting factual knowledge from textbooks. Furthermore, we
establish a general mechanism based on our proposed generalized entity linking
system for EDUKG's sustainable maintenance, which can dynamically index
numerous heterogeneous resources and data with knowledge topics in EDUKG. We
further evaluate EDUKG to illustrate its sufficiency, richness, and
variability. We publish EDUKG with more than 252 million entities and 3.86
billion triplets. Our code and data repository is now available at
https://github.com/THU-KEG/EDUKG.",2022-10-21,2022,2022-10,education
"ClipBot: an educational, physically impaired robot that learns to walk
  via genetic algorithm optimization","Educational robots allow experimenting with a variety of principles from
mechanics, electronics, and informatics. Here we propose ClipBot, a low-cost,
do-it-yourself, robot whose skeleton is made of two paper clips. An Arduino
nano microcontroller actuates two servo motors that move the paper clips.
However, such mechanical configuration confers physical impairments to
movement. This creates the need for and allows experimenting with artificial
intelligence methods to overcome hardware limitations. We report our experience
in the usage of this robot during the study week 'fascinating informatics',
organized by the Swiss Foundation Schweizer Jugend Forscht (www.sjf.ch).
Students at the high school level were asked to implement a genetic algorithm
to optimize the movements of the robot until it learned to walk. Such a
methodology allowed the robot to learn the motor actuation scheme yielding
straight movement in the forward direction using less than 20 iterations.",2022-10-26,2022,2022-10,education
"Artificial Intelligence and Life in 2030: The One Hundred Year Study on
  Artificial Intelligence","In September 2016, Stanford's ""One Hundred Year Study on Artificial
Intelligence"" project (AI100) issued the first report of its planned long-term
periodic assessment of artificial intelligence (AI) and its impact on society.
It was written by a panel of 17 study authors, each of whom is deeply rooted in
AI research, chaired by Peter Stone of the University of Texas at Austin. The
report, entitled ""Artificial Intelligence and Life in 2030,"" examines eight
domains of typical urban settings on which AI is likely to have impact over the
coming years: transportation, home and service robots, healthcare, education,
public safety and security, low-resource communities, employment and workplace,
and entertainment. It aims to provide the general public with a scientifically
and technologically accurate portrayal of the current state of AI and its
potential and to help guide decisions in industry and governments, as well as
to inform research and development in the field. The charge for this report was
given to the panel by the AI100 Standing Committee, chaired by Barbara Grosz of
Harvard University.",2022-10-31,2022,2022-10,education
Reinforcement Learning in Education: A Multi-Armed Bandit Approach,"Advances in reinforcement learning research have demonstrated the ways in
which different agent-based models can learn how to optimally perform a task
within a given environment. Reinforcement leaning solves unsupervised problems
where agents move through a state-action-reward loop to maximize the overall
reward for the agent, which in turn optimizes the solving of a specific problem
in a given environment. However, these algorithms are designed based on our
understanding of actions that should be taken in a real-world environment to
solve a specific problem. One such problem is the ability to identify,
recommend and execute an action within a system where the users are the
subject, such as in education. In recent years, the use of blended learning
approaches integrating face-to-face learning with online learning in the
education context, has in-creased. Additionally, online platforms used for
education require the automation of certain functions such as the
identification, recommendation or execution of actions that can benefit the
user, in this sense, the student or learner. As promising as these scientific
advances are, there is still a need to conduct research in a variety of
different areas to ensure the successful deployment of these agents within
education systems. Therefore, the aim of this study was to contextualise and
simulate the cumulative reward within an environment for an intervention
recommendation problem in the education context.",2022-11-01,2022,2022-11,education
A device-interaction model for users with special needs,"Interaction is a fundamental part of using any computer system but it is
still an issue for people with special needs. In order to improve this
situation, this paper describes a new device-interaction model based on
adaptation rules for user models. The aim is the adaptation at the interaction
level, taking into account the interaction device features in order to improve
the usability through the user experience in the education sector. In the
evaluation process, several students from a special education center have
participated. These students have either a physical or sensory disability or
autism. The results are promising enough to consider that this model will be
able to help students with disabilities to interact with a computer system
which will inevitably provide tremendous benefits to their academic and
personal development.",2022-11-01,2022,2022-11,education
"Liability regimes in the age of AI: a use-case driven analysis of the
  burden of proof","New emerging technologies powered by Artificial Intelligence (AI) have the
potential to disruptively transform our societies for the better. In
particular, data-driven learning approaches (i.e., Machine Learning (ML)) have
been a true revolution in the advancement of multiple technologies in various
application domains. But at the same time there is growing concern about
certain intrinsic characteristics of these methodologies that carry potential
risks to both safety and fundamental rights. Although there are mechanisms in
the adoption process to minimize these risks (e.g., safety regulations), these
do not exclude the possibility of harm occurring, and if this happens, victims
should be able to seek compensation. Liability regimes will therefore play a
key role in ensuring basic protection for victims using or interacting with
these systems. However, the same characteristics that make AI systems
inherently risky, such as lack of causality, opacity, unpredictability or their
self and continuous learning capabilities, may lead to considerable
difficulties when it comes to proving causation. This paper presents three case
studies, as well as the methodology to reach them, that illustrate these
difficulties. Specifically, we address the cases of cleaning robots, delivery
drones and robots in education. The outcome of the proposed analysis suggests
the need to revise liability regimes to alleviate the burden of proof on
victims in cases involving AI technologies.",2022-11-03,2022,2022-11,education
"End-to-End Evaluation of a Spoken Dialogue System for Learning Basic
  Mathematics","The advances in language-based Artificial Intelligence (AI) technologies
applied to build educational applications can present AI for social-good
opportunities with a broader positive impact. Across many disciplines,
enhancing the quality of mathematics education is crucial in building critical
thinking and problem-solving skills at younger ages. Conversational AI systems
have started maturing to a point where they could play a significant role in
helping students learn fundamental math concepts. This work presents a
task-oriented Spoken Dialogue System (SDS) built to support play-based learning
of basic math concepts for early childhood education. The system has been
evaluated via real-world deployments at school while the students are
practicing early math concepts with multimodal interactions. We discuss our
efforts to improve the SDS pipeline built for math learning, for which we
explore utilizing MathBERT representations for potential enhancement to the
Natural Language Understanding (NLU) module. We perform an end-to-end
evaluation using real-world deployment outputs from the Automatic Speech
Recognition (ASR), Intent Recognition, and Dialogue Manager (DM) components to
understand how error propagation affects the overall performance in real-world
scenarios.",2022-11-07,2022,2022-11,education
Automatic Creativity Measurement in Scratch Programs Across Modalities,"Promoting creativity is considered an important goal of education, but
creativity is notoriously hard to measure.In this paper, we make the journey
fromdefining a formal measure of creativity that is efficientlycomputable to
applying the measure in a practical domain. The measure is general and relies
on coretheoretical concepts in creativity theory, namely fluency, flexibility,
and originality, integratingwith prior cognitive science literature. We adapted
the general measure for projects in the popular visual programming language
Scratch.We designed a machine learning model for predicting the creativity of
Scratch projects, trained and evaluated on human expert creativity assessments
in an extensive user study. Our results show that opinions about creativity in
Scratch varied widely across experts. The automatic creativity assessment
aligned with the assessment of the human experts more than the experts agreed
with each other. This is a first step in providing computational models for
measuring creativity that can be applied to educational technologies, and to
scale up the benefit of creativity education in schools.",2022-11-07,2022,2022-11,education
"Collaborative and AI-aided Exam Question Generation using Wikidata in
  Education","Since the COVID-19 outbreak, the use of digital learning or education
platforms has significantly increased. Teachers now digitally distribute
homework and provide exercise questions. In both cases, teachers need to
continuously develop novel and individual questions. This process can be very
time-consuming and should be facilitated and accelerated both through exchange
with other teachers and by using Artificial Intelligence (AI) capabilities. To
address this need, we propose a multilingual Wikimedia framework that allows
for collaborative worldwide teacher knowledge engineering and subsequent
AI-aided question generation, test, and correction. As a proof of concept, we
present >>PhysWikiQuiz<<, a physics question generation and test engine. Our
system (hosted by Wikimedia at https://physwikiquiz.wmflabs.org) retrieves
physics knowledge from the open community-curated database Wikidata. It can
generate questions in different variations and verify answer values and units
using a Computer Algebra System (CAS). We evaluate the performance on a public
benchmark dataset at each stage of the system workflow. For an average formula
with three variables, the system can generate and correct up to 300 questions
for individual students based on a single formula concept name as input by the
teacher.",2022-11-15,2022,2022-11,education
"edBB-Demo: Biometrics and Behavior Analysis for Online Educational
  Platforms","We present edBB-Demo, a demonstrator of an AI-powered research platform for
student monitoring in remote education. The edBB platform aims to study the
challenges associated to user recognition and behavior understanding in digital
platforms. This platform has been developed for data collection, acquiring
signals from a variety of sensors including keyboard, mouse, webcam,
microphone, smartwatch, and an Electroencephalography band. The information
captured from the sensors during the student sessions is modelled in a
multimodal learning framework. The demonstrator includes: i) Biometric user
authentication in an unsupervised environment; ii) Human action recognition
based on remote video analysis; iii) Heart rate estimation from webcam video;
and iv) Attention level estimation from facial expression analysis.",2022-11-16,2022,2022-11,education
"A Combined Approach of Process Mining and Rule-based AI for Study
  Planning and Monitoring in Higher Education","This paper presents an approach of using methods of process mining and
rule-based artificial intelligence to analyze and understand study paths of
students based on campus management system data and study program models.
Process mining techniques are used to characterize successful study paths, as
well as to detect and visualize deviations from expected plans. These insights
are combined with recommendations and requirements of the corresponding study
programs extracted from examination regulations. Here, event calculus and
answer set programming are used to provide models of the study programs which
support planning and conformance checking while providing feedback on possible
study plan violations. In its combination, process mining and rule-based
artificial intelligence are used to support study planning and monitoring by
deriving rules and recommendations for guiding students to more suitable study
paths with higher success rates. Two applications will be implemented, one for
students and one for study program designers.",2022-11-22,2022,2022-11,education
"Metaverse in Education: Vision, Opportunities, and Challenges","Traditional education has been updated with the development of information
technology in human history. Within big data and cyber-physical systems, the
Metaverse has generated strong interest in various applications (e.g.,
entertainment, business, and cultural travel) over the last decade. As a novel
social work idea, the Metaverse consists of many kinds of technologies, e.g.,
big data, interaction, artificial intelligence, game design, Internet
computing, Internet of Things, and blockchain. It is foreseeable that the usage
of Metaverse will contribute to educational development. However, the
architectures of the Metaverse in education are not yet mature enough. There
are many questions we should address for the Metaverse in education. To this
end, this paper aims to provide a systematic literature review of Metaverse in
education. This paper is a comprehensive survey of the Metaverse in education,
with a focus on current technologies, challenges, opportunities, and future
directions. First, we present a brief overview of the Metaverse in education,
as well as the motivation behind its integration. Then, we survey some
important characteristics for the Metaverse in education, including the
personal teaching environment and the personal learning environment. Next, we
envisage what variations of this combination will bring to education in the
future and discuss their strengths and weaknesses. We also review the
state-of-the-art case studies (including technical companies and educational
institutions) for Metaverse in education. Finally, we point out several
challenges and issues in this promising area.",2022-11-27,2022,2022-11,education
"Prioritizing Policies for Furthering Responsible Artificial Intelligence
  in the United States","Several policy options exist, or have been proposed, to further responsible
artificial intelligence (AI) development and deployment. Institutions,
including U.S. government agencies, states, professional societies, and private
and public sector businesses, are well positioned to implement these policies.
However, given limited resources, not all policies can or should be equally
prioritized. We define and review nine suggested policies for furthering
responsible AI, rank each policy on potential use and impact, and recommend
prioritization relative to each institution type. We find that pre-deployment
audits and assessments and post-deployment accountability are likely to have
the highest impact but also the highest barriers to adoption. We recommend that
U.S. government agencies and companies highly prioritize development of
pre-deployment audits and assessments, while the U.S. national legislature
should highly prioritize post-deployment accountability. We suggest that U.S.
government agencies and professional societies should highly prioritize
policies that support responsible AI research and that states should highly
prioritize support of responsible AI education. We propose that companies can
highly prioritize involving community stakeholders in development efforts and
supporting diversity in AI development. We advise lower levels of
prioritization across institutions for AI ethics statements and databases of AI
technologies or incidents. We recognize that no one policy will lead to
responsible AI and instead advocate for strategic policy implementation across
institutions.",2022-11-30,2022,2022-11,education
Ontomathedu Ontology Enrichment Method,"Nowadays, distance learning technologies have become very popular. The recent
pandemic has had a particularly strong impact on the development of distance
education technologies. Kazan Federal University has a distance learning system
based on LMS Moodle. This article describes the structure of the OntoMathEdu
ecosystem aimed at improving the process of teaching school mathematics
courses, and also provides a method for improving the OntoMathEdu ontology
structure based on identifying new connections between contextually related
concepts.",2022-12-01,2022,2022-12,education
The Impact of Socioeconomic Factors on Health Disparities,"High-quality healthcare in the US can be cost-prohibitive for certain
socioeconomic groups. In this paper, we examined data from the US Census and
the CDC to determine the degree to which specific socioeconomic factors
correlate with both specific and general health metrics. We employed visual
analysis to find broad trends and predictive modeling to identify more complex
relationships between variables. Our results indicate that certain
socioeconomic factors, like income and educational attainment, are highly
correlated with aggregate measures of health.",2022-12-01,2022,2022-12,education
"Programming Is Hard -- Or at Least It Used to Be: Educational
  Opportunities And Challenges of AI Code Generation","The introductory programming sequence has been the focus of much research in
computing education. The recent advent of several viable and freely-available
AI-driven code generation tools present several immediate opportunities and
challenges in this domain. In this position paper we argue that the community
needs to act quickly in deciding what possible opportunities can and should be
leveraged and how, while also working on how to overcome or otherwise mitigate
the possible challenges. Assuming that the effectiveness and proliferation of
these tools will continue to progress rapidly, without quick, deliberate, and
concerted efforts, educators will lose advantage in helping shape what
opportunities come to be, and what challenges will endure. With this paper we
aim to seed this discussion within the computing education community.",2022-12-02,2022,2022-12,education
"RIPPLE: Concept-Based Interpretation for Raw Time Series Models in
  Education","Time series is the most prevalent form of input data for educational
prediction tasks. The vast majority of research using time series data focuses
on hand-crafted features, designed by experts for predictive performance and
interpretability. However, extracting these features is labor-intensive for
humans and computers. In this paper, we propose an approach that utilizes
irregular multivariate time series modeling with graph neural networks to
achieve comparable or better accuracy with raw time series clickstreams in
comparison to hand-crafted features. Furthermore, we extend concept activation
vectors for interpretability in raw time series models. We analyze these
advances in the education domain, addressing the task of early student
performance prediction for downstream targeted interventions and instructional
support. Our experimental analysis on 23 MOOCs with millions of combined
interactions over six behavioral dimensions show that models designed with our
approach can (i) beat state-of-the-art educational time series baselines with
no feature extraction and (ii) provide interpretable insights for personalized
interventions. Source code: https://github.com/epfl-ml4ed/ripple/.",2022-12-02,2022,2022-12,education
"Pre-Training With Scientific Text Improves Educational Question
  Generation","With the boom of digital educational materials and scalable e-learning
systems, the potential for realising AI-assisted personalised learning has
skyrocketed. In this landscape, the automatic generation of educational
questions will play a key role, enabling scalable self-assessment when a global
population is manoeuvring their personalised learning journeys. We develop
EduQG, a novel educational question generation model built by adapting a large
language model. Our initial experiments demonstrate that EduQG can produce
superior educational questions by pre-training on scientific text.",2022-12-07,2022,2022-12,education
"Research on College Students' Innovation and Entrepreneurship Education
  from The Perspective of Artificial Intelligence Knowledge-Based Crowdsourcing","Based on the practical process of innovation and entrepreneurship education
for college students in the author's university, this study analyzes and
deconstructs the key concepts of AI knowledge-based crowdsourcing on the basis
of literature research, and analyzes the objective fitting needs of combining
AI knowledge-based crowdsourcing with college students' innovation and
entrepreneurship education practice through a survey and research of a random
sample of college students, and verifies that college students' knowledge and
application of AI knowledge-based crowdsourcing in the learning and practice of
innovation and entrepreneurship The study also verifies the awareness and
application of AI knowledge-based crowdsourcing knowledge by university
students in the learning and practice of innovation and entrepreneurship.",2022-12-12,2022,2022-12,education
ChatGPT: The End of Online Exam Integrity?,"This study evaluated the ability of ChatGPT, a recently developed artificial
intelligence (AI) agent, to perform high-level cognitive tasks and produce text
that is indistinguishable from human-generated text. This capacity raises
concerns about the potential use of ChatGPT as a tool for academic misconduct
in online exams. The study found that ChatGPT is capable of exhibiting critical
thinking skills and generating highly realistic text with minimal input, making
it a potential threat to the integrity of online exams, particularly in
tertiary education settings where such exams are becoming more prevalent.
Returning to invigilated and oral exams could form part of the solution, while
using advanced proctoring techniques and AI-text output detectors may be
effective in addressing this issue, they are not likely to be foolproof
solutions. Further research is needed to fully understand the implications of
large language models like ChatGPT and to devise strategies for combating the
risk of cheating using these tools. It is crucial for educators and
institutions to be aware of the possibility of ChatGPT being used for cheating
and to investigate measures to address it in order to maintain the fairness and
validity of online exams for all students.",2022-12-19,2022,2022-12,education
"Simplifying Causality: A Brief Review of Philosophical Views and
  Definitions with Examples from Economics, Education, Medicine, Policy,
  Physics and Engineering","This short paper compiles the big ideas behind some philosophical views,
definitions, and examples of causality. This collection spans the realms of the
four commonly adopted approaches to causality: Humes regularity,
counterfactual, manipulation, and mechanisms. This short review is motivated by
presenting simplified views and definitions and then supplements them with
examples from various fields, including economics, education, medicine,
politics, physics, and engineering. It is the hope that this short review comes
in handy for new and interested readers with little knowledge of causality and
causal inference.",2022-12-27,2022,2022-12,education
"Unpacking the ""Black Box"" of AI in Education","Recent advances in Artificial Intelligence (AI) have sparked renewed interest
in its potential to improve education. However, AI is a loose umbrella term
that refers to a collection of methods, capabilities, and limitations-many of
which are often not explicitly articulated by researchers, education technology
companies, or other AI developers. In this paper, we seek to clarify what ""AI""
is and the potential it holds to both advance and hamper educational
opportunities that may improve the human condition. We offer a basic
introduction to different methods and philosophies underpinning AI, discuss
recent advances, explore applications to education, and highlight key
limitations and risks. We conclude with a set of questions that educationalists
may ask as they encounter AI in their research and practice. Our hope is to
make often jargon-laden terms and concepts accessible, so that all are equipped
to understand, interrogate, and ultimately shape the development of human
centered AI in education.",2022-12-31,2022,2022-12,education
"From Robots to Books: An Introduction to Smart Applications of AI in
  Education (AIEd)","The world around us has undergone a radical transformation due to rapid
technological advancement in recent decades. The industry of the future
generation is evolving, and artificial intelligence is the following change in
the making popularly known as Industry 4.0. Indeed, experts predict that
artificial intelligence(AI) will be the main force behind the following
significant virtual shift in the way we stay, converse, study, live,
communicate and conduct business. All facets of our social connection are being
transformed by this growing technology. One of the newest areas of educational
technology is Artificial Intelligence in the field of Education(AIEd).This
study emphasizes the different applications of artificial intelligence in
education from both an industrial and academic standpoint. It highlights the
most recent contextualized learning novel transformative evaluations and
advancements in sophisticated tutoring systems. It analyses the AIEd's ethical
component and the influence of the transition on people, particularly students
and instructors as well. Finally, this article touches on AIEd's potential
future research and practices. The goal of this study is to introduce the
present-day applications to its intended audience.",2023-01-11,2023,2023-01,education
"Conceptual Framework and Documentation Standards of Cystoscopic Media
  Content for Artificial Intelligence","Background: The clinical documentation of cystoscopy includes visual and
textual materials. However, the secondary use of visual cystoscopic data for
educational and research purposes remains limited due to inefficient data
management in routine clinical practice. Methods: A conceptual framework was
designed to document cystoscopy in a standardized manner with three major
sections: data management, annotation management, and utilization management. A
Swiss-cheese model was proposed for quality control and root cause analyses. We
defined the infrastructure required to implement the framework with respect to
FAIR (findable, accessible, interoperable, re-usable) principles. We applied
two scenarios exemplifying data sharing for research and educational projects
to ensure the compliance with FAIR principles. Results: The framework was
successfully implemented while following FAIR principles. The cystoscopy atlas
produced from the framework could be presented in an educational web portal; a
total of 68 full-length qualitative videos and corresponding annotation data
were sharable for artificial intelligence projects covering frame
classification and segmentation problems at case, lesion and frame levels.
Conclusion: Our study shows that the proposed framework facilitates the storage
of the visual documentation in a standardized manner and enables FAIR data for
education and artificial intelligence research.",2023-01-14,2023,2023-01,education
"Monotonicity for AI ethics and society: An empirical study of the
  monotonic neural additive model in criminology, education, health care, and
  finance","Algorithm fairness in the application of artificial intelligence (AI) is
essential for a better society. As the foundational axiom of social mechanisms,
fairness consists of multiple facets. Although the machine learning (ML)
community has focused on intersectionality as a matter of statistical parity,
especially in discrimination issues, an emerging body of literature addresses
another facet -- monotonicity. Based on domain expertise, monotonicity plays a
vital role in numerous fairness-related areas, where violations could misguide
human decisions and lead to disastrous consequences. In this paper, we first
systematically evaluate the significance of applying monotonic neural additive
models (MNAMs), which use a fairness-aware ML algorithm to enforce both
individual and pairwise monotonicity principles, for the fairness of AI ethics
and society. We have found, through a hybrid method of theoretical reasoning,
simulation, and extensive empirical analysis, that considering monotonicity
axioms is essential in all areas of fairness, including criminology, education,
health care, and finance. Our research contributes to the interdisciplinary
research at the interface of AI ethics, explainable AI (XAI), and
human-computer interactions (HCIs). By evidencing the catastrophic consequences
if monotonicity is not met, we address the significance of monotonicity
requirements in AI applications. Furthermore, we demonstrate that MNAMs are an
effective fairness-aware ML approach by imposing monotonicity restrictions
integrating human intelligence.",2023-01-17,2023,2023-01,education
"A Review of the Trends and Challenges in Adopting Natural Language
  Processing Methods for Education Feedback Analysis","Artificial Intelligence (AI) is a fast-growing area of study that stretching
its presence to many business and research domains. Machine learning, deep
learning, and natural language processing (NLP) are subsets of AI to tackle
different areas of data processing and modelling. This review article presents
an overview of AI impact on education outlining with current opportunities. In
the education domain, student feedback data is crucial to uncover the merits
and demerits of existing services provided to students. AI can assist in
identifying the areas of improvement in educational infrastructure, learning
management systems, teaching practices and study environment. NLP techniques
play a vital role in analyzing student feedback in textual format. This
research focuses on existing NLP methodologies and applications that could be
adapted to educational domain applications like sentiment annotations, entity
annotations, text summarization, and topic modelling. Trends and challenges in
adopting NLP in education were reviewed and explored. Contextbased challenges
in NLP like sarcasm, domain-specific language, ambiguity, and aspect-based
sentiment analysis are explained with existing methodologies to overcome them.
Research community approaches to extract the semantic meaning of emoticons and
special characters in feedback which conveys user opinion and challenges in
adopting NLP in education are explored.",2023-01-20,2023,2023-01,education
"Matching Exemplar as Next Sentence Prediction (MeNSP): Zero-shot Prompt
  Learning for Automatic Scoring in Science Education","Developing models to automatically score students' written responses to
science problems is critical for science education. However, collecting and
labeling sufficient student responses for training models is time and
cost-consuming. Recent studies suggest that pre-trained language models can be
adapted to downstream tasks without fine-tuning with prompts. However, no
research has employed such a prompt approach in science education. As student
responses are presented with natural language, aligning the scoring procedure
as the next sentence prediction task using prompts can skip the costly
fine-tuning stage. In this study, we developed a zero-shot approach to
automatically score student responses via Matching Exemplars as Next Sentence
Prediction (MeNSP). This approach employs no training samples. We first apply
MeNSP in scoring three assessment tasks of scientific argumentation and found
machine-human scoring agreements, Cohen's Kappa ranges from 0.30 to 0.57, and
F1 score ranges from 0.54 to 0.81. To improve the performance, we extend our
research to the few-shots setting, either randomly selecting labeled student
responses or manually constructing responses to fine-tune the models. We find
that one task's performance is improved with more samples, Cohen's Kappa from
0.30 to 0.38, and F1 score from 0.54 to 0.59; for the two others, scoring
performance is not improved. We also find that randomly selected few-shots
perform better than the human expert-crafted approach. This study suggests that
MeNSP can yield referable automatic scoring for student responses while
significantly reducing the cost of model training. This method can benefit
low-stakes classroom assessment practices in science education. Future research
should further explore the applicability of the MeNSP in different types of
assessment tasks in science education and improve the model performance.",2023-01-20,2023,2023-01,education
"Proactive and Reactive Engagement of Artificial Intelligence Methods for
  Education: A Review","Quality education, one of the seventeen sustainable development goals (SDGs)
identified by the United Nations General Assembly, stands to benefit enormously
from the adoption of artificial intelligence (AI) driven tools and
technologies. The concurrent boom of necessary infrastructure, digitized data
and general social awareness has propelled massive research and development
efforts in the artificial intelligence for education (AIEd) sector. In this
review article, we investigate how artificial intelligence, machine learning
and deep learning methods are being utilized to support students, educators and
administrative staff. We do this through the lens of a novel categorization
approach. We consider the involvement of AI-driven methods in the education
process in its entirety - from students admissions, course scheduling etc. in
the proactive planning phase to knowledge delivery, performance assessment etc.
in the reactive execution phase. We outline and analyze the major research
directions under proactive and reactive engagement of AI in education using a
representative group of 194 original research articles published in the past
two decades i.e., 2003 - 2022. We discuss the paradigm shifts in the solution
approaches proposed, i.e., in the choice of data and algorithms used over this
time. We further dive into how the COVID-19 pandemic challenged and reshaped
the education landscape at the fag end of this time period. Finally, we
pinpoint existing limitations in adopting artificial intelligence for education
and reflect on the path forward.",2023-01-23,2023,2023-01,education
Investigating Labeler Bias in Face Annotation for Machine Learning,"In a world increasingly reliant on artificial intelligence, it is more
important than ever to consider the ethical implications of artificial
intelligence on humanity. One key under-explored challenge is labeler bias,
which can create inherently biased datasets for training and subsequently lead
to inaccurate or unfair decisions in healthcare, employment, education, and law
enforcement. Hence, we conducted a study to investigate and measure the
existence of labeler bias using images of people from different ethnicities and
sexes in a labeling task. Our results show that participants possess
stereotypes that influence their decision-making process and that labeler
demographics impact assigned labels. We also discuss how labeler bias
influences datasets and, subsequently, the models trained on them. Overall, a
high degree of transparency must be maintained throughout the entire artificial
intelligence training process to identify and correct biases in the data as
early as possible.",2023-01-24,2023,2023-01,education
Smart tutor to provide feedback in programming courses,"Artificial Intelligence (AI) is becoming more and more popular as time
passes, allowing to perform tasks that were difficult to do in the past. From
predictions to customization, AI is being used in many areas, not being
educational environments outside this situation. AI is being used in
educational settings to customize contents or to provide personalized feedback
to the students, among others. In this scenario, AI in programming teaching is
something that still has to be explored, since in this area we usually find
assessment tools that allow grading the students work, but we can not find many
tools aimed towards providing feedback to the students in the process of
creating their program. In this work we present an AI based intelligent tutor
that answers students programming questions. The tool has been tested by
university students at the URJC along a whole course. Even if the tool is still
in its preliminary phase, it helped the students with their questions,
providing accurate answers and examples. The students were able to use the
intelligent tutor easily and they thought that it could be a useful tool to use
in other courses.",2023-01-24,2023,2023-01,education
"Generating High-Precision Feedback for Programming Syntax Errors using
  Large Language Models","Large language models (LLMs), such as Codex, hold great promise in enhancing
programming education by automatically generating feedback for students. We
investigate using LLMs to generate feedback for fixing syntax errors in Python
programs, a key scenario in introductory programming. More concretely, given a
student's buggy program, our goal is to generate feedback comprising a fixed
program along with a natural language explanation describing the errors/fixes,
inspired by how a human tutor would give feedback. While using LLMs is
promising, the critical challenge is to ensure high precision in the generated
feedback, which is imperative before deploying such technology in classrooms.
The main research question we study is: Can we develop LLMs-based feedback
generation techniques with a tunable precision parameter, giving educators
quality control over the feedback that students receive? To this end, we
introduce PyFiXV, our technique to generate high-precision feedback powered by
Codex. The key idea behind PyFiXV is to use a novel run-time validation
mechanism to decide whether the generated feedback is suitable for sharing with
the student; notably, this validation mechanism also provides a precision knob
to educators. We perform an extensive evaluation using two real-world datasets
of Python programs with syntax errors and show the efficacy of PyFiXV in
generating high-precision feedback.",2023-01-24,2023,2023-01,education
"Context Matters: A Strategy to Pre-train Language Model for Science
  Education","This study aims at improving the performance of scoring student responses in
science education automatically. BERT-based language models have shown
significant superiority over traditional NLP models in various language-related
tasks. However, science writing of students, including argumentation and
explanation, is domain-specific. In addition, the language used by students is
different from the language in journals and Wikipedia, which are training
sources of BERT and its existing variants. All these suggest that a
domain-specific model pre-trained using science education data may improve
model performance. However, the ideal type of data to contextualize pre-trained
language model and improve the performance in automatically scoring student
written responses remains unclear. Therefore, we employ different data in this
study to contextualize both BERT and SciBERT models and compare their
performance on automatic scoring of assessment tasks for scientific
argumentation. We use three datasets to pre-train the model: 1) journal
articles in science education, 2) a large dataset of students' written
responses (sample size over 50,000), and 3) a small dataset of students'
written responses of scientific argumentation tasks. Our experimental results
show that in-domain training corpora constructed from science questions and
responses improve language model performance on a wide variety of downstream
tasks. Our study confirms the effectiveness of continual pre-training on
domain-specific data in the education domain and demonstrates a generalizable
strategy for automating science education tasks with high accuracy. We plan to
release our data and SciEdBERT models for public use and community engagement.",2023-01-27,2023,2023-01,education
"Can an AI Win Ghana's National Science and Maths Quiz? An AI Grand
  Challenge for Education","There is a lack of enough qualified teachers across Africa which hampers
efforts to provide adequate learning support such as educational question
answering (EQA) to students. An AI system that can enable students to ask
questions via text or voice and get instant answers will make high-quality
education accessible. Despite advances in the field of AI, there exists no
robust benchmark or challenge to enable building such an (EQA) AI within the
African context. Ghana's National Science and Maths Quiz competition (NSMQ) is
the perfect competition to evaluate the potential of such an AI due to its wide
coverage of scientific fields, variety of question types, highly competitive
nature, and live, real-world format. The NSMQ is a Jeopardy-style annual live
quiz competition in which 3 teams of 2 students compete by answering questions
across biology, chemistry, physics, and math in 5 rounds over 5 progressive
stages until a winning team is crowned for that year. In this position paper,
we propose the NSMQ AI Grand Challenge, an AI Grand Challenge for Education
using Ghana's National Science and Maths Quiz competition (NSMQ) as a case
study. Our proposed grand challenge is to ""Build an AI to compete live in
Ghana's National Science and Maths Quiz (NSMQ) competition and win - performing
better than the best contestants in all rounds and stages of the competition.""
We describe the competition, and key technical challenges to address along with
ideas from recent advances in machine learning that could be leveraged to solve
this challenge. This position paper is a first step towards conquering such a
challenge and importantly, making advances in AI for education in the African
context towards democratizing high-quality education across Africa.",2023-01-30,2023,2023-01,education
"Exploring the Cognitive Dynamics of Artificial Intelligence in the
  Post-COVID-19 and Learning 3.0 Era: A Case Study of ChatGPT","The emergence of artificial intelligence has incited a paradigm shift across
the spectrum of human endeavors, with ChatGPT serving as a catalyst for the
transformation of various established domains, including but not limited to
education, journalism, security, and ethics. In the post-pandemic era, the
widespread adoption of remote work has prompted the educational sector to
reassess conventional pedagogical methods. This paper is to scrutinize the
underlying psychological principles of ChatGPT, delve into the factors that
captivate user attention, and implicate its ramifications on the future of
learning. The ultimate objective of this study is to instigate a scholarly
discourse on the interplay between technological advancements in education and
the evolution of human learning patterns, raising the question of whether
technology is driving human evolution or vice versa.",2023-02-03,2023,2023-02,education
Will ChatGPT get you caught? Rethinking of Plagiarism Detection,"The rise of Artificial Intelligence (AI) technology and its impact on
education has been a topic of growing concern in recent years. The new
generation AI systems such as chatbots have become more accessible on the
Internet and stronger in terms of capabilities. The use of chatbots,
particularly ChatGPT, for generating academic essays at schools and colleges
has sparked fears among scholars. This study aims to explore the originality of
contents produced by one of the most popular AI chatbots, ChatGPT. To this end,
two popular plagiarism detection tools were used to evaluate the originality of
50 essays generated by ChatGPT on various topics. Our results manifest that
ChatGPT has a great potential to generate sophisticated text outputs without
being well caught by the plagiarism check software. In other words, ChatGPT can
create content on many topics with high originality as if they were written by
someone. These findings align with the recent concerns about students using
chatbots for an easy shortcut to success with minimal or no effort. Moreover,
ChatGPT was asked to verify if the essays were generated by itself, as an
additional measure of plagiarism check, and it showed superior performance
compared to the traditional plagiarism-detection tools. The paper discusses the
need for institutions to consider appropriate measures to mitigate potential
plagiarism issues and advise on the ongoing debate surrounding the impact of AI
technology on education. Further implications are discussed in the paper.",2023-02-08,2023,2023-02,education
"A Human-Centered Review of Algorithms in Decision-Making in Higher
  Education","The use of algorithms for decision-making in higher education is steadily
growing, promising cost-savings to institutions and personalized service for
students but also raising ethical challenges around surveillance, fairness, and
interpretation of data. To address the lack of systematic understanding of how
these algorithms are currently designed, we reviewed an extensive corpus of
papers proposing algorithms for decision-making in higher education. We
categorized them based on input data, computational method, and target outcome,
and then investigated the interrelations of these factors with the application
of human-centered lenses: theoretical, participatory, or speculative design. We
found that the models are trending towards deep learning, and increased use of
student personal data and protected attributes, with the target scope expanding
towards automated decisions. However, despite the associated decrease in
interpretability and explainability, current development predominantly fails to
incorporate human-centered lenses. We discuss the challenges with these trends
and advocate for a human-centered approach.",2023-02-12,2023,2023-02,education
"Improving Interpretability of Deep Sequential Knowledge Tracing Models
  with Question-centric Cognitive Representations","Knowledge tracing (KT) is a crucial technique to predict students' future
performance by observing their historical learning processes. Due to the
powerful representation ability of deep neural networks, remarkable progress
has been made by using deep learning techniques to solve the KT problem. The
majority of existing approaches rely on the \emph{homogeneous question}
assumption that questions have equivalent contributions if they share the same
set of knowledge components. Unfortunately, this assumption is inaccurate in
real-world educational scenarios. Furthermore, it is very challenging to
interpret the prediction results from the existing deep learning based KT
models. Therefore, in this paper, we present QIKT, a question-centric
interpretable KT model to address the above challenges. The proposed QIKT
approach explicitly models students' knowledge state variations at a
fine-grained level with question-sensitive cognitive representations that are
jointly learned from a question-centric knowledge acquisition module and a
question-centric problem solving module. Meanwhile, the QIKT utilizes an item
response theory based prediction layer to generate interpretable prediction
results. The proposed QIKT model is evaluated on three public real-world
educational datasets. The results demonstrate that our approach is superior on
the KT prediction task, and it outperforms a wide range of deep learning based
KT models in terms of prediction accuracy with better model interpretability.
To encourage reproducible results, we have provided all the datasets and code
at \url{https://pykt.org/}.",2023-02-14,2023,2023-02,education
"Platform-Independent and Curriculum-Oriented Intelligent Assistant for
  Higher Education","Miscommunication and communication challenges between instructors and
students represents one of the primary barriers to post-secondary learning.
Students often avoid or miss opportunities to ask questions during office hours
due to insecurities or scheduling conflicts. Moreover, students need to work at
their own pace to have the freedom and time for the self-contemplation needed
to build conceptual understanding and develop creative thinking skills. To
eliminate barriers to student engagement, academic institutions need to
redefine their fundamental approach to education by proposing flexible
educational pathways that recognize continuous learning. To this end, we
developed an AI-augmented intelligent educational assistance framework based on
a power language model (i.e., GPT-3) that automatically generates
course-specific intelligent assistants regardless of discipline or academic
level. The virtual intelligent teaching assistant (TA) system will serve as a
voice-enabled helper capable of answering course-specific questions concerning
curriculum, logistics and course policies. It is envisioned to improve access
to course-related information for the students and reduce logistical workload
for the instructors and TAs. Its GPT-3-based knowledge discovery component as
well as the generalized system architecture is presented accompanied by a
methodical evaluation of the system accuracy and performance.",2023-02-15,2023,2023-02,education
"DKT-STDRL: Spatial and Temporal Representation Learning Enhanced Deep
  Knowledge Tracing for Learning Performance Prediction","Knowledge tracing (KT) serves as a primary part of intelligent education
systems. Most current KTs either rely on expert judgments or only exploit a
single network structure, which affects the full expression of learning
features. To adequately mine features of students' learning process, Deep
Knowledge Tracing Based on Spatial and Temporal Deep Representation Learning
for Learning Performance Prediction (DKT-STDRL) is proposed in this paper.
DKT-STDRL extracts spatial features from students' learning history sequence,
and then further extracts temporal features to extract deeper hidden
information. Specifically, firstly, the DKT-STDRL model uses CNN to extract the
spatial feature information of students' exercise sequences. Then, the spatial
features are connected with the original students' exercise features as joint
learning features. Then, the joint features are input into the BiLSTM part.
Finally, the BiLSTM part extracts the temporal features from the joint learning
features to obtain the prediction information of whether the students answer
correctly at the next time step. Experiments on the public education datasets
ASSISTment2009, ASSISTment2015, Synthetic-5, ASSISTchall, and Statics2011 prove
that DKT-STDRL can achieve better prediction effects than DKT and CKT.",2023-02-15,2023,2023-02,education
"Real-World Deployment and Evaluation of Kwame for Science, An AI
  Teaching Assistant for Science Education in West Africa","Africa has a high student-to-teacher ratio which limits students' access to
teachers for learning support such as educational question answering. In this
work, we extended Kwame, a bilingual AI teaching assistant for coding
education, adapted it for science education, and deployed it as a web app.
Kwame for Science provides passages from well-curated knowledge sources and
related past national exam questions as answers to questions from students
based on the Integrated Science subject of the West African Senior Secondary
Certificate Examination (WASSCE). Furthermore, students can view past national
exam questions along with their answers and filter by year, question type, and
topics that were automatically categorized by a topic detection model which we
developed (91% unweighted average recall). We deployed Kwame for Science in the
real world over 8 months and had 750 users across 32 countries (15 in Africa)
and 1.5K questions asked. Our evaluation showed an 87.2% top 3 accuracy (n=109
questions) implying that Kwame for Science has a high chance of giving at least
one useful answer among the 3 displayed. We categorized the reasons the model
incorrectly answered questions to provide insights for future improvements. We
also share challenges and lessons with the development, deployment, and
human-computer interaction component of such a tool to enable other researchers
to deploy similar tools. With a first-of-its-kind tool within the African
context, Kwame for Science has the potential to enable the delivery of
scalable, cost-effective, and quality remote education to millions of people
across Africa.",2023-02-21,2023,2023-02,education
"TUTORING: Instruction-Grounded Conversational Agent for Language
  Learners","In this paper, we propose Tutoring bot, a generative chatbot trained on a
large scale of tutor-student conversations for English-language learning. To
mimic a human tutor's behavior in language education, the tutor bot leverages
diverse educational instructions and grounds to each instruction as additional
input context for the tutor response generation. As a single instruction
generally involves multiple dialogue turns to give the student sufficient
speaking practice, the tutor bot is required to monitor and capture when the
current instruction should be kept or switched to the next instruction. For
that, the tutor bot is learned to not only generate responses but also infer
its teaching action and progress on the current conversation simultaneously by
a multi-task learning scheme. Our Tutoring bot is deployed under a
non-commercial use license at https://tutoringai.com.",2023-02-24,2023,2023-02,education
"Leveraging Large Language Model and Story-Based Gamification in
  Intelligent Tutoring System to Scaffold Introductory Programming Courses: A
  Design-Based Research Study","Programming skills are rapidly becoming essential for many educational paths
and career opportunities. Yet, for many international students, the traditional
approach to teaching introductory programming courses can be a significant
challenge due to the complexities of the language, the lack of prior
programming knowledge, and the language and cultural barriers. This study
explores how large language models and gamification can scaffold coding
learning and increase Chinese students sense of belonging in introductory
programming courses. In this project, a gamification intelligent tutoring
system was developed to adapt to Chinese international students learning needs
and provides scaffolding to support their success in introductory computer
programming courses.",2023-02-25,2023,2023-02,education
"Artificial Intelligence Impact On The Labour Force -- Searching For The
  Analytical Skills Of The Future Software Engineers","This systematic literature review aims to investigate the impact of
artificial intelligence (AI) on the labour force in software engineering, with
a particular focus on the skills needed for future software engineers, the
impact of AI on the demand for software engineering skills, and the future of
work for software engineers. The review identified 42 relevant publications
through a comprehensive search strategy and analysed their findings. The
results indicate that future software engineers will need to be competent in
programming and have soft skills such as problem-solving and interpersonal
communication. AI will have a significant impact on the software engineering
workforce, with the potential to automate many jobs currently done by software
engineers. The role of a software engineer is changing and will continue to
change in the future, with AI-assisted software development posing challenges
for the software engineering profession. The review suggests that the software
engineering profession must adapt to the changing landscape to remain relevant
and effective in the future.",2023-02-26,2023,2023-02,education
"Investigating Girls' Perspectives and Knowledge Gaps on Ethics and
  Fairness in Artificial Intelligence in a Lightweight Workshop","Artificial intelligence (AI) is everywhere, with many children having
increased exposure to AI technologies in daily life. We aimed to understand
middle school girls' (a group often excluded group in tech) perceptions and
knowledge gaps about AI. We created and explored the feasibility of a
lightweight (less than 3 hours) educational workshop in which learners
considered challenges in their lives and communities and critically considered
how existing and future AI could have an impact. After the workshop, learners
had nuanced perceptions of AI, understanding AI can both help and harm. We
discuss design implications for creating educational experiences in AI and
fairness that embolden learners.",2023-02-27,2023,2023-02,education
"Let's have a chat! A Conversation with ChatGPT: Technology,
  Applications, and Limitations","The emergence of an AI-powered chatbot that can generate human-like sentences
and write coherent essays has caught the world's attention. This paper
discusses the historical overview of chatbots and the technology behind Chat
Generative Pre-trained Transformer, better known as ChatGPT. Moreover,
potential applications of ChatGPT in various domains, including healthcare,
education, and research, are highlighted. Despite promising results, there are
several privacy and ethical concerns surrounding ChatGPT. In addition, we
highlight some of the important limitations of the current version of ChatGPT.
We also ask ChatGPT to provide its point of view and present its responses to
several questions we attempt to answer.",2023-02-27,2023,2023-02,education
"Analysis and Evaluation of Explainable Artificial Intelligence on
  Suicide Risk Assessment","This study investigates the effectiveness of Explainable Artificial
Intelligence (XAI) techniques in predicting suicide risks and identifying the
dominant causes for such behaviours. Data augmentation techniques and ML models
are utilized to predict the associated risk. Furthermore, SHapley Additive
exPlanations (SHAP) and correlation analysis are used to rank the importance of
variables in predictions. Experimental results indicate that Decision Tree
(DT), Random Forest (RF) and eXtreme Gradient Boosting (XGBoost) models achieve
the best results while DT has the best performance with an accuracy of 95:23%
and an Area Under Curve (AUC) of 0.95. As per SHAP results, anger problems,
depression, and social isolation are the leading variables in predicting the
risk of suicide, and patients with good incomes, respected occupations, and
university education have the least risk. Results demonstrate the effectiveness
of machine learning and XAI framework for suicide risk prediction, and they can
assist psychiatrists in understanding complex human behaviours and can also
assist in reliable clinical decision-making.",2023-03-09,2023,2023-03,education
"Proceedings 11th International Workshop on Theorem Proving Components
  for Educational Software","The ThEdu series pursues the smooth transition from an intuitive way of doing
mathematics at secondary school to a more formal approach to the subject in
STEM education, while favouring software support for this transition by
exploiting the power of theorem-proving technologies. What follows is a brief
description of how the present volume contributes to this enterprise. The 11th
International Workshop on Theorem Proving Components for Educational Software
(ThEdu'22), was a satellite event of the 8th Federated Logic Conference (FLoC
2022), July 31-August 12, 2022, Haifa, Israel ThEdu'22 was a vibrant workshop,
with two invited talk by Thierry Dana-Picard (Jerusalem College of Technology,
Jerusalem, Israel) and Yoni Zohar (Bar Ilan University, Tel Aviv, Israel) and
four contributions. An open call for papers was then issued, and attracted
seven submissions. Those submissions have been accepted by our reviewers, who
jointly produced at least three careful reports on each of the contributions.
The resulting revised papers are collected in the present volume. The
contributions in this volume are a faithful representation of the wide spectrum
of ThEdu, ranging from those more focused on the automated deduction research,
not losing track of the possible applications in an educational setting, to
those focused on the applications, in educational settings, of automated
deduction tools and methods. We, the volume editors, hope that this collection
of papers will further promote the development of theorem-proving based
software, and that it will allow to improve the mutual understanding between
computer scientists, mathematicians and stakeholders in education. While this
volume goes to press, the next edition of the ThEdu workshop is being prepared:
ThEdu'23 will be a satellite event of the 29th international Conference on
Automated Deduction (CADE 2023), July 1-4, 2023, Rome, Italy.",2023-03-09,2023,2023-03,education
Computer Assisted Proofs and Automated Methods in Mathematics Education,"This survey paper is an expanded version of an invited keynote at the
ThEdu'22 workshop, August 2022, in Haifa (Israel). After a short introduction
on the developments of CAS, DGS and other useful technologies, we show
implications in Mathematics Education, and in the broader frame of STEAM
Education. In particular, we discuss the transformation of Mathematics
Education into exploration-discovery-conjecture-proof scheme, avoiding usage as
a black box . This scheme fits well into the so-called 4 C's of 21st Century
Education. Communication and Collaboration are emphasized not only between
humans, but also between machines, and between man and machine. Specific
characteristics of the outputs enhance the need of Critical Thinking. The usage
of automated commands for exploration and discovery is discussed, with mention
of limitations where they exist. We illustrate the topic with examples from
parametric integrals (describing a ""cognitive neighborhood"" of a mathematical
notion), plane geometry, and the study of plane curves (envelopes, isoptic
curves). Some of the examples are fully worked out, others are explained and
references are given.",2023-03-10,2023,2023-03,education
"A Rule Based Theorem Prover: an Introduction to Proofs in Secondary
  Schools","The introduction of automated deduction systems in secondary schools face
several bottlenecks. Beyond the problems related with the curricula and the
teachers, the dissonance between the outcomes of the geometry automated theorem
provers and the normal practice of conjecturing and proving in schools is a
major barrier to a wider use of such tools in an educational environment. Since
the early implementations of geometry automated theorem provers, applications
of artificial intelligence methods, synthetic provers based on inference rules
and using forward chaining reasoning are considered to be more suited for
education proposes. Choosing an appropriate set of rules and an automated
method that can use those rules is a major challenge. We discuss one such rule
set and its implementation using the geometry deductive databases method
(GDDM). The approach is tested using some chosen geometric conjectures that
could be the goal of a 7th year class (approx. 12-year-old students). A lesson
plan is presented, its goal is the introduction of formal demonstration of
proving geometric theorems, trying to motivate students to that goal",2023-03-10,2023,2023-03,education
Finding Similar Exercises in Retrieval Manner,"When students make a mistake in an exercise, they can consolidate it by
``similar exercises'' which have the same concepts, purposes and methods.
Commonly, for a certain subject and study stage, the size of the exercise bank
is in the range of millions to even tens of millions, how to find similar
exercises for a given exercise becomes a crucial technical problem. Generally,
we can assign a variety of explicit labels to the exercise, and then query
through the labels, but the label annotation is time-consuming, laborious and
costly, with limited precision and granularity, so it is not feasible. In
practice, we define ``similar exercises'' as a retrieval process of finding a
set of similar exercises based on recall, ranking and re-rank procedures,
called the \textbf{FSE} problem (Finding similar exercises). Furthermore,
comprehensive representation of the semantic information of exercises was
obtained through representation learning. In addition to the reasonable
architecture, we also explore what kind of tasks are more conducive to the
learning of exercise semantic information from pre-training and supervised
learning. It is difficult to annotate similar exercises and the annotation
consistency among experts is low. Therefore this paper also provides solutions
to solve the problem of low-quality annotated data. Compared with other
methods, this paper has obvious advantages in both architecture rationality and
algorithm precision, which now serves the daily teaching of hundreds of
schools.",2023-03-15,2023,2023-03,education
"Practical and Ethical Challenges of Large Language Models in Education:
  A Systematic Scoping Review","Educational technology innovations leveraging large language models (LLMs)
have shown the potential to automate the laborious process of generating and
analysing textual content. While various innovations have been developed to
automate a range of educational tasks (e.g., question generation, feedback
provision, and essay grading), there are concerns regarding the practicality
and ethicality of these innovations. Such concerns may hinder future research
and the adoption of LLMs-based innovations in authentic educational contexts.
To address this, we conducted a systematic scoping review of 118 peer-reviewed
papers published since 2017 to pinpoint the current state of research on using
LLMs to automate and support educational tasks. The findings revealed 53 use
cases for LLMs in automating education tasks, categorised into nine main
categories: profiling/labelling, detection, grading, teaching support,
prediction, knowledge representation, feedback, content generation, and
recommendation. Additionally, we also identified several practical and ethical
challenges, including low technological readiness, lack of replicability and
transparency, and insufficient privacy and beneficence considerations. The
findings were summarised into three recommendations for future studies,
including updating existing innovations with state-of-the-art models (e.g.,
GPT-3/4), embracing the initiative of open-sourcing models/systems, and
adopting a human-centred approach throughout the developmental process. As the
intersection of AI and education is continuously evolving, the findings of this
study can serve as an essential reference point for researchers, allowing them
to leverage the strengths, learn from the limitations, and uncover potential
research opportunities enabled by ChatGPT and other generative AI models.",2023-03-17,2023,2023-03,education
"On the Educational Impact of ChatGPT: Is Artificial Intelligence Ready
  to Obtain a University Degree?","In late 2022, OpenAI released a new version of ChatGPT, a sophisticated
natural language processing system capable of holding natural conversations
while preserving and responding to the context of the discussion. ChatGPT has
exceeded expectations in its abilities, leading to extensive considerations of
its potential applications and misuse. In this work, we evaluate the influence
of ChatGPT on university education, with a primary focus on computer
security-oriented specialization. We gather data regarding the effectiveness
and usability of this tool for completing exams, programming assignments, and
term papers. We evaluate multiple levels of tool misuse, ranging from utilizing
it as a consultant to simply copying its outputs. While we demonstrate how
easily ChatGPT can be used to cheat, we also discuss the potentially
significant benefits to the educational system. For instance, it might be used
as an aid (assistant) to discuss problems encountered while solving an
assignment or to speed up the learning process. Ultimately, we discuss how
computer science higher education should adapt to tools like ChatGPT.",2023-03-20,2023,2023-03,education
Hey Dona! Can you help me with student course registration?,"In this paper, we present a demo of an intelligent personal agent called Hey
Dona (or just Dona) with virtual voice assistance in student course
registration. It is a deployed project in the theme of AI for education. In
this digital age with a myriad of smart devices, users often delegate tasks to
agents. While pointing and clicking supersedes the erstwhile command-typing,
modern devices allow users to speak commands for agents to execute tasks,
enhancing speed and convenience. In line with this progress, Dona is an
intelligent agent catering to student needs by automated, voice-operated course
registration, spanning a multitude of accents, entailing task planning
optimization, with some language translation as needed. Dona accepts voice
input by microphone (Bluetooth, wired microphone), converts human voice to
computer understandable language, performs query processing as per user
commands, connects with the Web to search for answers, models task
dependencies, imbibes quality control, and conveys output by speaking to users
as well as displaying text, thus enabling human-AI interaction by speech cum
text. It is meant to work seamlessly on desktops, smartphones etc. and in
indoor as well as outdoor settings. To the best of our knowledge, Dona is among
the first of its kind as an intelligent personal agent for voice assistance in
student course registration. Due to its ubiquitous access for educational
needs, Dona directly impacts AI for education. It makes a broader impact on
smart city characteristics of smart living and smart people due to its
contributions to providing benefits for new ways of living and assisting 21st
century education, respectively.",2023-03-21,2023,2023-03,education
"Open Learning Analytics: A Systematic Literature Review and Future
  Perspectives","Open Learning Analytics (OLA) is an emerging research area that aims at
improving learning efficiency and effectiveness in lifelong learning
environments. OLA employs multiple methods to draw value from a wide range of
educational data coming from various learning environments and contexts in
order to gain insight into the learning processes of different stakeholders. As
the research field is still relatively young, only a few technical platforms
are available and a common understanding of requirements is lacking. This paper
provides a systematic literature review of tools available in the learning
analytics literature from 2011-2019 with an eye on their support for openness.
137 tools from nine academic databases are collected to form the base for this
review. The analysis of selected tools is performed based on four dimensions,
namely 'Data, Environments, Context (What?)', 'Stakeholders (Who?)',
'Objectives (Why?)', and 'Methods (How?)'. Moreover, five well-known OLA
frameworks available in the community are systematically compared. The review
concludes by eliciting the main requirements for an effective OLA platform and
by identifying key challenges and future lines of work in this emerging field.",2023-03-22,2023,2023-03,education
"Generative AI Assistants in Software Development Education: A vision for
  integrating Generative AI into educational practice, not instinctively
  defending against it","The software development industry is amid another disruptive paradigm change
- adopting the use of generative AI (GAI) assistants for programming. Whilst AI
is already used in various areas of software engineering, GAI technologies,
such as GitHub Copilot and ChatGPT, have ignited peoples' imaginations (and
fears). It is unclear how the industry will adapt, but the move to integrate
these technologies by large software companies, such as Microsoft (GitHub,
Bing) and Google (Bard), is a clear indication of intent and direction. We
performed exploratory interviews with industry professionals to understand
current practice and challenges, which we incorporate into our vision of a
future of software development education and make some pedagogical
recommendations.",2023-03-24,2023,2023-03,education
Unleashing GPT on the Metaverse: Savior or Destroyer?,"Incorporating artificial intelligence (AI) technology, particularly large
language models (LLMs), is becoming increasingly vital for developing immersive
and interactive metaverse experiences. GPT, a representative LLM developed by
OpenAI, is leading LLM development and gaining attention for its potential in
building the metaverse. The article delves into the pros and cons of utilizing
GPT for metaverse-based education, entertainment, personalization, and support.
Dynamic and personalized experiences are possible with this technology, but
there are also legitimate privacy, bias, and ethical issues to consider. This
article aims to help readers understand the possible influence of GPT,
according to its unique technological advantages, on the metaverse and how it
may be used to effectively create a more immersive and engaging virtual
environment by evaluating these opportunities and obstacles.",2023-03-24,2023,2023-03,education
Advances in apparent conceptual physics reasoning in GPT-4,"ChatGPT is built on a large language model trained on an enormous corpus of
human text to emulate human conversation. Despite lacking any explicit
programming regarding the laws of physics, recent work has demonstrated that
GPT-3.5 could pass an introductory physics course at some nominal level and
register something close to a minimal understanding of Newtonian Mechanics on
the Force Concept Inventory. This work replicates those results and also
demonstrates that the latest version, GPT-4, has reached a much higher mark in
the latter context. Indeed, its responses come quite close to perfectly
demonstrating expert-level competence, with a few very notable exceptions and
limitations. We briefly comment on the implications of this for the future of
physics education and pedagogy.",2023-03-29,2023,2023-03,education
"Scientists' Perspectives on the Potential for Generative AI in their
  Fields","Generative AI models, including large language models and multimodal models
that include text and other media, are on the cusp of transforming many aspects
of modern life, including entertainment, education, civic life, the arts, and a
range of professions. There is potential for Generative AI to have a
substantive impact on the methods and pace of discovery for a range of
scientific disciplines. We interviewed twenty scientists from a range of fields
(including the physical, life, and social sciences) to gain insight into
whether or how Generative AI technologies might add value to the practice of
their respective disciplines, including not only ways in which AI might
accelerate scientific discovery (i.e., research), but also other aspects of
their profession, including the education of future scholars and the
communication of scientific findings. In addition to identifying opportunities
for Generative AI to augment scientists' current practices, we also asked
participants to reflect on concerns about AI. These findings can help guide the
responsible development of models and interfaces for scientific education,
inquiry, and communication.",2023-04-04,2023,2023-04,education
"ChatGPT: More than a Weapon of Mass Deception, Ethical challenges and
  responses from the Human-Centered Artificial Intelligence (HCAI) perspective","This article explores the ethical problems arising from the use of ChatGPT as
a kind of generative AI and suggests responses based on the Human-Centered
Artificial Intelligence (HCAI) framework. The HCAI framework is appropriate
because it understands technology above all as a tool to empower, augment, and
enhance human agency while referring to human wellbeing as a grand challenge,
thus perfectly aligning itself with ethics, the science of human flourishing.
Further, HCAI provides objectives, principles, procedures, and structures for
reliable, safe, and trustworthy AI which we apply to our ChatGPT assessments.
The main danger ChatGPT presents is the propensity to be used as a weapon of
mass deception (WMD) and an enabler of criminal activities involving deceit. We
review technical specifications to better comprehend its potentials and
limitations. We then suggest both technical (watermarking, styleme, detectors,
and fact-checkers) and non-technical measures (terms of use, transparency,
educator considerations, HITL) to mitigate ChatGPT misuse or abuse and
recommend best uses (creative writing, non-creative writing, teaching and
learning). We conclude with considerations regarding the role of humans in
ensuring the proper use of ChatGPT for individual and social wellbeing.",2023-04-06,2023,2023-04,education
"Generative AI for learning: Investigating the potential of synthetic
  learning videos","Recent advances in generative artificial intelligence (AI) have captured
worldwide attention. Tools such as Dalle-2 and ChatGPT suggest that tasks
previously thought to be beyond the capabilities of AI may now augment the
productivity of creative media in various new ways, including through the
generation of synthetic video. This research paper explores the utility of
using AI-generated synthetic video to create viable educational content for
online educational settings. To date, there is limited research investigating
the real-world educational value of AI-generated synthetic media. To address
this gap, we examined the impact of using AI-generated synthetic video in an
online learning platform on both learners content acquisition and learning
experience. We took a mixed-method approach, randomly assigning adult learners
(n=83) into one of two micro-learning conditions, collecting pre- and
post-learning assessments, and surveying participants on their learning
experience. The control condition included a traditionally produced instructor
video, while the experimental condition included a synthetic video with a
realistic AI-generated character. The results show that learners in both
conditions demonstrated significant improvement from pre- to post-learning
(p<.001), with no significant differences in gains between the two conditions
(p=.80). In addition, no differences were observed in how learners perceived
the traditional and synthetic videos. These findings suggest that AI-generated
synthetic learning videos have the potential to be a viable substitute for
videos produced via traditional methods in online educational settings, making
high quality educational content more accessible across the globe.",2023-04-07,2023,2023-04,education
"Reinforcement Learning Tutor Better Supported Lower Performers in a Math
  Task","Resource limitations make it hard to provide all students with one of the
most effective educational interventions: personalized instruction.
Reinforcement learning could be a key tool to reduce the development cost and
improve the effectiveness of intelligent tutoring software that aims to provide
the right support, at the right time, to a student. Here we illustrate that
deep reinforcement learning can be used to provide adaptive pedagogical support
to students learning about the concept of volume in a narrative storyline
software. Using explainable artificial intelligence tools, we extracted
interpretable insights about the pedagogical policy learned and demonstrated
that the resulting policy had similar performance in a different student
population. Most importantly, in both studies, the reinforcement-learning
narrative system had the largest benefit for those students with the lowest
initial pretest scores, suggesting the opportunity for AI to adapt and provide
support for those most in need.",2023-04-11,2023,2023-04,education
"Does Informativeness Matter? Active Learning for Educational Dialogue
  Act Classification","Dialogue Acts (DAs) can be used to explain what expert tutors do and what
students know during the tutoring process. Most empirical studies adopt the
random sampling method to obtain sentence samples for manual annotation of DAs,
which are then used to train DA classifiers. However, these studies have paid
little attention to sample informativeness, which can reflect the information
quantity of the selected samples and inform the extent to which a classifier
can learn patterns. Notably, the informativeness level may vary among the
samples and the classifier might only need a small amount of low informative
samples to learn the patterns. Random sampling may overlook sample
informativeness, which consumes human labelling costs and contributes less to
training the classifiers. As an alternative, researchers suggest employing
statistical sampling methods of Active Learning (AL) to identify the
informative samples for training the classifiers. However, the use of AL
methods in educational DA classification tasks is under-explored. In this
paper, we examine the informativeness of annotated sentence samples. Then, the
study investigates how the AL methods can select informative samples to support
DA classifiers in the AL sampling process. The results reveal that most
annotated sentences present low informativeness in the training dataset and the
patterns of these sentences can be easily captured by the DA classifier. We
also demonstrate how AL methods can reduce the cost of manual annotation in the
AL sampling process.",2023-04-12,2023,2023-04,education
"How do physics students evaluate artificial intelligence responses on
  comprehension questions? A study on the perceived scientific accuracy and
  linguistic quality","This study aimed at evaluating how students perceive the linguistic quality
and scientific accuracy of ChatGPT responses to physics comprehension
questions. A total of 102 first- and second-year physics students were
confronted with three questions of progressing difficulty from introductory
mechanics (rolling motion, waves, and fluid dynamics). Each question was
presented with four different responses. All responses were attributed to
ChatGPT, but in reality one sample solution was created by the researchers. All
ChatGPT responses obtained in this study were wrong, imprecise, incomplete, or
misleading. We found little differences in the perceived linguistic quality
between ChatGPT responses and the sample solution. However, the students rated
the overall scientific accuracy of the responses significantly differently,
with the sample solution being rated best for the questions of low and medium
difficulty. The discrepancy between the sample solution and the ChatGPT
responses increased with the level of self-assessed knowledge of the question
content. For the question of highest difficulty (fluid dynamics) that was
unknown to most students, a ChatGPT response was rated just as good as the
sample solution. Thus, this study provides data on the students' perception of
ChatGPT responses and the factors influencing their perception. The results
highlight the need for careful evaluation of ChatGPT responses both by
instructors and students, particularly regarding scientific accuracy.
Therefore, future research could explore the potential of similar ""spot the
bot""-activities in physics education to foster students' critical thinking
skills.",2023-04-12,2023,2023-04,education
How Useful are Educational Questions Generated by Large Language Models?,"Controllable text generation (CTG) by large language models has a huge
potential to transform education for teachers and students alike. Specifically,
high quality and diverse question generation can dramatically reduce the load
on teachers and improve the quality of their educational content. Recent work
in this domain has made progress with generation, but fails to show that real
teachers judge the generated questions as sufficiently useful for the classroom
setting; or if instead the questions have errors and/or pedagogically unhelpful
content. We conduct a human evaluation with teachers to assess the quality and
usefulness of outputs from combining CTG and question taxonomies (Bloom's and a
difficulty taxonomy). The results demonstrate that the questions generated are
high quality and sufficiently useful, showing their promise for widespread use
in the classroom setting.",2023-04-13,2023,2023-04,education
"MedAlpaca -- An Open-Source Collection of Medical Conversational AI
  Models and Training Data","As large language models (LLMs) like OpenAI's GPT series continue to make
strides, we witness the emergence of artificial intelligence applications in an
ever-expanding range of fields. In medicine, these LLMs hold considerable
promise for improving medical workflows, diagnostics, patient care, and
education. Yet, there is an urgent need for open-source models that can be
deployed on-premises to safeguard patient privacy. In our work, we present an
innovative dataset consisting of over 160,000 entries, specifically crafted to
fine-tune LLMs for effective medical applications. We investigate the impact of
fine-tuning these datasets on publicly accessible pre-trained LLMs, and
subsequently, we juxtapose the performance of pre-trained-only models against
the fine-tuned models concerning the examinations that future medical doctors
must pass to achieve certification.",2023-04-14,2023,2023-04,education
"Robust Educational Dialogue Act Classifiers with Low-Resource and
  Imbalanced Datasets","Dialogue acts (DAs) can represent conversational actions of tutors or
students that take place during tutoring dialogues. Automating the
identification of DAs in tutoring dialogues is significant to the design of
dialogue-based intelligent tutoring systems. Many prior studies employ machine
learning models to classify DAs in tutoring dialogues and invest much effort to
optimize the classification accuracy by using limited amounts of training data
(i.e., low-resource data scenario). However, beyond the classification
accuracy, the robustness of the classifier is also important, which can reflect
the capability of the classifier on learning the patterns from different class
distributions. We note that many prior studies on classifying educational DAs
employ cross entropy (CE) loss to optimize DA classifiers on low-resource data
with imbalanced DA distribution. The DA classifiers in these studies tend to
prioritize accuracy on the majority class at the expense of the minority class
which might not be robust to the data with imbalanced ratios of different DA
classes. To optimize the robustness of classifiers on imbalanced class
distributions, we propose to optimize the performance of the DA classifier by
maximizing the area under the ROC curve (AUC) score (i.e., AUC maximization).
Through extensive experiments, our study provides evidence that (i) by
maximizing AUC in the training process, the DA classifier achieves significant
performance improvement compared to the CE approach under low-resource data,
and (ii) AUC maximization approaches can improve the robustness of the DA
classifier under different class imbalance ratios.",2023-04-15,2023,2023-04,education
"Exploring the Use of ChatGPT as a Tool for Learning and Assessment in
  Undergraduate Computer Science Curriculum: Opportunities and Challenges","The application of Artificial intelligence for teaching and learning in the
academic sphere is a trending subject of interest in the computing education.
ChatGPT, as an AI-based tool, provides various advantages, such as heightened
student involvement, cooperation, accessibility and availability. This paper
addresses the prospects and obstacles associated with utilizing ChatGPT as a
tool for learning and assessment in undergraduate Computer Science curriculum
in particular to teaching and learning fundamental programming courses.
Students having completed the course work for a Data Structures and Algorithms
(a sophomore level course) participated in this study. Two groups of students
were given programming challenges to solve within a short period of time. The
control group (group A) had access to text books and notes of programming
courses, however no Internet access was provided. Group B students were given
access to ChatGPT and were encouraged to use it to help solve the programming
challenges. The challenge was conducted in a computer lab environment using PC2
environment. Each team of students address the problem by writing executable
code that satisfies certain number of test cases. Student teams were scored
based on their performance in terms of number of successful passed testcases.
Results show that students using ChatGPT had an advantage in terms of earned
scores, however there were inconsistencies and inaccuracies in the submitted
code consequently affecting the overall performance. After a thorough analysis,
the paper's findings indicate that incorporating AI in higher education brings
about various opportunities and challenges.",2023-04-16,2023,2023-04,education
Creating Large Language Model Resistant Exams: Guidelines and Strategies,"The proliferation of Large Language Models (LLMs), such as ChatGPT, has
raised concerns about their potential impact on academic integrity, prompting
the need for LLM-resistant exam designs. This article investigates the
performance of LLMs on exams and their implications for assessment, focusing on
ChatGPT's abilities and limitations. We propose guidelines for creating
LLM-resistant exams, including content moderation, deliberate inaccuracies,
real-world scenarios beyond the model's knowledge base, effective distractor
options, evaluating soft skills, and incorporating non-textual information. The
article also highlights the significance of adapting assessments to modern
tools and promoting essential skills development in students. By adopting these
strategies, educators can maintain academic integrity while ensuring that
assessments accurately reflect contemporary professional settings and address
the challenges and opportunities posed by artificial intelligence in education.",2023-04-18,2023,2023-04,education
"Un jeu a debattre pour sensibiliser a l'Intelligence Artificielle dans
  le contexte de la pandemie de COVID-19","Artificial Intelligence is more and more pervasive in our lives. Many
important decisions are delegated to AI algorithms: accessing higher education,
determining prison sentences, autonomously driving vehicles... Engineers and
researchers are educated to this field, while the general population has very
little knowledge about AI. As a result, they are very sensitive to the (more or
less accurate) ideas disseminated by the media: an AI that is unbiased,
infallible, and will either save the world or lead to its demise. We therefore
believe, as highlighted by UNESCO, that it is essential to provide the
population with a general understanding of AI algorithms, so that they can
choose wisely whether to use them (or not). To this end, we propose a serious
game in the form of a civic debate aiming at selecting an AI solution to
control a pandemic. This game is targeted at high school students, it was first
experimented during a science fair, and is now available freely.",2023-04-19,2023,2023-04,education
"Performance of ChatGPT on the US Fundamentals of Engineering Exam:
  Comprehensive Assessment of Proficiency and Potential Implications for
  Professional Environmental Engineering Practice","In recent years, advancements in artificial intelligence (AI) have led to the
development of large language models like GPT-4, demonstrating potential
applications in various fields, including education. This study investigates
the feasibility and effectiveness of using ChatGPT, a GPT-4 based model, in
achieving satisfactory performance on the Fundamentals of Engineering (FE)
Environmental Exam. This study further shows a significant improvement in the
model's accuracy when answering FE exam questions through noninvasive prompt
modifications, substantiating the utility of prompt modification as a viable
approach to enhance AI performance in educational contexts. Furthermore, the
findings reflect remarkable improvements in mathematical capabilities across
successive iterations of ChatGPT models, showcasing their potential in solving
complex engineering problems. Our paper also explores future research
directions, emphasizing the importance of addressing AI challenges in
education, enhancing accessibility and inclusion for diverse student
populations, and developing AI-resistant exam questions to maintain examination
integrity. By evaluating the performance of ChatGPT in the context of the FE
Environmental Exam, this study contributes valuable insights into the potential
applications and limitations of large language models in educational settings.
As AI continues to evolve, these findings offer a foundation for further
research into the responsible and effective integration of AI models across
various disciplines, ultimately optimizing the learning experience and
improving student outcomes.",2023-04-20,2023,2023-04,education
Using Text-to-Image Generation for Architectural Design Ideation,"The recent progress of text-to-image generation has been recognized in
architectural design. Our study is the first to investigate the potential of
text-to-image generators in supporting creativity during the early stages of
the architectural design process. We conducted a laboratory study with 17
architecture students, who developed a concept for a culture center using three
popular text-to-image generators: Midjourney, Stable Diffusion, and DALL-E.
Through standardized questionnaires and group interviews, we found that image
generation could be a meaningful part of the design process when design
constraints are carefully considered. Generative tools support serendipitous
discovery of ideas and an imaginative mindset, enriching the design process. We
identified several challenges of image generators and provided considerations
for software development and educators to support creativity and emphasize
designers' imaginative mindset. By understanding the limitations and potential
of text-to-image generators, architects and designers can leverage this
technology in their design process and education, facilitating innovation and
effective communication of concepts.",2023-04-20,2023,2023-04,education
"Utilizing Online and Open-Source Machine Learning Toolkits to Leverage
  the Future of Sustainable Engineering","Recently, there has been a national push to use machine learning (ML) and
artificial intelligence (AI) to advance engineering techniques in all
disciplines ranging from advanced fracture mechanics in materials science to
soil and water quality testing in the civil and environmental engineering
fields. Using AI, specifically machine learning, engineers can automate and
decrease the processing or human labeling time while maintaining statistical
repeatability via trained models and sensors. Edge Impulse has designed an
open-source TinyML-enabled Arduino education tool kit for engineering
disciplines. This paper discusses the various applications and approaches
engineering educators have taken to utilize ML toolkits in the classroom. We
provide in-depth implementation guides and associated learning outcomes focused
on the Environmental Engineering Classroom. We discuss five specific examples
of four standard Environmental Engineering courses for freshman and
junior-level engineering. There are currently few programs in the nation that
utilize machine learning toolkits to prepare the next generation of ML and
AI-educated engineers for industry and academic careers. This paper will guide
educators to design and implement ML/AI into engineering curricula (without a
specific AI or ML focus within the course) using simple, cheap, and open-source
tools and technological aid from an online platform in collaboration with Edge
Impulse.",2023-04-21,2023,2023-04,education
AGI: Artificial General Intelligence for Education,"Artificial general intelligence (AGI) has gained global recognition as a
future technology due to the emergence of breakthrough large language models
and chatbots such as GPT-4 and ChatGPT, respectively. Compared to conventional
AI models, typically designed for a limited range of tasks, demand significant
amounts of domain-specific data for training and may not always consider
intricate interpersonal dynamics in education. AGI, driven by the recent large
pre-trained models, represents a significant leap in the capability of machines
to perform tasks that require human-level intelligence, such as reasoning,
problem-solving, decision-making, and even understanding human emotions and
social interactions. This position paper reviews AGI's key concepts,
capabilities, scope, and potential within future education, including achieving
future educational goals, designing pedagogy and curriculum, and performing
assessments. It highlights that AGI can significantly improve intelligent
tutoring systems, educational assessment, and evaluation procedures. AGI
systems can adapt to individual student needs, offering tailored learning
experiences. They can also provide comprehensive feedback on student
performance and dynamically adjust teaching methods based on student progress.
The paper emphasizes that AGI's capabilities extend to understanding human
emotions and social interactions, which are critical in educational settings.
The paper discusses that ethical issues in education with AGI include data
bias, fairness, and privacy and emphasizes the need for codes of conduct to
ensure responsible AGI use in academic settings like homework, teaching, and
recruitment. We also conclude that the development of AGI necessitates
interdisciplinary collaborations between educators and AI engineers to advance
research and application efforts.",2023-04-24,2023,2023-04,education
Measuring Massive Multitask Chinese Understanding,"The development of large-scale Chinese language models is flourishing, yet
there is a lack of corresponding capability assessments. Therefore, we propose
a test to measure the multitask accuracy of large Chinese language models. This
test encompasses four major domains, including medicine, law, psychology, and
education, with 15 subtasks in medicine and 8 subtasks in education. We found
that the best-performing models in the zero-shot setting outperformed the
worst-performing models by nearly 18.6 percentage points on average. Across the
four major domains, the highest average zero-shot accuracy of all models is
0.512. In the subdomains, only the GPT-3.5-turbo model achieved a zero-shot
accuracy of 0.693 in clinical medicine, which was the highest accuracy among
all models across all subtasks. All models performed poorly in the legal
domain, with the highest zero-shot accuracy reaching only 0.239. By
comprehensively evaluating the breadth and depth of knowledge across multiple
disciplines, this test can more accurately identify the shortcomings of the
models.",2023-04-25,2023,2023-04,education
Games for Artificial Intelligence Research: A Review and Perspectives,"Games have been the perfect test-beds for artificial intelligence research
for the characteristics that widely exist in real-world scenarios. Learning and
optimisation, decision making in dynamic and uncertain environments, game
theory, planning and scheduling, design and education are common research areas
shared between games and real-world problems. Numerous open-source games or
game-based environments have been implemented for studying artificial
intelligence. In addition to single- or multi-player, collaborative or
adversarial games, there has also been growing interest in implementing
platforms for creative design in recent years. Those platforms provide ideal
benchmarks for exploring and comparing artificial intelligence ideas and
techniques. This paper reviews the games and game-based platforms for
artificial intelligence research, provides guidance on matching particular
types of artificial intelligence with suitable games for testing and matching
particular needs in games with suitable artificial intelligence techniques,
discusses the research trend induced by the evolution of those games and
platforms, and gives an outlook.",2023-04-26,2023,2023-04,education
"A Portrait of Emotion: Empowering Self-Expression through AI-Generated
  Art","We investigated the potential and limitations of generative artificial
intelligence (AI) in reflecting the authors' cognitive processes through
creative expression. The focus is on the AI-generated artwork's ability to
understand human intent (alignment) and visually represent emotions based on
criteria such as creativity, aesthetic, novelty, amusement, and depth. Results
show a preference for images based on the descriptions of the authors' emotions
over the main events. We also found that images that overrepresent specific
elements or stereotypes negatively impact AI alignment. Our findings suggest
that AI could facilitate creativity and the self-expression of emotions. Our
research framework with generative AIs can help design AI-based interventions
in related fields (e.g., mental health education, therapy, and counseling).",2023-04-26,2023,2023-04,education
"A Review of ChatGPT Applications in Education, Marketing, Software
  Engineering, and Healthcare: Benefits, Drawbacks, and Research Directions","ChatGPT is a type of artificial intelligence language model that uses deep
learning algorithms to generate human-like responses to text-based prompts. The
introduction of the latest ChatGPT version in November of 2022 has caused
shockwaves in the industrial and academic communities for its powerful
capabilities, plethora of possible applications, and the great possibility for
abuse. At the time of writing this work, several other language models (e.g.,
Google Bard and Meta LLaMA) just came out in an attempt to get a foothold in
the vast possible market. These models have the ability to revolutionize the
way we interact with computers and have potential applications in many fields,
including education, software engineering, healthcare, and marketing. In this
paper, we will discuss the possible applications, drawbacks, and research
directions using advanced language Chatbots (e.g., ChatGPT) in each of these
fields. We first start with a brief introduction and the development timeline
of artificial intelligence based language models, then we go through possible
applications of such models, after that we discuss the limitations and
drawbacks of the current technological state of the art, and finally we point
out future possible research directions.",2023-04-29,2023,2023-04,education
"Students' Voices on Generative AI: Perceptions, Benefits, and Challenges
  in Higher Education","This study explores university students' perceptions of generative AI (GenAI)
technologies, such as ChatGPT, in higher education, focusing on familiarity,
their willingness to engage, potential benefits and challenges, and effective
integration. A survey of 399 undergraduate and postgraduate students from
various disciplines in Hong Kong revealed a generally positive attitude towards
GenAI in teaching and learning. Students recognized the potential for
personalized learning support, writing and brainstorming assistance, and
research and analysis capabilities. However, concerns about accuracy, privacy,
ethical issues, and the impact on personal development, career prospects, and
societal values were also expressed. According to John Biggs' 3P model, student
perceptions significantly influence learning approaches and outcomes. By
understanding students' perceptions, educators and policymakers can tailor
GenAI technologies to address needs and concerns while promoting effective
learning outcomes. Insights from this study can inform policy development
around the integration of GenAI technologies into higher education. By
understanding students' perceptions and addressing their concerns, policymakers
can create well-informed guidelines and strategies for the responsible and
effective implementation of GenAI tools, ultimately enhancing teaching and
learning experiences in higher education.",2023-04-29,2023,2023-04,education
"A Comprehensive AI Policy Education Framework for University Teaching
  and Learning","This study aims to develop an AI education policy for higher education by
examining the perceptions and implications of text generative AI technologies.
Data was collected from 457 students and 180 teachers and staff across various
disciplines in Hong Kong universities, using both quantitative and qualitative
research methods. Based on the findings, the study proposes an AI Ecological
Education Policy Framework to address the multifaceted implications of AI
integration in university teaching and learning. This framework is organized
into three dimensions: Pedagogical, Governance, and Operational. The
Pedagogical dimension concentrates on using AI to improve teaching and learning
outcomes, while the Governance dimension tackles issues related to privacy,
security, and accountability. The Operational dimension addresses matters
concerning infrastructure and training. The framework fosters a nuanced
understanding of the implications of AI integration in academic settings,
ensuring that stakeholders are aware of their responsibilities and can take
appropriate actions accordingly.",2023-04-29,2023,2023-04,education
"The AI Revolution in Education: Will AI Replace or Assist Teachers in
  Higher Education?","This paper explores the potential of artificial intelligence (AI) in higher
education, specifically its capacity to replace or assist human teachers. By
reviewing relevant literature and analysing survey data from students and
teachers, the study provides a comprehensive perspective on the future role of
educators in the face of advancing AI technologies. Findings suggest that
although some believe AI may eventually replace teachers, the majority of
participants argue that human teachers possess unique qualities, such as
critical thinking, creativity, and emotions, which make them irreplaceable. The
study also emphasizes the importance of social-emotional competencies developed
through human interactions, which AI technologies cannot currently replicate.
The research proposes that teachers can effectively integrate AI to enhance
teaching and learning without viewing it as a replacement. To do so, teachers
need to understand how AI can work well with teachers and students while
avoiding potential pitfalls, develop AI literacy, and address practical issues
such as data protection, ethics, and privacy. The study reveals that students
value and respect human teachers, even as AI becomes more prevalent in
education. The study also introduces a roadmap for students, teachers, and
universities. This roadmap serves as a valuable guide for refining teaching
skills, fostering personal connections, and designing curriculums that
effectively balance the strengths of human educators with AI technologies. The
future of education lies in the synergy between human teachers and AI. By
understanding and refining their unique qualities, teachers, students, and
universities can effectively navigate the integration of AI, ensuring a
well-rounded and impactful learning experience.",2023-05-02,2023,2023-05,education
GPTutor: a ChatGPT-powered programming tool for code explanation,"Learning new programming skills requires tailored guidance. With the
emergence of advanced Natural Language Generation models like the ChatGPT API,
there is now a possibility of creating a convenient and personalized tutoring
system with AI for computer science education. This paper presents GPTutor, a
ChatGPT-powered programming tool, which is a Visual Studio Code extension using
the ChatGPT API to provide programming code explanations. By integrating Visual
Studio Code API, GPTutor can comprehensively analyze the provided code by
referencing the relevant source codes. As a result, GPTutor can use designed
prompts to explain the selected code with a pop-up message. GPTutor is now
published at the Visual Studio Code Extension Marketplace, and its source code
is openly accessible on GitHub. Preliminary evaluation indicates that GPTutor
delivers the most concise and accurate explanations compared to vanilla ChatGPT
and GitHub Copilot. Moreover, the feedback from students and teachers indicated
that GPTutor is user-friendly and can explain given codes satisfactorily.
Finally, we discuss possible future research directions for GPTutor. This
includes enhancing its performance and personalization via further prompt
programming, as well as evaluating the effectiveness of GPTutor with real
users.",2023-05-03,2023,2023-05,education
"The AI generation gap: Are Gen Z students more interested in adopting
  generative AI such as ChatGPT in teaching and learning than their Gen X and
  Millennial Generation teachers?","This study aimed to explore the experiences, perceptions, knowledge,
concerns, and intentions of Gen Z students with Gen X and Gen Y teachers
regarding the use of generative AI (GenAI) in higher education. A sample of
students and teachers were recruited to investigate the above using a survey
consisting of both open and closed questions. The findings showed that Gen Z
participants were generally optimistic about the potential benefits of GenAI,
including enhanced productivity, efficiency, and personalized learning, and
expressed intentions to use GenAI for various educational purposes. Gen X and
Gen Y teachers acknowledged the potential benefits of GenAI but expressed
heightened concerns about overreliance, ethical and pedagogical implications,
emphasizing the need for proper guidelines and policies to ensure responsible
use of the technology. The study highlighted the importance of combining
technology with traditional teaching methods to provide a more effective
learning experience. Implications of the findings include the need to develop
evidence-based guidelines and policies for GenAI integration, foster critical
thinking and digital literacy skills among students, and promote responsible
use of GenAI technologies in higher education.",2023-05-04,2023,2023-05,education
"Towards Applying Powerful Large AI Models in Classroom Teaching:
  Opportunities, Challenges and Prospects","This perspective paper proposes a series of interactive scenarios that
utilize Artificial Intelligence (AI) to enhance classroom teaching, such as
dialogue auto-completion, knowledge and style transfer, and assessment of
AI-generated content. By leveraging recent developments in Large Language
Models (LLMs), we explore the potential of AI to augment and enrich
teacher-student dialogues and improve the quality of teaching. Our goal is to
produce innovative and meaningful conversations between teachers and students,
create standards for evaluation, and improve the efficacy of AI-for-Education
initiatives. In Section 3, we discuss the challenges of utilizing existing LLMs
to effectively complete the educated tasks and present a unified framework for
addressing diverse education dataset, processing lengthy conversations, and
condensing information to better accomplish more downstream tasks. In Section
4, we summarize the pivoting tasks including Teacher-Student Dialogue
Auto-Completion, Expert Teaching Knowledge and Style Transfer, and Assessment
of AI-Generated Content (AIGC), providing a clear path for future research. In
Section 5, we also explore the use of external and adjustable LLMs to improve
the generated content through human-in-the-loop supervision and reinforcement
learning. Ultimately, this paper seeks to highlight the potential for AI to aid
the field of education and promote its further exploration.",2023-05-05,2023,2023-05,education
"Multi-source Education Knowledge Graph Construction and Fusion for
  College Curricula","The field of education has undergone a significant transformation due to the
rapid advancements in Artificial Intelligence (AI). Among the various AI
technologies, Knowledge Graphs (KGs) using Natural Language Processing (NLP)
have emerged as powerful visualization tools for integrating multifaceted
information. In the context of university education, the availability of
numerous specialized courses and complicated learning resources often leads to
inferior learning outcomes for students. In this paper, we propose an automated
framework for knowledge extraction, visual KG construction, and graph fusion,
tailored for the major of Electronic Information. Furthermore, we perform data
analysis to investigate the correlation degree and relationship between
courses, rank hot knowledge concepts, and explore the intersection of courses.
Our objective is to enhance the learning efficiency of students and to explore
new educational paradigms enabled by AI. The proposed framework is expected to
enable students to better understand and appreciate the intricacies of their
field of study by providing them with a comprehensive understanding of the
relationships between the various concepts and courses.",2023-05-08,2023,2023-05,education
"""Alexa doesn't have that many feelings"": Children's understanding of AI
  through interactions with smart speakers in their homes","As voice-based Conversational Assistants (CAs), including Alexa, Siri, Google
Home, have become commonly embedded in households, many children now routinely
interact with Artificial Intelligence (AI) systems. It is important to research
children's experiences with consumer devices which use AI techniques because
these shape their understanding of AI and its capabilities. We conducted a
mixed-methods study (questionnaires and interviews) with primary-school
children aged 6-11 in Scotland to establish children's understanding of how
voice-based CAs work, how they perceive their cognitive abilities, agency and
other human-like qualities, their awareness and trust of privacy aspects when
using CAs and what they perceive as appropriate verbal interactions with CAs.
Most children overestimated the CAs' intelligence and were uncertain about the
systems' feelings or agency. They also lacked accurate understanding of data
privacy and security aspects, and believed it was wrong to be rude to
conversational assistants. Exploring children's current understanding of
AI-supported technology has educational implications; such findings will enable
educators to develop appropriate materials to address the pressing need for AI
literacy.",2023-05-09,2023,2023-05,education
"What Students Can Learn About Artificial Intelligence -- Recommendations
  for K-12 Computing Education","Technological advances in the context of digital transformation are the basis
for rapid developments in the field of artificial intelligence (AI). Although
AI is not a new topic in computer science (CS), recent developments are having
an immense impact on everyday life and society. In consequence, everyone needs
competencies to be able to adequately and competently analyze, discuss and help
shape the impact, opportunities, and limits of artificial intelligence on their
personal lives and our society. As a result, an increasing number of CS
curricula are being extended to include the topic of AI. However, in order to
integrate AI into existing CS curricula, what students can and should learn in
the context of AI needs to be clarified. This has proven to be particularly
difficult, considering that so far CS education research on central concepts
and principles of AI lacks sufficient elaboration. Therefore, in this paper, we
present a curriculum of learning objectives that addresses digital literacy and
the societal perspective in particular. The learning objectives can be used to
comprehensively design curricula, but also allow for analyzing current
curricula and teaching materials and provide insights into the central concepts
and corresponding competencies of AI.",2023-05-10,2023,2023-05,education
"Towards Scalable Adaptive Learning with Graph Neural Networks and
  Reinforcement Learning","Adaptive learning is an area of educational technology that consists in
delivering personalized learning experiences to address the unique needs of
each learner. An important subfield of adaptive learning is learning path
personalization: it aims at designing systems that recommend sequences of
educational activities to maximize students' learning outcomes. Many machine
learning approaches have already demonstrated significant results in a variety
of contexts related to learning path personalization. However, most of them
were designed for very specific settings and are not very reusable. This is
accentuated by the fact that they often rely on non-scalable models, which are
unable to integrate new elements after being trained on a specific set of
educational resources. In this paper, we introduce a flexible and scalable
approach towards the problem of learning path personalization, which we
formalize as a reinforcement learning problem. Our model is a sequential
recommender system based on a graph neural network, which we evaluate on a
population of simulated learners. Our results demonstrate that it can learn to
make good recommendations in the small-data regime.",2023-05-10,2023,2023-05,education
"New Era of Artificial Intelligence in Education: Towards a Sustainable
  Multifaceted Revolution","The recent high performance of ChatGPT on several standardized academic tests
has thrust the topic of artificial intelligence (AI) into the mainstream
conversation about the future of education. As deep learning is poised to shift
the teaching paradigm, it is essential to have a clear understanding of its
effects on the current education system to ensure sustainable development and
deployment of AI-driven technologies at schools and universities. This research
aims to investigate the potential impact of AI on education through review and
analysis of the existing literature across three major axes: applications,
advantages, and challenges. Our review focuses on the use of artificial
intelligence in collaborative teacher--student learning, intelligent tutoring
systems, automated assessment, and personalized learning. We also report on the
potential negative aspects, ethical issues, and possible future routes for AI
implementation in education. Ultimately, we find that the only way forward is
to embrace the new technology, while implementing guardrails to prevent its
abuse.",2023-05-12,2023,2023-05,education
Generative AI: Implications and Applications for Education,"The launch of ChatGPT in November 2022 precipitated a panic among some
educators while prompting qualified enthusiasm from others. Under the umbrella
term Generative AI, ChatGPT is an example of a range of technologies for the
delivery of computer-generated text, image, and other digitized media. This
paper examines the implications for education of one generative AI technology,
chatbots responding from large language models, or C-LLM. It reports on an
application of a C-LLM to AI review and assessment of complex student work. In
a concluding discussion, the paper explores the intrinsic limits of generative
AI, bound as it is to language corpora and their textual representation through
binary notation. Within these limits, we suggest the range of emerging and
potential applications of Generative AI in education.",2023-05-12,2023,2023-05,education
"Scalable Educational Question Generation with Pre-trained Language
  Models","The automatic generation of educational questions will play a key role in
scaling online education, enabling self-assessment at scale when a global
population is manoeuvring their personalised learning journeys. We develop
\textit{EduQG}, a novel educational question generation model built by adapting
a large language model. Our extensive experiments demonstrate that
\textit{EduQG} can produce superior educational questions by further
pre-training and fine-tuning a pre-trained language model on the scientific
text and science question data.",2023-05-13,2023,2023-05,education
Critical Appraisal of Artificial Intelligence-Mediated Communication,"Over the last two decades, technology use in language learning and teaching
has significantly advanced and is now referred to as Computer-Assisted Language
Learning (CALL). Recently, the integration of Artificial Intelligence (AI) into
CALL has brought about a significant shift in the traditional approach to
language education both inside and outside the classroom. In line with this
book's scope, I explore the advantages and disadvantages of AI-mediated
communication in language education. I begin with a brief review of AI in
education. I then introduce the ICALL and give a critical appraisal of the
potential of AI-powered automatic speech recognition (ASR), Machine Translation
(MT), Intelligent Tutoring Systems (ITSs), AI-powered chatbots, and Extended
Reality (XR). In conclusion, I argue that it is crucial for language teachers
to engage in CALL teacher education and professional development to keep up
with the ever-evolving technology landscape and improve their teaching
effectiveness.",2023-05-15,2023,2023-05,education
"ChatGPT and the Labor Market: Unraveling the Effect of AI Discussions on
  Students' Earnings Expectations","This paper investigates the causal impact of negatively and positively toned
ChatGPT Artificial Intelligence (AI) discussions on US students' anticipated
labor market outcomes. Our findings reveal students reduce their confidence
regarding their future earnings prospects after exposure to AI debates, and
this effect is more pronounced after reading discussion excerpts with a
negative tone. Unlike STEM majors, students in Non-STEM fields show asymmetric
and pessimistic belief changes, suggesting that they might feel more vulnerable
to emerging AI technologies. Pessimistic belief updates regarding future
earnings are also prevalent among non-male students, indicating widespread AI
concerns among vulnerable student subgroups. Educators, administrators, and
policymakers may regularly engage with students to address their concerns and
enhance educational curricula to better prepare them for a future that AI will
inevitably shape.",2023-05-15,2023,2023-05,education
Balancing Test Accuracy and Security in Computerized Adaptive Testing,"Computerized adaptive testing (CAT) is a form of personalized testing that
accurately measures students' knowledge levels while reducing test length.
Bilevel optimization-based CAT (BOBCAT) is a recent framework that learns a
data-driven question selection algorithm to effectively reduce test length and
improve test accuracy. However, it suffers from high question exposure and test
overlap rates, which potentially affects test security. This paper introduces a
constrained version of BOBCAT to address these problems by changing its
optimization setup and enabling us to trade off test accuracy for question
exposure and test overlap rates. We show that C-BOBCAT is effective through
extensive experiments on two real-world adult testing datasets.",2023-05-18,2023,2023-05,education
"Leveraging Human Feedback to Scale Educational Datasets: Combining
  Crowdworkers and Comparative Judgement","Machine Learning models have many potentially beneficial applications in
education settings, but a key barrier to their development is securing enough
data to train these models. Labelling educational data has traditionally relied
on highly skilled raters using complex, multi-class rubrics, making the process
expensive and difficult to scale. An alternative, more scalable approach could
be to use non-expert crowdworkers to evaluate student work, however,
maintaining sufficiently high levels of accuracy and inter-rater reliability
when using non-expert workers is challenging. This paper reports on two
experiments investigating using non-expert crowdworkers and comparative
judgement to evaluate complex student data. Crowdworkers were hired to evaluate
student responses to open-ended reading comprehension questions. Crowdworkers
were randomly assigned to one of two conditions: the control, where they were
asked to decide whether answers were correct or incorrect (i.e., a categorical
judgement), or the treatment, where they were shown the same question and
answers, but were instead asked to decide which of two candidate answers was
more correct (i.e., a comparative/preference-based judgement). We found that
using comparative judgement substantially improved inter-rater reliability on
both tasks. These results are in-line with well-established literature on the
benefits of comparative judgement in the field of educational assessment, as
well as with recent trends in artificial intelligence research, where
comparative judgement is becoming the preferred method for providing human
feedback on model outputs when working with non-expert crowdworkers. However,
to our knowledge, these results are novel and important in demonstrating the
beneficial effects of using the combination of comparative judgement and
crowdworkers to evaluate educational data.",2023-05-22,2023,2023-05,education
"Transformative Effects of ChatGPT on Modern Education: Emerging Era of
  AI Chatbots","ChatGPT, an AI-based chatbot, was released to provide coherent and useful
replies based on analysis of large volumes of data. In this article, leading
scientists, researchers and engineers discuss the transformative effects of
ChatGPT on modern education. This research seeks to improve our knowledge of
ChatGPT capabilities and its use in the education sector, identifying potential
concerns and challenges. Our preliminary evaluation concludes that ChatGPT
performed differently in each subject area including finance, coding and maths.
While ChatGPT has the ability to help educators by creating instructional
content, offering suggestions and acting as an online educator to learners by
answering questions and promoting group work, there are clear drawbacks in its
use, such as the possibility of producing inaccurate or false data and
circumventing duplicate content (plagiarism) detectors where originality is
essential. The often reported hallucinations within Generative AI in general,
and also relevant for ChatGPT, can render its use of limited benefit where
accuracy is essential. What ChatGPT lacks is a stochastic measure to help
provide sincere and sensitive communication with its users. Academic
regulations and evaluation practices used in educational institutions need to
be updated, should ChatGPT be used as a tool in education. To address the
transformative effects of ChatGPT on the learning environment, educating
teachers and students alike about its capabilities and limitations will be
crucial.",2023-05-25,2023,2023-05,education
"Chatbots to ChatGPT in a Cybersecurity Space: Evolution,
  Vulnerabilities, Attacks, Challenges, and Future Recommendations","Chatbots shifted from rule-based to artificial intelligence techniques and
gained traction in medicine, shopping, customer services, food delivery,
education, and research. OpenAI developed ChatGPT blizzard on the Internet as
it crossed one million users within five days of its launch. However, with the
enhanced popularity, chatbots experienced cybersecurity threats and
vulnerabilities. This paper discussed the relevant literature, reports, and
explanatory incident attacks generated against chatbots. Our initial point is
to explore the timeline of chatbots from ELIZA (an early natural language
processing computer program) to GPT-4 and provide the working mechanism of
ChatGPT. Subsequently, we explored the cybersecurity attacks and
vulnerabilities in chatbots. Besides, we investigated the ChatGPT, specifically
in the context of creating the malware code, phishing emails, undetectable
zero-day attacks, and generation of macros and LOLBINs. Furthermore, the
history of cyberattacks and vulnerabilities exploited by cybercriminals are
discussed, particularly considering the risk and vulnerabilities in ChatGPT.
Addressing these threats and vulnerabilities requires specific strategies and
measures to reduce the harmful consequences. Therefore, the future directions
to address the challenges were presented.",2023-05-29,2023,2023-05,education
"Using artificial-intelligence tools to make LaTeX content accessible to
  blind readers","Screen-reader software enables blind users to access large segments of
electronic content, particularly if accessibility standards are followed.
Unfortunately, this is not true for much of the content written in physics,
mathematics, and other STEM-disciplines, due to the strong reliance on
mathematical symbols and expressions, which screen-reader software generally
fails to process correctly. A large portion of such content is based on source
documents written in LaTeX, which are rendered to PDF or HTML for online
distribution. Unfortunately, the resulting PDF documents are essentially
inaccessible, and the HTML documents greatly vary in accessibility, since their
rendering using standard tools is cumbersome at best. The paper explores the
possibility of generating standards-compliant, accessible HTML from LaTeX
sources using Large Language Models. It is found that the resulting documents
are highly accessible, with possible complications occurring when the
artificial intelligence tool starts to interpret the content.",2023-06-04,2023,2023-06,education
Computing Education in the Era of Generative AI,"The computing education community has a rich history of pedagogical
innovation designed to support students in introductory courses, and to support
teachers in facilitating student learning. Very recent advances in artificial
intelligence have resulted in code generation models that can produce source
code from natural language problem descriptions -- with impressive accuracy in
many cases. The wide availability of these models and their ease of use has
raised concerns about potential impacts on many aspects of society, including
the future of computing education. In this paper, we discuss the challenges and
opportunities such models present to computing educators, with a focus on
introductory programming classrooms. We summarize the results of two recent
articles, the first evaluating the performance of code generation models on
typical introductory-level programming problems, and the second exploring the
quality and novelty of learning resources generated by these models. We
consider likely impacts of such models upon pedagogical practice in the context
of the most recent advances at the time of writing.",2023-06-05,2023,2023-06,education
"Is AI Changing the Rules of Academic Misconduct? An In-depth Look at
  Students' Perceptions of 'AI-giarism'","This pioneering study explores students' perceptions of AI-giarism, an
emergent form of academic dishonesty involving AI and plagiarism, within the
higher education context. A survey, undertaken by 393 undergraduate and
postgraduate students from a variety of disciplines, investigated their
perceptions of diverse AI-giarism scenarios. The findings portray a complex
landscape of understanding, with clear disapproval for direct AI content
generation, yet more ambivalent attitudes towards subtler uses of AI. The study
introduces a novel instrument, as an initial conceptualization of AI-giarism,
offering a significant tool for educators and policy-makers. This scale
facilitates understanding and discussions around AI-related academic
misconduct, aiding in pedagogical design and assessment in an era of AI
integration. Moreover, it challenges traditional definitions of academic
misconduct, emphasizing the need to adapt in response to evolving AI
technology. Despite limitations, such as the rapidly changing nature of AI and
the use of convenience sampling, the study provides pivotal insights for
academia, policy-making, and the broader integration of AI technology in
education.",2023-06-06,2023,2023-06,education
"The ADAIO System at the BEA-2023 Shared Task on Generating AI Teacher
  Responses in Educational Dialogues","This paper presents the ADAIO team's system entry in the Building Educational
Applications (BEA) 2023 Shared Task on Generating AI Teacher Responses in
Educational Dialogues. The task aims to assess the performance of
state-of-the-art generative models as AI teachers in producing suitable
responses within a student-teacher dialogue. Our system comprises evaluating
various baseline models using OpenAI GPT-3 and designing diverse prompts to
prompt the OpenAI models for teacher response generation. After the challenge,
our system achieved second place by employing a few-shot prompt-based approach
with the OpenAI text-davinci-003 model. The results highlight the few-shot
learning capabilities of large-language models, particularly OpenAI's GPT-3, in
the role of AI teachers.",2023-06-08,2023,2023-06,education
"Legal and ethical considerations regarding the use of ChatGPT in
  education","Artificial intelligence has evolved enormously over the last two decades,
becoming mainstream in different scientific domains including education, where
so far, it is mainly utilized to enhance administrative and intelligent
tutoring systems services and academic support. ChatGPT, an artificial
intelligence-based chatbot, developed by OpenAI and released in November 2022,
has rapidly gained attention from the entire international community for its
impressive performance in generating comprehensive, systematic, and informative
human-like responses to user input through natural language processing.
Inevitably, it has also rapidly posed several challenges, opportunities, and
potential issues and concerns raised regarding its use across various
scientific disciplines. This paper aims to discuss the legal and ethical
implications arising from this new technology, identify potential use cases,
and enrich our understanding of Generative AI, such as ChatGPT, and its
capabilities in education.",2023-06-09,2023,2023-06,education
More than programming? The impact of AI on work and skills,"This chapter explores the ways in which organisational readiness and
scientific advances in Artificial Intelligence have been affecting the demand
for skills and their training in Australia and other nations leading in the
promotion, use or development of AI. The consensus appears that having adequate
numbers of qualified data scientists and machine learning experts is critical
for meeting the challenges ahead. The chapter asks what this may mean for
Australia's education and training system, what needs to be taught and learned,
and whether technical skills are all that matter.",2023-06-09,2023,2023-06,education
"Employing Crowdsourcing for Enriching a Music Knowledge Base in Higher
  Education","This paper describes the methodology followed and the lessons learned from
employing crowdsourcing techniques as part of a homework assignment involving
higher education students of computer science. Making use of a platform that
supports crowdsourcing in the cultural heritage domain students were solicited
to enrich the metadata associated with a selection of music tracks. The results
of the campaign were further analyzed and exploited by students through the use
of semantic web technologies. In total, 98 students participated in the
campaign, contributing more than 6400 annotations concerning 854 tracks. The
process also led to the creation of an openly available annotated dataset,
which can be useful for machine learning models for music tagging. The
campaign's results and the comments gathered through an online survey enable us
to draw some useful insights about the benefits and challenges of integrating
crowdsourcing into computer science curricula and how this can enhance
students' engagement in the learning process.",2023-06-12,2023,2023-06,education
Leveraging Skill-to-Skill Supervision for Knowledge Tracing,"Knowledge tracing plays a pivotal role in intelligent tutoring systems. This
task aims to predict the probability of students answering correctly to
specific questions. To do so, knowledge tracing systems should trace the
knowledge state of the students by utilizing their problem-solving history and
knowledge about the problems. Recent advances in knowledge tracing models have
enabled better exploitation of problem solving history. However, knowledge
about problems has not been studied, as well compared to students' answering
histories. Knowledge tracing algorithms that incorporate knowledge directly are
important to settings with limited data or cold starts. Therefore, we consider
the problem of utilizing skill-to-skill relation to knowledge tracing. In this
work, we introduce expert labeled skill-to-skill relationships. Moreover, we
also provide novel methods to construct a knowledge-tracing model to leverage
human experts' insight regarding relationships between skills. The results of
an extensive experimental analysis show that our method outperformed a baseline
Transformer model. Furthermore, we found that the extent of our model's
superiority was greater in situations with limited data, which allows a smooth
cold start of our model.",2023-06-12,2023,2023-06,education
"Towards social generative AI for education: theory, practices and ethics","This paper explores educational interactions involving humans and artificial
intelligences not as sequences of prompts and responses, but as a social
process of conversation and exploration. In this conception, learners
continually converse with AI language models within a dynamic computational
medium of internet tools and resources. Learning happens when this distributed
system sets goals, builds meaning from data, consolidates understanding,
reconciles differences, and transfers knowledge to new domains. Building social
generative AI for education will require development of powerful AI systems
that can converse with each other as well as humans, construct external
representations such as knowledge maps, access and contribute to internet
resources, and act as teachers, learners, guides and mentors. This raises
fundamental problems of ethics. Such systems should be aware of their
limitations, their responsibility to learners and the integrity of the
internet, and their respect for human teachers and experts. We need to consider
how to design and constrain social generative AI for education.",2023-06-14,2023,2023-06,education
Maestro: A Gamified Platform for Teaching AI Robustness,"Although the prevention of AI vulnerabilities is critical to preserve the
safety and privacy of users and businesses, educational tools for robust AI are
still underdeveloped worldwide. We present the design, implementation, and
assessment of Maestro. Maestro is an effective open-source game-based platform
that contributes to the advancement of robust AI education. Maestro provides
goal-based scenarios where college students are exposed to challenging
life-inspired assignments in a competitive programming environment. We assessed
Maestro's influence on students' engagement, motivation, and learning success
in robust AI. This work also provides insights into the design features of
online learning tools that promote active learning opportunities in the robust
AI domain. We analyzed the reflection responses (measured with Likert scales)
of 147 undergraduate students using Maestro in two quarterly college courses in
AI. According to the results, students who felt the acquisition of new skills
in robust AI tended to appreciate highly Maestro and scored highly on material
consolidation, curiosity, and mastery in robust AI. Moreover, the leaderboard,
our key gamification element in Maestro, has effectively contributed to
students' engagement and learning. Results also indicate that Maestro can be
effectively adapted to any course length and depth without losing its
educational quality.",2023-06-14,2023,2023-06,education
"Friend or Foe? Exploring the Implications of Large Language Models on
  the Science System","The advent of ChatGPT by OpenAI has prompted extensive discourse on its
potential implications for science and higher education. While the impact on
education has been a primary focus, there is limited empirical research on the
effects of large language models (LLMs) and LLM-based chatbots on science and
scientific practice. To investigate this further, we conducted a Delphi study
involving 72 experts specialising in research and AI. The study focused on
applications and limitations of LLMs, their effects on the science system,
ethical and legal considerations, and the required competencies for their
effective use. Our findings highlight the transformative potential of LLMs in
science, particularly in administrative, creative, and analytical tasks.
However, risks related to bias, misinformation, and quality assurance need to
be addressed through proactive regulation and science education. This research
contributes to informed discussions on the impact of generative AI in science
and helps identify areas for future action.",2023-06-16,2023,2023-06,education
"Reorganizing Educational Institutional Domain using Faceted Ontological
  Principles","The purpose of this work is to find out how different library classification
systems and linguistic ontologies arrange a particular domain of interest and
what are the limitations for information retrieval. We use knowledge
representation techniques and languages for construction of a domain specific
ontology. This ontology would help not only in problem solving, but it would
demonstrate the ease with which complex queries can be handled using principles
of domain ontology, thereby facilitating better information retrieval.",2023-06-17,2023,2023-06,education
"Developing Effective Educational Chatbots with ChatGPT prompts: Insights
  from Preliminary Tests in a Case Study on Social Media Literacy (with
  appendix)","Educational chatbots come with a promise of interactive and personalized
learning experiences, yet their development has been limited by the restricted
free interaction capabilities of available platforms and the difficulty of
encoding knowledge in a suitable format. Recent advances in language learning
models with zero-shot learning capabilities, such as ChatGPT, suggest a new
possibility for developing educational chatbots using a prompt-based approach.
We present a case study with a simple system that enables mixed-turn chatbot
interactions and discuss the insights and preliminary guidelines obtained from
initial tests. We examine ChatGPT's ability to pursue multiple interconnected
learning objectives, adapt the educational activity to users' characteristics,
such as culture, age, and level of education, and its ability to use diverse
educational strategies and conversational styles. Although the results are
encouraging, challenges are posed by the limited history maintained for the
conversation and the highly structured form of responses by ChatGPT, as well as
their variability, which can lead to an unexpected switch of the chatbot's role
from a teacher to a therapist. We provide some initial guidelines to address
these issues and to facilitate the development of effective educational
chatbots.",2023-06-18,2023,2023-06,education
Modern Constraint Programming Education: Lessons for the Future,"This paper details an outlook on modern constraint programming (CP) education
through the lens of a CP instructor. A general overview of current CP courses
and instructional methods is presented, with a focus on online and
virtually-delivered courses. This is followed by a discussion of the novel
approach taken to introductory CP education for engineering students at large
scale at the Georgia Institute of Technology (Georgia Tech) in Atlanta, GA,
USA. The paper summarizes important takeaways from the Georgia Tech CP course
and ends with a discussion on the future of CP education. Some ideas for
instructional methods, promotional methods, and organizational changes are
proposed to aid in the long-term growth of CP education.",2023-06-20,2023,2023-06,education
Towards Enriched Controllability for Educational Question Generation,"Question Generation (QG) is a task within Natural Language Processing (NLP)
that involves automatically generating questions given an input, typically
composed of a text and a target answer. Recent work on QG aims to control the
type of generated questions so that they meet educational needs. A remarkable
example of controllability in educational QG is the generation of questions
underlying certain narrative elements, e.g., causal relationship, outcome
resolution, or prediction. This study aims to enrich controllability in QG by
introducing a new guidance attribute: question explicitness. We propose to
control the generation of explicit and implicit wh-questions from
children-friendly stories. We show preliminary evidence of controlling QG via
question explicitness alone and simultaneously with another target attribute:
the question's narrative element. The code is publicly available at
github.com/bernardoleite/question-generation-control.",2023-06-21,2023,2023-06,education
Testing of Detection Tools for AI-Generated Text,"Recent advances in generative pre-trained transformer large language models
have emphasised the potential risks of unfair use of artificial intelligence
(AI) generated content in an academic environment and intensified efforts in
searching for solutions to detect such content. The paper examines the general
functionality of detection tools for artificial intelligence generated text and
evaluates them based on accuracy and error type analysis. Specifically, the
study seeks to answer research questions about whether existing detection tools
can reliably differentiate between human-written text and ChatGPT-generated
text, and whether machine translation and content obfuscation techniques affect
the detection of AI-generated text. The research covers 12 publicly available
tools and two commercial systems (Turnitin and PlagiarismCheck) that are widely
used in the academic setting. The researchers conclude that the available
detection tools are neither accurate nor reliable and have a main bias towards
classifying the output as human-written rather than detecting AI-generated
text. Furthermore, content obfuscation techniques significantly worsen the
performance of tools. The study makes several significant contributions. First,
it summarises up-to-date similar scientific and non-scientific efforts in the
field. Second, it presents the result of one of the most comprehensive tests
conducted so far, based on a rigorous research methodology, an original
document set, and a broad coverage of tools. Third, it discusses the
implications and drawbacks of using detection tools for AI-generated text in
academic settings.",2023-06-21,2023,2023-06,education
"Potential Benefits of Employing Large Language Models in Research in
  Moral Education and Development","Recently, computer scientists have developed large language models (LLMs) by
training prediction models with large-scale language corpora and human
reinforcements. The LLMs have become one promising way to implement artificial
intelligence with accuracy in various fields. Interestingly, recent LLMs
possess emergent functional features that emulate sophisticated human
cognition, especially in-context learning and the chain of thought, which were
unavailable in previous prediction models. In this paper, I will examine how
LLMs might contribute to moral education and development research. To achieve
this goal, I will review the most recently published conference papers and
ArXiv preprints to overview the novel functional features implemented in LLMs.
I also intend to conduct brief experiments with ChatGPT to investigate how LLMs
behave while addressing ethical dilemmas and external feedback. The results
suggest that LLMs might be capable of solving dilemmas based on reasoning and
revising their reasoning process with external input. Furthermore, a
preliminary experimental result from the moral exemplar test may demonstrate
that exemplary stories can elicit moral elevation in LLMs as do they among
human participants. I will discuss the potential implications of LLMs on
research on moral education and development with the results.",2023-06-23,2023,2023-06,education
"Using Large Language Models to Provide Explanatory Feedback to Human
  Tutors","Research demonstrates learners engaging in the process of producing
explanations to support their reasoning, can have a positive impact on
learning. However, providing learners real-time explanatory feedback often
presents challenges related to classification accuracy, particularly in
domain-specific environments, containing situationally complex and nuanced
responses. We present two approaches for supplying tutors real-time feedback
within an online lesson on how to give students effective praise. This
work-in-progress demonstrates considerable accuracy in binary classification
for corrective feedback of effective, or effort-based (F1 score = 0.811), and
ineffective, or outcome-based (F1 score = 0.350), praise responses. More
notably, we introduce progress towards an enhanced approach of providing
explanatory feedback using large language model-facilitated named entity
recognition, which can provide tutors feedback, not only while engaging in
lessons, but can potentially suggest real-time tutor moves. Future work
involves leveraging large language models for data augmentation to improve
accuracy, while also developing an explanatory feedback interface.",2023-06-27,2023,2023-06,education
Emotion Analysis of Tweets Banning Education in Afghanistan,"This paper introduces the first emotion annotated dataset for the Dari
variant of Persian spoken in Afghanistan. The LetHerLearn dataset contains
7,600 tweets posted in reaction to the Taliban ban of women rights to education
in 2022 and has been manually annotated according to Ekman emotion categories.
We here detail the data collection and annotation process, present relevant
dataset statistics as well as initial experiments on the resulting dataset,
benchmarking a number of different neural architectures for the task of Dari
emotion classification.",2023-06-28,2023,2023-06,education
"Generative AI for Programming Education: Benchmarking ChatGPT, GPT-4,
  and Human Tutors","Generative AI and large language models hold great promise in enhancing
computing education by powering next-generation educational technologies for
introductory programming. Recent works have studied these models for different
scenarios relevant to programming education; however, these works are limited
for several reasons, as they typically consider already outdated models or only
specific scenario(s). Consequently, there is a lack of a systematic study that
benchmarks state-of-the-art models for a comprehensive set of programming
education scenarios. In our work, we systematically evaluate two models,
ChatGPT (based on GPT-3.5) and GPT-4, and compare their performance with human
tutors for a variety of scenarios. We evaluate using five introductory Python
programming problems and real-world buggy programs from an online platform, and
assess performance using expert-based annotations. Our results show that GPT-4
drastically outperforms ChatGPT (based on GPT-3.5) and comes close to human
tutors' performance for several scenarios. These results also highlight
settings where GPT-4 still struggles, providing exciting future directions on
developing techniques to improve the performance of these models.",2023-06-29,2023,2023-06,education
"Towards Anatomy Education with Generative AI-based Virtual Assistants in
  Immersive Virtual Reality Environments","Virtual reality (VR) and interactive 3D visualization systems have enhanced
educational experiences and environments, particularly in complicated subjects
such as anatomy education. VR-based systems surpass the potential limitations
of traditional training approaches in facilitating interactive engagement among
students. However, research on embodied virtual assistants that leverage
generative artificial intelligence (AI) and verbal communication in the anatomy
education context is underrepresented. In this work, we introduce a VR
environment with a generative AI-embodied virtual assistant to support
participants in responding to varying cognitive complexity anatomy questions
and enable verbal communication. We assessed the technical efficacy and
usability of the proposed environment in a pilot user study with 16
participants. We conducted a within-subject design for virtual assistant
configuration (avatar- and screen-based), with two levels of cognitive
complexity (knowledge- and analysis-based). The results reveal a significant
difference in the scores obtained from knowledge- and analysis-based questions
in relation to avatar configuration. Moreover, results provide insights into
usability, cognitive task load, and the sense of presence in the proposed
virtual assistant configurations. Our environment and results of the pilot
study offer potential benefits and future research directions beyond medical
education, using generative AI and embodied virtual agents as customized
virtual conversational assistants.",2023-06-29,2023,2023-06,education
"The future of human-centric eXplainable Artificial Intelligence (XAI) is
  not post-hoc explanations","Explainable Artificial Intelligence (XAI) plays a crucial role in enabling
human understanding and trust in deep learning systems. As models get larger,
more ubiquitous, and pervasive in aspects of daily life, explainability is
necessary to minimize adverse effects of model mistakes. Unfortunately, current
approaches in human-centric XAI (e.g. predictive tasks in healthcare,
education, or personalized ads) tend to rely on a single post-hoc explainer,
whereas recent work has identified systematic disagreement between post-hoc
explainers when applied to the same instances of underlying black-box models.
In this paper, we therefore present a call for action to address the
limitations of current state-of-the-art explainers. We propose a shift from
post-hoc explainability to designing interpretable neural network
architectures. We identify five needs of human-centric XAI (real-time,
accurate, actionable, human-interpretable, and consistent) and propose two
schemes for interpretable-by-design neural network workflows (adaptive routing
with InterpretCC and temporal diagnostics with I2MD). We postulate that the
future of human-centric XAI is neither in explaining black-boxes nor in
reverting to traditional, interpretable models, but in neural networks that are
intrinsically interpretable.",2023-07-01,2023,2023-07,education
"Transcribing Educational Videos Using Whisper: A preliminary study on
  using AI for transcribing educational videos","Videos are increasingly being used for e-learning, and transcripts are vital
to enhance the learning experience. The costs and delays of generating
transcripts can be alleviated by automatic speech recognition (ASR) systems. In
this article, we quantify the transcripts generated by whisper for 25
educational videos and identify some open avenues of research when leveraging
ASR for transcribing educational videos.",2023-07-04,2023,2023-07,education
"Learning to Prompt in the Classroom to Understand AI Limits: A pilot
  study","Artificial intelligence's (AI) progress holds great promise in tackling
pressing societal concerns such as health and climate. Large Language Models
(LLM) and the derived chatbots, like ChatGPT, have highly improved the natural
language processing capabilities of AI systems allowing them to process an
unprecedented amount of unstructured data. However, the ensuing excitement has
led to negative sentiments, even as AI methods demonstrate remarkable
contributions (e.g. in health and genetics). A key factor contributing to this
sentiment is the misleading perception that LLMs can effortlessly provide
solutions across domains, ignoring their limitations such as hallucinations and
reasoning constraints. Acknowledging AI fallibility is crucial to address the
impact of dogmatic overconfidence in possibly erroneous suggestions generated
by LLMs. At the same time, it can reduce fear and other negative attitudes
toward AI. This necessitates comprehensive AI literacy interventions that
educate the public about LLM constraints and effective usage techniques, i.e
prompting strategies. With this aim, a pilot educational intervention was
performed in a high school with 21 students. It involved presenting high-level
concepts about intelligence, AI, and LLMs, followed by practical exercises
involving ChatGPT in creating natural educational conversations and applying
established prompting strategies. Encouraging preliminary results emerged,
including high appreciation of the activity, improved interaction quality with
the LLM, reduced negative AI sentiments, and a better grasp of limitations,
specifically unreliability, limited understanding of commands leading to
unsatisfactory responses, and limited presentation flexibility. Our aim is to
explore AI acceptance factors and refine this approach for more controlled
future studies.",2023-07-04,2023,2023-07,education
AI4OPT: AI Institute for Advances in Optimization,"This article is a short introduction to AI4OPT, the NSF AI Institute for
Advances in Optimization. AI4OPT fuses AI and Optimization, inspired by end-use
cases in supply chains, energy systems, chip design and manufacturing, and
sustainable food systems. AI4OPT also applies its ""teaching the teachers""
philosophy to provide longitudinal educational pathways in AI for engineering.",2023-07-05,2023,2023-07,education
"Generative Adversarial Networks for Dental Patient Identity Protection
  in Orthodontic Educational Imaging","Objectives: This research introduces a novel area-preserving Generative
Adversarial Networks (GAN) inversion technique for effectively de-identifying
dental patient images. This innovative method addresses privacy concerns while
preserving key dental features, thereby generating valuable resources for
dental education and research.
  Methods: We enhanced the existing GAN Inversion methodology to maximize the
preservation of dental characteristics within the synthesized images. A
comprehensive technical framework incorporating several deep learning models
was developed to provide end-to-end development guidance and practical
application for image de-identification.
  Results: Our approach was assessed with varied facial pictures, extensively
used for diagnosing skeletal asymmetry and facial anomalies. Results
demonstrated our model's ability to adapt the context from one image to
another, maintaining compatibility, while preserving dental features essential
for oral diagnosis and dental education. A panel of five clinicians conducted
an evaluation on a set of original and GAN-processed images. The generated
images achieved effective de-identification, maintaining the realism of
important dental features and were deemed useful for dental diagnostics and
education.
  Clinical Significance: Our GAN model and the encompassing framework can
streamline the de-identification process of dental patient images, enhancing
efficiency in dental education. This method improves students' diagnostic
capabilities by offering more exposure to orthodontic malocclusions.
Furthermore, it facilitates the creation of de-identified datasets for broader
2D image research at major research institutions.",2023-07-05,2023,2023-07,education
"Comparative Analysis of GPT-4 and Human Graders in Evaluating Praise
  Given to Students in Synthetic Dialogues","Research suggests that providing specific and timely feedback to human tutors
enhances their performance. However, it presents challenges due to the
time-consuming nature of assessing tutor performance by human evaluators. Large
language models, such as the AI-chatbot ChatGPT, hold potential for offering
constructive feedback to tutors in practical settings. Nevertheless, the
accuracy of AI-generated feedback remains uncertain, with scant research
investigating the ability of models like ChatGPT to deliver effective feedback.
In this work-in-progress, we evaluate 30 dialogues generated by GPT-4 in a
tutor-student setting. We use two different prompting approaches, the zero-shot
chain of thought and the few-shot chain of thought, to identify specific
components of effective praise based on five criteria. These approaches are
then compared to the results of human graders for accuracy. Our goal is to
assess the extent to which GPT-4 can accurately identify each praise criterion.
We found that both zero-shot and few-shot chain of thought approaches yield
comparable results. GPT-4 performs moderately well in identifying instances
when the tutor offers specific and immediate praise. However, GPT-4
underperforms in identifying the tutor's ability to deliver sincere praise,
particularly in the zero-shot prompting scenario where examples of sincere
tutor praise statements were not provided. Future work will focus on enhancing
prompt engineering, developing a more general tutoring rubric, and evaluating
our method using real-life tutoring dialogues.",2023-07-05,2023,2023-07,education
"It is not Sexually Suggestive, It is Educative. Separating Sex Education
  from Suggestive Content on TikTok Videos","We introduce SexTok, a multi-modal dataset composed of TikTok videos labeled
as sexually suggestive (from the annotator's point of view), sex-educational
content, or neither. Such a dataset is necessary to address the challenge of
distinguishing between sexually suggestive content and virtual sex education
videos on TikTok. Children's exposure to sexually suggestive videos has been
shown to have adversarial effects on their development. Meanwhile, virtual sex
education, especially on subjects that are more relevant to the LGBTQIA+
community, is very valuable. The platform's current system removes or penalizes
some of both types of videos, even though they serve different purposes. Our
dataset contains video URLs, and it is also audio transcribed. To validate its
importance, we explore two transformer-based models for classifying the videos.
Our preliminary results suggest that the task of distinguishing between these
types of videos is learnable but challenging. These experiments suggest that
this dataset is meaningful and invites further study on the subject.",2023-07-06,2023,2023-07,education
What Should Data Science Education Do with Large Language Models?,"The rapid advances of large language models (LLMs), such as ChatGPT, are
revolutionizing data science and statistics. These state-of-the-art tools can
streamline complex processes. As a result, it reshapes the role of data
scientists. We argue that LLMs are transforming the responsibilities of data
scientists, shifting their focus from hands-on coding, data-wrangling and
conducting standard analyses to assessing and managing analyses performed by
these automated AIs. This evolution of roles is reminiscent of the transition
from a software engineer to a product manager. We illustrate this transition
with concrete data science case studies using LLMs in this paper. These
developments necessitate a meaningful evolution in data science education.
Pedagogy must now place greater emphasis on cultivating diverse skillsets among
students, such as LLM-informed creativity, critical thinking, AI-guided
programming. LLMs can also play a significant role in the classroom as
interactive teaching and learning tools, contributing to personalized
education. This paper discusses the opportunities, resources and open
challenges for each of these directions. As with any transformative technology,
integrating LLMs into education calls for careful consideration. While LLMs can
perform repetitive tasks efficiently, it's crucial to remember that their role
is to supplement human intelligence and creativity, not to replace it.
Therefore, the new era of data science education should balance the benefits of
LLMs while fostering complementary human expertise and innovations. In
conclusion, the rise of LLMs heralds a transformative period for data science
and its education. This paper seeks to shed light on the emerging trends,
potential opportunities, and challenges accompanying this paradigm shift,
hoping to spark further discourse and investigation into this exciting,
uncharted territory.",2023-07-06,2023,2023-07,education
"EFL Students' Attitudes and Contradictions in a Machine-in-the-loop
  Activity System","This study applies Activity Theory and investigates the attitudes and
contradictions of 67 English as a foreign language (EFL) students from four
Hong Kong secondary schools towards machine-in-the-loop writing, where
artificial intelligence (AI) suggests ideas during composition. Students
answered an open-ended question about their feelings on writing with AI.
Results revealed mostly positive attitudes, with some negative or mixed
feelings. From a thematic analysis, contradictions or points of tension between
students and AI stemmed from AI inadequacies, students' balancing enthusiasm
with preference, and their striving for language autonomy. The research
highlights the benefits and challenges of implementing machine-in-the-loop
writing in EFL classrooms, suggesting educators align activity goals with
students' values, language abilities, and AI capabilities to enhance students'
activity systems.",2023-07-13,2023,2023-07,education
"Balancing Privacy and Progress in Artificial Intelligence: Anonymization
  in Histopathology for Biomedical Research and Education","The advancement of biomedical research heavily relies on access to large
amounts of medical data. In the case of histopathology, Whole Slide Images
(WSI) and clinicopathological information are valuable for developing
Artificial Intelligence (AI) algorithms for Digital Pathology (DP).
Transferring medical data ""as open as possible"" enhances the usability of the
data for secondary purposes but poses a risk to patient privacy. At the same
time, existing regulations push towards keeping medical data ""as closed as
necessary"" to avoid re-identification risks. Generally, these legal regulations
require the removal of sensitive data but do not consider the possibility of
data linkage attacks due to modern image-matching algorithms. In addition, the
lack of standardization in DP makes it harder to establish a single solution
for all formats of WSIs. These challenges raise problems for bio-informatics
researchers in balancing privacy and progress while developing AI algorithms.
This paper explores the legal regulations and terminologies for medical
data-sharing. We review existing approaches and highlight challenges from the
histopathological perspective. We also present a data-sharing guideline for
histological data to foster multidisciplinary research and education.",2023-07-18,2023,2023-07,education
Amortised Design Optimization for Item Response Theory,"Item Response Theory (IRT) is a well known method for assessing responses
from humans in education and psychology. In education, IRT is used to infer
student abilities and characteristics of test items from student responses.
Interactions with students are expensive, calling for methods that efficiently
gather information for inferring student abilities. Methods based on Optimal
Experimental Design (OED) are computationally costly, making them inapplicable
for interactive applications. In response, we propose incorporating amortised
experimental design into IRT. Here, the computational cost is shifted to a
precomputing phase by training a Deep Reinforcement Learning (DRL) agent with
synthetic data. The agent is trained to select optimally informative test items
for the distribution of students, and to conduct amortised inference
conditioned on the experiment outcomes. During deployment the agent estimates
parameters from data, and suggests the next test item for the student, in close
to real-time, by taking into account the history of experiments and outcomes.",2023-07-19,2023,2023-07,education
Solving differential equations with Deep Learning: a beginner's guide,"The research in Artificial Intelligence methods with potential applications
in science has become an essential task in the scientific community last years.
Physics Informed Neural Networks (PINNs) is one of this methods and represent a
contemporary technique that is based on the fundamentals of neural networks to
solve differential equations. These kind of networks have the potential to
improve or complement classical numerical methods in computational physics,
making them an exciting area of study. In this paper, we introduce PINNs at an
elementary level, mainly oriented to physics education so making them suitable
for educational purposes at both undergraduate and graduate levels. PINNs can
be used to create virtual simulations and educational tools that aid in
understating complex physical concepts and processes where differential
equations are involved. By combining the power of neural networks with physics
principles, PINNs can provide an interactive and engaging learning experience
that can improve students' understanding and retention of physics concepts in
higher education.",2023-07-20,2023,2023-07,education
"How to Design and Deliver Courses for Higher Education in the AI Era:
  Insights from Exam Data Analysis","In this position paper, we advocate for the idea that courses and exams in
the AI era have to be designed based on two factors: (1) the strengths and
limitations of AI, and (2) the pedagogical educational objectives. Based on
insights from the Delors report on education [1], we first address the role of
education and recall the main objectives that educational institutes must
strive to achieve independently of any technology. We then explore the
strengths and limitations of AI, based on current advances in AI. We explain
how courses and exams can be designed based on these strengths and limitations
of AI, providing different examples in the IT, English, and Art domains. We
show how we adopted a pedagogical approach that is inspired from the Socratic
teaching method from January 2023 to May 2023. Then, we present the data
analysis results of seven ChatGPT-authorized exams conducted between December
2022 and March 2023. Our exam data results show that there is no correlation
between students' grades and whether or not they use ChatGPT to answer their
exam questions. Finally, we present a new exam system that allows us to apply
our pedagogical approach in the AI era.",2023-07-22,2023,2023-07,education
"The Imitation Game: Detecting Human and AI-Generated Texts in the Era of
  ChatGPT and BARD","The potential of artificial intelligence (AI)-based large language models
(LLMs) holds considerable promise in revolutionizing education, research, and
practice. However, distinguishing between human-written and AI-generated text
has become a significant task. This paper presents a comparative study,
introducing a novel dataset of human-written and LLM-generated texts in
different genres: essays, stories, poetry, and Python code. We employ several
machine learning models to classify the texts. Results demonstrate the efficacy
of these models in discerning between human and AI-generated text, despite the
dataset's limited sample size. However, the task becomes more challenging when
classifying GPT-generated text, particularly in story writing. The results
indicate that the models exhibit superior performance in binary classification
tasks, such as distinguishing human-generated text from a specific LLM,
compared to the more complex multiclass tasks that involve discerning among
human-generated and multiple LLMs. Our findings provide insightful implications
for AI text detection while our dataset paves the way for future research in
this evolving area.",2023-07-22,2023,2023-07,education
Use Scenarios & Practical Examples of AI Use in Education,"This report presents a set of use scenarios based on existing resources that
teachers can use as inspiration to create their own, with the aim of
introducing artificial intelligence (AI) at different pre-university levels,
and with different goals. The Artificial Intelligence Education field (AIEd) is
very active, with new resources and tools arising continuously. Those included
in this document have already been tested with students and selected by experts
in the field, but they must be taken just as practical examples to guide and
inspire teachers creativity.",2023-07-25,2023,2023-07,education
"AI and Education: An Investigation into the Use of ChatGPT for Systems
  Thinking","This exploratory study investigates the potential of the artificial
intelligence tool, ChatGPT, to support systems thinking (ST) in various
subjects. Using both general and subject specific prompts, the study assesses
the accuracy, helpfulness, and reliability of ChatGPT's responses across
different versions of the tool. The results indicate that ChatGPT can provide
largely correct and very helpful responses in various subjects, demonstrating
its potential as a tool for enhancing ST skills. However, occasional
inaccuracies highlight the need for users to remain critical of ChatGPT's
responses. Despite some limitations, this study suggests that with careful use
and attention to its idiosyncrasies, ChatGPT can be a valuable tool for
teaching and learning ST.",2023-07-26,2023,2023-07,education
"A Large-Scale Feasibility Study of Screen-based 3D Visualization and
  Augmented Reality Tools for Human Anatomy Education: Exploring Gender
  Perspectives in Learning Experience","Anatomy education is an indispensable part of medical training, but
traditional methods face challenges like limited resources for dissection in
large classes and difficulties understanding 2D anatomy in textbooks. Advanced
technologies, such as 3D visualization and augmented reality (AR), are
transforming anatomy learning. This paper presents two in-house solutions that
use handheld tablets or screen-based AR to visualize 3D anatomy models with
informative labels and in-situ visualizations of the muscle anatomy. To assess
these tools, a user study of muscle anatomy education involved 236 premedical
students in dyadic teams, with results showing that the tablet-based 3D
visualization and screen-based AR tools led to significantly higher learning
experience scores than traditional textbook. While knowledge retention didn't
differ significantly, ethnographic and gender analysis showed that male
students generally reported more positive learning experiences than female
students. This study discusses the implications for anatomy and medical
education, highlighting the potential of these innovative learning tools
considering gender and team dynamics in body painting anatomy learning
interventions.",2023-07-26,2023,2023-07,education
"Education 5.0: Requirements, Enabling Technologies, and Future
  Directions","We are currently in a post-pandemic era in which life has shifted to a
digital world. This has affected many aspects of life, including education and
learning. Education 5.0 refers to the fifth industrial revolution in education
by leveraging digital technologies to eliminate barriers to learning, enhance
learning methods, and promote overall well-being. The concept of Education 5.0
represents a new paradigm in the field of education, one that is focused on
creating a learner-centric environment that leverages the latest technologies
and teaching methods. This paper explores the key requirements of Education 5.0
and the enabling technologies that make it possible, including artificial
intelligence, blockchain, and virtual and augmented reality. We analyze the
potential impact of these technologies on the future of education, including
their ability to improve personalization, increase engagement, and provide
greater access to education. Additionally, we examine the challenges and
ethical considerations associated with Education 5.0 and propose strategies for
addressing these issues. Finally, we offer insights into future directions for
the development of Education 5.0, including the need for ongoing research,
collaboration, and innovation in the field. Overall, this paper provides a
comprehensive overview of Education 5.0, its requirements, enabling
technologies, and future directions, and highlights the potential of this new
paradigm to transform education and improve learning outcomes for students.",2023-07-29,2023,2023-07,education
Evaluating ChatGPT and GPT-4 for Visual Programming,"Generative AI and large language models have the potential to drastically
improve the landscape of computing education by automatically generating
personalized feedback and content. Recent works have studied the capabilities
of these models for different programming education scenarios; however, these
works considered only text-based programming, in particular, Python
programming. Consequently, they leave open the question of how well these
models would perform in visual programming domains popularly used for K-8
programming education. The main research question we study is: Do
state-of-the-art generative models show advanced capabilities in visual
programming on par with their capabilities in text-based Python programming? In
our work, we evaluate two models, ChatGPT (based on GPT-3.5) and GPT-4, in
visual programming domains for various scenarios and assess performance using
expert-based annotations. In particular, we base our evaluation using reference
tasks from the domains of Hour of Code: Maze Challenge by Code-dot-org and
Karel. Our results show that these models perform poorly and struggle to
combine spatial, logical, and programming skills crucial for visual
programming. These results also provide exciting directions for future work on
developing techniques to improve the performance of generative models in visual
programming.",2023-07-30,2023,2023-07,education
"Retrieval Augmented Generation and Representative Vector Summarization
  for large unstructured textual data in Medical Education","Large Language Models are increasingly being used for various tasks including
content generation and as chatbots. Despite their impressive performances in
general tasks, LLMs need to be aligned when applying for domain specific tasks
to mitigate the problems of hallucination and producing harmful answers.
Retrieval Augmented Generation (RAG) allows to easily attach and manipulate a
non-parametric knowledgebases to LLMs. Applications of RAG in the field of
medical education are discussed in this paper. A combined extractive and
abstractive summarization method for large unstructured textual data using
representative vectors is proposed.",2023-08-01,2023,2023-08,education
Is GPT-4 a reliable rater? Evaluating Consistency in GPT-4 Text Ratings,"This study investigates the consistency of feedback ratings generated by
OpenAI's GPT-4, a state-of-the-art artificial intelligence language model,
across multiple iterations, time spans and stylistic variations. The model
rated responses to tasks within the Higher Education (HE) subject domain of
macroeconomics in terms of their content and style. Statistical analysis was
conducted in order to learn more about the interrater reliability, consistency
of the ratings across iterations and the correlation between ratings in terms
of content and style. The results revealed a high interrater reliability with
ICC scores ranging between 0.94 and 0.99 for different timespans, suggesting
that GPT-4 is capable of generating consistent ratings across repetitions with
a clear prompt. Style and content ratings show a high correlation of 0.87. When
applying a non-adequate style the average content ratings remained constant,
while style ratings decreased, which indicates that the large language model
(LLM) effectively distinguishes between these two criteria during evaluation.
The prompt used in this study is furthermore presented and explained. Further
research is necessary to assess the robustness and reliability of AI models in
various use cases.",2023-08-03,2023,2023-08,education
"AI Chatbots as Multi-Role Pedagogical Agents: Transforming Engagement in
  CS Education","This study investigates the use of Artificial Intelligence (AI)-powered,
multi-role chatbots as a means to enhance learning experiences and foster
engagement in computer science education. Leveraging a design-based research
approach, we develop, implement, and evaluate a novel learning environment
enriched with four distinct chatbot roles: Instructor Bot, Peer Bot, Career
Advising Bot, and Emotional Supporter Bot. These roles, designed around the
tenets of Self-Determination Theory, cater to the three innate psychological
needs of learners - competence, autonomy, and relatedness. Additionally, the
system embraces an inquiry-based learning paradigm, encouraging students to ask
questions, seek solutions, and explore their curiosities.
  We test this system in a higher education context over a period of one month
with 200 participating students, comparing outcomes with conditions involving a
human tutor and a single chatbot. Our research utilizes a mixed-methods
approach, encompassing quantitative measures such as chat log sequence
analysis, and qualitative methods including surveys and focus group interviews.
By integrating cutting-edge Natural Language Processing techniques such as
topic modelling and sentiment analysis, we offer an in-depth understanding of
the system's impact on learner engagement, motivation, and inquiry-based
learning.
  This study, through its rigorous design and innovative approach, provides
significant insights into the potential of AI-empowered, multi-role chatbots in
reshaping the landscape of computer science education and fostering an
engaging, supportive, and motivating learning environment.",2023-08-08,2023,2023-08,education
"Assessing Student Errors in Experimentation Using Artificial
  Intelligence and Large Language Models: A Comparative Study with Human Raters","Identifying logical errors in complex, incomplete or even contradictory and
overall heterogeneous data like students' experimentation protocols is
challenging. Recognizing the limitations of current evaluation methods, we
investigate the potential of Large Language Models (LLMs) for automatically
identifying student errors and streamlining teacher assessments. Our aim is to
provide a foundation for productive, personalized feedback. Using a dataset of
65 student protocols, an Artificial Intelligence (AI) system based on the
GPT-3.5 and GPT-4 series was developed and tested against human raters. Our
results indicate varying levels of accuracy in error detection between the AI
system and human raters. The AI system can accurately identify many fundamental
student errors, for instance, the AI system identifies when a student is
focusing the hypothesis not on the dependent variable but solely on an expected
observation (acc. = 0.90), when a student modifies the trials in an ongoing
investigation (acc. = 1), and whether a student is conducting valid test trials
(acc. = 0.82) reliably. The identification of other, usually more complex
errors, like whether a student conducts a valid control trial (acc. = .60),
poses a greater challenge. This research explores not only the utility of AI in
educational settings, but also contributes to the understanding of the
capabilities of LLMs in error detection in inquiry-based learning like
experimentation.",2023-08-11,2023,2023-08,education
"LittleMu: Deploying an Online Virtual Teaching Assistant via
  Heterogeneous Sources Integration and Chain of Teach Prompts","Teaching assistants have played essential roles in the long history of
education. However, few MOOC platforms are providing human or virtual teaching
assistants to support learning for massive online students due to the
complexity of real-world online education scenarios and the lack of training
data. In this paper, we present a virtual MOOC teaching assistant, LittleMu
with minimum labeled training data, to provide question answering and chit-chat
services. Consisting of two interactive modules of heterogeneous retrieval and
language model prompting, LittleMu first integrates structural, semi- and
unstructured knowledge sources to support accurate answers for a wide range of
questions. Then, we design delicate demonstrations named ""Chain of Teach""
prompts to exploit the large-scale pre-trained model to handle complex
uncollected questions. Except for question answering, we develop other
educational services such as knowledge-grounded chit-chat. We test the system's
performance via both offline evaluation and online deployment. Since May 2020,
our LittleMu system has served over 80,000 users with over 300,000 queries from
over 500 courses on XuetangX MOOC platform, which continuously contributes to a
more convenient and fair education. Our code, services, and dataset will be
available at https://github.com/THU-KEG/VTA.",2023-08-11,2023,2023-08,education
Education in the age of Generative AI: Context and Recent Developments,"With the emergence of generative artificial intelligence, an increasing
number of individuals and organizations have begun exploring its potential to
enhance productivity and improve product quality across various sectors. The
field of education is no exception. However, it is vital to notice that
artificial intelligence adoption in education dates back to the 1960s. In light
of this historical context, this white paper serves as the inaugural piece in a
four-part series that elucidates the role of AI in education. The series delves
into topics such as its potential, successful applications, limitations,
ethical considerations, and future trends. This initial article provides a
comprehensive overview of the field, highlighting the recent developments
within the generative artificial intelligence sphere.",2023-08-17,2023,2023-08,education
"Exploring the Power of Creative AI Tools and Game-Based Methodologies
  for Interactive Web-Based Programming","In recent years, the fields of artificial intelligence and web-based
programming have seen tremendous advancements, enabling developers to create
dynamic and interactive websites and applications. At the forefront of these
advancements, creative AI tools and game-based methodologies have emerged as
potent instruments, promising enhanced user experiences and increased
engagement in educational environments. This chapter explores the potential of
these tools and methodologies for interactive web-based programming, examining
their benefits, limitations, and real-world applications. We examine the
challenges and ethical considerations that arise when integrating these
technologies into web development, such as privacy concerns and the potential
for bias in AI-generated content. Through this exploration, we aim to provide
insights into the exciting possibilities that creative AI tools and game-based
methodologies offer for the future of web-based programming.",2023-08-18,2023,2023-08,education
"Artificial Intelligence across Europe: A Study on Awareness, Attitude
  and Trust","This paper presents the results of an extensive study investigating the
opinions on Artificial Intelligence (AI) of a sample of 4,006 European citizens
from eight distinct countries (France, Germany, Italy, Netherlands, Poland,
Romania, Spain, and Sweden). The aim of the study is to gain a better
understanding of people's views and perceptions within the European context,
which is already marked by important policy actions and regulatory processes.
To survey the perceptions of the citizens of Europe we design and validate a
new questionnaire (PAICE) structured around three dimensions: people's
awareness, attitude, and trust. We observe that while awareness is
characterized by a low level of self-assessed competency, the attitude toward
AI is very positive for more than half of the population. Reflecting upon the
collected results, we highlight implicit contradictions and identify trends
that may interfere with the creation of an ecosystem of trust and the
development of inclusive AI policies. The introduction of rules that ensure
legal and ethical standards, along with the activity of high-level educational
entities, and the promotion of AI literacy are identified as key factors in
supporting a trustworthy AI ecosystem. We make some recommendations for AI
governance focused on the European context and conclude with suggestions for
future work.",2023-08-19,2023,2023-08,education
"Elucidating STEM Concepts through Generative AI: A Multi-modal
  Exploration of Analogical Reasoning","This study explores the integration of generative artificial intelligence
(AI), specifically large language models, with multi-modal analogical reasoning
as an innovative approach to enhance science, technology, engineering, and
mathematics (STEM) education. We have developed a novel system that utilizes
the capacities of generative AI to transform intricate principles in
mathematics, physics, and programming into comprehensible metaphors. To further
augment the educational experience, these metaphors are subsequently converted
into visual form. Our study aims to enhance the learners' understanding of STEM
concepts and their learning engagement by using the visual metaphors. We
examine the efficacy of our system via a randomized A/B/C test, assessing
learning gains and motivation shifts among the learners. Our study demonstrates
the potential of applying large language models to educational practice on STEM
subjects. The results will shed light on the design of educational system in
terms of harnessing AI's potential to empower educational stakeholders.",2023-08-21,2023,2023-08,education
"Unreflected Acceptance -- Investigating the Negative Consequences of
  ChatGPT-Assisted Problem Solving in Physics Education","Large language models (LLMs) have recently gained popularity. However, the
impact of their general availability through ChatGPT on sensitive areas of
everyday life, such as education, remains unclear. Nevertheless, the societal
impact on established educational methods is already being experienced by both
students and educators. Our work focuses on higher physics education and
examines problem solving strategies. In a study, students with a background in
physics were assigned to solve physics exercises, with one group having access
to an internet search engine (N=12) and the other group being allowed to use
ChatGPT (N=27). We evaluated their performance, strategies, and interaction
with the provided tools. Our results showed that nearly half of the solutions
provided with the support of ChatGPT were mistakenly assumed to be correct by
the students, indicating that they overly trusted ChatGPT even in their field
of expertise. Likewise, in 42% of cases, students used copy & paste to query
ChatGPT -- an approach only used in 4% of search engine queries -- highlighting
the stark differences in interaction behavior between the groups and indicating
limited reflection when using ChatGPT. In our work, we demonstrated a need to
(1) guide students on how to interact with LLMs and (2) create awareness of
potential shortcomings for users.",2023-08-21,2023,2023-08,education
"Spoken Language Intelligence of Large Language Models for Language
  Learning","People have long hoped for a conversational system that can assist in
real-life situations, and recent progress on large language models (LLMs) is
bringing this idea closer to reality. While LLMs are often impressive in
performance, their efficacy in real-world scenarios that demand expert
knowledge remains unclear. LLMs are believed to hold the most potential and
value in education, especially in the development of Artificial intelligence
(AI) based virtual teachers capable of facilitating language learning. Our
focus is centered on evaluating the efficacy of LLMs in the realm of education,
specifically in the areas of spoken language learning which encompass
phonetics, phonology, and second language acquisition. We introduce a new
multiple-choice question dataset to evaluate the effectiveness of LLMs in the
aforementioned scenarios, including understanding and application of spoken
language knowledge. In addition, we investigate the influence of various
prompting techniques such as zero- and few-shot method (prepending the question
with question-answer exemplars), chain-of-thought (CoT, think step-by-step),
in-domain exampler and external tools (Google, Wikipedia). We conducted
large-scale evaluation on popular LLMs (20 distinct models) using these
methods. We achieved significant performance improvements compared to the
zero-shot baseline in the practical questions reasoning (GPT-3.5, 49.1% ->
63.1%; LLaMA2-70B-Chat, 42.2% -> 48.6%). We found that models of different
sizes have good understanding of concepts in phonetics, phonology, and second
language acquisition, but show limitations in reasoning for real-world
problems. Additionally, we also explore preliminary findings on conversational
communication.",2023-08-28,2023,2023-08,education
"AI-Based Facial Emotion Recognition Solutions for Education: A Study of
  Teacher-User and Other Categories","Existing information on AI-based facial emotion recognition (FER) is not
easily comprehensible by those outside the field of computer science, requiring
cross-disciplinary effort to determine a categorisation framework that promotes
the understanding of this technology, and its impact on users. Most proponents
classify FER in terms of methodology, implementation and analysis; relatively
few by its application in education; and none by its users. This paper is
concerned primarily with (potential) teacher-users of FER tools for education.
It proposes a three-part classification of these teachers, by orientation,
condition and preference, based on a classical taxonomy of affective
educational objectives, and related theories. It also compiles and organises
the types of FER solutions found in or inferred from the literature into
""technology"" and ""applications"" categories, as a prerequisite for structuring
the proposed ""teacher-user"" category. This work has implications for
proponents', critics', and users' understanding of the relationship between
teachers and FER.",2023-08-29,2023,2023-08,education
"Automatic assessment of text-based responses in post-secondary
  education: A systematic review","Text-based open-ended questions in academic formative and summative
assessments help students become deep learners and prepare them to understand
concepts for a subsequent conceptual assessment. However, grading text-based
questions, especially in large courses, is tedious and time-consuming for
instructors. Text processing models continue progressing with the rapid
development of Artificial Intelligence (AI) tools and Natural Language
Processing (NLP) algorithms. Especially after breakthroughs in Large Language
Models (LLM), there is immense potential to automate rapid assessment and
feedback of text-based responses in education. This systematic review adopts a
scientific and reproducible literature search strategy based on the PRISMA
process using explicit inclusion and exclusion criteria to study text-based
automatic assessment systems in post-secondary education, screening 838 papers
and synthesizing 93 studies. To understand how text-based automatic assessment
systems have been developed and applied in education in recent years, three
research questions are considered. All included studies are summarized and
categorized according to a proposed comprehensive framework, including the
input and output of the system, research motivation, and research outcomes,
aiming to answer the research questions accordingly. Additionally, the typical
studies of automated assessment systems, research methods, and application
domains in these studies are investigated and summarized. This systematic
review provides an overview of recent educational applications of text-based
assessment systems for understanding the latest AI/NLP developments assisting
in text-based assessments in higher education. Findings will particularly
benefit researchers and educators incorporating LLMs such as ChatGPT into their
educational activities.",2023-08-30,2023,2023-08,education
"Ethical Framework for Harnessing the Power of AI in Healthcare and
  Beyond","In the past decade, the deployment of deep learning (Artificial Intelligence
(AI)) methods has become pervasive across a spectrum of real-world
applications, often in safety-critical contexts. This comprehensive research
article rigorously investigates the ethical dimensions intricately linked to
the rapid evolution of AI technologies, with a particular focus on the
healthcare domain. Delving deeply, it explores a multitude of facets including
transparency, adept data management, human oversight, educational imperatives,
and international collaboration within the realm of AI advancement. Central to
this article is the proposition of a conscientious AI framework, meticulously
crafted to accentuate values of transparency, equity, answerability, and a
human-centric orientation. The second contribution of the article is the
in-depth and thorough discussion of the limitations inherent to AI systems. It
astutely identifies potential biases and the intricate challenges of navigating
multifaceted contexts. Lastly, the article unequivocally accentuates the
pressing need for globally standardized AI ethics principles and frameworks.
Simultaneously, it aptly illustrates the adaptability of the ethical framework
proposed herein, positioned skillfully to surmount emergent challenges.",2023-08-31,2023,2023-08,education
"The Impact of Artificial Intelligence on the Evolution of Digital
  Education: A Comparative Study of OpenAI Text Generation Tools including
  ChatGPT, Bing Chat, Bard, and Ernie","In the digital era, the integration of artificial intelligence (AI) in
education has ushered in transformative changes, redefining teaching
methodologies, curriculum planning, and student engagement. This review paper
delves deep into the rapidly evolving landscape of digital education by
contrasting the capabilities and impact of OpenAI's pioneering text generation
tools like Bing Chat, Bard, Ernie with a keen focus on the novel ChatGPT.
Grounded in a typology that views education through the lenses of system,
process, and result, the paper navigates the multifaceted applications of AI.
From decentralizing global education and personalizing curriculums to digitally
documenting competence-based outcomes, AI stands at the forefront of
educational modernization. Highlighting ChatGPT's meteoric rise to one million
users in just five days, the study underscores its role in democratizing
education, fostering autodidacticism, and magnifying student engagement.
However, with such transformative power comes the potential for misuse, as
text-generation tools can inadvertently challenge academic integrity. By
juxtaposing the promise and pitfalls of AI in education, this paper advocates
for a harmonized synergy between AI tools and the educational community,
emphasizing the urgent need for ethical guidelines, pedagogical adaptations,
and strategic collaborations.",2023-09-05,2023,2023-09,education
Using Curriculum Theory to Inform Approaches to Generative AI in Schools,"In an educational landscape dramatically altered by the swift proliferation
of Large Language Models, this essay interrogates the urgent this essay
interrogates the urgent pedagogical modifications required in secondary
schooling. Anchored in Madeline Grumet's triadic framework of curriculum
inquiry, the study delineates the multifaceted relationship between Generative
AI and Elliot Eisner's explicit, implicit, and null curriculum concepts. It
scrutinizes the logistical and ethical challenges, such as the reliability of
AI detectors, that educators confront when attempting to assimilate this
nascent technology into long-standing curricular structures. Engaging with Ted
Aoki's theory of the ""zone of between"", the essay illuminates educators'
dilemmas in reconciling prescriptive curricular aims with the fluid realities
of classroom life, all within an educational milieu in constant flux due to
Generative AI. The paper culminates in a reflective analysis by the researcher,
identifying avenues for further scholarly investigation within each of Grumet's
constitutive strands of curriculum theory, thereby providing a roadmap for
future research on Generative AI's transformative impact on educational
practice.",2023-09-07,2023,2023-09,education
"Beyond Traditional Teaching: The Potential of Large Language Models and
  Chatbots in Graduate Engineering Education","In the rapidly evolving landscape of education, digital technologies have
repeatedly disrupted traditional pedagogical methods. This paper explores the
latest of these disruptions: the potential integration of large language models
(LLMs) and chatbots into graduate engineering education. We begin by tracing
historical and technological disruptions to provide context and then introduce
key terms such as machine learning and deep learning and the underlying
mechanisms of recent advancements, namely attention/transformer models and
graphics processing units. The heart of our investigation lies in the
application of an LLM-based chatbot in a graduate fluid mechanics course. We
developed a question bank from the course material and assessed the chatbot's
ability to provide accurate, insightful responses. The results are encouraging,
demonstrating not only the bot's ability to effectively answer complex
questions but also the potential advantages of chatbot usage in the classroom,
such as the promotion of self-paced learning, the provision of instantaneous
feedback, and the reduction of instructors' workload. The study also examines
the transformative effect of intelligent prompting on enhancing the chatbot's
performance. Furthermore, we demonstrate how powerful plugins like Wolfram
Alpha for mathematical problem-solving and code interpretation can
significantly extend the chatbot's capabilities, transforming it into a
comprehensive educational tool. While acknowledging the challenges and ethical
implications surrounding the use of such AI models in education, we advocate
for a balanced approach. The use of LLMs and chatbots in graduate education can
be greatly beneficial but requires ongoing evaluation and adaptation to ensure
ethical and efficient use.",2023-09-09,2023,2023-09,education
Towards LLM-based Autograding for Short Textual Answers,"Grading exams is an important, labor-intensive, subjective, repetitive, and
frequently challenging task. The feasibility of autograding textual responses
has greatly increased thanks to the availability of large language models
(LLMs) such as ChatGPT and the substantial influx of data brought about by
digitalization. However, entrusting AI models with decision-making roles raises
ethical considerations, mainly stemming from potential biases and issues
related to generating false information. Thus, in this manuscript, we provide
an evaluation of a large language model for the purpose of autograding, while
also highlighting how LLMs can support educators in validating their grading
procedures. Our evaluation is targeted towards automatic short textual answers
grading (ASAG), spanning various languages and examinations from two distinct
courses. Our findings suggest that while ""out-of-the-box"" LLMs provide a
valuable tool to provide a complementary perspective, their readiness for
independent automated grading remains a work in progress, necessitating human
oversight.",2023-09-09,2023,2023-09,education
"The Impact of AI in Physics Education: A Comprehensive Review from GCSE
  to University Levels","With the rapid evolution of Artificial Intelligence (AI), its potential
implications for higher education have become a focal point of interest. This
study delves into the capabilities of AI in Physics Education and offers
actionable AI policy recommendations. Using a Large Language Model (LLM), we
assessed its ability to answer 1337 Physics exam questions spanning GCSE,
A-Level, and Introductory University curricula. We employed various AI
prompting techniques: Zero Shot, In Context Learning, and Confirmatory
Checking, which merges Chain of Thought reasoning with Reflection. The AI's
proficiency varied across academic levels: it scored an average of 83.4% on
GCSE, 63.8% on A-Level, and 37.4% on university-level questions, with an
overall average of 59.9% using the most effective prompting technique. In a
separate test, the LLM's accuracy on 5000 mathematical operations was found to
decrease as the number of digits increased. Furthermore, when evaluated as a
marking tool, the LLM's concordance with human markers averaged at 50.8%, with
notable inaccuracies in marking straightforward questions, like
multiple-choice. Given these results, our recommendations underscore caution:
while current LLMs can consistently perform well on Physics questions at
earlier educational stages, their efficacy diminishes with advanced content and
complex calculations. LLM outputs often showcase novel methods not in the
syllabus, excessive verbosity, and miscalculations in basic arithmetic. This
suggests that at university, there's no substantial threat from LLMs for
non-invigilated Physics questions. However, given the LLMs' considerable
proficiency in writing Physics essays and coding abilities, non-invigilated
examinations of these skills in Physics are highly vulnerable to automated
completion by LLMs. This vulnerability also extends to Physics questions
pitched at lower academic levels.",2023-09-10,2023,2023-09,education
Empowering Private Tutoring by Chaining Large Language Models,"Artificial intelligence has been applied in various aspects of online
education to facilitate teaching and learning. However, few approaches has been
made toward a complete AI-powered tutoring system. In this work, we explore the
development of a full-fledged intelligent tutoring system powered by
state-of-the-art large language models (LLMs), covering automatic course
planning and adjusting, tailored instruction, and flexible quiz evaluation. To
make the system robust to prolonged interaction and cater to individualized
education, the system is decomposed into three inter-connected core
processes-interaction, reflection, and reaction. Each process is implemented by
chaining LLM-powered tools along with dynamically updated memory modules. Tools
are LLMs prompted to execute one specific task at a time, while memories are
data storage that gets updated during education process. Statistical results
from learning logs demonstrate the effectiveness and mechanism of each tool
usage. Subjective feedback from human users reveal the usability of each
function, and comparison with ablation systems further testify the benefits of
the designed processes in long-term interaction.",2023-09-15,2023,2023-09,education
"""I'm Not Confident in Debiasing AI Systems Since I Know Too Little"":
  Teaching AI Creators About Gender Bias Through Hands-on Tutorials","Gender bias is rampant in AI systems, causing bad user experience,
injustices, and mental harm to women. School curricula fail to educate AI
creators on this topic, leaving them unprepared to mitigate gender bias in AI.
In this paper, we designed hands-on tutorials to raise AI creators' awareness
of gender bias in AI and enhance their knowledge of sources of gender bias and
debiasing techniques. The tutorials were evaluated with 18 AI creators,
including AI researchers, AI industrial practitioners (i.e., developers and
product managers), and students who had learned AI. Their improved awareness
and knowledge demonstrated the effectiveness of our tutorials, which have the
potential to complement the insufficient AI gender bias education in CS/AI
courses. Based on the findings, we synthesize design implications and a rubric
to guide future research, education, and design efforts.",2023-09-15,2023,2023-09,education
"Examining the Influence of Varied Levels of Domain Knowledge Base
  Inclusion in GPT-based Intelligent Tutors","Recent advancements in large language models (LLMs) have facilitated the
development of chatbots with sophisticated conversational capabilities.
However, LLMs exhibit frequent inaccurate responses to queries, hindering
applications in educational settings. In this paper, we investigate the
effectiveness of integrating a knowledge base (KB) with LLM intelligent tutors
to increase response reliability. To achieve this, we design a scaleable KB
that affords educational supervisors seamless integration of lesson curricula,
which is automatically processed by the intelligent tutoring system. We then
detail an evaluation, where student participants were presented with questions
about the artificial intelligence curriculum to respond to. GPT-4 intelligent
tutors with varying hierarchies of KB access and human domain experts then
assessed these responses. Lastly, students cross-examined the intelligent
tutors' responses to the domain experts' and ranked their various pedagogical
abilities. Results suggest that, although these intelligent tutors still
demonstrate a lower accuracy compared to domain experts, the accuracy of the
intelligent tutors increases when access to a KB is granted. We also observe
that the intelligent tutors with KB access exhibit better pedagogical abilities
to speak like a teacher and understand students than those of domain experts,
while their ability to help students remains lagging behind domain experts.",2023-09-16,2023,2023-09,education
"Artificial Intelligence-Enabled Intelligent Assistant for Personalized
  and Adaptive Learning in Higher Education","This paper presents a novel framework, Artificial Intelligence-Enabled
Intelligent Assistant (AIIA), for personalized and adaptive learning in higher
education. The AIIA system leverages advanced AI and Natural Language
Processing (NLP) techniques to create an interactive and engaging learning
platform. This platform is engineered to reduce cognitive load on learners by
providing easy access to information, facilitating knowledge assessment, and
delivering personalized learning support tailored to individual needs and
learning styles. The AIIA's capabilities include understanding and responding
to student inquiries, generating quizzes and flashcards, and offering
personalized learning pathways. The research findings have the potential to
significantly impact the design, implementation, and evaluation of AI-enabled
Virtual Teaching Assistants (VTAs) in higher education, informing the
development of innovative educational tools that can enhance student learning
outcomes, engagement, and satisfaction. The paper presents the methodology,
system architecture, intelligent services, and integration with Learning
Management Systems (LMSs) while discussing the challenges, limitations, and
future directions for the development of AI-enabled intelligent assistants in
education.",2023-09-19,2023,2023-09,education
"Generative Agent-Based Modeling: Unveiling Social System Dynamics
  through Coupling Mechanistic Models with Generative Artificial Intelligence","We discuss the emerging new opportunity for building feedback-rich
computational models of social systems using generative artificial
intelligence. Referred to as Generative Agent-Based Models (GABMs), such
individual-level models utilize large language models such as ChatGPT to
represent human decision-making in social settings. We provide a GABM case in
which human behavior can be incorporated in simulation models by coupling a
mechanistic model of human interactions with a pre-trained large language
model. This is achieved by introducing a simple GABM of social norm diffusion
in an organization. For educational purposes, the model is intentionally kept
simple. We examine a wide range of scenarios and the sensitivity of the results
to several changes in the prompt. We hope the article and the model serve as a
guide for building useful diffusion models that include realistic human
reasoning and decision-making.",2023-09-20,2023,2023-09,education
"TrueLearn: A Python Library for Personalised Informational
  Recommendations with (Implicit) Feedback","This work describes the TrueLearn Python library, which contains a family of
online learning Bayesian models for building educational (or more generally,
informational) recommendation systems. This family of models was designed
following the ""open learner"" concept, using humanly-intuitive user
representations. For the sake of interpretability and putting the user in
control, the TrueLearn library also contains different representations to help
end-users visualise the learner models, which may in the future facilitate user
interaction with their own models. Together with the library, we include a
previously publicly released implicit feedback educational dataset with
evaluation metrics to measure the performance of the models. The extensive
documentation and coding examples make the library highly accessible to both
machine learning developers and educational data mining and learning analytic
practitioners. The library and the support documentation with examples are
available at https://truelearn.readthedocs.io/en/latest.",2023-09-20,2023,2023-09,education
Generativism: the new hybrid,"Generative Artificial Intelligence (GenAI) in Education has in a few short
months moved from being the topic of discussion around speculative education
futures to a very concrete reality. It is clear that the future of education,
as all industries, is collaboration with GenAI. GenAI attributes make it well
suited for social and constructivist approaches to learning that value
collaboration, community and the construction of knowledge and skills through
active learning. This article presents an approach to designing education in
collaboration with GenAI, based on digital education frameworks adapted for
this new hybrid of the AI age.",2023-09-21,2023,2023-09,education
"Transitioning To The Digital Generation Case Studies (Previous Digital
  Point Studies In Japan Cases:1993-2023)","In this paper, we discuss at The 8th International Workshop on Application of
Big Data for Computational Social Science, October 26-29, 2023, Venice, Italy.
To achieve the realization of the Global and Innovation Gateway for All (GIGA)
initiative (2019), proposed in December 2019 by the Primary and Secondary
Education Planning Division of the Elementary and Secondary Education Bureau of
the Ministry of Education, Culture, Sports, Science and Technology, a movement
has emerged to utilize information and communication technology (ICT) in the
field of education. The history of ICT education in Japan dates back to the 100
Schools Project (1994), which aimed to provide network access environments, and
the New 100 Schools Project (1997), which marked the beginning of full-scale
ICT education in Japan. In this paper, we discuss the usage dynamics of
smartphone-based learning applications among young people (analyzing data from
January to September 2020) and their current status. Further, the results are
summarized and future research topics and issues are discussed. The results
show that there are situations in which ICT learning environments can be
effectively utilized and others in which they cannot, depending on the
differences between digital students and analog students who utilize ICT in
their studies; this indicates that we are currently in a transition to a
generation of digital natives. ICT education has both advantages and
disadvantages, and it is expected that it will be used in combination with
conventional educational methods while assessing the characteristics of ICT
education in the future. Of course, there are many challenges. We plan to
discuss how to appeal in this regard at the Workshop.",2023-09-21,2023,2023-09,education
Class Attendance System in Education with Deep Learning Method,"With the advancing technology, the hardware gain of computers and the
increase in the processing capacity of processors have facilitated the
processing of instantaneous and real-time images. Face recognition processes
are also studies in the field of image processing. Facial recognition processes
are frequently used in security applications and commercial applications.
Especially in the last 20 years, the high performances of artificial
intelligence (AI) studies have contributed to the spread of these studies in
many different fields. Education is one of them. The potential and advantages
of using AI in education; can be grouped under three headings: student,
teacher, and institution. One of the institutional studies may be the security
of educational environments and the contribution of automation to education and
training processes. From this point of view, deep learning methods, one of the
sub-branches of AI, were used in this study. For object detection from images,
a pioneering study has been designed and successfully implemented to keep
records of students' entrance to the educational institution and to perform
class attendance with images taken from the camera using image processing
algorithms. The application of the study to real-life problems will be carried
out in a school determined in the 2022-2023 academic year.",2023-09-23,2023,2023-09,education
"Experimental Evidence on Negative Impact of Generative AI on Scientific
  Learning Outcomes","In this study, I explored the impact of Generative AI on learning efficacy in
academic reading materials using experimental methods. College-educated
participants engaged in three cycles of reading and writing tasks. After each
cycle, they responded to comprehension questions related to the material. After
adjusting for background knowledge and demographic factors, complete reliance
on AI for writing tasks led to a 25.1% reduction in accuracy. In contrast,
AI-assisted reading resulted in a 12% decline. Interestingly, using AI for
summarization significantly improved both quality and output. Accuracy
exhibited notable variance in the AI-assisted section. Further analysis
revealed that individuals with a robust background in the reading topic and
superior reading/writing skills benefitted the most. I conclude the research by
discussing educational policy implications, emphasizing the need for educators
to warn students about the dangers of over-dependence on AI and provide
guidance on its optimal use in educational settings.",2023-09-23,2023,2023-09,education
Automating question generation from educational text,"The use of question-based activities (QBAs) is wide-spread in education,
traditionally forming an integral part of the learning and assessment process.
In this paper, we design and evaluate an automated question generation tool for
formative and summative assessment in schools. We present an expert survey of
one hundred and four teachers, demonstrating the need for automated generation
of QBAs, as a tool that can significantly reduce the workload of teachers and
facilitate personalized learning experiences. Leveraging the recent
advancements in generative AI, we then present a modular framework employing
transformer based language models for automatic generation of multiple-choice
questions (MCQs) from textual content. The presented solution, with distinct
modules for question generation, correct answer prediction, and distractor
formulation, enables us to evaluate different language models and generation
techniques. Finally, we perform an extensive quantitative and qualitative
evaluation, demonstrating trade-offs in the use of different techniques and
models.",2023-09-26,2023,2023-09,education
"With ChatGPT, do we have to rewrite our learning objectives -- CASE
  study in Cybersecurity","With the emergence of Artificial Intelligent chatbot tools such as ChatGPT
and code writing AI tools such as GitHub Copilot, educators need to question
what and how we should teach our courses and curricula in the future. In
reality, automated tools may result in certain academic fields being deeply
reduced in the number of employable people. In this work, we make a case study
of cybersecurity undergrad education by using the lens of ``Understanding by
Design'' (UbD). First, we provide a broad understanding of learning objectives
(LOs) in cybersecurity from a computer science perspective. Next, we dig a
little deeper into a curriculum with an undergraduate emphasis on cybersecurity
and examine the major courses and their LOs for our cybersecurity program at
Miami University. With these details, we perform a thought experiment on how
attainable the LOs are with the above-described tools, asking the key question
``what needs to be enduring concepts?'' learned in this process. If an LO
becomes something that the existence of automation tools might be able to do,
we then ask ``what level is attainable for the LO that is not a simple query to
the tools?''. With this exercise, we hope to establish an example of how to
prompt ChatGPT to accelerate students in their achievements of LOs given the
existence of these new AI tools, and our goal is to push all of us to leverage
and teach these tools as powerful allies in our quest to improve human
existence and knowledge.",2023-09-26,2023,2023-09,education
Brave new world: Artificial Intelligence in teaching and learning,"We exemplify how Large Language Models are used in both teaching and
learning. We also discuss the AI incidents that have already occurred in the
education domain, and we argue for the urgent need to introduce AI policies in
universities and for the ongoing strategies to regulate AI. Regarding policy
for AI, our view is that each institution should have a policy for AI in
teaching and learning. This is important from at least twofolds: (i) to raise
awareness on the numerous educational tools that can both positively and
negatively affect education; (ii) to minimise the risk of AI incidents in
education.",2023-09-27,2023,2023-09,education
"""ChatGPT, a Friend or Foe for Education?"" Analyzing the User's
  Perspectives on the Latest AI Chatbot Via Reddit","Latest developments in Artificial Intelligence (AI) and big data gave rise to
Artificial Intelligent agents like Open AI's ChatGPT, which has recently become
the fastest growing application since Facebook and WhatsApp. ChatGPT has
demonstrated its ability to impact students' classroom learning experience and
exam outcomes. However, there is evidence that ChatGPT provides biased and
erroneous information, yet students use ChatGPT in academic tasks. Therefore,
an accurate understanding of ChatGPT user perception is crucial. This study has
analyzed 247 Reddit top posts related to the educational use of ChatGPT from a
prominent subreddit called ""ChatGPT"" for user perception analysis. Descriptive
statistics, sentiment analysis using NLP techniques, and LDA topic modeling
were used for analysis to gather a contextual understanding of the data.
Results show that the majority of the users took a neutral viewpoint. However,
there was more positive perception than negative regarding the usefulness of
ChatGPT in education.",2023-09-27,2023,2023-09,education
An Empirical Study of AI Generated Text Detection Tools,"Since ChatGPT has emerged as a major AIGC model, providing high-quality
responses across a wide range of applications (including software development
and maintenance), it has attracted much interest from many individuals. ChatGPT
has great promise, but there are serious problems that might arise from its
misuse, especially in the realms of education and public safety. Several AIGC
detectors are available, and they have all been tested on genuine text.
However, more study is needed to see how effective they are for multi-domain
ChatGPT material. This study aims to fill this need by creating a multi-domain
dataset for testing the state-of-the-art APIs and tools for detecting
artificially generated information used by universities and other research
institutions. A large dataset consisting of articles, abstracts, stories, news,
and product reviews was created for this study. The second step is to use the
newly created dataset to put six tools through their paces. Six different
artificial intelligence (AI) text identification systems, including ""GPTkit,""
""GPTZero,"" ""Originality,"" ""Sapling,"" ""Writer,"" and ""Zylalab,"" have accuracy
rates between 55.29 and 97.0%. Although all the tools fared well in the
evaluations, originality was particularly effective across the board.",2023-09-27,2023,2023-09,education
"The Robots are Here: Navigating the Generative AI Revolution in
  Computing Education","Recent advancements in artificial intelligence (AI) are fundamentally
reshaping computing, with large language models (LLMs) now effectively being
able to generate and interpret source code and natural language instructions.
These emergent capabilities have sparked urgent questions in the computing
education community around how educators should adapt their pedagogy to address
the challenges and to leverage the opportunities presented by this new
technology. In this working group report, we undertake a comprehensive
exploration of LLMs in the context of computing education and make five
significant contributions. First, we provide a detailed review of the
literature on LLMs in computing education and synthesise findings from 71
primary articles. Second, we report the findings of a survey of computing
students and instructors from across 20 countries, capturing prevailing
attitudes towards LLMs and their use in computing education contexts. Third, to
understand how pedagogy is already changing, we offer insights collected from
in-depth interviews with 22 computing educators from five continents who have
already adapted their curricula and assessments. Fourth, we use the ACM Code of
Ethics to frame a discussion of ethical issues raised by the use of large
language models in computing education, and we provide concrete advice for
policy makers, educators, and students. Finally, we benchmark the performance
of LLMs on various computing education datasets, and highlight the extent to
which the capabilities of current models are rapidly improving. Our aim is that
this report will serve as a focal point for both researchers and practitioners
who are exploring, adapting, using, and evaluating LLMs and LLM-based tools in
computing classrooms.",2023-10-01,2023,2023-10,education
"My Machine and I: ChatGPT and the Future of Human-Machine Collaboration
  in Africa","Recent advancements in technology have necessitated a paradigm shift in the
people use technology necessitating a new research field called Human-Machine
collaboration. ChatGPT, an Artificial intelligence (AI) assistive technology,
has gained mainstream adoption and implementation in academia and industry;
however, a lot is left unknown about how this new technology holds for
Human-Machine Collaboration in Africa. Our survey paper highlights to answer
some of these questions. To understand the effectiveness of ChatGPT on
human-machine collaboration we utilized reflexive thematic analysis to analyze
(N= 51) articles between 2019 and 2023 obtained from our literature search. Our
findings indicate the prevalence of ChatGPT for human-computer interaction
within academic sectors such as education, and research; trends also revealed
the relatively high effectiveness of ChatGPT in improving human-machine
collaboration.",2023-10-01,2023,2023-10,education
"A Review of Digital Learning Environments for Teaching Natural Language
  Processing in K-12 Education","Natural Language Processing (NLP) plays a significant role in our daily lives
and has become an essential part of Artificial Intelligence (AI) education in
K-12. As children grow up with NLP-powered applications, it is crucial to
introduce NLP concepts to them, fostering their understanding of language
processing, language generation, and ethical implications of AI and NLP. This
paper presents a comprehensive review of digital learning environments for
teaching NLP in K-12. Specifically, it explores existing digital learning
tools, discusses how they support specific NLP tasks and procedures, and
investigates their explainability and evaluation results in educational
contexts. By examining the strengths and limitations of these tools, this
literature review sheds light on the current state of NLP learning tools in
K-12 education. It aims to guide future research efforts to refine existing
tools, develop new ones, and explore more effective and inclusive strategies
for integrating NLP into K-12 educational contexts.",2023-10-02,2023,2023-10,education
Generative AI in the Classroom: Can Students Remain Active Learners?,"Generative Artificial Intelligence (GAI) can be seen as a double-edged weapon
in education. Indeed, it may provide personalized, interactive and empowering
pedagogical sequences that could favor students' intrinsic motivation, active
engagement and help them have more control over their learning. But at the same
time, other GAI properties such as the lack of uncertainty signalling even in
cases of failure (particularly with Large Language Models (LLMs)) could lead to
opposite effects, e.g. over-estimation of one's own competencies, passiveness,
loss of curious and critical-thinking sense, etc.
  These negative effects are due in particular to the lack of a pedagogical
stance in these models' behaviors. Indeed, as opposed to standard pedagogical
activities, GAI systems are often designed to answers users' inquiries easily
and conveniently, without asking them to make an effort, and without focusing
on their learning process and/or outcomes.
  This article starts by outlining some of these opportunities and challenges
surrounding the use of GAI in education, with a focus on the effects on
students' active learning strategies and related metacognitive skills. Then, we
present a framework for introducing pedagogical transparency in GAI-based
educational applications. This framework presents 1) training methods to
include pedagogical principles in the models, 2) methods to ensure controlled
and pedagogically-relevant interactions when designing activities with GAI and
3) educational methods enabling students to acquire the relevant skills to
properly benefit from the use of GAI in their learning activities
(meta-cognitive skills, GAI litteracy).",2023-10-04,2023,2023-10,education
"Generative AI May Prefer to Present National-level Characteristics of
  Cities Based on Stereotypical Geographic Impressions at the Continental Level","A simple experiment was conducted to test the ability of the Chinese-based
generative artificial intelligence (AI) platform, Wenxin Yige, to render images
of urban street views of different countries. The study found that images
generated by this AI platform may contain continental-level stereotypes in
terms of showing the level of economic development and modernization. Street
view images generated from Wenxin Yige do not adequately represent the diverse
range of urban landscapes found across different nations. Using these generated
images for geography education or outreach initiatives could inadvertently
strengthen people's existing stereotypical views about individual countries.",2023-10-07,2023,2023-10,education
"The AI Incident Database as an Educational Tool to Raise Awareness of AI
  Harms: A Classroom Exploration of Efficacy, Limitations, & Future
  Improvements","Prior work has established the importance of integrating AI ethics topics
into computer and data sciences curricula. We provide evidence suggesting that
one of the critical objectives of AI Ethics education must be to raise
awareness of AI harms. While there are various sources to learn about such
harms, The AI Incident Database (AIID) is one of the few attempts at offering a
relatively comprehensive database indexing prior instances of harms or near
harms stemming from the deployment of AI technologies in the real world. This
study assesses the effectiveness of AIID as an educational tool to raise
awareness regarding the prevalence and severity of AI harms in socially
high-stakes domains. We present findings obtained through a classroom study
conducted at an R1 institution as part of a course focused on the societal and
ethical considerations around AI and ML. Our qualitative findings characterize
students' initial perceptions of core topics in AI ethics and their desire to
close the educational gap between their technical skills and their ability to
think systematically about ethical and societal aspects of their work. We find
that interacting with the database helps students better understand the
magnitude and severity of AI harms and instills in them a sense of urgency
around (a) designing functional and safe AI and (b) strengthening governance
and accountability mechanisms. Finally, we compile students' feedback about the
tool and our class activity into actionable recommendations for the database
development team and the broader community to improve awareness of AI harms in
AI ethics education.",2023-10-10,2023,2023-10,education
"Gender, Age, and Technology Education Influence the Adoption and
  Appropriation of LLMs","Large Language Models (LLMs) such as ChatGPT have become increasingly
integrated into critical activities of daily life, raising concerns about
equitable access and utilization across diverse demographics. This study
investigates the usage of LLMs among 1,500 representative US citizens.
Remarkably, 42% of participants reported utilizing an LLM. Our findings reveal
a gender gap in LLM technology adoption (more male users than female users)
with complex interaction patterns regarding age. Technology-related education
eliminates the gender gap in our sample. Moreover, expert users are more likely
than novices to list professional tasks as typical application scenarios,
suggesting discrepancies in effective usage at the workplace. These results
underscore the importance of providing education in artificial intelligence in
our technology-driven society to promote equitable access to and benefits from
LLMs. We urge for both international replication beyond the US and longitudinal
observation of adoption.",2023-10-10,2023,2023-10,education
"BC4LLM: Trusted Artificial Intelligence When Blockchain Meets Large
  Language Models","In recent years, artificial intelligence (AI) and machine learning (ML) are
reshaping society's production methods and productivity, and also changing the
paradigm of scientific research. Among them, the AI language model represented
by ChatGPT has made great progress. Such large language models (LLMs) serve
people in the form of AI-generated content (AIGC) and are widely used in
consulting, healthcare, and education. However, it is difficult to guarantee
the authenticity and reliability of AIGC learning data. In addition, there are
also hidden dangers of privacy disclosure in distributed AI training. Moreover,
the content generated by LLMs is difficult to identify and trace, and it is
difficult to cross-platform mutual recognition. The above information security
issues in the coming era of AI powered by LLMs will be infinitely amplified and
affect everyone's life. Therefore, we consider empowering LLMs using blockchain
technology with superior security features to propose a vision for trusted AI.
This paper mainly introduces the motivation and technical route of blockchain
for LLM (BC4LLM), including reliable learning corpus, secure training process,
and identifiable generated content. Meanwhile, this paper also reviews the
potential applications and future challenges, especially in the frontier
communication networks field, including network resource allocation, dynamic
spectrum sharing, and semantic communication. Based on the above work combined
and the prospect of blockchain and LLMs, it is expected to help the early
realization of trusted AI and provide guidance for the academic community.",2023-10-10,2023,2023-10,education
"Opportunities for Adaptive Experiments to Enable Continuous Improvement
  in Computer Science Education","Randomized A/B comparisons of alternative pedagogical strategies or other
course improvements could provide useful empirical evidence for instructor
decision-making. However, traditional experiments do not provide a
straightforward pathway to rapidly utilize data, increasing the chances that
students in an experiment experience the best conditions. Drawing inspiration
from the use of machine learning and experimentation in product development at
leading technology companies, we explore how adaptive experimentation might aid
continuous course improvement. In adaptive experiments, data is analyzed and
utilized as different conditions are deployed to students. This can be achieved
using machine learning algorithms to identify which actions are more beneficial
in improving students' learning experiences and outcomes. These algorithms can
then dynamically deploy the most effective conditions in subsequent
interactions with students, resulting in better support for students' needs. We
illustrate this approach with a case study that provides a side-by-side
comparison of traditional and adaptive experiments on adding self-explanation
prompts in online homework problems in a CS1 course. This work paves the way
for exploring the importance of adaptive experiments in bridging research and
practice to achieve continuous improvement in educational settings.",2023-10-18,2023,2023-10,education
"Chat GPT Integrated with Voice Assistant as Learning Oral Chat-based
  Constructive Communication to Improve Communicative Competence for EFL
  earners","Chat GPT belongs to the category of Generative Pre-trained Transformer (GPT)
language models, which have received specialized training to produce text based
on natural language inputs. Its purpose is to imitate human-like conversation
and can be implemented in multiple applications, such as chatbots, virtual
assistants, and language translation systems, starting with an introduction to
the new trends and differences between artificial intelligence, machine
learning, and artificial neural networks, and highlighting the rigorous
language logic and powerful text generation capabilities of Chat GPT. This
paper delves into how advances in artificial intelligence will shape e-learning
in the coming decades, particularly in terms of Chat- GPT's ability to improve
learners' Communicative Competence when English is a second language. The
combination of new trends in artificial intelligence, mainly in the particular
case of English as a second language, and, at the academic level, chatbot
technology, will be the next step in the replacement of the human academic
community by virtual assistants, apparently until a certain point. Despite the
controversy, this very innovative solution will be able to bridge the gap
between technology and education. Moreover, such innovative practices
facilitate communication by enabling its inclusion in various applications,
including virtual assistants, chatbots, and language education. Keyword: Chat
GPT, artificial intelligence, Communicative Competence, Communicative Language
Teaching (CLT)",2023-10-27,2023,2023-10,education
EHRTutor: Enhancing Patient Understanding of Discharge Instructions,"Large language models have shown success as a tutor in education in various
fields. Educating patients about their clinical visits plays a pivotal role in
patients' adherence to their treatment plans post-discharge. This paper
presents EHRTutor, an innovative multi-component framework leveraging the Large
Language Model (LLM) for patient education through conversational
question-answering. EHRTutor first formulates questions pertaining to the
electronic health record discharge instructions. It then educates the patient
through conversation by administering each question as a test. Finally, it
generates a summary at the end of the conversation. Evaluation results using
LLMs and domain experts have shown a clear preference for EHRTutor over the
baseline. Moreover, EHRTutor also offers a framework for generating synthetic
patient education dialogues that can be used for future in-house system
training.",2023-10-30,2023,2023-10,education
"Leveraging generative artificial intelligence to simulate student
  learning behavior","Student simulation presents a transformative approach to enhance learning
outcomes, advance educational research, and ultimately shape the future of
effective pedagogy. We explore the feasibility of using large language models
(LLMs), a remarkable achievement in AI, to simulate student learning behaviors.
Unlike conventional machine learning based prediction, we leverage LLMs to
instantiate virtual students with specific demographics and uncover intricate
correlations among learning experiences, course materials, understanding
levels, and engagement. Our objective is not merely to predict learning
outcomes but to replicate learning behaviors and patterns of real students. We
validate this hypothesis through three experiments. The first experiment, based
on a dataset of N = 145, simulates student learning outcomes from demographic
data, revealing parallels with actual students concerning various demographic
factors. The second experiment (N = 4524) results in increasingly realistic
simulated behaviors with more assessment history for virtual students
modelling. The third experiment (N = 27), incorporating prior knowledge and
course interactions, indicates a strong link between virtual students' learning
behaviors and fine-grained mappings from test questions, course materials,
engagement and understanding levels. Collectively, these findings deepen our
understanding of LLMs and demonstrate its viability for student simulation,
empowering more adaptable curricula design to enhance inclusivity and
educational effectiveness.",2023-10-30,2023,2023-10,education
"Plagiarism and AI Assistance Misuse in Web Programming: Unfair Benefits
  and Characteristics","In programming education, plagiarism and misuse of artificial intelligence
(AI) assistance are emerging issues. However, not many relevant studies are
focused on web programming. We plan to develop automated tools to help
instructors identify both misconducts. To fully understand the issues, we
conducted a controlled experiment to observe the unfair benefits and the
characteristics. We compared student performance in completing web programming
tasks independently, with a submission to plagiarize, and with the help of AI
assistance (ChatGPT). Our study shows that students who are involved in such
misconducts get comparable test marks with less completion time. Plagiarized
submissions are similar to the independent ones except in trivial aspects such
as color and identifier names. AI-assisted submissions are more complex, making
them less readable. Students believe AI assistance could be useful given proper
acknowledgment of the use, although they are not convinced with readability and
correctness of the solutions.",2023-10-31,2023,2023-10,education
"Augmenting deep neural networks with symbolic knowledge: Towards
  trustworthy and interpretable AI for education","Artificial neural networks (ANNs) have shown to be amongst the most important
artificial intelligence (AI) techniques in educational applications, providing
adaptive educational services. However, their educational potential is limited
in practice due to three major challenges: i) difficulty in incorporating
symbolic educational knowledge (e.g., causal relationships, and practitioners'
knowledge) in their development, ii) learning and reflecting biases, and iii)
lack of interpretability. Given the high-risk nature of education, the
integration of educational knowledge into ANNs becomes crucial for developing
AI applications that adhere to essential educational restrictions, and provide
interpretability over the predictions. This research argues that the
neural-symbolic family of AI has the potential to address the named challenges.
To this end, it adapts a neural-symbolic AI framework and accordingly develops
an approach called NSAI, that injects and extracts educational knowledge into
and from deep neural networks, for modelling learners computational thinking.
Our findings reveal that the NSAI approach has better generalizability compared
to deep neural networks trained merely on training data, as well as training
data augmented by SMOTE and autoencoder methods. More importantly, unlike the
other models, the NSAI approach prioritises robust representations that capture
causal relationships between input features and output labels, ensuring safety
in learning to avoid spurious correlations and control biases in training data.
Furthermore, the NSAI approach enables the extraction of rules from the learned
network, facilitating interpretation and reasoning about the path to
predictions, as well as refining the initial educational knowledge. These
findings imply that neural-symbolic AI can overcome the limitations of ANNs in
education, enabling trustworthy and interpretable applications.",2023-11-01,2023,2023-11,education
"A Spatial-Temporal Transformer based Framework For Human Pose Assessment
  And Correction in Education Scenarios","Human pose assessment and correction play a crucial role in applications
across various fields, including computer vision, robotics, sports analysis,
healthcare, and entertainment. In this paper, we propose a Spatial-Temporal
Transformer based Framework (STTF) for human pose assessment and correction in
education scenarios such as physical exercises and science experiment. The
framework comprising skeletal tracking, pose estimation, posture assessment,
and posture correction modules to educate students with professional,
quick-to-fix feedback. We also create a pose correction method to provide
corrective feedback in the form of visual aids. We test the framework with our
own dataset. It comprises (a) new recordings of five exercises, (b) existing
recordings found on the internet of the same exercises, and (c) corrective
feedback on the recordings by professional athletes and teachers. Results show
that our model can effectively measure and comment on the quality of students'
actions. The STTF leverages the power of transformer models to capture spatial
and temporal dependencies in human poses, enabling accurate assessment and
effective correction of students' movements.",2023-11-01,2023,2023-11,education
"Artificial Intelligence Ethics Education in Cybersecurity: Challenges
  and Opportunities: a focus group report","The emergence of AI tools in cybersecurity creates many opportunities and
uncertainties. A focus group with advanced graduate students in cybersecurity
revealed the potential depth and breadth of the challenges and opportunities.
The salient issues are access to open source or free tools, documentation,
curricular diversity, and clear articulation of ethical principles for AI
cybersecurity education. Confronting the ""black box"" mentality in AI
cybersecurity work is also of the greatest importance, doubled by deeper and
prior education in foundational AI work. Systems thinking and effective
communication were considered relevant areas of educational improvement. Future
AI educators and practitioners need to address these issues by implementing
rigorous technical training curricula, clear documentation, and frameworks for
ethically monitoring AI combined with critical and system's thinking and
communication skills.",2023-11-02,2023,2023-11,education
"AI-assisted Learning for Electronic Engineering Courses in High
  Education","This study evaluates the efficacy of ChatGPT as an AI teaching and learning
support tool in an integrated circuit systems course at a higher education
institution in an Asian country. Various question types were completed, and
ChatGPT responses were assessed to gain valuable insights for further
investigation. The objective is to assess ChatGPT's ability to provide
insights, personalized support, and interactive learning experiences in
engineering education. The study includes the evaluation and reflection of
different stakeholders: students, lecturers, and engineers. The findings of
this study shed light on the benefits and limitations of ChatGPT as an AI tool,
paving the way for innovative learning approaches in technical disciplines.
Furthermore, the study contributes to our understanding of how digital
transformation is likely to unfold in the education sector.",2023-11-02,2023,2023-11,education
"When fairness is an abstraction: Equity and AI in Swedish compulsory
  education","Artificial intelligence experts often question whether AI is fair. They view
fairness as a property of AI systems rather than of sociopolitical and economic
systems. This paper emphasizes the need to be fair in the social, political,
and economic contexts within which an educational system operates and uses AI.
Taking Swedish decentralized compulsory education as the context, this paper
examines whether and how the use of AI envisaged by national authorities and
edtech companies exacerbates unfairness. A qualitative content analysis of
selected Swedish policy documents and edtech reports was conducted using the
concept of relevant social groups to understand how different groups view the
risks and benefits of AI for fairness. Three groups that view efficiency as a
key value of AI are identified, and interpreted as economical, pedagogical and
accessibility-related. By separating fairness from social justice, this paper
challenges the notion of fairness as the formal equality of opportunities.",2023-11-03,2023,2023-11,education
"Brief for the Canada House of Commons Study on the Implications of
  Artificial Intelligence Technologies for the Canadian Labor Force: Generative
  Artificial Intelligence Shatters Models of AI and Labor","Exciting advances in generative artificial intelligence (AI) have sparked
concern for jobs, education, productivity, and the future of work. As with past
technologies, generative AI may not lead to mass unemployment. But, unlike past
technologies, generative AI is creative, cognitive, and potentially ubiquitous
which makes the usual assumptions of automation predictions ill-suited for
today. Existing projections suggest that generative AI will impact workers in
occupations that were previously considered immune to automation. As AI's full
set of capabilities and applications emerge, policy makers should promote
workers' career adaptability. This goal requires improved data on job
separations and unemployment by locality and job titles in order to identify
early-indicators for the workers facing labor disruption. Further, prudent
policy should incentivize education programs to accommodate learning with AI as
a tool while preparing students for the demands of the future of work.",2023-11-06,2023,2023-11,education
"Analysis of the User Perception of Chatbots in Education Using A Partial
  Least Squares Structural Equation Modeling Approach","The integration of Artificial Intelligence (AI) into education is a recent
development, with chatbots emerging as a noteworthy addition to this
transformative landscape. As online learning platforms rapidly advance,
students need to adapt swiftly to excel in this dynamic environment.
Consequently, understanding the acceptance of chatbots, particularly those
employing Large Language Model (LLM) such as Chat Generative Pretrained
Transformer (ChatGPT), Google Bard, and other interactive AI technologies, is
of paramount importance. However, existing research on chatbots in education
has overlooked key behavior-related aspects, such as Optimism, Innovativeness,
Discomfort, Insecurity, Transparency, Ethics, Interaction, Engagement, and
Accuracy, creating a significant literature gap. To address this gap, this
study employs Partial Least Squares Structural Equation Modeling (PLS-SEM) to
investigate the determinant of chatbots adoption in education among students,
considering the Technology Readiness Index (TRI) and Technology Acceptance
Model (TAM). Utilizing a five-point Likert scale for data collection, we
gathered a total of 185 responses, which were analyzed using R-Studio software.
We established 12 hypotheses to achieve its objectives. The results showed that
Optimism and Innovativeness are positively associated with Perceived Ease of
Use (PEOU) and Perceived Usefulness (PU). Conversely, Discomfort and Insecurity
negatively impact PEOU, with only Insecurity negatively affecting PU. These
findings provide insights for future technology designers, elucidating critical
user behavior factors influencing chatbots adoption and utilization in
educational contexts.",2023-11-07,2023,2023-11,education
"Is a Seat at the Table Enough? Engaging Teachers and Students in Dataset
  Specification for ML in Education","Despite the promises of ML in education, its adoption in the classroom has
surfaced numerous issues regarding fairness, accountability, and transparency,
as well as concerns about data privacy and student consent. A root cause of
these issues is the lack of understanding of the complex dynamics of education,
including teacher-student interactions, collaborative learning, and classroom
environment. To overcome these challenges and fully utilize the potential of ML
in education, software practitioners need to work closely with educators and
students to fully understand the context of the data (the backbone of ML
applications) and collaboratively define the ML data specifications. To gain a
deeper understanding of such a collaborative process, we conduct ten co-design
sessions with ML software practitioners, educators, and students. In the
sessions, teachers and students work with ML engineers, UX designers, and legal
practitioners to define dataset characteristics for a given ML application. We
find that stakeholders contextualize data based on their domain and procedural
knowledge, proactively design data requirements to mitigate downstream harms
and data reliability concerns, and exhibit role-based collaborative strategies
and contribution patterns. Further, we find that beyond a seat at the table,
meaningful stakeholder participation in ML requires structured supports:
defined processes for continuous iteration and co-evaluation, shared contextual
data quality standards, and information scaffolds for both technical and
non-technical stakeholders to traverse expertise boundaries.",2023-11-09,2023,2023-11,education
"Transdisciplinary AI Education: The Confluence of Curricular and
  Community Needs in the Instruction of Artificial Intelligence","The integration of artificial intelligence (AI) into education has the
potential to transform the way we learn and teach. In this paper, we examine
the current state of AI in education and explore the potential benefits and
challenges of incorporating this technology into the classroom. The approaches
currently available for AI education often present students with experiences
only focusing on discrete computer science concepts agnostic to a larger
curriculum. However, teaching AI must not be siloed or interdisciplinary.
Rather, AI instruction ought to be transdisciplinary, including connections to
the broad curriculum and community in which students are learning. This paper
delves into the AI program currently in development for Neom Community School
and the larger Education, Research, and Innovation Sector in Neom, Saudi Arabia
s new megacity under development. In this program, AI is both taught as a
subject and to learn other subjects within the curriculum through the school
systems International Baccalaureate (IB) approach, which deploys learning
through Units of Inquiry. This approach to education connects subjects across a
curriculum under one major guiding question at a time. The proposed method
offers a meaningful approach to introducing AI to students throughout these
Units of Inquiry, as it shifts AI from a subject that students like or not like
to a subject that is taught throughout the curriculum.",2023-11-10,2023,2023-11,education
"ChatGPT as Co-Advisor in Scientific Initiation: Action Research with
  Project-Based Learning in Elementary Education","Background: In the contemporary educational landscape, technology has the
power to drive innovative pedagogical practices. Overcoming the resistance of
teachers and students to adopting new methods and technologies is a challenge
that needs to be addressed. Objectives: To evaluate the effectiveness of
ChatGPT as a co-advisor in research projects and its influence on the
implementation of Project-Based Learning (PBL), as well as overcoming
resistance to the use of new pedagogical methodologies. Design: An
action-research methodology was employed, including unstructured interviews and
the application of questionnaires via Google Forms. Setting and Participants:
The research was conducted in an elementary school, involving 353 students and
16 teachers. Data Collection and Analysis: Data were gathered through
observations and notes in meetings and interviews, complemented by electronic
questionnaires, with quantitative and qualitative analyses performed via
Microsoft Excel and Google Forms. Results: The introduction of ChatGPT as a
pedagogical tool led to increased student engagement and decreased teacher
resistance, reflected in recognition at local science fairs. Conclusion: The
study confirmed the utility of ChatGPT in school research co-orientation,
highlighting its role in facilitating PBL and promoting cultural changes in
educational practice, with proactive school management identified as a
catalysing element in adapting to educational innovations.",2023-11-10,2023,2023-11,education
"The Power of Attention: Bridging Cognitive Load, Multimedia Learning,
  and AI","This article addresses the intersection of various educational theories and
their relationship with the education of computer science students, with a
focus on the importance of understanding computational thinking and its
application in education. The historical context and fundamental concepts of
Cognitive Load Theory, Multimedia Learning, and Constructivism are explored,
highlighting their underlying biological assumptions about human learning. It
also examines how these theories can be integrated with the use of Artificial
Intelligence (AI) in education, with a particular emphasis on the attention
mechanisms and abstract learning present in AI models like Transformers.
Lastly, the relevance of these theories and practices for computer education
student training is discussed, emphasizing how the development of computational
thinking can contribute to a more effective approach in teaching and learning.",2023-11-11,2023,2023-11,education
"Anticipating User Needs: Insights from Design Fiction on Conversational
  Agents for Computational Thinking","Computational thinking, and by extension, computer programming, is
notoriously challenging to learn. Conversational agents and generative
artificial intelligence (genAI) have the potential to facilitate this learning
process by offering personalized guidance, interactive learning experiences,
and code generation. However, current genAI-based chatbots focus on
professional developers and may not adequately consider educational needs.
Involving educators in conceiving educational tools is critical for ensuring
usefulness and usability. We enlisted nine instructors to engage in design
fiction sessions in which we elicited abilities such a conversational agent
supported by genAI should display. Participants envisioned a conversational
agent that guides students stepwise through exercises, tuning its method of
guidance with an awareness of the educational background, skills and deficits,
and learning preferences. The insights obtained in this paper can guide future
implementations of tutoring conversational agents oriented toward teaching
computational thinking and computer programming.",2023-11-12,2023,2023-11,education
Performance of ChatGPT on the Test of Understanding Graphs in Kinematics,"The well-known artificial intelligence-based chatbot ChatGPT-4 has become
able to process image data as input in October 2023. We investigated its
performance on the Test of Understanding Graphs in Kinematics to inform the
physics education community of the current potential of using ChatGPT in the
education process, particularly on tasks that involve graphical interpretation.
We found that ChatGPT, on average, performed similarly to students taking a
high-school level physics course, but with important differences in the
distribution of the correctness of its responses, as well as in terms of the
displayed ""reasoning"" and ""visual"" abilities. While ChatGPT was very successful
at proposing productive strategies for solving the tasks on the test and
expressed correct ""reasoning"" in most of its responses, it had difficulties
correctly ""seeing"" graphs. We suggest that, based on its performance, caution
and a critical approach are needed if one intends to use it in the role of a
tutor, a model of a student, or a tool for assisting vision-impaired persons in
the context of kinematics graphs.",2023-11-12,2023,2023-11,education
"Empowering Learning: Standalone, Browser-Only Courses for Seamless
  Education","Massive Open Online Courses (MOOCs) have transformed the educational
landscape, offering scalable and flexible learning opportunities, particularly
in data-centric fields like data science and artificial intelligence.
Incorporating AI and data science into MOOCs is a potential means of enhancing
the learning experience through adaptive learning approaches. In this context,
we introduce PyGlide, a proof-of-concept open-source MOOC delivery system that
underscores autonomy, transparency, and collaboration in maintaining course
content. We provide a user-friendly, step-by-step guide for PyGlide,
emphasizing its distinct advantage of not requiring any local software
installation for students. Highlighting its potential to enhance accessibility,
inclusivity, and the manageability of course materials, we showcase PyGlide's
practical application in a continuous integration pipeline on GitHub. We
believe that PyGlide charts a promising course for the future of open-source
MOOCs, effectively addressing crucial challenges in online education.",2023-11-12,2023,2023-11,education
"EduGym: An Environment and Notebook Suite for Reinforcement Learning
  Education","Due to the empirical success of reinforcement learning, an increasing number
of students study the subject. However, from our practical teaching experience,
we see students entering the field (bachelor, master and early PhD) often
struggle. On the one hand, textbooks and (online) lectures provide the
fundamentals, but students find it hard to translate between equations and
code. On the other hand, public codebases do provide practical examples, but
the implemented algorithms tend to be complex, and the underlying test
environments contain multiple reinforcement learning challenges at once.
Although this is realistic from a research perspective, it often hinders
educational conceptual understanding. To solve this issue we introduce EduGym,
a set of educational reinforcement learning environments and associated
interactive notebooks tailored for education. Each EduGym environment is
specifically designed to illustrate a certain aspect/challenge of reinforcement
learning (e.g., exploration, partial observability, stochasticity, etc.), while
the associated interactive notebook explains the challenge and its possible
solution approaches, connecting equations and code in a single document. An
evaluation among RL students and researchers shows 86% of them think EduGym is
a useful tool for reinforcement learning education. All notebooks are available
from https://www.edugym.org/, while the full software package can be installed
from https://github.com/RLG-Leiden/edugym.",2023-11-17,2023,2023-11,education
Generative AI has lowered the barriers to computational social sciences,"Generative artificial intelligence (AI) has revolutionized the field of
computational social science (CSS), unleashing new possibilities for collecting
and analyzing multimodal data, especially for scholars who may not have
extensive programming expertise. This breakthrough carries profound
implications for social scientists. First, generative AI can significantly
enhance the productivity of social scientists by automating the generation,
annotation, and debugging of code. Second, it empowers researchers to delve
into sophisticated data analysis through the innovative use of prompt
engineering. Last, the educational sphere of CSS stands to benefit immensely
from these tools, given their exceptional ability to annotate and elucidate
complex codes for learners, thereby simplifying the learning process and making
the technology more accessible.",2023-11-17,2023,2023-11,education
Large Language Models in Education: Vision and Opportunities,"With the rapid development of artificial intelligence technology, large
language models (LLMs) have become a hot research topic. Education plays an
important role in human social development and progress. Traditional education
faces challenges such as individual student differences, insufficient
allocation of teaching resources, and assessment of teaching effectiveness.
Therefore, the applications of LLMs in the field of digital/smart education
have broad prospects. The research on educational large models (EduLLMs) is
constantly evolving, providing new methods and approaches to achieve
personalized learning, intelligent tutoring, and educational assessment goals,
thereby improving the quality of education and the learning experience. This
article aims to investigate and summarize the application of LLMs in smart
education. It first introduces the research background and motivation of LLMs
and explains the essence of LLMs. It then discusses the relationship between
digital education and EduLLMs and summarizes the current research status of
educational large models. The main contributions are the systematic summary and
vision of the research background, motivation, and application of large models
for education (LLM4Edu). By reviewing existing research, this article provides
guidance and insights for educators, researchers, and policy-makers to gain a
deep understanding of the potential and challenges of LLM4Edu. It further
provides guidance for further advancing the development and application of
LLM4Edu, while still facing technical, ethical, and practical challenges
requiring further research and exploration.",2023-11-22,2023,2023-11,education
Education distillation:getting student models to learn in shcools,"This paper introduces a new knowledge distillation method, called education
distillation (ED), which is inspired by the structured and progressive nature
of human learning. ED mimics the educational stages of primary school, middle
school, and university and designs teaching reference blocks. The student model
is split into a main body and multiple teaching reference blocks to learn from
teachers step by step. This promotes efficient knowledge distillation while
maintaining the architecture of the student model. Experimental results on the
CIFAR100, Tiny Imagenet, Caltech and Food-101 datasets show that the teaching
reference blocks can effectively avoid the problem of forgetting. Compared with
conventional single-teacher and multi-teacher knowledge distillation methods,
ED significantly improves the accuracy and generalization ability of the
student model. These findings highlight the potential of ED to improve model
performance across different architectures and datasets, indicating its value
in various deep learning scenarios. Code examples can be obtained at:
https://github.com/Revolutioner1/ED.git.",2023-11-23,2023,2023-11,education
Ethical Implications of ChatGPT in Higher Education: A Scoping Review,"This scoping review explores the ethical challenges of using ChatGPT in
higher education. By reviewing recent academic articles in English, Chinese,
and Japanese, we aimed to provide a deep dive review and identify gaps in the
literature. Drawing on Arksey and O'Malley's (2005) scoping review framework,
we defined search terms and identified relevant publications from four
databases in the three target languages. The research results showed that the
majority of the papers were discussion papers, but there was some early
empirical work. The ethical issues highlighted in these works mainly concern
academic integrity, assessment issues, and data protection. Given the rapid
deployment of generative artificial intelligence, it is imperative for
educators to conduct more empirical studies to develop sound ethical policies
for its use.",2023-11-24,2023,2023-11,education
"Potential Societal Biases of ChatGPT in Higher Education: A Scoping
  Review","Purpose:Generative Artificial Intelligence (GAI) models, such as ChatGPT, may
inherit or amplify societal biases due to their training on extensive datasets.
With the increasing usage of GAI by students, faculty, and staff in higher
education institutions (HEIs), it is urgent to examine the ethical issues and
potential biases associated with these technologies.
Design/Approach/Methods:This scoping review aims to elucidate how biases
related to GAI in HEIs have been researched and discussed in recent academic
publications. We categorized the potential societal biases that GAI might cause
in the field of higher education. Our review includes articles written in
English, Chinese, and Japanese across four main databases, focusing on GAI
usage in higher education and bias. Findings:Our findings reveal that while
there is meaningful scholarly discussion around bias and discrimination
concerning LLMs in the AI field, most articles addressing higher education
approach the issue superficially. Few articles identify specific types of bias
under different circumstances, and there is a notable lack of empirical
research. Most papers in our review focus primarily on educational and research
fields related to medicine and engineering, with some addressing English
education. However, there is almost no discussion regarding the humanities and
social sciences. Additionally, a significant portion of the current discourse
is in English and primarily addresses English-speaking contexts.
Originality/Value:To the best of our knowledge, our study is the first to
summarize the potential societal biases in higher education. This review
highlights the need for more in-depth studies and empirical work to understand
the specific biases that GAI might introduce or amplify in educational
settings, guiding the development of more ethical AI applications in higher
education.",2023-11-24,2023,2023-11,education
ChatGPT and Beyond: The Generative AI Revolution in Education,"The wide adoption and usage of generative artificial intelligence (AI)
models, particularly ChatGPT, has sparked a surge in research exploring their
potential applications in the educational landscape. This survey examines
academic literature published between November, 2022, and July, 2023,
specifically targeting high-impact research from Scopus-indexed Q1 and Q2
journals. This survey delves into the practical applications and implications
of generative AI models across a diverse range of educational contexts. Through
a comprehensive and rigorous evaluation of recent academic literature, this
survey seeks to illuminate the evolving role of generative AI models,
particularly ChatGPT, in education. By shedding light on the potential
benefits, challenges, and emerging trends in this dynamic field, the survey
endeavors to contribute to the understanding of the nexus between artificial
intelligence and education. The findings of this review will empower educators,
researchers, and policymakers to make informed decisions about the integration
of AI technologies into learning environments.",2023-11-26,2023,2023-11,education
chatGPT for generating questions and assessments based on accreditations,"This research aims to take advantage of artificial intelligence techniques in
producing students assessment that is compatible with the different academic
accreditations of the same program. The possibility of using generative
artificial intelligence technology was studied to produce an academic
accreditation compliant test the National Center for Academic Accreditation of
Kingdom of Saudi Arabia and Accreditation Board for Engineering and Technology.
A novel method was introduced to map the verbs used to create the questions
introduced in the tests. The method allows a possibility of using the
generative artificial intelligence technology to produce and check the validity
of questions that measure educational outcomes. A questionnaire was distributed
to ensure that the use of generative artificial intelligence to create exam
questions is acceptable by the faculty members, as well as to ask about the
acceptance of assistance in validating questions submitted by faculty members
and amending them in accordance with academic accreditations. The questionnaire
was distributed to faculty members of different majors in the Kingdom of Saudi
Arabias universities. one hundred twenty responses obtained with eight five
percentile approval percentage for generate complete exam questions by
generative artificial intelligence . Whereas ninety eight percentage was the
approval percentage for editing and improving already existed questions.",2023-11-27,2023,2023-11,education
"Italian Crossword Generator: Enhancing Education through Interactive
  Word Puzzles","Educational crosswords offer numerous benefits for students, including
increased engagement, improved understanding, critical thinking, and memory
retention. Creating high-quality educational crosswords can be challenging, but
recent advances in natural language processing and machine learning have made
it possible to use language models to generate nice wordplays. The exploitation
of cutting-edge language models like GPT3-DaVinci, GPT3-Curie, GPT3-Babbage,
GPT3-Ada, and BERT-uncased has led to the development of a comprehensive system
for generating and verifying crossword clues. A large dataset of clue-answer
pairs was compiled to fine-tune the models in a supervised manner to generate
original and challenging clues from a given keyword. On the other hand, for
generating crossword clues from a given text, Zero/Few-shot learning techniques
were used to extract clues from the input text, adding variety and creativity
to the puzzles. We employed the fine-tuned model to generate data and labeled
the acceptability of clue-answer parts with human supervision. To ensure
quality, we developed a classifier by fine-tuning existing language models on
the labeled dataset. Conversely, to assess the quality of clues generated from
the given text using zero/few-shot learning, we employed a zero-shot learning
approach to check the quality of generated clues. The results of the evaluation
have been very promising, demonstrating the effectiveness of the approach in
creating high-standard educational crosswords that offer students engaging and
rewarding learning experiences.",2023-11-27,2023,2023-11,education
"Finnish 5th and 6th graders' misconceptions about Artificial
  Intelligence","Research on children's initial conceptions of AI is in an emerging state,
which, from a constructivist viewpoint, challenges the development of
pedagogically sound AI-literacy curricula, methods, and materials. To
contribute to resolving this need in the present paper, qualitative survey data
from 195 children were analyzed abductively to answer the following three
research questions: What kind of misconceptions do Finnish 5th and 6th graders'
have about the essence AI?; 2) How do these misconceptions relate to common
misconception types?; and 3) How profound are these misconceptions? As a
result, three misconception categories were identified: 1) Non-technological
AI, in which AI was conceptualized as peoples' cognitive processes (factual
misconception); 2) Anthropomorphic AI, in which AI was conceptualized as a
human-like entity (vernacular, non-scientific, and conceptual misconception);
and 3) AI as a machine with a pre-installed intelligence or knowledge (factual
misconception). Majority of the children evaluated their AI-knowledge low,
which implies that the misconceptions are more superficial than profound. The
findings suggest that context-specific linguistic features can contribute to
students' AI misconceptions. Implications for future research and AI literacy
education are discussed.",2023-11-28,2023,2023-11,education
"Generative Artificial Intelligence in Learning Analytics:
  Contextualising Opportunities and Challenges through the Learning Analytics
  Cycle","Generative artificial intelligence (GenAI), exemplified by ChatGPT,
Midjourney, and other state-of-the-art large language models and diffusion
models, holds significant potential for transforming education and enhancing
human productivity. While the prevalence of GenAI in education has motivated
numerous research initiatives, integrating these technologies within the
learning analytics (LA) cycle and their implications for practical
interventions remain underexplored. This paper delves into the prospective
opportunities and challenges GenAI poses for advancing LA. We present a concise
overview of the current GenAI landscape and contextualise its potential roles
within Clow's generic framework of the LA cycle. We posit that GenAI can play
pivotal roles in analysing unstructured data, generating synthetic learner
data, enriching multimodal learner interactions, advancing interactive and
explanatory analytics, and facilitating personalisation and adaptive
interventions. As the lines blur between learners and GenAI tools, a renewed
understanding of learners is needed. Future research can delve deep into
frameworks and methodologies that advocate for human-AI collaboration. The LA
community can play a pivotal role in capturing data about human and AI
contributions and exploring how they can collaborate most effectively. As LA
advances, it is essential to consider the pedagogical implications and broader
socioeconomic impact of GenAI for ensuring an inclusive future.",2023-11-30,2023,2023-11,education
Anatomy and Physiology of Artificial Intelligence in PET Imaging,"The influence of artificial intelligence (AI) within the field of nuclear
medicine has been rapidly growing. Many researchers and clinicians are seeking
to apply AI within PET, and clinicians will soon find themselves engaging with
AI-based applications all along the chain of molecular imaging, from image
reconstruction to enhanced reporting. This expanding presence of AI in PET
imaging will result in greater demand for educational resources for those
unfamiliar with AI. The objective of this article to is provide an illustrated
guide to the core principles of modern AI, with specific focus on aspects that
are most likely to be encountered in PET imaging. We describe convolutional
neural networks, algorithm training, and explain the components of the commonly
used U-Net for segmentation and image synthesis.",2023-11-30,2023,2023-11,education
"Clustering Students According to their Academic Achievement Using Fuzzy
  Logic","The software for clustering students according to their educational
achievements using fuzzy logic was developed in Python using the Google Colab
cloud service. In the process of analyzing educational data, the problems of
Data Mining are solved, since only some characteristics of the educational
process are obtained from a large sample of data. Data clustering was performed
using the classic K-Means method, which is characterized by simplicity and high
speed. Cluster analysis was performed in the space of two features using the
machine learning library scikit-learn (Python). The obtained clusters are
described by fuzzy triangular membership functions, which allowed to correctly
determine the membership of each student to a certain cluster. Creation of
fuzzy membership functions is done using the scikit-fuzzy library. The
development of fuzzy functions of objects belonging to clusters is also useful
for educational purposes, as it allows a better understanding of the principles
of using fuzzy logic. As a result of processing test educational data using the
developed software, correct results were obtained. It is shown that the use of
fuzzy membership functions makes it possible to correctly determine the
belonging of students to certain clusters, even if such clusters are not
clearly separated. Due to this, it is possible to more accurately determine the
recommended level of difficulty of tasks for each student, depending on his
previous evaluations.",2023-12-01,2023,2023-12,education
"Kattis vs. ChatGPT: Assessment and Evaluation of Programming Tasks in
  the Age of Artificial Intelligence","AI-powered education technologies can support students and teachers in
computer science education. However, with the recent developments in generative
AI, and especially the increasingly emerging popularity of ChatGPT, the
effectiveness of using large language models for solving programming tasks has
been underexplored. The present study examines ChatGPT's ability to generate
code solutions at different difficulty levels for introductory programming
courses. We conducted an experiment where ChatGPT was tested on 127 randomly
selected programming problems provided by Kattis, an automatic software grading
tool for computer science programs, often used in higher education. The results
showed that ChatGPT independently could solve 19 out of 127 programming tasks
generated and assessed by Kattis. Further, ChatGPT was found to be able to
generate accurate code solutions for simple problems but encountered
difficulties with more complex programming tasks. The results contribute to the
ongoing debate on the utility of AI-powered tools in programming education.",2023-12-02,2023,2023-12,education
"ArabIcros: AI-Powered Arabic Crossword Puzzle Generation for Educational
  Applications","This paper presents the first Arabic crossword puzzle generator driven by
advanced AI technology. Leveraging cutting-edge large language models including
GPT4, GPT3-Davinci, GPT3-Curie, GPT3-Babbage, GPT3-Ada, and BERT, the system
generates distinctive and challenging clues. Based on a dataset comprising over
50,000 clue-answer pairs, the generator employs fine-tuning, few/zero-shot
learning strategies, and rigorous quality-checking protocols to enforce the
generation of high-quality clue-answer pairs. Importantly, educational
crosswords contribute to enhancing memory, expanding vocabulary, and promoting
problem-solving skills, thereby augmenting the learning experience through a
fun and engaging approach, reshaping the landscape of traditional learning
methods. The overall system can be exploited as a powerful educational tool
that amalgamates AI and innovative learning techniques, heralding a
transformative era for Arabic crossword puzzles and the intersection of
technology and education.",2023-12-03,2023,2023-12,education
Know Your Audience: Do LLMs Adapt to Different Age and Education Levels?,"Large language models (LLMs) offer a range of new possibilities, including
adapting the text to different audiences and their reading needs. But how well
do they adapt? We evaluate the readability of answers generated by four
state-of-the-art LLMs (commercial and open-source) to science questions when
prompted to target different age groups and education levels. To assess the
adaptability of LLMs to diverse audiences, we compare the readability scores of
the generated responses against the recommended comprehension level of each age
and education group. We find large variations in the readability of the answers
by different LLMs. Our results suggest LLM answers need to be better adapted to
the intended audience demographics to be more comprehensible. They underline
the importance of enhancing the adaptability of LLMs in education settings to
cater to diverse age and education levels. Overall, current LLMs have set
readability ranges and do not adapt well to different audiences, even when
prompted. That limits their potential for educational purposes.",2023-12-04,2023,2023-12,education
Peer attention enhances student learning,"Human visual attention is susceptible to social influences. In education,
peer effects impact student learning, but their precise role in modulating
attention remains unclear. Our experiment (N=311) demonstrates that displaying
peer visual attention regions when students watch online course videos enhances
their focus and engagement. However, students retain adaptability in following
peer attention cues. Overall, guided peer attention improves learning
experiences and outcomes. These findings elucidate how peer visual attention
shapes students' gaze patterns, deepening understanding of peer influence on
learning. They also offer insights into designing adaptive online learning
interventions leveraging peer attention modelling to optimize student
attentiveness and success.",2023-12-04,2023,2023-12,education
"Teenagers and Artificial Intelligence: Bootcamp Experience and Lessons
  Learned","Artificial intelligence (AI) stands out as a game-changer in today's
technology landscape. However, the integration of AI education in classroom
curricula currently lags behind, leaving teenagers inadequately prepared for an
imminent AI-driven future.
  In this pilot study, we designed a three-day bootcamp offered in the summer
of 2023 to a cohort of 60 high school students. The curriculum was delivered in
person through animated video content, easy-to-follow slides, interactive
playgrounds, and quizzes. These were packaged in the early version of an online
learning platform we are developing. Results from the post-bootcamp survey
conveyed a 91.4% overall satisfaction. Despite the short bootcamp duration,
88.5% and 71.4% of teenagers responded that they had an improved understanding
of AI concepts and programming, respectively.
  Overall, we found that employing diverse modalities effectively engaged
students, and building foundational modules proved beneficial for introducing
more complex topics. Furthermore, using Google Colab notebooks for coding
assignments proved challenging to most students. Students' activity on the
platform and their answers to quizzes showed proficient engagement and a grasp
of the material.
  Our results strongly highlight the need for compelling and accessible AI
education methods for the next generation and the potential for informal
learning to fill the gap of providing early AI education to teenagers.",2023-12-05,2023,2023-12,education
"A Comparative Study of AI-Generated (GPT-4) and Human-crafted MCQs in
  Programming Education","There is a constant need for educators to develop and maintain effective
up-to-date assessments. While there is a growing body of research in computing
education on utilizing large language models (LLMs) in generation and
engagement with coding exercises, the use of LLMs for generating programming
MCQs has not been extensively explored. We analyzed the capability of GPT-4 to
produce multiple-choice questions (MCQs) aligned with specific learning
objectives (LOs) from Python programming classes in higher education.
Specifically, we developed an LLM-powered (GPT-4) system for generation of MCQs
from high-level course context and module-level LOs. We evaluated 651
LLM-generated and 449 human-crafted MCQs aligned to 246 LOs from 6 Python
courses. We found that GPT-4 was capable of producing MCQs with clear language,
a single correct choice, and high-quality distractors. We also observed that
the generated MCQs appeared to be well-aligned with the LOs. Our findings can
be leveraged by educators wishing to take advantage of the state-of-the-art
generative models to support MCQ authoring efforts.",2023-12-05,2023,2023-12,education
Contra generative AI detection in higher education assessments,"This paper presents a critical analysis of generative Artificial Intelligence
(AI) detection tools in higher education assessments. The rapid advancement and
widespread adoption of generative AI, particularly in education, necessitates a
reevaluation of traditional academic integrity mechanisms. We explore the
effectiveness, vulnerabilities, and ethical implications of AI detection tools
in the context of preserving academic integrity. Our study synthesises insights
from various case studies, newspaper articles, and student testimonies to
scrutinise the practical and philosophical challenges associated with AI
detection. We argue that the reliance on detection mechanisms is misaligned
with the educational landscape, where AI plays an increasingly widespread role.
This paper advocates for a strategic shift towards robust assessment methods
and educational policies that embrace generative AI usage while ensuring
academic integrity and authenticity in assessments.",2023-12-08,2023,2023-12,education
"Generative AI in Higher Education: Seeing ChatGPT Through Universities'
  Policies, Resources, and Guidelines","The advancements in Generative Artificial Intelligence (GenAI) provide
opportunities to enrich educational experiences, but also raise concerns about
academic integrity. Many educators have expressed anxiety and hesitation in
integrating GenAI in their teaching practices, and are in needs of
recommendations and guidance from their institutions that can support them to
incorporate GenAI in their classrooms effectively. In order to respond to
higher educators' needs, this study aims to explore how universities and
educators respond and adapt to the development of GenAI in their academic
contexts by analyzing academic policies and guidelines established by
top-ranked U.S. universities regarding the use of GenAI, especially ChatGPT.
Data sources include academic policies, statements, guidelines, and relevant
resources provided by the top 100 universities in the U.S. Results show that
the majority of these universities adopt an open but cautious approach towards
GenAI. Primary concerns lie in ethical usage, accuracy, and data privacy. Most
universities actively respond and provide diverse types of resources, such as
syllabus templates, workshops, shared articles, and one-on-one consultations
focusing on a range of topics: general technical introduction, ethical
concerns, pedagogical applications, preventive strategies, data privacy,
limitations, and detective tools. The findings provide four practical
pedagogical implications for educators in teaching practices: accept its
presence, align its use with learning objectives, evolve curriculum to prevent
misuse, and adopt multifaceted evaluation strategies rather than relying on AI
detectors. Two recommendations are suggested for educators in policy making:
establish discipline-specific policies and guidelines, and manage sensitive
information carefully.",2023-12-08,2023,2023-12,education
"Artificial intelligence in social science: A study based on
  bibliometrics analysis","Artificial intelligence (AI) is gradually changing the planet. Data
digitisation, computing infrastructure and machine learning are helping AI
tools to spread across all sectors of society. This article presents the
results of a bibliometric analysis of AI-related publications in the social
sciences over the last ten years (2013-2022). Most of the historical
publications are taken into consideration with the aim of identifying research
relevance and trends in this field. The results indicate that more than 19,408
articles have been published, 85% from 2008 to 2022, showing that research in
this field is increasing significantly year on year. Clear domains or
disciplines of research related to AI within the social sciences can be grouped
into sub-areas such as law and legal reasoning, education, economics, and
ethics. The United States is the country that publishes the most (20%),
followed by China (13%). The influence of AI on society is inevitable and the
advances can generate great opportunities for innovation and new jobs, but in
the medium term it is necessary to adequately face this transition, setting
regulations and reviewing the challenges of ethics and responsibility.",2023-12-09,2023,2023-12,education
"Multimodality of AI for Education: Towards Artificial General
  Intelligence","This paper presents a comprehensive examination of how multimodal artificial
intelligence (AI) approaches are paving the way towards the realization of
Artificial General Intelligence (AGI) in educational contexts. It scrutinizes
the evolution and integration of AI in educational systems, emphasizing the
crucial role of multimodality, which encompasses auditory, visual, kinesthetic,
and linguistic modes of learning. This research delves deeply into the key
facets of AGI, including cognitive frameworks, advanced knowledge
representation, adaptive learning mechanisms, strategic planning, sophisticated
language processing, and the integration of diverse multimodal data sources. It
critically assesses AGI's transformative potential in reshaping educational
paradigms, focusing on enhancing teaching and learning effectiveness, filling
gaps in existing methodologies, and addressing ethical considerations and
responsible usage of AGI in educational settings. The paper also discusses the
implications of multimodal AI's role in education, offering insights into
future directions and challenges in AGI development. This exploration aims to
provide a nuanced understanding of the intersection between AI, multimodality,
and education, setting a foundation for future research and development in AGI.",2023-12-10,2023,2023-12,education
"Explain To Decide: A Human-Centric Review on the Role of Explainable
  Artificial Intelligence in AI-assisted Decision Making","The unprecedented performance of machine learning models in recent years,
particularly Deep Learning and transformer models, has resulted in their
application in various domains such as finance, healthcare, and education.
However, the models are error-prone and cannot be used autonomously, especially
in decision-making scenarios where, technically or ethically, the cost of error
is high. Moreover, because of the black-box nature of these models, it is
frequently difficult for the end user to comprehend the models' outcomes and
underlying processes to trust and use the model outcome to make a decision.
Explainable Artificial Intelligence (XAI) aids end-user understanding of the
model by utilizing approaches, including visualization techniques, to explain
and interpret the inner workings of the model and how it arrives at a result.
Although numerous research studies have been conducted recently focusing on the
performance of models and the XAI approaches, less work has been done on the
impact of explanations on human-AI team performance. This paper surveyed the
recent empirical studies on XAI's impact on human-AI decision-making,
identified the challenges, and proposed future research directions.",2023-12-11,2023,2023-12,education
"The AI Assessment Scale (AIAS): A Framework for Ethical Integration of
  Generative AI in Educational Assessment","Recent developments in Generative Artificial Intelligence (GenAI) have
created a paradigm shift in multiple areas of society, and the use of these
technologies is likely to become a defining feature of education in coming
decades. GenAI offers transformative pedagogical opportunities, while
simultaneously posing ethical and academic challenges. Against this backdrop,
we outline a practical, simple, and sufficiently comprehensive tool to allow
for the integration of GenAI tools into educational assessment: the AI
Assessment Scale (AIAS).
  The AIAS empowers educators to select the appropriate level of GenAI usage in
assessments based on the learning outcomes they seek to address. The AIAS
offers greater clarity and transparency for students and educators, provides a
fair and equitable policy tool for institutions to work with, and offers a
nuanced approach which embraces the opportunities of GenAI while recognising
that there are instances where such tools may not be pedagogically appropriate
or necessary.
  By adopting a practical, flexible approach that can be implemented quickly,
the AIAS can form a much-needed starting point to address the current
uncertainty and anxiety regarding GenAI in education. As a secondary objective,
we engage with the current literature and advocate for a refocused discourse on
GenAI tools in education, one which foregrounds how technologies can help
support and enhance teaching and learning, which contrasts with the current
focus on GenAI as a facilitator of academic misconduct.",2023-12-12,2023,2023-12,education
"Harnessing Retrieval-Augmented Generation (RAG) for Uncovering Knowledge
  Gaps","The paper presents a methodology for uncovering knowledge gaps on the
internet using the Retrieval Augmented Generation (RAG) model. By simulating
user search behaviour, the RAG system identifies and addresses gaps in
information retrieval systems. The study demonstrates the effectiveness of the
RAG system in generating relevant suggestions with a consistent accuracy of
93%. The methodology can be applied in various fields such as scientific
discovery, educational enhancement, research development, market analysis,
search engine optimisation, and content development. The results highlight the
value of identifying and understanding knowledge gaps to guide future
endeavours.",2023-12-12,2023,2023-12,education
ArchiGuesser -- AI Art Architecture Educational Game,"The use of generative AI in education is a controversial topic. Current
technology offers the potential to create educational content from text,
speech, to images based on simple input prompts. This can enhance productivity
by summarizing knowledge and improving communication, quickly adjusting to
different types of learners. Moreover, generative AI holds the promise of
making the learning itself more fun, by responding to user inputs and
dynamically generating high-quality creative material. In this paper we present
the multisensory educational game ArchiGuesser that combines various AI
technologies from large language models, image generation, to computer vision
to serve a single purpose: Teaching students in a playful way the diversity of
our architectural history and how generative AI works.",2023-12-14,2023,2023-12,education
"Integrating AI and Learning Analytics for Data-Driven Pedagogical
  Decisions and Personalized Interventions in Education","This research study explores the conceptualization, development, and
deployment of an innovative learning analytics tool, leveraging OpenAI's GPT-4
model to quantify student engagement, map learning progression, and evaluate
diverse instructional strategies within an educational context. By analyzing
critical data points such as students' stress levels, curiosity, confusion,
agitation, topic preferences, and study methods, the tool provides a
comprehensive view of the learning environment. It also employs Bloom's
taxonomy to assess cognitive development based on student inquiries. In
addition to technical evaluation through synthetic data, feedback from a survey
of teaching faculty at the University of Iowa was collected to gauge perceived
benefits and challenges. Faculty recognized the tool's potential to enhance
instructional decision-making through real-time insights but expressed concerns
about data security and the accuracy of AI-generated insights. The study
outlines the design, implementation, and evaluation of the tool, highlighting
its contributions to educational outcomes, practical integration within
learning management systems, and future refinements needed to address privacy
and accuracy concerns. This research underscores AI's role in shaping
personalized, data-driven education.",2023-12-15,2023,2023-12,education
"Students' Perceptions and Preferences of Generative Artificial
  Intelligence Feedback for Programming","The rapid evolution of artificial intelligence (AI), specifically large
language models (LLMs), has opened opportunities for various educational
applications. This paper explored the feasibility of utilizing ChatGPT, one of
the most popular LLMs, for automating feedback for Java programming assignments
in an introductory computer science (CS1) class. Specifically, this study
focused on three questions: 1) To what extent do students view LLM-generated
feedback as formative? 2) How do students see the comparative affordances of
feedback prompts that include their code, vs. those that exclude it? 3) What
enhancements do students suggest for improving AI-generated feedback? To
address these questions, we generated automated feedback using the ChatGPT API
for four lab assignments in the CS1 class. The survey results revealed that
students perceived the feedback as aligning well with formative feedback
guidelines established by Shute. Additionally, students showed a clear
preference for feedback generated by including the students' code as part of
the LLM prompt, and our thematic study indicated that the preference was mainly
attributed to the specificity, clarity, and corrective nature of the feedback.
Moreover, this study found that students generally expected specific and
corrective feedback with sufficient code examples, but had diverged opinions on
the tone of the feedback. This study demonstrated that ChatGPT could generate
Java programming assignment feedback that students perceived as formative. It
also offered insights into the specific improvements that would make the
ChatGPT-generated feedback useful for students.",2023-12-17,2023,2023-12,education
"From Google Gemini to OpenAI Q* (Q-Star): A Survey of Reshaping the
  Generative Artificial Intelligence (AI) Research Landscape","This comprehensive survey explored the evolving landscape of generative
Artificial Intelligence (AI), with a specific focus on the transformative
impacts of Mixture of Experts (MoE), multimodal learning, and the speculated
advancements towards Artificial General Intelligence (AGI). It critically
examined the current state and future trajectory of generative Artificial
Intelligence (AI), exploring how innovations like Google's Gemini and the
anticipated OpenAI Q* project are reshaping research priorities and
applications across various domains, including an impact analysis on the
generative AI research taxonomy. It assessed the computational challenges,
scalability, and real-world implications of these technologies while
highlighting their potential in driving significant progress in fields like
healthcare, finance, and education. It also addressed the emerging academic
challenges posed by the proliferation of both AI-themed and AI-generated
preprints, examining their impact on the peer-review process and scholarly
communication. The study highlighted the importance of incorporating ethical
and human-centric methods in AI development, ensuring alignment with societal
norms and welfare, and outlined a strategy for future AI research that focuses
on a balanced and conscientious use of MoE, multimodality, and AGI in
generative AI.",2023-12-18,2023,2023-12,education
Dissecting Bias of ChatGPT in College Major Recommendations,"I investigate bias in terms of ChatGPT's college major recommendations for
students with various profiles, looking at demographic disparities in factors
such as race, gender, and socioeconomic status, as well as educational
disparities such as score percentiles. By constructing prompts for the ChatGPT
API, allowing the model to recommend majors based on high school student
profiles, I evaluate bias using various metrics, including the Jaccard
Coefficient, Wasserstein Metric, and STEM Disparity Score. The results of this
study reveal a significant disparity in the set of recommended college majors,
irrespective of the bias metric applied.",2023-12-18,2023,2023-12,education
Skills or Degree? The Rise of Skill-Based Hiring for AI and Green Jobs,"Emerging professions in fields like Artificial Intelligence (AI) and
sustainability (green jobs) are experiencing labour shortages as industry
demand outpaces labour supply. In this context, our study aims to understand
whether employers have begun focusing more on individual skills rather than
formal qualifications in their recruitment processes. We analysed a large
time-series dataset of approximately eleven million online job vacancies in the
UK from 2018 to mid-2024, drawing on diverse literature on technological change
and labour market signalling. Our findings provide evidence that employers have
initiated ""skill-based hiring"" for AI roles, adopting more flexible hiring
practices to expand the available talent pool. From 2018-2023, demand for AI
roles grew by 21% as a proportion of all postings (and accelerated into 2024).
Simultaneously, mentions of university education requirements for AI roles
declined by 15%. Our regression analysis shows that university degrees have a
significantly lower wage premium for both AI and green roles. In contrast, AI
skills command a wage premium of 23%, exceeding the value of degrees up until
the PhD-level (33%). In occupations with high demand for AI skills, the premium
for skills is high, and the reward for degrees is relatively low. We recommend
leveraging alternative skill-building formats such as apprenticeships,
on-the-job training, MOOCs, vocational education and training,
micro-certificates, and online bootcamps to fully utilise human capital and
address talent shortages.",2023-12-19,2023,2023-12,education
"The Key Artificial Intelligence Technologies in Early Childhood
  Education: A Review","Artificial Intelligence (AI) technologies have been applied in various
domains, including early childhood education (ECE). Integration of AI
educational technology is a recent significant trend in ECE. Currently, there
are more and more studies of AI in ECE. To date, there is a lack of survey
articles that discuss the studies of AI in ECE. In this paper, we provide an
up-to-date and in-depth overview of the key AI technologies in ECE that
provides a historical perspective, summarizes the representative works,
outlines open questions, discusses the trends and challenges through a detailed
bibliometric analysis, and provides insightful recommendations for future
research. We mainly discuss the studies that apply AI-based robots and AI
technologies to ECE, including improving the social interaction of children
with an autism spectrum disorder. This paper significantly contributes to
provide an up-to-date and in-depth survey that is suitable as introductory
material for beginners to AI in ECE, as well as supplementary material for
advanced users.",2023-12-20,2023,2023-12,education
"Human-Centred Learning Analytics and AI in Education: a Systematic
  Literature Review","The rapid expansion of Learning Analytics (LA) and Artificial Intelligence in
Education (AIED) offers new scalable, data-intensive systems but also raises
concerns about data privacy and agency. Excluding stakeholders -- like students
and teachers -- from the design process can potentially lead to mistrust and
inadequately aligned tools. Despite a shift towards human-centred design in
recent LA and AIED research, there remain gaps in our understanding of the
importance of human control, safety, reliability, and trustworthiness in the
design and implementation of these systems. We conducted a systematic
literature review to explore these concerns and gaps. We analysed 108 papers to
provide insights about i) the current state of human-centred LA/AIED research;
ii) the extent to which educational stakeholders have contributed to the design
process of human-centred LA/AIED systems; iii) the current balance between
human control and computer automation of such systems; and iv) the extent to
which safety, reliability and trustworthiness have been considered in the
literature. Results indicate some consideration of human control in LA/AIED
system design, but limited end-user involvement in actual design. Based on
these findings, we recommend: 1) carefully balancing stakeholders' involvement
in designing and deploying LA/AIED systems throughout all design phases, 2)
actively involving target end-users, especially students, to delineate the
balance between human control and automation, and 3) exploring safety,
reliability, and trustworthiness as principles in future human-centred LA/AIED
systems.",2023-12-20,2023,2023-12,education
"Future-proofing Education: A Prototype for Simulating Oral Examinations
  Using Large Language Models","This study explores the impact of Large Language Models (LLMs) in higher
education, focusing on an automated oral examination simulation using a
prototype. The design considerations of the prototype are described, and the
system is evaluated with a select group of educators and students. Technical
and pedagogical observations are discussed. The prototype proved to be
effective in simulating oral exams, providing personalized feedback, and
streamlining educators' workloads. The promising results of the prototype show
the potential for LLMs in democratizing education, inclusion of diverse student
populations, and improvement of teaching quality and efficiency.",2023-12-22,2023,2023-12,education
"The Global Impact of AI-Artificial Intelligence: Recent Advances and
  Future Directions, A Review","Artificial intelligence (AI) is an emerging technology that has the potential
to transform many aspects of society, including the economy, healthcare, and
transportation. This article synthesizes recent research literature on the
global impact of AI, exploring its potential benefits and risks. The article
highlights the implications of AI, including its impact on economic, ethical,
social, security & privacy, and job displacement aspects. It discusses the
ethical concerns surrounding AI development, including issues of bias,
security, and privacy violations. To ensure the responsible development and
deployment of AI, collaboration between government, industry, and academia is
essential. The article concludes by emphasizing the importance of public
engagement and education to promote awareness and understanding of AI's impact
on society at large.",2023-12-22,2023,2023-12,education
"Integrating ChatGPT in a Computer Science Course: Students Perceptions
  and Suggestions","The integration of artificial intelligence tools such as ChatGPT in the
education system has gained attention in recent years. This experience report
explores students' perceptions and suggestions for integrating ChatGPT in a
computer science course. Following a ChatGPT activity which includes code
completion and analysis, seven students participated in in-depth interviews.
Findings from the transcribed interviews suggest that ChatGPT has the potential
to enhance learning experience including programming. They highlighted the
tool's ability to respond immediately to queries and supporting personalised
learning. However, they raise concerns that heavy reliance on ChatGPT may
adversely affect students' critical thinking and problem-solving skills. These
findings show the importance of carefully balancing using ChatGPT in computer
science courses. The findings of this research have significant implications
for educators, curriculum designers and policymakers as they explore
integrating AI tools into educational contexts.",2023-12-22,2023,2023-12,education
"Reinforcement Learning for Safe Occupancy Strategies in Educational
  Spaces during an Epidemic","Epidemic modeling, encompassing deterministic and stochastic approaches, is
vital for understanding infectious diseases and informing public health
strategies. This research adopts a prescriptive approach, focusing on
reinforcement learning (RL) to develop strategies that balance minimizing
infections with maximizing in-person interactions in educational settings. We
introduce SafeCampus , a novel tool that simulates infection spread and
facilitates the exploration of various RL algorithms in response to epidemic
challenges. SafeCampus incorporates a custom RL environment, informed by
stochastic epidemic models, to realistically represent university campus
dynamics during epidemics. We evaluate Q-learning for a discretized state space
which resulted in a policy matrix that not only guides occupancy decisions
under varying epidemic conditions but also illustrates the inherent trade-off
in epidemic management. This trade-off is characterized by the dilemma between
stricter measures, which may effectively reduce infections but impose less
educational benefit (more in-person interactions), and more lenient policies,
which could lead to higher infection rates.",2023-12-23,2023,2023-12,education
Gemini Pro Defeated by GPT-4V: Evidence from Education,"This study compared the classification performance of Gemini Pro and GPT-4V
in educational settings. Employing visual question answering (VQA) techniques,
the study examined both models' abilities to read text-based rubrics and then
automatically score student-drawn models in science education. We employed both
quantitative and qualitative analyses using a dataset derived from
student-drawn scientific models and employing NERIF (Notation-Enhanced Rubrics
for Image Feedback) prompting methods. The findings reveal that GPT-4V
significantly outperforms Gemini Pro in terms of scoring accuracy and Quadratic
Weighted Kappa. The qualitative analysis reveals that the differences may be
due to the models' ability to process fine-grained texts in images and overall
image classification performance. Even adapting the NERIF approach by further
de-sizing the input images, Gemini Pro seems not able to perform as well as
GPT-4V. The findings suggest GPT-4V's superior capability in handling complex
multimodal educational tasks. The study concludes that while both models
represent advancements in AI, GPT-4V's higher performance makes it a more
suitable tool for educational applications involving multimodal data
interpretation.",2023-12-27,2023,2023-12,education
"Adapting Large Language Models for Education: Foundational Capabilities,
  Potentials, and Challenges","Online education platforms, leveraging the internet to distribute education
resources, seek to provide convenient education but often fall short in
real-time communication with students. They often struggle to address the
diverse obstacles students encounter throughout their learning journey. Solving
the problems encountered by students poses a significant challenge for
traditional deep learning models, as it requires not only a broad spectrum of
subject knowledge but also the ability to understand what constitutes a
student's individual difficulties. It's challenging for traditional machine
learning models, as they lack the capacity to comprehend students' personalized
needs. Recently, the emergence of large language models (LLMs) offers the
possibility for resolving this issue by comprehending individual requests.
Although LLMs have been successful in various fields, creating an LLM-based
education system is still challenging for the wide range of educational skills
required. This paper reviews the recently emerged LLM research related to
educational capabilities, including mathematics, writing, programming,
reasoning, and knowledge-based question answering, with the aim to explore
their potential in constructing the next-generation intelligent education
system. Specifically, for each capability, we focus on investigating two
aspects. Firstly, we examine the current state of LLMs regarding this
capability: how advanced they have become, whether they surpass human
abilities, and what deficiencies might exist. Secondly, we evaluate whether the
development methods for LLMs in this area are generalizable, that is, whether
these methods can be applied to construct a comprehensive educational
supermodel with strengths across various capabilities, rather than being
effective in only a singular aspect.",2023-12-27,2023,2023-12,education
"Empowering Africa: An In-depth Exploration of the Adoption of Artificial
  Intelligence Across the Continent","This paper explores the dynamic landscape of Artificial Intelligence (AI)
adoption in Africa, analysing its varied applications in addressing
socio-economic challenges and fostering development. Examining the African AI
ecosystem, the study considers regional nuances, cultural factors, and
infrastructural constraints shaping the deployment of AI solutions. Case
studies in healthcare, agriculture, finance, and education highlight AI's
transformative potential for efficiency, accessibility, and inclusivity. The
paper emphasizes indigenous AI innovations and international collaborations
contributing to a distinct African AI ecosystem. Ethical considerations,
including data privacy and algorithmic bias, are addressed alongside policy
frameworks supporting responsible AI implementation. The role of governmental
bodies, regulations, and private sector partnerships is explored in creating a
conducive AI development environment. Challenges such as digital literacy gaps
and job displacement are discussed, with proposed strategies for mitigation. In
conclusion, the paper provides a nuanced understanding of AI in Africa,
contributing to sustainable development discussions and advocating for an
inclusive and ethical AI ecosystem on the continent.",2023-12-28,2023,2023-12,education
A Toolbox for Modelling Engagement with Educational Videos,"With the advancement and utility of Artificial Intelligence (AI),
personalising education to a global population could be a cornerstone of new
educational systems in the future. This work presents the PEEKC dataset and the
TrueLearn Python library, which contains a dataset and a series of online
learner state models that are essential to facilitate research on learner
engagement modelling.TrueLearn family of models was designed following the
""open learner"" concept, using humanly-intuitive user representations. This
family of scalable, online models also help end-users visualise the learner
models, which may in the future facilitate user interaction with their
models/recommenders. The extensive documentation and coding examples make the
library highly accessible to both machine learning developers and educational
data mining and learning analytics practitioners. The experiments show the
utility of both the dataset and the library with predictive performance
significantly exceeding comparative baseline models. The dataset contains a
large amount of AI-related educational videos, which are of interest for
building and validating AI-specific educational recommenders.",2023-12-30,2023,2023-12,education
"Taking the Next Step with Generative Artificial Intelligence: The
  Transformative Role of Multimodal Large Language Models in Science Education","The integration of Artificial Intelligence (AI), particularly Large Language
Model (LLM)-based systems, in education has shown promise in enhancing teaching
and learning experiences. However, the advent of Multimodal Large Language
Models (MLLMs) like GPT-4 with vision (GPT-4V), capable of processing
multimodal data including text, sound, and visual inputs, opens a new era of
enriched, personalized, and interactive learning landscapes in education.
Grounded in theory of multimedia learning, this paper explores the
transformative role of MLLMs in central aspects of science education by
presenting exemplary innovative learning scenarios. Possible applications for
MLLMs could range from content creation to tailored support for learning,
fostering competencies in scientific practices, and providing assessment and
feedback. These scenarios are not limited to text-based and uni-modal formats
but can be multimodal, increasing thus personalization, accessibility, and
potential learning effectiveness. Besides many opportunities, challenges such
as data protection and ethical considerations become more salient, calling for
robust frameworks to ensure responsible integration. This paper underscores the
necessity for a balanced approach in implementing MLLMs, where the technology
complements rather than supplants the educator's role, ensuring thus an
effective and ethical use of AI in science education. It calls for further
research to explore the nuanced implications of MLLMs on the evolving role of
educators and to extend the discourse beyond science education to other
disciplines. Through the exploration of potentials, challenges, and future
implications, we aim to contribute to a preliminary understanding of the
transformative trajectory of MLLMs in science education and beyond.",2024-01-01,2024,2024-01,education
"Student and AI responses to physics problems examined through the lenses
  of sensemaking and mechanistic reasoning","Several reports in education have called for transforming physics learning
environments by promoting sensemaking of real-world scenarios in light of
curricular ideas. Recent advancements in Generative-Artificial Intelligence has
garnered increasing traction in educators' community by virtue of its potential
in transforming STEM learning. In this exploratory study, we adopt a
mixed-methods approach in comparatively examining student- and AI-generated
responses to two different formats of a physics problem through the cognitive
lenses of sensemaking and mechanistic reasoning. The student data is derived
from think-aloud interviews of introductory students and the AI data comes from
ChatGPT's solutions collected using Zero shot approach. The results highlight
AI responses to evidence most features of the two processes through
well-structured solutions and student responses to effectively leverage
representations in their solutions through iterative refinement of arguments.
In other words, while AI responses reflect how physics is talked about, the
student responses reflect how physics is practiced. Implications of these
results in light of development and deployment of AI systems in physics
pedagogy are discussed.",2024-01-01,2024,2024-01,education
"Evaluating Large Language Models on the GMAT: Implications for the
  Future of Business Education","The rapid evolution of artificial intelligence (AI), especially in the domain
of Large Language Models (LLMs) and generative AI, has opened new avenues for
application across various fields, yet its role in business education remains
underexplored. This study introduces the first benchmark to assess the
performance of seven major LLMs, OpenAI's models (GPT-3.5 Turbo, GPT-4, and
GPT-4 Turbo), Google's models (PaLM 2, Gemini 1.0 Pro), and Anthropic's models
(Claude 2 and Claude 2.1), on the GMAT, which is a key exam in the admission
process for graduate business programs. Our analysis shows that most LLMs
outperform human candidates, with GPT-4 Turbo not only outperforming the other
models but also surpassing the average scores of graduate students at top
business schools. Through a case study, this research examines GPT-4 Turbo's
ability to explain answers, evaluate responses, identify errors, tailor
instructions, and generate alternative scenarios. The latest LLM versions,
GPT-4 Turbo, Claude 2.1, and Gemini 1.0 Pro, show marked improvements in
reasoning tasks compared to their predecessors, underscoring their potential
for complex problem-solving. While AI's promise in education, assessment, and
tutoring is clear, challenges remain. Our study not only sheds light on LLMs'
academic potential but also emphasizes the need for careful development and
application of AI in education. As AI technology advances, it is imperative to
establish frameworks and protocols for AI interaction, verify the accuracy of
AI-generated content, ensure worldwide access for diverse learners, and create
an educational environment where AI supports human expertise. This research
sets the stage for further exploration into the responsible use of AI to enrich
educational experiences and improve exam preparation and assessment methods.",2024-01-02,2024,2024-01,education
Mastery Guided Non-parametric Clustering to Scale-up Strategy Prediction,"Predicting the strategy (sequence of concepts) that a student is likely to
use in problem-solving helps Adaptive Instructional Systems (AISs) better adapt
themselves to different types of learners based on their learning abilities.
This can lead to a more dynamic, engaging, and personalized experience for
students. To scale up training a prediction model (such as LSTMs) over
large-scale education datasets, we develop a non-parametric approach to cluster
symmetric instances in the data. Specifically, we learn a representation based
on Node2Vec that encodes symmetries over mastery or skill level since, to solve
a problem, it is natural that a student's strategy is likely to involve
concepts in which they have gained mastery. Using this representation, we use
DP-Means to group symmetric instances through a coarse-to-fine refinement of
the clusters. We apply our model to learn strategies for Math learning from
large-scale datasets from MATHia, a leading AIS for middle-school math
learning. Our results illustrate that our approach can consistently achieve
high accuracy using a small sample that is representative of the full dataset.
Further, we show that this approach helps us learn strategies with high
accuracy for students at different skill levels, i.e., leveraging symmetries
improves fairness in the prediction model.",2024-01-04,2024,2024-01,education
"Build Your Own Robot Friend: An Open-Source Learning Module for
  Accessible and Engaging AI Education","As artificial intelligence (AI) is playing an increasingly important role in
our society and global economy, AI education and literacy have become necessary
components in college and K-12 education to prepare students for an AI-powered
society. However, current AI curricula have not yet been made accessible and
engaging enough for students and schools from all socio-economic backgrounds
with different educational goals. In this work, we developed an open-source
learning module for college and high school students, which allows students to
build their own robot companion from the ground up. This open platform can be
used to provide hands-on experience and introductory knowledge about various
aspects of AI, including robotics, machine learning (ML), software engineering,
and mechanical engineering. Because of the social and personal nature of a
socially assistive robot companion, this module also puts a special emphasis on
human-centered AI, enabling students to develop a better understanding of
human-AI interaction and AI ethics through hands-on learning activities. With
open-source documentation, assembling manuals and affordable materials,
students from different socio-economic backgrounds can personalize their
learning experience based on their individual educational goals. To evaluate
the student-perceived quality of our module, we conducted a usability testing
workshop with 15 college students recruited from a minority-serving
institution. Our results indicate that our AI module is effective,
easy-to-follow, and engaging, and it increases student interest in studying
AI/ML and robotics in the future. We hope that this work will contribute toward
accessible and engaging AI education in human-AI interaction for college and
high school students.",2024-01-06,2024,2024-01,education
"Assessing AI Detectors in Identifying AI-Generated Code: Implications
  for Education","Educators are increasingly concerned about the usage of Large Language Models
(LLMs) such as ChatGPT in programming education, particularly regarding the
potential exploitation of imperfections in Artificial Intelligence Generated
Content (AIGC) Detectors for academic misconduct. In this paper, we present an
empirical study where the LLM is examined for its attempts to bypass detection
by AIGC Detectors. This is achieved by generating code in response to a given
question using different variants. We collected a dataset comprising 5,069
samples, with each sample consisting of a textual description of a coding
problem and its corresponding human-written Python solution codes. These
samples were obtained from various sources, including 80 from Quescol, 3,264
from Kaggle, and 1,725 from LeetCode. From the dataset, we created 13 sets of
code problem variant prompts, which were used to instruct ChatGPT to generate
the outputs. Subsequently, we assessed the performance of five AIGC detectors.
Our results demonstrate that existing AIGC Detectors perform poorly in
distinguishing between human-written code and AI-generated code.",2024-01-08,2024,2024-01,education
Imagining Computing Education Assessment after Generative AI,"In the contemporary landscape of computing education, the ubiquity of
Generative Artificial Intelligence has significantly disrupted traditional
assessment methods, rendering them obsolete and prompting educators to seek
innovative alternatives. This research paper explores the challenges posed by
Generative AI in the assessment domain and the persistent attempts to
circumvent its impact. Despite various efforts to devise workarounds, the
academic community is yet to find a comprehensive solution. Amidst this
struggle, ungrading emerges as a potential yet under-appreciated solution to
the assessment dilemma. Ungrading, a pedagogical approach that involves moving
away from traditional grading systems, has faced resistance due to its
perceived complexity and the reluctance of educators to depart from
conventional assessment practices. However, as the inadequacies of current
assessment methods become increasingly evident in the face of Generative AI,
the time is ripe to reconsider and embrace ungrading.",2024-01-09,2024,2024-01,education
"CADgpt: Harnessing Natural Language Processing for 3D Modelling to
  Enhance Computer-Aided Design Workflows","This paper introduces CADgpt, an innovative plugin integrating Natural
Language Processing (NLP) with Rhino3D for enhancing 3D modelling in
computer-aided design (CAD) environments. Leveraging OpenAI's GPT-4, CADgpt
simplifies the CAD interface, enabling users, particularly beginners, to
perform complex 3D modelling tasks through intuitive natural language commands.
This approach significantly reduces the learning curve associated with
traditional CAD software, fostering a more inclusive and engaging educational
environment. The paper discusses CADgpt's technical architecture, including its
integration within Rhino3D and the adaptation of GPT-4 capabilities for CAD
tasks. It presents case studies demonstrating CADgpt's efficacy in various
design scenarios, highlighting its potential to democratise design education by
making sophisticated design tools accessible to a broader range of students.
The discussion further explores CADgpt's implications for pedagogy and
curriculum development, emphasising its role in enhancing creative exploration
and conceptual thinking in design education.
  Keywords: Natural Language Processing, Computer-Aided Design, 3D Modelling,
Design Automation, Design Education, Architectural Education",2024-01-10,2024,2024-01,education
"How Teachers Can Use Large Language Models and Bloom's Taxonomy to
  Create Educational Quizzes","Question generation (QG) is a natural language processing task with an
abundance of potential benefits and use cases in the educational domain. In
order for this potential to be realized, QG systems must be designed and
validated with pedagogical needs in mind. However, little research has assessed
or designed QG approaches with the input from real teachers or students. This
paper applies a large language model-based QG approach where questions are
generated with learning goals derived from Bloom's taxonomy. The automatically
generated questions are used in multiple experiments designed to assess how
teachers use them in practice. The results demonstrate that teachers prefer to
write quizzes with automatically generated questions, and that such quizzes
have no loss in quality compared to handwritten versions. Further, several
metrics indicate that automatically generated questions can even improve the
quality of the quizzes created, showing the promise for large scale use of QG
in the classroom setting.",2024-01-11,2024,2024-01,education
"Generative Artificial Intelligence in Higher Education: Evidence from an
  Analysis of Institutional Policies and Guidelines","The release of ChatGPT in November 2022 prompted a massive uptake of
generative artificial intelligence (GenAI) across higher education institutions
(HEIs). HEIs scrambled to respond to its use, especially by students, looking
first to regulate it and then arguing for its productive integration within
teaching and learning. In the year since the release, HEIs have increasingly
provided policies and guidelines to direct GenAI. In this paper we examined
documents produced by 116 US universities categorized as high research activity
or R1 institutions to comprehensively understand GenAI related advice and
guidance given to institutional stakeholders. Through an extensive analysis, we
found the majority of universities (N=73, 63%) encourage the use of GenAI and
many provide detailed guidance for its use in the classroom (N=48, 41%). More
than half of all institutions provided sample syllabi (N=65, 56%) and half
(N=58, 50%) provided sample GenAI curriculum and activities that would help
instructors integrate and leverage GenAI in their classroom. Notably, most
guidance for activities focused on writing, whereas code and STEM-related
activities were mentioned half the time and vaguely even when they were (N=58,
50%). Finally, more than one half of institutions talked about the ethics of
GenAI on a range of topics broadly, including Diversity, Equity and Inclusion
(DEI) (N=60, 52%). Overall, based on our findings we caution that guidance for
faculty can become burdensome as extensive revision of pedagogical approaches
is often recommended in the policies.",2024-01-12,2024,2024-01,education
"Determining the Difficulties of Students With Dyslexia via Virtual
  Reality and Artificial Intelligence: An Exploratory Analysis","Learning disorders are neurological conditions that affect the brain's
ability to interconnect communication areas. Dyslexic students experience
problems with reading, memorizing, and exposing concepts; however the magnitude
of these can be mitigated through both therapies and the creation of
compensatory mechanisms. Several efforts have been made to mitigate these
issues, leading to the creation of digital resources for students with specific
learning disorders attending primary and secondary education levels.
Conversely, a standard approach is still missed in higher education. The
VRAIlexia project has been created to tackle this issue by proposing two
different tools: a mobile application integrating virtual reality (VR) to
collect data quickly and easily, and an artificial intelligencebased software
(AI) to analyze the collected data for customizing the supporting methodology
for each student. The first one has been created and is being distributed among
dyslexic students in Higher Education Institutions, for the conduction of
specific psychological and psychometric tests. The second tool applies specific
artificial intelligence algorithms to the data gathered via the application and
other surveys. These AI techniques have allowed us to identify the most
relevant difficulties faced by the students' cohort. Our different models have
obtained around 90\% mean accuracy for predicting the support tools and
learning strategies.",2024-01-15,2024,2024-01,education
"Survey of Natural Language Processing for Education: Taxonomy,
  Systematic Review, and Future Trends","Natural Language Processing (NLP) aims to analyze text or speech via
techniques in the computer science field. It serves the applications in domains
of healthcare, commerce, education and so on. Particularly, NLP has been widely
applied to the education domain and its applications have enormous potential to
help teaching and learning. In this survey, we review recent advances in NLP
with the focus on solving problems relevant to the education domain. In detail,
we begin with introducing the related background and the real-world scenarios
in education where NLP techniques could contribute. Then, we present a taxonomy
of NLP in the education domain and highlight typical NLP applications including
question answering, question construction, automated assessment, and error
correction. Next, we illustrate the task definition, challenges, and
corresponding cutting-edge techniques based on the above taxonomy. In
particular, LLM-involved methods are included for discussion due to the wide
usage of LLMs in diverse NLP applications. After that, we showcase some
off-the-shelf demonstrations in this domain. At last, we conclude with six
promising directions for future research, including more datasets in education
domain, controllable usage of LLMs, intervention of difficulty-level control,
interpretable educational NLP, methods with adaptive learning, and integrated
systems for education. We organize all relevant datasets and papers in the
open-available Github Link for better
review~\url{https://github.com/LiXinyuan1015/NLP-for-Education}.",2024-01-15,2024,2024-01,education
"A Comprehensive Exploration of Personalized Learning in Smart Education:
  From Student Modeling to Personalized Recommendations","With the development of artificial intelligence, personalized learning has
attracted much attention as an integral part of intelligent education. China,
the United States, the European Union, and others have put forward the
importance of personalized learning in recent years, emphasizing the
realization of the organic combination of large-scale education and
personalized training. The development of a personalized learning system
oriented to learners' preferences and suited to learners' needs should be
accelerated. This review provides a comprehensive analysis of the current
situation of personalized learning and its key role in education. It discusses
the research on personalized learning from multiple perspectives, combining
definitions, goals, and related educational theories to provide an in-depth
understanding of personalized learning from an educational perspective,
analyzing the implications of different theories on personalized learning, and
highlighting the potential of personalized learning to meet the needs of
individuals and to enhance their abilities. Data applications and assessment
indicators in personalized learning are described in detail, providing a solid
data foundation and evaluation system for subsequent research. Meanwhile, we
start from both student modeling and recommendation algorithms and deeply
analyze the cognitive and non-cognitive perspectives and the contribution of
personalized recommendations to personalized learning. Finally, we explore the
challenges and future trajectories of personalized learning. This review
provides a multidimensional analysis of personalized learning through a more
comprehensive study, providing academics and practitioners with cutting-edge
explorations to promote continuous progress in the field of personalized
learning.",2024-01-15,2024,2024-01,education
"AI Thrust: Ranking Emerging Powers for Tech Startup Investment in Latin
  America","Artificial intelligence (AI) is rapidly transforming the global economy, and
Latin America is no exception. In recent years, there has been a growing
interest in AI development and implementation in the region. This paper
presents a ranking of Latin American (LATAM) countries based on their potential
to become emerging powers in AI. The ranking is based on three pillars:
infrastructure, education, and finance. Infrastructure is measured by the
availability of electricity, high-speed internet, the quality of
telecommunications networks, and the availability of supercomputers. Education
is measured by the quality of education and the research status. Finance is
measured by the cost of investments, history of investments, economic metrics,
and current implementation of AI.
  While Brazil, Chile, and Mexico have established themselves as major players
in the AI industry in Latin America, our ranking demonstrates the new emerging
powers in the region. According to the results, Argentina, Colombia, Uruguay,
Costa Rica, and Ecuador are leading as new emerging powers in AI in Latin
America. These countries have strong education systems, well-developed
infrastructure, and growing financial resources. The ranking provides a useful
tool for policymakers, investors, and businesses interested in AI development
in Latin America. It can help to identify emerging LATAM countries with the
greatest potential for AI growth and success.",2024-01-17,2024,2024-01,education
Prerequisite Structure Discovery in Intelligent Tutoring Systems,"This paper addresses the importance of Knowledge Structure (KS) and Knowledge
Tracing (KT) in improving the recommendation of educational content in
intelligent tutoring systems. The KS represents the relations between different
Knowledge Components (KCs), while KT predicts a learner's success based on her
past history. The contribution of this research includes proposing a KT model
that incorporates the KS as a learnable parameter, enabling the discovery of
the underlying KS from learner trajectories. The quality of the uncovered KS is
assessed by using it to recommend content and evaluating the recommendation
algorithm with simulated students.",2024-01-18,2024,2024-01,education
"Lessons Learned from Designing an Open-Source Automated Feedback System
  for STEM Education","As distance learning becomes increasingly important and artificial
intelligence tools continue to advance, automated systems for individual
learning have attracted significant attention. However, the scarcity of
open-source online tools that are capable of providing personalized feedback
has restricted the widespread implementation of research-based feedback
systems. In this work, we present RATsApp, an open-source automated feedback
system (AFS) that incorporates research-based features such as formative
feedback. The system focuses on core STEM competencies such as mathematical
competence, representational competence, and data literacy. It also allows
lecturers to monitor students' progress. We conducted a survey based on the
technology acceptance model (TAM2) among a set of students (N=64). Our findings
confirm the applicability of the TAM2 framework, revealing that factors such as
the relevance of the studies, output quality, and ease of use significantly
influence the perceived usefulness. We also found a linear relation between the
perceived usefulness and the intention to use, which in turn is a significant
predictor of the frequency of use. Moreover, the formative feedback feature of
RATsApp received positive feedback, indicating its potential as an educational
tool. Furthermore, as an open-source platform, RATsApp encourages public
contributions to its ongoing development, fostering a collaborative approach to
improve educational tools.",2024-01-19,2024,2024-01,education
"CodeAid: Evaluating a Classroom Deployment of an LLM-based Programming
  Assistant that Balances Student and Educator Needs","Timely, personalized feedback is essential for students learning programming.
LLM-powered tools like ChatGPT offer instant support, but reveal direct answers
with code, which may hinder deep conceptual engagement. We developed CodeAid,
an LLM-powered programming assistant delivering helpful, technically correct
responses, without revealing code solutions. CodeAid answers conceptual
questions, generates pseudo-code with line-by-line explanations, and annotates
student's incorrect code with fix suggestions. We deployed CodeAid in a
programming class of 700 students for a 12-week semester. A thematic analysis
of 8,000 usages of CodeAid was performed, further enriched by weekly surveys,
and 22 student interviews. We then interviewed eight programming educators to
gain further insights. Our findings reveal four design considerations for
future educational AI assistants: D1) exploiting AI's unique benefits; D2)
simplifying query formulation while promoting cognitive engagement; D3)
avoiding direct responses while encouraging motivated learning; and D4)
maintaining transparency and control for students to asses and steer AI
responses.",2024-01-20,2024,2024-01,education
"Applications, challenges and ethical issues of AI and ChatGPT in
  education","Artificial Intelligence (AI) in recent years has shown an unprecedentedly
impressive development, tending to play a catalytic role in all aspects of
life. The interest of the academic community, but also of governments, is huge
in the dynamics of AI and is reflected by the truly explosive amount of
investment and research that is underway. Enthusiastic opinions and statements
about AI are made every day, but at the same time they also bring to the fore
alarming predictions about its effects. This paper aims to describe the
opportunities emerging from the use of artificial intelligence and ChatGPT to
improve education, but also to identify the challenges and ethical issues that
arise.",2024-01-22,2024,2024-01,education
"Using Java Geometry Expert as Guide in the Preparations for Math
  Contests","We give an insight into Java Geometry Expert (JGEX) in use in a school
context, focusing on the Austrian school system. JGEX can offer great support
in some classroom situations, especially for solving mathematical competition
tasks. Also, we discuss some limitations of the program.",2024-01-22,2024,2024-01,education
"Solving Some Geometry Problems of the N√°boj 2023 Contest with
  Automated Deduction in GeoGebra Discovery","In this article, we solve some of the geometry problems of the N\'aboj 2023
competition with the help of a computer, using examples that the software tool
GeoGebra Discovery can calculate. In each case, the calculation requires
symbolic computations. We analyze the difficulty of feeding the problem into
the machine and set further goals to make the problems of this type of contests
even more tractable in the future.",2024-01-22,2024,2024-01,education
"Health Text Simplification: An Annotated Corpus for Digestive Cancer
  Education and Novel Strategies for Reinforcement Learning","Objective: The reading level of health educational materials significantly
influences the understandability and accessibility of the information,
particularly for minoritized populations. Many patient educational resources
surpass the reading level and complexity of widely accepted standards. There is
a critical need for high-performing text simplification models in health
information to enhance dissemination and literacy. This need is particularly
acute in cancer education, where effective prevention and screening education
can substantially reduce morbidity and mortality.
  Methods: We introduce Simplified Digestive Cancer (SimpleDC), a parallel
corpus of cancer education materials tailored for health text simplification
research, comprising educational content from the American Cancer Society,
Centers for Disease Control and Prevention, and National Cancer Institute.
Utilizing SimpleDC alongside the existing Med-EASi corpus, we explore Large
Language Model (LLM)-based simplification methods, including fine-tuning,
reinforcement learning (RL), reinforcement learning with human feedback (RLHF),
domain adaptation, and prompt-based approaches. Our experimentation encompasses
Llama 2 and GPT-4. A novel RLHF reward function is introduced, featuring a
lightweight model adept at distinguishing between original and simplified
texts, thereby enhancing the model's effectiveness with unlabeled data.
  Results: Fine-tuned Llama 2 models demonstrated high performance across
various metrics. Our innovative RLHF reward function surpassed existing RL text
simplification reward functions in effectiveness. The results underscore that
RL/RLHF can augment fine-tuning, facilitating model training on unlabeled text
and improving performance.",2024-01-26,2024,2024-01,education
"Charting the Future of AI in Project-Based Learning: A Co-Design
  Exploration with Students","The increasing use of Artificial Intelligence (AI) by students in learning
presents new challenges for assessing their learning outcomes in project-based
learning (PBL). This paper introduces a co-design study to explore the
potential of students' AI usage data as a novel material for PBL assessment. We
conducted workshops with 18 college students, encouraging them to speculate an
alternative world where they could freely employ AI in PBL while needing to
report this process to assess their skills and contributions. Our workshops
yielded various scenarios of students' use of AI in PBL and ways of analyzing
these uses grounded by students' vision of education goal transformation. We
also found students with different attitudes toward AI exhibited distinct
preferences in how to analyze and understand the use of AI. Based on these
findings, we discuss future research opportunities on student-AI interactions
and understanding AI-enhanced learning.",2024-01-26,2024,2024-01,education
"Experimental Interface for Multimodal and Large Language Model Based
  Explanations of Educational Recommender Systems","In the age of artificial intelligence (AI), providing learners with suitable
and sufficient explanations of AI-based recommendation algorithm's output
becomes essential to enable them to make an informed decision about it.
However, the rapid development of AI approaches for educational recommendations
and their explainability is not accompanied by an equal level of evidence-based
experimentation to evaluate the learning effect of those explanations. To
address this issue, we propose an experimental web-based tool for evaluating
multimodal and large language model (LLM) based explainability approaches. Our
tool provides a comprehensive set of modular, interactive, and customizable
explainability elements, which researchers and educators can utilize to study
the role of individual and hybrid explainability methods. We design a two-stage
evaluation of the proposed tool, with learners and with educators. Our
preliminary results from the first stage show high acceptance of the tool's
components, user-friendliness, and an induced motivation to use the
explanations for exploring more information about the recommendation.",2024-01-29,2024,2024-01,education
"Identifying Student Profiles Within Online Judge Systems Using
  Explainable Artificial Intelligence","Online Judge (OJ) systems are typically considered within programming-related
courses as they yield fast and objective assessments of the code developed by
the students. Such an evaluation generally provides a single decision based on
a rubric, most commonly whether the submission successfully accomplished the
assignment. Nevertheless, since in an educational context such information may
be deemed insufficient, it would be beneficial for both the student and the
instructor to receive additional feedback about the overall development of the
task. This work aims to tackle this limitation by considering the further
exploitation of the information gathered by the OJ and automatically inferring
feedback for both the student and the instructor. More precisely, we consider
the use of learning-based schemes -- particularly, multi-instance learning
(MIL) and classical machine learning formulations -- to model student behavior.
Besides, explainable artificial intelligence (XAI) is contemplated to provide
human-understandable feedback. The proposal has been evaluated considering a
case of study comprising 2500 submissions from roughly 90 different students
from a programming-related course in a computer science degree. The results
obtained validate the proposal: The model is capable of significantly
predicting the user outcome (either passing or failing the assignment) solely
based on the behavioral pattern inferred by the submissions provided to the OJ.
Moreover, the proposal is able to identify prone-to-fail student groups and
profiles as well as other relevant information, which eventually serves as
feedback to both the student and the instructor.",2024-01-29,2024,2024-01,education
"Integrating Generative AI in Hackathons: Opportunities, Challenges, and
  Educational Implications","Hackathons have emerged as pivotal platforms in the software industry,
driving both innovation and skill development for organizations and students
alike. These events enable companies to quickly prototype new ideas while
offering students practical, hands-on learning experiences. Over time,
hackathons have transitioned from purely competitive events to valuable
educational tools, integrating theory with real-world problem-solving through
collaboration between academia and industry. The infusion of artificial
intelligence (AI) and machine learning is now reshaping hackathons, providing
enhanced learning opportunities while also introducing ethical challenges. This
study explores the influence of generative AI on students' technological
choices, focusing on a case study from the 2023 University of Iowa Hackathon.
The findings offer insights into AI's role in these events, its educational
impact, and propose strategies for integrating such technologies in future
hackathons, ensuring a balance between innovation, ethics, and educational
value.",2024-01-30,2024,2024-01,education
"QACP: An Annotated Question Answering Dataset for Assisting Chinese
  Python Programming Learners","In online learning platforms, particularly in rapidly growing computer
programming courses, addressing the thousands of students' learning queries
requires considerable human cost. The creation of intelligent assistant large
language models (LLMs) tailored for programming education necessitates distinct
data support. However, in real application scenarios, the data resources for
training such LLMs are relatively scarce. Therefore, to address the data
scarcity in intelligent educational systems for programming, this paper
proposes a new Chinese question-and-answer dataset for Python learners. To
ensure the authenticity and reliability of the sources of the questions, we
collected questions from actual student questions and categorized them
according to various dimensions such as the type of questions and the type of
learners. This annotation principle is designed to enhance the effectiveness
and quality of online programming education, providing a solid data foundation
for developing the programming teaching assists (TA). Furthermore, we conducted
comprehensive evaluations of various LLMs proficient in processing and
generating Chinese content, highlighting the potential limitations of general
LLMs as intelligent teaching assistants in computer programming courses.",2024-01-30,2024,2024-01,education
"Trust and ethical considerations in a multi-modal, explainable AI-driven
  chatbot tutoring system: The case of collaboratively solving Rubik's Cube","Artificial intelligence (AI) has the potential to transform education with
its power of uncovering insights from massive data about student learning
patterns. However, ethical and trustworthy concerns of AI have been raised but
are unsolved. Prominent ethical issues in high school AI education include data
privacy, information leakage, abusive language, and fairness. This paper
describes technological components that were built to address ethical and
trustworthy concerns in a multi-modal collaborative platform (called ALLURE
chatbot) for high school students to collaborate with AI to solve the Rubik's
cube. In data privacy, we want to ensure that the informed consent of children,
parents, and teachers, is at the center of any data that is managed. Since
children are involved, language, whether textual, audio, or visual, is
acceptable both from users and AI and the system can steer interaction away
from dangerous situations. In information management, we also want to ensure
that the system, while learning to improve over time, does not leak information
about users from one group to another.",2024-01-30,2024,2024-01,education
"Generative AI for Education (GAIED): Advances, Opportunities, and
  Challenges","This survey article has grown out of the GAIED (pronounced ""guide"") workshop
organized by the authors at the NeurIPS 2023 conference. We organized the GAIED
workshop as part of a community-building effort to bring together researchers,
educators, and practitioners to explore the potential of generative AI for
enhancing education. This article aims to provide an overview of the workshop
activities and highlight several future research directions in the area of
GAIED.",2024-02-02,2024,2024-02,education
Bringing Generative AI to Adaptive Learning in Education,"The recent surge in generative AI technologies, such as large language models
and diffusion models, has boosted the development of AI applications in various
domains, including science, finance, and education. Concurrently, adaptive
learning, a concept that has gained substantial interest in the educational
sphere, has proven its efficacy in enhancing students' learning efficiency. In
this position paper, we aim to shed light on the intersectional studies of
these two methods, which combine generative AI with adaptive learning concepts.
By presenting discussions about the benefits, challenges, and potentials in
this field, we argue that this union will contribute significantly to the
development of the next-stage learning format in education.",2024-02-02,2024,2024-02,education
Evaluating Large Language Models in Analysing Classroom Dialogue,"This study explores the application of Large Language Models (LLMs),
specifically GPT-4, in the analysis of classroom dialogue, a crucial research
task for both teaching diagnosis and quality improvement. Recognizing the
knowledge-intensive and labor-intensive nature of traditional qualitative
methods in educational research, this study investigates the potential of LLM
to streamline and enhance the analysis process. The study involves datasets
from a middle school, encompassing classroom dialogues across mathematics and
Chinese classes. These dialogues were manually coded by educational experts and
then analyzed using a customised GPT-4 model. This study focuses on comparing
manual annotations with the outputs of GPT-4 to evaluate its efficacy in
analyzing educational dialogues. Time efficiency, inter-coder agreement, and
inter-coder reliability between human coders and GPT-4 are evaluated. Results
indicate substantial time savings with GPT-4, and a high degree of consistency
in coding between the model and human coders, with some discrepancies in
specific codes. These findings highlight the strong potential of LLM in
teaching evaluation and facilitation.",2024-02-04,2024,2024-02,education
"From Algorithm Worship to the Art of Human Learning: Insights from
  50-year journey of AI in Education","Current discourse surrounding Artificial Intelligence (AI) oscillates between
hope and apprehension, painting a future where AI reshapes every facet of human
life, including Education. This paper delves into the complexities of AI's role
in Education, addressing the mixed messages that have both enthused and alarmed
educators, policymakers, and the public. It explores the promises that AI holds
for enhancing learning through personalisation at scale, against the backdrop
of concerns about ethical implications, the devaluation of non-STEM subjects,
and the potential transformative impact on our neurocognitive and
socio-emotional functioning. Drawing on recent research and global discourse,
the paper seeks to unpack the reasons behind the vagueness of current
discussions on AI in Education (AIED) and the implications of this ambiguity
for future educational practices and policies. By highlighting insights from
educational research and synthesising evidence-based best practices in AIED,
the aim is to provide a clearer understanding of how AI technologies can be
aligned with the fundamental principles of learning and teaching, and explore
what concrete actions may need to be prioritised now to truly enhance learning
experiences and outcomes for all in the future.",2024-02-05,2024,2024-02,education
"Enhancing textual textbook question answering with large language models
  and retrieval augmented generation","Textbook question answering (TQA) is a challenging task in artificial
intelligence due to the complex nature of context needed to answer complex
questions. Although previous research has improved the task, there are still
some limitations in textual TQA, including weak reasoning and inability to
capture contextual information in the lengthy context. We propose a framework
(PLRTQA) that incorporates the retrieval augmented generation (RAG) technique
to handle the out-of-domain scenario where concepts are spread across different
lessons, and utilize transfer learning to handle the long context and enhance
reasoning abilities. Our architecture outperforms the baseline, achieving an
accuracy improvement of 4. 12% in the validation set and 9. 84% in the test set
for textual multiple-choice questions. While this paper focuses on solving
challenges in the textual TQA, It provides a foundation for future work in
multimodal TQA where the visual components are integrated to address more
complex educational scenarios. Code: https://github.com/hessaAlawwad/PLR-TQA",2024-02-05,2024,2024-02,education
Edu-ConvoKit: An Open-Source Library for Education Conversation Data,"We introduce Edu-ConvoKit, an open-source library designed to handle
pre-processing, annotation and analysis of conversation data in education.
Resources for analyzing education conversation data are scarce, making the
research challenging to perform and therefore hard to access. We address these
challenges with Edu-ConvoKit. Edu-ConvoKit is open-source
(https://github.com/stanfordnlp/edu-convokit ), pip-installable
(https://pypi.org/project/edu-convokit/ ), with comprehensive documentation
(https://edu-convokit.readthedocs.io/en/latest/ ). Our demo video is available
at: https://youtu.be/zdcI839vAko?si=h9qlnl76ucSuXb8- . We include additional
resources, such as Colab applications of Edu-ConvoKit to three diverse
education datasets and a repository of Edu-ConvoKit related papers, that can be
found in our GitHub repository.",2024-02-07,2024,2024-02,education
"Scaling Artificial Intelligence for Digital Wargaming in Support of
  Decision-Making","In this unprecedented era of technology-driven transformation, it becomes
more critical than ever that we aggressively invest in developing robust
artificial intelligence (AI) for wargaming in support of decision-making. By
advancing AI-enabled systems and pairing these with human judgment, we will be
able to enhance all-domain awareness, improve the speed and quality of our
decision cycles, offer recommendations for novel courses of action, and more
rapidly counter our adversary's actions. It therefore becomes imperative that
we accelerate the development of AI to help us better address the complexity of
modern challenges and dilemmas that currently requires human intelligence and,
if possible, attempt to surpass human intelligence--not to replace humans, but
to augment and better inform human decision-making at machine speed. Although
deep reinforcement learning continues to show promising results in intelligent
agent behavior development for the long-horizon, complex tasks typically found
in combat modeling and simulation, further research is needed to enable the
scaling of AI to deal with these intricate and expansive state-spaces
characteristic of wargaming for either concept development, education, or
analysis. To help address this challenge, in our research, we are developing
and implementing a hierarchical reinforcement learning framework that includes
a multi-model approach and dimension-invariant observation abstractions.",2024-02-08,2024,2024-02,education
LLMs for Coding and Robotics Education,"Large language models and multimodal large language models have
revolutionized artificial intelligence recently. An increasing number of
regions are now embracing these advanced technologies. Within this context,
robot coding education is garnering increasing attention. To teach young
children how to code and compete in robot challenges, large language models are
being utilized for robot code explanation, generation, and modification. In
this paper, we highlight an important trend in robot coding education. We test
several mainstream large language models on both traditional coding tasks and
the more challenging task of robot code generation, which includes block
diagrams. Our results show that GPT-4V outperforms other models in all of our
tests but struggles with generating block diagram images.",2024-02-09,2024,2024-02,education
"LLaVA-Docent: Instruction Tuning with Multimodal Large Language Model to
  Support Art Appreciation Education","Despite the development of various AI systems to support learning in various
domains, AI assistance for art appreciation education has not been extensively
explored. Art appreciation, often perceived as an unfamiliar and challenging
endeavor for most students, can be more accessible with a generative AI enabled
conversation partner that provides tailored questions and encourages the
audience to deeply appreciate artwork. This study explores the application of
multimodal large language models (MLLMs) in art appreciation education, with a
focus on developing LLaVA-Docent, a model designed to serve as a personal tutor
for art appreciation. Our approach involved design and development research,
focusing on iterative enhancement to design and develop the application to
produce a functional MLLM-enabled chatbot along with a data design framework
for art appreciation education. To that end, we established a virtual dialogue
dataset that was generated by GPT-4, which was instrumental in training our
MLLM, LLaVA-Docent. The performance of LLaVA-Docent was evaluated by
benchmarking it against alternative settings and revealed its distinct
strengths and weaknesses. Our findings highlight the efficacy of the MMLM-based
personalized art appreciation chatbot and demonstrate its applicability for a
novel approach in which art appreciation is taught and experienced.",2024-02-09,2024,2024-02,education
Educational data mining and learning analytics: An updated survey,"This survey is an updated and improved version of the previous one published
in 2013 in this journal with the title data mining in education. It reviews in
a comprehensible and very general way how Educational Data Mining and Learning
Analytics have been applied over educational data. In the last decade, this
research area has evolved enormously and a wide range of related terms are now
used in the bibliography such as Academic Analytics, Institutional Analytics,
Teaching Analytics, Data-Driven Education, Data-Driven Decision-Making in
Education, Big Data in Education, and Educational Data Science. This paper
provides the current state of the art by reviewing the main publications, the
key milestones, the knowledge discovery cycle, the main educational
environments, the specific tools, the free available datasets, the most used
methods, the main objectives, and the future trends in this research area.",2024-02-10,2024,2024-02,education
Tailoring Education with GenAI: A New Horizon in Lesson Planning,"The advent of Generative AI (GenAI) in education presents a transformative
approach to traditional teaching methodologies, which often overlook the
diverse needs of individual students. This study introduces a GenAI tool, based
on advanced natural language processing, designed as a digital assistant for
educators, enabling the creation of customized lesson plans. The tool utilizes
an innovative feature termed 'interactive mega-prompt,' a comprehensive query
system that allows educators to input detailed classroom specifics such as
student demographics, learning objectives, and preferred teaching styles. This
input is then processed by the GenAI to generate tailored lesson plans. To
evaluate the tool's effectiveness, a comprehensive methodology incorporating
both quantitative (i.e., % of time savings) and qualitative (i.e., user
satisfaction) criteria was implemented, spanning various subjects and
educational levels, with continuous feedback collected from educators through a
structured evaluation form. Preliminary results show that educators find the
GenAI-generated lesson plans effective, significantly reducing lesson planning
time and enhancing the learning experience by accommodating diverse student
needs. This AI-driven approach signifies a paradigm shift in education,
suggesting its potential applicability in broader educational contexts,
including special education needs (SEN), where individualized attention and
specific learning aids are paramount",2024-02-12,2024,2024-02,education
"Leveraging AI to Advance Science and Computing Education across Africa:
  Challenges, Progress and Opportunities","Across the African continent, students grapple with various educational
challenges, including limited access to essential resources such as computers,
internet connectivity, reliable electricity, and a shortage of qualified
teachers. Despite these challenges, recent advances in AI such as BERT, and
GPT-4 have demonstrated their potential for advancing education. Yet, these AI
tools tend to be deployed and evaluated predominantly within the context of
Western educational settings, with limited attention directed towards the
unique needs and challenges faced by students in Africa. In this chapter, we
discuss challenges with using AI to advance education across Africa. Then, we
describe our work developing and deploying AI in Education tools in Africa for
science and computing education: (1) SuaCode, an AI-powered app that enables
Africans to learn to code using their smartphones, (2) AutoGrad, an automated
grading, and feedback tool for graphical and interactive coding assignments,
(3) a tool for code plagiarism detection that shows visual evidence of
plagiarism, (4) Kwame, a bilingual AI teaching assistant for coding courses,
(5) Kwame for Science, a web-based AI teaching assistant that provides instant
answers to students' science questions and (6) Brilla AI, an AI contestant for
the National Science and Maths Quiz competition. Finally, we discuss potential
opportunities to leverage AI to advance education across Africa.",2024-02-12,2024,2024-02,education
"Artificial intelligence and the transformation of higher education
  institutions","Artificial intelligence (AI) advances and the rapid adoption of generative AI
tools like ChatGPT present new opportunities and challenges for higher
education. While substantial literature discusses AI in higher education, there
is a lack of a systemic approach that captures a holistic view of the AI
transformation of higher education institutions (HEIs). To fill this gap, this
article, taking a complex systems approach, develops a causal loop diagram
(CLD) to map the causal feedback mechanisms of AI transformation in a typical
HEI. Our model accounts for the forces that drive the AI transformation and the
consequences of the AI transformation on value creation in a typical HEI. The
article identifies and analyzes several reinforcing and balancing feedback
loops, showing how, motivated by AI technology advances, the HEI invests in AI
to improve student learning, research, and administration. The HEI must take
measures to deal with academic integrity problems and adapt to changes in
available jobs due to AI, emphasizing AI-complementary skills for its students.
However, HEIs face a competitive threat and several policy traps that may lead
to decline. HEI leaders need to become systems thinkers to manage the
complexity of the AI transformation and benefit from the AI feedback loops
while avoiding the associated pitfalls. We also discuss long-term scenarios,
the notion of HEIs influencing the direction of AI, and directions for future
research on AI transformation.",2024-02-13,2024,2024-02,education
"I would love this to be like an assistant, not the teacher: a voice of
  the customer perspective of what distance learning students want from an
  Artificial Intelligence Digital Assistant","With the release of Generative AI systems such as ChatGPT, an increasing
interest in using Artificial Intelligence (AI) has been observed across
domains, including higher education. While emerging statistics show the
popularity of using AI amongst undergraduate students, little is yet known
about students' perceptions regarding AI including self-reported benefits and
concerns from their actual usage, in particular in distance learning contexts.
Using a two-step, mixed-methods approach, we examined the perceptions of ten
online and distance learning students from diverse disciplines regarding the
design of a hypothetical AI Digital Assistant (AIDA). In the first step, we
captured students' perceptions via interviews, while the second step supported
the triangulation of data by enabling students to share, compare, and contrast
perceptions with those of peers. All participants agreed on the usefulness of
such an AI tool while studying and reported benefits from using it for
real-time assistance and query resolution, support for academic tasks,
personalisation and accessibility, together with emotional and social support.
Students' concerns related to the ethical and social implications of
implementing AIDA, data privacy and data use, operational challenges, academic
integrity and misuse, and the future of education. Implications for the design
of AI-tailored systems are also discussed.",2024-02-16,2024,2024-02,education
"Enhancing Surgical Performance in Cardiothoracic Surgery with
  Innovations from Computer Vision and Artificial Intelligence: A Narrative
  Review","When technical requirements are high, and patient outcomes are critical,
opportunities for monitoring and improving surgical skills via objective motion
analysis feedback may be particularly beneficial. This narrative review
synthesises work on technical and non-technical surgical skills, collaborative
task performance, and pose estimation to illustrate new opportunities to
advance cardiothoracic surgical performance with innovations from computer
vision and artificial intelligence. These technological innovations are
critically evaluated in terms of the benefits they could offer the
cardiothoracic surgical community, and any barriers to the uptake of the
technology are elaborated upon. Like some other specialities, cardiothoracic
surgery has relatively few opportunities to benefit from tools with data
capture technology embedded within them (as with robotic-assisted laparoscopic
surgery, for example). In such cases, pose estimation techniques that allow for
movement tracking across a conventional operating field without using
specialist equipment or markers offer considerable potential. With video data
from either simulated or real surgical procedures, these tools can (1) provide
insight into the development of expertise and surgical performance over a
surgeon's career, (2) provide feedback to trainee surgeons regarding areas for
improvement, (3) provide the opportunity to investigate what aspects of skill
may be linked to patient outcomes which can (4) inform the aspects of surgical
skill which should be focused on within training or mentoring programmes.
Classifier or assessment algorithms that use artificial intelligence to 'learn'
what expertise is from expert surgical evaluators could further assist
educators in determining if trainees meet competency thresholds.",2024-02-17,2024,2024-02,education
"From Cloud to Edge: Rethinking Generative AI for Low-Resource Design
  Challenges","Generative Artificial Intelligence (AI) has shown tremendous prospects in all
aspects of technology, including design. However, due to its heavy demand on
resources, it is usually trained on large computing infrastructure and often
made available as a cloud-based service. In this position paper, we consider
the potential, challenges, and promising approaches for generative AI for
design on the edge, i.e., in resource-constrained settings where memory,
compute, energy (battery) and network connectivity may be limited. Adapting
generative AI for such settings involves overcoming significant hurdles,
primarily in how to streamline complex models to function efficiently in
low-resource environments. This necessitates innovative approaches in model
compression, efficient algorithmic design, and perhaps even leveraging edge
computing. The objective is to harness the power of generative AI in creating
bespoke solutions for design problems, such as medical interventions, farm
equipment maintenance, and educational material design, tailored to the unique
constraints and needs of remote areas. These efforts could democratize access
to advanced technology and foster sustainable development, ensuring universal
accessibility and environmental consideration of AI-driven design benefits.",2024-02-20,2024,2024-02,education
DREsS: Dataset for Rubric-based Essay Scoring on EFL Writing,"Automated essay scoring (AES) is a useful tool in English as a Foreign
Language (EFL) writing education, offering real-time essay scores for students
and instructors. However, previous AES models were trained on essays and scores
irrelevant to the practical scenarios of EFL writing education and usually
provided a single holistic score due to the lack of appropriate datasets. In
this paper, we release DREsS, a large-scale, standard dataset for rubric-based
automated essay scoring. DREsS comprises three sub-datasets: DREsS_New,
DREsS_Std., and DREsS_CASE. We collect DREsS_New, a real-classroom dataset with
2.3K essays authored by EFL undergraduate students and scored by English
education experts. We also standardize existing rubric-based essay scoring
datasets as DREsS_Std. We suggest CASE, a corruption-based augmentation
strategy for essays, which generates 40.1K synthetic samples of DREsS_CASE and
improves the baseline results by 45.44%. DREsS will enable further research to
provide a more accurate and practical AES system for EFL writing education.",2024-02-21,2024,2024-02,education
"Multi-stakeholder Perspective on Responsible Artificial Intelligence and
  Acceptability in Education","This study investigates the acceptability of different artificial
intelligence (AI) applications in education from a multi-stakeholder
perspective, including students, teachers, and parents. Acknowledging the
transformative potential of AI in education, it addresses concerns related to
data privacy, AI agency, transparency, explainability and the ethical
deployment of AI. Through a vignette methodology, participants were presented
with four scenarios where AI's agency, transparency, explainability, and
privacy were manipulated. After each scenario, participants completed a survey
that captured their perceptions of AI's global utility, individual usefulness,
justice, confidence, risk, and intention to use each scenario's AI if
available. The data collection comprising a final sample of 1198
multi-stakeholder participants was distributed through a partner institution
and social media campaigns and focused on individual responses to four AI use
cases. A mediation analysis of the data indicated that acceptance and trust in
AI varies significantly across stakeholder groups. We found that the key
mediators between high and low levels of AI's agency, transparency, and
explainability, as well as the intention to use the different educational AI,
included perceived global utility, justice, and confidence. The study
highlights that the acceptance of AI in education is a nuanced and multifaceted
issue that requires careful consideration of specific AI applications and their
characteristics, in addition to the diverse stakeholders' perceptions.",2024-02-22,2024,2024-02,education
"Economic and Financial Learning with Artificial Intelligence: A
  Mixed-Methods Study on ChatGPT","In the evolving landscape of digital education, chatbots have emerged as
potential game-changers, promising personalized and adaptive learning
experiences. This research undertook an in-depth exploration of ChatGPT's
potential as an educational tool, focusing on user perceptions, experiences and
learning outcomes. Through a mixed-methods approach, a diverse group of 102
participants engaged with ChatGPT, providing insights pre- and postinteraction.
The study reveals a notable positive shift in perceptions after exposure,
underscoring the efficacy of ChatGPT. However, challenges such as prompting
effectiveness and information accuracy emerged as pivotal concerns. Introducing
the concept of 'AI-learning-competence', this study lays the groundwork for
future research, emphasizing the need for formal training and pedagogical
integration of AI tools.",2024-02-23,2024,2024-02,education
"ChatGPT in Veterinary Medicine: A Practical Guidance of Generative
  Artificial Intelligence in Clinics, Education, and Research","ChatGPT, the most accessible generative artificial intelligence (AI) tool,
offers considerable potential for veterinary medicine, yet a dedicated review
of its specific applications is lacking. This review concisely synthesizes the
latest research and practical applications of ChatGPT within the clinical,
educational, and research domains of veterinary medicine. It intends to provide
specific guidance and actionable examples of how generative AI can be directly
utilized by veterinary professionals without a programming background. For
practitioners, ChatGPT can extract patient data, generate progress notes, and
potentially assist in diagnosing complex cases. Veterinary educators can create
custom GPTs for student support, while students can utilize ChatGPT for exam
preparation. ChatGPT can aid in academic writing tasks in research, but
veterinary publishers have set specific requirements for authors to follow.
Despite its transformative potential, careful use is essential to avoid
pitfalls like hallucination. This review addresses ethical considerations,
provides learning resources, and offers tangible examples to guide responsible
implementation. Carefully selected, up-to-date links to platforms that host
large language models are provided for advanced readers with programming
capability. A table of key takeaways was provided to summarize this review. By
highlighting potential benefits and limitations, this review equips
veterinarians, educators, and researchers to harness the power of ChatGPT
effectively.",2024-02-26,2024,2024-02,education
"A Review of Data Mining in Personalized Education: Current Trends and
  Future Prospects","Personalized education, tailored to individual student needs, leverages
educational technology and artificial intelligence (AI) in the digital age to
enhance learning effectiveness. The integration of AI in educational platforms
provides insights into academic performance, learning preferences, and
behaviors, optimizing the personal learning process. Driven by data mining
techniques, it not only benefits students but also provides educators and
institutions with tools to craft customized learning experiences. To offer a
comprehensive review of recent advancements in personalized educational data
mining, this paper focuses on four primary scenarios: educational
recommendation, cognitive diagnosis, knowledge tracing, and learning analysis.
This paper presents a structured taxonomy for each area, compiles commonly used
datasets, and identifies future research directions, emphasizing the role of
data mining in enhancing personalized education and paving the way for future
exploration and innovation.",2024-02-27,2024,2024-02,education
"Improving the Validity of Automatically Generated Feedback via
  Reinforcement Learning","Automatically generating feedback via large language models (LLMs) in
intelligent tutoring systems and online learning platforms has the potential to
improve the learning outcomes of many students. However, both feedback
generation and evaluation are challenging: feedback content has to be valid
especially in subjects like math, which requires models to understand the
problem, the solution, and where the student's error lies. Feedback also has to
be pedagogically valid to reflect effective tutoring strategies, such as
explaining possible misconceptions and encouraging the student, among other
desirable features. In this work, we address both problems of automatically
generating and evaluating feedback while considering both correctness and
alignment. First, we propose a rubric for evaluating math feedback and show
that GPT-4 is able to effectively use it to annotate human-written and
LLM-generated feedback. Second, we propose a framework for feedback generation
that optimizes both correctness and alignment using reinforcement learning
(RL). Specifically, we use GPT-4's annotations to create preferences over
feedback pairs in an augmented dataset for training via direct preference
optimization (DPO). We show that our methods significantly increase the
correctness and alignment of generated feedback with Llama 2, an open-source
LLM, qualitatively analyze our generation and evaluation systems using case
studies, and outline several areas for future work.",2024-03-02,2024,2024-03,education
"Evaluating and Optimizing Educational Content with Large Language Model
  Judgments","Creating effective educational materials generally requires expensive and
time-consuming studies of student learning outcomes. To overcome this barrier,
one idea is to build computational models of student learning and use them to
optimize instructional materials. However, it is difficult to model the
cognitive processes of learning dynamics. We propose an alternative approach
that uses Language Models (LMs) as educational experts to assess the impact of
various instructions on learning outcomes. Specifically, we use GPT-3.5 to
evaluate the overall effect of instructional materials on different student
groups and find that it can replicate well-established educational findings
such as the Expertise Reversal Effect and the Variability Effect. This
demonstrates the potential of LMs as reliable evaluators of educational
content. Building on this insight, we introduce an instruction optimization
approach in which one LM generates instructional materials using the judgments
of another LM as a reward function. We apply this approach to create math word
problem worksheets aimed at maximizing student learning gains. Human teachers'
evaluations of these LM-generated worksheets show a significant alignment
between the LM judgments and human teacher preferences. We conclude by
discussing potential divergences between human and LM opinions and the
resulting pitfalls of automating instructional design.",2024-03-05,2024,2024-03,education
"Enhancing Instructional Quality: Leveraging Computer-Assisted Textual
  Analysis to Generate In-Depth Insights from Educational Artifacts","This paper explores the transformative potential of computer-assisted textual
analysis in enhancing instructional quality through in-depth insights from
educational artifacts. We integrate Richard Elmore's Instructional Core
Framework to examine how artificial intelligence (AI) and machine learning (ML)
methods, particularly natural language processing (NLP), can analyze
educational content, teacher discourse, and student responses to foster
instructional improvement. Through a comprehensive review and case studies
within the Instructional Core Framework, we identify key areas where AI/ML
integration offers significant advantages, including teacher coaching, student
support, and content development. We unveil patterns that indicate AI/ML not
only streamlines administrative tasks but also introduces novel pathways for
personalized learning, providing actionable feedback for educators and
contributing to a richer understanding of instructional dynamics. This paper
emphasizes the importance of aligning AI/ML technologies with pedagogical goals
to realize their full potential in educational settings, advocating for a
balanced approach that considers ethical considerations, data quality, and the
integration of human expertise.",2024-03-06,2024,2024-03,education
"Legally Binding but Unfair? Towards Assessing Fairness of Privacy
  Policies","Privacy policies are expected to inform data subjects about their data
protection rights and should explain the data controller's data management
practices. Privacy policies only fulfill their purpose, if they are correctly
interpreted, understood, and trusted by the data subject. This implies that a
privacy policy is written in a fair way, e.g., it does not use polarizing
terms, does not require a certain education, or does not assume a particular
social background. We outline our approach to assessing fairness in privacy
policies. We identify from fundamental legal sources and fairness research, how
the dimensions informational fairness, representational fairness and ethics /
morality are related to privacy policies. We propose options to automatically
assess policies in these fairness dimensions, based on text statistics,
linguistic methods and artificial intelligence. We conduct initial experiments
with German privacy policies to provide evidence that our approach is
applicable. Our experiments indicate that there are issues in all three
dimensions of fairness. This is important, as future privacy policies may be
used in a corpus for legal artificial intelligence models.",2024-03-12,2024,2024-03,education
A Survey of Explainable Knowledge Tracing,"With the long term accumulation of high quality educational data, artificial
intelligence has shown excellent performance in knowledge tracing. However, due
to the lack of interpretability and transparency of some algorithms, this
approach will result in reduced stakeholder trust and a decreased acceptance of
intelligent decisions. Therefore, algorithms need to achieve high accuracy, and
users need to understand the internal operating mechanism and provide reliable
explanations for decisions. This paper thoroughly analyzes the interpretability
of KT algorithms. First, the concepts and common methods of explainable
artificial intelligence and knowledge tracing are introduced. Next, explainable
knowledge tracing models are classified into two categories: transparent models
and black box models. Then, the interpretable methods used are reviewed from
three stages: ante hoc interpretable methods, post hoc interpretable methods,
and other dimensions. It is worth noting that current evaluation methods for
explainable knowledge tracing are lacking. Hence, contrast and deletion
experiments are conducted to explain the prediction results of the deep
knowledge tracing model on the ASSISTment2009 by using three XAI methods.
Moreover, this paper offers some insights into evaluation methods from the
perspective of educational stakeholders. This paper provides a detailed and
comprehensive review of the research on explainable knowledge tracing, aiming
to offer some basis and inspiration for researchers interested in the
interpretability of knowledge tracing.",2024-03-12,2024,2024-03,education
"Developing and Deploying Industry Standards for Artificial Intelligence
  in Education (AIED): Challenges, Strategies, and Future Directions","The adoption of Artificial Intelligence in Education (AIED) holds the promise
of revolutionizing educational practices by offering personalized learning
experiences, automating administrative and pedagogical tasks, and reducing the
cost of content creation. However, the lack of standardized practices in the
development and deployment of AIED solutions has led to fragmented ecosystems,
which presents challenges in interoperability, scalability, and ethical
governance. This article aims to address the critical need to develop and
implement industry standards in AIED, offering a comprehensive analysis of the
current landscape, challenges, and strategic approaches to overcome these
obstacles. We begin by examining the various applications of AIED in various
educational settings and identify key areas lacking in standardization,
including system interoperability, ontology mapping, data integration,
evaluation, and ethical governance. Then, we propose a multi-tiered framework
for establishing robust industry standards for AIED. In addition, we discuss
methodologies for the iterative development and deployment of standards,
incorporating feedback loops from real-world applications to refine and adapt
standards over time. The paper also highlights the role of emerging
technologies and pedagogical theories in shaping future standards for AIED.
Finally, we outline a strategic roadmap for stakeholders to implement these
standards, fostering a cohesive and ethical AIED ecosystem. By establishing
comprehensive industry standards, such as those by IEEE Artificial Intelligence
Standards Committee (AISC) and International Organization for Standardization
(ISO), we can accelerate and scale AIED solutions to improve educational
outcomes, ensuring that technological advances align with the principles of
inclusivity, fairness, and educational excellence.",2024-03-13,2024,2024-03,education
"Evaluating the Application of Large Language Models to Generate Feedback
  in Programming Education","This study investigates the application of large language models,
specifically GPT-4, to enhance programming education. The research outlines the
design of a web application that uses GPT-4 to provide feedback on programming
tasks, without giving away the solution. A web application for working on
programming tasks was developed for the study and evaluated with 51 students
over the course of one semester. The results show that most of the feedback
generated by GPT-4 effectively addressed code errors. However, challenges with
incorrect suggestions and hallucinated issues indicate the need for further
improvements.",2024-03-13,2024,2024-03,education
"The AI Assessment Scale (AIAS) in action: A pilot implementation of
  GenAI supported assessment- A Preprint","The rapid adoption of Generative Artificial Intelligence (GenAI) technologies
in higher education has raised concerns about academic integrity, assessment
practices, and student learning. Banning or blocking GenAI tools has proven
ineffective, and punitive approaches ignore the potential benefits of these
technologies. This paper presents the findings of a pilot study conducted at
British University Vietnam (BUV) exploring the implementation of the Artificial
Intelligence Assessment Scale (AIAS), a flexible framework for incorporating
GenAI into educational assessments. The AIAS consists of five levels, ranging
from 'No AI' to 'Full AI', enabling educators to design assessments that focus
on areas requiring human input and critical thinking.
  Following the implementation of the AIAS, the pilot study results indicate a
significant reduction in academic misconduct cases related to GenAI, a 5.9%
increase in student attainment across the university, and a 33.3% increase in
module passing rates. The AIAS facilitated a shift in pedagogical practices,
with faculty members incorporating GenAI tools into their modules and students
producing innovative multimodal submissions. The findings suggest that the AIAS
can support the effective integration of GenAI in HE, promoting academic
integrity while leveraging the technology's potential to enhance learning
experiences.
  Refer to published version for final text.",2024-03-15,2024,2024-03,education
Causality from Bottom to Top: A Survey,"Causality has become a fundamental approach for explaining the relationships
between events, phenomena, and outcomes in various fields of study. It has
invaded various fields and applications, such as medicine, healthcare,
economics, finance, fraud detection, cybersecurity, education, public policy,
recommender systems, anomaly detection, robotics, control, sociology,
marketing, and advertising. In this paper, we survey its development over the
past five decades, shedding light on the differences between causality and
other approaches, as well as the preconditions for using it. Furthermore, the
paper illustrates how causality interacts with new approaches such as
Artificial Intelligence (AI), Generative AI (GAI), Machine and Deep Learning,
Reinforcement Learning (RL), and Fuzzy Logic. We study the impact of causality
on various fields, its contribution, and its interaction with state-of-the-art
approaches. Additionally, the paper exemplifies the trustworthiness and
explainability of causality models. We offer several ways to evaluate causality
models and discuss future directions.",2024-03-17,2024,2024-03,education
"Embracing the Generative AI Revolution: Advancing Tertiary Education in
  Cybersecurity with GPT","The rapid advancement of generative Artificial Intelligence (AI)
technologies, particularly Generative Pre-trained Transformer (GPT) models such
as ChatGPT, has the potential to significantly impact cybersecurity. In this
study, we investigated the impact of GPTs, specifically ChatGPT, on tertiary
education in cybersecurity, and provided recommendations for universities to
adapt their curricula to meet the evolving needs of the industry. Our research
highlighted the importance of understanding the alignment between GPT's
``mental model'' and human cognition, as well as the enhancement of GPT
capabilities to human skills based on Bloom's taxonomy. By analyzing current
educational practices and the alignment of curricula with industry
requirements, we concluded that universities providing practical degrees like
cybersecurity should align closely with industry demand and embrace the
inevitable generative AI revolution, while applying stringent ethics oversight
to safeguard responsible GPT usage. We proposed a set of recommendations
focused on updating university curricula, promoting agility within
universities, fostering collaboration between academia, industry, and
policymakers, and evaluating and assessing educational outcomes.",2024-03-18,2024,2024-03,education
The future of generative AI chatbots in higher education,"The integration of generative Artificial Intelligence (AI) chatbots in higher
education institutions (HEIs) is reshaping the educational landscape, offering
opportunities for enhanced student support, and administrative and research
efficiency. This study explores the future implications of generative AI
chatbots in HEIs, aiming to understand their potential impact on teaching and
learning, and research processes. Utilizing a narrative literature review (NLR)
methodology, this study synthesizes existing research on generative AI chatbots
in higher education from diverse sources, including academic databases and
scholarly publications. The findings highlight the transformative potential of
generative AI chatbots in streamlining administrative tasks, enhancing student
learning experiences, and supporting research activities. However, challenges
such as academic integrity concerns, user input understanding, and resource
allocation pose significant obstacles to the effective integration of
generative AI chatbots in HEIs. This study underscores the importance of
proactive measures to address ethical considerations, provide comprehensive
training for stakeholders, and establish clear guidelines for the responsible
use of generative AI chatbots in higher education. By navigating these
challenges, and leveraging the benefits of generative AI technologies, HEIs can
harness the full potential of generative AI chatbots to create a more
efficient, effective, inclusive, and innovative educational environment.",2024-03-20,2024,2024-03,education
"Enhancing Programming Education with ChatGPT: A Case Study on Student
  Perceptions and Interactions in a Python Course","The integration of ChatGPT as a supportive tool in education, notably in
programming courses, addresses the unique challenges of programming education
by providing assistance with debugging, code generation, and explanations.
Despite existing research validating ChatGPT's effectiveness, its application
in university-level programming education and a detailed understanding of
student interactions and perspectives remain limited. This paper explores
ChatGPT's impact on learning in a Python programming course tailored for
first-year students over eight weeks. By analyzing responses from surveys,
open-ended questions, and student-ChatGPT dialog data, we aim to provide a
comprehensive view of ChatGPT's utility and identify both its advantages and
limitations as perceived by students. Our study uncovers a generally positive
reception toward ChatGPT and offers insights into its role in enhancing the
programming education experience. These findings contribute to the broader
discourse on AI's potential in education, suggesting paths for future research
and application.",2024-03-20,2024,2024-03,education
"Generative AI in Education: A Study of Educators' Awareness, Sentiments,
  and Influencing Factors","The rapid advancement of artificial intelligence (AI) and the expanding
integration of large language models (LLMs) have ignited a debate about their
application in education. This study delves into university instructors'
experiences and attitudes toward AI language models, filling a gap in the
literature by analyzing educators' perspectives on AI's role in the classroom
and its potential impacts on teaching and learning. The objective of this
research is to investigate the level of awareness, overall sentiment
towardsadoption, and the factors influencing these attitudes for LLMs and
generative AI-based tools in higher education. Data was collected through a
survey using a Likert scale, which was complemented by follow-up interviews to
gain a more nuanced understanding of the instructors' viewpoints. The collected
data was processed using statistical and thematic analysis techniques. Our
findings reveal that educators are increasingly aware of and generally positive
towards these tools. We find no correlation between teaching style and attitude
toward generative AI. Finally, while CS educators show far more confidence in
their technical understanding of generative AI tools and more positivity
towards them than educators in other fields, they show no more confidence in
their ability to detect AI-generated work.",2024-03-22,2024,2024-03,education
The Ethics of AI in Education,"The transition of Artificial Intelligence (AI) from a lab-based science to
live human contexts brings into sharp focus many historic, socio-cultural
biases, inequalities, and moral dilemmas. Many questions that have been raised
regarding the broader ethics of AI are also relevant for AI in Education
(AIED). AIED raises further specific challenges related to the impact of its
technologies on users, how such technologies might be used to reinforce or
alter the way that we learn and teach, and what we, as a society and
individuals, value as outcomes of education. This chapter discusses key ethical
dimensions of AI and contextualises them within AIED design and engineering
practices to draw connections between the AIED systems we build, the questions
about human learning and development we ask, the ethics of the pedagogies we
use, and the considerations of values that we promote in and through AIED
within a wider socio-technical system.",2024-03-22,2024,2024-03,education
From Guidelines to Governance: A Study of AI Policies in Education,"Emerging technologies like generative AI tools, including ChatGPT, are
increasingly utilized in educational settings, offering innovative approaches
to learning while simultaneously posing new challenges. This study employs a
survey methodology to examine the policy landscape concerning these
technologies, drawing insights from 102 high school principals and higher
education provosts. Our results reveal a prominent policy gap: the majority of
institutions lack specialized guide-lines for the ethical deployment of AI
tools such as ChatGPT. Moreover,we observed that high schools are less inclined
to work on policies than higher educational institutions. Where such policies
do exist, they often overlook crucial issues, including student privacy and
algorithmic transparency. Administrators overwhelmingly recognize the necessity
of these policies, primarily to safeguard student safety and mitigate
plagiarism risks. Our findings underscore the urgent need for flexible and
iterative policy frameworks in educational contexts.",2024-03-22,2024,2024-03,education
Bioinformatics and Biomedical Informatics with ChatGPT: Year One Review,"The year 2023 marked a significant surge in the exploration of applying large
language model (LLM) chatbots, notably ChatGPT, across various disciplines. We
surveyed the applications of ChatGPT in bioinformatics and biomedical
informatics throughout the year, covering omics, genetics, biomedical text
mining, drug discovery, biomedical image understanding, bioinformatics
programming, and bioinformatics education. Our survey delineates the current
strengths and limitations of this chatbot in bioinformatics and offers insights
into potential avenues for future developments.",2024-03-22,2024,2024-03,education
"The Interplay of Learning, Analytics, and Artificial Intelligence in
  Education: A Vision for Hybrid Intelligence","This paper presents a multi-dimensional view of AI's role in learning and
education, emphasizing the intricate interplay between AI, analytics, and the
learning processes. Here, I challenge the prevalent narrow conceptualisation of
AI as tools, as exemplified in generative AI tools, and argue for the
importance of alternative conceptualisations of AI for achieving human-AI
hybrid intelligence. I highlight the differences between human intelligence and
artificial information processing, the importance of hybrid human-AI systems to
extend human cognition, and posit that AI can also serve as an instrument for
understanding human learning. Early learning sciences and AI in Education
research (AIED), which saw AI as an analogy for human intelligence, have
diverged from this perspective, prompting a need to rekindle this connection.
The paper presents three unique conceptualisations of AI: the externalization
of human cognition, the internalization of AI models to influence human mental
models, and the extension of human cognition via tightly coupled human-AI
hybrid intelligence systems. Examples from current research and practice are
examined as instances of the three conceptualisations in education,
highlighting the potential value and limitations of each conceptualisation for
education, as well as the perils of overemphasis on externalising human
cognition. The paper concludes with advocacy for a broader approach to AIED
that goes beyond considerations on the design and development of AI, but also
includes educating people about AI and innovating educational systems to remain
relevant in an AI-ubiquitous world.",2024-03-24,2024,2024-03,education
"Opportunities and challenges in the application of large artificial
  intelligence models in radiology","Influenced by ChatGPT, artificial intelligence (AI) large models have
witnessed a global upsurge in large model research and development. As people
enjoy the convenience by this AI large model, more and more large models in
subdivided fields are gradually being proposed, especially large models in
radiology imaging field. This article first introduces the development history
of large models, technical details, workflow, working principles of multimodal
large models and working principles of video generation large models. Secondly,
we summarize the latest research progress of AI large models in radiology
education, radiology report generation, applications of unimodal and multimodal
radiology. Finally, this paper also summarizes some of the challenges of large
AI models in radiology, with the aim of better promoting the rapid revolution
in the field of radiography.",2024-03-24,2024,2024-03,education
Large Language Models for Education: A Survey and Outlook,"The advent of Large Language Models (LLMs) has brought in a new era of
possibilities in the realm of education. This survey paper summarizes the
various technologies of LLMs in educational settings from multifaceted
perspectives, encompassing student and teacher assistance, adaptive learning,
and commercial tools. We systematically review the technological advancements
in each perspective, organize related datasets and benchmarks, and identify the
risks and challenges associated with deploying LLMs in education. Furthermore,
we outline future research opportunities, highlighting the potential promising
directions. Our survey aims to provide a comprehensive technological picture
for educators, researchers, and policymakers to harness the power of LLMs to
revolutionize educational practices and foster a more effective personalized
learning environment.",2024-03-26,2024,2024-03,education
The Pursuit of Fairness in Artificial Intelligence Models: A Survey,"Artificial Intelligence (AI) models are now being utilized in all facets of
our lives such as healthcare, education and employment. Since they are used in
numerous sensitive environments and make decisions that can be life altering,
potential biased outcomes are a pressing matter. Developers should ensure that
such models don't manifest any unexpected discriminatory practices like
partiality for certain genders, ethnicities or disabled people. With the
ubiquitous dissemination of AI systems, researchers and practitioners are
becoming more aware of unfair models and are bound to mitigate bias in them.
Significant research has been conducted in addressing such issues to ensure
models don't intentionally or unintentionally perpetuate bias. This survey
offers a synopsis of the different ways researchers have promoted fairness in
AI systems. We explore the different definitions of fairness existing in the
current literature. We create a comprehensive taxonomy by categorizing
different types of bias and investigate cases of biased AI in different
application domains. A thorough study is conducted of the approaches and
techniques employed by researchers to mitigate bias in AI models. Moreover, we
also delve into the impact of biased models on user experience and the ethical
considerations to contemplate when developing and deploying such models. We
hope this survey helps researchers and practitioners understand the intricate
details of fairness and bias in AI systems. By sharing this thorough survey, we
aim to promote additional discourse in the domain of equitable and responsible
AI.",2024-03-26,2024,2024-03,education
The use of ChatGPT in higher education: The advantages and disadvantages,"Higher education scholars are interested in an artificial intelligence (AI)
technology called ChatGPT, which was developed by OpenAI. Whether ChatGPT can
improve learning is still a topic of debate among experts. This concise
overview of the literature examines the application of ChatGPT in higher
education to comprehend and produce high-level instruction. By examining the
essential literature, this study seeks to provide a thorough assessment of the
advantages and disadvantages of utilizing ChatGPT in higher education settings.
But it's crucial to consider both the positive and negative elements. For this
rapid review, the researcher searched Google Scholar, Scopus, and others
between January 2023 and July 2023 for prior research from various
publications. These studies were examined. The study found that employing
ChatGPT in higher education is beneficial for a number of reasons. It can
provide individualized instruction, and prompt feedback, facilitate access to
learning, and promote student interaction. These benefits could improve the
learning environment and make it more fun for academics and students. The cons
of ChatGPT are equally present. These problems include the inability to
comprehend emotions, the lack of social interaction chances, technological
limitations, and the dangers of depending too much on ChatGPT for higher
education. Higher education should combine ChatGPT with other teaching
techniques to provide students and lecturers with a comprehensive education.
However, it is crucial to consider the positives, negatives, and moral issues
before adopting ChatGPT in the classroom.",2024-03-28,2024,2024-03,education
"Developing generative AI chatbots conceptual framework for higher
  education","This research explores the quickly changing field of generative artificial
intelligence (GAI) chatbots in higher education, an industry that is undergoing
major technological changes. AI chatbots, such as ChatGPT, HuggingChat, and
Google Bard, are becoming more and more common in a variety of sectors,
including education. Their acceptance is still in its early phases, with a
variety of prospects and obstacles. However, their potential in higher
education is particularly noteworthy, providing lecturers and students with
affordable, individualized support. Creating a comprehensive framework to aid
the usage of generative AI chatbots in higher education institutions (HEIs) is
the aim of this project. The Generative AI Chatbots Acceptance Model (GAICAM)
is the result of this study's synthesis of elements from well-known frameworks,
including the TAM, UTAUT2, TPB, and others along with variables like optimism,
innovativeness, discomfort, insecurity, and others. Using a research method
that encompasses a comprehensive analysis of extant literature from databases
such as IEEE, ACM, ScienceDirect, and Google Scholar, the study aims to
comprehend the implications of AI Chatbots on higher education and pinpoint
critical elements for their efficacious implementation. Peer-reviewed
English-language publications published between 2020 and 2023 with a focus on
the use of AI chatbots in higher education were the main focus of the search
criteria. The results demonstrate how much AI chatbots can do to improve
student engagement, streamline the educational process, and support
administrative and research duties. But there are also clear difficulties, such
as unfavorable student sentiments, doubts about the veracity of material
produced by AI, and unease and nervousness with new technologies.",2024-03-28,2024,2024-03,education
"Generative AI Adoption in Classroom in Context of Technology Acceptance
  Model (TAM) and the Innovation Diffusion Theory (IDT)","The burgeoning development of generative artificial intelligence (GenAI) and
the widespread adoption of large language models (LLMs) in educational settings
have sparked considerable debate regarding their efficacy and
acceptability.Despite the potential benefits, the assimilation of these
cutting-edge technologies among educators exhibits a broad spectrum of
attitudes, from enthusiastic advocacy to profound skepticism.This study aims to
dissect the underlying factors influencing educators' perceptions and
acceptance of GenAI and LLMs.We conducted a survey among educators and analyzed
the data through the frameworks of the Technology Acceptance Model (TAM) and
Innovation Diffusion Theory (IDT). Our investigation reveals a strong positive
correlation between the perceived usefulness of GenAI tools and their
acceptance, underscoring the importance of demonstrating tangible benefits to
educators. Additionally, the perceived ease of use emerged as a significant
factor, though to a lesser extent, influencing acceptance. Our findings also
show that the knowledge and acceptance of these tools is not uniform,
suggesting that targeted strategies are required to address the specific needs
and concerns of each adopter category to facilitate broader integration of AI
tools.in education.",2024-03-29,2024,2024-03,education
Higher education assessment practice in the era of generative AI tools,"The higher education (HE) sector benefits every nation's economy and society
at large. However, their contributions are challenged by advanced technologies
like generative artificial intelligence (GenAI) tools. In this paper, we
provide a comprehensive assessment of GenAI tools towards assessment and
pedagogic practice and, subsequently, discuss the potential impacts. This study
experimented using three assessment instruments from data science, data
analytics, and construction management disciplines. Our findings are two-fold:
first, the findings revealed that GenAI tools exhibit subject knowledge,
problem-solving, analytical, critical thinking, and presentation skills and
thus can limit learning when used unethically. Secondly, the design of the
assessment of certain disciplines revealed the limitations of the GenAI tools.
Based on our findings, we made recommendations on how AI tools can be utilised
for teaching and learning in HE.",2024-04-01,2024,2024-04,education
"Rapid Mobile App Development for Generative AI Agents on MIT App
  Inventor","The evolution of Artificial Intelligence (AI) stands as a pivotal force
shaping our society, finding applications across diverse domains such as
education, sustainability, and safety. Leveraging AI within mobile applications
makes it easily accessible to the public, catalyzing its transformative
potential. In this paper, we present a methodology for the rapid development of
AI agent applications using the development platform provided by MIT App
Inventor. To demonstrate its efficacy, we share the development journey of
three distinct mobile applications: SynchroNet for fostering sustainable
communities; ProductiviTeams for addressing procrastination; and iHELP for
enhancing community safety. All three applications seamlessly integrate a
spectrum of generative AI features, leveraging OpenAI APIs. Furthermore, we
offer insights gleaned from overcoming challenges in integrating diverse tools
and AI functionalities, aiming to inspire young developers to join our efforts
in building practical AI agent applications.",2024-04-01,2024,2024-04,education
"Automated Assessment of Encouragement and Warmth in Classrooms
  Leveraging Multimodal Emotional Features and ChatGPT","Classroom observation protocols standardize the assessment of teaching
effectiveness and facilitate comprehension of classroom interactions. Whereas
these protocols offer teachers specific feedback on their teaching practices,
the manual coding by human raters is resource-intensive and often unreliable.
This has sparked interest in developing AI-driven, cost-effective methods for
automating such holistic coding. Our work explores a multimodal approach to
automatically estimating encouragement and warmth in classrooms, a key
component of the Global Teaching Insights (GTI) study's observation protocol.
To this end, we employed facial and speech emotion recognition with sentiment
analysis to extract interpretable features from video, audio, and transcript
data. The prediction task involved both classification and regression methods.
Additionally, in light of recent large language models' remarkable text
annotation capabilities, we evaluated ChatGPT's zero-shot performance on this
scoring task based on transcripts. We demonstrated our approach on the GTI
dataset, comprising 367 16-minute video segments from 92 authentic lesson
recordings. The inferences of GPT-4 and the best-trained model yielded
correlations of r = .341 and r = .441 with human ratings, respectively.
Combining estimates from both models through averaging, an ensemble approach
achieved a correlation of r = .513, comparable to human inter-rater
reliability. Our model explanation analysis indicated that text sentiment
features were the primary contributors to the trained model's decisions.
Moreover, GPT-4 could deliver logical and concrete reasoning as potential
teacher guidelines. Our findings provide insights into using advanced,
multimodal techniques for automated classroom observation, aiming to foster
teacher training through frequent and valuable feedback.",2024-04-01,2024,2024-04,education
"The Artificial Intelligence Ontology: LLM-assisted construction of AI
  concept hierarchies","The Artificial Intelligence Ontology (AIO) is a systematization of artificial
intelligence (AI) concepts, methodologies, and their interrelations. Developed
via manual curation, with the additional assistance of large language models
(LLMs), AIO aims to address the rapidly evolving landscape of AI by providing a
comprehensive framework that encompasses both technical and ethical aspects of
AI technologies. The primary audience for AIO includes AI researchers,
developers, and educators seeking standardized terminology and concepts within
the AI domain. The ontology is structured around six top-level branches:
Networks, Layers, Functions, LLMs, Preprocessing, and Bias, each designed to
support the modular composition of AI methods and facilitate a deeper
understanding of deep learning architectures and ethical considerations in AI.
  AIO's development utilized the Ontology Development Kit (ODK) for its
creation and maintenance, with its content being dynamically updated through
AI-driven curation support. This approach not only ensures the ontology's
relevance amidst the fast-paced advancements in AI but also significantly
enhances its utility for researchers, developers, and educators by simplifying
the integration of new AI concepts and methodologies.
  The ontology's utility is demonstrated through the annotation of AI methods
data in a catalog of AI research publications and the integration into the
BioPortal ontology resource, highlighting its potential for cross-disciplinary
research. The AIO ontology is open source and is available on GitHub
(https://github.com/berkeleybop/artificial-intelligence-ontology) and BioPortal
(https://bioportal.bioontology.org/ontologies/AIO).",2024-04-03,2024,2024-04,education
"AI and personalized learning: bridging the gap with modern educational
  goals","Personalized learning (PL) aspires to provide an alternative to the
one-size-fits-all approach in education. Technology-based PL solutions have
shown notable effectiveness in enhancing learning performance. However, their
alignment with the broader goals of modern education is inconsistent across
technologies and research areas. In this paper, we examine the characteristics
of AI-driven PL solutions in light of the goals outlined in the OECD Learning
Compass 2030. Our analysis indicates a gap between the objectives of modern
education and the technological approach to PL. We identify areas where the
AI-based PL solutions could embrace essential elements of contemporary
education, such as fostering learner's agency, cognitive engagement, and
general competencies. While the PL solutions that narrowly focus on
domain-specific knowledge acquisition are instrumental in aiding learning
processes, the PL envisioned by educational experts extends beyond simple
technological tools and requires a holistic change in the educational system.
Finally, we explore the potential of generative AI, such as ChatGPT, and
propose a hybrid model that blends artificial intelligence with a
collaborative, teacher-facilitated approach to personalized learning.",2024-04-03,2024,2024-04,education
AI-Tutoring in Software Engineering Education,"With the rapid advancement of artificial intelligence (AI) in various
domains, the education sector is set for transformation. The potential of
AI-driven tools in enhancing the learning experience, especially in
programming, is immense. However, the scientific evaluation of Large Language
Models (LLMs) used in Automated Programming Assessment Systems (APASs) as an
AI-Tutor remains largely unexplored. Therefore, there is a need to understand
how students interact with such AI-Tutors and to analyze their experiences. In
this paper, we conducted an exploratory case study by integrating the
GPT-3.5-Turbo model as an AI-Tutor within the APAS Artemis. Through a
combination of empirical data collection and an exploratory survey, we
identified different user types based on their interaction patterns with the
AI-Tutor. Additionally, the findings highlight advantages, such as timely
feedback and scalability. However, challenges like generic responses and
students' concerns about a learning progress inhibition when using the AI-Tutor
were also evident. This research adds to the discourse on AI's role in
education.",2024-04-03,2024,2024-04,education
"The Promises and Pitfalls of Using Language Models to Measure
  Instruction Quality in Education","Assessing instruction quality is a fundamental component of any improvement
efforts in the education system. However, traditional manual assessments are
expensive, subjective, and heavily dependent on observers' expertise and
idiosyncratic factors, preventing teachers from getting timely and frequent
feedback. Different from prior research that mostly focuses on low-inference
instructional practices on a singular basis, this paper presents the first
study that leverages Natural Language Processing (NLP) techniques to assess
multiple high-inference instructional practices in two distinct educational
settings: in-person K-12 classrooms and simulated performance tasks for
pre-service teachers. This is also the first study that applies NLP to measure
a teaching practice that is widely acknowledged to be particularly effective
for students with special needs. We confront two challenges inherent in
NLP-based instructional analysis, including noisy and long input data and
highly skewed distributions of human ratings. Our results suggest that
pretrained Language Models (PLMs) demonstrate performances comparable to the
agreement level of human raters for variables that are more discrete and
require lower inference, but their efficacy diminishes with more complex
teaching practices. Interestingly, using only teachers' utterances as input
yields strong results for student-centered variables, alleviating common
concerns over the difficulty of collecting and transcribing high-quality
student speech data in in-person teaching settings. Our findings highlight both
the potential and the limitations of current NLP techniques in the education
domain, opening avenues for further exploration.",2024-04-03,2024,2024-04,education
"Proceedings 12th International Workshop on Theorem proving components
  for Educational software","The ThEdu series pursues the smooth transition from an intuitive way of doing
mathematics at secondary school to a more formal approach to the subject in
STEM education, while favouring software support for this transition by
exploiting the power of theorem-proving technologies. What follows is a brief
description of how the present volume contributes to this enterprise.
  The 12th International Workshop on Theorem Proving Components for Educational
Software(ThEdu'23), was a satellite event of the 29th international Conference
on Automated Deduction (CADE 2023), July 1-4, 2023, Rome, Italy. ThEdu'23 was
very successful, with one invited talk, by Yves Bertot (Inria, France), ""The
challenges of using Type Theory to teach Mathematics"", and seven regular
contributions. An open call for papers was then issued, to which eight
contributions were submitted. Seven submissions have been accepted by our
reviewers, who jointly produced at least three careful reports on each of the
contributions. The resulting revised papers are collected in the present
volume.
  We, the volume editors, hope that this collection of papers will further
promote the development of theorem-proving based software, and that it will
allow to improve the mutual understanding between computer scientists,
mathematicians and stakeholders in education.
  PC Chairs:Julien Narboux (University of Strasbourg, France); Walther Neuper
(JKU, Johannes Kepler University, Linz, Austria); Pedro Quaresma (University of
Coimbra, Portugal)",2024-04-04,2024,2024-04,education
"Sentiment analysis and random forest to classify LLM versus human source
  applied to Scientific Texts","After the launch of ChatGPT v.4 there has been a global vivid discussion on
the ability of this artificial intelligence powered platform and some other
similar ones for the automatic production of all kinds of texts, including
scientific and technical texts. This has triggered a reflection in many
institutions on whether education and academic procedures should be adapted to
the fact that in future many texts we read will not be written by humans
(students, scholars, etc.), at least, not entirely. In this work it is proposed
a new methodology to classify texts coming from an automatic text production
engine or a human, based on Sentiment Analysis as a source for feature
engineering independent variables and then train with them a Random Forest
classification algorithm. Using four different sentiment lexicons, a number of
new features where produced, and then fed to a machine learning random forest
methodology, to train such a model. Results seem very convincing that this may
be a promising research line to detect fraud, in such environments where human
are supposed to be the source of texts.",2024-04-05,2024,2024-04,education
"Clue-Instruct: Text-Based Clue Generation for Educational Crossword
  Puzzles","Crossword puzzles are popular linguistic games often used as tools to engage
students in learning. Educational crosswords are characterized by less cryptic
and more factual clues that distinguish them from traditional crossword
puzzles. Despite there exist several publicly available clue-answer pair
databases for traditional crosswords, educational clue-answer pairs datasets
are missing. In this article, we propose a methodology to build educational
clue generation datasets that can be used to instruct Large Language Models
(LLMs). By gathering from Wikipedia pages informative content associated with
relevant keywords, we use Large Language Models to automatically generate
pedagogical clues related to the given input keyword and its context. With such
an approach, we created clue-instruct, a dataset containing 44,075 unique
examples with text-keyword pairs associated with three distinct crossword
clues. We used clue-instruct to instruct different LLMs to generate educational
clues from a given input content and keyword. Both human and automatic
evaluations confirmed the quality of the generated clues, thus validating the
effectiveness of our approach.",2024-04-09,2024,2024-04,education
Deep Learning for Educational Data Science,"With the ever-growing presence of deep artificial neural networks in every
facet of modern life, a growing body of researchers in educational data science
-- a field consisting of various interrelated research communities -- have
turned their attention to leveraging these powerful algorithms within the
domain of education. Use cases range from advanced knowledge tracing models
that can leverage open-ended student essays or snippets of code to automatic
affect and behavior detectors that can identify when a student is frustrated or
aimlessly trying to solve problems unproductively -- and much more. This
chapter provides a brief introduction to deep learning, describes some of its
advantages and limitations, presents a survey of its many uses in education,
and discusses how it may further come to shape the field of educational data
science.",2024-04-12,2024,2024-04,education
"Artificial Intelligence in Everyday Life 2.0: Educating University
  Students from Different Majors","With the surge in data-centric AI and its increasing capabilities, AI
applications have become a part of our everyday lives. However,
misunderstandings regarding their capabilities, limitations, and associated
advantages and disadvantages are widespread. Consequently, in the university
setting, there is a crucial need to educate not only computer science majors
but also students from various disciplines about AI. In this experience report,
we present an overview of an introductory course that we offered to students
coming from different majors. Moreover, we discuss the assignments and quizzes
of the course, which provided students with a firsthand experience of AI
processes and insights into their learning patterns. Additionally, we provide a
summary of the course evaluation, as well as students' performance. Finally, we
present insights gained from teaching this course and elaborate on our future
plans.",2024-04-12,2024,2024-04,education
"Leveraging Large Language Model as Simulated Patients for Clinical
  Education","Simulated Patients (SPs) play a crucial role in clinical medical education by
providing realistic scenarios for student practice. However, the high cost of
training and hiring qualified SPs, along with the heavy workload and potential
risks they face in consistently portraying actual patients, limit students'
access to this type of clinical training. Consequently, the integration of
computer program-based simulated patients has emerged as a valuable educational
tool in recent years. With the rapid development of Large Language Models
(LLMs), their exceptional capabilities in conversational artificial
intelligence and role-playing have been demonstrated, making them a feasible
option for implementing Virtual Simulated Patient (VSP). In this paper, we
present an integrated model-agnostic framework called CureFun that harnesses
the potential of LLMs in clinical medical education. This framework facilitates
natural conversations between students and simulated patients, evaluates their
dialogue, and provides suggestions to enhance students' clinical inquiry
skills. Through comprehensive evaluations, our approach demonstrates more
authentic and professional SP-scenario dialogue flows compared to other
LLM-based chatbots, thus proving its proficiency in simulating patients.
Additionally, leveraging CureFun's evaluation ability, we assess several
medical LLMs and discuss the possibilities and limitations of using LLMs as
virtual doctors from the perspective of their diagnostic abilities.",2024-04-13,2024,2024-04,education
"Cross-Data Knowledge Graph Construction for LLM-enabled Educational
  Question-Answering System: A Case Study at HCMUT","In today's rapidly evolving landscape of Artificial Intelligence, large
language models (LLMs) have emerged as a vibrant research topic. LLMs find
applications in various fields and contribute significantly. Despite their
powerful language capabilities, similar to pre-trained language models (PLMs),
LLMs still face challenges in remembering events, incorporating new
information, and addressing domain-specific issues or hallucinations. To
overcome these limitations, researchers have proposed Retrieval-Augmented
Generation (RAG) techniques, some others have proposed the integration of LLMs
with Knowledge Graphs (KGs) to provide factual context, thereby improving
performance and delivering more accurate feedback to user queries.
  Education plays a crucial role in human development and progress. With the
technology transformation, traditional education is being replaced by digital
or blended education. Therefore, educational data in the digital environment is
increasing day by day. Data in higher education institutions are diverse,
comprising various sources such as unstructured/structured text, relational
databases, web/app-based API access, etc. Constructing a Knowledge Graph from
these cross-data sources is not a simple task. This article proposes a method
for automatically constructing a Knowledge Graph from multiple data sources and
discusses some initial applications (experimental trials) of KG in conjunction
with LLMs for question-answering tasks.",2024-04-14,2024,2024-04,education
Occupation Life Cycle,"This paper explores the evolution of occupations within the context of
industry and technology life cycles, highlighting the critical yet
underexplored intersection between occupational trends and broader economic
dynamics. Introducing the Occupation Life Cycle (OLC) model, we delineate five
stages (i.e., growth, peak, fluctuation, maturity, and decline) to
systematically explore the trajectory of occupations. Utilizing job posting
data from one of China's largest recruitment platforms as a novel proxy, our
study meticulously tracks the fluctuations and emerging trends in the labor
market from 2018 to 2023. Through a detailed examination of representative
roles, such as short video operators and data analysts, alongside emerging
occupations within the artificial intelligence (AI) sector, our findings
allocate occupations to specific life cycle stages, revealing insightful
patterns of occupational development and decline. Our findings offer a unique
perspective on the interplay between occupational evolution and economic
factors, with a particular focus on the rapidly changing Chinese labor market.
This study not only contributes to the theoretical understanding of OLC but
also provides practical insights for policymakers, educators, and industry
leaders facing the challenges of workforce planning and development in the face
of technological advancement and market shifts.",2024-04-15,2024,2024-04,education
AI-Assisted Writing in Education: Ecosystem Risks and Mitigations,"While the excitement around the capabilities of technological advancements is
giving rise to new AI-based writing assistants, the overarching ecosystem plays
a crucial role in how they are adopted in educational practice. In this paper,
we point to key ecological aspects for consideration. We draw insights from
extensive research integrated with practice on a writing feedback tool over 9
years at a university, and we highlight potential risks when these are
overlooked. It informs the design of educational writing support tools to be
better aligned within broader contexts to balance innovation with practical
impact.",2024-04-16,2024,2024-04,education
The application of Augmented Reality (AR) in Remote Work and Education,"With the rapid advancement of technology, Augmented Reality (AR) technology,
known for its ability to deeply integrate virtual information with the real
world, is gradually transforming traditional work modes and teaching methods.
Particularly in the realms of remote work and online education, AR technology
demonstrates a broad spectrum of application prospects. This paper delves into
the application potential and actual effects of AR technology in remote work
and education. Through a systematic literature review, this study outlines the
key features, advantages, and challenges of AR technology. Based on theoretical
analysis, it discusses the scientific basis and technical support that AR
technology provides for enhancing remote work efficiency and promoting
innovation in educational teaching models. Additionally, by designing an
empirical research plan and analyzing experimental data, this article reveals
the specific performance and influencing factors of AR technology in practical
applications. Finally, based on the results of the experiments, this research
summarizes the application value of AR technology in remote work and education,
looks forward to its future development trends, and proposes forward-looking
research directions and strategic suggestions, offering empirical foundation
and theoretical guidance for further promoting the in-depth application of AR
technology in related fields.",2024-04-16,2024,2024-04,education
"The Evolution of Learning: Assessing the Transformative Impact of
  Generative AI on Higher Education","Generative Artificial Intelligence (GAI) models such as ChatGPT have
experienced a surge in popularity, attracting 100 million active users in 2
months and generating an estimated 10 million daily queries. Despite this
remarkable adoption, there remains a limited understanding to which extent this
innovative technology influences higher education. This research paper
investigates the impact of GAI on university students and Higher Education
Institutions (HEIs). The study adopts a mixed-methods approach, combining a
comprehensive survey with scenario analysis to explore potential benefits,
drawbacks, and transformative changes the new technology brings. Using an
online survey with 130 participants we assessed students' perspectives and
attitudes concerning present ChatGPT usage in academics. Results show that
students use the current technology for tasks like assignment writing and exam
preparation and believe it to be a effective help in achieving academic goals.
The scenario analysis afterwards projected potential future scenarios,
providing valuable insights into the possibilities and challenges associated
with incorporating GAI into higher education. The main motivation is to gain a
tangible and precise understanding of the potential consequences for HEIs and
to provide guidance responding to the evolving learning environment. The
findings indicate that irresponsible and excessive use of the technology could
result in significant challenges. Hence, HEIs must develop stringent policies,
reevaluate learning objectives, upskill their lecturers, adjust the curriculum
and reconsider examination approaches.",2024-04-16,2024,2024-04,education
"Large Language Models Meet User Interfaces: The Case of Provisioning
  Feedback","Incorporating Generative AI (GenAI) and Large Language Models (LLMs) in
education can enhance teaching efficiency and enrich student learning. Current
LLM usage involves conversational user interfaces (CUIs) for tasks like
generating materials or providing feedback. However, this presents challenges
including the need for educator expertise in AI and CUIs, ethical concerns with
high-stakes decisions, and privacy risks. CUIs also struggle with complex
tasks. To address these, we propose transitioning from CUIs to user-friendly
applications leveraging LLMs via API calls. We present a framework for
ethically incorporating GenAI into educational tools and demonstrate its
application in our tool, Feedback Copilot, which provides personalized feedback
on student assignments. Our evaluation shows the effectiveness of this
approach, with implications for GenAI researchers, educators, and
technologists. This work charts a course for the future of GenAI in education.",2024-04-17,2024,2024-04,education
"Enhancing Educational Efficiency: Generative AI Chatbots and DevOps in
  Education 4.0","This research paper will bring forth the innovative pedagogical approach in
computer science education, which uses a combination of methodologies borrowed
from Artificial Intelligence (AI) and DevOps to enhance the learning experience
in Content Management Systems (CMS) Development. It has been done over three
academic years, comparing the traditional way of teaching with the lately
introduced AI-supported techniques. This had three structured sprints, each one
of them covering the major parts of the sprint: object-oriented PHP, theme
development, and plugin development. In each sprint, the student deals with
part of the theoretical content and part of the practical task, using ChatGPT
as an auxiliary tool. In that sprint, the model will provide solutions in code
debugging and extensions of complex problems. The course includes practical
examples like code replication with PHP, functionality expansion of the CMS,
even development of custom plugins, and themes. The course practice includes
versions' control with Git repositories. Efficiency will touch the theme and
plugin output rates during development and mobile/web application development.
Comparative analysis indicates that there is a marked increase in efficiency
and shows effectiveness with the proposed AI- and DevOps-supported methodology.
The study is very informative since education in computer science and its
landscape change embodies an emerging technology that could have transformation
impacts on amplifying the potential for scalable and adaptive learning
approaches.",2024-04-18,2024,2024-04,education
"The Emerging Generative Artificial Intelligence Divide in the United
  States","The digital divide refers to disparities in access to and use of digital
tooling across social and economic groups. This divide can reinforce
marginalization both at the individual level and at the level of places,
because persistent economic advantages accrue to places where new technologies
are adopted early. To what extent are emerging generative artificial
intelligence (AI) tools subject to these social and spatial divides? We
leverage a large-scale search query database to characterize U.S. residents'
knowledge of a novel generative AI tool, ChatGPT, during its first six months
of release. We identify hotspots of higher-than-expected search volumes for
ChatGPT in coastal metropolitan areas, while coldspots are evident in the
American South, Appalachia, and the Midwest. Nationwide, counties with the
highest rates of search have proportionally more educated and more economically
advantaged populations, as well as proportionally more technology and
finance-sector jobs in comparison with other counties or with the national
average. Observed associations with race/ethnicity and urbanicity are
attenuated in fully adjusted hierarchical models, but education emerges as the
strongest positive predictor of generative AI awareness. In the absence of
intervention, early differences in uptake show a potential to reinforce
existing spatial and socioeconomic divides.",2024-04-18,2024,2024-04,education
Intelligence Education made in Europe,"Global conflicts and trouble spots have thrown the world into turmoil.
Intelligence services have never been as necessary as they are today when it
comes to providing political decision-makers with concrete, accurate, and
up-to-date decision-making knowledge. This requires a common co-operation, a
common working language and a common understanding of each other. The best way
to create this ""intelligence community"" is through a harmonized intelligence
education.
  In this paper, we show how joint intelligence education can succeed. We draw
on the experience of Germany, where all intelligence services and the
Bundeswehr are academically educated together in a single degree program that
lays the foundations for a common working language. We also show how these
experiences have been successfully transferred to a European level, namely to
ICE, the Intelligence College in Europe. Our experience has shown that three
aspects are particularly important: firstly, interdisciplinarity or better,
transdisciplinarity, secondly, the integration of IT knowhow and thirdly, the
development and learning of methodological skills. Using the example of the
cyber intelligence module with a special focus on data-driven decision support,
additionally with its many points of reference to numerous other academic
modules, we show how the specific analytic methodology presented is embedded in
our specific European teaching context.",2024-04-18,2024,2024-04,education
"The AI Companion in Education: Analyzing the Pedagogical Potential of
  ChatGPT in Computer Science and Engineering","Artificial Intelligence (AI), with ChatGPT as a prominent example, has
recently taken center stage in various domains including higher education,
particularly in Computer Science and Engineering (CSE). The AI revolution
brings both convenience and controversy, offering substantial benefits while
lacking formal guidance on their application. The primary objective of this
work is to comprehensively analyze the pedagogical potential of ChatGPT in CSE
education, understanding its strengths and limitations from the perspectives of
educators and learners. We employ a systematic approach, creating a diverse
range of educational practice problems within CSE field, focusing on various
subjects such as data science, programming, AI, machine learning, networks, and
more. According to our examinations, certain question types, like conceptual
knowledge queries, typically do not pose significant challenges to ChatGPT, and
thus, are excluded from our analysis. Alternatively, we focus our efforts on
developing more in-depth and personalized questions and project-based tasks.
These questions are presented to ChatGPT, followed by interactions to assess
its effectiveness in delivering complete and meaningful responses. To this end,
we propose a comprehensive five-factor reliability analysis framework to
evaluate the responses. This assessment aims to identify when ChatGPT excels
and when it faces challenges. Our study concludes with a correlation analysis,
delving into the relationships among subjects, task types, and limiting
factors. This analysis offers valuable insights to enhance ChatGPT's utility in
CSE education, providing guidance to educators and students regarding its
reliability and efficacy.",2024-04-23,2024,2024-04,education
AI and Machine Learning for Next Generation Science Assessments,"This chapter focuses on the transformative role of Artificial Intelligence
(AI) and Machine Learning (ML) in science assessments. The paper begins with a
discussion of the Framework for K-12 Science Education, which calls for a shift
from conceptual learning to knowledge-in-use. This shift necessitates the
development of new types of assessments that align with the Framework's three
dimensions: science and engineering practices, disciplinary core ideas, and
crosscutting concepts. The paper further highlights the limitations of
traditional assessment methods like multiple-choice questions, which often fail
to capture the complexities of scientific thinking and three-dimensional
learning in science. It emphasizes the need for performance-based assessments
that require students to engage in scientific practices like modeling,
explanation, and argumentation. The paper achieves three major goals: reviewing
the current state of ML-based assessments in science education, introducing a
framework for scoring accuracy in ML-based automatic assessments, and
discussing future directions and challenges. It delves into the evolution of
ML-based automatic scoring systems, discussing various types of ML, like
supervised, unsupervised, and semi-supervised learning. These systems can
provide timely and objective feedback, thus alleviating the burden on teachers.
The paper concludes by exploring pre-trained models like BERT and finetuned
ChatGPT, which have shown promise in assessing students' written responses
effectively.",2024-04-23,2024,2024-04,education
Retrieval Augmented Generation for Domain-specific Question Answering,"Question answering (QA) has become an important application in the advanced
development of large language models. General pre-trained large language models
for question-answering are not trained to properly understand the knowledge or
terminology for a specific domain, such as finance, healthcare, education, and
customer service for a product. To better cater to domain-specific
understanding, we build an in-house question-answering system for Adobe
products. We propose a novel framework to compile a large question-answer
database and develop the approach for retrieval-aware finetuning of a Large
Language model. We showcase that fine-tuning the retriever leads to major
improvements in the final generation. Our overall approach reduces
hallucinations during generation while keeping in context the latest retrieval
information for contextual grounding.",2024-04-23,2024,2024-04,education
"Deepfakes and Higher Education: A Research Agenda and Scoping Review of
  Synthetic Media","The availability of software which can produce convincing yet synthetic media
poses both threats and benefits to tertiary education globally. While other
forms of synthetic media exist, this study focuses on deepfakes, which are
advanced Generative AI (GenAI) fakes of real people. This conceptual paper
assesses the current literature on deepfakes across multiple disciplines by
conducting an initial scoping review of 182 peer-reviewed publications.
  The review reveals three major trends: detection methods, malicious
applications, and potential benefits, although no specific studies on deepfakes
in the tertiary educational context were found. Following a discussion of these
trends, this study applies the findings to postulate the major risks and
potential mitigation strategies of deepfake technologies in higher education,
as well as potential beneficial uses to aid the teaching and learning of both
deepfakes and synthetic media. This culminates in the proposal of a research
agenda to build a comprehensive, cross-cultural approach to investigate
deepfakes in higher education.",2024-04-24,2024,2024-04,education
"Leveraging Prompts in LLMs to Overcome Imbalances in Complex Educational
  Text Data","In this paper, we explore the potential of Large Language Models (LLMs) with
assertions to mitigate imbalances in educational datasets. Traditional models
often fall short in such contexts, particularly due to the complexity and
nuanced nature of the data. This issue is especially prominent in the education
sector, where cognitive engagement levels among students show significant
variation in their open responses. To test our hypothesis, we utilized an
existing technology for assertion-based prompt engineering through an
'Iterative - ICL PE Design Process' comparing traditional Machine Learning (ML)
models against LLMs augmented with assertions (N=135). Further, we conduct a
sensitivity analysis on a subset (n=27), examining the variance in model
performance concerning classification metrics and cognitive engagement levels
in each iteration. Our findings reveal that LLMs with assertions significantly
outperform traditional ML models, particularly in cognitive engagement levels
with minority representation, registering up to a 32% increase in F1-score.
Additionally, our sensitivity study indicates that incorporating targeted
assertions into the LLM tested on the subset enhances its performance by
11.94%. This improvement primarily addresses errors stemming from the model's
limitations in understanding context and resolving lexical ambiguities in
student responses.",2024-04-28,2024,2024-04,education
"AfricAIED 2024: 2nd Workshop on Artificial Intelligence in Education in
  Africa","Recent AI advancements offer transformative potential for global education,
yet their application often overlooks Africa's unique educational landscape.
AfricAIED 2024 will address this gap, spotlighting efforts to develop AI in
Education (AIED) systems tailored to Africa's needs. Building on the success of
the inaugural workshop, AfricAIED 2024 will feature an online AI Hackathon
focused on democratizing preparation for Ghana's National Science & Maths Quiz
(NSMQ). Participants will create open-source AI tools leveraging resources from
the Brilla AI project to level the academic playing field and enhance science
and math education across Africa. The workshop will showcase top competitors'
solutions, invite discussions on AIED opportunities and challenges in Africa,
and highlight the latest advancements in AI education integration. AfricAIED
2024 aims to foster collaboration and innovation, amplifying African voices in
the AIED community and driving positive change in African education through AI.",2024-04-30,2024,2024-04,education
ChatGPT in Data Visualization Education: A Student Perspective,"Unlike traditional educational chatbots that rely on pre-programmed
responses, large-language model-driven chatbots, such as ChatGPT, demonstrate
remarkable versatility to serve as a dynamic resource for addressing student
needs from understanding advanced concepts to solving complex problems. This
work explores the impact of such technology on student learning in an
interdisciplinary, project-oriented data visualization course. Throughout the
semester, students engaged with ChatGPT across four distinct projects,
designing and implementing data visualizations using a variety of tools such as
Tableau, D3, and Vega-lite. We collected conversation logs and reflection
surveys after each assignment and conducted interviews with selected students
to gain deeper insights into their experiences with ChatGPT. Our analysis
examined the advantages and barriers of using ChatGPT, students' querying
behavior, the types of assistance sought, and its impact on assignment outcomes
and engagement. We discuss design considerations for an educational solution
tailored for data visualization education, extending beyond ChatGPT's basic
interface.",2024-05-01,2024,2024-05,education
"CourseAssist: Pedagogically Appropriate AI Tutor for Computer Science
  Education","The growing enrollments in computer science courses and increase in class
sizes necessitate scalable, automated tutoring solutions to adequately support
student learning. While Large Language Models (LLMs) like GPT-4 have
demonstrated potential in assisting students through question-answering,
educators express concerns over student overreliance, miscomprehension of
generated code, and the risk of inaccurate answers. Rather than banning these
tools outright, we advocate for a constructive approach that harnesses the
capabilities of AI while mitigating potential risks. This poster introduces
CourseAssist, a novel LLM-based tutoring system tailored for computer science
education. Unlike generic LLM systems, CourseAssist uses retrieval-augmented
generation, user intent classification, and question decomposition to align AI
responses with specific course materials and learning objectives, thereby
ensuring pedagogical appropriateness of LLMs in educational settings. We
evaluated CourseAssist against a baseline of GPT-4 using a dataset of 50
question-answer pairs from a programming languages course, focusing on the
criteria of usefulness, accuracy, and pedagogical appropriateness. Evaluation
results show that CourseAssist significantly outperforms the baseline,
demonstrating its potential to serve as an effective learning assistant. We
have also deployed CourseAssist in 6 computer science courses at a large public
R1 research university reaching over 500 students. Interviews with 20 student
users show that CourseAssist improves computer science instruction by
increasing the accessibility of course-specific tutoring help and shortening
the feedback loop on their programming assignments. Future work will include
extensive pilot testing at more universities and exploring better collaborative
relationships between students, educators, and AI that improve computer science
learning experiences.",2024-05-01,2024,2024-05,education
A Manifesto for a Pro-Actively Responsible AI in Education,"This paper examines the historical foundations, current practices, and
emerging challenges for Artificial Intelligence in Education (AIED) within
broader AI practices. It highlights AIED's unique and rich potential for
contributing to the current AI policy and practices, especially in the context
of responsible AI. It also discusses the key gaps in the AIED field, which need
to be addressed by the community to elevate the field from a cottage industry
to the level where it will deservedly be seen as key to advancin AI research
and practical applications. The paper offers a five-point manifesto aimed to
revitalise AIED' contributions to education and broader AI community,
suggesting enhanced interdisciplinary collaboration, a broadened understanding
of AI's impact on human functioning, and commitment to setting agendas for
human-centred educational innovations.This approach positions AIED to
significantly influence educational technologies to achieve genuine positive
impact across diverse societal segments.",2024-05-03,2024,2024-05,education
"Modern Information Technologies in Scientific Research and Educational
  Activities","The monograph summarizes and analyzes the current state of scientific
research in the field of interactive artificial intelligence systems, text
generation systems, diagnostics of the competitiveness of specialists, in the
areas of correct color rendering in image formation, informatization of the
work of graduate students, accessible technology for creating three-dimensional
3D models. The monograph will be useful both to specialists and employees of
companies working in the IT field, as well as teachers, masters, students and
graduate students of higher educational institutions, as well as anyone
interested in issues related to information technology. The monograph was
compiled based on the results of the 16-th international scientific and
practical conference Information technologies and automation - 2023, which took
place in October 2023 at Odessa National University of Technology.",2024-05-04,2024,2024-05,education
"The Role of AI in Peer Support for Young People: A Study of Preferences
  for Human- and AI-Generated Responses","Generative Artificial Intelligence (AI) is integrated into everyday
technology, including news, education, and social media. AI has further
pervaded private conversations as conversational partners, auto-completion, and
response suggestions. As social media becomes young people's main method of
peer support exchange, we need to understand when and how AI can facilitate and
assist in such exchanges in a beneficial, safe, and socially appropriate way.
We asked 622 young people to complete an online survey and evaluate blinded
human- and AI-generated responses to help-seeking messages. We found that
participants preferred the AI-generated response to situations about
relationships, self-expression, and physical health. However, when addressing a
sensitive topic, like suicidal thoughts, young people preferred the human
response. We also discuss the role of training in online peer support exchange
and its implications for supporting young people's well-being. Disclaimer: This
paper includes sensitive topics, including suicide ideation. Reader discretion
is advised.",2024-05-04,2024,2024-05,education
"Can Large Language Models Make the Grade? An Empirical Study Evaluating
  LLMs Ability to Mark Short Answer Questions in K-12 Education","This paper presents reports on a series of experiments with a novel dataset
evaluating how well Large Language Models (LLMs) can mark (i.e. grade) open
text responses to short answer questions, Specifically, we explore how well
different combinations of GPT version and prompt engineering strategies
performed at marking real student answers to short answer across different
domain areas (Science and History) and grade-levels (spanning ages 5-16) using
a new, never-used-before dataset from Carousel, a quizzing platform. We found
that GPT-4, with basic few-shot prompting performed well (Kappa, 0.70) and,
importantly, very close to human-level performance (0.75). This research builds
on prior findings that GPT-4 could reliably score short answer reading
comprehension questions at a performance-level very close to that of expert
human raters. The proximity to human-level performance, across a variety of
subjects and grade levels suggests that LLMs could be a valuable tool for
supporting low-stakes formative assessment tasks in K-12 education and has
important implications for real-world education delivery.",2024-05-05,2024,2024-05,education
"FOKE: A Personalized and Explainable Education Framework Integrating
  Foundation Models, Knowledge Graphs, and Prompt Engineering","Integrating large language models (LLMs) and knowledge graphs (KGs) holds
great promise for revolutionizing intelligent education, but challenges remain
in achieving personalization, interactivity, and explainability. We propose
FOKE, a Forest Of Knowledge and Education framework that synergizes foundation
models, knowledge graphs, and prompt engineering to address these challenges.
FOKE introduces three key innovations: (1) a hierarchical knowledge forest for
structured domain knowledge representation; (2) a multi-dimensional user
profiling mechanism for comprehensive learner modeling; and (3) an interactive
prompt engineering scheme for generating precise and tailored learning
guidance.
  We showcase FOKE's application in programming education, homework assessment,
and learning path planning, demonstrating its effectiveness and practicality.
Additionally, we implement Scholar Hero, a real-world instantiation of FOKE.
Our research highlights the potential of integrating foundation models,
knowledge graphs, and prompt engineering to revolutionize intelligent education
practices, ultimately benefiting learners worldwide. FOKE provides a principled
and unified approach to harnessing cutting-edge AI technologies for
personalized, interactive, and explainable educational services, paving the way
for further research and development in this critical direction.",2024-05-06,2024,2024-05,education
"Research information in the light of artificial intelligence: quality
  and data ecologies","This paper presents multi- and interdisciplinary approaches for finding the
appropriate AI technologies for research information. Professional research
information management (RIM) is becoming increasingly important as an expressly
data-driven tool for researchers. It is not only the basis of scientific
knowledge processes, but also related to other data. A concept and a process
model of the elementary phases from the start of the project to the ongoing
operation of the AI methods in the RIM is presented, portraying the
implementation of an AI project, meant to enable universities and research
institutions to support their researchers in dealing with incorrect and
incomplete research information, while it is being stored in their RIMs. Our
aim is to show how research information harmonizes with the challenges of data
literacy and data quality issues, related to AI, also wanting to underline that
any project can be successful if the research institutions and various
departments of universities, involved work together and appropriate support is
offered to improve research information and data management.",2024-05-06,2024,2024-05,education
"Enhancing LLM-Based Feedback: Insights from Intelligent Tutoring Systems
  and the Learning Sciences","The field of Artificial Intelligence in Education (AIED) focuses on the
intersection of technology, education, and psychology, placing a strong
emphasis on supporting learners' needs with compassion and understanding. The
growing prominence of Large Language Models (LLMs) has led to the development
of scalable solutions within educational settings, including generating
different types of feedback in Intelligent Tutoring Systems. However, the
approach to utilizing these models often involves directly formulating prompts
to solicit specific information, lacking a solid theoretical foundation for
prompt construction and empirical assessments of their impact on learning. This
work advocates careful and caring AIED research by going through previous
research on feedback generation in ITS, with emphasis on the theoretical
frameworks they utilized and the efficacy of the corresponding design in
empirical evaluations, and then suggesting opportunities to apply these
evidence-based principles to the design, experiment, and evaluation phases of
LLM-based feedback generation. The main contributions of this paper include: an
avocation of applying more cautious, theoretically grounded methods in feedback
generation in the era of generative AI; and practical suggestions on theory and
evidence-based feedback design for LLM-powered ITS.",2024-05-07,2024,2024-05,education
Benchmarking Educational Program Repair,"The emergence of large language models (LLMs) has sparked enormous interest
due to their potential application across a range of educational tasks. For
example, recent work in programming education has used LLMs to generate
learning resources, improve error messages, and provide feedback on code.
However, one factor that limits progress within the field is that much of the
research uses bespoke datasets and different evaluation metrics, making direct
comparisons between results unreliable. Thus, there is a pressing need for
standardization and benchmarks that facilitate the equitable comparison of
competing approaches. One task where LLMs show great promise is program repair,
which can be used to provide debugging support and next-step hints to students.
In this article, we propose a novel educational program repair benchmark. We
curate two high-quality publicly available programming datasets, present a
unified evaluation procedure introducing a novel evaluation metric rouge@k for
approximating the quality of repairs, and evaluate a set of five recent models
to establish baseline performance.",2024-05-08,2024,2024-05,education
The Potential and Implications of Generative AI on HCI Education,"Generative AI (GAI) is impacting teaching and learning directly or indirectly
across a range of subjects and disciplines. As educators, we need to understand
the potential and limitations of AI in HCI education and ensure our graduating
HCI students are aware of the potential and limitations of AI in HCI. In this
paper, we report on the main pedagogical insights gained from the inclusion of
generative AI into a 10 week undergraduate module. We designed the module to
encourage student experimentation with GAI models as part of the design brief
requirement and planned practical sessions and discussions. Our insights are
based on replies to a survey sent out to the students after completing the
module. Our key findings, for HCI educators, report on the use of AI as a
persona for developing project ideas and creating resources for design, and AI
as a mirror for reflecting students' understanding of key concepts and ideas
and highlighting knowledge gaps. We also discuss potential pitfalls that should
be considered and the need to assess students' literacies and assumptions of
GAIs as pedagogical tools. Finally, we put forward the case for educators to
take the opportunities GAI presents as an educational tool and be experimental,
creative, and courageous in their practice. We end with a discussion of our
findings in relation to the TPACK framework in HCI.",2024-05-08,2024,2024-05,education
"Evaluating Students' Open-ended Written Responses with LLMs: Using the
  RAG Framework for GPT-3.5, GPT-4, Claude-3, and Mistral-Large","Evaluating open-ended written examination responses from students is an
essential yet time-intensive task for educators, requiring a high degree of
effort, consistency, and precision. Recent developments in Large Language
Models (LLMs) present a promising opportunity to balance the need for thorough
evaluation with efficient use of educators' time. In our study, we explore the
effectiveness of LLMs ChatGPT-3.5, ChatGPT-4, Claude-3, and Mistral-Large in
assessing university students' open-ended answers to questions made about
reference material they have studied. Each model was instructed to evaluate 54
answers repeatedly under two conditions: 10 times (10-shot) with a temperature
setting of 0.0 and 10 times with a temperature of 0.5, expecting a total of
1,080 evaluations per model and 4,320 evaluations across all models. The RAG
(Retrieval Augmented Generation) framework was used as the framework to make
the LLMs to process the evaluation of the answers. As of spring 2024, our
analysis revealed notable variations in consistency and the grading outcomes
provided by studied LLMs. There is a need to comprehend strengths and
weaknesses of LLMs in educational settings for evaluating open-ended written
responses. Further comparative research is essential to determine the accuracy
and cost-effectiveness of using LLMs for educational assessments.",2024-05-08,2024,2024-05,education
Iris: An AI-Driven Virtual Tutor For Computer Science Education,"Integrating AI-driven tools in higher education is an emerging area with
transformative potential. This paper introduces Iris, a chat-based virtual
tutor integrated into the interactive learning platform Artemis that offers
personalized, context-aware assistance in large-scale educational settings.
Iris supports computer science students by guiding them through programming
exercises and is designed to act as a tutor in a didactically meaningful way.
Its calibrated assistance avoids revealing complete solutions, offering subtle
hints or counter-questions to foster independent problem-solving skills. For
each question, it issues multiple prompts in a Chain-of-Thought to
GPT-3.5-Turbo. The prompts include a tutor role description and examples of
meaningful answers through few-shot learning. Iris employs contextual awareness
by accessing the problem statement, student code, and automated feedback to
provide tailored advice.
  An empirical evaluation shows that students perceive Iris as effective
because it understands their questions, provides relevant support, and
contributes to the learning process. While students consider Iris a valuable
tool for programming exercises and homework, they also feel confident solving
programming tasks in computer-based exams without Iris. The findings underscore
students' appreciation for Iris' immediate and personalized support, though
students predominantly view it as a complement to, rather than a replacement
for, human tutors. Nevertheless, Iris creates a space for students to ask
questions without being judged by others.",2024-05-09,2024,2024-05,education
Large Language Models for Education: A Survey,"Artificial intelligence (AI) has a profound impact on traditional education.
In recent years, large language models (LLMs) have been increasingly used in
various applications such as natural language processing, computer vision,
speech recognition, and autonomous driving. LLMs have also been applied in many
fields, including recommendation, finance, government, education, legal
affairs, and finance. As powerful auxiliary tools, LLMs incorporate various
technologies such as deep learning, pre-training, fine-tuning, and
reinforcement learning. The use of LLMs for smart education (LLMEdu) has been a
significant strategic direction for countries worldwide. While LLMs have shown
great promise in improving teaching quality, changing education models, and
modifying teacher roles, the technologies are still facing several challenges.
In this paper, we conduct a systematic review of LLMEdu, focusing on current
technologies, challenges, and future developments. We first summarize the
current state of LLMEdu and then introduce the characteristics of LLMs and
education, as well as the benefits of integrating LLMs into education. We also
review the process of integrating LLMs into the education industry, as well as
the introduction of related technologies. Finally, we discuss the challenges
and problems faced by LLMEdu, as well as prospects for future optimization of
LLMEdu.",2024-05-12,2024,2024-05,education
"Realizing Visual Question Answering for Education: GPT-4V as a
  Multimodal AI","Educational scholars have analyzed various image data acquired from teaching
and learning situations, such as photos that shows classroom dynamics,
students' drawings with regard to the learning content, textbook illustrations,
etc. Unquestioningly, most qualitative analysis of and explanation on image
data have been conducted by human researchers, without machine-based
automation. It was partially because most image processing artificial
intelligence models were not accessible to general educational scholars or
explainable due to their complex deep neural network architecture. However, the
recent development of Visual Question Answering (VQA) techniques is
accomplishing usable visual language models, which receive from the user a
question about the given image and returns an answer, both in natural language.
Particularly, GPT-4V released by OpenAI, has wide opened the state-of-the-art
visual langauge model service so that VQA could be used for a variety of
purposes. However, VQA and GPT-4V have not yet been applied to educational
studies much. In this position paper, we suggest that GPT-4V contributes to
realizing VQA for education. By 'realizing' VQA, we denote two meanings: (1)
GPT-4V realizes the utilization of VQA techniques by any educational scholars
without technical/accessibility barrier, and (2) GPT-4V makes educational
scholars realize the usefulness of VQA to educational research. Given these,
this paper aims to introduce VQA for educational studies so that it provides a
milestone for educational research methodology. In this paper, chapter II
reviews the development of VQA techniques, which primes with the release of
GPT-4V. Chapter III reviews the use of image analysis in educational studies.
Chapter IV demonstrates how GPT-4V can be used for each research usage reviewed
in Chapter III, with operating prompts provided. Finally, chapter V discusses
the future implications.",2024-05-12,2024,2024-05,education
"Interpreting Latent Student Knowledge Representations in Programming
  Assignments","Recent advances in artificial intelligence for education leverage generative
large language models, including using them to predict open-ended student
responses rather than their correctness only. However, the black-box nature of
these models limits the interpretability of the learned student knowledge
representations. In this paper, we conduct a first exploration into
interpreting latent student knowledge representations by presenting InfoOIRT,
an Information regularized Open-ended Item Response Theory model, which
encourages the latent student knowledge states to be interpretable while being
able to generate student-written code for open-ended programming questions.
InfoOIRT maximizes the mutual information between a fixed subset of latent
knowledge states enforced with simple prior distributions and generated student
code, which encourages the model to learn disentangled representations of
salient syntactic and semantic code features including syntactic styles,
mastery of programming skills, and code structures. Through experiments on a
real-world programming education dataset, we show that InfoOIRT can both
accurately generate student code and lead to interpretable student knowledge
representations.",2024-05-13,2024,2024-05,education
"Intelligent Tutor: Leveraging ChatGPT and Microsoft Copilot Studio to
  Deliver a Generative AI Student Support and Feedback System within Teams","This study explores the integration of the ChatGPT API with GPT-4 model and
Microsoft Copilot Studio on the Microsoft Teams platform to develop an
intelligent tutoring system. Designed to provide instant support to students,
the system dynamically adjusts educational content in response to the learners'
progress and feedback. Utilizing advancements in natural language processing
and machine learning, it interprets student inquiries, offers tailored
feedback, and facilitates the educational journey. Initial implementation
highlights the system's potential in boosting students' motivation and
engagement, while equipping educators with critical insights into the learning
process, thus promoting tailored educational experiences and enhancing
instructional effectiveness.",2024-05-15,2024,2024-05,education
StyloAI: Distinguishing AI-Generated Content with Stylometric Analysis,"The emergence of large language models (LLMs) capable of generating realistic
texts and images has sparked ethical concerns across various sectors. In
response, researchers in academia and industry are actively exploring methods
to distinguish AI-generated content from human-authored material. However, a
crucial question remains: What are the unique characteristics of AI-generated
text? Addressing this gap, this study proposes StyloAI, a data-driven model
that uses 31 stylometric features to identify AI-generated texts by applying a
Random Forest classifier on two multi-domain datasets. StyloAI achieves
accuracy rates of 81% and 98% on the test set of the AuTextification dataset
and the Education dataset, respectively. This approach surpasses the
performance of existing state-of-the-art models and provides valuable insights
into the differences between AI-generated and human-authored texts.",2024-05-16,2024,2024-05,education
"ChatGPT in Classrooms: Transforming Challenges into Opportunities in
  Education","In the era of exponential technology growth, one unexpected guest has claimed
a seat in classrooms worldwide, Artificial Intelligence. Generative AI, such as
ChatGPT, promises a revolution in education, yet it arrives with a double-edged
sword. Its potential for personalized learning is offset by issues of cheating,
inaccuracies, and educators struggling to incorporate it effectively into their
lesson design. We are standing on the brink of this educational frontier, and
it is clear that we need to navigate this terrain with a lot of care. This is a
major challenge that could undermine the integrity and value of our educational
process. So, how can we turn these challenges into opportunities? When used
inappropriately, AI tools can become the perfect tool for the cut copy paste
mentality, and quickly begin to corrode critical thinking, creativity, and deep
understanding, the most important skills in our rapidly changing world.
Teachers feel that they are not equipped to leverage this technology, widening
the digital divide among educators and institutions. Addressing these concerns
calls for an in depth research approach. We will employ empirical research,
drawing on the Technology Acceptance Model, to assess the attitudes toward
generative AI among educators and students. Understanding their perceptions,
usage patterns, and hurdles is the first crucial step in creating an effective
solution. The present study will be used as a process manual for future
researchers to apply, running their own data, based on the steps explained here",2024-05-17,2024,2024-05,education
"Sociotechnical Implications of Generative Artificial Intelligence for
  Information Access","Robust access to trustworthy information is a critical need for society with
implications for knowledge production, public health education, and promoting
informed citizenry in democratic societies. Generative AI technologies may
enable new ways to access information and improve effectiveness of existing
information retrieval systems but we are only starting to understand and
grapple with their long-term social implications. In this chapter, we present
an overview of some of the systemic consequences and risks of employing
generative AI in the context of information access. We also provide
recommendations for evaluation and mitigation, and discuss challenges for
future research.",2024-05-19,2024,2024-05,education
"Exploring the Capabilities of Prompted Large Language Models in
  Educational and Assessment Applications","In the era of generative artificial intelligence (AI), the fusion of large
language models (LLMs) offers unprecedented opportunities for innovation in the
field of modern education. We embark on an exploration of prompted LLMs within
the context of educational and assessment applications to uncover their
potential. Through a series of carefully crafted research questions, we
investigate the effectiveness of prompt-based techniques in generating
open-ended questions from school-level textbooks, assess their efficiency in
generating open-ended questions from undergraduate-level technical textbooks,
and explore the feasibility of employing a chain-of-thought inspired
multi-stage prompting approach for language-agnostic multiple-choice question
(MCQ) generation. Additionally, we evaluate the ability of prompted LLMs for
language learning, exemplified through a case study in the low-resource Indian
language Bengali, to explain Bengali grammatical errors. We also evaluate the
potential of prompted LLMs to assess human resource (HR) spoken interview
transcripts. By juxtaposing the capabilities of LLMs with those of human
experts across various educational tasks and domains, our aim is to shed light
on the potential and limitations of LLMs in reshaping educational practices.",2024-05-19,2024,2024-05,education
"Exploring Teachers' Perception of Artificial Intelligence: The
  Socio-emotional Deficiency as Opportunities and Challenges in Human-AI
  Complementarity in K-12 Education","In schools, teachers play a multitude of roles, serving as educators,
counselors, decision-makers, and members of the school community. With recent
advances in artificial intelligence (AI), there is increasing discussion about
how AI can assist, complement, and collaborate with teachers. To pave the way
for better teacher-AI complementary relationships in schools, our study aims to
expand the discourse on teacher-AI complementarity by seeking educators'
perspectives on the potential strengths and limitations of AI across a spectrum
of responsibilities. Through a mixed method using a survey with 100 elementary
school teachers in South Korea and in-depth interviews with 12 teachers, our
findings indicate that teachers anticipate AI's potential to complement human
teachers by automating administrative tasks and enhancing personalized learning
through advanced intelligence. Interestingly, the deficit of AI's
socio-emotional capabilities has been perceived as both challenges and
opportunities. Overall, our study demonstrates the nuanced perception of
teachers and different levels of expectations over their roles, challenging the
need for decisions about AI adoption tailored to educators' preferences and
concerns.",2024-05-20,2024,2024-05,education
A review on the use of large language models as virtual tutors,"Transformer architectures contribute to managing long-term dependencies for
Natural Language Processing, representing one of the most recent changes in the
field. These architectures are the basis of the innovative, cutting-edge Large
Language Models (LLMs) that have produced a huge buzz in several fields and
industrial sectors, among the ones education stands out. Accordingly, these
generative Artificial Intelligence-based solutions have directed the change in
techniques and the evolution in educational methods and contents, along with
network infrastructure, towards high-quality learning. Given the popularity of
LLMs, this review seeks to provide a comprehensive overview of those solutions
designed specifically to generate and evaluate educational materials and which
involve students and teachers in their design or experimental plan. To the best
of our knowledge, this is the first review of educational applications (e.g.,
student assessment) of LLMs. As expected, the most common role of these systems
is as virtual tutors for automatic question generation. Moreover, the most
popular models are GTP-3 and BERT. However, due to the continuous launch of new
generative models, new works are expected to be published shortly.",2024-05-20,2024,2024-05,education
"Generative AI in Higher Education: A Global Perspective of Institutional
  Adoption Policies and Guidelines","Integrating generative AI (GAI) into higher education is crucial for
preparing a future generation of GAI-literate students. Yet a thorough
understanding of the global institutional adoption policy remains absent, with
most of the prior studies focused on the Global North and the promises and
challenges of GAI, lacking a theoretical lens. This study utilizes the
Diffusion of Innovations Theory to examine GAI adoption strategies in higher
education across 40 universities from six global regions. It explores the
characteristics of GAI innovation, including compatibility, trialability, and
observability, and analyses the communication channels and roles and
responsibilities outlined in university policies and guidelines. The findings
reveal a proactive approach by universities towards GAI integration,
emphasizing academic integrity, teaching and learning enhancement, and equity.
Despite a cautious yet optimistic stance, a comprehensive policy framework is
needed to evaluate the impacts of GAI integration and establish effective
communication strategies that foster broader stakeholder engagement. The study
highlights the importance of clear roles and responsibilities among faculty,
students, and administrators for successful GAI integration, supporting a
collaborative model for navigating the complexities of GAI in education. This
study contributes insights for policymakers in crafting detailed strategies for
its integration.",2024-05-20,2024,2024-05,education
Generating A Crowdsourced Conversation Dataset to Combat Cybergrooming,"Cybergrooming emerges as a growing threat to adolescent safety and mental
health. One way to combat cybergrooming is to leverage predictive artificial
intelligence (AI) to detect predatory behaviors in social media. However, these
methods can encounter challenges like false positives and negative implications
such as privacy concerns. Another complementary strategy involves using
generative artificial intelligence to empower adolescents by educating them
about predatory behaviors. To this end, we envision developing state-of-the-art
conversational agents to simulate the conversations between adolescents and
predators for educational purposes. Yet, one key challenge is the lack of a
dataset to train such conversational agents. In this position paper, we present
our motivation for empowering adolescents to cope with cybergrooming. We
propose to develop large-scale, authentic datasets through an online survey
targeting adolescents and parents. We discuss some initial background behind
our motivation and proposed design of the survey, such as situating the
participants in artificial cybergrooming scenarios, then allowing participants
to respond to the survey to obtain their authentic responses. We also present
several open questions related to our proposed approach and hope to discuss
them with the workshop attendees.",2024-05-21,2024,2024-05,education
"Qualitative and quantitative analysis of student's perceptions in the
  use of generative AI in educational environments","The effective integration of generative artificial intelligence in education
is a fundamental aspect to prepare future generations. The objective of this
study is to analyze from a quantitative and qualitative point of view the
perception of controlled student-IA interaction within the classroom. This
analysis includes assessing the ethical implications and everyday use of AI
tools, as well as understanding whether AI tools encourage students to pursue
STEM careers. Several points for improvement in education are found, such as
the challenge of getting teachers to engage with new technologies and adapt
their methods in all subjects, not just those related to technologies.",2024-05-22,2024,2024-05,education
"Towards Educator-Driven Tutor Authoring: Generative AI Approaches for
  Creating Intelligent Tutor Interfaces","Intelligent Tutoring Systems (ITSs) have shown great potential in delivering
personalized and adaptive education, but their widespread adoption has been
hindered by the need for specialized programming and design skills. Existing
approaches overcome the programming limitations with no-code authoring through
drag and drop, however they assume that educators possess the necessary skills
to design effective and engaging tutor interfaces. To address this assumption
we introduce generative AI capabilities to assist educators in creating tutor
interfaces that meet their needs while adhering to design principles. Our
approach leverages Large Language Models (LLMs) and prompt engineering to
generate tutor layout and contents based on high-level requirements provided by
educators as inputs. However, to allow them to actively participate in the
design process, rather than relying entirely on AI-generated solutions, we
allow generation both at the entire interface level and at the individual
component level. The former provides educators with a complete interface that
can be refined using direct manipulation, while the latter offers the ability
to create specific elements to be added to the tutor interface. A small-scale
comparison shows the potential of our approach to enhance the efficiency of
tutor interface design. Moving forward, we raise critical questions for
assisting educators with generative AI capabilities to create personalized,
effective, and engaging tutors, ultimately enhancing their adoption.",2024-05-23,2024,2024-05,education
ChatGPT Code Detection: Techniques for Uncovering the Source of Code,"In recent times, large language models (LLMs) have made significant strides
in generating computer code, blurring the lines between code created by humans
and code produced by artificial intelligence (AI). As these technologies evolve
rapidly, it is crucial to explore how they influence code generation,
especially given the risk of misuse in areas like higher education. This paper
explores this issue by using advanced classification techniques to
differentiate between code written by humans and that generated by ChatGPT, a
type of LLM. We employ a new approach that combines powerful embedding features
(black-box) with supervised learning algorithms - including Deep Neural
Networks, Random Forests, and Extreme Gradient Boosting - to achieve this
differentiation with an impressive accuracy of 98%. For the successful
combinations, we also examine their model calibration, showing that some of the
models are extremely well calibrated. Additionally, we present white-box
features and an interpretable Bayes classifier to elucidate critical
differences between the code sources, enhancing the explainability and
transparency of our approach. Both approaches work well but provide at most
85-88% accuracy. We also show that untrained humans solve the same task not
better than random guessing. This study is crucial in understanding and
mitigating the potential risks associated with using AI in code generation,
particularly in the context of higher education, software development, and
competitive programming.",2024-05-24,2024,2024-05,education
"The global landscape of academic guidelines for generative AI and Large
  Language Models","The integration of Generative Artificial Intelligence (GAI) and Large
Language Models (LLMs) in academia has spurred a global discourse on their
potential pedagogical benefits and ethical considerations. Positive reactions
highlight some potential, such as collaborative creativity, increased access to
education, and empowerment of trainers and trainees. However, negative
reactions raise concerns about ethical complexities, balancing innovation and
academic integrity, unequal access, and misinformation risks. Through a
systematic survey and text-mining-based analysis of global and national
directives, insights from independent research, and eighty university-level
guidelines, this study provides a nuanced understanding of the opportunities
and challenges posed by GAI and LLMs in education. It emphasizes the importance
of balanced approaches that harness the benefits of these technologies while
addressing ethical considerations and ensuring equitable access and educational
outcomes. The paper concludes with recommendations for fostering responsible
innovation and ethical practices to guide the integration of GAI and LLMs in
academia.",2024-05-26,2024,2024-05,education
"Building Better AI Agents: A Provocation on the Utilisation of Persona
  in LLM-based Conversational Agents","The incorporation of Large Language Models (LLMs) such as the GPT series into
diverse sectors including healthcare, education, and finance marks a
significant evolution in the field of artificial intelligence (AI). The
increasing demand for personalised applications motivated the design of
conversational agents (CAs) to possess distinct personas. This paper commences
by examining the rationale and implications of imbuing CAs with unique
personas, smoothly transitioning into a broader discussion of the
personalisation and anthropomorphism of CAs based on LLMs in the LLM era. We
delve into the specific applications where the implementation of a persona is
not just beneficial but critical for LLM-based CAs. The paper underscores the
necessity of a nuanced approach to persona integration, highlighting the
potential challenges and ethical dilemmas that may arise. Attention is directed
towards the importance of maintaining persona consistency, establishing robust
evaluation mechanisms, and ensuring that the persona attributes are effectively
complemented by domain-specific knowledge.",2024-05-26,2024,2024-05,education
"Adoption and Impact of ChatGPT in Computer Science Education: A Case
  Study on a Database Administration Course","Contribution: The combination of ChatGPT with traditional learning resources
is very effective in computer science education. High-performing students are
the ones who are using ChatGPT the most. So, a new digital trench could be
rising between these students and those with lower degree of fundamentals and
worse prompting skills, who may not take advantage of all the ChatGPT
possibilities. Background: The irruption of GenAI such as ChatGPT has changed
the educational landscape. Therefore, methodological guidelines and more
empirical experiences in computer science education are needed to better
understand these tools and know how to use them to their fullest potential.
Research Questions: This article addresses three questions. The first two
explore the degree of use and perceived usefulness of ChatGPT among computer
science students to learn database administration, where as the third one
explore how the utilization of ChatGPT can impact academic performance.
Methodology: This contribution presents an exploratory and correlational study
conducted with 37 students who used ChatGPT as a support tool to learn database
administration. The student grades and a comprehensive questionnaire were
employed as research instruments. Findings: The obtained results indicate that
traditional learning resources, such as teacher explanations and student
reports, were widely used and correlated positively with student grade. The
usage and perceived utility of ChatGPT were moderate, but positive correlations
between student grade and ChatGPT usage were found. Indeed, a significantly
higher use of this tool was identified among the group of outstanding students.",2024-05-26,2024,2024-05,education
Towards Integrating Emerging AI Applications in SE Education,"Artificial Intelligence (AI) approaches have been incorporated into modern
learning environments and software engineering (SE) courses and curricula for
several years. However, with the significant rise in popularity of large
language models (LLMs) in general, and OpenAI's LLM-powered chatbot ChatGPT in
particular in the last year, educators are faced with rapidly changing
classroom environments and disrupted teaching principles. Examples range from
programming assignment solutions that are fully generated via ChatGPT, to
various forms of cheating during exams. However, despite these negative aspects
and emerging challenges, AI tools in general, and LLM applications in
particular, can also provide significant opportunities in a wide variety of SE
courses, supporting both students and educators in meaningful ways. In this
early research paper, we present preliminary results of a systematic analysis
of current trends in the area of AI, and how they can be integrated into
university-level SE curricula, guidelines, and approaches to support both
instructors and learners. We collected both teaching and research papers and
analyzed their potential usage in SE education, using the ACM Computer Science
Curriculum Guidelines CS2023. As an initial outcome, we discuss a series of
opportunities for AI applications and further research areas.",2024-05-28,2024,2024-05,education
"Interpret3C: Interpretable Student Clustering Through Individualized
  Feature Selection","Clustering in education, particularly in large-scale online environments like
MOOCs, is essential for understanding and adapting to diverse student needs.
However, the effectiveness of clustering depends on its interpretability, which
becomes challenging with high-dimensional data. Existing clustering approaches
often neglect individual differences in feature importance and rely on a
homogenized feature set. Addressing this gap, we introduce Interpret3C
(Interpretable Conditional Computation Clustering), a novel clustering pipeline
that incorporates interpretable neural networks (NNs) in an unsupervised
learning context. This method leverages adaptive gating in NNs to select
features for each student. Then, clustering is performed using the most
relevant features per student, enhancing clusters' relevance and
interpretability. We use Interpret3C to analyze the behavioral clusters
considering individual feature importances in a MOOC with over 5,000 students.
This research contributes to the field by offering a scalable, robust
clustering methodology and an educational case study that respects individual
student differences and improves interpretability for high-dimensional data.",2024-05-28,2024,2024-05,education
"Challenge-Device-Synthesis: A multi-disciplinary approach for the
  development of social innovation competences for students of Artificial
  Intelligence","The advent of Artificial Intelligence is expected to imply profound changes
in the short-term. It is therefore imperative for Academia, and particularly
for the Computer Science scope, to develop cross-disciplinary tools that bond
AI developments to their social dimension. To this aim, we introduce the
Challenge-Device-Synthesis methodology (CDS), in which a specific challenge is
presented to the students of AI, who are required to develop a device as a
solution for the challenge. The device becomes the object of study for the
different dimensions of social transformation, and the conclusions addressed by
the students during the discussion around the device are presented in a
synthesis piece in the shape of a 10-page scientific paper. The latter is
evaluated taking into account both the depth of analysis and the level to which
it genuinely reflects the social transformations associated with the proposed
AI-based device. We provide data obtained during the pilot for the
implementation phase of CDS within the subject of Social Innovation, a 6-ECTS
subject from the 6th semester of the Degree of Artificial Intelligence,
UAB-Barcelona. We provide details on temporalisation, task distribution,
methodological tools used and assessment delivery procedure, as well as
qualitative analysis of the results obtained.",2024-05-29,2024,2024-05,education
"The Future of Child Development in the AI Era. Cross-Disciplinary
  Perspectives Between AI and Child Development Experts","This report explores the potential implications of rapidly integrating
Artificial Intelligence (AI) applications into children's environments. The
introduction of AI in our daily lives necessitates scrutiny considering the
significant role of the environment in shaping cognition, socio-emotional
skills, and behaviors, especially during the first 25 years of cerebral
development. As AI becomes prevalent in educational and leisure activities, it
will significantly modify the experiences of children and adolescents,
presenting both challenges and opportunities for their developmental
trajectories. This analysis was informed by consulting with 15 experts from
pertinent disciplines (AI, product development, child development, and
neurosciences), along with a comprehensive review of scientific literature on
children development and child-technology interactions. Overall, AI experts
anticipate that AI will transform leisure activities, revolutionize education,
and redefine human-machine interactions. While AI offers substantial benefits
in fostering interactive engagement, it also poses risks that require careful
considerations, especially during sensitive developmental periods. The report
advocates for proactive international collaboration across multiple disciplines
and increased research into how technological innovations affect child
development. Such efforts are crucial for designing a sustainable and ethical
future for the next generation through specific child-centered regulations, and
helping to educate all potential stakeholders (regulators, developers, parents
and educators, children) about responsible AI use and its potential impacts on
child development.",2024-05-29,2024,2024-05,education
Probabilities of Causation for Continuous and Vector Variables,"Probabilities of causation (PoC) are valuable concepts for explainable
artificial intelligence and practical decision-making. PoC are originally
defined for scalar binary variables. In this paper, we extend the concept of
PoC to continuous treatment and outcome variables, and further generalize PoC
to capture causal effects between multiple treatments and multiple outcomes. In
addition, we consider PoC for a sub-population and PoC with multi-hypothetical
terms to capture more sophisticated counterfactual information useful for
decision-making. We provide a nonparametric identification theorem for each
type of PoC we introduce. Finally, we illustrate the application of our results
on a real-world dataset about education.",2024-05-30,2024,2024-05,education
"A Survey Study on the State of the Art of Programming Exercise
  Generation using Large Language Models","This paper analyzes Large Language Models (LLMs) with regard to their
programming exercise generation capabilities. Through a survey study, we
defined the state of the art, extracted their strengths and weaknesses and
finally proposed an evaluation matrix, helping researchers and educators to
decide which LLM is the best fitting for the programming exercise generation
use case. We also found that multiple LLMs are capable of producing useful
programming exercises. Nevertheless, there exist challenges like the ease with
which LLMs might solve exercises generated by LLMs. This paper contributes to
the ongoing discourse on the integration of LLMs in education.",2024-05-30,2024,2024-05,education
"Lifelong learning challenges in the era of artificial intelligence: a
  computational thinking perspective","The rapid advancement of artificial intelligence (AI) has brought significant
challenges to the education and workforce skills required to take advantage of
AI for human-AI collaboration in the workplace. As AI continues to reshape
industries and job markets, the need to define how AI literacy can be
considered in lifelong learning has become increasingly critical (Cetindamar et
al., 2022; Laupichler et al., 2022; Romero et al., 2023). Like any new
technology, AI is the subject of both hopes and fears, and what it entails
today presents major challenges (Cugurullo \& Acheampong, 2023; Villani et al.,
2018). It also raises profound questions about our own humanity. Will the
machine surpass the intelligence of the humans who designed it? What will be
the relationship between so-called AI and our human intelligences? How could
human-AI collaboration be regulated in a way that serves the Sustainable
Development Goals (SDGs)? This paper provides a review of the challenges of
lifelong learning in the era of AI from a computational thinking, critical
thinking, and creative competencies perspective, highlighting the implications
for management and leadership in organizations.",2024-05-30,2024,2024-05,education
An Automatic Question Usability Evaluation Toolkit,"Evaluating multiple-choice questions (MCQs) involves either labor intensive
human assessments or automated methods that prioritize readability, often
overlooking deeper question design flaws. To address this issue, we introduce
the Scalable Automatic Question Usability Evaluation Toolkit (SAQUET), an
open-source tool that leverages the Item-Writing Flaws (IWF) rubric for a
comprehensive and automated quality evaluation of MCQs. By harnessing the
latest in large language models such as GPT-4, advanced word embeddings, and
Transformers designed to analyze textual complexity, SAQUET effectively
pinpoints and assesses a wide array of flaws in MCQs. We first demonstrate the
discrepancy between commonly used automated evaluation metrics and the human
assessment of MCQ quality. Then we evaluate SAQUET on a diverse dataset of MCQs
across the five domains of Chemistry, Statistics, Computer Science, Humanities,
and Healthcare, showing how it effectively distinguishes between flawed and
flawless questions, providing a level of analysis beyond what is achievable
with traditional metrics. With an accuracy rate of over 94% in detecting the
presence of flaws identified by human evaluators, our findings emphasize the
limitations of existing evaluation methods and showcase potential in improving
the quality of educational assessments.",2024-05-30,2024,2024-05,education
"Synthetic Patients: Simulating Difficult Conversations with Multimodal
  Generative AI for Medical Education","Problem: Effective patient-centered communication is a core competency for
physicians. However, both seasoned providers and medical trainees report
decreased confidence in leading conversations on sensitive topics such as goals
of care or end-of-life discussions. The significant administrative burden and
the resources required to provide dedicated training in leading difficult
conversations has been a long-standing problem in medical education.
  Approach: In this work, we present a novel educational tool designed to
facilitate interactive, real-time simulations of difficult conversations in a
video-based format through the use of multimodal generative artificial
intelligence (AI). Leveraging recent advances in language modeling, computer
vision, and generative audio, this tool creates realistic, interactive
scenarios with avatars, or ""synthetic patients."" These synthetic patients
interact with users throughout various stages of medical care using a
custom-built video chat application, offering learners the chance to practice
conversations with patients from diverse belief systems, personalities, and
ethnic backgrounds.
  Outcomes: While the development of this platform demanded substantial upfront
investment in labor, it offers a highly-realistic simulation experience with
minimal financial investment. For medical trainees, this educational tool can
be implemented within programs to simulate patient-provider conversations and
can be incorporated into existing palliative care curriculum to provide a
scalable, high-fidelity simulation environment for mastering difficult
conversations.
  Next Steps: Future developments will explore enhancing the authenticity of
these encounters by working with patients to incorporate their histories and
personalities, as well as employing the use of AI-generated evaluations to
offer immediate, constructive feedback to learners post-simulation.",2024-05-30,2024,2024-05,education
Visions of a Discipline: Analyzing Introductory AI Courses on YouTube,"Education plays an indispensable role in fostering societal well-being and is
widely regarded as one of the most influential factors in shaping the future of
generations to come. As artificial intelligence (AI) becomes more deeply
integrated into our daily lives and the workforce, educational institutions at
all levels are directing their focus on resources that cater to AI education.
Our work investigates the current landscape of introductory AI courses on
YouTube, and the potential for introducing ethics in this context. We
qualitatively analyze the 20 most watched introductory AI courses on YouTube,
coding a total of 92.2 hours of educational content viewed by close to 50
million people. Introductory AI courses do not meaningfully engage with ethical
or societal challenges of AI (RQ1). When \textit{defining and framing AI},
introductory AI courses foreground excitement around AI's transformative role
in society, over-exaggerate AI's current and future abilities, and
anthropomorphize AI (RQ2). In \textit{teaching AI}, we see a widespread
reliance on corporate AI tools and frameworks as well as a prioritization on a
hands-on approach to learning rather than on conceptual foundations (RQ3). In
promoting key \textit{AI practices}, introductory AI courses abstract away
entirely the socio-technical nature of AI classification and prediction, for
example by favoring data quantity over data quality (RQ4). We extend our
analysis with recommendations that aim to integrate ethical reflections into
introductory AI courses. We recommend that introductory AI courses should (1)
highlight ethical challenges of AI to present a more balanced perspective, (2)
raise ethical issues explicitly relevant to the technical concepts discussed
and (3) nurture a sense of accountability in future AI developers.",2024-05-31,2024,2024-05,education
Comparative Analysis Vision of Worldwide AI Courses,"This research investigates the curriculum structures of undergraduate
Artificial Intelligence (AI) education across universities worldwide. By
examining the curricula of leading universities, the research seeks to
contribute to a deeper understanding of AI education on a global scale,
facilitating the alignment of educational practices with the evolving needs of
the AI landscape. This research delves into the diverse course structures of
leading universities, exploring contemporary trends and priorities to reveal
the nuanced approaches in AI education. It also investigates the core AI topics
and learning contents frequently taught, comparing them with the CS2023
curriculum guidance to identify convergence and divergence. Additionally, it
examines how universities across different countries approach AI education,
analyzing educational objectives, priorities, potential careers, and
methodologies to understand the global landscape and implications of AI
pedagogy.",2024-06-04,2024,2024-06,education
"Generative AI and Digital Neocolonialism in Global Education: Towards an
  Equitable Framework","This paper critically discusses how generative artificial intelligence
(GenAI) might impose Western ideologies on non-Western societies, perpetuating
digital neocolonialism in education through its inherent biases. It further
suggests strategies for local and global stakeholders to mitigate these
effects. Our discussions demonstrated that GenAI can foster cultural
imperialism by generating content that primarily incorporates cultural
references and examples relevant to Western students, thereby alienating
students from non-Western backgrounds. Also, the predominant use of Western
languages by GenAI can marginalize non-dominant languages, making educational
content less accessible to speakers of indigenous languages and potentially
impacting their ability to learn in their first language. Additionally, GenAI
often generates content and curricula that reflect the perspectives of
technologically dominant countries, overshadowing marginalized indigenous
knowledge and practices. Moreover, the cost of access to GenAI intensifies
educational inequality and the control of GenAI data could lead to commercial
exploitation without benefiting local students and their communities. We
propose human-centric reforms to prioritize cultural diversity and equity in
GenAI development; a liberatory design to empower educators and students to
identify and dismantle the oppressive structures within GenAI applications;
foresight by design to create an adjustable GenAI system to meet future
educational needs; and finally, effective prompting skills to reduce the
retrieval of neocolonial outputs.",2024-06-05,2024,2024-06,education
"Unpacking Approaches to Learning and Teaching Machine Learning in K-12
  Education: Transparency, Ethics, and Design Activities","In this conceptual paper, we review existing literature on artificial
intelligence/machine learning (AI/ML) education to identify three approaches to
how learning and teaching ML could be conceptualized. One of them, a
data-driven approach, emphasizes providing young people with opportunities to
create data sets, train, and test models. A second approach, learning
algorithm-driven, prioritizes learning about how the learning algorithms or
engines behind how ML models work. In addition, we identify efforts within a
third approach that integrates the previous two. In our review, we focus on how
the approaches: (1) glassbox and blackbox different aspects of ML, (2) build on
learner interests and provide opportunities for designing applications, (3)
integrate ethics and justice. In the discussion, we address the challenges and
opportunities of current approaches and suggest future directions for the
design of learning activities.",2024-06-05,2024,2024-06,education
"Cluster Model for parsimonious selection of variables and enhancing
  Students Employability Prediction","Educational Data Mining (EDM) is a promising field, where data mining is
widely used for predicting students performance. One of the most prevalent and
recent challenge that higher education faces today is making students
skillfully employable. Institutions possess large volume of data; still they
are unable to reveal knowledge and guide their students. Data in education is
generally very large, multidimensional and unbalanced in nature. Process of
extracting knowledge from such data has its own set of problems and is a very
complicated task. In this paper, Engineering and MCA (Masters in Computer
Applications) students data is collected from various universities and
institutes pan India. The dataset is large, unbalanced and multidimensional in
nature. A cluster based model is presented in this paper, which, when applied
at preprocessing stage helps in parsimonious selection of variables and
improves the performance of predictive algorithms. Hence, facilitate in better
prediction of Students Employability.",2024-06-05,2024,2024-06,education
"Unified Prediction Model for Employability in Indian Higher Education
  System","Educational Data Mining has become extremely popular among researchers in
last decade. Prior effort in this area was only directed towards prediction of
academic performance of a student. Very less number of researches are directed
towards predicting employability of a student i.e. prediction of students
performance in campus placements at an early stage of enrollment. Furthermore,
existing researches on students employability prediction are not universal in
approach and is either based upon only one type of course or
University/Institute. Henceforth, is not scalable from one context to another.
With the necessity of unification, data of professional technical courses
namely Bachelor in Engineering/Technology and Masters in Computer Applications
students have been collected from 17 states of India. To deal with such a data,
a unified predictive model has been developed and applied on 17 states
datasets. The research done in this paper proves that model has universal
application and can be applied to various states and institutes pan India with
different cultural background and course structure. This paper also explores
and proves statistically that there is no significant difference in Indian
Education System with respect to states as far as prediction of employability
of students is concerned. Model provides a generalized solution for student
employability prediction in Indian Scenario.",2024-06-05,2024,2024-06,education
"Comprehensive AI Assessment Framework: Enhancing Educational Evaluation
  with Ethical AI Integration","The integration of generative artificial intelligence (GenAI) tools into
education has been a game-changer for teaching and assessment practices,
bringing new opportunities, but also novel challenges which need to be dealt
with. This paper presents the Comprehensive AI Assessment Framework (CAIAF), an
evolved version of the AI Assessment Scale (AIAS) by Perkins, Furze, Roe, and
MacVaugh, targeted toward the ethical integration of AI into educational
assessments. This is where the CAIAF differs, as it incorporates stringent
ethical guidelines, with clear distinctions based on educational levels, and
advanced AI capabilities of real-time interactions and personalized assistance.
The framework developed herein has a very intuitive use, mainly through the use
of a color gradient that enhances the user-friendliness of the framework.
Methodologically, the framework has been developed through the huge support of
a thorough literature review and practical insight into the topic, becoming a
dynamic tool to be used in different educational settings. The framework will
ensure better learning outcomes, uphold academic integrity, and promote
responsible use of AI, hence the need for this framework in modern educational
practice.",2024-06-07,2024,2024-06,education
"Leveraging Pedagogical Theories to Understand Student Learning Process
  with Graph-based Reasonable Knowledge Tracing","Knowledge tracing (KT) is a crucial task in intelligent education, focusing
on predicting students' performance on given questions to trace their evolving
knowledge. The advancement of deep learning in this field has led to
deep-learning knowledge tracing (DLKT) models that prioritize high predictive
accuracy. However, many existing DLKT methods overlook the fundamental goal of
tracking students' dynamical knowledge mastery. These models do not explicitly
model knowledge mastery tracing processes or yield unreasonable results that
educators find difficulty to comprehend and apply in real teaching scenarios.
In response, our research conducts a preliminary analysis of mainstream KT
approaches to highlight and explain such unreasonableness. We introduce GRKT, a
graph-based reasonable knowledge tracing method to address these issues. By
leveraging graph neural networks, our approach delves into the mutual
influences of knowledge concepts, offering a more accurate representation of
how the knowledge mastery evolves throughout the learning process.
Additionally, we propose a fine-grained and psychological three-stage modeling
process as knowledge retrieval, memory strengthening, and knowledge
learning/forgetting, to conduct a more reasonable knowledge tracing process.
Comprehensive experiments demonstrate that GRKT outperforms eleven baselines
across three datasets, not only enhancing predictive accuracy but also
generating more reasonable knowledge tracing results. This makes our model a
promising advancement for practical implementation in educational settings. The
source code is available at https://github.com/JJCui96/GRKT.",2024-06-07,2024,2024-06,education
"Insights from Social Shaping Theory: The Appropriation of Large Language
  Models in an Undergraduate Programming Course","The capability of large language models (LLMs) to generate, debug, and
explain code has sparked the interest of researchers and educators in
undergraduate programming, with many anticipating their transformative
potential in programming education. However, decisions about why and how to use
LLMs in programming education may involve more than just the assessment of an
LLM's technical capabilities. Using the social shaping of technology theory as
a guiding framework, our study explores how students' social perceptions
influence their own LLM usage. We then examine the correlation of self-reported
LLM usage with students' self-efficacy and midterm performances in an
undergraduate programming course. Triangulating data from an anonymous
end-of-course student survey (n = 158), a mid-course self-efficacy survey
(n=158), student interviews (n = 10), self-reported LLM usage on homework, and
midterm performances, we discovered that students' use of LLMs was associated
with their expectations for their future careers and their perceptions of peer
usage. Additionally, early self-reported LLM usage in our context correlated
with lower self-efficacy and lower midterm scores, while students' perceived
over-reliance on LLMs, rather than their usage itself, correlated with
decreased self-efficacy later in the course.",2024-06-10,2024,2024-06,education
"Automated Question Generation for Science Tests in Arabic Language Using
  NLP Techniques","Question generation for education assessments is a growing field within
artificial intelligence applied to education. These question-generation tools
have significant importance in the educational technology domain, such as
intelligent tutoring systems and dialogue-based platforms. The automatic
generation of assessment questions, which entail clear-cut answers, usually
relies on syntactical and semantic indications within declarative sentences,
which are then transformed into questions. Recent research has explored the
generation of assessment educational questions in Arabic. The reported
performance has been adversely affected by inherent errors, including sentence
parsing inaccuracies, name entity recognition issues, and errors stemming from
rule-based question transformation. Furthermore, the complexity of lengthy
Arabic sentences has contributed to these challenges. This research presents an
innovative Arabic question-generation system built upon a three-stage process:
keywords and key phrases extraction, question generation, and subsequent
ranking. The aim is to tackle the difficulties associated with automatically
generating assessment questions in the Arabic language. The proposed approach
and results show a precision of 83.50%, a recall of 78.68%, and an Fl score of
80.95%, indicating the framework high efficiency. Human evaluation further
confirmed the model efficiency, receiving an average rating of 84%.",2024-06-11,2024,2024-06,education
"Battling Botpoop using GenAI for Higher Education: A Study of a
  Retrieval Augmented Generation Chatbots Impact on Learning","Generative artificial intelligence (GenAI) and large language models (LLMs)
have simultaneously opened new avenues for enhancing human learning and
increased the prevalence of poor-quality information in student response -
termed Botpoop. This study introduces Professor Leodar, a custom-built,
Singlish-speaking Retrieval Augmented Generation (RAG) chatbot designed to
enhance educational while reducing Botpoop. Deployed at Nanyang Technological
University, Singapore, Professor Leodar offers a glimpse into the future of
AI-assisted learning, offering personalized guidance, 24/7 availability, and
contextually relevant information. Through a mixed-methods approach, we examine
the impact of Professor Leodar on learning, engagement, and exam preparedness,
with 97.1% of participants reporting positive experiences. These findings help
define possible roles of AI in education and highlight the potential of custom
GenAI chatbots. Our combination of chatbot development, in-class deployment and
outcomes study offers a benchmark for GenAI educational tools and is a stepping
stone for redefining the interplay between AI and human learning.",2024-06-12,2024,2024-06,education
A Systematic Review of Generative AI for Teaching and Learning Practice,"The use of generative artificial intelligence (GenAI) in academia is a
subjective and hotly debated topic. Currently, there are no agreed guidelines
towards the usage of GenAI systems in higher education (HE) and, thus, it is
still unclear how to make effective use of the technology for teaching and
learning practice. This paper provides an overview of the current state of
research on GenAI for teaching and learning in HE. To this end, this study
conducted a systematic review of relevant studies indexed by Scopus, using the
preferred reporting items for systematic reviews and meta-analyses (PRISMA)
guidelines. The search criteria revealed a total of 625 research papers, of
which 355 met the final inclusion criteria. The findings from the review showed
the current state and the future trends in documents, citations, document
sources/authors, keywords, and co-authorship. The research gaps identified
suggest that while some authors have looked at understanding the detection of
AI-generated text, it may be beneficial to understand how GenAI can be
incorporated into supporting the educational curriculum for assessments,
teaching, and learning delivery. Furthermore, there is a need for additional
interdisciplinary, multidimensional studies in HE through collaboration. This
will strengthen the awareness and understanding of students, tutors, and other
stakeholders, which will be instrumental in formulating guidelines, frameworks,
and policies for GenAI usage.",2024-06-13,2024,2024-06,education
"Evaluation of Large Language Models: STEM education and Gender
  Stereotypes","Large Language Models (LLMs) have an increasing impact on our lives with use
cases such as chatbots, study support, coding support, ideation, writing
assistance, and more. Previous studies have revealed linguistic biases in
pronouns used to describe professions or adjectives used to describe men vs
women. These issues have to some degree been addressed in updated LLM versions,
at least to pass existing tests. However, biases may still be present in the
models, and repeated use of gender stereotypical language may reinforce the
underlying assumptions and are therefore important to examine further. This
paper investigates gender biases in LLMs in relation to educational choices
through an open-ended, true to user-case experimental design and a quantitative
analysis. We investigate the biases in the context of four different cultures,
languages, and educational systems (English/US/UK, Danish/DK, Catalan/ES, and
Hindi/IN) for ages ranging from 10 to 16 years, corresponding to important
educational transition points in the different countries. We find that there
are significant and large differences in the ratio of STEM to non-STEM
suggested education paths provided by chatGPT when using typical girl vs boy
names to prompt lists of suggested things to become. There are generally fewer
STEM suggestions in the Danish, Spanish, and Indian context compared to the
English. We also find subtle differences in the suggested professions, which we
categorise and report.",2024-06-14,2024,2024-06,education
"Validating an Instrument for Teachers' Acceptance of Artificial
  Intelligence in Education","As artificial intelligence (AI) receives wider attention in education,
examining teachers' acceptance of AI (TAAI) becomes essential. However,
existing instruments measuring TAAI reported limited reliability and validity
evidence and faced some design challenges, such as missing informed definitions
of AI to participants. This study aimed to develop and validate a TAAI
instrument, with providing sufficient evidence for high psychometric quality.
Based on the literature, we first identified five dimensions of TAAI, including
perceived usefulness, perceived ease of use, behavioral intention,
self-efficacy, and anxiety, and then developed items to assess each dimension.
We examined the face and content validity using expert review and think-aloud
with pre-service teachers. Using the revised instrument, we collected responses
from 274 pre-service teachers and examined the item discriminations to identify
outlier items. We employed the confirmatory factor analysis and Cronbach's
alpha to examine the construct validity, convergent validity, discriminant
validity, and reliability. Results confirmed the dimensionality of the scale,
resulting in 27 items distributed in five dimensions. The study exhibits robust
validity and reliability evidence for TAAI, thus affirming its usefulness as a
valid measurement instrument.",2024-06-15,2024,2024-06,education
"An investigation into the scientific landscape of the conversational and
  generative artificial intelligence, and human-chatbot interaction in
  education and research","Artificial intelligence (AI) as a disruptive technology is not new. However,
its recent evolution, engineered by technological transformation, big data
analytics, and quantum computing, produces conversational and generative AI
(CGAI/GenAI) and human-like chatbots that disrupt conventional operations and
methods in different fields. This study investigates the scientific landscape
of CGAI and human-chatbot interaction/collaboration and evaluates use cases,
benefits, challenges, and policy implications for multidisciplinary education
and allied industry operations. The publications trend showed that just 4%
(n=75) occurred during 2006-2018, while 2019-2023 experienced astronomical
growth (n=1763 or 96%). The prominent use cases of CGAI (e.g., ChatGPT) for
teaching, learning, and research activities occurred in computer science
[multidisciplinary and AI] (32%), medical/healthcare (17%), engineering (7%),
and business fields (6%). The intellectual structure shows strong collaboration
among eminent multidisciplinary sources in business, Information Systems, and
other areas. The thematic structure of SLP highlights prominent CGAI use cases,
including improved user experience in human-computer interaction, computer
programs/code generation, and systems creation. Widespread CGAI usefulness for
teachers, researchers, and learners includes syllabi/course content generation,
testing aids, and academic writing. The concerns about abuse and misuse
(plagiarism, academic integrity, privacy violations) and issues about
misinformation, danger of self-diagnoses, and patient privacy in
medical/healthcare applications are prominent. Formulating strategies and
policies to address potential CGAI challenges in teaching/learning and practice
are priorities. Developing discipline-based automatic detection of GenAI
contents to check abuse is proposed.",2024-06-15,2024,2024-06,education
"Beyond Answers: Large Language Model-Powered Tutoring System in Physics
  Education for Deep Learning and Precise Understanding","The integration of artificial intelligence (AI) in education has shown
significant promise, yet the effective personalization of learning,
particularly in physics education, remains a challenge. This paper proposes
Physics-STAR, a framework for large language model (LLM)- powered tutoring
system designed to address this gap by providing personalized and adaptive
learning experiences for high school students. Our study evaluates Physics-STAR
against traditional teacher-led lectures and generic LLM tutoring through a
controlled experiment with 12 high school sophomores. Results showed that
Physics-STAR increased students' average scores and efficiency on conceptual,
computational, and on informational questions. In particular, students' average
scores on complex information problems increased by 100% and their efficiency
increased by 5.95%. By facilitating step-by-step guidance and reflective
learning, Physics-STAR helps students develop critical thinking skills and a
robust comprehension of abstract concepts. The findings underscore the
potential of AI-driven personalized tutoring systems to transform physics
education. As LLM continues to advance, the future of student-centered AI in
education looks promising, with the potential to significantly improve learning
outcomes and efficiency.",2024-06-16,2024,2024-06,education
"Generative Artificial Intelligence-Guided User Studies: An Application
  for Air Taxi Services","User studies are crucial for meeting user needs. In user studies, real
experimental scenarios and participants are constructed and recruited. However,
emerging and unfamiliar studies face limitations, including safety concerns and
iterative efficiency. To address these challenges, this study utilises a
Generative Artificial Intelligence (GenAI) to create GenAI-generated scenarios
for user experience (UX). By recruiting real users to evaluate this experience,
we can collect feedback that enables rapid iteration in the early design phase.
The air taxi is particularly representative of these challenges and has been
chosen as the case study for this research. The key contribution was designing
an Air Taxi Journey (ATJ) using Large Language Models (LLMs) and AI image and
video generators. Based on the GPT-4-generated scripts, key visuals were
created for the air taxi, and the ATJ was evaluated by 72 participants.
Furthermore, the LLMs demonstrated the ability to identify and suggest
environments that significantly improve participants' willingness toward air
taxis. Education level and gender significantly influenced participants' the
difference in willingness and their satisfaction with the ATJ. Satisfaction
with the ATJ serves as a mediator, significantly influencing participants'
willingness to take air taxis. Our study confirms the capability of GenAI to
support user studies, providing a feasible approach and valuable insights for
designing air taxi UX in the early design phase.",2024-06-18,2024,2024-06,education
QOG:Question and Options Generation based on Language Model,"Question-Options Generation (QOG) is a task that involves generating a set of
question-options pairs given context. This task has various applications,
including fine-tuning large models, information retrieval, and automated
multiple-choice question generation for education. In this paper, we develop
QOG models using three different methods based on fine-tuning
sequence-to-sequence language models (LMs). Experiments demonstrate that the
end-to-end QOG model is computationally efficient and stable during both
training and inference, outperforming other methods. Furthermore, our analysis
indicates that our QOG models are competitive on the QOG task compared to the
large language model Llama 3-8B.",2024-06-18,2024,2024-06,education
RITA: A Real-time Interactive Talking Avatars Framework,"RITA presents a high-quality real-time interactive framework built upon
generative models, designed with practical applications in mind. Our framework
enables the transformation of user-uploaded photos into digital avatars that
can engage in real-time dialogue interactions. By leveraging the latest
advancements in generative modeling, we have developed a versatile platform
that not only enhances the user experience through dynamic conversational
avatars but also opens new avenues for applications in virtual reality, online
education, and interactive gaming. This work showcases the potential of
integrating computer vision and natural language processing technologies to
create immersive and interactive digital personas, pushing the boundaries of
how we interact with digital content.",2024-06-18,2024,2024-06,education
"Generative AI for Enhancing Active Learning in Education: A Comparative
  Study of GPT-3.5 and GPT-4 in Crafting Customized Test Questions","This study investigates how LLMs, specifically GPT-3.5 and GPT-4, can develop
tailored questions for Grade 9 math, aligning with active learning principles.
By utilizing an iterative method, these models adjust questions based on
difficulty and content, responding to feedback from a simulated 'student'
model. A novel aspect of the research involved using GPT-4 as a 'teacher' to
create complex questions, with GPT-3.5 as the 'student' responding to these
challenges. This setup mirrors active learning, promoting deeper engagement.
The findings demonstrate GPT-4's superior ability to generate precise,
challenging questions and notable improvements in GPT-3.5's ability to handle
more complex problems after receiving instruction from GPT-4. These results
underscore the potential of LLMs to mimic and enhance active learning
scenarios, offering a promising path for AI in customized education. This
research contributes to understanding how AI can support personalized learning
experiences, highlighting the need for further exploration in various
educational contexts",2024-06-20,2024,2024-06,education
"EduQate: Generating Adaptive Curricula through RMABs in Education
  Settings","There has been significant interest in the development of personalized and
adaptive educational tools that cater to a student's individual learning
progress. A crucial aspect in developing such tools is in exploring how mastery
can be achieved across a diverse yet related range of content in an efficient
manner. While Reinforcement Learning and Multi-armed Bandits have shown promise
in educational settings, existing works often assume the independence of
learning content, neglecting the prevalent interdependencies between such
content. In response, we introduce Education Network Restless Multi-armed
Bandits (EdNetRMABs), utilizing a network to represent the relationships
between interdependent arms. Subsequently, we propose EduQate, a method
employing interdependency-aware Q-learning to make informed decisions on arm
selection at each time step. We establish the optimality guarantee of EduQate
and demonstrate its efficacy compared to baseline policies, using students
modeled from both synthetic and real-world data.",2024-06-20,2024,2024-06,education
"How critically can an AI think? A framework for evaluating the quality
  of thinking of generative artificial intelligence","Generative AI such as those with large language models have created
opportunities for innovative assessment design practices. Due to recent
technological developments, there is a need to know the limits and capabilities
of generative AI in terms of simulating cognitive skills. Assessing student
critical thinking skills has been a feature of assessment for time immemorial,
but the demands of digital assessment create unique challenges for equity,
academic integrity and assessment authorship. Educators need a framework for
determining their assessments vulnerability to generative AI to inform
assessment design practices. This paper presents a framework that explores the
capabilities of the LLM ChatGPT4 application, which is the current industry
benchmark. This paper presents the Mapping of questions, AI vulnerability
testing, Grading, Evaluation (MAGE) framework to methodically critique their
assessments within their own disciplinary contexts. This critique will provide
specific and targeted indications of their questions vulnerabilities in terms
of the critical thinking skills. This can go on to form the basis of assessment
design for their tasks.",2024-06-20,2024,2024-06,education
"How Effective is GPT-4 Turbo in Generating School-Level Questions from
  Textbooks Based on Bloom's Revised Taxonomy?","We evaluate the effectiveness of GPT-4 Turbo in generating educational
questions from NCERT textbooks in zero-shot mode. Our study highlights GPT-4
Turbo's ability to generate questions that require higher-order thinking
skills, especially at the ""understanding"" level according to Bloom's Revised
Taxonomy. While we find a notable consistency between questions generated by
GPT-4 Turbo and those assessed by humans in terms of complexity, there are
occasional differences. Our evaluation also uncovers variations in how humans
and machines evaluate question quality, with a trend inversely related to
Bloom's Revised Taxonomy levels. These findings suggest that while GPT-4 Turbo
is a promising tool for educational question generation, its efficacy varies
across different cognitive levels, indicating a need for further refinement to
fully meet educational standards.",2024-06-21,2024,2024-06,education
A GPT-based Code Review System for Programming Language Learning,"The increasing demand for programming language education and growing class
sizes require immediate and personalized feedback. However, traditional code
review methods have limitations in providing this level of feedback. As the
capabilities of Large Language Models (LLMs) like GPT for generating accurate
solutions and timely code reviews are verified, this research proposes a system
that employs GPT-4 to offer learner-friendly code reviews and minimize the risk
of AI-assist cheating.
  To provide learner-friendly code reviews, a dataset was collected from an
online judge system, and this dataset was utilized to develop and enhance the
system's prompts. In addition, to minimize AI-assist cheating, the system flow
was designed to provide code reviews only for code submitted by a learner, and
a feature that highlights code lines to fix was added. After the initial system
was deployed on the web, software education experts conducted usability test.
Based on the results, improvement strategies were developed to improve code
review and code correctness check module, thereby enhancing the system.
  The improved system underwent evaluation by software education experts based
on four criteria: strict code correctness checks, response time, lower API call
costs, and the quality of code reviews. The results demonstrated a performance
to accurately identify error types, shorten response times, lower API call
costs, and maintain high-quality code reviews without major issues. Feedback
from participants affirmed the tool's suitability for teaching programming to
primary and secondary school students. Given these benefits, the system is
anticipated to be a efficient learning tool in programming language learning
for educational settings.",2024-06-21,2024,2024-06,education
"Understanding Student and Academic Staff Perceptions of AI Use in
  Assessment and Feedback","The rise of Artificial Intelligence (AI) and Generative Artificial
Intelligence (GenAI) in higher education necessitates assessment reform. This
study addresses a critical gap by exploring student and academic staff
experiences with AI and GenAI tools, focusing on their familiarity and comfort
with current and potential future applications in learning and assessment. An
online survey collected data from 35 academic staff and 282 students across two
universities in Vietnam and one in Singapore, examining GenAI familiarity,
perceptions of its use in assessment marking and feedback, knowledge checking
and participation, and experiences of GenAI text detection.
  Descriptive statistics and reflexive thematic analysis revealed a generally
low familiarity with GenAI among both groups. GenAI feedback was viewed
negatively; however, it was viewed more positively when combined with
instructor feedback. Academic staff were more accepting of GenAI text detection
tools and grade adjustments based on detection results compared to students.
Qualitative analysis identified three themes: unclear understanding of text
detection tools, variability in experiences with GenAI detectors, and mixed
feelings about GenAI's future impact on educational assessment. These findings
have major implications regarding the development of policies and practices for
GenAI-enabled assessment and feedback in higher education.",2024-06-22,2024,2024-06,education
"Enhancing Explainability of Knowledge Learning Paths: Causal Knowledge
  Networks","A reliable knowledge structure is a prerequisite for building effective
adaptive learning systems and intelligent tutoring systems. Pursuing an
explainable and trustworthy knowledge structure, we propose a method for
constructing causal knowledge networks. This approach leverages Bayesian
networks as a foundation and incorporates causal relationship analysis to
derive a causal network. Additionally, we introduce a dependable
knowledge-learning path recommendation technique built upon this framework,
improving teaching and learning quality while maintaining transparency in the
decision-making process.",2024-06-25,2024,2024-06,education
"The Rise of Artificial Intelligence in Educational Measurement:
  Opportunities and Ethical Challenges","The integration of artificial intelligence (AI) in educational measurement
has revolutionized assessment methods, enabling automated scoring, rapid
content analysis, and personalized feedback through machine learning and
natural language processing. These advancements provide timely, consistent
feedback and valuable insights into student performance, thereby enhancing the
assessment experience. However, the deployment of AI in education also raises
significant ethical concerns regarding validity, reliability, transparency,
fairness, and equity. Issues such as algorithmic bias and the opacity of AI
decision-making processes pose risks of perpetuating inequalities and affecting
assessment outcomes. Responding to these concerns, various stakeholders,
including educators, policymakers, and organizations, have developed guidelines
to ensure ethical AI use in education. The National Council of Measurement in
Education's Special Interest Group on AI in Measurement and Education (AIME)
also focuses on establishing ethical standards and advancing research in this
area. In this paper, a diverse group of AIME members examines the ethical
implications of AI-powered tools in educational measurement, explores
significant challenges such as automation bias and environmental impact, and
proposes solutions to ensure AI's responsible and effective use in education.",2024-06-27,2024,2024-06,education
"FernUni LLM Experimental Infrastructure (FLEXI) -- Enabling
  Experimentation and Innovation in Higher Education Through Access to Open
  Large Language Models","Using the full potential of LLMs in higher education is hindered by
challenges with access to LLMs. The two main access modes currently discussed
are paying for a cloud-based LLM or providing a locally maintained open LLM. In
this paper, we describe the current state of establishing an open LLM
infrastructure at FernUniversit\""at in Hagen under the project name FLEXI
(FernUni LLM Experimental Infrastructure). FLEXI enables experimentation within
teaching and research with the goal of generating strongly needed evidence in
favor (or against) the use of locally maintained open LLMs in higher education.
The paper will provide some practical guidance for everyone trying to decide
whether to run their own LLM server.",2024-06-27,2024,2024-06,education
"Influence of Personality Traits on Plagiarism Through Collusion in
  Programming Assignments","Educating students about academic integrity expectations has been suggested
as one of the ways to reduce malpractice in take-home programming assignments.
We test this hypothesis using data collected from an artificial intelligence
course with 105 participants (N=105) at a university in India. The AI course
had two programming assignments. Plagiarism through collusion was quantified
using the Measure of Software Similarity (MOSS) tool. Students were educated
about what constitutes academic dishonesty and were required to take an honor
pledge before the start of the second take-home programming assignment. The two
programming assignments were novel and did not have solutions available on the
internet. We expected the mean percentage of similar lines of code to be
significantly less in the second programming assignment. However, our results
show no significant difference in the mean percentage of similar lines of code
across the two programming assignments. We also study how the Big-five
personality traits affect the propensity for plagiarism in the two take-home
assignments. Our results across both assignments show that the extraversion
trait of the Big Five personality exhibits a positive association, and the
conscientiousness trait exhibits a negative association with plagiarism
tendencies. Our result suggests that the policy of educating students about
academic integrity will have a limited impact as long as students perceive an
opportunity for plagiarism to be present. We explain our results using the
Fraud triangle model.",2024-06-29,2024,2024-06,education
"""I understand why I got this grade"": Automatic Short Answer Grading with
  Feedback","The demand for efficient and accurate assessment methods has intensified as
education systems transition to digital platforms. Providing feedback is
essential in educational settings and goes beyond simply conveying marks as it
justifies the assigned marks. In this context, we present a significant
advancement in automated grading by introducing Engineering Short Answer
Feedback (EngSAF) -- a dataset of 5.8k student answers accompanied by reference
answers and questions for the Automatic Short Answer Grading (ASAG) task. The
EngSAF dataset is meticulously curated to cover a diverse range of subjects,
questions, and answer patterns from multiple engineering domains. We leverage
state-of-the-art large language models' (LLMs) generative capabilities with our
Label-Aware Synthetic Feedback Generation (LASFG) strategy to include feedback
in our dataset. This paper underscores the importance of enhanced feedback in
practical educational settings, outlines dataset annotation and feedback
generation processes, conducts a thorough EngSAF analysis, and provides
different LLMs-based zero-shot and finetuned baselines for future comparison.
Additionally, we demonstrate the efficiency and effectiveness of the ASAG
system through its deployment in a real-world end-semester exam at the Indian
Institute of Technology Bombay (IITB), showcasing its practical viability and
potential for broader implementation in educational institutions.",2024-06-30,2024,2024-06,education
Revolutionising Role-Playing Games with ChatGPT,"Digitalisation in education and its influence on teaching methods is the
focus of this study, which examines the use of ChatGPT in a role-playing game
used in the Cloud Computing Engineering Master's programme at the University of
Applied Sciences Burgenland. The aim of the study was to analyse the impact of
AI-based simulations on students' learning experience. Based on Vygotsky's
sociocultural theory, ChatGPT was used to give students a deeper understanding
of strategic decision-making processes in simulated business scenarios. The
methodological approach included role-playing and qualitative content analysis
of 20 student reflections. The findings suggest that ChatGPT enhances students'
engagement, critical thinking, and communication skills, in addition to
contributing to the effective application of theoretical knowledge.
Furthermore, simulations can contribute to the effective application of
theoretical knowledge. The results underscore the significance of adaptive
teaching approaches in promoting digital literacy and equipping learners for
the digital workplace. The integration of AI into curricula and the need for
ongoing innovation in higher education are also emphasised as a means of
guaranteeing excellent, future-focused instruction. The findings highlight the
potential of AI and ChatGPT in particular, as an innovative cutting-edge
educational tool that can both enhance the learning experience and help achieve
the Sustainable Development Goals (SDGs) through education.",2024-07-02,2024,2024-07,education
"Domain Generalizable Knowledge Tracing via Concept Aggregation and
  Relation-Based Attention","Knowledge Tracing (KT) is a critical task in online education systems, aiming
to monitor students' knowledge states throughout a learning period. Common KT
approaches involve predicting the probability of a student correctly answering
the next question based on their exercise history. However, these methods often
suffer from performance degradation when faced with the scarcity of student
interactions in new education systems. To address this, we leverage student
interactions from existing education systems to mitigate performance
degradation caused by limited training data. Nevertheless, these interactions
exhibit significant differences since they are derived from different education
systems. To address this issue, we propose a domain generalization approach for
knowledge tracing, where existing education systems are considered source
domains, and new education systems with limited data are considered target
domains. Additionally, we design a domain-generalizable knowledge tracing
framework (DGKT) that can be applied to any KT model. Specifically, we present
a concept aggregation approach designed to reduce conceptual disparities within
sequences of student interactions from diverse domains. To further mitigate
domain discrepancies, we introduce a novel normalization module called Sequence
Instance Normalization (SeqIN). Moreover, to fully leverage exercise
information, we propose a new knowledge tracing model tailored for the domain
generalization KT task, named Domain-Generalizable Relation-based Knowledge
Tracing (DGRKT). Extensive experiments across five benchmark datasets
demonstrate that the proposed method performs well despite limited training
data.",2024-07-02,2024,2024-07,education
"Integrating Randomness in Large Language Models: A Linear Congruential
  Generator Approach for Generating Clinically Relevant Content","Generating diverse, high-quality outputs from language models is crucial for
applications in education and content creation. Achieving true randomness and
avoiding repetition remains a significant challenge. This study uses the Linear
Congruential Generator method for systematic fact selection, combined with
AI-powered content generation. We ensured unique combinations of
gastrointestinal physiology and pathology facts across multiple rounds,
integrating these facts into prompts for GPT-4o to create clinically relevant,
vignette-style outputs. Over 14 rounds, 98 unique outputs were generated,
demonstrating LCG's effectiveness in producing diverse and high-quality
content. This method addresses key issues of randomness and repetition,
enhancing the quality and efficiency of language model-generated content for
various applications.",2024-07-04,2024,2024-07,education
RAMO: Retrieval-Augmented Generation for Enhancing MOOCs Recommendations,"Massive Open Online Courses (MOOCs) have significantly enhanced educational
accessibility by offering a wide variety of courses and breaking down
traditional barriers related to geography, finance, and time. However, students
often face difficulties navigating the vast selection of courses, especially
when exploring new fields of study. Driven by this challenge, researchers have
been exploring course recommender systems to offer tailored guidance that
aligns with individual learning preferences and career aspirations. These
systems face particular challenges in effectively addressing the ``cold start''
problem for new users. Recent advancements in recommender systems suggest
integrating large language models (LLMs) into the recommendation process to
enhance personalized recommendations and address the ``cold start'' problem.
Motivated by these advancements, our study introduces RAMO (Retrieval-Augmented
Generation for MOOCs), a system specifically designed to overcome the ``cold
start'' challenges of traditional course recommender systems. The RAMO system
leverages the capabilities of LLMs, along with Retrieval-Augmented Generation
(RAG)-facilitated contextual understanding, to provide course recommendations
through a conversational interface, aiming to enhance the e-learning
experience.",2024-07-06,2024,2024-07,education
"Enhancing Computer Programming Education with LLMs: A Study on Effective
  Prompt Engineering for Python Code Generation","Large language models (LLMs) and prompt engineering hold significant
potential for advancing computer programming education through personalized
instruction. This paper explores this potential by investigating three critical
research questions: the systematic categorization of prompt engineering
strategies tailored to diverse educational needs, the empowerment of LLMs to
solve complex problems beyond their inherent capabilities, and the
establishment of a robust framework for evaluating and implementing these
strategies. Our methodology involves categorizing programming questions based
on educational requirements, applying various prompt engineering strategies,
and assessing the effectiveness of LLM-generated responses. Experiments with
GPT-4, GPT-4o, Llama3-8b, and Mixtral-8x7b models on datasets such as LeetCode
and USACO reveal that GPT-4o consistently outperforms others, particularly with
the ""multi-step"" prompt strategy. The results show that tailored prompt
strategies significantly enhance LLM performance, with specific strategies
recommended for foundational learning, competition preparation, and advanced
problem-solving. This study underscores the crucial role of prompt engineering
in maximizing the educational benefits of LLMs. By systematically categorizing
and testing these strategies, we provide a comprehensive framework for both
educators and students to optimize LLM-based learning experiences. Future
research should focus on refining these strategies and addressing current LLM
limitations to further enhance educational outcomes in computer programming
instruction.",2024-07-07,2024,2024-07,education
"A Fair Post-Processing Method based on the MADD Metric for Predictive
  Student Models","Predictive student models are increasingly used in learning environments.
However, due to the rising social impact of their usage, it is now all the more
important for these models to be both sufficiently accurate and fair in their
predictions. To evaluate algorithmic fairness, a new metric has been developed
in education, namely the Model Absolute Density Distance (MADD). This metric
enables us to measure how different a predictive model behaves regarding two
groups of students, in order to quantify its algorithmic unfairness. In this
paper, we thus develop a post-processing method based on this metric, that aims
at improving the fairness while preserving the accuracy of relevant predictive
models' results. We experiment with our approach on the task of predicting
student success in an online course, using both simulated and real-world
educational data, and obtain successful results. Our source code and data are
in open access at https://github.com/melinaverger/MADD .",2024-07-07,2024,2024-07,education
"Integrating AI in College Education: Positive yet Mixed Experiences with
  ChatGPT","The integration of artificial intelligence (AI) chatbots into higher
education marks a shift towards a new generation of pedagogical tools,
mirroring the arrival of milestones like the internet. With the launch of
ChatGPT-4 Turbo in November 2023, we developed a ChatGPT-based teaching
application (https://chat.openai.com/g/g-1imx1py4K-chatge-medical-imaging) and
integrated it into our undergraduate medical imaging course in the Spring 2024
semester. This study investigates the use of ChatGPT throughout a semester-long
trial, providing insights into students' engagement, perception, and the
overall educational effectiveness of the technology. We systematically
collected and analyzed data concerning students' interaction with ChatGPT,
focusing on their attitudes, concerns, and usage patterns. The findings
indicate that ChatGPT offers significant advantages such as improved
information access and increased interactivity, but its adoption is accompanied
by concerns about the accuracy of the information provided and the necessity
for well-defined guidelines to optimize its use.",2024-07-08,2024,2024-07,education
Collaborative Design of AI-Enhanced Learning Activities,"Artificial intelligence has accelerated innovations in different aspects of
citizens' lives. Many contexts have already addressed technology-enhanced
learning, but educators at different educational levels now need to develop AI
literacy and the ability to integrate appropriate AI usage into their teaching.
We take into account this objective, along with the creative learning design,
to create a formative intervention that enables preservice teachers, in-service
teachers, and EdTech specialists to effectively incorporate AI into their
teaching practices. We developed the formative intervention with Terra Numerica
and Maison de l'Intelligence Artificielle in two phases in order to enhance
their understanding of AI and foster its creative application in learning
design. Participants reflect on AI's potential in teaching and learning by
exploring different activities that can integrate AI literacy in education,
including its ethical considerations and potential for innovative pedagogy. The
approach emphasises not only acculturating professionals to AI but also
empowering them to collaboratively design AI-enhanced educational activities
that promote learner engagement and personalised learning experiences. Through
this process, participants in the workshops develop the skills and mindset
necessary to effectively leverage AI while maintaining a critical awareness of
its implications in education.",2024-07-09,2024,2024-07,education
"Teacher agency in the age of generative AI: towards a framework of
  hybrid intelligence for learning design","Generative AI (genAI) is being used in education for different purposes. From
the teachers' perspective, genAI can support activities such as learning
design. However, there is a need to study the impact of genAI on the teachers'
agency. While GenAI can support certain processes of idea generation and
co-creation, GenAI has the potential to negatively affect professional agency
due to teachers' limited power to (i) act, (ii) affect matters, and (iii) make
decisions or choices, as well as the possibility to (iv) take a stance. Agency
is identified in the learning sciences studies as being one of the factors in
teachers' ability to trust AI. This paper aims to introduce a dual perspective.
First, educational technology, as opposed to other computer-mediated
communication (CMC) tools, has two distinctly different user groups and
different user needs, in the form of learners and teachers, to cater for.
Second, the design of educational technology often prioritises learner agency
and engagement, thereby limiting the opportunities for teachers to influence
the technology and take action. This study aims to analyse the way GenAI is
influencing teachers' agency. After identifying the current limits of GenAI, a
solution based on the combination of human intelligence and artificial
intelligence through a hybrid intelligence approach is proposed. This
combination opens up the discussion of a collaboration between teacher and
genAI being able to open up new practices in learning design in which they HI
support the extension of the teachers' activity.",2024-07-09,2024,2024-07,education
Evaluating Human-AI Collaboration: A Review and Methodological Framework,"The use of artificial intelligence (AI) in working environments with
individuals, known as Human-AI Collaboration (HAIC), has become essential in a
variety of domains, boosting decision-making, efficiency, and innovation.
Despite HAIC's wide potential, evaluating its effectiveness remains challenging
due to the complex interaction of components involved.
  This paper provides a detailed analysis of existing HAIC evaluation
approaches and develops a fresh paradigm for more effectively evaluating these
systems.
  Our framework includes a structured decision tree which assists to select
relevant metrics based on distinct HAIC modes (AI-Centric, Human-Centric, and
Symbiotic). By including both quantitative and qualitative metrics, the
framework seeks to represent HAIC's dynamic and reciprocal nature, enabling the
assessment of its impact and success. This framework's practicality can be
examined by its application in an array of domains, including manufacturing,
healthcare, finance, and education, each of which has unique challenges and
requirements. Our hope is that this study will facilitate further research on
the systematic evaluation of HAIC in real-world applications.",2024-07-09,2024,2024-07,education
"Promoting AI Competencies for Medical Students: A Scoping Review on
  Frameworks, Programs, and Tools","As more clinical workflows continue to be augmented by artificial
intelligence (AI), AI literacy among physicians will become a critical
requirement for ensuring safe and ethical AI-enabled patient care. Despite the
evolving importance of AI in healthcare, the extent to which it has been
adopted into traditional and often-overloaded medical curricula is currently
unknown. In a scoping review of 1,699 articles published between January 2016
and June 2024, we identified 18 studies which propose guiding frameworks, and
11 studies documenting real-world instruction, centered around the integration
of AI into medical education. We found that comprehensive guidelines will
require greater clinical relevance and personalization to suit medical student
interests and career trajectories. Current efforts highlight discrepancies in
the teaching guidelines, emphasizing AI evaluation and ethics over technical
topics such as data science and coding. Additionally, we identified several
challenges associated with integrating AI training into the medical education
program, including a lack of guidelines to define medical students AI literacy,
a perceived lack of proven clinical value, and a scarcity of qualified
instructors. With this knowledge, we propose an AI literacy framework to define
competencies for medical students. To prioritize relevant and personalized AI
education, we categorize literacy into four dimensions: Foundational,
Practical, Experimental, and Ethical, with tailored learning objectives to the
pre-clinical, clinical, and clinical research stages of medical education. This
review provides a road map for developing practical and relevant education
strategies for building an AI-competent healthcare workforce.",2024-07-10,2024,2024-07,education
"Have We Reached AGI? Comparing ChatGPT, Claude, and Gemini to Human
  Literacy and Education Benchmarks","Recent advancements in AI, particularly in large language models (LLMs) like
ChatGPT, Claude, and Gemini, have prompted questions about their proximity to
Artificial General Intelligence (AGI). This study compares LLM performance on
educational benchmarks with Americans' average educational attainment and
literacy levels, using data from the U.S. Census Bureau and technical reports.
Results show that LLMs significantly outperform human benchmarks in tasks such
as undergraduate knowledge and advanced reading comprehension, indicating
substantial progress toward AGI. However, true AGI requires broader cognitive
assessments. The study highlights the implications for AI development,
education, and societal impact, emphasizing the need for ongoing research and
ethical considerations.",2024-07-11,2024,2024-07,education
"Artificial Intelligence from Idea to Implementation. How Can AI Reshape
  the Education Landscape?","This introductory chapter provides an overview of the evolution and impact of
Artificial Intelligence technologies in today society. Beginning with a
historical context while exploring a few general definitions of AI, the author
provides a timeline of the used technologies, highlighting its periods of
stagnation, commonly referred to as AI winters, and the subsequent resurgence
fueled by relentless enthusiasm and investment. The narrative then transitions
to focus on the transformative effects of AI on society at large, with a
particular emphasis on educational applications. Through examples, the paper
shows how AI technologies have moved from theoretical constructs to practical
tools that are reshaping pedagogical approaches and student engagement. The
essay concludes by discussing the prospects of AI in education, emphasizing the
need for a balanced approach that considers both technological advancements and
societal implications.",2024-07-14,2024,2024-07,education
Ontology-driven Reinforcement Learning for Personalized Student Support,"In the search for more effective education, there is a widespread effort to
develop better approaches to personalize student education. Unassisted,
educators often do not have time or resources to personally support every
student in a given classroom. Motivated by this issue, and by recent
advancements in artificial intelligence, this paper presents a general-purpose
framework for personalized student support, applicable to any virtual
educational system such as a serious game or an intelligent tutoring system. To
fit any educational situation, we apply ontologies for their semantic
organization, combining them with data collection considerations and
multi-agent reinforcement learning. The result is a modular system that can be
adapted to any virtual educational software to provide useful personalized
assistance to students.",2024-07-14,2024,2024-07,education
"How Do Students Interact with an LLM-powered Virtual Teaching Assistant
  in Different Educational Settings?","Jill Watson, a virtual teaching assistant powered by LLMs, answers student
questions and engages them in extended conversations on courseware provided by
the instructors. In this paper, we analyze student interactions with Jill
across multiple courses and colleges, focusing on the types and complexity of
student questions based on Bloom's Revised Taxonomy and tool usage patterns. We
find that, by supporting a wide range of cognitive demands, Jill encourages
students to engage in sophisticated, higher-order cognitive questions. However,
the frequency of usage varies significantly across deployments, and the types
of questions asked depend on course-specific contexts. These findings pave the
way for future work on AI-driven educational tools tailored to individual
learning styles and course structure, potentially enhancing both the teaching
and learning experience in classrooms.",2024-07-15,2024,2024-07,education
"Graphusion: Leveraging Large Language Models for Scientific Knowledge
  Graph Fusion and Construction in NLP Education","Knowledge graphs (KGs) are crucial in the field of artificial intelligence
and are widely applied in downstream tasks, such as enhancing Question
Answering (QA) systems. The construction of KGs typically requires significant
effort from domain experts. Recently, Large Language Models (LLMs) have been
used for knowledge graph construction (KGC), however, most existing approaches
focus on a local perspective, extracting knowledge triplets from individual
sentences or documents. In this work, we introduce Graphusion, a zero-shot KGC
framework from free text. The core fusion module provides a global view of
triplets, incorporating entity merging, conflict resolution, and novel triplet
discovery. We showcase how Graphusion could be applied to the natural language
processing (NLP) domain and validate it in the educational scenario.
Specifically, we introduce TutorQA, a new expert-verified benchmark for graph
reasoning and QA, comprising six tasks and a total of 1,200 QA pairs. Our
evaluation demonstrates that Graphusion surpasses supervised baselines by up to
10% in accuracy on link prediction. Additionally, it achieves average scores of
2.92 and 2.37 out of 3 in human evaluations for concept entity extraction and
relation recognition, respectively.",2024-07-15,2024,2024-07,education
"StuGPTViz: A Visual Analytics Approach to Understand Student-ChatGPT
  Interactions","The integration of Large Language Models (LLMs), especially ChatGPT, into
education is poised to revolutionize students' learning experiences by
introducing innovative conversational learning methodologies. To empower
students to fully leverage the capabilities of ChatGPT in educational
scenarios, understanding students' interaction patterns with ChatGPT is crucial
for instructors. However, this endeavor is challenging due to the absence of
datasets focused on student-ChatGPT conversations and the complexities in
identifying and analyzing the evolutional interaction patterns within
conversations. To address these challenges, we collected conversational data
from 48 students interacting with ChatGPT in a master's level data
visualization course over one semester. We then developed a coding scheme,
grounded in the literature on cognitive levels and thematic analysis, to
categorize students' interaction patterns with ChatGPT. Furthermore, we present
a visual analytics system, StuGPTViz, that tracks and compares temporal
patterns in student prompts and the quality of ChatGPT's responses at multiple
scales, revealing significant pedagogical insights for instructors. We
validated the system's effectiveness through expert interviews with six data
visualization instructors and three case studies. The results confirmed
StuGPTViz's capacity to enhance educators' insights into the pedagogical value
of ChatGPT. We also discussed the potential research opportunities of applying
visual analytics in education and developing AI-driven personalized learning
solutions.",2024-07-17,2024,2024-07,education
"Explainable AI-based Intrusion Detection System for Industry 5.0: An
  Overview of the Literature, associated Challenges, the existing Solutions,
  and Potential Research Directions","Industry 5.0, which focuses on human and Artificial Intelligence (AI)
collaboration for performing different tasks in manufacturing, involves a
higher number of robots, Internet of Things (IoTs) devices and
interconnections, Augmented/Virtual Reality (AR), and other smart devices. The
huge involvement of these devices and interconnection in various critical
areas, such as economy, health, education and defense systems, poses several
types of potential security flaws. AI itself has been proven a very effective
and powerful tool in different areas of cybersecurity, such as intrusion
detection, malware detection, and phishing detection, among others. Just as in
many application areas, cybersecurity professionals were reluctant to accept
black-box ML solutions for cybersecurity applications. This reluctance pushed
forward the adoption of eXplainable Artificial Intelligence (XAI) as a tool
that helps explain how decisions are made in ML-based systems. In this survey,
we present a comprehensive study of different XAI-based intrusion detection
systems for industry 5.0, and we also examine the impact of explainability and
interpretability on Cybersecurity practices through the lens of Adversarial
XIDS (Adv-XIDS) approaches. Furthermore, we analyze the possible opportunities
and challenges in XAI cybersecurity systems for industry 5.0 that elicit future
research toward XAI-based solutions to be adopted by high-stakes industry 5.0
applications. We believe this rigorous analysis will establish a foundational
framework for subsequent research endeavors within the specified domain.",2024-07-21,2024,2024-07,education
"Nonverbal Immediacy Analysis in Education: A Multimodal Computational
  Model","This paper introduces a novel computational approach for analyzing nonverbal
social behavior in educational settings. Integrating multimodal behavioral
cues, including facial expressions, gesture intensity, and spatial dynamics,
the model assesses the nonverbal immediacy (NVI) of teachers from RGB classroom
videos. A dataset of 400 30-second video segments from German classrooms was
constructed for model training and validation. The gesture intensity regressor
achieved a correlation of 0.84, the perceived distance regressor 0.55, and the
NVI model 0.44 with median human ratings. The model demonstrates the potential
to provide a valuable support in nonverbal behavior assessment, approximating
the accuracy of individual human raters. Validated against both questionnaire
data and trained observer ratings, our models show moderate to strong
correlations with relevant educational outcomes, indicating their efficacy in
reflecting effective teaching behaviors. This research advances the objective
assessment of nonverbal communication behaviors, opening new pathways for
educational research.",2024-07-24,2024,2024-07,education
"Generative artificial intelligence in dentistry: Current approaches and
  future challenges","Artificial intelligence (AI) has become a commodity for people because of the
advent of generative AI (GenAI) models that bridge the usability gap of AI by
providing a natural language interface to interact with complex models. These
GenAI models range from text generation - such as two-way chat systems - to the
generation of image or video from textual descriptions input by a user. These
advancements in AI have impacted Dentistry in multiple aspects. In dental
education, the student now has the opportunity to solve a plethora of questions
by only prompting a GenAI model and have the answer in a matter of seconds.
GenAI models can help us deliver better patient healthcare by helping
practitioners gather knowledge quickly and efficiently. Finally, GenAI can also
be used in dental research, where the applications range from new drug
discovery to assistance in academic writing. In this review, we first define
GenAI models and describe their multiple generation modalities; then, we
explain and discuss their current and potential applications in Dentistry; and
finally, we describe the challenges these new technologies impose in our area.",2024-07-24,2024,2024-07,education
"Shaping Integrity: Why Generative Artificial Intelligence Does Not Have
  to Undermine Education","This paper examines the role of generative artificial intelligence (GAI) in
promoting academic integrity within educational settings. It explores how AI
can be ethically integrated into classrooms to enhance learning experiences,
foster intrinsic motivation, and support voluntary behavior change among
students. By analyzing established ethical frameworks and educational theories
such as deontological ethics, consequentialism, constructivist learning, and
Self-Determination Theory (SDT), the paper argues that GAI, when used
responsibly, can enhance digital literacy, encourage genuine knowledge
construction, and uphold ethical standards in education. This research
highlights the potential of GAI to create enriching, personalized learning
environments that prepare students to navigate the complexities of the modern
world ethically and effectively.",2024-07-26,2024,2024-07,education
"FairAIED: Navigating Fairness, Bias, and Ethics in Educational AI
  Applications","The integration of Artificial Intelligence (AI) into education has
transformative potential, providing tailored learning experiences and creative
instructional approaches. However, the inherent biases in AI algorithms hinder
this improvement by unintentionally perpetuating prejudice against specific
demographics, especially in human-centered applications like education. This
survey delves deeply into the developing topic of algorithmic fairness in
educational contexts, providing a comprehensive evaluation of the diverse
literature on fairness, bias, and ethics in AI-driven educational applications.
It identifies the common forms of biases, such as data-related, algorithmic,
and user-interaction, that fundamentally undermine the accomplishment of
fairness in AI teaching aids. By outlining existing techniques for mitigating
these biases, ranging from varied data gathering to algorithmic fairness
interventions, the survey emphasizes the critical role of ethical
considerations and legal frameworks in shaping a more equitable educational
environment. Furthermore, it guides readers through the complexities of
fairness measurements, methods, and datasets, shedding light on the way to bias
reduction. Despite these gains, this survey highlights long-standing issues,
such as achieving a balance between fairness and accuracy, as well as the need
for diverse datasets. Overcoming these challenges and ensuring the ethical and
fair use of AI's promise in education call for a collaborative,
interdisciplinary approach.",2024-07-26,2024,2024-07,education
"To accept or not to accept? An IRT-TOE Framework to Understand
  Educators' Resistance to Generative AI in Higher Education","Since the public release of Chat Generative Pre-Trained Transformer
(ChatGPT), extensive discourse has emerged concerning the potential advantages
and challenges of integrating Generative Artificial Intelligence (GenAI) into
education. In the realm of information systems, research on technology adoption
is crucial for understanding the diverse factors influencing the uptake of
specific technologies. Theoretical frameworks, refined and validated over
decades, serve as guiding tools to elucidate the individual and organizational
dynamics, obstacles, and perceptions surrounding technology adoption. However,
while several models have been proposed, they often prioritize elucidating the
factors that facilitate acceptance over those that impede it, typically
focusing on the student perspective and leaving a gap in empirical evidence
regarding educators viewpoints. Given the pivotal role educators play in higher
education, this study aims to develop a theoretical model to empirically
predict the barriers preventing educators from adopting GenAI in their
classrooms. Acknowledging the lack of theoretical models tailored to
identifying such barriers, our approach is grounded in the Innovation
Resistance Theory (IRT) framework and augmented with constructs from the
Technology-Organization-Environment (TOE) framework. This model is transformed
into a measurement instrument employing a quantitative approach, complemented
by a qualitative approach to enrich the analysis and uncover concerns related
to GenAI adoption in the higher education domain.",2024-07-29,2024,2024-07,education
"Evaluating Large Language Models for automatic analysis of teacher
  simulations","Digital Simulations (DS) provide safe environments where users interact with
an agent through conversational prompts, providing engaging learning
experiences that can be used to train teacher candidates in realistic classroom
scenarios. These simulations usually include open-ended questions, allowing
teacher candidates to express their thoughts but complicating an automatic
response analysis. To address this issue, we have evaluated Large Language
Models (LLMs) to identify characteristics (user behaviors) in the responses of
DS for teacher education. We evaluated the performance of DeBERTaV3 and Llama
3, combined with zero-shot, few-shot, and fine-tuning. Our experiments
discovered a significant variation in the LLMs' performance depending on the
characteristic to identify. Additionally, we noted that DeBERTaV3 significantly
reduced its performance when it had to identify new characteristics. In
contrast, Llama 3 performed better than DeBERTaV3 in detecting new
characteristics and showing more stable performance. Therefore, in DS where
teacher educators need to introduce new characteristics because they change
depending on the simulation or the educational objectives, it is more
recommended to use Llama 3. These results can guide other researchers in
introducing LLMs to provide the highly demanded automatic evaluations in DS.",2024-07-29,2024,2024-07,education
"How Novice Programmers Use and Experience ChatGPT when Solving
  Programming Exercises in an Introductory Course","This research paper contributes to the computing education research
community's understanding of Generative AI (GenAI) in the context of
introductory programming, and specifically, how students utilize related tools,
such as ChatGPT. An increased understanding of students' use is mandatory for
educators and higher education institutions, as GenAI is here to stay, and its
performance is likely to improve rapidly in the near future. Learning about
students' use patterns is not only crucial to support their learning, but to
develop adequate forms of instruction and assessment. With the rapid
advancement of AI, its broad availability, and ubiquitous presence in
educational environments, elaborating how AI can enhance learning experiences,
especially in courses such as introductory programming is important. To date,
most studies have focused on the educator's perspective on GenAI, its
performance, characteristics, and limitations. However, the student
perspective, and how they actually use GenAI tools in course contexts, has not
been subject to a great number of studies. Therefore, this study is guided by
the following research questions: (1) What do students report on their use
pattern of ChatGPT in the context of introductory programming exercises? and
(2) How do students perceive ChatGPT in the context of introductory programming
exercises? To address these questions, computing students at a large German
university were asked to solve programming tasks with the assistance of ChatGPT
as part of their introductory programming course. Students (n=298) provided
information regarding the use of ChatGPT, and their evaluation of the tool via
an online survey. This research provides a comprehensive evaluation of
ChatGPT-3.5's application by novice programmers in a higher education
context...",2024-07-30,2024,2024-07,education
Decomposed Prompting to Answer Questions on a Course Discussion Board,"We propose and evaluate a question-answering system that uses decomposed
prompting to classify and answer student questions on a course discussion
board. Our system uses a large language model (LLM) to classify questions into
one of four types: conceptual, homework, logistics, and not answerable. This
enables us to employ a different strategy for answering questions that fall
under different types. Using a variant of GPT-3, we achieve $81\%$
classification accuracy. We discuss our system's performance on answering
conceptual questions from a machine learning course and various failure modes.",2024-07-30,2024,2024-07,education
"Comparison of Large Language Models for Generating Contextually Relevant
  Questions","This study explores the effectiveness of Large Language Models (LLMs) for
Automatic Question Generation in educational settings. Three LLMs are compared
in their ability to create questions from university slide text without
fine-tuning. Questions were obtained in a two-step pipeline: first, answer
phrases were extracted from slides using Llama 2-Chat 13B; then, the three
models generated questions for each answer. To analyze whether the questions
would be suitable in educational applications for students, a survey was
conducted with 46 students who evaluated a total of 246 questions across five
metrics: clarity, relevance, difficulty, slide relation, and question-answer
alignment. Results indicate that GPT-3.5 and Llama 2-Chat 13B outperform Flan
T5 XXL by a small margin, particularly in terms of clarity and question-answer
alignment. GPT-3.5 especially excels at tailoring questions to match the input
answers. The contribution of this research is the analysis of the capacity of
LLMs for Automatic Question Generation in education.",2024-07-30,2024,2024-07,education
Need of AI in Modern Education: in the Eyes of Explainable AI (xAI),"Modern Education is not \textit{Modern} without AI. However, AI's complex
nature makes understanding and fixing problems challenging. Research worldwide
shows that a parent's income greatly influences a child's education. This led
us to explore how AI, especially complex models, makes important decisions
using Explainable AI tools. Our research uncovered many complexities linked to
parental income and offered reasonable explanations for these decisions.
However, we also found biases in AI that go against what we want from AI in
education: clear transparency and equal access for everyone. These biases can
impact families and children's schooling, highlighting the need for better AI
solutions that offer fair opportunities to all. This chapter tries to shed
light on the complex ways AI operates, especially concerning biases. These are
the foundational steps towards better educational policies, which include using
AI in ways that are more reliable, accountable, and beneficial for everyone
involved.",2024-07-31,2024,2024-07,education
"SmileyNet -- Towards the Prediction of the Lottery by Reading Tea Leaves
  with AI","We introduce SmileyNet, a novel neural network with psychic abilities. It is
inspired by the fact that a positive mood can lead to improved cognitive
capabilities including classification tasks. The network is hence presented in
a first phase with smileys and an encouraging loss function is defined to bias
it into a good mood. SmileyNet is then used to forecast the flipping of a coin
based on an established method of Tasseology, namely by reading tea leaves.
Training and testing in this second phase are done with a high-fidelity
simulation based on real-world pixels sampled from a professional tea-reading
cup. SmileyNet has an amazing accuracy of 72% to correctly predict the flip of
a coin. Resnet-34, respectively YOLOv5 achieve only 49%, respectively 53%. It
is then shown how multiple SmileyNets can be combined to win the lottery.",2024-07-31,2024,2024-07,education
"Towards Explainable and Interpretable Musical Difficulty Estimation: A
  Parameter-efficient Approach","Estimating music piece difficulty is important for organizing educational
music collections. This process could be partially automatized to facilitate
the educator's role. Nevertheless, the decisions performed by prevalent
deep-learning models are hardly understandable, which may impair the acceptance
of such a technology in music education curricula. Our work employs explainable
descriptors for difficulty estimation in symbolic music representations.
Furthermore, through a novel parameter-efficient white-box model, we outperform
previous efforts while delivering interpretable results. These comprehensible
outcomes emulate the functionality of a rubric, a tool widely used in music
education. Our approach, evaluated in piano repertoire categorized in 9
classes, achieved 41.4% accuracy independently, with a mean squared error (MSE)
of 1.7, showing precise difficulty estimation. Through our baseline, we
illustrate how building on top of past research can offer alternatives for
music difficulty assessment which are explainable and interpretable. With this,
we aim to promote a more effective communication between the Music Information
Retrieval (MIR) community and the music education one.",2024-08-01,2024,2024-08,education
"Evaluating the Impact of Advanced LLM Techniques on AI-Lecture Tutors
  for a Robotics Course","This study evaluates the performance of Large Language Models (LLMs) as an
Artificial Intelligence-based tutor for a university course. In particular,
different advanced techniques are utilized, such as prompt engineering,
Retrieval-Augmented-Generation (RAG), and fine-tuning. We assessed the
different models and applied techniques using common similarity metrics like
BLEU-4, ROUGE, and BERTScore, complemented by a small human evaluation of
helpfulness and trustworthiness. Our findings indicate that RAG combined with
prompt engineering significantly enhances model responses and produces better
factual answers. In the context of education, RAG appears as an ideal technique
as it is based on enriching the input of the model with additional information
and material which usually is already present for a university course.
Fine-tuning, on the other hand, can produce quite small, still strong expert
models, but poses the danger of overfitting. Our study further asks how we
measure performance of LLMs and how well current measurements represent
correctness or relevance? We find high correlation on similarity metrics and a
bias of most of these metrics towards shorter responses. Overall, our research
points to both the potential and challenges of integrating LLMs in educational
settings, suggesting a need for balanced training approaches and advanced
evaluation frameworks.",2024-08-02,2024,2024-08,education
"The EAP-AIAS: Adapting the AI Assessment Scale for English for Academic
  Purposes","The rapid advancement of Generative Artificial Intelligence (GenAI) presents
both opportunities and challenges for English for Academic Purposes (EAP)
instruction. This paper proposes an adaptation of the AI Assessment Scale
(AIAS) specifically tailored for EAP contexts, termed the EAP-AIAS.
  This framework aims to provide a structured approach for integrating GenAI
tools into EAP assessment practices while maintaining academic integrity and
supporting language development. The EAP-AIAS consists of five levels, ranging
from ""No AI"" to ""Full AI"", each delineating appropriate GenAI usage in EAP
tasks. We discuss the rationale behind this adaptation, considering the unique
needs of language learners and the dual focus of EAP on language proficiency
and academic acculturation.
  This paper explores potential applications of the EAP-AIAS across various EAP
assessment types, including writing tasks, presentations, and research
projects. By offering a flexible framework, the EAP-AIAS seeks to empower EAP
practitioners seeking to deal with the complexities of GenAI integration in
education and prepare students for an AI-enhanced academic and professional
future. This adaptation represents a step towards addressing the pressing need
for ethical and pedagogically sound AI integration in language education.",2024-08-02,2024,2024-08,education
"Designing the virtual CAT: A digital tool for algorithmic thinking
  assessment in compulsory education","Algorithmic thinking (AT) is a critical skill in today's digital society, and
it is indispensable not only in computer science-related fields but also in
everyday problem-solving. As a foundational component of digital education and
literacy, fostering AT skills is increasingly relevant for all students and
should become a standard part of compulsory education. However, successfully
integrating AT into formal education requires effective teaching strategies and
robust and scalable assessment procedures. In this paper, we present the design
and development process of the virtual Cross Array Task (CAT), a digital
adaptation of an unplugged assessment activity aimed at evaluating algorithmic
skills in Swiss compulsory education. The development process followed
iterative design cycles, incorporating expert evaluations to refine the tool's
usability, accessibility and functionality. A participatory design study played
a dual role in shaping the platform. First, it gathered valuable insights from
end users, including students and teachers, to ensure the tool's relevance and
practicality in classroom settings. Second, it facilitated the collection and
preliminary analysis of data related to students' AT skills, providing an
initial evaluation of the tool's assessment capabilities across various
developmental stages. This was achieved through a pilot study involving a
diverse group of students aged 4 to 12, spanning preschool to lower secondary
school levels. The resulting instrument features multilingual support and
includes both gesture-based and visual block-based programming interfaces,
making it accessible to a broad range of learners. Findings from the pilot
study demonstrate the platform's usability and accessibility, as well as its
suitability for assessing AT skills, with preliminary results showing its
ability to cater to diverse age groups and educational contexts.",2024-08-02,2024,2024-08,education
The Artificial Intelligence Disclosure (AID) Framework: An Introduction,"As the use of Generative Artificial Intelligence tools have grown in higher
education and research, there have been increasing calls for transparency and
granularity around the use and attribution of the use of these tools. Thus far,
this need has been met via the recommended inclusion of a note, with little to
no guidance on what the note itself should include. This has been identified as
a problem to the use of AI in academic and research contexts. This article
introduces The Artificial Intelligence Disclosure (AID) Framework, a standard,
comprehensive, and detailed framework meant to inform the development and
writing of GenAI disclosure for education and research.",2024-08-04,2024,2024-08,education
"Automated Educational Question Generation at Different Bloom's Skill
  Levels using Large Language Models: Strategies and Evaluation","Developing questions that are pedagogically sound, relevant, and promote
learning is a challenging and time-consuming task for educators. Modern-day
large language models (LLMs) generate high-quality content across multiple
domains, potentially helping educators to develop high-quality questions.
Automated educational question generation (AEQG) is important in scaling online
education catering to a diverse student population. Past attempts at AEQG have
shown limited abilities to generate questions at higher cognitive levels. In
this study, we examine the ability of five state-of-the-art LLMs of different
sizes to generate diverse and high-quality questions of different cognitive
levels, as defined by Bloom's taxonomy. We use advanced prompting techniques
with varying complexity for AEQG. We conducted expert and LLM-based evaluations
to assess the linguistic and pedagogical relevance and quality of the
questions. Our findings suggest that LLms can generate relevant and
high-quality educational questions of different cognitive levels when prompted
with adequate information, although there is a significant variance in the
performance of the five LLms considered. We also show that automated evaluation
is not on par with human evaluation.",2024-08-08,2024,2024-08,education
Learning with Digital Agents: An Analysis based on the Activity Theory,"Digital agents are considered a general-purpose technology. They spread
quickly in private and organizational contexts, including education. Yet,
research lacks a conceptual framing to describe interaction with such agents in
a holistic manner. While focusing on the interaction with a pedagogical agent,
i.e., a digital agent capable of natural-language interaction with a learner,
we propose a model of learning activity based on activity theory. We use this
model and a review of prior research on digital agents in education to analyze
how various characteristics of the activity, including features of a
pedagogical agent or learner, influence learning outcomes. The analysis leads
to identification of IS research directions and guidance for developers of
pedagogical agents and digital agents in general. We conclude by extending the
activity theory-based model beyond the context of education and show how it
helps designers and researchers ask the right questions when creating a digital
agent.",2024-08-08,2024,2024-08,education
"Educational Customization by Homogenous Grouping of e-Learners based on
  their Learning Styles","The E-learning environment offers greater flexibility compared to
face-to-face interactions, allowing for adapting educational content to meet
learners' individual needs and abilities through personalization and
customization of e-content and the educational process. Despite the advantages
of this approach, customizing the learning environment can reduce the costs of
tutoring systems for similar learners by utilizing the same content and process
for co-like learning groups. Various indicators for grouping learners exist,
but many of them are conceptual, uncertain, and subject to change over time. In
this article, we propose using the Felder-Silverman model, which is based on
learning styles, to group similar learners. Additionally, we model the
behaviors and actions of e-learners in a network environment using Fuzzy Set
Theory (FST). After identifying the learning styles of the learners, co-like
learning groups are formed, and each group receives adaptive content based on
their preferences, needs, talents, and abilities. By comparing the results of
the experimental and control groups, we determine the effectiveness of the
proposed grouping method. In terms of ""educational success,"" the weighted
average score of the experimental group is 17.65 out of 20, while the control
group achieves a score of 12.6 out of 20. Furthermore, the ""educational
satisfaction"" of the experimental group is 67%, whereas the control group's
satisfaction level is 37%.",2024-08-09,2024,2024-08,education
"Evaluating the capability of large language models to personalize
  science texts for diverse middle-school-age learners","Large language models (LLMs), including OpenAI's GPT-series, have made
significant advancements in recent years. Known for their expertise across
diverse subject areas and quick adaptability to user-provided prompts, LLMs
hold unique potential as Personalized Learning (PL) tools. Despite this
potential, their application in K-12 education remains largely unexplored. This
paper presents one of the first randomized controlled trials (n = 23) to
evaluate the effectiveness of GPT-4 in personalizing educational science texts
for middle school students. In this study, GPT-4 was used to profile student
learning preferences based on choices made during a training session. For the
experimental group, GPT-4 was used to rewrite science texts to align with the
student's predicted profile while, for students in the control group, texts
were rewritten to contradict their learning preferences. The results of a
Mann-Whitney U test showed that students significantly preferred (at the .10
level) the rewritten texts when they were aligned with their profile (p =
.059). These findings suggest that GPT-4 can effectively interpret and tailor
educational content to diverse learner preferences, marking a significant
advancement in PL technology. The limitations of this study and ethical
considerations for using artificial intelligence in education are also
discussed.",2024-08-09,2024,2024-08,education
"CIKMar: A Dual-Encoder Approach to Prompt-Based Reranking in Educational
  Dialogue Systems","In this study, we introduce CIKMar, an efficient approach to educational
dialogue systems powered by the Gemma Language model. By leveraging a
Dual-Encoder ranking system that incorporates both BERT and SBERT model, we
have designed CIKMar to deliver highly relevant and accurate responses, even
with the constraints of a smaller language model size. Our evaluation reveals
that CIKMar achieves a robust recall and F1-score of 0.70 using BERTScore
metrics. However, we have identified a significant challenge: the Dual-Encoder
tends to prioritize theoretical responses over practical ones. These findings
underscore the potential of compact and efficient models like Gemma in
democratizing access to advanced educational AI systems, ensuring effective and
contextually appropriate responses.",2024-08-16,2024,2024-08,education
"Quantifying the Effectiveness of Student Organization Activities using
  Natural Language Processing","Student extracurricular activities play an important role in enriching the
students' educational experiences. With the increasing popularity of Machine
Learning and Natural Language Processing, it becomes a logical step that
incorporating ML-NLP in improving extracurricular activities is a potential
focus of study in Artificial Intelligence (AI). This research study aims to
develop a machine learning workflow that will quantify the effectiveness of
student-organized activities based on student emotional responses using
sentiment analysis. The study uses the Bidirectional Encoder Representations
from Transformers (BERT) Large Language Model (LLM) called via the
pysentimiento toolkit, as a Transformer pipeline in Hugging Face. A sample data
set from Organization C, a Recognized Student Organization (RSO) of a higher
educational institute in the Philippines, College X, was used to develop the
workflow. The workflow consisted of data preprocessing, key feature selection,
LLM feature processing, and score aggregation, resulting in an Event Score for
each data set. The results show that the BERT LLM can also be used effectively
in analyzing sentiment beyond product reviews and post comments. For the
student affairs offices of educational institutions, this study can provide a
practical example of how NLP can be applied to real-world scenarios, showcasing
the potential impact of data-driven decision making.",2024-08-16,2024,2024-08,education
"Sentiment analysis of preservice teachers' reflections using a large
  language model","In this study, the emotion and tone of preservice teachers' reflections were
analyzed using sentiment analysis with LLMs: GPT-4, Gemini, and BERT. We
compared the results to understand how each tool categorizes and describes
individual reflections and multiple reflections as a whole. This study aims to
explore ways to bridge the gaps between qualitative, quantitative, and
computational analyses of reflective practices in teacher education. This study
finds that to effectively integrate LLM analysis into teacher education,
developing an analysis method and result format that are both comprehensive and
relevant for preservice teachers and teacher educators is crucial.",2024-08-17,2024,2024-08,education
"Evaluating Usability and Engagement of Large Language Models in Virtual
  Reality for Traditional Scottish Curling","This paper explores the innovative application of Large Language Models
(LLMs) in Virtual Reality (VR) environments to promote heritage education,
focusing on traditional Scottish curling presented in the game ``Scottish
Bonspiel VR''. Our study compares the effectiveness of LLM-based chatbots with
pre-defined scripted chatbots, evaluating key criteria such as usability, user
engagement, and learning outcomes. The results show that LLM-based chatbots
significantly improve interactivity and engagement, creating a more dynamic and
immersive learning environment. This integration helps document and preserve
cultural heritage and enhances dissemination processes, which are crucial for
safeguarding intangible cultural heritage (ICH) amid environmental changes.
Furthermore, the study highlights the potential of novel technologies in
education to provide immersive experiences that foster a deeper appreciation of
cultural heritage. These findings support the wider application of LLMs and VR
in cultural education to address global challenges and promote sustainable
practices to preserve and enhance cultural heritage.",2024-08-17,2024,2024-08,education
"Dr.Academy: A Benchmark for Evaluating Questioning Capability in
  Education for Large Language Models","Teachers are important to imparting knowledge and guiding learners, and the
role of large language models (LLMs) as potential educators is emerging as an
important area of study. Recognizing LLMs' capability to generate educational
content can lead to advances in automated and personalized learning. While LLMs
have been tested for their comprehension and problem-solving skills, their
capability in teaching remains largely unexplored. In teaching, questioning is
a key skill that guides students to analyze, evaluate, and synthesize core
concepts and principles. Therefore, our research introduces a benchmark to
evaluate the questioning capability in education as a teacher of LLMs through
evaluating their generated educational questions, utilizing Anderson and
Krathwohl's taxonomy across general, monodisciplinary, and interdisciplinary
domains. We shift the focus from LLMs as learners to LLMs as educators,
assessing their teaching capability through guiding them to generate questions.
We apply four metrics, including relevance, coverage, representativeness, and
consistency, to evaluate the educational quality of LLMs' outputs. Our results
indicate that GPT-4 demonstrates significant potential in teaching general,
humanities, and science courses; Claude2 appears more apt as an
interdisciplinary teacher. Furthermore, the automatic scores align with human
perspectives.",2024-08-20,2024,2024-08,education
"Understanding the Skills Gap between Higher Education and Industry in
  the UK in Artificial Intelligence Sector","As Artificial Intelligence (AI) changes how businesses work, there is a
growing need for people who can work in this sector. This paper investigates
how well universities in United Kingdom offering courses in AI, prepare
students for jobs in the real world. To gain insight into the differences
between university curricula and industry demands we review the contents of
taught courses and job advertisement portals. By using custom data scraping
tools to gather information from job advertisements and university curricula,
and frequency and Naive Bayes classifier analysis, this study will show exactly
what skills industry is looking for. In this study we identified 12 skill
categories that were used for mapping. The study showed that the university
curriculum in the AI domain is well balanced in most technical skills,
including Programming and Machine learning subjects, but have a gap in Data
Science and Maths and Statistics skill categories.",2024-08-20,2024,2024-08,education
"Tipta uzmanlik sinavinda (tus) buyuk dil modelleri insanlardan daha mi
  basarili?","The potential of artificial intelligence in medical education and assessment
has been made evident by recent developments in natural language processing and
artificial intelligence. Medical questions can now be successfully answered by
artificial intelligence algorithms. It can help medical practitioners. This
study evaluates the performance of three different artificial intelligence
models in answering Turkish medical questions in the 2021 1st Term Medical
Specialization Examination (MSE). MSE consists of a total of 240 questions
across clinical (CMST) and basic (BMST) medical sciences. According to the
results in CMST, it was concluded that Gemini correctly answered 82 questions,
ChatGPT-4 answered 105 questions and ChatGPT-4o answered 117 questions. In
BMST, Gemini and ChatGPT-4 answered 93 questions and ChatGPT-4o answered 107
questions correctly according to the answer key. ChatGPT-4o outperformed the
candidate with the highest scores of 113 and 106 according to CMST and BMST
respectively. This study highlights the importance of the potential of
artificial intelligence in medical education and assessment. It demonstrates
that advanced models can achieve high accuracy and contextual understanding,
demonstrating their potential role in medical education and evaluation.",2024-08-22,2024,2024-08,education
MEDCO: Medical Education Copilots Based on A Multi-Agent Framework,"Large language models (LLMs) have had a significant impact on diverse
research domains, including medicine and healthcare. However, the potential of
LLMs as copilots in medical education remains underexplored. Current
AI-assisted educational tools are limited by their solitary learning approach
and inability to simulate the multi-disciplinary and interactive nature of
actual medical training. To address these limitations, we propose MEDCO
(Medical EDucation COpilots), a novel multi-agent-based copilot system
specially developed to emulate real-world medical training environments. MEDCO
incorporates three primary agents: an agentic patient, an expert doctor, and a
radiologist, facilitating a multi-modal and interactive learning environment.
Our framework emphasizes the learning of proficient question-asking skills,
multi-disciplinary collaboration, and peer discussions between students. Our
experiments show that simulated virtual students who underwent training with
MEDCO not only achieved substantial performance enhancements comparable to
those of advanced models, but also demonstrated human-like learning behaviors
and improvements, coupled with an increase in the number of learning samples.
This work contributes to medical education by introducing a copilot that
implements an interactive and collaborative learning approach. It also provides
valuable insights into the effectiveness of AI-integrated training paradigms.",2024-08-22,2024,2024-08,education
"Promises and challenges of generative artificial intelligence for human
  learning","Generative artificial intelligence (GenAI) holds the potential to transform
the delivery, cultivation, and evaluation of human learning. This Perspective
examines the integration of GenAI as a tool for human learning, addressing its
promises and challenges from a holistic viewpoint that integrates insights from
learning sciences, educational technology, and human-computer interaction.
GenAI promises to enhance learning experiences by scaling personalised support,
diversifying learning materials, enabling timely feedback, and innovating
assessment methods. However, it also presents critical issues such as model
imperfections, ethical dilemmas, and the disruption of traditional assessments.
Cultivating AI literacy and adaptive skills is imperative for facilitating
informed engagement with GenAI technologies. Rigorous research across learning
contexts is essential to evaluate GenAI's impact on human cognition,
metacognition, and creativity. Humanity must learn with and about GenAI,
ensuring it becomes a powerful ally in the pursuit of knowledge and innovation,
rather than a crutch that undermines our intellectual abilities.",2024-08-22,2024,2024-08,education
"MedDiT: A Knowledge-Controlled Diffusion Transformer Framework for
  Dynamic Medical Image Generation in Virtual Simulated Patient","Medical education relies heavily on Simulated Patients (SPs) to provide a
safe environment for students to practice clinical skills, including medical
image analysis. However, the high cost of recruiting qualified SPs and the lack
of diverse medical imaging datasets have presented significant challenges. To
address these issues, this paper introduces MedDiT, a novel
knowledge-controlled conversational framework that can dynamically generate
plausible medical images aligned with simulated patient symptoms, enabling
diverse diagnostic skill training. Specifically, MedDiT integrates various
patient Knowledge Graphs (KGs), which describe the attributes and symptoms of
patients, to dynamically prompt Large Language Models' (LLMs) behavior and
control the patient characteristics, mitigating hallucination during medical
conversation. Additionally, a well-tuned Diffusion Transformer (DiT) model is
incorporated to generate medical images according to the specified patient
attributes in the KG. In this paper, we present the capabilities of MedDiT
through a practical demonstration, showcasing its ability to act in diverse
simulated patient cases and generate the corresponding medical images. This can
provide an abundant and interactive learning experience for students, advancing
medical education by offering an immersive simulation platform for future
healthcare professionals. The work sheds light on the feasibility of
incorporating advanced technologies like LLM, KG, and DiT in education
applications, highlighting their potential to address the challenges faced in
simulated patient-based medical education.",2024-08-22,2024,2024-08,education
"Time Series Analysis for Education: Methods, Applications, and Future
  Directions","Recent advancements in the collection and analysis of sequential educational
data have brought time series analysis to a pivotal position in educational
research, highlighting its essential role in facilitating data-driven
decision-making. However, there is a lack of comprehensive summaries that
consolidate these advancements. To the best of our knowledge, this paper is the
first to provide a comprehensive review of time series analysis techniques
specifically within the educational context. We begin by exploring the
landscape of educational data analytics, categorizing various data sources and
types relevant to education. We then review four prominent time series
methods-forecasting, classification, clustering, and anomaly
detection-illustrating their specific application points in educational
settings. Subsequently, we present a range of educational scenarios and
applications, focusing on how these methods are employed to address diverse
educational tasks, which highlights the practical integration of multiple time
series methods to solve complex educational problems. Finally, we conclude with
a discussion on future directions, including personalized learning analytics,
multimodal data fusion, and the role of large language models (LLMs) in
educational time series. The contributions of this paper include a detailed
taxonomy of educational data, a synthesis of time series techniques with
specific educational applications, and a forward-looking perspective on
emerging trends and future research opportunities in educational analysis. The
related papers and resources are available and regularly updated at the project
page.",2024-08-25,2024,2024-08,education
"A Meta-analysis of College Students' Intention to Use Generative
  Artificial Intelligence","It is of critical importance to analyse the factors influencing college
students' intention to use generative artificial intelligence (GenAI) to
understand and predict learners' learning behaviours and academic outcomes.
Nevertheless, a lack of congruity has been shown in extant research results.
This study, therefore, conducted a meta-analysis of 27 empirical studies under
an integrated theoretical framework, including 87 effect sizes of independent
research and 33,833 sample data. The results revealed that the main variables
are strongly correlated with students' behavioural intention to use GenAI.
Among them, performance expectancy (r = 0.389) and attitudes (r = 0.576) play
particularly critical roles, and effort expectancy and habit are moderated by
locational factors. Gender, notably, only moderated attitudes on students'
behavioural intention to use GenAI. This study provides valuable insights for
addressing the debate regarding students' intention to use GenAI in existed
research, improving educational technology, as well as offering support for
school decision-makers and educators to apply GenAI in school settings.",2024-08-25,2024,2024-08,education
"Adapting to the AI Disruption: Reshaping the IT Landscape and
  Educational Paradigms","Artificial intelligence (AI) signals the beginning of a revolutionary period
where technological advancement and social change interact to completely
reshape economies, work paradigms, and industries worldwide. This essay
addresses the opportunities and problems brought about by the AI-driven economy
as it examines the effects of AI disruption on the IT sector and information
technology education. By comparing the current AI revolution to previous
industrial revolutions, we investigate the significant effects of AI
technologies on workforce dynamics, employment, and organizational procedures.
Human-centered design principles and ethical considerations become crucial
requirements for the responsible development and implementation of AI systems
in the face of the field's rapid advancements. IT education programs must
change to meet the changing demands of the AI era and give students the skills
and competencies they need to succeed in a digital world that is changing
quickly. In light of AI-driven automation, we also examine the possible
advantages and difficulties of moving to a shorter workweek, emphasizing
chances to improve worker productivity, well-being, and work-life balance. We
can build a more incslusive and sustainable future for the IT industry and
beyond, enhancing human capabilities, advancing collective well-being, and
fostering a society where AI serves as a force for good by embracing the
opportunities presented by AI while proactively addressing its challenges.",2024-09-01,2024,2024-09,education
"AI Literacy for All: Adjustable Interdisciplinary Socio-technical
  Curriculum","This paper presents a curriculum, ""AI Literacy for All,"" to promote an
interdisciplinary understanding of AI, its socio-technical implications, and
its practical applications for all levels of education. With the rapid
evolution of artificial intelligence (AI), there is a need for AI literacy that
goes beyond the traditional AI education curriculum. AI literacy has been
conceptualized in various ways, including public literacy, competency building
for designers, conceptual understanding of AI concepts, and domain-specific
upskilling. Most of these conceptualizations were established before the public
release of Generative AI (Gen-AI) tools like ChatGPT. AI education has focused
on the principles and applications of AI through a technical lens that
emphasizes the mastery of AI principles, the mathematical foundations
underlying these technologies, and the programming and mathematical skills
necessary to implement AI solutions. In AI Literacy for All, we emphasize a
balanced curriculum that includes technical and non-technical learning outcomes
to enable a conceptual understanding and critical evaluation of AI technologies
in an interdisciplinary socio-technical context. The paper presents four
pillars of AI literacy: understanding the scope and technical dimensions of AI,
learning how to interact with Gen-AI in an informed and responsible way, the
socio-technical issues of ethical and responsible AI, and the social and future
implications of AI. While it is important to include all learning outcomes for
AI education in a Computer Science major, the learning outcomes can be adjusted
for other learning contexts, including, non-CS majors, high school summer
camps, the adult workforce, and the public. This paper advocates for a shift in
AI literacy education to offer a more interdisciplinary socio-technical
approach as a pathway to broaden participation in AI.",2024-09-02,2024,2024-09,education
"""Flipped"" University: LLM-Assisted Lifelong Learning Environment","The rapid development of artificial intelligence technologies, particularly
Large Language Models (LLMs), has revolutionized the landscape of lifelong
learning. This paper introduces a conceptual framework for a self-constructed
lifelong learning environment supported by LLMs. It highlights the inadequacies
of traditional education systems in keeping pace with the rapid deactualization
of knowledge and skills. The proposed framework emphasizes the transformation
from institutionalized education to personalized, self-driven learning. It
leverages the natural language capabilities of LLMs to provide dynamic and
adaptive learning experiences, facilitating the creation of personal
intellectual agents that assist in knowledge acquisition. The framework
integrates principles of lifelong learning, including the necessity of building
personal world models, the dual modes of learning (training and exploration),
and the creation of reusable learning artifacts. Additionally, it underscores
the importance of curiosity-driven learning and reflective practices in
maintaining an effective learning trajectory. The paper envisions the evolution
of educational institutions into ""flipped"" universities, focusing on supporting
global knowledge consistency rather than merely structuring and transmitting
knowledge.",2024-09-02,2024,2024-09,education
"AI Governance in Higher Education: Case Studies of Guidance at Big Ten
  Universities","Generative AI has drawn significant attention from stakeholders in higher
education. As it introduces new opportunities for personalized learning and
tutoring support, it simultaneously poses challenges to academic integrity and
leads to ethical issues. Consequently, governing responsible AI usage within
higher education institutions (HEIs) becomes increasingly important. Leading
universities have already published guidelines on Generative AI, with most
attempting to embrace this technology responsibly. This study provides a new
perspective by focusing on strategies for responsible AI governance as
demonstrated in these guidelines. Through a case study of 14 prestigious
universities in the United States, we identified the multi-unit governance of
AI, the role-specific governance of AI, and the academic characteristics of AI
governance from their AI guidelines. The strengths and potential limitations of
these strategies and characteristics are discussed. The findings offer
practical implications for guiding responsible AI usage in HEIs and beyond.",2024-09-03,2024,2024-09,education
"A+AI: Threats to Society, Remedies, and Governance","This document focuses on the threats, especially near-term threats, that
Artificial Intelligence (AI) brings to society. Most of the threats discussed
here can result from any algorithmic process, not just AI; in addition,
defining AI is notoriously difficult. For both reasons, it is important to
think of ""A+AI"": Algorithms and Artificial Intelligence.
  In addition to the threats, this paper discusses countermeasures to them, and
it includes a table showing which countermeasures are likely to mitigate which
threats. Thoughtful governance could manage the risks without seriously
impeding progress; in fact, chances are it would accelerate progress by
reducing the social chaos that would otherwise be likely. The paper lists
specific actions government should take as soon as possible, namely:
  * Require all social media platforms accessible in the U.S. to offer users
verification that their accounts are owned by citizens, and to display every
account's verification status
  * Establish regulations to require that all products created or significantly
modified with A+AI be clearly labeled as such; to restrict use of generative AI
to create likenesses of persons; and to require creators of generative AI
software to disclose materials used to train their software and to compensate
the creators of any copyrighted material used
  * Fund a crash project of research on mitigating the threats
  * Fund educational campaigns to raise awareness of the threats",2024-09-03,2024,2024-09,education
"Artificial Intelligence in Education: Ethical Considerations and
  Insights from Ancient Greek Philosophy","This paper explores the ethical implications of integrating Artificial
Intelligence (AI) in educational settings, from primary schools to
universities, while drawing insights from ancient Greek philosophy to address
emerging concerns. As AI technologies increasingly influence learning
environments, they offer novel opportunities for personalized learning,
efficient assessment, and data-driven decision-making. However, these
advancements also raise critical ethical questions regarding data privacy,
algorithmic bias, student autonomy, and the changing roles of educators. This
research examines specific use cases of AI in education, analyzing both their
potential benefits and drawbacks. By revisiting the philosophical principles of
ancient Greek thinkers such as Socrates, Aristotle, and Plato, we discuss how
their writings can guide the ethical implementation of AI in modern education.
The paper argues that while AI presents significant challenges, a balanced
approach informed by classical philosophical thought can lead to an ethically
sound transformation of education. It emphasizes the evolving role of teachers
as facilitators and the importance of fostering student initiative in AI-rich
environments.",2024-09-04,2024,2024-09,education
"Using Generative Artificial Intelligence Creatively in the Classroom:
  Examples and Lessons Learned","Although generative artificial intelligence (AI) is not new, recent
technological breakthroughs have transformed its capabilities across many
domains. These changes necessitate new attention from educators and specialized
training within the atmospheric sciences and related fields. Enabling students
to use generative AI effectively, responsibly, and ethically is critically
important for their academic and professional preparation. Educators can also
use generative AI to create engaging classroom activities, such as active
learning modules and games, but must be aware of potential pitfalls and biases.
There are also ethical implications in using tools that lack transparency, as
well as equity concerns for students who lack access to more sophisticated paid
versions of generative AI tools. This article is written for students and
educators alike, particularly those who want to learn more about generative AI
in education, including use cases, ethical concerns, and a brief history of its
emergence. Sample user prompts are also provided across numerous applications
in education and the atmospheric and related sciences. While we don't have
solutions for some broader ethical concerns surrounding the use of generative
AI in education, our goal is to start a conversation that could galvanize the
education community around shared goals and values.",2024-09-08,2024,2024-09,education
"DataliVR: Transformation of Data Literacy Education through Virtual
  Reality with ChatGPT-Powered Enhancements","Data literacy is essential in today's data-driven world, emphasizing
individuals' abilities to effectively manage data and extract meaningful
insights. However, traditional classroom-based educational approaches often
struggle to fully address the multifaceted nature of data literacy. As
education undergoes digital transformation, innovative technologies such as
Virtual Reality (VR) offer promising avenues for immersive and engaging
learning experiences. This paper introduces DataliVR, a pioneering VR
application aimed at enhancing the data literacy skills of university students
within a contextual and gamified virtual learning environment. By integrating
Large Language Models (LLMs) like ChatGPT as a conversational artificial
intelligence (AI) chatbot embodied within a virtual avatar, DataliVR provides
personalized learning assistance, enriching user learning experiences. Our
study employed an experimental approach, with chatbot availability as the
independent variable, analyzing learning experiences and outcomes as dependent
variables with a sample of thirty participants. Our approach underscores the
effectiveness and user-friendliness of ChatGPT-powered DataliVR in fostering
data literacy skills. Moreover, our study examines the impact of the
ChatGPT-based AI chatbot on users' learning, revealing significant effects on
both learning experiences and outcomes. Our study presents a robust tool for
fostering data literacy skills, contributing significantly to the digital
advancement of data literacy education through cutting-edge VR and AI
technologies. Moreover, our research provides valuable insights and
implications for future research endeavors aiming to integrate LLMs (e.g.,
ChatGPT) into educational VR platforms.",2024-09-13,2024,2024-09,education
"Reading ability detection using eye-tracking data with LSTM-based
  few-shot learning","Reading ability detection is important in modern educational field. In this
paper, a method of predicting scores of reading ability is proposed, using the
eye-tracking data of a few subjects (e.g., 68 subjects). The proposed method
built a regression model for the score prediction by combining Long Short Time
Memory (LSTM) and light-weighted neural networks. Experiments show that with
few-shot learning strategy, the proposed method achieved higher accuracy than
previous methods of score prediction in reading ability detection. The code can
later be downloaded at
https://github.com/pumpkinLNX/LSTM-eye-tracking-pytorch.git",2024-09-13,2024,2024-09,education
"AI-Driven Virtual Teacher for Enhanced Educational Efficiency:
  Leveraging Large Pretrain Models for Autonomous Error Analysis and Correction","Students frequently make mistakes while solving mathematical problems, and
traditional error correction methods are both time-consuming and
labor-intensive. This paper introduces an innovative \textbf{V}irtual
\textbf{A}I \textbf{T}eacher system designed to autonomously analyze and
correct student \textbf{E}rrors (VATE). Leveraging advanced large language
models (LLMs), the system uses student drafts as a primary source for error
analysis, which enhances understanding of the student's learning process. It
incorporates sophisticated prompt engineering and maintains an error pool to
reduce computational overhead. The AI-driven system also features a real-time
dialogue component for efficient student interaction. Our approach demonstrates
significant advantages over traditional and machine learning-based error
correction methods, including reduced educational costs, high scalability, and
superior generalizability. The system has been deployed on the Squirrel AI
learning platform for elementary mathematics education, where it achieves
78.3\% accuracy in error analysis and shows a marked improvement in student
learning efficiency. Satisfaction surveys indicate a strong positive reception,
highlighting the system's potential to transform educational practices.",2024-09-14,2024,2024-09,education
Strategic AI Governance: Insights from Leading Nations,"Artificial Intelligence (AI) has the potential to revolutionize various
sectors, yet its adoption is often hindered by concerns about data privacy,
security, and the understanding of AI capabilities. This paper synthesizes AI
governance approaches, strategic themes, and enablers and challenges for AI
adoption by reviewing national AI strategies from leading nations. The key
contribution is the development of an EPIC (Education, Partnership,
Infrastructure, Community) framework, which maps AI implementation requirements
to fully realize social impacts and public good from successful and sustained
AI deployment. Through a multi-perspective content analysis of the latest AI
strategy documents, this paper provides a structured comparison of AI
governance strategies across nations. The findings offer valuable insights for
governments, academics, industries, and communities to enable responsible and
trustworthy AI deployments. Future work should focus on incorporating specific
requirements for developing countries and applying the strategies to specific
AI applications, industries, and the public sector.",2024-09-16,2024,2024-09,education
"Empowering Abilities: Increasing Representation of Students with
  Disabilities in the STEM Field","The ExploreSTEM Summer Camps 2023 were designed to deliver inclusive STEM
education to students aged 14 to 22 years with disabilities. This paper
presents a thorough examination of the 2023 camp program, emphasizing the
pivotal role of inclusive STEM education in potentially shaping students'
personal and academic trajectories. The curriculum encompassed four weeklong
fundamental STEM domains: Internet of Things (IoT), Computational Engineering,
Artificial Intelligence (AI), and Augmented and Virtual Reality (AR/VR). Within
Camp 1, students actively engaged with Dash robots, employing dedicated
programming environments to command actions and gather sensor data, fostering
interactions with the IoT platform and facilitating seamless data transmission.
Camp 2 was dedicated to acquainting students with foundational computational
engineering principles, establishing a robust framework for comprehending
intricate engineering concepts. Camp 3 commenced with insightful presentations
elucidating AI applications across multifaceted industries, including
engineering, healthcare, and education, illuminating AI's pervasive influence
on contemporary society. The primary aim of Camp 4 was to introduce students to
the immersive domains of AR and VR, showcasing their applications beyond
conventional STEM disciplines into everyday life experiences. The amalgamation
of informative presentations, interactive activities, and a nurturing learning
environment cultivated an engaging and enriching experience for all
participants. By embracing inclusivity and harnessing innovative pedagogical
approaches, the ExploreSTEM Summer Camps empowered students to explore,
innovate, and excel within the dynamic realm of STEM education.",2024-09-18,2024,2024-09,education
"Generative AI Is Not Ready for Clinical Use in Patient Education for
  Lower Back Pain Patients, Even With Retrieval-Augmented Generation","Low back pain (LBP) is a leading cause of disability globally. Following the
onset of LBP and subsequent treatment, adequate patient education is crucial
for improving functionality and long-term outcomes. Despite advancements in
patient education strategies, significant gaps persist in delivering
personalized, evidence-based information to patients with LBP. Recent
advancements in large language models (LLMs) and generative artificial
intelligence (GenAI) have demonstrated the potential to enhance patient
education. However, their application and efficacy in delivering educational
content to patients with LBP remain underexplored and warrant further
investigation. In this study, we introduce a novel approach utilizing LLMs with
Retrieval-Augmented Generation (RAG) and few-shot learning to generate tailored
educational materials for patients with LBP. Physical therapists manually
evaluated our model responses for redundancy, accuracy, and completeness using
a Likert scale. In addition, the readability of the generated education
materials is assessed using the Flesch Reading Ease score. The findings
demonstrate that RAG-based LLMs outperform traditional LLMs, providing more
accurate, complete, and readable patient education materials with less
redundancy. Having said that, our analysis reveals that the generated materials
are not yet ready for use in clinical practice. This study underscores the
potential of AI-driven models utilizing RAG to improve patient education for
LBP; however, significant challenges remain in ensuring the clinical relevance
and granularity of content generated by these models.",2024-09-23,2024,2024-09,education
"RAM2C: A Liberal Arts Educational Chatbot based on Retrieval-augmented
  Multi-role Multi-expert Collaboration","Recently, many studies focus on utilizing large language models (LLMs) into
educational dialogues. Especially, within liberal arts dialogues, educators
must balance \textbf{H}umanized communication, \textbf{T}eaching expertise, and
\textbf{S}afety-ethics (\textbf{HTS}), besides the subject knowledge itself.
However, due to collecting massive amounts of HTS-compliant teaching dialogues
from real world as training corpus is expensive, the outputs of existing LLMs
in teaching dialogues fall short of human standards. To address this, we design
a Retrieval-augmented Multi-role Multi-expert Collaboration (RAM2C) framework
to automatically generate such dialogues data. Specifically, we first establish
HTS-guided knowledge bases, encompassing three domain knowledge in teaching
skills, psychology, and safety ethics. Then, RAM2C organizes LLMs, which are
retrieval-augmented by the above different knowledge bases, into multi-experts
groups with distinct roles to generate the HTS-compliant educational dialogues
dataset. We then fine-tuned the LLMs using this dataset. Empirical evaluations
indicate that RM2C-empowered LLMs excel in Chinese reading teaching, offering
more personalized, and ethically safe teaching response, demonstrating RAM2C's
practicality and high quality. We release the experiments at
\hyperlink{https://github.com/ram2c/ram2c}{https://github.com/ram2c/ram2c}.",2024-09-23,2024,2024-09,education
"Beyond Text-to-Text: An Overview of Multimodal and Generative Artificial
  Intelligence for Education Using Topic Modeling","Generative artificial intelligence (GenAI) can reshape education and
learning. While large language models (LLMs) like ChatGPT dominate current
educational research, multimodal capabilities, such as text-to-speech and
text-to-image, are less explored. This study uses topic modeling to map the
research landscape of multimodal and generative AI in education. An extensive
literature search using Dimensions yielded 4175 articles. Employing a topic
modeling approach, latent topics were extracted, resulting in 38 interpretable
topics organized into 14 thematic areas. Findings indicate a predominant focus
on text-to-text models in educational contexts, with other modalities
underexplored, overlooking the broader potential of multimodal approaches. The
results suggest a research gap, stressing the importance of more balanced
attention across different AI modalities and educational levels. In summary,
this research provides an overview of current trends in generative AI for
education, underlining opportunities for future exploration of multimodal
technologies to fully realize the transformative potential of artificial
intelligence in education.",2024-09-24,2024,2024-09,education
"CJEval: A Benchmark for Assessing Large Language Models Using Chinese
  Junior High School Exam Data","Online education platforms have significantly transformed the dissemination
of educational resources by providing a dynamic and digital infrastructure.
With the further enhancement of this transformation, the advent of Large
Language Models (LLMs) has elevated the intelligence levels of these platforms.
However, current academic benchmarks provide limited guidance for real-world
industry scenarios. This limitation arises because educational applications
require more than mere test question responses. To bridge this gap, we
introduce CJEval, a benchmark based on Chinese Junior High School Exam
Evaluations. CJEval consists of 26,136 samples across four application-level
educational tasks covering ten subjects. These samples include not only
questions and answers but also detailed annotations such as question types,
difficulty levels, knowledge concepts, and answer explanations. By utilizing
this benchmark, we assessed LLMs' potential applications and conducted a
comprehensive analysis of their performance by fine-tuning on various
educational tasks. Extensive experiments and discussions have highlighted the
opportunities and challenges of applying LLMs in the field of education.",2024-09-24,2024,2024-09,education
"From Passive Watching to Active Learning: Empowering Proactive
  Participation in Digital Classrooms with AI Video Assistant","In online education, innovative tools are crucial for enhancing learning
outcomes. SAM (Study with AI Mentor) is an advanced platform that integrates
educational videos with a context-aware chat interface powered by large
language models. SAM encourages students to ask questions and explore unclear
concepts in real time, offering personalized, context-specific assistance,
including explanations of formulas, slides, and images. We evaluated SAM in two
studies: one with 25 university students and another with 80 crowdsourced
participants, using pre- and post-knowledge tests to compare a group using SAM
and a control group. The results demonstrated that SAM users achieved greater
knowledge gains specifically for younger learners and individuals in flexible
working environments, such as students, supported by a 97.6% accuracy rate in
the chatbot's responses. Participants also provided positive feedback on SAM's
usability and effectiveness. SAM's proactive approach to learning not only
enhances learning outcomes but also empowers students to take full ownership of
their educational experience, representing a promising future direction for
online learning tools.",2024-09-24,2024,2024-09,education
Automated Assessment of Multimodal Answer Sheets in the STEM domain,"In the domain of education, the integration of,technology has led to a
transformative era, reshaping traditional,learning paradigms. Central to this
evolution is the automation,of grading processes, particularly within the STEM
domain encompassing Science, Technology, Engineering, and Mathematics.,While
efforts to automate grading have been made in subjects,like Literature, the
multifaceted nature of STEM assessments,presents unique challenges, ranging
from quantitative analysis,to the interpretation of handwritten diagrams. To
address these,challenges, this research endeavors to develop efficient and
reliable grading methods through the implementation of automated,assessment
techniques using Artificial Intelligence (AI). Our,contributions lie in two key
areas: firstly, the development of a,robust system for evaluating textual
answers in STEM, leveraging,sample answers for precise comparison and grading,
enabled by,advanced algorithms and natural language processing
techniques.,Secondly, a focus on enhancing diagram evaluation,
particularly,flowcharts, within the STEM context, by transforming diagrams,into
textual representations for nuanced assessment using a,Large Language Model
(LLM). By bridging the gap between,visual representation and semantic meaning,
our approach ensures accurate evaluation while minimizing manual
intervention.,Through the integration of models such as CRAFT for
text,extraction and YoloV5 for object detection, coupled with LLMs,like
Mistral-7B for textual evaluation, our methodology facilitates,comprehensive
assessment of multimodal answer sheets. This,paper provides a detailed account
of our methodology, challenges,encountered, results, and implications,
emphasizing the potential,of AI-driven approaches in revolutionizing grading
practices in,STEM education.",2024-09-24,2024,2024-09,education
Code Generation and Algorithmic Problem Solving Using Llama 3.1 405B,"Code generation by Llama 3.1 models, such as Meta's Llama 3.1 405B,
represents a significant advancement in the field of artificial intelligence,
particularly in natural language processing and programming automation. This
paper explores the capabilities and applications of Llama-driven code
generation, highlighting its ability to translate natural language prompts into
executable code across multiple programming languages. Key features include
contextual awareness, multi-language support, and enhanced debugging and
optimization functionalities. By examining these aspects, we illustrate how
Llama can serve as a versatile tool for developers of all skill levels,
improving productivity and efficiency in software development. The potential
implications for education, industry, and the future of coding practices are
also discussed, underscoring the transformative impact of AI in programming.
Experimentation shows that while Llama 3.1 405B performs well with simple
algorithmic and data structure based problems, it still struggles with problems
on Quantum Computing, Bioinformatics, and Artificial Intelligence.",2024-09-26,2024,2024-09,education
"The application of GPT-4 in grading design university students'
  assignment and providing feedback: An exploratory study","This study aims to investigate whether GPT-4 can effectively grade
assignments for design university students and provide useful feedback. In
design education, assignments do not have a single correct answer and often
involve solving an open-ended design problem. This subjective nature of design
projects often leads to grading problems,as grades can vary between different
raters,for instance instructor from engineering background or architecture
background. This study employs an iterative research approach in developing a
Custom GPT with the aim of achieving more reliable results and testing whether
it can provide design students with constructive feedback. The findings
include: First,through several rounds of iterations the inter-reliability
between GPT and human raters reached a level that is generally accepted by
educators. This indicates that by providing accurate prompts to GPT,and
continuously iterating to build a Custom GPT, it can be used to effectively
grade students' design assignments, serving as a reliable complement to human
raters. Second, the intra-reliability of GPT's scoring at different times is
between 0.65 and 0.78. This indicates that, with adequate instructions, a
Custom GPT gives consistent results which is a precondition for grading
students. As consistency and comparability are the two main rules to ensure the
reliability of educational assessment, this study has looked at whether a
Custom GPT can be developed that adheres to these two rules. We finish the
paper by testing whether Custom GPT can provide students with useful feedback
and reflecting on how educators can develop and iterate a Custom GPT to serve
as a complementary rater.",2024-09-26,2024,2024-09,education
bnRep: A repository of Bayesian networks from the academic literature,"Bayesian networks (BNs) are widely used for modeling complex systems with
uncertainty, yet repositories of pre-built BNs remain limited. This paper
introduces bnRep, an open-source R package offering a comprehensive collection
of documented BNs, facilitating benchmarking, replicability, and education.
With over 200 networks from academic publications, bnRep integrates seamlessly
with bnlearn and other R packages, providing users with interactive tools for
network exploration.",2024-09-27,2024,2024-09,education
"Integrating AI Education in Disciplinary Engineering Fields: Towards a
  System and Change Perspective","Building up competencies in working with data and tools of Artificial
Intelligence (AI) is becoming more relevant across disciplinary engineering
fields. While the adoption of tools for teaching and learning, such as ChatGPT,
is garnering significant attention, integration of AI knowledge, competencies,
and skills within engineering education is lacking. Building upon existing
curriculum change research, this practice paper introduces a systems
perspective on integrating AI education within engineering through the lens of
a change model. In particular, it identifies core aspects that shape AI
adoption on a program level as well as internal and external influences using
existing literature and a practical case study. Overall, the paper provides an
analysis frame to enhance the understanding of change initiatives and builds
the basis for generalizing insights from different initiatives in the adoption
of AI in engineering education.",2024-09-28,2024,2024-09,education
"MedQA-CS: Benchmarking Large Language Models Clinical Skills Using an
  AI-SCE Framework","Artificial intelligence (AI) and large language models (LLMs) in healthcare
require advanced clinical skills (CS), yet current benchmarks fail to evaluate
these comprehensively. We introduce MedQA-CS, an AI-SCE framework inspired by
medical education's Objective Structured Clinical Examinations (OSCEs), to
address this gap. MedQA-CS evaluates LLMs through two instruction-following
tasks, LLM-as-medical-student and LLM-as-CS-examiner, designed to reflect real
clinical scenarios. Our contributions include developing MedQA-CS, a
comprehensive evaluation framework with publicly available data and expert
annotations, and providing the quantitative and qualitative assessment of LLMs
as reliable judges in CS evaluation. Our experiments show that MedQA-CS is a
more challenging benchmark for evaluating clinical skills than traditional
multiple-choice QA benchmarks (e.g., MedQA). Combined with existing benchmarks,
MedQA-CS enables a more comprehensive evaluation of LLMs' clinical capabilities
for both open- and closed-source LLMs.",2024-10-02,2024,2024-10,education
"Transforming Teachers' Roles and Agencies in the Era of Generative AI:
  Perceptions, Acceptance, Knowledge, and Practices","This paper explores the transformative impact of Generative Artificial
Intelligence (GenAI) on teachers' roles and agencies in education, presenting a
comprehensive framework that addresses teachers' perceptions, knowledge,
acceptance, and practices of GenAI. As GenAI technologies, such as ChatGPT,
become increasingly integrated into educational settings, teachers are required
to adapt to evolving classroom dynamics, where AI plays a significant role in
content creation, personalized learning, and student engagement. However,
existing literature often treats these factors in isolation, overlooking how
they collectively influence teachers' ability to effectively integrate GenAI
into their pedagogical practices. This paper fills this gap by proposing a
framework that categorizes teachers into four roles -- Observer, Adopter,
Collaborator, and Innovator -- each representing different levels of GenAI
engagement, outlining teachers' agencies in GenAI classrooms. By highlighting
the need for continuous professional development and institutional support, we
demonstrate how teachers can evolve from basic GenAI users to co-creators of
knowledge alongside GenAI systems. The findings emphasize that for GenAI to
reach its full educational potential, teachers must not only accept and
understand its capabilities but also integrate it deeply into their teaching
strategies. This study contributes to the growing literature on GenAI in
education, offering practical implications for supporting teachers in
navigating the complexities of GenAI adoption.",2024-10-03,2024,2024-10,education
"Artificial Human Lecturers: Initial Findings From Asia's First AI
  Lecturers in Class to Promote Innovation in Education","In recent years, artificial intelligence (AI) has become increasingly
integrated into education, reshaping traditional learning environments. Despite
this, there has been limited investigation into fully operational artificial
human lecturers. To the best of our knowledge, our paper presents the world's
first study examining their deployment in a real-world educational setting.
Specifically, we investigate the use of ""digital teachers,"" AI-powered virtual
lecturers, in a postgraduate course at the Hong Kong University of Science and
Technology (HKUST). Our study explores how features such as appearance,
non-verbal cues, voice, and verbal expression impact students' learning
experiences. Findings suggest that students highly value naturalness,
authenticity, and interactivity in digital teachers, highlighting areas for
improvement, such as increased responsiveness, personalized avatars, and
integration with larger learning platforms. We conclude that digital teachers
have significant potential to enhance education by providing a more flexible,
engaging, personalized, and accessible learning experience for students.",2024-10-04,2024,2024-10,education
"An Innovative Solution: AI-Based Digital Screen-Integrated Tables for
  Educational Settings","In this paper, we have gone through different AI-Based frameworks used for
various educational tasks like digital customized assignment allotment and
performance monitoring, identifying slow-learners and fast-learners, etc.
application describes a novel invention, digital screen-integrated tables,
designed specifically for educational settings. The tables feature integrated
digital screens controlled by a central processing unit (CPU), enabling
synchronized display of educational content such as textbooks, presentations,
exam questions, and interactive learning materials. Additionally, the invention
facilitates the collection of student performance data during classroom
activities and assessments. The gathered data is utilized for analysis using
machine learning models to identify patterns and trends in student learning
behaviours. By leveraging machine learning algorithms, educators can ascertain
whether a student is a fast learner or a slow learner, based on which, the
teacher can allocate more resources to the slow learners. This innovative
approach aims to address the evolving needs of modern classrooms by providing a
dynamic and data-driven learning environment. The unique integration of digital
screens into traditional classroom furniture represents a significant
advancement in educational technology. This patent filing encompasses the
design, functionality, and method of operation of the digital screen-integrated
tables, emphasizing their innovative features and applications in educational
institutions.",2024-10-08,2024,2024-10,education
"FAIREDU: A Multiple Regression-Based Method for Enhancing Fairness in
  Machine Learning Models for Educational Applications","Fairness in artificial intelligence and machine learning (AI/ML) models is
becoming critically important, especially as decisions made by these systems
impact diverse groups. In education, a vital sector for all countries, the
widespread application of AI/ML systems raises specific concerns regarding
fairness. Current research predominantly focuses on fairness for individual
sensitive features, which limits the comprehensiveness of fairness assessments.
This paper introduces FAIREDU, a novel and effective method designed to improve
fairness across multiple sensitive features. Through extensive experiments, we
evaluate FAIREDU effectiveness in enhancing fairness without compromising model
performance. The results demonstrate that FAIREDU addresses intersectionality
across features such as gender, race, age, and other sensitive features,
outperforming state-of-the-art methods with minimal effect on model accuracy.
The paper also explores potential future research directions to enhance further
the method robustness and applicability to various machine-learning models and
datasets.",2024-10-08,2024,2024-10,education
"Towards an Operational Responsible AI Framework for Learning Analytics
  in Higher Education","Universities are increasingly adopting data-driven strategies to enhance
student success, with AI applications like Learning Analytics (LA) and
Predictive Learning Analytics (PLA) playing a key role in identifying at-risk
students, personalising learning, supporting teachers, and guiding educational
decision-making. However, concerns are rising about potential harms these
systems may pose, such as algorithmic biases leading to unequal support for
minority students. While many have explored the need for Responsible AI in LA,
existing works often lack practical guidance for how institutions can
operationalise these principles. In this paper, we propose a novel Responsible
AI framework tailored specifically to LA in Higher Education (HE). We started
by mapping 11 established Responsible AI frameworks, including those by leading
tech companies, to the context of LA in HE. This led to the identification of
seven key principles such as transparency, fairness, and accountability. We
then conducted a systematic review of the literature to understand how these
principles have been applied in practice. Drawing from these findings, we
present a novel framework that offers practical guidance to HE institutions and
is designed to evolve with community input, ensuring its relevance as LA
systems continue to develop.",2024-10-08,2024,2024-10,education
"Exploring Natural Language-Based Strategies for Efficient Number
  Learning in Children through Reinforcement Learning","This paper investigates how children learn numbers using the framework of
reinforcement learning (RL), with a focus on the impact of language
instructions. The motivation for using reinforcement learning stems from its
parallels with psychological learning theories in controlled environments. By
using state of the art deep reinforcement learning models, we simulate and
analyze the effects of various forms of language instructions on number
acquisition. Our findings indicate that certain linguistic structures more
effectively improve numerical comprehension in RL agents. Additionally, our
model predicts optimal sequences for presenting numbers to RL agents which
enhance their speed of learning. This research provides valuable insights into
the interplay between language and numerical cognition, with implications for
both educational strategies and the development of artificial intelligence
systems designed to support early childhood learning.",2024-10-10,2024,2024-10,education
"Integrating AI for Enhanced Feedback in Translation Revision- A
  Mixed-Methods Investigation of Student Engagement","Despite the well-established importance of feedback in education, the
application of Artificial Intelligence (AI)-generated feedback, particularly
from language models like ChatGPT, remains understudied in translation
education. This study investigates the engagement of master's students in
translation with ChatGPT-generated feedback during their revision process. A
mixed-methods approach, combining a translation-and-revision experiment with
quantitative and qualitative analyses, was employed to examine the feedback,
translations pre-and post-revision, the revision process, and student
reflections. The results reveal complex interrelations among cognitive,
affective, and behavioural dimensions influencing students' engagement with AI
feedback and their subsequent revisions. Specifically, the findings indicate
that students invested considerable cognitive effort in the revision process,
despite finding the feedback comprehensible. Additionally, they exhibited
moderate affective satisfaction with the feedback model. Behaviourally, their
actions were largely influenced by cognitive and affective factors, although
some inconsistencies were observed. This research provides novel insights into
the potential applications of AI-generated feedback in translation teachingand
opens avenues for further investigation into the integration of AI tools in
language teaching settings.",2024-10-11,2024,2024-10,education
"A Systematic Assessment of OpenAI o1-Preview for Higher Order Thinking
  in Education","As artificial intelligence (AI) continues to advance, it demonstrates
capabilities comparable to human intelligence, with significant potential to
transform education and workforce development. This study evaluates OpenAI
o1-preview's ability to perform higher-order cognitive tasks across 14
dimensions, including critical thinking, systems thinking, computational
thinking, design thinking, metacognition, data literacy, creative thinking,
abstract reasoning, quantitative reasoning, logical reasoning, analogical
reasoning, and scientific reasoning. We used validated instruments like the
Ennis-Weir Critical Thinking Essay Test and the Biological Systems Thinking
Test to compare the o1-preview's performance with human performance
systematically. Our findings reveal that o1-preview outperforms humans in most
categories, achieving 150% better results in systems thinking, computational
thinking, data literacy, creative thinking, scientific reasoning, and abstract
reasoning. However, compared to humans, it underperforms by around 25% in
logical reasoning, critical thinking, and quantitative reasoning. In analogical
reasoning, both o1-preview and humans achieved perfect scores. Despite these
strengths, the o1-preview shows limitations in abstract reasoning, where human
psychology students outperform it, highlighting the continued importance of
human oversight in tasks requiring high-level abstraction. These results have
significant educational implications, suggesting a shift toward developing
human skills that complement AI, such as creativity, abstract reasoning, and
critical thinking. This study emphasizes the transformative potential of AI in
education and calls for a recalibration of educational goals, teaching methods,
and curricula to align with an AI-driven world.",2024-10-11,2024,2024-10,education
Hey AI Can You Grade My Essay?: Automatic Essay Grading,"Automatic essay grading (AEG) has attracted the the attention of the NLP
community because of its applications to several educational applications, such
as scoring essays, short answers, etc. AEG systems can save significant time
and money when grading essays. In the existing works, the essays are graded
where a single network is responsible for the whole process, which may be
ineffective because a single network may not be able to learn all the features
of a human-written essay. In this work, we have introduced a new model that
outperforms the state-of-the-art models in the field of AEG. We have used the
concept of collaborative and transfer learning, where one network will be
responsible for checking the grammatical and structural features of the
sentences of an essay while another network is responsible for scoring the
overall idea present in the essay. These learnings are transferred to another
network to score the essay. We also compared the performances of the different
models mentioned in our work, and our proposed model has shown the highest
accuracy of 85.50%.",2024-10-12,2024,2024-10,education
"Generative AI and Its Impact on Personalized Intelligent Tutoring
  Systems","Generative Artificial Intelligence (AI) is revolutionizing educational
technology by enabling highly personalized and adaptive learning environments
within Intelligent Tutoring Systems (ITS). This report delves into the
integration of Generative AI, particularly large language models (LLMs) like
GPT-4, into ITS to enhance personalized education through dynamic content
generation, real-time feedback, and adaptive learning pathways. We explore key
applications such as automated question generation, customized feedback
mechanisms, and interactive dialogue systems that respond to individual learner
needs. The report also addresses significant challenges, including ensuring
pedagogical accuracy, mitigating inherent biases in AI models, and maintaining
learner engagement. Future directions highlight the potential advancements in
multimodal AI integration, emotional intelligence in tutoring systems, and the
ethical implications of AI-driven education. By synthesizing current research
and practical implementations, this report underscores the transformative
potential of Generative AI in creating more effective, equitable, and engaging
educational experiences.",2024-10-14,2024,2024-10,education
"Personalised Feedback Framework for Online Education Programmes Using
  Generative AI","AI tools, particularly large language modules, have recently proven their
effectiveness within learning management systems and online education
programmes. As feedback continues to play a crucial role in learning and
assessment in schools, educators must carefully customise the use of AI tools
in order to optimally support students in their learning journey. Efforts to
improve educational feedback systems have seen numerous attempts reflected in
the research studies but mostly have been focusing on qualitatively
benchmarking AI feedback against human-generated feedback. This paper presents
an exploration of an alternative feedback framework which extends the
capabilities of ChatGPT by integrating embeddings, enabling a more nuanced
understanding of educational materials and facilitating topic-targeted feedback
for quiz-based assessments. As part of the study, we proposed and developed a
proof of concept solution, achieving an efficacy rate of 90% and 100% for
open-ended and multiple-choice questions, respectively. The results showed that
our framework not only surpasses expectations but also rivals human narratives,
highlighting the potential of AI in revolutionising educational feedback
mechanisms.",2024-10-14,2024,2024-10,education
"HR-Agent: A Task-Oriented Dialogue (TOD) LLM Agent Tailored for HR
  Applications","Recent LLM (Large Language Models) advancements benefit many fields such as
education and finance, but HR has hundreds of repetitive processes, such as
access requests, medical claim filing and time-off submissions, which are
unaddressed. We relate these tasks to the LLM agent, which has addressed tasks
such as writing assisting and customer support. We present HR-Agent, an
efficient, confidential, and HR-specific LLM-based task-oriented dialogue
system tailored for automating repetitive HR processes such as medical claims
and access requests. Since conversation data is not sent to an LLM during
inference, it preserves confidentiality required in HR-related tasks.",2024-10-15,2024,2024-10,education
"Perceptions of Discriminatory Decisions of Artificial Intelligence:
  Unpacking the Role of Individual Characteristics","This study investigates how personal differences (digital self-efficacy,
technical knowledge, belief in equality, political ideology) and demographic
factors (age, education, and income) are associated with perceptions of
artificial intelligence (AI) outcomes exhibiting gender and racial bias and
with general attitudes towards AI. Analyses of a large-scale experiment dataset
(N = 1,206) indicate that digital self-efficacy and technical knowledge are
positively associated with attitudes toward AI, while liberal ideologies are
negatively associated with outcome trust, higher negative emotion, and greater
skepticism. Furthermore, age and income are closely connected to cognitive gaps
in understanding discriminatory AI outcomes. These findings highlight the
importance of promoting digital literacy skills and enhancing digital
self-efficacy to maintain trust in AI and beliefs in AI usefulness and safety.
The findings also suggest that the disparities in understanding problematic AI
outcomes may be aligned with economic inequalities and generational gaps in
society. Overall, this study sheds light on the socio-technological system in
which complex interactions occur between social hierarchies, divisions, and
machines that reflect and exacerbate the disparities.",2024-10-17,2024,2024-10,education
"Co-Designing with Algorithms: Unpacking the Complex Role of GenAI in
  Interactive System Design Education","Generative Artificial Intelligence (GenAI) is transforming Human-Computer
Interaction (HCI) education and technology design, yet its impact remains
poorly understood. This study explores how graduate students in an applied HCI
course used GenAI tools during interactive device design. Despite no
encouragement, all groups integrated GenAI into their workflows. Through 12
post-class group interviews, we identified how GenAI co-design behaviors
present both benefits, such as enhanced creativity and faster design
iterations, and risks, including shallow learning and reflection. Benefits were
most evident during the execution phases, while the discovery and reflection
phases showed limited gains. A taxonomy of usage patterns revealed that
students' outcomes depended more on how they used GenAI than the specific tasks
performed. These findings highlight the need for HCI education to adapt to
GenAI's role and offer recommendations for curricula to better prepare future
designers for effective creative co-design.",2024-10-17,2024,2024-10,education
Human-Centric eXplainable AI in Education,"As artificial intelligence (AI) becomes more integrated into educational
environments, how can we ensure that these systems are both understandable and
trustworthy? The growing demand for explainability in AI systems is a critical
area of focus. This paper explores Human-Centric eXplainable AI (HCXAI) in the
educational landscape, emphasizing its role in enhancing learning outcomes,
fostering trust among users, and ensuring transparency in AI-driven tools,
particularly through the innovative use of large language models (LLMs). What
challenges arise in the implementation of explainable AI in educational
contexts? This paper analyzes these challenges, addressing the complexities of
AI models and the diverse needs of users. It outlines comprehensive frameworks
for developing HCXAI systems that prioritize user understanding and engagement,
ensuring that educators and students can effectively interact with these
technologies. Furthermore, what steps can educators, developers, and
policymakers take to create more effective, inclusive, and ethically
responsible AI solutions in education? The paper provides targeted
recommendations to address this question, highlighting the necessity of
prioritizing explainability. By doing so, how can we leverage AI's
transformative potential to foster equitable and engaging educational
experiences that support diverse learners?",2024-10-18,2024,2024-10,education
GenAI Assisting Medical Training,"Medical procedures such as venipuncture and cannulation are essential for
nurses and require precise skills. Learning this skill, in turn, is a challenge
for educators due to the number of teachers per class and the complexity of the
task. The study aims to help students with skill acquisition and alleviate the
educator's workload by integrating generative AI methods to provide real-time
feedback on medical procedures such as venipuncture and cannulation.",2024-10-21,2024,2024-10,education
"Kenyan Sign Language (KSL) Dataset: Using Artificial Intelligence (AI)
  in Bridging Communication Barrier among the Deaf Learners","Kenyan Sign Language (KSL) is the primary language used by the deaf community
in Kenya. It is the medium of instruction from Pre-primary 1 to university
among deaf learners, facilitating their education and academic achievement.
Kenyan Sign Language is used for social interaction, expression of needs,
making requests and general communication among persons who are deaf in Kenya.
However, there exists a language barrier between the deaf and the hearing
people in Kenya. Thus, the innovation on AI4KSL is key in eliminating the
communication barrier. Artificial intelligence for KSL is a two-year research
project (2023-2024) that aims to create a digital open-access AI of spontaneous
and elicited data from a representative sample of the Kenyan deaf community.
The purpose of this study is to develop AI assistive technology dataset that
translates English to KSL as a way of fostering inclusion and bridging language
barriers among deaf learners in Kenya. Specific objectives are: Build KSL
dataset for spoken English and video recorded Kenyan Sign Language and to build
transcriptions of the KSL signs to a phonetic-level interface of the sign
language. In this paper, the methodology for building the dataset is described.
Data was collected from 48 teachers and tutors of the deaf learners and 400
learners who are Deaf. Participants engaged mainly in sign language elicitation
tasks through reading and singing. Findings of the dataset consisted of about
14,000 English sentences with corresponding KSL Gloss derived from a pool of
about 4000 words and about 20,000 signed KSL videos that are either signed
words or sentences. The second level of data outcomes consisted of 10,000 split
and segmented KSL videos. The third outcome of the dataset consists of 4,000
transcribed words into five articulatory parameters according to HamNoSys
system.",2024-10-23,2024,2024-10,education
"Developing a Tutoring Dialog Dataset to Optimize LLMs for Educational
  Use","Recent advances in large language models (LLMs) have shown promise for
scalable educational applications, but their use in dialog-based tutoring
systems remains challenging due to the need for effective pedagogical
strategies and the high costs associated with expert-curated datasets. Our
study explores the use of smaller, more affordable LLMs for one-on-one tutoring
in the context of solving reading comprehension problems. We developed a
synthetic tutoring dialog dataset, evaluated by human teachers, and fine-tuned
a smaller LLM using this dataset. Furthermore, we conducted an interactive
experiment comparing the performance of the fine-tuned model with a larger
model in real-world tutoring scenarios. Our results show that the fine-tuned
model performs on par with the larger model but at a lower cost, demonstrating
a viable, cost-effective approach for implementing LLM-based tutoring systems
in educational settings.",2024-10-25,2024,2024-10,education
"Auto-assessment of assessment: A conceptual framework towards fulfilling
  the policy gaps in academic assessment practices","Education is being transformed by rapid advances in Artificial Intelligence
(AI), including emerging Generative Artificial Intelligence (GAI). Such
technology can significantly support academics and students by automating
monotonous tasks and making personalised suggestions. However, despite the
potential of the technology, there are significant concerns regarding AI
misuse, particularly by students in assessments. There are two schools of
thought: one advocates for a complete ban on it, while the other views it as a
valuable educational tool, provided it is governed by a robust usage policy.
This contradiction clearly indicates a major policy gap in academic practices,
and new policies are required to uphold academic standards while enabling staff
and students to benefit from technological advancements. We surveyed 117
academics from three countries (UK, UAE, and Iraq), and identified that most
academics retain positive opinions regarding AI in education. For example, the
majority of experienced academics do not favour complete bans, and they see the
potential benefits of AI for students, teaching staff, and academic
institutions. Importantly, academics specifically identified the particular
benefits of AI for autonomous assessment (71.79% of respondents agreed).
Therefore, for the first time, we propose a novel AI framework for autonomously
evaluating students' work (e.g., reports, coursework, etc.) and automatically
assigning grades based on their knowledge and in-depth understanding of the
submitted content. The survey results further highlight a significant lack of
awareness of modern AI-based tools (e.g., ChatGPT) among experienced academics,
a gap that must be addressed to uphold educational standards.",2024-10-28,2024,2024-10,education
"Standardization Trends on Safety and Trustworthiness Technology for
  Advanced AI","Artificial Intelligence (AI) has rapidly evolved over the past decade and has
advanced in areas such as language comprehension, image and video recognition,
programming, and scientific reasoning. Recent AI technologies based on large
language models and foundation models are approaching or surpassing artificial
general intelligence. These systems demonstrate superior performance in complex
problem solving, natural language processing, and multi-domain tasks, and can
potentially transform fields such as science, industry, healthcare, and
education. However, these advancements have raised concerns regarding the
safety and trustworthiness of advanced AI, including risks related to
uncontrollability, ethical conflicts, long-term socioeconomic impacts, and
safety assurance. Efforts are being expended to develop internationally
agreed-upon standards to ensure the safety and reliability of AI. This study
analyzes international trends in safety and trustworthiness standardization for
advanced AI, identifies key areas for standardization, proposes future
directions and strategies, and draws policy implications. The goal is to
support the safe and trustworthy development of advanced AI and enhance
international competitiveness through effective standardization.",2024-10-29,2024,2024-10,education
"Designing AI Personalities: Enhancing Human-Agent Interaction Through
  Thoughtful Persona Design","In the rapidly evolving field of artificial intelligence (AI) agents,
designing the agent's characteristics is crucial for shaping user experience.
This workshop aims to establish a research community focused on AI agent
persona design for various contexts, such as in-car assistants, educational
tools, and smart home environments. We will explore critical aspects of persona
design, such as voice, embodiment, and demographics, and their impact on user
satisfaction and engagement. Through discussions and hands-on activities, we
aim to propose practices and standards that enhance the ecological validity of
agent personas. Topics include the design of conversational interfaces, the
influence of agent personas on user experience, and approaches for creating
contextually appropriate AI agents. This workshop will provide a platform for
building a community dedicated to developing AI agent personas that better fit
diverse, everyday interactions.",2024-10-30,2024,2024-10,education
"Transfer Learning in Vocal Education: Technical Evaluation of Limited
  Samples Describing Mezzo-soprano","Vocal education in the music field is difficult to quantify due to the
individual differences in singers' voices and the different quantitative
criteria of singing techniques. Deep learning has great potential to be applied
in music education due to its efficiency to handle complex data and perform
quantitative analysis. However, accurate evaluations with limited samples over
rare vocal types, such as Mezzo-soprano, requires extensive well-annotated data
support using deep learning models. In order to attain the objective, we
perform transfer learning by employing deep learning models pre-trained on the
ImageNet and Urbansound8k datasets for the improvement on the precision of
vocal technique evaluation. Furthermore, we tackle the problem of the lack of
samples by constructing a dedicated dataset, the Mezzo-soprano Vocal Set (MVS),
for vocal technique assessment. Our experimental results indicate that transfer
learning increases the overall accuracy (OAcc) of all models by an average of
8.3%, with the highest accuracy at 94.2%. We not only provide a novel approach
to evaluating Mezzo-soprano vocal techniques but also introduce a new
quantitative assessment method for music education.",2024-10-30,2024,2024-10,education
GLAT: The Generative AI Literacy Assessment Test,"The rapid integration of generative artificial intelligence (GenAI)
technology into education necessitates precise measurement of GenAI literacy to
ensure that learners and educators possess the skills to engage with and
critically evaluate this transformative technology effectively. Existing
instruments often rely on self-reports, which may be biased. In this study, we
present the GenAI Literacy Assessment Test (GLAT), a 20-item multiple-choice
instrument developed following established procedures in psychological and
educational measurement. Structural validity and reliability were confirmed
with responses from 355 higher education students using classical test theory
and item response theory, resulting in a reliable 2-parameter logistic (2PL)
model (Cronbach's alpha = 0.80; omega total = 0.81) with a robust factor
structure (RMSEA = 0.03; CFI = 0.97). Critically, GLAT scores were found to be
significant predictors of learners' performance in GenAI-supported tasks,
outperforming self-reported measures such as perceived ChatGPT proficiency and
demonstrating external validity. These results suggest that GLAT offers a
reliable and valid method for assessing GenAI literacy, with the potential to
inform educational practices and policy decisions that aim to enhance learners'
and educators' GenAI literacy, ultimately equipping them to navigate an
AI-enhanced future.",2024-11-01,2024,2024-11,education
"Generative AI and Agency in Education: A Critical Scoping Review and
  Thematic Analysis","This scoping review examines the relationship between Generative AI (GenAI)
and agency in education, analyzing the literature available through the lens of
Critical Digital Pedagogy. Following PRISMA-ScR guidelines, we collected 10
studies from academic databases focusing on both learner and teacher agency in
GenAI-enabled environments. We conducted an AI-supported hybrid thematic
analysis that revealed three key themes: Control in Digital Spaces, Variable
Engagement and Access, and Changing Notions of Agency.
  The findings suggest that while GenAI may enhance learner agency through
personalization and support, it also risks exacerbating educational
inequalities and diminishing learner autonomy in certain contexts. This review
highlights gaps in the current research on GenAI's impact on agency. These
findings have implications for educational policy and practice, suggesting the
need for frameworks that promote equitable access while preserving learner
agency in GenAI-enhanced educational environments.",2024-11-01,2024,2024-11,education
"Artificial Intelligence Driven Course Generation: A Case Study Using
  ChatGPT","This study explores Artificial Intelligence use, specifically ChatGPT, in
creating educational content. The study aims to elaborate on using ChatGPT to
create course materials. The main objective is to assess the efficiency,
quality, and impact of AI-driven course generation, and to create a Multimedia
Databases course as a case study. The study highlights the potential of AI to
revolutionize educational content creation, making it more accessible,
personalized, and efficient. The course content was generated in less than one
day through iterative methods, using prompts for translation, content
expansion, practical examples, assignments, supplementary materials, and LaTeX
formatting. Each part was verified immediately after generation to ensure
accuracy. Post-generation analysis with Detectia and Turnitin showed similarity
rates of 8.7% and 13%, indicating high originality. Experts and university
committees reviewed and approved the course, with English university teachers
praising its language quality. ChatGPT also created a well-structured and
diversified exam for the module. Key findings reveal significant time
efficiency, comprehensive content coverage, and high flexibility. The study
underscores AI's transformative potential in education, addressing challenges
related to data privacy, technology dependence, content accuracy, and
algorithmic biases. The conclusions emphasize the need for collaboration
between educators, policymakers, and technology developers to harness AI's
benefits in education fully.",2024-11-02,2024,2024-11,education
"Transforming Engineering Education Using Generative AI and Digital Twin
  Technologies","Digital twin technology, traditionally used in industry, is increasingly
recognized for its potential to enhance educational experiences. This study
investigates the application of industrial digital twins (DTs) in education,
focusing on how DT models of varying fidelity can support different stages of
Bloom's taxonomy in the cognitive domain. We align Bloom's six cognitive stages
with educational levels: undergraduate studies for ""Remember"" and ""Understand,""
master's level for ""Apply"" and ""Analyze,"" and doctoral level for ""Evaluate"" and
""Create."" Low-fidelity DTs aid essential knowledge acquisition and skill
training, providing a low-risk environment for grasping fundamental concepts.
Medium-fidelity DTs offer more detailed and dynamic simulations, enhancing
application skills and problem-solving. High-fidelity DTs support advanced
learners by replicating physical phenomena, allowing for innovative design and
complex experiments. Within this framework, large language models (LLMs) serve
as mentors, assessing progress, filling knowledge gaps, and assisting with DT
interactions, parameter setting, and debugging. We evaluate the educational
impact using the Kirkpatrick Model, examining how each DT model's fidelity
influences learning outcomes. This framework helps educators make informed
decisions on integrating DTs and LLMs to meet specific learning objectives.",2024-11-02,2024,2024-11,education
"An Exploration of Higher Education Course Evaluation by Large Language
  Models","Course evaluation is a critical component in higher education pedagogy. It
not only serves to identify limitations in existing course designs and provide
a basis for curricular innovation, but also to offer quantitative insights for
university administrative decision-making. Traditional evaluation methods,
primarily comprising student surveys, instructor self-assessments, and expert
reviews, often encounter challenges, including inherent subjectivity, feedback
delays, inefficiencies, and limitations in addressing innovative teaching
approaches. Recent advancements in large language models (LLMs) within
artificial intelligence (AI) present promising new avenues for enhancing course
evaluation processes. This study explores the application of LLMs in automated
course evaluation from multiple perspectives and conducts rigorous experiments
across 100 courses at a major university in China. The findings indicate that:
(1) LLMs can be an effective tool for course evaluation; (2) their
effectiveness is contingent upon appropriate fine-tuning and prompt
engineering; and (3) LLM-generated evaluation results demonstrate a notable
level of rationality and interpretability.",2024-11-03,2024,2024-11,education
ChatGPT in Research and Education: Exploring Benefits and Threats,"In recent years, advanced artificial intelligence technologies, such as
ChatGPT, have significantly impacted various fields, including education and
research. Developed by OpenAI, ChatGPT is a powerful language model that
presents numerous opportunities for students and educators. It offers
personalized feedback, enhances accessibility, enables interactive
conversations, assists with lesson preparation and evaluation, and introduces
new methods for teaching complex subjects. However, ChatGPT also poses
challenges to traditional education and research systems. These challenges
include the risk of cheating on online exams, the generation of human-like text
that may compromise academic integrity, a potential decline in critical
thinking skills, and difficulties in assessing the reliability of information
generated by AI. This study examines both the opportunities and challenges
ChatGPT brings to education from the perspectives of students and educators.
Specifically, it explores the role of ChatGPT in helping students develop their
subjective skills. To demonstrate its effectiveness, we conducted several
subjective experiments using ChatGPT, such as generating solutions from
subjective problem descriptions. Additionally, surveys were conducted with
students and teachers to gather insights into how ChatGPT supports subjective
learning and teaching. The results and analysis of these surveys are presented
to highlight the impact of ChatGPT in this context.",2024-11-05,2024,2024-11,education
ICE-T: A Multi-Faceted Concept for Teaching Machine Learning,"The topics of Artificial intelligence (AI) and especially Machine Learning
(ML) are increasingly making their way into educational curricula. To
facilitate the access for students, a variety of platforms, visual tools, and
digital games are already being used to introduce ML concepts and strengthen
the understanding of how AI works. We take a look at didactic principles that
are employed for teaching computer science, define criteria, and, based on
those, evaluate a selection of prominent existing platforms, tools, and games.
Additionally, we criticize the approach of portraying ML mostly as a black-box
and the resulting missing focus on creating an understanding of data,
algorithms, and models that come with it. To tackle this issue, we present a
concept that covers intermodal transfer, computational and explanatory
thinking, ICE-T, as an extension of known didactic principles. With our
multi-faceted concept, we believe that planners of learning units, creators of
learning platforms and educators can improve on teaching ML.",2024-11-08,2024,2024-11,education
"VISTA: Visual Integrated System for Tailored Automation in Math Problem
  Generation Using LLM","Generating accurate and consistent visual aids is a critical challenge in
mathematics education, where visual representations like geometric shapes and
functions play a pivotal role in enhancing student comprehension. This paper
introduces a novel multi-agent framework that leverages Large Language Models
(LLMs) to automate the creation of complex mathematical visualizations
alongside coherent problem text. Our approach not only simplifies the
generation of precise visual aids but also aligns these aids with the problem's
core mathematical concepts, improving both problem creation and assessment. By
integrating multiple agents, each responsible for distinct tasks such as
numeric calculation, geometry validation, and visualization, our system
delivers mathematically accurate and contextually relevant problems with visual
aids. Evaluation across Geometry and Function problem types shows that our
method significantly outperforms basic LLMs in terms of text coherence,
consistency, relevance and similarity, while maintaining the essential
geometrical and functional integrity of the original problems. Although some
challenges remain in ensuring consistent visual outputs, our framework
demonstrates the immense potential of LLMs in transforming the way educators
generate and utilize visual aids in math education.",2024-11-08,2024,2024-11,education
"Generating Mixcode Popular Songs with Artificial Intelligence: Concepts,
  Plans, and Speculations","Music is a potent form of expression that can communicate, accentuate or even
create the emotions of an individual or a collective. Both historically and in
contemporary experiences, musical expression was and is commonly
instrumentalized for social, political and/or economic purposes. Generative
artificial intelligence provides a wealth of both opportunities and challenges
with regard to music and its role in society. This paper discusses a proposed
project integrating artificial intelligence and popular music, with the
ultimate goal of creating a powerful tool for implementing music for social
transformation, education, healthcare, and emotional well-being. Given that it
is being presented at the outset of a collaboration between a computer
scientist/data analyst and an ethnomusicologist/social anthropologist. it is
mainly conceptual and somewhat speculative in nature.",2024-11-10,2024,2024-11,education
"Prompts Matter: Comparing ML/GAI Approaches for Generating Inductive
  Qualitative Coding Results","Inductive qualitative methods have been a mainstay of education research for
decades, yet it takes much time and effort to conduct rigorously. Recent
advances in artificial intelligence, particularly with generative AI (GAI),
have led to initial success in generating inductive coding results. Like human
coders, GAI tools rely on instructions to work, and how to instruct it may
matter. To understand how ML/GAI approaches could contribute to qualitative
coding processes, this study applied two known and two theory-informed novel
approaches to an online community dataset and evaluated the resulting coding
results. Our findings show significant discrepancies between ML/GAI approaches
and demonstrate the advantage of our approaches, which introduce human coding
processes into GAI prompts.",2024-11-10,2024,2024-11,education
Artificial Intelligence Ecosystem for Automating Self-Directed Teaching,"This research introduces an innovative artificial intelligence-driven
educational concept designed to optimize self-directed learning through
personalized course delivery and automated teaching assistance. The system
leverages fine-tuned AI models to create an adaptive learning environment that
encompasses customized roadmaps, automated presentation generation, and
three-dimensional modeling for complex concept visualization. By integrating
real-time virtual assistance for doubt resolution, the platform addresses the
immediate educational needs of learners while promoting autonomous learning
practices. This study explores the psychological advantages of self-directed
learning and demonstrates how AI automation can enhance educational outcomes
through personalized content delivery and interactive support mechanisms. The
research contributes to the growing field of educational technology by
presenting a comprehensive framework that combines automated content
generation, visual learning aids, and intelligent tutoring to create an
efficient, scalable solution for modern educational needs. Preliminary findings
suggest that this approach not only accommodates diverse learning styles but
also strengthens student engagement and knowledge retention through its
emphasis on self-paced, independent learning methodologies.",2024-11-11,2024,2024-11,education
"LLM-Powered AI Tutors with Personas for d/Deaf and Hard-of-Hearing
  Online Learners","Intelligent tutoring systems (ITS) using artificial intelligence (AI)
technology have shown promise in supporting learners with diverse abilities;
however, they often fail to meet the specific communication needs and cultural
nuances needed by d/Deaf and Hard-of-Hearing (DHH) learners. As large language
models (LLMs) provide new opportunities to incorporate personas to AI-based
tutors and support dynamic interactive dialogue, this paper explores how DHH
learners perceive LLM-powered ITS with different personas and identified design
suggestions for improving the interaction. We developed an interface that
allows DHH learners to interact with ChatGPT and three LLM-powered AI tutors
with different experiences in DHH education while the learners watch an
educational video. A user study with 16 DHH participants showed that they
perceived conversations with the AI tutors who had DHH education experiences to
be more human-like and trustworthy due to the tutors' cultural knowledge of DHH
communities. Participants also suggested providing more transparency regarding
the tutors' background information to clarify each AI tutor's position within
the DHH community. We discuss design implications for more inclusive LLM-based
systems, such as supports for the multimodality of sign language.",2024-11-15,2024,2024-11,education
Education in the Era of Neurosymbolic AI,"Education is poised for a transformative shift with the advent of
neurosymbolic artificial intelligence (NAI), which will redefine how we support
deeply adaptive and personalized learning experiences. NAI-powered education
systems will be capable of interpreting complex human concepts and contexts
while employing advanced problem-solving strategies, all grounded in
established pedagogical frameworks. This will enable a level of personalization
in learning systems that to date has been largely unattainable at scale,
providing finely tailored curricula that adapt to an individual's learning pace
and accessibility needs, including the diagnosis of student understanding of
subjects at a fine-grained level, identifying gaps in foundational knowledge,
and adjusting instruction accordingly. In this paper, we propose a system that
leverages the unique affordances of pedagogical agents -- embodied characters
designed to enhance learning -- as critical components of a hybrid NAI
architecture. To do so, these agents can thus simulate nuanced discussions,
debates, and problem-solving exercises that push learners beyond rote
memorization toward deep comprehension. We discuss the rationale for our system
design and the preliminary findings of our work. We conclude that education in
the era of NAI will make learning more accessible, equitable, and aligned with
real-world skills. This is an era that will explore a new depth of
understanding in educational tools.",2024-11-16,2024,2024-11,education
"Early Adoption of Generative Artificial Intelligence in Computing
  Education: Emergent Student Use Cases and Perspectives in 2023","Because of the rapid development and increasing public availability of
Generative Artificial Intelligence (GenAI) models and tools, educational
institutions and educators must immediately reckon with the impact of students
using GenAI. There is limited prior research on computing students' use and
perceptions of GenAI. In anticipation of future advances and evolutions of
GenAI, we capture a snapshot of student attitudes towards and uses of yet
emerging GenAI, in a period of time before university policies had reacted to
these technologies. We surveyed all computer science majors in a small
engineering-focused R1 university in order to: (1) capture a baseline
assessment of how GenAI has been immediately adopted by aspiring computer
scientists; (2) describe computing students' GenAI-related needs and concerns
for their education and careers; and (3) discuss GenAI influences on CS
pedagogy, curriculum, culture, and policy. We present an exploratory
qualitative analysis of this data and discuss the impact of our findings on the
emerging conversation around GenAI and education.",2024-11-17,2024,2024-11,education
"A Pre-Trained Graph-Based Model for Adaptive Sequencing of Educational
  Documents","Massive Open Online Courses (MOOCs) have greatly contributed to making
education more accessible. However, many MOOCs maintain a rigid,
one-size-fits-all structure that fails to address the diverse needs and
backgrounds of individual learners. Learning path personalization aims to
address this limitation, by tailoring sequences of educational content to
optimize individual student learning outcomes. Existing approaches, however,
often require either massive student interaction data or extensive expert
annotation, limiting their broad application. In this study, we introduce a
novel data-efficient framework for learning path personalization that operates
without expert annotation. Our method employs a flexible recommender system
pre-trained with reinforcement learning on a dataset of raw course materials.
Through experiments on semi-synthetic data, we show that this pre-training
stage substantially improves data-efficiency in a range of adaptive learning
scenarios featuring new educational materials. This opens up new perspectives
for the design of foundation models for adaptive learning.",2024-11-18,2024,2024-11,education
"AI-powered Digital Framework for Personalized Economical Quality
  Learning at Scale","The disparity in access to quality education is significant, both between
developed and developing countries and within nations, regardless of their
economic status. Socioeconomic barriers and rapid changes in the job market
further intensify this issue, highlighting the need for innovative solutions
that can deliver quality education at scale and low cost. This paper addresses
these challenges by proposing an AI-powered digital learning framework grounded
in Deep Learning (DL) theory. The DL theory emphasizes learner agency and
redefines the role of teachers as facilitators, making it particularly suitable
for scalable educational environments. We outline eight key principles derived
from learning science and AI that are essential for implementing DL-based
Digital Learning Environments (DLEs). Our proposed framework leverages AI for
learner modelling based on Open Learner Modeling (OLM), activity suggestions,
and AI-assisted support for both learners and facilitators, fostering
collaborative and engaging learning experiences. Our framework provides a
promising direction for scalable, high-quality education globally, offering
practical solutions to some of the AI-related challenges in education.",2024-11-20,2024,2024-11,education
"Optimizing Student Ability Assessment: A Hierarchy Constraint-Aware
  Cognitive Diagnosis Framework for Educational Contexts","Cognitive diagnosis (CD) aims to reveal students' proficiency in specific
knowledge concepts. With the increasing adoption of intelligent education
applications, accurately assessing students' knowledge mastery has become an
urgent challenge. Although existing cognitive diagnosis frameworks enhance
diagnostic accuracy by analyzing students' explicit response records, they
primarily focus on individual knowledge state, failing to adequately reflect
the relative ability performance of students within hierarchies. To address
this, we propose the Hierarchy Constraint-Aware Cognitive Diagnosis Framework
(HCD), designed to more accurately represent student ability performance within
real educational contexts. Specifically, the framework introduces a hierarchy
mapping layer to identify students' levels. It then employs a hierarchy
convolution-enhanced attention layer for in-depth analysis of knowledge
concepts performance among students at the same level, uncovering nuanced
differences. A hierarchy inter-sampling attention layer captures performance
differences across hierarchies, offering a comprehensive understanding of the
relationships among students' knowledge state. Finally, through personalized
diagnostic enhancement, the framework integrates hierarchy constraint
perception features with existing models, improving the representation of both
individual and group characteristics. This approach enables precise inference
of students' knowledge state. Research shows that this framework not only
reasonably constrains changes in students' knowledge states to align with real
educational settings, but also supports the scientific rigor and fairness of
educational assessments, thereby advancing the field of cognitive diagnosis.",2024-11-21,2024,2024-11,education
"The CTSkills App -- Measuring Problem Decomposition Skills of Students
  in Computational Thinking","This paper addresses the incorporation of problem decomposition skills as an
important component of computational thinking (CT) in K-12 computer science
(CS) education. Despite the growing integration of CS in schools, there is a
lack of consensus on the precise definition of CT in general and decomposition
in particular. While decomposition is commonly referred to as the starting
point of (computational) problem-solving, algorithmic solution formulation
often receives more attention in the classroom, while decomposition remains
rather unexplored. This study presents ""CTSKills"", a web-based skill assessment
tool developed to measure students' problem decomposition skills. With the data
collected from 75 students in grades 4-9, this research aims to contribute to a
baseline of students' decomposition proficiency in compulsory education.
Furthermore, a thorough understanding of a given problem is becoming
increasingly important with the advancement of generative artificial
intelligence (AI) tools that can effectively support the process of formulating
algorithms. This study highlights the importance of problem decomposition as a
key skill in K-12 CS education to foster more adept problem solvers.",2024-11-22,2024,2024-11,education
"FEAD: Figma-Enhanced App Design Framework for Improving UI/UX in
  Educational App Development","Designing user-centric mobile applications is increasingly essential in
educational technology. However, platforms like MIT App Inventor-one of the
world's largest educational app development tools-face inherent limitations in
supporting modern UI/UX design. This study introduces the Figma-Enhanced App
Design (FEAD) Method, a structured framework that integrates Figma's advanced
design tools into MIT App Inventor using an identify-design-implement workflow.
Leveraging principles such as the 8-point grid system and Gestalt laws of
perception, the FEAD Method empowers users to address design gaps, creating
visually appealing, functional, and accessible applications. A comparative
evaluation revealed that 61.2% of participants perceived FEAD-enhanced designs
as on par with professional apps, compared to just 8.2% for baseline designs.
These findings highlight the potential of bridging design with development
platforms to enhance app creation, offering a scalable framework for students
to master both functional and aesthetic design principles and excel in shaping
the future of user-centric technology.",2024-11-22,2024,2024-11,education
"Understanding Student Acceptance, Trust, and Attitudes Toward
  AI-Generated Images for Educational Purposes","Recent advancements in artificial intelligence (AI) have broadened the
applicability of AI-generated images across various sectors, including the
creative industry and design. However, their utilization in educational
contexts, particularly among undergraduate students in computer science and
software engineering, remains underexplored. This study adopts an exploratory
approach, employing questionnaires and interviews, to assess students'
acceptance, trust, and positive attitudes towards AI-generated images for
educational tasks such as presentations, reports, and web design. The results
reveal high acceptance, trust, and positive attitudes among students who value
the ease of use and potential academic benefits. However, concerns regarding
the lack of technical precision, where the AI fails to accurately produce
images as specified by prompts, moderately impact their practical application
in detail-oriented educational tasks. These findings suggest a need for
developing comprehensive guidelines that address ethical considerations and
intellectual property issues, while also setting quality standards for
AI-generated images to enhance their educational use. Enhancing the
capabilities of AI tools to meet precise user specifications could foster
creativity and improve educational outcomes in technical disciplines.",2024-11-24,2024,2024-11,education
"Advancing Transformative Education: Generative AI as a Catalyst for
  Equity and Innovation","Generative AI is transforming education by enabling personalized learning,
enhancing administrative efficiency, and fostering creative engagement. This
paper explores the opportunities and challenges these tools bring to pedagogy,
proposing actionable frameworks to address existing equity gaps. Ethical
considerations such as algorithmic bias, data privacy, and AI role in human
centric education are emphasized. The findings underscore the need for
responsible AI integration that ensures accessibility, equity, and innovation
in educational systems.",2024-11-24,2024,2024-11,education
"Harnessing LLMs for Educational Content-Driven Italian Crossword
  Generation","In this work, we unveil a novel tool for generating Italian crossword puzzles
from text, utilizing advanced language models such as GPT-4o,
Mistral-7B-Instruct-v0.3, and Llama3-8b-Instruct. Crafted specifically for
educational applications, this cutting-edge generator makes use of the
comprehensive Italian-Clue-Instruct dataset, which comprises over 30,000
entries including diverse text, solutions, and types of clues. This carefully
assembled dataset is designed to facilitate the creation of contextually
relevant clues in various styles associated with specific texts and keywords.
The study delves into four distinctive styles of crossword clues: those without
format constraints, those formed as definite determiner phrases, copular
sentences, and bare noun phrases. Each style introduces unique linguistic
structures to diversify clue presentation. Given the lack of sophisticated
educational tools tailored to the Italian language, this project seeks to
enhance learning experiences and cognitive development through an engaging,
interactive platform. By meshing state-of-the-art AI with contemporary
educational strategies, our tool can dynamically generate crossword puzzles
from Italian educational materials, thereby providing an enjoyable and
interactive learning environment. This technological advancement not only
redefines educational paradigms but also sets a new benchmark for interactive
and cognitive language learning solutions.",2024-11-25,2024,2024-11,education
"Embracing AI in Education: Understanding the Surge in Large Language
  Model Use by Secondary Students","The impressive essay writing and problem-solving capabilities of large
language models (LLMs) like OpenAI's ChatGPT have opened up new avenues in
education. Our goal is to gain insights into the widespread use of LLMs among
secondary students to inform their future development. Despite school
restrictions, our survey of over 300 middle and high school students revealed
that a remarkable 70% of students have utilized LLMs, higher than the usage
percentage among young adults, and this percentage remains consistent across
7th to 12th grade. Students also reported using LLMs for multiple subjects,
including language arts, history, and math assignments, but expressed mixed
thoughts on their effectiveness due to occasional hallucinations in historical
contexts and incorrect answers for lack of rigorous reasoning. The survey
feedback called for LLMs better adapted for students, and also raised questions
to developers and educators on how to help students from underserved
communities leverage LLMs' capabilities for equal access to advanced education
resources. We propose a few ideas to address such issues, including
subject-specific models, personalized learning, and AI classrooms.",2024-11-27,2024,2024-11,education
Generative AI Literacy: Twelve Defining Competencies,"This paper introduces a competency-based model for generative artificial
intelligence (AI) literacy covering essential skills and knowledge areas
necessary to interact with generative AI. The competencies range from
foundational AI literacy to prompt engineering and programming skills,
including ethical and legal considerations. These twelve competencies offer a
framework for individuals, policymakers, government officials, and educators
looking to navigate and take advantage of the potential of generative AI
responsibly. Embedding these competencies into educational programs and
professional training initiatives can equip individuals to become responsible
and informed users and creators of generative AI. The competencies follow a
logical progression and serve as a roadmap for individuals seeking to get
familiar with generative AI and for researchers and policymakers to develop
assessments, educational programs, guidelines, and regulations.",2024-11-29,2024,2024-11,education
"The Impact of Generative AI on Student Churn and the Future of Formal
  Education","In the contemporary educational landscape, the advent of Generative
Artificial Intelligence (AI) presents unprecedented opportunities for
personalised learning, fundamentally challenging the traditional paradigms of
education. This research explores the emerging trend where high school
students, empowered by tailored educational experiences provided by Generative
AI, opt to forgo traditional university degrees to pursue entrepreneurial
ventures at a younger age. To understand and predict the future of education in
the age of Generative AI, we employ a comprehensive methodology to analyse
social media data. Our approach includes sentiment analysis to gauge public
opinion, topic modelling to identify key themes and emerging trends, and user
demographic analysis to understand the engagement of different age groups and
regions. We also perform influencer analysis to identify key figures shaping
the discourse and engagement metrics to measure the level of interest and
interaction with AI-related educational content. Content analysis helps us to
determine the types of content being shared and the prevalent narratives, while
hashtag analysis reveals the connectivity of discussions. The temporal analysis
tracks changes over time and identifies event-based spikes in discussions. The
insights derived from this analysis include the acceptance and adoption of
Generative AI in education, its impact on traditional education models, the
influence on students' entrepreneurial ambitions, and the educational outcomes
associated with AI-driven personalised learning. Additionally, we explore
public sentiment towards policies and regulations and use predictive modelling
to forecast future trends. This comprehensive social media analysis provides a
nuanced understanding of the evolving educational landscape, offering valuable
perspectives on the role of Generative AI in shaping the future of education.",2024-11-30,2024,2024-11,education
"Automatic answering of scientific questions using the FACTS-V1
  framework: New methods in research to increase efficiency through the use of
  AI","The use of artificial intelligence (AI) offers various possibilities to
expand and support educational research. Specifically, the implementation of AI
can be used to develop new frameworks to establish new research tools that
accelerate and meaningfully expand the efficiency of data evaluation and
interpretation (Buckingham Shum et al., 2023). This article presents the
prototype of the FACTS-V1 (Filtering and Analysis of Content in Textual
Sources) framework. With the help of the application, numerous scientific
papers can be automatically extracted, analyzed and interpreted from open
access document servers without having to rely on proprietary applications and
their limitations. The FACTS-V1 prototype consists of three building blocks.
The first part deals with the extraction of texts, the second with filtering
and interpretation, and the last with the actual statistical evaluation (topic
modeling) using an interactive overview. The aim of the framework is to provide
recommendations for future scientific questions based on existing data. The
functionality is illustrated by asking how the use of AI will change the
education sector. The data used to answer the question comes from 82 scientific
papers on the topic of AI from 2024. The papers are publicly available on the
peDOCS document server of the Leibniz Institute for Educational Research and
Educational Information.",2024-12-01,2024,2024-12,education
"The Advancement of Personalized Learning Potentially Accelerated by
  Generative AI","The rapid development of Generative AI (GAI) has sparked revolutionary
changes across various aspects of education. Personalized learning, a focal
point and challenge in educational research, has also been influenced by the
development of GAI. To explore GAI's extensive impact on personalized learning,
this study investigates its potential to enhance various facets of personalized
learning through a thorough analysis of existing research. The research
comprehensively examines GAI's influence on personalized learning by analyzing
its application across different methodologies and contexts, including learning
strategies, paths, materials, environments, and specific analyses within the
teaching and learning processes. Through this in-depth investigation, we find
that GAI demonstrates exceptional capabilities in providing adaptive learning
experiences tailored to individual preferences and needs. Utilizing different
forms of GAI across various subjects yields superior learning outcomes. The
article concludes by summarizing scenarios where GAI is applicable in
educational processes and discussing strategies for leveraging GAI to enhance
personalized learning, aiming to guide educators and learners in effectively
utilizing GAI to achieve superior learning objectives.",2024-12-01,2024,2024-12,education
"AI in Education: Rationale, Principles, and Instructional Implications","This study examines the integration of generative AI in schools, assessing
its benefits and risks. As AI use by students grows, it's crucial to understand
its impact on learning and teaching practices. Generative AI, like ChatGPT, can
create human-like content, prompting questions about its educational role. The
article differentiates large language models from traditional search engines
and stresses the need for students to develop critical source evaluation
skills. Although empirical evidence on AI's classroom effects is limited, AI
offers personalized learning support and problem-solving tools, alongside
challenges like undermining deep learning if misused. The study emphasizes
deliberate strategies to ensure AI complements, not replaces, genuine cognitive
effort. AI's educational role should be context-dependent, guided by
pedagogical goals. The study concludes with practical advice for teachers on
effectively utilizing AI to promote understanding and critical engagement,
advocating for a balanced approach to enhance students' knowledge and skills
development.",2024-12-02,2024,2024-12,education
Towards Type Agnostic Cyber Defense Agents,"With computing now ubiquitous across government, industry, and education,
cybersecurity has become a critical component for every organization on the
planet. Due to this ubiquity of computing, cyber threats have continued to grow
year over year, leading to labor shortages and a skills gap in cybersecurity.
As a result, many cybersecurity product vendors and security organizations have
looked to artificial intelligence to shore up their defenses. This work
considers how to characterize attackers and defenders in one approach to the
automation of cyber defense -- the application of reinforcement learning.
Specifically, we characterize the types of attackers and defenders in the sense
of Bayesian games and, using reinforcement learning, derive empirical findings
about how to best train agents that defend against multiple types of attackers.",2024-12-02,2024,2024-12,education
"The use of large language models to enhance cancer clinical trial
  educational materials","Cancer clinical trials often face challenges in recruitment and engagement
due to a lack of participant-facing informational and educational resources.
This study investigated the potential of Large Language Models (LLMs),
specifically GPT4, in generating patient-friendly educational content from
clinical trial informed consent forms. Using data from ClinicalTrials.gov, we
employed zero-shot learning for creating trial summaries and one-shot learning
for developing multiple-choice questions, evaluating their effectiveness
through patient surveys and crowdsourced annotation. Results showed that
GPT4-generated summaries were both readable and comprehensive, and may improve
patients' understanding and interest in clinical trials. The multiple-choice
questions demonstrated high accuracy and agreement with crowdsourced
annotators. For both resource types, hallucinations were identified that
require ongoing human oversight. The findings demonstrate the potential of LLMs
""out-of-the-box"" to support the generation of clinical trial education
materials with minimal trial-specific engineering, but implementation with a
human-in-the-loop is still needed to avoid misinformation risks.",2024-12-02,2024,2024-12,education
Artificial Intelligence Policy Framework for Institutions,"Artificial intelligence (AI) has transformed various sectors and
institutions, including education and healthcare. Although AI offers immense
potential for innovation and problem solving, its integration also raises
significant ethical concerns, such as privacy and bias. This paper delves into
key considerations for developing AI policies within institutions. We explore
the importance of interpretability and explainability in AI elements, as well
as the need to mitigate biases and ensure privacy. Additionally, we discuss the
environmental impact of AI and the importance of energy-efficient practices.
The culmination of these important components is centralized in a generalized
framework to be utilized for institutions developing their AI policy. By
addressing these critical factors, institutions can harness the power of AI
while safeguarding ethical principles.",2024-12-03,2024,2024-12,education
"Scaffold or Crutch? Examining College Students' Use and Views of
  Generative AI Tools for STEM Education","Developing problem-solving competency is central to Science, Technology,
Engineering, and Mathematics (STEM) education, yet translating this priority
into effective approaches to problem-solving instruction and assessment remain
a significant challenge. The recent proliferation of generative artificial
intelligence (genAI) tools like ChatGPT in higher education introduces new
considerations about how these tools can help or hinder students' development
of STEM problem-solving competency. Our research examines these considerations
by studying how and why college students use genAI tools in their STEM
coursework, focusing on their problem-solving support. We surveyed 40 STEM
college students from diverse U.S. institutions and 28 STEM faculty to
understand instructor perspectives on effective genAI tool use and guidance in
STEM courses. Our findings reveal high adoption rates and diverse applications
of genAI tools among STEM students. The most common use cases include finding
explanations, exploring related topics, summarizing readings, and helping with
problem-set questions. The primary motivation for using genAI tools was to save
time. Moreover, over half of student participants reported simply inputting
problems for AI to generate solutions, potentially bypassing their own
problem-solving processes. These findings indicate that despite high adoption
rates, students' current approaches to utilizing genAI tools often fall short
in enhancing their own STEM problem-solving competencies. The study also
explored students' and STEM instructors' perceptions of the benefits and risks
associated with using genAI tools in STEM education. Our findings provide
insights into how to guide students on appropriate genAI use in STEM courses
and how to design genAI-based tools to foster students' problem-solving
competency.",2024-12-03,2024,2024-12,education
"Analyzing the Impact of AI Tools on Student Study Habits and Academic
  Performance","This study explores the effectiveness of AI tools in enhancing student
learning, specifically in improving study habits, time management, and feedback
mechanisms. The research focuses on how AI tools can support personalized
learning, adaptive test adjustments, and provide real-time classroom analysis.
Student feedback revealed strong support for these features, and the study
found a significant reduction in study hours alongside an increase in GPA,
suggesting positive academic outcomes. Despite these benefits, challenges such
as over-reliance on AI and difficulties in integrating AI with traditional
teaching methods were also identified, emphasizing the need for AI tools to
complement conventional educational strategies rather than replace them. Data
were collected through a survey with a Likert scale and follow-up interviews,
providing both quantitative and qualitative insights. The analysis involved
descriptive statistics to summarize demographic data, AI usage patterns, and
perceived effectiveness, as well as inferential statistics (T-tests, ANOVA) to
examine the impact of demographic factors on AI adoption. Regression analysis
identified predictors of AI adoption, and qualitative responses were
thematically analyzed to understand students' perspectives on the future of AI
in education. This mixed-methods approach provided a comprehensive view of AI's
role in education and highlighted the importance of privacy, transparency, and
continuous refinement of AI features to maximize their educational benefits.",2024-12-03,2024,2024-12,education
"DMP_AI: An AI-Aided K-12 System for Teaching and Learning in Diverse
  Schools","The use of Artificial Intelligence (AI) has gained momentum in education.
However, the use of AI in K-12 education is still in its nascent stages, and
further research and development is needed to realize its potential. Moreover,
the creation of a comprehensive and cohesive system that effectively harnesses
AI to support teaching and learning across a diverse range of primary and
secondary schools presents substantial challenges that need to be addressed. To
fill these gaps, especially in countries like China, we designed and
implemented the DMP_AI (Data Management Platform_Artificial Intelligence)
system, an innovative AI-aided educational system specifically designed for
K-12 education. The system utilizes data mining, natural language processing,
and machine learning, along with learning analytics, to offer a wide range of
features, including student academic performance and behavior prediction, early
warning system, analytics of Individualized Education Plan, talented students
prediction and identification, and cross-school personalized electives
recommendation. The development of this system has been meticulously carried
out while prioritizing user privacy and addressing the challenges posed by data
heterogeneity. We successfully implemented the DMP_AI system in real-world
primary and secondary schools, allowing us to gain valuable insights into the
potential and challenges of integrating AI into K-12 education in the real
world. This system will serve as a valuable resource for supporting educators
in providing effective and inclusive K-12 education.",2024-12-04,2024,2024-12,education
"A Benchmark for Math Misconceptions: Bridging Gaps in Middle School
  Algebra with AI-Supported Instruction","This study introduces an evaluation benchmark for middle school algebra to be
used in artificial intelligence(AI) based educational platforms. The goal is to
support the design of AI systems that can enhance learner conceptual
understanding of algebra by taking into account their current level of algebra
comprehension. The data set comprises 55 misconceptions about algebra, common
errors, and 220 diagnostic examples identified in previous peer-reviewed
studies. We provide an example application using a large language model,
observing a range of precision and recall scores depending on the topic and
experimental setup that reaches 83.9% when including educator feedback and
restricting it by topic. We found that topics such as ratios and proportions
prove as difficult for LLMs as they are for students. We included a human
assessment of LLMs results and feedback from five middle school math educators
on the clarity and occurrence of misconceptions in the dataset and the
potential use of AI in conjunction with the dataset. Most educators (80% or
more) indicated that they encounter these misconceptions among their students,
suggesting the relevance of the data set to teaching middle school algebra.
Despite varying familiarity with AI tools, four out of five educators expressed
interest in using the data set with AI to diagnose student misconceptions or
train teachers. The results emphasize the importance of topic-constrained
testing, the need for multimodal approaches, and the relevance of human
expertise to gain practical insights when using AI for human learning.",2024-12-04,2024,2024-12,education
"Promoting AI Literacy in Higher Education: Evaluating the IEC-V1 Chatbot
  for Personalized Learning and Educational Equity","The unequal distribution of educational opportunities carries the risk of
having a long-term negative impact on general social peace, a country's economy
and basic democratic structures. In contrast to this observable development is
the rapid technological progress in the field of artificial intelligence (AI).
Progress makes it possible to solve various problems in the field of education
as well. In order to effectively exploit the advantages that arise from the use
of AI, prospective teacher training students need appropriate AI skills, which
must already be taught during their studies. In a first step, the added value
of this technology will be demonstrated using a concrete example. This article
is therefore about conducting an exploratory pilot study to test the Individual
Educational Chatbot (IEC-V1) prototype, in which the levels can be individually
determined in order to generate appropriate answers depending on the
requirements. The results show that this is an important function for
prospective teachers, and that there is great interest in taking a closer look
at this technology in order to be able to better support learners in the
future. The data shows that experience has already been gained with chatbots,
but that there is still room for improvement. It also shows that IEC-V1 is
already working well. The knowledge gained will be used for the further
development of the prototype to further improve the usability of the chatbot.
Overall, it is shown that useful AI applications can be effectively integrated
into learning situations even without proprietary systems and that important
data protection requirements can be complied with.",2024-12-04,2024,2024-12,education
"Learning-by-teaching with ChatGPT: The effect of teachable ChatGPT agent
  on programming education","This study investigates the potential of using ChatGPT as a teachable agent
to support students' learning by teaching process, specifically in programming
education. While learning by teaching is an effective pedagogical strategy for
promoting active learning, traditional teachable agents have limitations,
particularly in facilitating natural language dialogue. Our research explored
whether ChatGPT, with its ability to engage learners in natural conversations,
can support this process. The findings reveal that interacting with ChatGPT
improves students' knowledge gains and programming abilities, particularly in
writing readable and logically sound code. However, it had limited impact on
developing learners' error-correction skills, likely because ChatGPT tends to
generate correct code, reducing opportunities for students to practice
debugging. Additionally, students' self-regulated learning (SRL) abilities
improved, suggesting that teaching ChatGPT fosters learners' higher
self-efficacy and better implementation of SRL strategies. This study discussed
the role of natural dialogue in fostering socialized learning by teaching, and
explored ChatGPT's specific contributions in supporting students' SRL through
the learning by teaching process. Overall, the study highlights ChatGPT's
potential as a teachable agent, offering insights for future research on
ChatGPT-supported education.",2024-12-05,2024,2024-12,education
"The Impact of Artificial Intelligence on Art Research: An Analysis of
  Academic Productivity and Multidisciplinary Integration","This study investigates the transformative impact of artificial intelligence
on art research by analysing data from 749 art research projects and 555,982
non art research projects, as well as 23,999 journal articles. We utilized the
SciBERT model for text analysis on research funding proposals and the
econometric model to evaluate AI impact on the academic productivity and
impact. Our findings reveal that AI has significantly reshaped the role of art
across various disciplines. The integration of AI has led to a notable
expansion in keyword networks, highlighting advancements in visual art
creation, data driven methodologies, and interactive educational tools. AI has
also facilitated the integration of art knowledge into nearly all research
disciplines, contrasting with the traditionally confined distribution of art
knowledge. Despite the substantial increase in publication impact and citation
counts facilitated by AI, it has not markedly improved the likelihood of
publishing in high-prestige journals. These insights illustrate the complex
nature of AI's impact enhancing research impact while presenting challenges in
publication efficiency and multidisciplinary integration. The study offers a
nuanced understanding of AI's role in art research and suggests directions for
addressing the ongoing challenges of integrating art and AI across disciplines.",2024-12-06,2024,2024-12,education
"Raspberry Pi multispectral imaging camera system (PiMICS): a low-cost,
  skills-based physics educational tool","We report on an educational pilot program for low-cost physics
experimentation run in Ecuador, South Africa, and the United States. The
program was developed after having needs-based discussions with African
educators, researchers, and leaders. It was determined that the need and desire
for low-cost, skills-building, and active-learning tools is very high. From
this, we developed a 3D-printable, Raspberry Pi-based multispectral camera (15
to 25 spectral channels in the visible and near-IR) for as little as $100. The
program allows students to learn 3D modeling, 3D printing, feedback, control,
image analysis, Python programming, systems integration and artificial
intelligence as well as spectroscopy. After completing their cameras, the
students in the program studied plant health, plant stress, post-harvest fruit
ripeness, and polarization and spectral analysis of nanostructured insect
wings, the latter of which won the ``best-applied research"" award at a
conference poster session and will be highlighted in this paper. Importantly,
these cameras can be an integral part of any developing country's agricultural,
recycling, medical, and pharmaceutical infrastructure. Thus, we believe this
experiment can play an important role at the intersection of student training
and developing countries' capacity building.",2024-12-06,2024,2024-12,education
"Chatbots im Schulunterricht: Wir testen das Fobizz-Tool zur
  automatischen Bewertung von Hausaufgaben","This study examines the AI-powered grading tool ""AI Grading Assistant"" by the
German company Fobizz, designed to support teachers in evaluating and providing
feedback on student assignments. Against the societal backdrop of an
overburdened education system and rising expectations for artificial
intelligence as a solution to these challenges, the investigation evaluates the
tool's functional suitability through two test series. The results reveal
significant shortcomings: The tool's numerical grades and qualitative feedback
are often random and do not improve even when its suggestions are incorporated.
The highest ratings are achievable only with texts generated by ChatGPT. False
claims and nonsensical submissions frequently go undetected, while the
implementation of some grading criteria is unreliable and opaque. Since these
deficiencies stem from the inherent limitations of large language models
(LLMs), fundamental improvements to this or similar tools are not immediately
foreseeable. The study critiques the broader trend of adopting AI as a quick
fix for systemic problems in education, concluding that Fobizz's marketing of
the tool as an objective and time-saving solution is misleading and
irresponsible. Finally, the study calls for systematic evaluation and
subject-specific pedagogical scrutiny of the use of AI tools in educational
contexts.",2024-12-09,2024,2024-12,education
Generative AI in Modern Education Society,"Transitioning from Education 1.0 to Education 5.0, the integration of
generative artificial intelligence (GenAI) revolutionizes the learning
environment by fostering enhanced human-machine collaboration, enabling
personalized, adaptive and experiential learning, and preparing students with
the skills and adaptability needed for the future workforce. Our understanding
of academic integrity and the scholarship of teaching, learning, and research
has been revolutionised by GenAI. Schools and universities around the world are
experimenting and exploring the integration of GenAI in their education systems
(like, curriculum design, teaching process and assessments, administrative
tasks, results generation and so on). The findings of the literature study
demonstrate how well GenAI has been incorporated into the global educational
system. This study explains the roles of GenAI in the schooling and university
education systems with respect to the different stakeholders (students,
teachers, researchers etc,). It highlights the current challenges of
integrating Generative AI into the education system and outlines future
directions for leveraging GenAI to enhance educational practices.",2024-12-10,2024,2024-12,education
"Leveraging AI for Rapid Generation of Physics Simulations in Education:
  Building Your Own Virtual Lab","Seemingly we are not so far from Star Trek's food replicator. Generative
artificial intelligence is rapidly becoming an integral part of both science
and education, offering not only automation of processes but also the dynamic
creation of complex, personalized content for educational purposes. With such
advancement, educators are now crafting exams, building tutors, creating
writing partners for students, and developing an array of other powerful tools
for supporting our educational practices and student learning. We share a new
class of opportunities for supporting learners and educators through the
development of AI-generated simulations of physical phenomena and models. While
we are not at the stage of ""Computer: make me a mathematical simulation
depicting the quantum wave functions of electrons in the hydrogen atom"", we are
not far off.",2024-12-10,2024,2024-12,education
"Ontology-Aware RAG for Improved Question-Answering in Cybersecurity
  Education","Integrating AI into education has the potential to transform the teaching of
science and technology courses, particularly in the field of cybersecurity.
AI-driven question-answering (QA) systems can actively manage uncertainty in
cybersecurity problem-solving, offering interactive, inquiry-based learning
experiences. Large language models (LLMs) have gained prominence in AI-driven
QA systems, offering advanced language understanding and user engagement.
However, they face challenges like hallucinations and limited domain-specific
knowledge, which reduce their reliability in educational settings. To address
these challenges, we propose CyberRAG, an ontology-aware retrieval-augmented
generation (RAG) approach for developing a reliable and safe QA system in
cybersecurity education. CyberRAG employs a two-step approach: first, it
augments the domain-specific knowledge by retrieving validated cybersecurity
documents from a knowledge base to enhance the relevance and accuracy of the
response. Second, it mitigates hallucinations and misuse by integrating a
knowledge graph ontology to validate the final answer. Experiments on publicly
available cybersecurity datasets show that CyberRAG delivers accurate, reliable
responses aligned with domain knowledge, demonstrating the potential of AI
tools to enhance education.",2024-12-10,2024,2024-12,education
"MNIST-Fraction: Enhancing Math Education with AI-Driven Fraction
  Detection and Analysis","Mathematics education, a crucial and basic field, significantly influences
students' learning in related subjects and their future careers. Utilizing
artificial intelligence to interpret and comprehend math problems in education
is not yet fully explored. This is due to the scarcity of quality datasets and
the intricacies of processing handwritten information. In this paper, we
present a novel contribution to the field of mathematics education through the
development of MNIST-Fraction, a dataset inspired by the renowned MNIST,
specifically tailored for the recognition and understanding of handwritten math
fractions. Our approach is the utilization of deep learning, specifically
Convolutional Neural Networks (CNNs), for the recognition and understanding of
handwritten math fractions to effectively detect and analyze fractions, along
with their numerators and denominators. This capability is pivotal in
calculating the value of fractions, a fundamental aspect of math learning. The
MNIST-Fraction dataset is designed to closely mimic real-world scenarios,
providing a reliable and relevant resource for AI-driven educational tools.
Furthermore, we conduct a comprehensive comparison of our dataset with the
original MNIST dataset using various classifiers, demonstrating the
effectiveness and versatility of MNIST-Fraction in both detection and
classification tasks. This comparative analysis not only validates the
practical utility of our dataset but also offers insights into its potential
applications in math education. To foster collaboration and further research
within the computational and educational communities. Our work aims to bridge
the gap in high-quality educational resources for math learning, offering a
valuable tool for both educators and researchers in the field.",2024-12-11,2024,2024-12,education
The Parameters of Educability,"The educability model is a computational model that has been recently
proposed to describe the cognitive capability that makes humans unique among
existing biological species on Earth in being able to create advanced
civilizations. Educability is defined as a capability for acquiring and
applying knowledge. It is intended both to describe human capabilities and,
equally, as an aspirational description of what can be usefully realized by
machines. While the intention is to have a mathematically well-defined
computational model, in constructing an instance of the model there are a
number of decisions to make. We call these decisions {\it parameters}. In a
standard computer, two parameters are the memory capacity and clock rate. There
is no universally optimal choice for either one, or even for their ratio.
Similarly, in a standard machine learning system, two parameters are the
learning algorithm and the dataset used for training. Again, there are no
universally optimal choices known for either. An educable system has many more
parameters than either of these two kinds of system. This short paper discusses
some of the main parameters of educable systems, and the broader implications
of their existence.",2024-12-12,2024,2024-12,education
"The AI Assessment Scale Revisited: A Framework for Educational
  Assessment","Recent developments in Generative Artificial Intelligence (GenAI) have
created significant uncertainty in education, particularly in terms of
assessment practices. Against this backdrop, we present an updated version of
the AI Assessment Scale (AIAS), a framework with two fundamental purposes: to
facilitate open dialogue between educators and students about appropriate GenAI
use and to support educators in redesigning assessments in an era of expanding
AI capabilities.
  Grounded in social constructivist principles and designed with assessment
validity in mind, the AIAS provides a structured yet flexible approach that can
be adapted across different educational contexts. Building on implementation
feedback from global adoption across both the K-12 and higher education
contexts, this revision represents a significant change from the original AIAS.
Among these changes is a new visual guide that moves beyond the original
traffic light system and utilises a neutral colour palette that avoids implied
hierarchies between the levels. The scale maintains five distinct levels of
GenAI integration in assessment, from ""No AI"" to ""AI Exploration"", but has been
refined to better reflect rapidly advancing technological capabilities and
emerging pedagogical needs.
  This paper presents the theoretical foundations of the revised framework,
provides detailed implementation guidance through practical vignettes, and
discusses its limitations and future directions. As GenAI capabilities continue
to expand, particularly in multimodal content generation, the AIAS offers a
starting point for reimagining assessment design in an era of disruptive
technologies.",2024-12-12,2024,2024-12,education
"Beware of Metacognitive Laziness: Effects of Generative Artificial
  Intelligence on Learning Motivation, Processes, and Performance","With the continuous development of technological and educational innovation,
learners nowadays can obtain a variety of support from agents such as teachers,
peers, education technologies, and recently, generative artificial intelligence
such as ChatGPT. The concept of hybrid intelligence is still at a nascent
stage, and how learners can benefit from a symbiotic relationship with various
agents such as AI, human experts and intelligent learning systems is still
unknown. The emerging concept of hybrid intelligence also lacks deep insights
and understanding of the mechanisms and consequences of hybrid human-AI
learning based on strong empirical research. In order to address this gap, we
conducted a randomised experimental study and compared learners' motivations,
self-regulated learning processes and learning performances on a writing task
among different groups who had support from different agents (ChatGPT, human
expert, writing analytics tools, and no extra tool). A total of 117 university
students were recruited, and their multi-channel learning, performance and
motivation data were collected and analysed. The results revealed that:
learners who received different learning support showed no difference in
post-task intrinsic motivation; there were significant differences in the
frequency and sequences of the self-regulated learning processes among groups;
ChatGPT group outperformed in the essay score improvement but their knowledge
gain and transfer were not significantly different. Our research found that in
the absence of differences in motivation, learners with different supports
still exhibited different self-regulated learning processes, ultimately leading
to differentiated performance. What is particularly noteworthy is that AI
technologies such as ChatGPT may promote learners' dependence on technology and
potentially trigger metacognitive laziness.",2024-12-12,2024,2024-12,education
"Developing a custom GPT based on Inquiry Based Learning for Physics
  Teachers","Generative Artificial Intelligence (GenAI) has emerged as a valuable
assistant in many fields such as marketing, finance, project management, and
education. In education, many GenAI tools have been developed to aid teachers
in preparing proper educational material and offering personalized learning to
their students, tailored to their educational needs. In this paper, we present
a custom GPT (IBL Educator GPT) that is designed and developed based on
Inquiry-based Learning and offers physics teachers a framework in which they
can interact with ChatGPT and design educational strategies. The utilization of
the IBL Educator GPT has led to an improvement in teachers' perspectives
regarding the adoption of artificial intelligence-based tools for personalizing
teaching.",2024-12-13,2024,2024-12,education
"DK-PRACTICE: An Intelligent Educational Platform for Personalized
  Learning Content Recommendations Based on Students Knowledge State","This study introduces DK-PRACTICE (Dynamic Knowledge Prediction and
Educational Content Recommendation System), an intelligent online platform that
leverages machine learning to provide personalized learning recommendations
based on student knowledge state. Students participate in a short, adaptive
assessment using the question-and-answer method regarding key concepts in a
specific knowledge domain. The system dynamically selects the next question for
each student based on the correctness and accuracy of their previous answers.
After the test is completed, DK-PRACTICE analyzes students' interaction history
to recommend learning materials to empower the student's knowledge state in
identified knowledge gaps. Both question selection and learning material
recommendations are based on machine learning models trained using anonymized
data from a real learning environment. To provide self-assessment and monitor
learning progress, DK-PRACTICE allows students to take two tests: one
pre-teaching and one post-teaching. After each test, a report is generated with
detailed results. In addition, the platform offers functions to visualize
learning progress based on recorded test statistics. DK-PRACTICE promotes
adaptive and personalized learning by empowering students with self-assessment
capabilities and providing instructors with valuable information about
students' knowledge levels. DK-PRACTICE can be extended to various educational
environments and knowledge domains, provided the necessary data is available
according to the educational topics. A subsequent paper will present the
methodology for the experimental application and evaluation of the platform.",2024-12-13,2024,2024-12,education
"From Automation to Cognition: Redefining the Roles of Educators and
  Generative AI in Computing Education","Generative Artificial Intelligence (GenAI) offers numerous opportunities to
revolutionise teaching and learning in Computing Education (CE). However,
educators have expressed concerns that students may over-rely on GenAI and use
these tools to generate solutions without engaging in the learning process.
While substantial research has explored GenAI use in CE, and many Computer
Science (CS) educators have expressed their opinions and suggestions on the
subject, there remains little consensus on implementing curricula and
assessment changes. In this paper, we describe our experiences with using GenAI
in CS-focused educational settings and the changes we have implemented
accordingly in our teaching in recent years since the popularisation of GenAI.
From our experiences, we propose two primary actions for the CE community: 1)
redesign take-home assignments to incorporate GenAI use and assess students on
their process of using GenAI to solve a task rather than simply on the final
product; 2) redefine the role of educators to emphasise metacognitive aspects
of learning, such as critical thinking and self-evaluation. This paper presents
and discusses these stances and outlines several practical methods to implement
these strategies in CS classrooms. Then, we advocate for more research
addressing the concrete impacts of GenAI on CE, especially those evaluating the
validity and effectiveness of new teaching practices.",2024-12-16,2024,2024-12,education
"Toward an Insider Threat Education Platform: A Theoretical Literature
  Review","Insider threats (InTs) within organizations are small in number but have a
disproportionate ability to damage systems, information, and infrastructure.
Existing InT research studies the problem from psychological, technical, and
educational perspectives. Proposed theories include research on psychological
indicators, machine learning, user behavioral log analysis, and educational
methods to teach employees recognition and mitigation techniques. Because InTs
are a human problem, training methods that address InT detection from a
behavioral perspective are critical. While numerous technological and
psychological theories exist on detection, prevention, and mitigation, few
training methods prioritize psychological indicators. This literature review
studied peer-reviewed, InT research organized by subtopic and extracted
critical theories from psychological, technical, and educational disciplines.
In doing so, this is the first study to comprehensively organize research
across all three approaches in a manner which properly informs the development
of an InT education platform.",2024-12-18,2024,2024-12,education
Tuning Music Education: AI-Powered Personalization in Learning Music,"Recent AI-driven step-function advances in several longstanding problems in
music technology are opening up new avenues to create the next generation of
music education tools. Creating personalized, engaging, and effective learning
experiences are continuously evolving challenges in music education. Here we
present two case studies using such advances in music technology to address
these challenges. In our first case study we showcase an application that uses
Automatic Chord Recognition to generate personalized exercises from audio
tracks, connecting traditional ear training with real-world musical contexts.
In the second case study we prototype adaptive piano method books that use
Automatic Music Transcription to generate exercises at different skill levels
while retaining a close connection to musical interests. These applications
demonstrate how recent AI developments can democratize access to high-quality
music education and promote rich interaction with music in the age of
generative AI. We hope this work inspires other efforts in the community, aimed
at removing barriers to access to high-quality music education and fostering
human participation in musical expression.",2024-12-18,2024,2024-12,education
"Making Transparency Advocates: An Educational Approach Towards Better
  Algorithmic Transparency in Practice","Concerns about the risks and harms posed by artificial intelligence (AI) have
resulted in significant study into algorithmic transparency, giving rise to a
sub-field known as Explainable AI (XAI). Unfortunately, despite a decade of
development in XAI, an existential challenge remains: progress in research has
not been fully translated into the actual implementation of algorithmic
transparency by organizations. In this work, we test an approach for addressing
the challenge by creating transparency advocates, or motivated individuals
within organizations who drive a ground-up cultural shift towards improved
algorithmic transparency.
  Over several years, we created an open-source educational workshop on
algorithmic transparency and advocacy. We delivered the workshop to
professionals across two separate domains to improve their algorithmic
transparency literacy and willingness to advocate for change. In the weeks
following the workshop, participants applied what they learned, such as
speaking up for algorithmic transparency at an organization-wide AI strategy
meeting. We also make two broader observations: first, advocacy is not a
monolith and can be broken down into different levels. Second, individuals'
willingness for advocacy is affected by their professional field. For example,
news and media professionals may be more likely to advocate for algorithmic
transparency than those working at technology start-ups.",2024-12-19,2024,2024-12,education
"Beyond the Hype: A Comprehensive Review of Current Trends in Generative
  AI Research, Teaching Practices, and Tools","Generative AI (GenAI) is advancing rapidly, and the literature in computing
education is expanding almost as quickly. Initial responses to GenAI tools were
mixed between panic and utopian optimism. Many were fast to point out the
opportunities and challenges of GenAI. Researchers reported that these new
tools are capable of solving most introductory programming tasks and are
causing disruptions throughout the curriculum. These tools can write and
explain code, enhance error messages, create resources for instructors, and
even provide feedback and help for students like a traditional teaching
assistant. In 2024, new research started to emerge on the effects of GenAI
usage in the computing classroom. These new data involve the use of GenAI to
support classroom instruction at scale and to teach students how to code with
GenAI. In support of the former, a new class of tools is emerging that can
provide personalized feedback to students on their programming assignments or
teach both programming and prompting skills at the same time. With the
literature expanding so rapidly, this report aims to summarize and explain what
is happening on the ground in computing classrooms. We provide a systematic
literature review; a survey of educators and industry professionals; and
interviews with educators using GenAI in their courses, educators studying
GenAI, and researchers who create GenAI tools to support computing education.
The triangulation of these methods and data sources expands the understanding
of GenAI usage and perceptions at this critical moment for our community.",2024-12-19,2024,2024-12,education
"From Creation to Curriculum: Examining the role of generative AI in Arts
  Universities","The age of Artificial Intelligence (AI) is marked by its transformative
""generative"" capabilities, distinguishing it from prior iterations. This
burgeoning characteristic of AI has enabled it to produce new and original
content, inherently showcasing its creative prowess. This shift challenges and
requires a recalibration in the realm of arts education, urging a departure
from established pedagogies centered on human-driven image creation. The paper
meticulously addresses the integration of AI tools, with a spotlight on Stable
Diffusion (SD), into university arts curricula. Drawing from practical insights
gathered from workshops conducted in July 2023, which culminated in an
exhibition of AI-driven artworks, the paper aims to provide a roadmap for
seamlessly infusing these tools into academic settings. Given their recent
emergence, the paper delves into a comprehensive overview of such tools,
emphasizing the intricate dance between artists, developers, and researchers in
the open-source AI art world. This discourse extends to the challenges and
imperatives faced by educational institutions. It presents a compelling case
for the swift adoption of these avant-garde tools, underscoring the paramount
importance of equipping students with the competencies required to thrive in an
AI-augmented artistic landscape.",2024-12-21,2024,2024-12,education
"""From Unseen Needs to Classroom Solutions"": Exploring AI Literacy
  Challenges & Opportunities with Project-based Learning Toolkit in K-12
  Education","As artificial intelligence (AI) becomes increasingly central to various
fields, there is a growing need to equip K-12 students with AI literacy skills
that extend beyond computer science. This paper explores the integration of a
Project-Based Learning (PBL) AI toolkit into diverse subject areas, aimed at
helping educators teach AI concepts more effectively. Through interviews and
co-design sessions with K-12 teachers, we examined current AI literacy levels
and how teachers adapt AI tools like the AI Art Lab, AI Music Studio, and AI
Chatbot into their course designs. While teachers appreciated the potential of
AI tools to foster creativity and critical thinking, they also expressed
concerns about the accuracy, trustworthiness, and ethical implications of
AI-generated content. Our findings reveal the challenges teachers face,
including limited resources, varying student and instructor skill levels, and
the need for scalable, adaptable AI tools. This research contributes insights
that can inform the development of AI curricula tailored to diverse educational
contexts.",2024-12-23,2024,2024-12,education
"Is ChatGPT Massively Used by Students Nowadays? A Survey on the Use of
  Large Language Models such as ChatGPT in Educational Settings","The rapid adoption of Generative AI (GenAI) based on Large Language Models
(LLMs) such as ChatGPT has recently and profoundly impacted education, offering
transformative opportunities while raising significant concerns. In this study
we present the results of a survey that investigates how 395 students aged 13
to 25 years old in France and Italy integrate LLMs into their educational
routines.
  Key findings include the widespread use of these tools across all age groups
and disciplines, with older students and male students demonstrating higher
usage frequencies, particularly in scientific contexts. The results also show
gender disparities, raising concerns about an emerging AI literacy and
technological gender gap. Additionally, while most students utilise LLMs
constructively, the lack of systematic proofreading and critical evaluation
among younger users suggests potential risks to cognitive skills development,
including critical thinking and foundational knowledge. The survey results
underscore the need for educational institutions to adapt their curricula to
integrate AI tools effectively, promoting ethical use, critical thinking, and
awareness of AI limitations and environmental costs. This paper provides
actionable recommendations for fostering equitable and effective cohabitation
of LLMs and education while addressing emerging challenges.",2024-12-23,2024,2024-12,education
"A Self-Efficacy Theory-based Study on the Teachers Readiness to Teach
  Artificial Intelligence in Public Schools in Sri Lanka","This study investigates Sri Lankan ICT teachers' readiness to teach AI in
schools, focusing on self-efficacy. A survey of over 1,300 teachers assessed
their self-efficacy using a scale developed based on Bandura's theory. PLS-SEM
analysis revealed that teachers' self-efficacy was low, primarily influenced by
emotional and physiological states and imaginary experiences related to AI
instruction. Mastery experiences had a lesser impact, and vicarious experiences
and verbal persuasion showed no significant effect. The study highlights the
need for a systemic approach to teacher professional development, considering
the limitations in teachers' AI expertise and social capital. Further research
is recommended to explore a socio-technical systems perspective for effective
AI teacher training.",2024-12-27,2024,2024-12,education
"AI-Supported Data Analysis Boosts Student Motivation and Reduces Stress
  in Physics Education","The integration of artificial intelligence (AI) in physics education enables
novel approaches to data analysis and conceptual learning. A comparative
analysis of AI-supported and traditional Excel-based methods reveals distinct
strengths and limitations in fostering understanding of pendulum experiments.
This study explores the integration of AI-assisted tools, such as a custom
chatbot based on ChatGPT, and traditional Excel-based methods in physics
education, revealing that while both approaches produce comparable quantitative
learning gains, AI tools provide significant qualitative advantages. These
include enhanced emotional engagement and higher motivation, highlighting the
potential of AI to create a more positive and supportive learning environment.
Adaptive AI technologies offer significant promise in supporting structured,
data-intensive tasks, emphasizing the necessity for thoughtfully balanced
integration into educational practices.",2024-12-30,2024,2024-12,education
AI Agent for Education: von Neumann Multi-Agent System Framework,"The development of large language models has ushered in new paradigms for
education. This paper centers on the multi-Agent system in education and
proposes the von Neumann multi-Agent system framework. It breaks down each AI
Agent into four modules: control unit, logic unit, storage unit, and
input-output devices, defining four types of operations: task deconstruction,
self-reflection, memory processing, and tool invocation. Furthermore, it
introduces related technologies such as Chain-of-Thought, Reson+Act, and
Multi-Agent Debate associated with these four types of operations. The paper
also discusses the ability enhancement cycle of a multi-Agent system for
education, including the outer circulation for human learners to promote
knowledge construction and the inner circulation for LLM-based-Agents to
enhance swarm intelligence. Through collaboration and reflection, the
multi-Agent system can better facilitate human learners' learning and enhance
their teaching abilities in this process.",2024-12-30,2024,2024-12,education
"Overview of the development of smart classrooms under information
  technology: development and innovation of hardware and software","With the rapid development of information and communication technology (ICT),
smart classroom has become an important trend in education modernization. This
article reviews the development of smart classrooms from the hardware and
software levels. The hardware describes the transformation from the
construction of basic ICT facilities in single mode to a multi-modal
information cloud platform. In terms of software, we look at the evolution of
related supporting algorithms and technologies from the platform construction
technology to the integration of advanced artificial intelligence (AI)
technology from the perspectives of learning analysis and data mining. Provide
guidance and suggestions for future educators, researchers and policymakers on
the future direction of smart classrooms.",2024-12-30,2024,2024-12,education
"Efficient Multi-Task Inferencing with a Shared Backbone and Lightweight
  Task-Specific Adapters for Automatic Scoring","The integration of Artificial Intelligence (AI) in education requires
scalable and efficient frameworks that balance performance, adaptability, and
cost. This paper addresses these needs by proposing a shared backbone model
architecture enhanced with lightweight LoRA adapters for task-specific
fine-tuning, targeting the automated scoring of student responses across 27
mutually exclusive tasks. By achieving competitive performance (average QWK of
0.848 compared to 0.888 for fully fine-tuned models) while reducing GPU memory
consumption by 60% and inference latency by 40%, the framework demonstrates
significant efficiency gains. This approach aligns with the workshops' focus on
improving language models for educational tasks, creating responsible
innovations for cost-sensitive deployment, and supporting educators by
streamlining assessment workflows. The findings underscore the potential of
scalable AI to enhance learning outcomes while maintaining fairness and
transparency in automated scoring systems.",2024-12-30,2024,2024-12,education
"Intelligent Human Machine Interface Design for Advanced Product Life
  Cycle Management Systems","Designing and implementing an intelligent and user friendly human machine
interface for any kind of software or hardware oriented application is always
be a challenging task for the designers and developers because it is very
difficult to understand the psychology of the user, nature of the work and best
suit of the environment. This research paper is basically about to propose an
intelligent, flexible and user friendly machine interface for Product Life
Cycle Management products or PDM Systems since studies show that usability and
human computer interaction issues are a major cause of acceptance problems
introducing or using such systems. Going into details of the proposition, we
present prototype implementations about theme based on design requirements,
designed designs and technologies involved for the development of human machine
interface.",2010-08-07,2010,2010-08,environment
Context Capture in Software Development,"The context of a software developer is something hard to define and capture,
as it represents a complex network of elements across different dimensions that
are not limited to the work developed on an IDE. We propose the definition of a
software developer context model that takes into account all the dimensions
that characterize the work environment of the developer. We are especially
focused on what the software developer context encompasses at the project level
and how it can be captured. The experimental work done so far show that useful
context information can be extracted from project management tools. The
extraction, analysis and availability of this context information can be used
to enrich the work environment of the developer with additional knowledge to
support her/his work.",2011-01-21,2011,2011-01,environment
An architecture for the evaluation of intelligent systems,"One of the main research areas in Artificial Intelligence is the coding of
agents (programs) which are able to learn by themselves in any situation. This
means that agents must be useful for purposes other than those they were
created for, as, for example, playing chess. In this way we try to get closer
to the pristine goal of Artificial Intelligence. One of the problems to decide
whether an agent is really intelligent or not is the measurement of its
intelligence, since there is currently no way to measure it in a reliable way.
The purpose of this project is to create an interpreter that allows for the
execution of several environments, including those which are generated
randomly, so that an agent (a person or a program) can interact with them. Once
the interaction between the agent and the environment is over, the interpreter
will measure the intelligence of the agent according to the actions, states and
rewards the agent has undergone inside the environment during the test. As a
result we will be able to measure agents' intelligence in any possible
environment, and to make comparisons between several agents, in order to
determine which of them is the most intelligent. In order to perform the tests,
the interpreter must be able to randomly generate environments that are really
useful to measure agents' intelligence, since not any randomly generated
environment will serve that purpose.",2011-02-03,2011,2011-02,environment
"Planning to Be Surprised: Optimal Bayesian Exploration in Dynamic
  Environments","To maximize its success, an AGI typically needs to explore its initially
unknown world. Is there an optimal way of doing so? Here we derive an
affirmative answer for a broad class of environments.",2011-03-29,2011,2011-03,environment
The Ariadne's Clew Algorithm,"We present a new approach to path planning, called the ""Ariadne's clew
algorithm"". It is designed to find paths in high-dimensional continuous spaces
and applies to robots with many degrees of freedom in static, as well as
dynamic environments - ones where obstacles may move. The Ariadne's clew
algorithm comprises two sub-algorithms, called Search and Explore, applied in
an interleaved manner. Explore builds a representation of the accessible space
while Search looks for the target. Both are posed as optimization problems. We
describe a real implementation of the algorithm to plan paths for a six degrees
of freedom arm in a dynamic environment where another six degrees of freedom
arm is used as a moving obstacle. Experimental results show that a path is
found in about one second without any pre-processing.",2011-05-27,2011,2011-05,environment
Markov Localization for Mobile Robots in Dynamic Environments,"Localization, that is the estimation of a robot's location from sensor data,
is a fundamental problem in mobile robotics. This papers presents a version of
Markov localization which provides accurate position estimates and which is
tailored towards dynamic environments. The key idea of Markov localization is
to maintain a probability density over the space of all locations of a robot in
its environment. Our approach represents this space metrically, using a
fine-grained grid to approximate densities. It is able to globally localize the
robot from scratch and to recover from localization failures. It is robust to
approximate models of the environment (such as occupancy grid maps) and noisy
sensors (such as ultrasound sensors). Our approach also includes a filtering
technique which allows a mobile robot to reliably estimate its position even in
densely populated environments in which crowds of people block the robot's
sensors for extended periods of time. The method described here has been
implemented and tested in several real-world applications of mobile robots,
including the deployments of two mobile robots as interactive museum
tour-guides.",2011-06-01,2011,2011-06,environment
A Model of Inductive Bias Learning,"A major problem in machine learning is that of inductive bias: how to choose
a learner's hypothesis space so that it is large enough to contain a solution
to the problem being learnt, yet small enough to ensure reliable generalization
from reasonably-sized training sets. Typically such bias is supplied by hand
through the skill and insights of experts. In this paper a model for
automatically learning bias is investigated. The central assumption of the
model is that the learner is embedded within an environment of related learning
tasks. Within such an environment the learner can sample from multiple tasks,
and hence it can search for a hypothesis space that contains good solutions to
many of the problems in the environment. Under certain restrictions on the set
of all hypothesis spaces available to the learner, we show that a hypothesis
space that performs well on a sufficiently large number of training tasks will
also perform well when learning novel tasks in the same environment. Explicit
bounds are also derived demonstrating that learning multiple tasks within an
environment of related tasks can potentially give much better generalization
than learning a single task.",2011-06-01,2011,2011-06,environment
Robust Agent Teams via Socially-Attentive Monitoring,"Agents in dynamic multi-agent environments must monitor their peers to
execute individual and group plans. A key open question is how much monitoring
of other agents' states is required to be effective: The Monitoring Selectivity
Problem. We investigate this question in the context of detecting failures in
teams of cooperating agents, via Socially-Attentive Monitoring, which focuses
on monitoring for failures in the social relationships between the agents. We
empirically and analytically explore a family of socially-attentive teamwork
monitoring algorithms in two dynamic, complex, multi-agent domains, under
varying conditions of task distribution and uncertainty. We show that a
centralized scheme using a complex algorithm trades correctness for
completeness and requires monitoring all teammates. In contrast, a simple
distributed teamwork monitoring algorithm results in correct and complete
detection of teamwork failures, despite relying on limited, uncertain
knowledge, and monitoring only key agents in a team. In addition, we report on
the design of a socially-attentive monitoring system and demonstrate its
generality in monitoring several coordination relationships, diagnosing
detected failures, and both on-line and off-line applications.",2011-06-01,2011,2011-06,environment
"Learning Geometrically-Constrained Hidden Markov Models for Robot
  Navigation: Bridging the Topological-Geometrical Gap","Hidden Markov models (HMMs) and partially observable Markov decision
processes (POMDPs) provide useful tools for modeling dynamical systems. They
are particularly useful for representing the topology of environments such as
road networks and office buildings, which are typical for robot navigation and
planning. The work presented here describes a formal framework for
incorporating readily available odometric information and geometrical
constraints into both the models and the algorithm that learns them. By taking
advantage of such information, learning HMMs/POMDPs can be made to generate
better solutions and require fewer iterations, while being robust in the face
of data reduction. Experimental results, obtained from both simulated and real
robot data, demonstrate the effectiveness of the approach.",2011-06-03,2011,2011-06,environment
Accelerating Reinforcement Learning through Implicit Imitation,"Imitation can be viewed as a means of enhancing learning in multiagent
environments. It augments an agent's ability to learn useful behaviors by
making intelligent use of the knowledge implicit in behaviors demonstrated by
cooperative teachers or other more experienced agents. We propose and study a
formal model of implicit imitation that can accelerate reinforcement learning
dramatically in certain cases. Roughly, by observing a mentor, a
reinforcement-learning agent can extract information about its own capabilities
in, and the relative value of, unvisited parts of the state space. We study two
specific instantiations of this model, one in which the learning agent and the
mentor have identical abilities, and one designed to deal with agents and
mentors with different action sets. We illustrate the benefits of implicit
imitation by integrating it with prioritized sweeping, and demonstrating
improved performance and convergence through observation of single and multiple
mentors. Though we make some stringent assumptions regarding observability and
possible interactions, we briefly comment on extensions of the model that relax
these restricitions.",2011-06-03,2011,2011-06,environment
Exploiting Reputation in Distributed Virtual Environments,"The cognitive research on reputation has shown several interesting properties
that can improve both the quality of services and the security in distributed
electronic environments. In this paper, the impact of reputation on
decision-making under scarcity of information will be shown. First, a cognitive
theory of reputation will be presented, then a selection of simulation
experimental results from different studies will be discussed. Such results
concern the benefits of reputation when agents need to find out good sellers in
a virtual market-place under uncertainty and informational cheating.",2011-06-25,2011,2011-06,environment
"Reinforcement Learning for Agents with Many Sensors and Actuators Acting
  in Categorizable Environments","In this paper, we confront the problem of applying reinforcement learning to
agents that perceive the environment through many sensors and that can perform
parallel actions using many actuators as is the case in complex autonomous
robots. We argue that reinforcement learning can only be successfully applied
to this case if strong assumptions are made on the characteristics of the
environment in which the learning is performed, so that the relevant sensor
readings and motor commands can be readily identified. The introduction of such
assumptions leads to strongly-biased learning systems that can eventually lose
the generality of traditional reinforcement-learning algorithms. In this line,
we observe that, in realistic situations, the reward received by the robot
depends only on a reduced subset of all the executed actions and that only a
reduced subset of the sensor inputs (possibly different in each situation and
for each action) are relevant to predict the reward. We formalize this property
in the so called 'categorizability assumption' and we present an algorithm that
takes advantage of the categorizability of the environment, allowing a decrease
in the learning time with respect to existing reinforcement-learning
algorithms. Results of the application of the algorithm to a couple of
simulated realistic-robotic problems (landmark-based navigation and the
six-legged robot gait generation) are reported to validate our approach and to
compare it to existing flat and generalization-based reinforcement-learning
approaches.",2011-06-30,2011,2011-06,environment
"Towards a Reliable Framework of Uncertainty-Based Group Decision Support
  System","This study proposes a framework of Uncertainty-based Group Decision Support
System (UGDSS). It provides a platform for multiple criteria decision analysis
in six aspects including (1) decision environment, (2) decision problem, (3)
decision group, (4) decision conflict, (5) decision schemes and (6) group
negotiation. Based on multiple artificial intelligent technologies, this
framework provides reliable support for the comprehensive manipulation of
applications and advanced decision approaches through the design of an
integrated multi-agents architecture.",2011-07-01,2011,2011-07,environment
"An Information Theoretic Representation of Agent Dynamics as Set
  Intersections","We represent agents as sets of strings. Each string encodes a potential
interaction with another agent or environment. We represent the total set of
dynamics between two agents as the intersection of their respective strings, we
prove complexity properties of player interactions using Algorithmic
Information Theory. We show how the proposed construction is compatible with
Universal Artificial Intelligence, in that the AIXI model can be seen as
universal with respect to interaction.",2011-07-05,2011,2011-07,environment
"Information, Utility & Bounded Rationality","Perfectly rational decision-makers maximize expected utility, but crucially
ignore the resource costs incurred when determining optimal actions. Here we
employ an axiomatic framework for bounded rational decision-making based on a
thermodynamic interpretation of resource costs as information costs. This leads
to a variational ""free utility"" principle akin to thermodynamical free energy
that trades off utility and information costs. We show that bounded optimal
control solutions can be derived from this variational principle, which leads
in general to stochastic policies. Furthermore, we show that risk-sensitive and
robust (minimax) control schemes fall out naturally from this framework if the
environment is considered as a bounded rational and perfectly rational
opponent, respectively. When resource costs are ignored, the maximum expected
utility principle is recovered.",2011-07-28,2011,2011-07,environment
A prototype of a knowledge-based programming environment,"In this paper we present a proposal for a knowledge-based programming
environment. In such an environment, declarative background knowledge,
procedures, and concrete data are represented in suitable languages and
combined in a flexible manner. This leads to a highly declarative programming
style. We illustrate our approach on an example and report about our prototype
implementation.",2011-08-29,2011,2011-08,environment
ATP and Presentation Service for Mizar Formalizations,"This paper describes the Automated Reasoning for Mizar (MizAR) service, which
integrates several automated reasoning, artificial intelligence, and
presentation tools with Mizar and its authoring environment. The service
provides ATP assistance to Mizar authors in finding and explaining proofs, and
offers generation of Mizar problems as challenges to ATP systems. The service
is based on a sound translation from the Mizar language to that of first-order
ATP systems, and relies on the recent progress in application of ATP systems in
large theories containing tens of thousands of available facts. We present the
main features of MizAR services, followed by an account of initial experiments
in finding proofs with the ATP assistance. Our initial experience indicates
that the tool offers substantial help in exploring the Mizar library and in
preparing new Mizar articles.",2011-09-03,2011,2011-09,environment
"Semantic Matchmaking as Non-Monotonic Reasoning: A Description Logic
  Approach","Matchmaking arises when supply and demand meet in an electronic marketplace,
or when agents search for a web service to perform some task, or even when
recruiting agencies match curricula and job profiles. In such open
environments, the objective of a matchmaking process is to discover best
available offers to a given request. We address the problem of matchmaking from
a knowledge representation perspective, with a formalization based on
Description Logics. We devise Concept Abduction and Concept Contraction as
non-monotonic inferences in Description Logics suitable for modeling
matchmaking in a logical framework, and prove some related complexity results.
We also present reasonable algorithms for semantic matchmaking based on the
devised inferences, and prove that they obey to some commonsense properties.
Finally, we report on the implementation of the proposed matchmaking framework,
which has been used both as a mediator in e-marketplaces and for semantic web
services discovery.",2011-10-12,2011,2011-10,environment
Resource Allocation Among Agents with MDP-Induced Preferences,"Allocating scarce resources among agents to maximize global utility is, in
general, computationally challenging. We focus on problems where resources
enable agents to execute actions in stochastic environments, modeled as Markov
decision processes (MDPs), such that the value of a resource bundle is defined
as the expected value of the optimal MDP policy realizable given these
resources. We present an algorithm that simultaneously solves the
resource-allocation and the policy-optimization problems. This allows us to
avoid explicitly representing utilities over exponentially many resource
bundles, leading to drastic (often exponential) reductions in computational
complexity. We then use this algorithm in the context of self-interested agents
to design a combinatorial auction for allocating resources. We empirically
demonstrate the effectiveness of our approach by showing that it can, in
minutes, optimally solve problems for which a straightforward combinatorial
resource-allocation technique would require the agents to enumerate up to 2^100
resource bundles and the auctioneer to solve an NP-complete problem with an
input of that size.",2011-10-12,2011,2011-10,environment
"Emotional control - conditio sine qua non for advanced artificial
  intelligences?","Humans dispose of two intertwined information processing pathways, cognitive
information processing via neural firing patterns and diffusive volume control
via neuromodulation. The cognitive information processing in the brain is
traditionally considered to be the prime neural correlate of human
intelligence, clinical studies indicate that human emotions intrinsically
correlate with the activation of the neuromodulatory system.
  We examine here the question: Why do humans dispose of the diffusive
emotional control system? Is this a coincidence, a caprice of nature, perhaps a
leftover of our genetic heritage, or a necessary aspect of any advanced
intelligence, being it biological or synthetic? We argue here that emotional
control is necessary to solve the motivational problem, viz the selection of
short-term utility functions, in the context of an environment where
information, computing power and time constitute scarce resources.",2011-12-06,2011,2011-12,environment
"Performance Evaluation of Road Traffic Control Using a Fuzzy Cellular
  Model","In this paper a method is proposed for performance evaluation of road traffic
control systems. The method is designed to be implemented in an on-line
simulation environment, which enables optimisation of adaptive traffic control
strategies. Performance measures are computed using a fuzzy cellular traffic
model, formulated as a hybrid system combining cellular automata and fuzzy
calculus. Experimental results show that the introduced method allows the
performance to be evaluated using imprecise traffic measurements. Moreover, the
fuzzy definitions of performance measures are convenient for uncertainty
determination in traffic control decisions.",2011-12-17,2011,2011-12,environment
A Well-typed Lightweight Situation Calculus,"Situation calculus has been widely applied in Artificial Intelligence related
fields. This formalism is considered as a dialect of logic programming language
and mostly used in dynamic domain modeling. However, type systems are hardly
deployed in situation calculus in the literature. To achieve a correct and
sound typed program written in situation calculus, adding typing elements into
the current situation calculus will be quite helpful. In this paper, we propose
to add more typing mechanisms to the current version of situation calculus,
especially for three basic elements in situation calculus: situations, actions
and objects, and then perform rigid type checking for existing situation
calculus programs to find out the well-typed and ill-typed ones. In this way,
type correctness and soundness in situation calculus programs can be guaranteed
by type checking based on our type system. This modified version of a
lightweight situation calculus is proved to be a robust and well-typed system.",2012-01-11,2012,2012-01,environment
"Dynamic Shared Context Processing in an E-Collaborative Learning
  Environment","In this paper, we propose a dynamic shared context processing method based on
DSC (Dynamic Shared Context) model, applied in an e-collaborative learning
environment. Firstly, we present the model. This is a way to measure the
relevance between events and roles in collaborative environments. With this
method, we can share the most appropriate event information for each role
instead of sharing all information to all roles in a collaborative work
environment. Then, we apply and verify this method in our project with Google
App supported e-learning collaborative environment. During this experiment, we
compared DSC method measured relevance of events and roles to manual measured
relevance. And we describe the favorable points from this comparison and our
finding. Finally, we discuss our future research of a hybrid DSC method to make
dynamical information shared more effective in a collaborative work
environment.",2012-01-18,2012,2012-01,environment
"On the influence of intelligence in (social) intelligence testing
  environments","This paper analyses the influence of including agents of different degrees of
intelligence in a multiagent system. The goal is to better understand how we
can develop intelligence tests that can evaluate social intelligence. We
analyse several reinforcement algorithms in several contexts of cooperation and
competition. Our experimental setting is inspired by the recently developed
Darwin-Wallace distribution.",2012-02-03,2012,2012-02,environment
One Decade of Universal Artificial Intelligence,"The first decade of this century has seen the nascency of the first
mathematical theory of general artificial intelligence. This theory of
Universal Artificial Intelligence (UAI) has made significant contributions to
many theoretical, philosophical, and practical AI questions. In a series of
papers culminating in book (Hutter, 2005), an exciting sound and complete
mathematical model for a super intelligent agent (AIXI) has been developed and
rigorously analyzed. While nowadays most AI researchers avoid discussing
intelligence, the award-winning PhD thesis (Legg, 2008) provided the
philosophical embedding and investigated the UAI-based universal measure of
rational intelligence, which is formal, objective and non-anthropocentric.
Recently, effective approximations of AIXI have been derived and experimentally
investigated in JAIR paper (Veness et al. 2011). This practical breakthrough
has resulted in some impressive applications, finally muting earlier critique
that UAI is only a theory. For the first time, without providing any domain
knowledge, the same agent is able to self-adapt to a diverse range of
interactive environments. For instance, AIXI is able to learn from scratch to
play TicTacToe, Pacman, Kuhn Poker, and other games by trial and error, without
even providing the rules of the games.
  These achievements give new hope that the grand goal of Artificial General
Intelligence is not elusive.
  This article provides an informal overview of UAI in context. It attempts to
gently introduce a very theoretical, formal, and mathematical subject, and
discusses philosophical and technical ingredients, traits of intelligence, some
social questions, and the past and future of UAI.",2012-02-28,2012,2012-02,environment
Truthful Feedback for Sanctioning Reputation Mechanisms,"For product rating environments, similar to that of Amazon Reviews, it has
been shown that the truthful elicitation of feedback is possible through
mechanisms which pay buyer reports contingent on the reports of other buyers.
We study whether similar mechanisms can be designed for reputation mechanisms
at online auction sites where the buyers' experiences are partially determined
by a strategic seller. We show that this is impossible for the basic setting.
However, introducing a small prior belief that the seller is a cooperative
commitment player leads to a payment scheme with a truthful perfect Bayesian
equilibrium.",2012-03-15,2012,2012-03,environment
Variance-Based Rewards for Approximate Bayesian Reinforcement Learning,"The explore{exploit dilemma is one of the central challenges in Reinforcement
Learning (RL). Bayesian RL solves the dilemma by providing the agent with
information in the form of a prior distribution over environments; however,
full Bayesian planning is intractable. Planning with the mean MDP is a common
myopic approximation of Bayesian planning. We derive a novel reward bonus that
is a function of the posterior distribution over environments, which, when
added to the reward in planning with the mean MDP, results in an agent which
explores efficiently and effectively. Although our method is similar to
existing methods when given an uninformative or unstructured prior, unlike
existing methods, our method can exploit structured priors. We prove that our
method results in a polynomial sample complexity and empirically demonstrate
its advantages in a structured exploration task.",2012-03-15,2012,2012-03,environment
Bayesian Inference in Monte-Carlo Tree Search,"Monte-Carlo Tree Search (MCTS) methods are drawing great interest after
yielding breakthrough results in computer Go. This paper proposes a Bayesian
approach to MCTS that is inspired by distributionfree approaches such as UCT
[13], yet significantly differs in important respects. The Bayesian framework
allows potentially much more accurate (Bayes-optimal) estimation of node values
and node uncertainties from a limited number of simulation trials. We further
propose propagating inference in the tree via fast analytic Gaussian
approximation methods: this can make the overhead of Bayesian inference
manageable in domains such as Go, while preserving high accuracy of
expected-value estimates. We find substantial empirical outperformance of UCT
in an idealized bandit-tree test environment, where we can obtain valuable
insights by comparing with known ground truth. Additionally we rigorously prove
on-policy and off-policy convergence of the proposed methods.",2012-03-15,2012,2012-03,environment
"When majority voting fails: Comparing quality assurance methods for
  noisy human computation environment","Quality assurance remains a key topic in human computation research. Prior
work indicates that majority voting is effective for low difficulty tasks, but
has limitations for harder tasks. This paper explores two methods of addressing
this problem: tournament selection and elimination selection, which exploit 2-,
3- and 4-way comparisons between different answers to human computation tasks.
Our experimental results and statistical analyses show that both methods
produce the correct answer in noisy human computation environment more often
than majority voting. Furthermore, we find that the use of 4-way comparisons
can significantly reduce the cost of quality assurance relative to the use of
2-way comparisons.",2012-04-16,2012,2012-04,environment
Generating Optimal Plans in Highly-Dynamic Domains,"Generating optimal plans in highly dynamic environments is challenging. Plans
are predicated on an assumed initial state, but this state can change
unexpectedly during plan generation, potentially invalidating the planning
effort. In this paper we make three contributions: (1) We propose a novel
algorithm for generating optimal plans in settings where frequent, unexpected
events interfere with planning. It is able to quickly distinguish relevant from
irrelevant state changes, and to update the existing planning search tree if
necessary. (2) We argue for a new criterion for evaluating plan adaptation
techniques: the relative running time compared to the ""size"" of changes. This
is significant since during recovery more changes may occur that need to be
recovered from subsequently, and in order for this process of repeated recovery
to terminate, recovery time has to converge. (3) We show empirically that our
approach can converge and find optimal plans in environments that would
ordinarily defy planning due to their high dynamics.",2012-05-09,2012,2012-05,environment
"A Sampling-Based Approach to Computing Equilibria in Succinct
  Extensive-Form Games","A central task of artificial intelligence is the design of artificial agents
that act towards specified goals in partially observed environments. Since such
environments frequently include interaction over time with other agents with
their own goals, reasoning about such interaction relies on sequential
game-theoretic models such as extensive-form games or some of their succinct
representations such as multi-agent influence diagrams. The current algorithms
for calculating equilibria either work with inefficient representations,
possibly doubly exponential inthe number of time steps, or place strong
assumptions on the game structure. In this paper,we propose a sampling-based
approach, which calculates extensive-form correlated equilibria with small
representations without placing such strong assumptions. Thus, it is practical
in situations where the previous approaches would fail. In addition, our
algorithm allows control over characteristics of the target equilibrium, e.g.,
we can ask for an equilibrium with high social welfare. Our approach is based
on a multiplicativeweight update algorithm analogous to AdaBoost, and Markov
chain Monte Carlo sampling. We prove convergence guarantees and explore the
utility of our approach on several moderately sized multi-player games.",2012-05-09,2012,2012-05,environment
Improving Gradient Estimation by Incorporating Sensor Data,"An efficient policy search algorithm should estimate the local gradient of
the objective function, with respect to the policy parameters, from as few
trials as possible. Whereas most policy search methods estimate this gradient
by observing the rewards obtained during policy trials, we show, both
theoretically and empirically, that taking into account the sensor data as well
gives better gradient estimates and hence faster learning. The reason is that
rewards obtained during policy execution vary from trial to trial due to noise
in the environment; sensor data, which correlates with the noise, can be used
to partially correct for this variation, resulting in an estimatorwith lower
variance.",2012-06-13,2012,2012-06,environment
CT-NOR: Representing and Reasoning About Events in Continuous Time,"We present a generative model for representing and reasoning about the
relationships among events in continuous time. We apply the model to the domain
of networked and distributed computing environments where we fit the parameters
of the model from timestamp observations, and then use hypothesis testing to
discover dependencies between the events and changes in behavior for monitoring
and diagnosis. After introducing the model, we present an EM algorithm for
fitting the parameters and then present the hypothesis testing approach for
both dependence discovery and change-point detection. We validate the approach
for both tasks using real data from a trace of network events at Microsoft
Research Cambridge. Finally, we formalize the relationship between the proposed
model and the noisy-or gate for cases when time can be discretized.",2012-06-13,2012,2012-06,environment
Probabilistic Models for Anomaly Detection in Remote Sensor Data Streams,"Remote sensors are becoming the standard for observing and recording
ecological data in the field. Such sensors can record data at fine temporal
resolutions, and they can operate under extreme conditions prohibitive to human
access. Unfortunately, sensor data streams exhibit many kinds of errors ranging
from corrupt communications to partial or total sensor failures. This means
that the raw data stream must be cleaned before it can be used by domain
scientists. In our application environment|the H.J. Andrews Experimental
Forest|this data cleaning is performed manually. This paper introduces a
Dynamic Bayesian Network model for analyzing sensor observations and
distinguishing sensor failures from valid data for the case of air temperature
measured at 15 minute time resolution. The model combines an accurate
distribution of long-term and short-term temperature variations with a single
generalized fault model. Experiments with historical data show that the
precision and recall of the method is comparable to that of the domain expert.
The system is currently being deployed to perform real-time automated data
cleaning.",2012-06-20,2012,2012-06,environment
"Predicting the behavior of interacting humans by fusing data from
  multiple sources","Multi-fidelity methods combine inexpensive low-fidelity simulations with
costly but high-fidelity simulations to produce an accurate model of a system
of interest at minimal cost. They have proven useful in modeling physical
systems and have been applied to engineering problems such as wing-design
optimization. During human-in-the-loop experimentation, it has become
increasingly common to use online platforms, like Mechanical Turk, to run
low-fidelity experiments to gather human performance data in an efficient
manner. One concern with these experiments is that the results obtained from
the online environment generalize poorly to the actual domain of interest. To
address this limitation, we extend traditional multi-fidelity approaches to
allow us to combine fewer data points from high-fidelity human-in-the-loop
experiments with plentiful but less accurate data from low-fidelity experiments
to produce accurate models of how humans interact. We present both model-based
and model-free methods, and summarize the predictive performance of each method
under different conditions.",2012-06-26,2012,2012-06,environment
"Apprenticeship Learning for Model Parameters of Partially Observable
  Environments","We consider apprenticeship learning, i.e., having an agent learn a task by
observing an expert demonstrating the task in a partially observable
environment when the model of the environment is uncertain. This setting is
useful in applications where the explicit modeling of the environment is
difficult, such as a dialogue system. We show that we can extract information
about the environment model by inferring action selection process behind the
demonstration, under the assumption that the expert is choosing optimal actions
based on knowledge of the true model of the target environment. Proposed
algorithms can achieve more accurate estimates of POMDP parameters and better
policies from a short demonstration, compared to methods that learns only from
the reaction from the environment.",2012-06-27,2012,2012-06,environment
"Optimal Coordinated Planning Amongst Self-Interested Agents with Private
  State","Consider a multi-agent system in a dynamic and uncertain environment. Each
agent's local decision problem is modeled as a Markov decision process (MDP)
and agents must coordinate on a joint action in each period, which provides a
reward to each agent and causes local state transitions. A social planner knows
the model of every agent's MDP and wants to implement the optimal joint policy,
but agents are self-interested and have private local state. We provide an
incentive-compatible mechanism for eliciting state information that achieves
the optimal joint plan in a Markov perfect equilibrium of the induced
stochastic game. In the special case in which local problems are Markov chains
and agents compete to take a single action in each period, we leverage Gittins
allocation indices to provide an efficient factored algorithm and distribute
computation of the optimal policy among the agents. Distributed, optimal
coordinated learning in a multi-agent variant of the multi-armed bandit problem
is obtained as a special case.",2012-06-27,2012,2012-06,environment
"A compact, hierarchical Q-function decomposition","Previous work in hierarchical reinforcement learning has faced a dilemma:
either ignore the values of different possible exit states from a subroutine,
thereby risking suboptimal behavior, or represent those values explicitly
thereby incurring a possibly large representation cost because exit values
refer to nonlocal aspects of the world (i.e., all subsequent rewards). This
paper shows that, in many cases, one can avoid both of these problems. The
solution is based on recursively decomposing the exit value function in terms
of Q-functions at higher levels of the hierarchy. This leads to an intuitively
appealing runtime architecture in which a parent subroutine passes to its child
a value function on the exit states and the child reasons about how its choices
affect the exit value. We also identify structural conditions on the value
function and transition distributions that allow much more concise
representations of exit state distributions, leading to further state
abstraction. In essence, the only variables whose exit values need be
considered are those that the parent cares about and the child affects. We
demonstrate the utility of our algorithms on a series of increasingly complex
environments.",2012-06-27,2012,2012-06,environment
"A unified setting for inference and decision: An argumentation-based
  approach","Inferring from inconsistency and making decisions are two problems which have
always been treated separately by researchers in Artificial Intelligence.
Consequently, different models have been proposed for each category. Different
argumentation systems [2, 7, 10, 11] have been developed for handling
inconsistency in knowledge bases. Recently, other argumentation systems [3, 4,
8] have been defined for making decisions under uncertainty. The aim of this
paper is to present a general argumentation framework in which both inferring
from inconsistency and decision making are captured. The proposed framework can
be used for decision under uncertainty, multiple criteria decision, rule-based
decision and finally case-based decision. Moreover, works on classical decision
suppose that the information about environment is coherent, and this no longer
required by this general framework.",2012-07-04,2012,2012-07,environment
Robotic Mapping with Polygonal Random Fields,"Two types of probabilistic maps are popular in the mobile robotics
literature: occupancy grids and geometric maps. Occupancy grids have the
advantages of simplicity and speed, but they represent only a restricted class
of maps and they make incorrect independence assumptions. On the other hand,
current geometric approaches, which characterize the environment by features
such as line segments, can represent complex environments compactly. However,
they do not reason explicitly about occupancy, a necessity for motion planning;
and, they lack a complete probability model over environmental structures. In
this paper we present a probabilistic mapping technique based on polygonal
random fields (PRF), which combines the advantages of both approaches. Our
approach explicitly represents occupancy using a geometric representation, and
it is based upon a consistent probability distribution over environments which
avoids the incorrect independence assumptions made by occupancy grids. We show
how sampling techniques for PRFs can be applied to localized laser and sonar
data, and we demonstrate significant improvements in mapping performance over
occupancy grids.",2012-07-04,2012,2012-07,environment
MAA*: A Heuristic Search Algorithm for Solving Decentralized POMDPs,"We present multi-agent A* (MAA*), the first complete and optimal heuristic
search algorithm for solving decentralized partially-observable Markov decision
problems (DEC-POMDPs) with finite horizon. The algorithm is suitable for
computing optimal plans for a cooperative group of agents that operate in a
stochastic environment such as multirobot coordination, network traffic
control, `or distributed resource allocation. Solving such problems efiectively
is a major challenge in the area of planning under uncertainty. Our solution is
based on a synthesis of classical heuristic search and decentralized control
theory. Experimental results show that MAA* has significant advantages. We
introduce an anytime variant of MAA* and conclude with a discussion of
promising extensions such as an approach to solving infinite horizon problems.",2012-07-04,2012,2012-07,environment
Counterexample-guided Planning,"Planning in adversarial and uncertain environments can be modeled as the
problem of devising strategies in stochastic perfect information games. These
games are generalizations of Markov decision processes (MDPs): there are two
(adversarial) players, and a source of randomness. The main practical obstacle
to computing winning strategies in such games is the size of the state space.
In practice therefore, one typically works with abstractions of the model. The
diffculty is to come up with an abstraction that is neither too coarse to
remove all winning strategies (plans), nor too fine to be intractable. In
verification, the paradigm of counterexample-guided abstraction refinement has
been successful to construct useful but parsimonious abstractions
automatically. We extend this paradigm to probabilistic models (namely, perfect
information games and, as a special case, MDPs). This allows us to apply the
counterexample-guided abstraction paradigm to the AI planning problem. As
special cases, we get planning algorithms for MDPs and deterministic systems
that automatically construct system abstractions.",2012-07-04,2012,2012-07,environment
Unsupervised Activity Discovery and Characterization From Event-Streams,"We present a framework to discover and characterize different classes of
everyday activities from event-streams. We begin by representing activities as
bags of event n-grams. This allows us to analyze the global structural
information of activities, using their local event statistics. We demonstrate
how maximal cliques in an undirected edge-weighted graph of activities, can be
used for activity-class discovery in an unsupervised manner. We show how
modeling an activity as a variable length Markov process, can be used to
discover recurrent event-motifs to characterize the discovered
activity-classes. We present results over extensive data-sets, collected from
multiple active environments, to show the competence and generalizability of
our proposed framework.",2012-07-04,2012,2012-07,environment
"The Arcade Learning Environment: An Evaluation Platform for General
  Agents","In this article we introduce the Arcade Learning Environment (ALE): both a
challenge problem and a platform and methodology for evaluating the development
of general, domain-independent AI technology. ALE provides an interface to
hundreds of Atari 2600 game environments, each one different, interesting, and
designed to be a challenge for human players. ALE presents significant research
challenges for reinforcement learning, model learning, model-based planning,
imitation learning, transfer learning, and intrinsic motivation. Most
importantly, it provides a rigorous testbed for evaluating and comparing
approaches to these problems. We illustrate the promise of ALE by developing
and benchmarking domain-independent agents designed using well-established AI
techniques for both reinforcement learning and planning. In doing so, we also
propose an evaluation methodology made possible by ALE, reporting empirical
results on over 55 different games. All of the software, including the
benchmark agents, is publicly available.",2012-07-19,2012,2012-07,environment
Optimistic Agents are Asymptotically Optimal,"We use optimism to introduce generic asymptotically optimal reinforcement
learning agents. They achieve, with an arbitrary finite or compact class of
environments, asymptotically optimal behavior. Furthermore, in the finite
deterministic case we provide finite error bounds.",2012-09-29,2012,2012-09,environment
Dynamic Teaching in Sequential Decision Making Environments,"We describe theoretical bounds and a practical algorithm for teaching a model
by demonstration in a sequential decision making environment. Unlike previous
efforts that have optimized learners that watch a teacher demonstrate a static
policy, we focus on the teacher as a decision maker who can dynamically choose
different policies to teach different parts of the environment. We develop
several teaching frameworks based on previously defined supervised protocols,
such as Teaching Dimension, extending them to handle noise and sequences of
inputs encountered in an MDP.We provide theoretical bounds on the learnability
of several important model classes in this setting and suggest a practical
algorithm for dynamic teaching.",2012-10-16,2012,2012-10,environment
The Do-Calculus Revisited,"The do-calculus was developed in 1995 to facilitate the identification of
causal effects in non-parametric models. The completeness proofs of [Huang and
Valtorta, 2006] and [Shpitser and Pearl, 2006] and the graphical criteria of
[Tian and Shpitser, 2010] have laid this identification problem to rest. Recent
explorations unveil the usefulness of the do-calculus in three additional
areas: mediation analysis [Pearl, 2012], transportability [Pearl and
Bareinboim, 2011] and metasynthesis. Meta-synthesis (freshly coined) is the
task of fusing empirical results from several diverse studies, conducted on
heterogeneous populations and under different conditions, so as to synthesize
an estimate of a causal relation in some target environment, potentially
different from those under study. The talk surveys these results with emphasis
on the challenges posed by meta-synthesis. For background material, see
http://bayes.cs.ucla.edu/csl_papers.html",2012-10-16,2012,2012-10,environment
"The Revisiting Problem in Mobile Robot Map Building: A Hierarchical
  Bayesian Approach","We present an application of hierarchical Bayesian estimation to robot map
building. The revisiting problem occurs when a robot has to decide whether it
is seeing a previously-built portion of a map, or is exploring new territory.
This is a difficult decision problem, requiring the probability of being
outside of the current known map. To estimate this probability, we model the
structure of a ""typical"" environment as a hidden Markov model that generates
sequences of views observed by a robot navigating through the environment. A
Dirichlet prior over structural models is learned from previously explored
environments. Whenever a robot explores a new environment, the posterior over
the model is estimated by Dirichlet hyperparameters. Our approach is
implemented and tested in the context of multi-robot map merging, a
particularly difficult instance of the revisiting problem. Experiments with
robot data show that the technique yields strong improvements over alternative
methods.",2012-10-19,2012,2012-10,environment
Symbolic Generalization for On-line Planning,"Symbolic representations have been used successfully in off-line planning
algorithms for Markov decision processes. We show that they can also improve
the performance of on-line planners. In addition to reducing computation time,
symbolic generalization can reduce the amount of costly real-world interactions
required for convergence. We introduce Symbolic Real-Time Dynamic Programming
(or sRTDP), an extension of RTDP. After each step of on-line interaction with
an environment, sRTDP uses symbolic model-checking techniques to generalizes
its experience by updating a group of states rather than a single state. We
examine two heuristic approaches to dynamic grouping of states and show that
they accelerate the planning process significantly in terms of both CPU time
and the number of steps of interaction with the environment.",2012-10-19,2012,2012-10,environment
Decentralized Sensor Fusion With Distributed Particle Filters,"This paper presents a scalable Bayesian technique for decentralized state
estimation from multiple platforms in dynamic environments. As has long been
recognized, centralized architectures impose severe scaling limitations for
distributed systems due to the enormous communication overheads. We propose a
strictly decentralized approach in which only nearby platforms exchange
information. They do so through an interactive communication protocol aimed at
maximizing information flow. Our approach is evaluated in the context of a
distributed surveillance scenario that arises in a robotic system for playing
the game of laser tag. Our results, both from simulation and using physical
robots, illustrate an unprecedented scaling capability to large teams of
vehicles.",2012-10-19,2012,2012-10,environment
Ambiente de Planejamento Ip√™,"In this work we investigate the systems that implements algorithms for the
planning problem in Artificial Intelligence, called planners, with especial
attention to the planners based on the plan graph. We analyze the problem of
comparing the performance of the different algorithms and we propose an
environment for the development and analysis of planners.",2012-10-23,2012,2012-10,environment
"Dynamic Decision Support System Based on Bayesian Networks Application
  to fight against the Nosocomial Infections","The improvement of medical care quality is a significant interest for the
future years. The fight against nosocomial infections (NI) in the intensive
care units (ICU) is a good example. We will focus on a set of observations
which reflect the dynamic aspect of the decision, result of the application of
a Medical Decision Support System (MDSS). This system has to make dynamic
decision on temporal data. We use dynamic Bayesian network (DBN) to model this
dynamic process. It is a temporal reasoning within a real-time environment; we
are interested in the Dynamic Decision Support Systems in healthcare domain
(MDDSS).",2012-11-09,2012,2012-11,environment
"An ontology-based approach to relax traffic regulation for autonomous
  vehicle assistance","Traffic regulation must be respected by all vehicles, either human- or
computer- driven. However, extreme traffic situations might exhibit practical
cases in which a vehicle should safely and reasonably relax traffic regulation,
e.g., in order not to be indefinitely blocked and to keep circulating. In this
paper, we propose a high-level representation of an automated vehicle, other
vehicles and their environment, which can assist drivers in taking such
""illegal"" but practical relaxation decisions. This high-level representation
(an ontology) includes topological knowledge and inference rules, in order to
compute the next high-level motion an automated vehicle should take, as
assistance to a driver. Results on practical cases are presented.",2012-12-04,2012,2012-12,environment
Particle Filters in Robotics (Invited Talk),"This presentation will introduce the audience to a new, emerging body of
research on sequential Monte Carlo techniques in robotics. In recent years,
particle filters have solved several hard perceptual robotic problems. Early
successes were limited to low-dimensional problems, such as the problem of
robot localization in environments with known maps. More recently, researchers
have begun exploiting structural properties of robotic domains that have led to
successful particle filter applications in spaces with as many as 100,000
dimensions. The presentation will discuss specific tricks necessary to make
these techniques work in real - world domains,and also discuss open challenges
for researchers IN the UAI community.",2012-12-12,2012,2012-12,environment
"Learning Hierarchical Object Maps Of Non-Stationary Environments with
  mobile robots","Building models, or maps, of robot environments is a highly active research
area; however, most existing techniques construct unstructured maps and assume
static environments. In this paper, we present an algorithm for learning object
models of non-stationary objects found in office-type environments. Our
algorithm exploits the fact that many objects found in office environments look
alike (e.g., chairs, recycling bins). It does so through a two-level
hierarchical representation, which links individual objects with generic shape
templates of object classes. We derive an approximate EM algorithm for learning
shape parameters at both levels of the hierarchy, using local occupancy grid
maps for representing shape. Additionally, we develop a Bayesian model
selection algorithm that enables the robot to estimate the total number of
objects and object templates in the environment. Experimental results using a
real robot equipped with a laser range finder indicate that our approach
performs well at learning object-based maps of simple office environments. The
approach outperforms a previously developed non-hierarchical algorithm that
models objects but lacks class templates.",2012-12-12,2012,2012-12,environment
"Artificial Intelligence Framework for Simulating Clinical
  Decision-Making: A Markov Decision Process Approach","In the modern healthcare system, rapidly expanding costs/complexity, the
growing myriad of treatment options, and exploding information streams that
often do not effectively reach the front lines hinder the ability to choose
optimal treatment decisions over time. The goal in this paper is to develop a
general purpose (non-disease-specific) computational/artificial intelligence
(AI) framework to address these challenges. This serves two potential
functions: 1) a simulation environment for exploring various healthcare
policies, payment methodologies, etc., and 2) the basis for clinical artificial
intelligence - an AI that can think like a doctor. This approach combines
Markov decision processes and dynamic decision networks to learn from clinical
data and develop complex plans via simulation of alternative sequential
decision paths while capturing the sometimes conflicting, sometimes synergistic
interactions of various components in the healthcare system. It can operate in
partially observable environments (in the case of missing observations or data)
by maintaining belief states about patient health status and functions as an
online agent that plans and re-plans. This framework was evaluated using real
patient data from an electronic health record. Such an AI framework easily
outperforms the current treatment-as-usual (TAU) case-rate/fee-for-service
models of healthcare (Cost per Unit Change: $189 vs. $497) while obtaining a
30-35% increase in patient outcomes. Tweaking certain model parameters further
enhances this advantage, obtaining roughly 50% more improvement for roughly
half the costs. Given careful design and problem formulation, an AI simulation
framework can approximate optimal decisions even in complex and uncertain
environments. Future work is described that outlines potential lines of
research and integration of machine learning algorithms for personalized
medicine.",2013-01-10,2013,2013-01,environment
"A Possibilistic Model for Qualitative Sequential Decision Problems under
  Uncertainty in Partially Observable Environments","In this article we propose a qualitative (ordinal) counterpart for the
Partially Observable Markov Decision Processes model (POMDP) in which the
uncertainty, as well as the preferences of the agent, are modeled by
possibility distributions. This qualitative counterpart of the POMDP model
relies on a possibilistic theory of decision under uncertainty, recently
developed. One advantage of such a qualitative framework is its ability to
escape from the classical obstacle of stochastic POMDPs, in which even with a
finite state space, the obtained belief state space of the POMDP is infinite.
Instead, in the possibilistic framework even if exponentially larger than the
state space, the belief state space remains finite.",2013-01-23,2013,2013-01,environment
Practical Uses of Belief Functions,"We present examples where the use of belief functions provided sound and
elegant solutions to real life problems. These are essentially characterized by
?missing' information. The examples deal with 1) discriminant analysis using a
learning set where classes are only partially known; 2) an information
retrieval systems handling inter-documents relationships; 3) the combination of
data from sensors competent on partially overlapping frames; 4) the
determination of the number of sources in a multi-sensor environment by
studying the inter-sensors contradiction. The purpose of the paper is to report
on such applications where the use of belief functions provides a convenient
tool to handle ?messy' data problems.",2013-01-23,2013,2013-01,environment
Learning Hidden Markov Models with Geometrical Constraints,"Hidden Markov models (HMMs) and partially observable Markov decision
processes (POMDPs) form a useful tool for modeling dynamical systems. They are
particularly useful for representing environments such as road networks and
office buildings, which are typical for robot navigation and planning. The work
presented here is concerned with acquiring such models. We demonstrate how
domain-specific information and constraints can be incorporated into the
statistical estimation process, greatly improving the learned models in terms
of the model quality, the number of iterations required for convergence and
robustness to reduction in the amount of available data. We present new
initialization heuristics which can be used even when the data suffers from
cumulative rotational error, new update rules for the model parameters, as an
instance of generalized EM, and a strategy for enforcing complete geometrical
consistency in the model. Experimental results demonstrate the effectiveness of
our approach for both simulated and real robot data, in traditionally
hard-to-learn environments.",2013-01-23,2013,2013-01,environment
Multi-objects association in perception of dynamical situation,"In current perception systems applied to the rebuilding of the environment
for intelligent vehicles, the part reserved to object association for the
tracking is increasingly significant. This allows firstly to follow the objects
temporal evolution and secondly to increase the reliability of environment
perception. We propose in this communication the development of a multi-objects
association algorithm with ambiguity removal entering into the design of such a
dynamic perception system for intelligent vehicles. This algorithm uses the
belief theory and data modelling with fuzzy mathematics in order to be able to
handle inaccurate as well as uncertain information due to imperfect sensors.
These theories also allow the fusion of numerical as well as symbolic data. We
develop in this article the problem of matching between known and perceived
objects. This makes it possible to update a dynamic environment map for a
vehicle. The belief theory will enable us to quantify the belief in the
association of each perceived object with each known object. Conflicts can
appear in the case of object appearance or disappearance, or in the case of a
confused situation or bad perception. These conflicts are removed or solved
using an assignment algorithm, giving a solution called the "" best "" and so
ensuring the tracking of some objects present in our environment.",2013-01-23,2013,2013-01,environment
Model-Based Bayesian Exploration,"Reinforcement learning systems are often concerned with balancing exploration
of untested actions against exploitation of actions that are known to be good.
The benefit of exploration can be estimated using the classical notion of Value
of Information - the expected improvement in future decision quality arising
from the information acquired by exploration. Estimating this quantity requires
an assessment of the agent's uncertainty about its current value estimates for
states. In this paper we investigate ways of representing and reasoning about
this uncertainty in algorithms where the system attempts to learn a model of
its environment. We explicitly represent uncertainty about the parameters of
the model and build probability distributions over Q-values based on these.
These distributions are used to compute a myopic approximation to the value of
information for each action and hence to select the action that best balances
exploration and exploitation.",2013-01-23,2013,2013-01,environment
Learning Finite-State Controllers for Partially Observable Environments,"Reactive (memoryless) policies are sufficient in completely observable Markov
decision processes (MDPs), but some kind of memory is usually necessary for
optimal control of a partially observable MDP. Policies with finite memory can
be represented as finite-state automata. In this paper, we extend Baird and
Moore's VAPS algorithm to the problem of learning general finite-state
automata. Because it performs stochastic gradient descent, this algorithm can
be shown to converge to a locally optimal finite-state controller. We provide
the details of the algorithm and then consider the question of under what
conditions stochastic gradient descent will outperform exact gradient descent.
We conclude with empirical results comparing the performance of stochastic and
exact gradient descent, and showing the ability of our algorithm to extract the
useful information contained in the sequence of past observations to compensate
for the lack of observability at each time-step.",2013-01-23,2013,2013-01,environment
Subjective Reality and Strong Artificial Intelligence,"The main prospective aim of modern research related to Artificial
Intelligence is the creation of technical systems that implement the idea of
Strong Intelligence. According our point of view the path to the development of
such systems comes through the research in the field related to perceptions.
Here we formulate the model of the perception of external world which may be
used for the description of perceptual activity of intelligent beings. We
consider a number of issues related to the development of the set of patterns
which will be used by the intelligent system when interacting with environment.
The key idea of the presented perception model is the idea of subjective
reality. The principle of the relativity of perceived world is formulated. It
is shown that this principle is the immediate consequence of the idea of
subjective reality. In this paper we show how the methodology of subjective
reality may be used for the creation of different types of Strong AI systems.",2013-01-27,2013,2013-01,environment
Dealing with Uncertainty on the Initial State of a Petri Net,"This paper proposes a method to find the actual state of a complex dynamic
system from information coming from the sensors on the system himself, or on
its environment. The nominal evolution of the system is a priori known and can
be modeled (by an expert, for example), by different methods. In this paper,
the Petri nets have been chosen. Contrary to the usual use of the Petri nets,
the initial state of the system is unknown. So a degree of belief is bound to
each places, or set of places. The theory used to model this uncertainty is the
Dempster-Shafer's one which is well adapted to this type of problems. From the
given Petri net characterizing the nominal evolution of the dynamic system, and
from the observation inputs, the proposed method allows to determine according
to the reliability of the model and the inputs, the state of the system at any
time.",2013-01-30,2013,2013-01,environment
On Stable Multi-Agent Behavior in Face of Uncertainty,"A stable joint plan should guarantee the achievement of a designer's goal in
a multi-agent environment, while ensuring that deviations from the prescribed
plan would be detected. We present a computational framework where stable joint
plans can be studied, as well as several basic results about the
representation, verification and synthesis of stable joint plans.",2013-02-06,2013,2013-02,environment
"Incremental Map Generation by Low Cost Robots Based on
  Possibility/Necessity Grids","In this paper we present some results obtained with a troupe of low-cost
robots designed to cooperatively explore and adquire the map of unknown
structured orthogonal environments. In order to improve the covering of the
explored zone, the robots show different behaviours and cooperate by
transferring each other the perceived environment when they meet. The returning
robots deliver to a host computer their partial maps and the host incrementally
generates the map of the environment by means of apossibility/ necessity grid.",2013-02-06,2013,2013-02,environment
Bayes Networks for Sonar Sensor Fusion,"Wide-angle sonar mapping of the environment by mobile robot is nontrivial due
to several sources of uncertainty: dropouts due to ""specular"" reflections,
obstacle location uncertainty due to the wide beam, and distance measurement
error. Earlier papers address the latter problems, but dropouts remain a
problem in many environments. We present an approach that lifts the
overoptimistic independence assumption used in earlier work, and use Bayes nets
to represent the dependencies between objects of the model. Objects of the
model consist of readings, and of regions in which ""quasi location invariance""
of the (possible) obstacles exists, with respect to the readings. Simulation
supports the method's feasibility. The model is readily extensible to allow for
prior distributions, as well as other types of sensing operations.",2013-02-06,2013,2013-02,environment
Complexity distribution of agent policies,"We analyse the complexity of environments according to the policies that need
to be used to achieve high performance. The performance results for a
population of policies leads to a distribution that is examined in terms of
policy complexity and analysed through several diagrams and indicators. The
notion of environment response curve is also introduced, by inverting the
performance results into an ability scale. We apply all these concepts,
diagrams and indicators to a minimalistic environment class, agent-populated
elementary cellular automata, showing how the difficulty, discriminating power
and ranges (previous to normalisation) may vary for several environments.",2013-02-08,2013,2013-02,environment
Plan Development using Local Probabilistic Models,"Approximate models of world state transitions are necessary when building
plans for complex systems operating in dynamic environments. External event
probabilities can depend on state feature values as well as time spent in that
particular state. We assign temporally -dependent probability functions to
state transitions. These functions are used to locally compute state
probabilities, which are then used to select highly probable goal paths and
eliminate improbable states. This probabilistic model has been implemented in
the Cooperative Intelligent Real-time Control Architecture (CIRCA), which
combines an AI planner with a separate real-time system such that plans are
developed, scheduled, and executed with real-time guarantees. We present flight
simulation tests that demonstrate how our probabilistic model may improve CIRCA
performance.",2013-02-13,2013,2013-02,environment
Probabilistic Exploration in Planning while Learning,"Sequential decision tasks with incomplete information are characterized by
the exploration problem; namely the trade-off between further exploration for
learning more about the environment and immediate exploitation of the accrued
information for decision-making. Within artificial intelligence, there has been
an increasing interest in studying planning-while-learning algorithms for these
decision tasks. In this paper we focus on the exploration problem in
reinforcement learning and Q-learning in particular. The existing exploration
strategies for Q-learning are of a heuristic nature and they exhibit limited
scaleability in tasks with large (or infinite) state and action spaces.
Efficient experimentation is needed for resolving uncertainties when possible
plans are compared (i.e. exploration). The experimentation should be sufficient
for selecting with statistical significance a locally optimal plan (i.e.
exploitation). For this purpose, we develop a probabilistic hill-climbing
algorithm that uses a statistical selection procedure to decide how much
exploration is needed for selecting a plan which is, with arbitrarily high
probability, arbitrarily close to a locally optimal one. Due to its generality
the algorithm can be employed for the exploration strategy of robust
Q-learning. An experiment on a relatively complex control task shows that the
proposed exploration strategy performs better than a typical exploration
strategy.",2013-02-20,2013,2013-02,environment
"A Structured, Probabilistic Representation of Action","When agents devise plans for execution in the real world, they face two
important forms of uncertainty: they can never have complete knowledge about
the state of the world, and they do not have complete control, as the effects
of their actions are uncertain. While most classical planning methods avoid
explicit uncertainty reasoning, we believe that uncertainty should be
explicitly represented and reasoned about. We develop a probabilistic
representation for states and actions, based on belief networks. We define
conditional belief nets (CBNs) to capture the probabilistic dependency of the
effects of an action upon the state of the world. We also use a CBN to
represent the intrinsic relationships among entities in the environment, which
persist from state to state. We present a simple projection algorithm to
construct the belief network of the state succeeding an action, using the
environment CBN model to infer indirect effects. We discuss how the qualitative
aspects of belief networks and CBNs make them appropriate for the various
stages of the problem solving process, from model construction to the design of
planning algorithms.",2013-02-27,2013,2013-02,environment
Operator Selection While Planning Under Uncertainty,"This paper describes the best first search strategy used by U-Plan (Mansell
1993a), a planning system that constructs quantitatively ranked plans given an
incomplete description of an uncertain environment. U-Plan uses uncertain and
incomplete evidence de scribing the environment, characterizes it using a
Dempster-Shafer interval, and generates a set of possible world states. Plan
construction takes place in an abstraction hierarchy where strategic decisions
are made before tactical decisions. Search through this abstraction hierarchy
is guided by a quantitative measure (expected fulfillment) based on decision
theory. The search strategy is best first with the provision to update expected
fulfillment and review previous decisions in the light of planning
developments. U-Plan generates multiple plans for multiple possible worlds, and
attempts to use existing plans for new world situations. A super-plan is then
constructed, based on merging the set of plans and appropriately timed
knowledge acquisition operators, which are used to decide between plan
alternatives during plan execution.",2013-02-27,2013,2013-02,environment
Robust Planning in Uncertain Environments,"This paper describes a novel approach to planning which takes advantage of
decision theory to greatly improve robustness in an uncertain environment. We
present an algorithm which computes conditional plans of maximum expected
utility. This algorithm relies on a representation of the search space as an
AND/OR tree and employs a depth-limit to control computation costs. A numeric
robustness factor, which parameterizes the utility function, allows the user to
modulate the degree of risk-aversion employed by the planner. Via a look-ahead
search, the planning algorithm seeks to find an optimal plan using expected
utility as its optimization criterion. We present experimental results obtained
by applying our algorithm to a non-deterministic extension of the blocks world
domain. Our results demonstrate that the robustness factor governs the degree
of risk embodied in the conditional plans computed by our algorithm.",2013-02-27,2013,2013-02,environment
Learning in Multi-level Stochastic games with Delayed Information,"Distributed decision-makers are modeled as players in a game with two levels.
High level decisions concern the game environment and determine the willingness
of the players to form a coalition (or group). Low level decisions involve the
actions to be implemented within the chosen environment. Coalition and action
strategies are determined by probability distributions, which are updated using
learning automata schemes. The payoffs are also probabilistic and there is
uncertainty in the state vector since information is delayed. The goal is to
reach equilibrium in both levels of decision making; the results show the
conditions for instability, based on the age of information.",2013-02-27,2013,2013-02,environment
The Automated Mapping of Plans for Plan Recognition,"To coordinate with other agents in its environment, an agent needs models of
what the other agents are trying to do. When communication is impossible or
expensive, this information must be acquired indirectly via plan recognition.
Typical approaches to plan recognition start with a specification of the
possible plans the other agents may be following, and develop special
techniques for discriminating among the possibilities. Perhaps more desirable
would be a uniform procedure for mapping plans to general structures supporting
inference based on uncertain and incomplete observations. In this paper, we
describe a set of methods for converting plans represented in a flexible
procedural language to observation models represented as probabilistic belief
networks.",2013-02-27,2013,2013-02,environment
Syntax-based Default Reasoning as Probabilistic Model-based Diagnosis,"We view the syntax-based approaches to default reasoning as a model-based
diagnosis problem, where each source giving a piece of information is
considered as a component. It is formalized in the ATMS framework (each source
corresponds to an assumption). We assume then that all sources are independent
and ""fail"" with a very small probability. This leads to a probability
assignment on the set of candidates, or equivalently on the set of consistent
environments. This probability assignment induces a Dempster-Shafer belief
function which measures the probability that a proposition can be deduced from
the evidence. This belief function can be used in several different ways to
define a non-monotonic consequence relation. We study and compare these
consequence relations. The -case of prioritized knowledge bases is briefly
considered.",2013-02-27,2013,2013-02,environment
The Semantic Web takes Wing: Programming Ontologies with Tawny-OWL,"The Tawny-OWL library provides a fully-programmatic environment for ontology
building; it enables the use of a rich set of tools for ontology development,
by recasting development as a form of programming. It is built in Clojure - a
modern Lisp dialect, and is backed by the OWL API. Used simply, it has a
similar syntax to OWL Manchester syntax, but it provides arbitrary
extensibility and abstraction. It builds on existing facilities for Clojure,
which provides a rich and modern programming tool chain, for versioning,
distributed development, build, testing and continuous integration. In this
paper, we describe the library, this environment and the its potential
implications for the ontology development process.",2013-03-01,2013,2013-03,environment
"Representing and Reasoning With Probabilistic Knowledge: A Bayesian
  Approach","PAGODA (Probabilistic Autonomous Goal-Directed Agent) is a model for
autonomous learning in probabilistic domains [desJardins, 1992] that
incorporates innovative techniques for using the agent's existing knowledge to
guide and constrain the learning process and for representing, reasoning with,
and learning probabilistic knowledge. This paper describes the probabilistic
representation and inference mechanism used in PAGODA. PAGODA forms theories
about the effects of its actions and the world state on the environment over
time. These theories are represented as conditional probability distributions.
A restriction is imposed on the structure of the theories that allows the
inference mechanism to find a unique predicted distribution for any action and
world state description. These restricted theories are called uniquely
predictive theories. The inference mechanism, Probability Combination using
Independence (PCI), uses minimal independence assumptions to combine the
probabilities in a theory to make probabilistic predictions.",2013-03-06,2013,2013-03,environment
A Method for Planning Given Uncertain and Incomplete Information,"This paper describes ongoing research into planning in an uncertain
environment. In particular, it introduces U-Plan, a planning system that
constructs quantitatively ranked plans given an incomplete description of the
state of the world. U-Plan uses a DempsterShafer interval to characterise
uncertain and incomplete information about the state of the world. The planner
takes as input what is known about the world, and constructs a number of
possible initial states with representations at different abstraction levels. A
plan is constructed for the initial state with the greatest support, and this
plan is tested to see if it will work for other possible initial states. All,
part, or none of the existing plans may be used in the generation of the plans
for the remaining possible worlds. Planning takes place in an abstraction
hierarchy where strategic decisions are made before tactical decisions. A
super-plan is then constructed, based on merging the set of plans and the
appropriately timed acquisition of essential knowledge, which is used to decide
between plan alternatives. U-Plan usually produces a super-plan in less time
than a classical planner would take to produce a set of plans, one for each
possible world.",2013-03-06,2013,2013-03,environment
Sensor Validation Using Dynamic Belief Networks,"The trajectory of a robot is monitored in a restricted dynamic environment
using light beam sensor data. We have a Dynamic Belief Network (DBN), based on
a discrete model of the domain, which provides discrete monitoring analogous to
conventional quantitative filter techniques. Sensor observations are added to
the basic DBN in the form of specific evidence. However, sensor data is often
partially or totally incorrect. We show how the basic DBN, which infers only an
impossible combination of evidence, may be modified to handle specific types of
incorrect data which may occur in the domain. We then present an extension to
the DBN, the addition of an invalidating node, which models the status of the
sensor as working or defective. This node provides a qualitative explanation of
inconsistent data: it is caused by a defective sensor. The connection of
successive instances of the invalidating node models the status of a sensor
over time, allowing the DBN to handle both persistent and intermittent faults.",2013-03-13,2013,2013-03,environment
High Level Path Planning with Uncertainty,"For high level path planning, environments are usually modeled as distance
graphs, and path planning problems are reduced to computing the shortest path
in distance graphs. One major drawback of this modeling is the inability to
model uncertainties, which are often encountered in practice. In this paper, a
new tool, called U-yraph, is proposed for environment modeling. A U-graph is an
extension of distance graphs with the ability to handle a kind of uncertainty.
By modeling an uncertain environment as a U-graph, and a navigation problem as
a Markovian decision process, we can precisely define a new optimality
criterion for navigation plans, and more importantly, we can come up with a
general algorithm for computing optimal plans for navigation tasks.",2013-03-20,2013,2013-03,environment
Ergo: A Graphical Environment for Constructing Bayesian,"We describe an environment that considerably simplifies the process of
generating Bayesian belief networks. The system has been implemented on readily
available, inexpensive hardware, and provides clarity and high performance. We
present an introduction to Bayesian belief networks, discuss algorithms for
inference with these networks, and delineate the classes of problems that can
be solved with this paradigm. We then describe the hardware and software that
constitute the system, and illustrate Ergo's use with several example",2013-03-27,2013,2013-03,environment
A Probabilistic Reasoning Environment,"A framework is presented for a computational theory of probabilistic
argument. The Probabilistic Reasoning Environment encodes knowledge at three
levels. At the deepest level are a set of schemata encoding the system's domain
knowledge. This knowledge is used to build a set of second-level arguments,
which are structured for efficient recapture of the knowledge used to construct
them. Finally, at the top level is a Bayesian network constructed from the
arguments. The system is designed to facilitate not just propagation of beliefs
and assimilation of evidence, but also the dynamic process of constructing a
belief network, evaluating its adequacy, and revising it when necessary.",2013-03-27,2013,2013-03,environment
IDEAL: A Software Package for Analysis of Influence Diagrams,"IDEAL (Influence Diagram Evaluation and Analysis in Lisp) is a software
environment for creation and evaluation of belief networks and influence
diagrams. IDEAL is primarily a research tool and provides an implementation of
many of the latest developments in belief network and influence diagram
evaluation in a unified framework. This paper describes IDEAL and some lessons
learned during its development.",2013-03-27,2013,2013-03,environment
"An Uncertainty Management Calculus for Ordering Searches in Distributed
  Dynamic Databases","MINDS is a distributed system of cooperating query engines that customize,
document retrieval for each user in a dynamic environment. It improves its
performance and adapts to changing patterns of document distribution by
observing system-user interactions and modifying the appropriate certainty
factors, which act as search control parameters. It argued here that the
uncertainty management calculus must account for temporal precedence,
reliability of evidence, degree of support for a proposition, and saturation
effects. The calculus presented here possesses these features. Some results
obtained with this scheme are discussed.",2013-03-27,2013,2013-03,environment
Exact Reasoning Under Uncertainty,"This paper focuses on designing expert systems to support decision making in
complex, uncertain environments. In this context, our research indicates that
strictly probabilistic representations, which enable the use of
decision-theoretic reasoning, are highly preferable to recently proposed
alternatives (e.g., fuzzy set theory and Dempster-Shafer theory). Furthermore,
we discuss the language of influence diagrams and a corresponding methodology
-decision analysis -- that allows decision theory to be used effectively and
efficiently as a decision-making aid. Finally, we use RACHEL, a system that
helps infertile couples select medical treatments, to illustrate the
methodology of decision analysis as basis for expert decision systems.",2013-03-27,2013,2013-03,environment
Probabilistic Conflict Resolution in Hierarchical Hypothesis Spaces,"Artificial intelligence applications such as industrial robotics, military
surveillance, and hazardous environment clean-up, require situation
understanding based on partial, uncertain, and ambiguous or erroneous evidence.
It is necessary to evaluate the relative likelihood of multiple possible
hypotheses of the (current) situation faced by the decision making program.
Often, the evidence and hypotheses are hierarchical in nature. In image
understanding tasks, for example, evidence begins with raw imagery, from which
ambiguous features are extracted which have multiple possible aggregations
providing evidential support for the presence of multiple hypothesis of objects
and terrain, which in turn aggregate in multiple ways to provide partial
evidence for different interpretations of the ambient scene. Information fusion
for military situation understanding has a similar evidence/hypothesis
hierarchy from multiple sensor through message level interpretations, and also
provides evidence at multiple levels of the doctrinal hierarchy of military
forces.",2013-03-27,2013,2013-03,environment
Reducing Uncertainty in Navigation and Exploration,"A significant problem in designing mobile robot control systems involves
coping with the uncertainty that arises in moving about in an unknown or
partially unknown environment and relying on noisy or ambiguous sensor data to
acquire knowledge about that environment. We describe a control system that
chooses what activity to engage in next on the basis of expectations about how
the information re- turned as a result of a given activity will improve 2 its
knowledge about the spatial layout of its environment. Certain of the
higher-level components of the control system are specified in terms of
probabilistic decision models whose output is used to mediate the behavior of
lower-level control components responsible for movement and sensing.",2013-03-27,2013,2013-03,environment
Application of Evidential Reasoning to Helicopter Flight Path Control,"This paper presents a methodology for research and development of the
inferencing and knowledge representation aspects of an Expert System approach
for performing reasoning under uncertainty in support of a real time vehicle
guidance and navigation system. Such a system could be of major benefit for
non-terrain following low altitude flight systems operating in foreign hostile
environments such as might be experienced by NOE helicopter or similar mission
craft. An innovative extension of the evidential reasoning methodology, termed
the Sum-and-Lattice-Points Method, has been developed. The research and
development effort presented in this paper consists of a formal mathematical
development of the Sum-and-Lattice-Points Method, its formulation and
representation in a parallel environment, prototype software development of the
method within an expert system, and initial testing of the system within the
confines of the vehicle guidance system.",2013-03-27,2013,2013-03,environment
"An Empirical Evaluation of a Randomized Algorithm for Probabilistic
  Inference","In recent years, researchers in decision analysis and artificial intelligence
(Al) have used Bayesian belief networks to build models of expert opinion.
Using standard methods drawn from the theory of computational complexity,
workers in the field have shown that the problem of probabilistic inference in
belief networks is difficult and almost certainly intractable. K N ET, a
software environment for constructing knowledge-based systems within the
axiomatic framework of decision theory, contains a randomized approximation
scheme for probabilistic inference. The algorithm can, in many circumstances,
perform efficient approximate inference in large and richly interconnected
models of medical diagnosis. Unlike previously described stochastic algorithms
for probabilistic inference, the randomized approximation scheme computes a
priori bounds on running time by analyzing the structure and contents of the
belief network. In this article, we describe a randomized algorithm for
probabilistic inference and analyze its performance mathematically. Then, we
devote the major portion of the paper to a discussion of the algorithm's
empirical behavior. The results indicate that the generation of good trials
(that is, trials whose distribution closely matches the true distribution),
rather than the computation of numerous mediocre trials, dominates the
performance of stochastic simulation. Key words: probabilistic inference,
belief networks, stochastic simulation, computational complexity theory,
randomized algorithms.",2013-03-27,2013,2013-03,environment
A Decision-Theoretic Model for Using Scientific Data,"Many Artificial Intelligence systems depend on the agent's updating its
beliefs about the world on the basis of experience. Experiments constitute one
type of experience, so scientific methodology offers a natural environment for
examining the issues attendant to using this class of evidence. This paper
presents a framework which structures the process of using scientific data from
research reports for the purpose of making decisions, using decision analysis
as the basis for the structure and using medical research as the general
scientific domain. The structure extends the basic influence diagram for
updating belief in an object domain parameter of interest by expanding the
parameter into four parts: those of the patient, the population, the study
sample, and the effective study sample. The structure uses biases to perform
the transformation of one parameter into another, so that, for instance,
selection biases, in concert with the population parameter, yield the study
sample parameter. The influence diagram structure provides decision theoretic
justification for practices of good clinical research such as randomized
assignment and blindfolding of care providers. The model covers most research
designs used in medicine: case-control studies, cohort studies, and controlled
clinical trials, and provides an architecture to separate clearly between
statistical knowledge and domain knowledge. The proposed general model can be
the basis for clinical epidemiological advisory systems, when coupled with
heuristic pruning of irrelevant biases; of statistical workstations, when the
computational machinery for calculation of posterior distributions is added;
and of meta-analytic reviews, when multiple studies may impact on a single
population parameter.",2013-03-27,2013,2013-03,environment
"Now that I Have a Good Theory of Uncertainty, What Else Do I Need?","Rather than discussing the isolated merits of a nominative theory of
uncertainty, this paper focuses on a class of problems, referred to as Dynamic
Classification Problem (DCP), which requires the integration of many theories,
including a prescriptive theory of uncertainty. We start by analyzing the
Dynamic Classification Problem and by defining its induced requirements on a
supporting (plausible) reasoning system. We provide a summary of the underlying
theory (based on the semantics of many-valed logics) and illustrate the
constraints imposed upon it to ensure the modularity and computational
performance required by the applications. We describe the technologies used for
knowledge engineering (such as object-based simulator to exercise requirements,
and development tools to build the Knowledge Base and functionally validate
it). We emphasize the difference between development environment and run-time
system, describe the rule cross-compiler, and the real-time inference engine
with meta-reasoning capabilities. Finally, we illustrate how our proposed
technology satisfies the pop's requirements and analyze some of the lessons
reamed from its applications to situation assessment problems for Pilot's
Associate and Submarine Commander Associate.",2013-03-27,2013,2013-03,environment
"Hierarchical Evidence Accumulation in the Pseiki System and Experiments
  in Model-Driven Mobile Robot Navigation","In this paper, we will review the process of evidence accumulation in the
PSEIKI system for expectation-driven interpretation of images of 3-D scenes.
Expectations are presented to PSEIKI as a geometrical hierarchy of
abstractions. PSEIKI's job is then to construct abstraction hierarchies in the
perceived image taking cues from the abstraction hierarchies in the
expectations. The Dempster-Shafer formalism is used for associating belief
values with the different possible labels for the constructed abstractions in
the perceived image. This system has been used successfully for autonomous
navigation of a mobile robot in indoor environments.",2013-03-27,2013,2013-03,environment
"Decision-Theoretic Control of Problem Solving: Principles and
  Architecture","This paper presents an approach to the design of autonomous, real-time
systems operating in uncertain environments. We address issues of problem
solving and reflective control of reasoning under uncertainty in terms of two
fundamental elements: l) a set of decision-theoretic models for selecting among
alternative problem-solving methods and 2) a general computational architecture
for resource-bounded problem solving. The decisiontheoretic models provide a
set of principles for choosing among alternative problem-solving methods based
on their relative costs and benefits, where benefits are characterized in terms
of the value of information provided by the output of a reasoning activity. The
output may be an estimate of some uncertain quantity or a recommendation for
action. The computational architecture, called Schemer-ll, provides for
interleaving of and communication among various problem-solving subsystems.
These subsystems provide alternative approaches to information gathering,
belief refinement, solution construction, and solution execution. In
particular, the architecture provides a mechanism for interrupting the
subsystems in response to critical events. We provide a decision theoretic
account for scheduling problem-solving elements and for critical-event-driven
interruption of activities in an architecture such as Schemer-II.",2013-03-27,2013,2013-03,environment
Compiling Fuzzy Logic Control Rules to Hardware Implementations,"A major aspect of human reasoning involves the use of approximations.
Particularly in situations where the decision-making process is under stringent
time constraints, decisions are based largely on approximate, qualitative
assessments of the situations. Our work is concerned with the application of
approximate reasoning to real-time control. Because of the stringent processing
speed requirements in such applications, hardware implementations of fuzzy
logic inferencing are being pursued. We describe a programming environment for
translating fuzzy control rules into hardware realizations. Two methods of
hardware realizations are possible. The First is based on a special purpose
chip for fuzzy inferencing. The second is based on a simple memory chip. The
ability to directly translate a set of decision rules into hardware
implementations is expected to make fuzzy control an increasingly practical
approach to the control of complex systems.",2013-03-27,2013,2013-03,environment
Logical Fuzzy Optimization,"We present a logical framework to represent and reason about fuzzy
optimization problems based on fuzzy answer set optimization programming. This
is accomplished by allowing fuzzy optimization aggregates, e.g., minimum and
maximum in the language of fuzzy answer set optimization programming to allow
minimization or maximization of some desired criteria under fuzzy environments.
We show the application of the proposed logical fuzzy optimization framework
under the fuzzy answer set optimization programming to the fuzzy water
allocation optimization problem.",2013-04-05,2013,2013-04,environment
"A General Framework for Interacting Bayes-Optimally with Self-Interested
  Agents using Arbitrary Parametric Model and Model Prior","Recent advances in Bayesian reinforcement learning (BRL) have shown that
Bayes-optimality is theoretically achievable by modeling the environment's
latent dynamics using Flat-Dirichlet-Multinomial (FDM) prior. In
self-interested multi-agent environments, the transition dynamics are mainly
controlled by the other agent's stochastic behavior for which FDM's
independence and modeling assumptions do not hold. As a result, FDM does not
allow the other agent's behavior to be generalized across different states nor
specified using prior domain knowledge. To overcome these practical limitations
of FDM, we propose a generalization of BRL to integrate the general class of
parametric models and model priors, thus allowing practitioners' domain
knowledge to be exploited to produce a fine-grained and compact representation
of the other agent's behavior. Empirical evaluation shows that our approach
outperforms existing multi-agent reinforcement learning algorithms.",2013-04-07,2013,2013-04,environment
Universal Induction with Varying Sets of Combinators,"Universal induction is a crucial issue in AGI. Its practical applicability
can be achieved by the choice of the reference machine or representation of
algorithms agreed with the environment. This machine should be updatable for
solving subsequent tasks more efficiently. We study this problem on an example
of combinatory logic as the very simple Turing-complete reference machine,
which enables modifying program representations by introducing different sets
of primitive combinators. Genetic programming system is used to search for
combinator expressions, which are easily decomposed into sub-expressions being
recombined in crossover. Our experiments show that low-complexity induction or
prediction tasks can be solved by the developed system (much more efficiently
than using brute force); useful combinators can be revealed and included into
the representation simplifying more difficult tasks. However, optimal sets of
combinators depend on the specific task, so the reference machine should be
adaptively chosen in coordination with the search engine.",2013-06-01,2013,2013-06,environment
Direct Uncertainty Estimation in Reinforcement Learning,"Optimal probabilistic approach in reinforcement learning is computationally
infeasible. Its simplification consisting in neglecting difference between true
environment and its model estimated using limited number of observations causes
exploration vs exploitation problem. Uncertainty can be expressed in terms of a
probability distribution over the space of environment models, and this
uncertainty can be propagated to the action-value function via Bellman
iterations, which are computationally insufficiently efficient though. We
consider possibility of directly measuring uncertainty of the action-value
function, and analyze sufficiency of this facilitated approach.",2013-06-06,2013,2013-06,environment
"Cognitive Interpretation of Everyday Activities: Toward Perceptual
  Narrative Based Visuo-Spatial Scene Interpretation","We position a narrative-centred computational model for high-level knowledge
representation and reasoning in the context of a range of assistive
technologies concerned with ""visuo-spatial perception and cognition"" tasks. Our
proposed narrative model encompasses aspects such as \emph{space, events,
actions, change, and interaction} from the viewpoint of commonsense reasoning
and learning in large-scale cognitive systems. The broad focus of this paper is
on the domain of ""human-activity interpretation"" in smart environments, ambient
intelligence etc. In the backdrop of a ""smart meeting cinematography"" domain,
we position the proposed narrative model, preliminary work on perceptual
narrativisation, and the immediate outlook on constructing general-purpose
open-source tools for perceptual narrativisation.
  ACM Classification: I.2 Artificial Intelligence: I.2.0 General -- Cognitive
Simulation, I.2.4 Knowledge Representation Formalisms and Methods, I.2.10
Vision and Scene Understanding: Architecture and control structures, Motion,
Perceptual reasoning, Shape, Video analysis
  General keywords: cognitive systems; human-computer interaction; spatial
cognition and computation; commonsense reasoning; spatial and temporal
reasoning; assistive technologies",2013-06-22,2013,2013-06,environment
"Linear combination of one-step predictive information with an external
  reward in an episodic policy gradient setting: a critical analysis","One of the main challenges in the field of embodied artificial intelligence
is the open-ended autonomous learning of complex behaviours. Our approach is to
use task-independent, information-driven intrinsic motivation(s) to support
task-dependent learning. The work presented here is a preliminary step in which
we investigate the predictive information (the mutual information of the past
and future of the sensor stream) as an intrinsic drive, ideally supporting any
kind of task acquisition. Previous experiments have shown that the predictive
information (PI) is a good candidate to support autonomous, open-ended learning
of complex behaviours, because a maximisation of the PI corresponds to an
exploration of morphology- and environment-dependent behavioural regularities.
The idea is that these regularities can then be exploited in order to solve any
given task. Three different experiments are presented and their results lead to
the conclusion that the linear combination of the one-step PI with an external
reward function is not generally recommended in an episodic policy gradient
setting. Only for hard tasks a great speed-up can be achieved at the cost of an
asymptotic performance lost.",2013-09-26,2013,2013-09,environment
Changing the Environment based on Intrinsic Motivation,"One of the remarkable feats of intelligent life is that it restructures the
world it lives in for its own benefit. This extended abstract outlines how the
information-theoretic principle of empowerment, as an intrinsic motivation, can
be used to restructure the environment an agent lives in. We present a first
qualitative evaluation of how an agent in a 3d-gridworld builds a
staircase-like structure, which reflects the agent's embodiment.",2013-10-14,2013,2013-10,environment
"Emotional Responses in Artificial Agent-Based Systems: Reflexivity and
  Adaptation in Artificial Life","The current work addresses a virtual environment with self-replicating agents
whose decisions are based on a form of ""somatic computation"" (soma - body) in
which basic emotional responses, taken in parallelism to actual living
organisms, are introduced as a way to provide the agents with greater reflexive
abilities. The work provides a contribution to the field of Artificial
Intelligence (AI) and Artificial Life (ALife) in connection to a
neurobiology-based cognitive framework for artificial systems and virtual
environments' simulations. The performance of the agents capable of emotional
responses is compared with that of self-replicating automata, and the
implications of research on emotions and AI, in connection to both virtual
agents as well as robots, is addressed regarding possible future directions and
applications.",2014-01-09,2014,2014-01,environment
"A Rigorously Bayesian Beam Model and an Adaptive Full Scan Model for
  Range Finders in Dynamic Environments","This paper proposes and experimentally validates a Bayesian network model of
a range finder adapted to dynamic environments. All modeling assumptions are
rigorously explained, and all model parameters have a physical interpretation.
This approach results in a transparent and intuitive model. With respect to the
state of the art beam model this paper: (i) proposes a different functional
form for the probability of range measurements caused by unmodeled objects,
(ii) intuitively explains the discontinuity encountered in te state of the art
beam model, and (iii) reduces the number of model parameters, while maintaining
the same representational power for experimental data. The proposed beam model
is called RBBM, short for Rigorously Bayesian Beam Model. A maximum likelihood
and a variational Bayesian estimator (both based on expectation-maximization)
are proposed to learn the model parameters.
  Furthermore, the RBBM is extended to a full scan model in two steps: first,
to a full scan model for static environments and next, to a full scan model for
general, dynamic environments. The full scan model accounts for the dependency
between beams and adapts to the local sample density when using a particle
filter. In contrast to Gaussian-based state of the art models, the proposed
full scan model uses a sample-based approximation. This sample-based
approximation enables handling dynamic environments and capturing
multi-modality, which occurs even in simple static environments.",2014-01-15,2014,2014-01,environment
Online Planning Algorithms for POMDPs,"Partially Observable Markov Decision Processes (POMDPs) provide a rich
framework for sequential decision-making under uncertainty in stochastic
domains. However, solving a POMDP is often intractable except for small
problems due to their complexity. Here, we focus on online approaches that
alleviate the computational complexity by computing good local policies at each
decision step during the execution. Online algorithms generally consist of a
lookahead search to find the best action to execute at each time step in an
environment. Our objectives here are to survey the various existing online
POMDP methods, analyze their properties and discuss their advantages and
disadvantages; and to thoroughly evaluate these online approaches in different
environments under various metrics (return, error bound reduction, lower bound
improvement). Our experimental results indicate that state-of-the-art online
heuristic search methods can handle large POMDP domains efficiently.",2014-01-15,2014,2014-01,environment
Computational Logic Foundations of KGP Agents,"This paper presents the computational logic foundations of a model of agency
called the KGP (Knowledge, Goals and Plan model. This model allows the
specification of heterogeneous agents that can interact with each other, and
can exhibit both proactive and reactive behaviour allowing them to function in
dynamic environments by adjusting their goals and plans when changes happen in
such environments. KGP provides a highly modular agent architecture that
integrates a collection of reasoning and physical capabilities, synthesised
within transitions that update the agents state in response to reasoning,
sensing and acting. Transitions are orchestrated by cycle theories that specify
the order in which transitions are executed while taking into account the
dynamic context and agent preferences, as well as selection operators for
providing inputs to transitions.",2014-01-15,2014,2014-01,environment
"Learning to Make Predictions In Partially Observable Environments
  Without a Generative Model","When faced with the problem of learning a model of a high-dimensional
environment, a common approach is to limit the model to make only a restricted
set of predictions, thereby simplifying the learning problem. These partial
models may be directly useful for making decisions or may be combined together
to form a more complete, structured model. However, in partially observable
(non-Markov) environments, standard model-learning methods learn generative
models, i.e. models that provide a probability distribution over all possible
futures (such as POMDPs). It is not straightforward to restrict such models to
make only certain predictions, and doing so does not always simplify the
learning problem. In this paper we present prediction profile models:
non-generative partial models for partially observable systems that make only a
given set of predictions, and are therefore far simpler than generative models
in some cases. We formalize the problem of learning a prediction profile model
as a transformation of the original model-learning problem, and show
empirically that one can learn prediction profile models that make a small set
of important predictions even in systems that are too complex for standard
generative models.",2014-01-16,2014,2014-01,environment
Efficient Planning under Uncertainty with Macro-actions,"Deciding how to act in partially observable environments remains an active
area of research. Identifying good sequences of decisions is particularly
challenging when good control performance requires planning multiple steps into
the future in domains with many states. Towards addressing this challenge, we
present an online, forward-search algorithm called the Posterior Belief
Distribution (PBD). PBD leverages a novel method for calculating the posterior
distribution over beliefs that result after a sequence of actions is taken,
given the set of observation sequences that could be received during this
process. This method allows us to efficiently evaluate the expected reward of a
sequence of primitive actions, which we refer to as macro-actions. We present a
formal analysis of our approach, and examine its performance on two very large
simulation experiments: scientific exploration and a target monitoring domain.
We also demonstrate our algorithm being used to control a real robotic
helicopter in a target monitoring experiment, which suggests that our approach
has practical potential for planning in real-world, large partially observable
domains where a multi-step lookahead is required to achieve good performance.",2014-01-16,2014,2014-01,environment
Safe Exploration of State and Action Spaces in Reinforcement Learning,"In this paper, we consider the important problem of safe exploration in
reinforcement learning. While reinforcement learning is well-suited to domains
with complex transition dynamics and high-dimensional state-action spaces, an
additional challenge is posed by the need for safe and efficient exploration.
Traditional exploration techniques are not particularly useful for solving
dangerous tasks, where the trial and error process may lead to the selection of
actions whose execution in some states may result in damage to the learning
system (or any other system). Consequently, when an agent begins an interaction
with a dangerous and high-dimensional state-action space, an important question
arises; namely, that of how to avoid (or at least minimize) damage caused by
the exploration of the state-action space. We introduce the PI-SRL algorithm
which safely improves suboptimal albeit robust behaviors for continuous state
and action control tasks and which efficiently learns from the experience
gained from the environment. We evaluate the proposed method in four complex
tasks: automatic car parking, pole-balancing, helicopter hovering, and business
management.",2014-02-04,2014,2014-02,environment
Intelligent User Interface in Fuzzy Environment,"Human-Computer Interaction with the traditional User Interface is done using
a specified in advance script dialog menu, mainly based on human intellect and
unproductive use of navigation. This approach does not lead to making
qualitative decision in control systems, where the situations and processes
cannot be structured in advance. Any dynamic changes in the controlled business
process (as example, in organizational unit of the information fuzzy control
system) make it necessary to modify the script dialogue in User Interface. This
circumstance leads to a redesign of the components of the User Interface and of
the entire control system. In the Intelligent User Interface, where the dialog
situations are unknown in advance, fuzzy structured and artificial intelligence
is crucial, the redesign described above is impossible. To solve this and other
problems, we propose the data, information and knowledge based technology of
Smart/ Intelligent User Interface (IUI) design, which interacts with users and
systems in natural and other languages, utilizing the principles of Situational
Control and Fuzzy Logic theories, Artificial Intelligence, Linguistics,
Knowledge Base technologies and others. The proposed technology of IUI design
is defined by multi-agents of Situational Control and of data, information and
knowledge, modelling of Fuzzy Logic Inference, Generalization, Representation
and Explanation of knowledge, Planning and Decision-making, Dialog Control,
Reasoning and Systems Thinking, Fuzzy Control of organizational unit in
real-time, fuzzy conditions, heterogeneous domains, and multi-lingual
communication under uncertainty and in Fuzzy Environment.",2014-02-10,2014,2014-02,environment
Line Maps in Cluttered Environments,"This paper uses the smoothing and mapping framework to solve the SLAM problem
in indoor environments; focusing on how some key issues such as feature
extraction and data association can be handled by applying probabilistic
techniques. For feature extraction, an odds ratio approach to find multiple
lines from laser scans is proposed, this criterion allows to decide which model
must be merged and to output the best number of models. In addition, to solve
the data association problem a method based on the segments of each line is
proposed. Experimental results show that high quality indoor maps can be
obtained from noisy data",2014-02-20,2014,2014-02,environment
"Enaction-Based Artificial Intelligence: Toward Coevolution with Humans
  in the Loop","This article deals with the links between the enaction paradigm and
artificial intelligence. Enaction is considered a metaphor for artificial
intelligence, as a number of the notions which it deals with are deemed
incompatible with the phenomenal field of the virtual. After explaining this
stance, we shall review previous works regarding this issue in terms of
artifical life and robotics. We shall focus on the lack of recognition of
co-evolution at the heart of these approaches. We propose to explicitly
integrate the evolution of the environment into our approach in order to refine
the ontogenesis of the artificial system, and to compare it with the enaction
paradigm. The growing complexity of the ontogenetic mechanisms to be activated
can therefore be compensated by an interactive guidance system emanating from
the environment. This proposition does not however resolve that of the
relevance of the meaning created by the machine (sense-making). Such
reflections lead us to integrate human interaction into this environment in
order to construct relevant meaning in terms of participative artificial
intelligence. This raises a number of questions with regards to setting up an
enactive interaction. The article concludes by exploring a number of issues,
thereby enabling us to associate current approaches with the principles of
morphogenesis, guidance, the phenomenology of interactions and the use of
minimal enactive interfaces in setting up experiments which will deal with the
problem of artificial intelligence in a variety of enaction-based ways.",2014-02-26,2014,2014-02,environment
"Cortex simulation system proposal using distributed computer network
  environments","In the dawn of computer science and the eve of neuroscience we participate in
rebirth of neuroscience due to new technology that allows us to deeply and
precisely explore whole new world that dwells in our brains.",2014-03-22,2014,2014-03,environment
TurKPF: TurKontrol as a Particle Filter,"TurKontrol, and algorithm presented in (Dai et al. 2010), uses a POMDP to
model and control an iterative workflow for crowdsourced work. Here, TurKontrol
is re-implemented as ""TurKPF,"" which uses a Particle Filter to reduce
computation time & memory usage. Most importantly, in our experimental
environment with default parameter settings, the action is chosen nearly
instantaneously. Through a series of experiments we see that TurKPF and
TurKontrol perform similarly.",2014-04-20,2014,2014-04,environment
"Projective simulation applied to the grid-world and the mountain-car
  problem","We study the model of projective simulation (PS) which is a novel approach to
artificial intelligence (AI). Recently it was shown that the PS agent performs
well in a number of simple task environments, also when compared to standard
models of reinforcement learning (RL). In this paper we study the performance
of the PS agent further in more complicated scenarios. To that end we chose two
well-studied benchmarking problems, namely the ""grid-world"" and the
""mountain-car"" problem, which challenge the model with large and continuous
input space. We compare the performance of the PS agent model with those of
existing models and show that the PS agent exhibits competitive performance
also in such scenarios.",2014-05-21,2014,2014-05,environment
"A self-organizing system for urban traffic control based on predictive
  interval microscopic model","This paper introduces a self-organizing traffic signal system for an urban
road network. The key elements of this system are agents that control traffic
signals at intersections. Each agent uses an interval microscopic traffic model
to predict effects of its possible control actions in a short time horizon. The
executed control action is selected on the basis of predicted delay intervals.
Since the prediction results are represented by intervals, the agents can
recognize and suspend those control actions, whose positive effect on the
performance of traffic control is uncertain. Evaluation of the proposed traffic
control system was performed in a simulation environment. The simulation
experiments have shown that the proposed approach results in an improved
performance, particularly for non-uniform traffic streams.",2014-06-04,2014,2014-06,environment
Flow for Meta Control,"The psychological state of flow has been linked to optimizing human
performance. A key condition of flow emergence is a match between the human
abilities and complexity of the task. We propose a simple computational model
of flow for Artificial Intelligence (AI) agents. The model factors the standard
agent-environment state into a self-reflective set of the agent's abilities and
a socially learned set of the environmental complexity. Maximizing the flow
serves as a meta control for the agent. We show how to apply the meta-control
policy to a broad class of AI control policies and illustrate our approach with
a specific implementation. Results in a synthetic testbed are promising and
open interesting directions for future work.",2014-07-17,2014,2014-07,environment
Learning to Cooperate via Policy Search,"Cooperative games are those in which both agents share the same payoff
structure. Value-based reinforcement-learning algorithms, such as variants of
Q-learning, have been applied to learning cooperative games, but they only
apply when the game state is completely observable to both agents. Policy
search methods are a reasonable alternative to value-based methods for
partially observable environments. In this paper, we provide a gradient-based
distributed policy-search method for cooperative games and compare the notion
of local optimum to that of Nash equilibrium. We demonstrate the effectiveness
of this method experimentally in a small, partially observable simulated soccer
domain.",2014-08-07,2014,2014-08,environment
"Predicting the behavior of interacting humans by fusing data from
  multiple sources","Multi-fidelity methods combine inexpensive low-fidelity simulations with
costly but highfidelity simulations to produce an accurate model of a system of
interest at minimal cost. They have proven useful in modeling physical systems
and have been applied to engineering problems such as wing-design optimization.
During human-in-the-loop experimentation, it has become increasingly common to
use online platforms, like Mechanical Turk, to run low-fidelity experiments to
gather human performance data in an efficient manner. One concern with these
experiments is that the results obtained from the online environment generalize
poorly to the actual domain of interest. To address this limitation, we extend
traditional multi-fidelity approaches to allow us to combine fewer data points
from high-fidelity human-in-the-loop experiments with plentiful but less
accurate data from low-fidelity experiments to produce accurate models of how
humans interact. We present both model-based and model-free methods, and
summarize the predictive performance of each method under dierent conditions.",2014-08-09,2014,2014-08,environment
Dynamic Sweep Filtering Algorithm for FlexC,"We investigate cumulative scheduling in uncertain environments, using
constraint programming. We detail in this paper the dynamic sweep filtering
algorithm of the FlexC global constraint.",2014-08-22,2014,2014-08,environment
A Complete framework for ambush avoidance in realistic environments,"Operating vehicles in adversarial environments between a recurring
origin-destination pair requires new planning techniques. A two players
zero-sum game is introduced. The goal of the first player is to minimize the
expected casualties undergone by a convoy. The goal of the second player is to
maximize this damage. The outcome of the game is obtained via a linear program
that solves the corresponding minmax optimization problem over this outcome.
Different environment models are defined in order to compute routing strategies
over unstructured environments. To compare these methods for increasingly
accurate representations of the environment, a grid-based model is chosen to
represent the environment and the existence of a sufficient network size is
highlighted. A global framework for the generation of realistic routing
strategies between any two points is described. This framework requires a good
assessment of the potential casualties at any location, therefore the most
important parameters are identified. Finally the framework is tested on real
world environments.",2014-08-26,2014,2014-08,environment
"Hybrid Systems Knowledge Representation Using Modelling Environment
  System Techniques Artificial Intelligence","Knowledge-based or Artificial Intelligence techniques are used increasingly
as alternatives to more classical techniques to model ENVIRONMENTAL SYSTEMS.
Use of Artificial Intelligence (AI) in environmental modelling has increased
with recognition of its potential. In this paper we examine the DIFFERENT
TECHNIQUES of Artificial intelligence with profound examples of human
perception, learning and reasoning to solve complex problems. However with the
increase of complexity better methods are required. Keeping in view of the
above some researchers introduced the idea of hybrid mechanism in which two or
more methods can be combined which seems to be a positive effort for creating a
more complex; advanced and intelligent system which has the capability to in-
cooperate human decisions thus driving the landscape changes.",2014-09-03,2014,2014-09,environment
Intelligent Indoor Mobile Robot Navigation Using Stereo Vision,"Majority of the existing robot navigation systems, which facilitate the use
of laser range finders, sonar sensors or artificial landmarks, has the ability
to locate itself in an unknown environment and then build a map of the
corresponding environment. Stereo vision, while still being a rapidly
developing technique in the field of autonomous mobile robots, are currently
less preferable due to its high implementation cost. This paper aims at
describing an experimental approach for the building of a stereo vision system
that helps the robots to avoid obstacles and navigate through indoor
environments and at the same time remaining very much cost effective. This
paper discusses the fusion techniques of stereo vision and ultrasound sensors
which helps in the successful navigation through different types of complex
environments. The data from the sensor enables the robot to create the two
dimensional topological map of unknown environments and stereo vision systems
models the three dimension model of the same environment.",2014-09-10,2014,2014-09,environment
Probabilistic Selection in AgentSpeak(L),"Agent programming is mostly a symbolic discipline and, as such, draws little
benefits from probabilistic areas as machine learning and graphical models.
However, the greatest objective of agent research is the achievement of
autonomy in dynamical and complex environments --- a goal that implies
embracing uncertainty and therefore the entailed representations, algorithms
and techniques. This paper proposes an innovative and conflict free two layer
approach to agent programming that uses already established methods and tools
from both symbolic and probabilistic artificial intelligence. Moreover, this
framework is illustrated by means of a widely used agent programming example,
GoldMiners.",2014-09-12,2014,2014-09,environment
A Comparison of learning algorithms on the Arcade Learning Environment,"Reinforcement learning agents have traditionally been evaluated on small toy
problems. With advances in computing power and the advent of the Arcade
Learning Environment, it is now possible to evaluate algorithms on diverse and
difficult problems within a consistent framework. We discuss some challenges
posed by the arcade learning environment which do not manifest in simpler
environments. We then provide a comparison of model-free, linear learning
algorithms on this challenging problem set.",2014-10-31,2014,2014-10,environment
"Quantifying Natural and Artificial Intelligence in Robots and Natural
  Systems with an Algorithmic Behavioural Test","One of the most important aims of the fields of robotics, artificial
intelligence and artificial life is the design and construction of systems and
machines as versatile and as reliable as living organisms at performing high
level human-like tasks. But how are we to evaluate artificial systems if we are
not certain how to measure these capacities in living systems, let alone how to
define life or intelligence? Here I survey a concrete metric towards measuring
abstract properties of natural and artificial systems, such as the ability to
react to the environment and to control one's own behaviour.",2014-12-20,2014,2014-12,environment
Different Types of Conflicting Knowledge in AmI Environments,"We characterize different types of conflicts that may occur in complex
distributed multi-agent scenarios, such as in Ambient Intelligence (AmI)
environments, and we argue that these conflicts should be resolved in a
suitable order and with the appropriate strategies for each individual conflict
type. We call for further research with the goal of turning conflict resolution
in AmI environments and similar multi-agent domains into a more coordinated and
agreed upon process.",2014-12-26,2014,2014-12,environment
Game-theoretic Approach for Non-Cooperative Planning,"When two or more self-interested agents put their plans to execution in the
same environment, conflicts may arise as a consequence, for instance, of a
common utilization of resources. In this case, an agent can postpone the
execution of a particular action, if this punctually solves the conflict, or it
can resort to execute a different plan if the agent's payoff significantly
diminishes due to the action deferral. In this paper, we present a
game-theoretic approach to non-cooperative planning that helps predict before
execution what plan schedules agents will adopt so that the set of strategies
of all agents constitute a Nash equilibrium. We perform some experiments and
discuss the solutions obtained with our game-theoretical approach, analyzing
how the conflicts between the plans determine the strategic behavior of the
agents.",2015-03-04,2015,2015-03,environment
"Quantifying Morphological Computation based on an Information
  Decomposition of the Sensorimotor Loop","The question how an agent is affected by its embodiment has attracted growing
attention in recent years. A new field of artificial intelligence has emerged,
which is based on the idea that intelligence cannot be understood without
taking into account embodiment. We believe that a formal approach to
quantifying the embodiment's effect on the agent's behaviour is beneficial to
the fields of artificial life and artificial intelligence. The contribution of
an agent's body and environment to its behaviour is also known as morphological
computation. Therefore, in this work, we propose a quantification of
morphological computation, which is based on an information decomposition of
the sensorimotor loop into shared, unique and synergistic information. In
numerical simulation based on a formal representation of the sensorimotor loop,
we show that the unique information of the body and environment is a good
measure for morphological computation. The results are compared to our
previously derived quantification of morphological computation.",2015-03-17,2015,2015-03,environment
Monte Carlo Localization in Hand-Drawn Maps,"Robot localization is a one of the most important problems in robotics. Most
of the existing approaches assume that the map of the environment is available
beforehand and focus on accurate metrical localization. In this paper, we
address the localization problem when the map of the environment is not present
beforehand, and the robot relies on a hand-drawn map from a non-expert user. We
addressed this problem by expressing the robot pose in the pixel coordinate and
simultaneously estimate a local deformation of the hand-drawn map. Experiments
show that we are able to localize the robot in the correct room with a
robustness up to 80%",2015-04-02,2015,2015-04,environment
Projective simulation with generalization,"The ability to generalize is an important feature of any intelligent agent.
Not only because it may allow the agent to cope with large amounts of data, but
also because in some environments, an agent with no generalization capabilities
cannot learn. In this work we outline several criteria for generalization, and
present a dynamic and autonomous machinery that enables projective simulation
agents to meaningfully generalize. Projective simulation, a novel, physical
approach to artificial intelligence, was recently shown to perform well in
standard reinforcement learning problems, with applications in advanced
robotics as well as quantum experiments. Both the basic projective simulation
model and the presented generalization machinery are based on very simple
principles. This allows us to provide a full analytical analysis of the agent's
performance and to illustrate the benefit the agent gains by generalizing.
Specifically, we show that already in basic (but extreme) environments,
learning without generalization may be impossible, and demonstrate how the
presented generalization machinery enables the projective simulation agent to
learn.",2015-04-09,2015,2015-04,environment
Multi-Context Systems for Reactive Reasoning in Dynamic Environments,"We show in this paper how managed multi-context systems (mMCSs) can be turned
into a reactive formalism suitable for continuous reasoning in dynamic
environments. We extend mMCSs with (abstract) sensors and define the notion of
a run of the extended systems. We then show how typical problems arising in
online reasoning can be addressed: handling potentially inconsistent sensor
input, modeling intelligent forms of forgetting, selective integration of
knowledge, and controlling the reasoning effort spent by contexts, like setting
contexts to an idle mode. We also investigate the complexity of some important
related decision problems and discuss different design choices which are given
to the knowledge engineer.",2015-05-20,2015,2015-05,environment
Qsmodels: ASP Planning in Interactive Gaming Environment,"Qsmodels is a novel application of Answer Set Programming to interactive
gaming environment. We describe a software architecture by which the behavior
of a bot acting inside the Quake 3 Arena can be controlled by a planner. The
planner is written as an Answer Set Program and is interpreted by the Smodels
solver.",2015-05-27,2015,2015-05,environment
"A genetic algorithm for autonomous navigation in partially observable
  domain","The problem of autonomous navigation is one of the basic problems for
robotics. Although, in general, it may be challenging when an autonomous
vehicle is placed into partially observable domain. In this paper we consider
simplistic environment model and introduce a navigation algorithm based on
Learning Classifier System.",2015-07-27,2015,2015-07,environment
Framework for learning agents in quantum environments,"In this paper we provide a broad framework for describing learning agents in
general quantum environments. We analyze the types of classically specified
environments which allow for quantum enhancements in learning, by contrasting
environments to quantum oracles. We show that whether or not quantum
improvements are at all possible depends on the internal structure of the
quantum environment. If the environments are constructed and the internal
structure is appropriately chosen, or if the agent has limited capacities to
influence the internal states of the environment, we show that improvements in
learning times are possible in a broad range of scenarios. Such scenarios we
call luck-favoring settings. The case of constructed environments is
particularly relevant for the class of model-based learning agents, where our
results imply a near-generic improvement.",2015-07-30,2015,2015-07,environment
A Roadmap towards Machine Intelligence,"The development of intelligent machines is one of the biggest unsolved
challenges in computer science. In this paper, we propose some fundamental
properties these machines should have, focusing in particular on communication
and learning. We discuss a simple environment that could be used to
incrementally teach a machine the basics of natural-language-based
communication, as a prerequisite to more complex interaction with human users.
We also present some conjectures on the sort of algorithms the machine should
support in order to profitably learn from the environment.",2015-11-25,2015,2015-11,environment
"Extracting Biomolecular Interactions Using Semantic Parsing of
  Biomedical Text","We advance the state of the art in biomolecular interaction extraction with
three contributions: (i) We show that deep, Abstract Meaning Representations
(AMR) significantly improve the accuracy of a biomolecular interaction
extraction system when compared to a baseline that relies solely on surface-
and syntax-based features; (ii) In contrast with previous approaches that infer
relations on a sentence-by-sentence basis, we expand our framework to enable
consistent predictions over sets of sentences (documents); (iii) We further
modify and expand a graph kernel learning framework to enable concurrent
exploitation of automatically induced AMR (semantic) and dependency structure
(syntactic) representations. Our experiments show that our approach yields
interaction extraction systems that are more robust in environments where there
is a significant mismatch between training and test conditions.",2015-12-04,2015,2015-12,environment
"An Empirical Comparison of Neural Architectures for Reinforcement
  Learning in Partially Observable Environments","This paper explores the performance of fitted neural Q iteration for
reinforcement learning in several partially observable environments, using
three recurrent neural network architectures: Long Short-Term Memory, Gated
Recurrent Unit and MUT1, a recurrent neural architecture evolved from a pool of
several thousands candidate architectures. A variant of fitted Q iteration,
based on Advantage values instead of Q values, is also explored. The results
show that GRU performs significantly better than LSTM and MUT1 for most of the
problems considered, requiring less training episodes and less CPU time before
learning a very good policy. Advantage learning also tends to produce better
results.",2015-12-17,2015,2015-12,environment
Deep Exploration via Bootstrapped DQN,"Efficient exploration in complex environments remains a major challenge for
reinforcement learning. We propose bootstrapped DQN, a simple algorithm that
explores in a computationally and statistically efficient manner through use of
randomized value functions. Unlike dithering strategies such as epsilon-greedy
exploration, bootstrapped DQN carries out temporally-extended (or deep)
exploration; this can lead to exponentially faster learning. We demonstrate
these benefits in complex stochastic MDPs and in the large-scale Arcade
Learning Environment. Bootstrapped DQN substantially improves learning times
and performance across most Atari games.",2016-02-15,2016,2016-02,environment
Distributed Constraint Optimization Problems and Applications: A Survey,"The field of Multi-Agent System (MAS) is an active area of research within
Artificial Intelligence, with an increasingly important impact in industrial
and other real-world applications. Within a MAS, autonomous agents interact to
pursue personal interests and/or to achieve common objectives. Distributed
Constraint Optimization Problems (DCOPs) have emerged as one of the prominent
agent architectures to govern the agents' autonomous behavior, where both
algorithms and communication models are driven by the structure of the specific
problem. During the last decade, several extensions to the DCOP model have
enabled them to support MAS in complex, real-time, and uncertain environments.
This survey aims at providing an overview of the DCOP model, giving a
classification of its multiple extensions and addressing both resolution
methods and applications that find a natural mapping within each class of
DCOPs. The proposed classification suggests several future perspectives for
DCOP extensions, and identifies challenges in the design of efficient
resolution algorithms, possibly through the adaptation of strategies from
different areas.",2016-02-20,2016,2016-02,environment
Thompson Sampling is Asymptotically Optimal in General Environments,"We discuss a variant of Thompson sampling for nonparametric reinforcement
learning in a countable classes of general stochastic environments. These
environments can be non-Markov, non-ergodic, and partially observable. We show
that Thompson sampling learns the environment class in the sense that (1)
asymptotically its value converges to the optimal value in mean and (2) given a
recoverability assumption regret is sublinear.",2016-02-25,2016,2016-02,environment
Meta-learning within Projective Simulation,"Learning models of artificial intelligence can nowadays perform very well on
a large variety of tasks. However, in practice different task environments are
best handled by different learning models, rather than a single, universal,
approach. Most non-trivial models thus require the adjustment of several to
many learning parameters, which is often done on a case-by-case basis by an
external party. Meta-learning refers to the ability of an agent to autonomously
and dynamically adjust its own learning parameters, or meta-parameters. In this
work we show how projective simulation, a recently developed model of
artificial intelligence, can naturally be extended to account for meta-learning
in reinforcement learning settings. The projective simulation approach is based
on a random walk process over a network of clips. The suggested meta-learning
scheme builds upon the same design and employs clip networks to monitor the
agent's performance and to adjust its meta-parameters ""on the fly"". We
distinguish between ""reflexive adaptation"" and ""adaptation through learning"",
and show the utility of both approaches. In addition, a trade-off between
flexibility and learning-time is addressed. The extended model is examined on
three different kinds of reinforcement learning tasks, in which the agent has
different optimal values of the meta-parameters, and is shown to perform well,
reaching near-optimal to optimal success rates in all of them, without ever
needing to manually adjust any meta-parameter.",2016-02-25,2016,2016-02,environment
Category Theoretic Analysis of Photon-based Decision Making,"Decision making is a vital function in this age of machine learning and
artificial intelligence, yet its physical realization and theoretical
fundamentals are still not completely understood. In our former study, we
demonstrated that single-photons can be used to make decisions in uncertain,
dynamically changing environments. The two-armed bandit problem was
successfully solved using the dual probabilistic and particle attributes of
single photons. In this study, we present a category theoretic modeling and
analysis of single-photon-based decision making, including a quantitative
analysis that is in agreement with the experimental results. A category
theoretic model reveals the complex interdependencies of subject matter
entities in a simplified manner, even in dynamically changing environments. In
particular, the octahedral and braid structures in triangulated categories
provide a better understanding and quantitative metrics of the underlying
mechanisms of a single-photon decision maker. This study provides both insight
and a foundation for analyzing more complex and uncertain problems, to further
machine learning and artificial intelligence.",2016-02-26,2016,2016-02,environment
The AGI Containment Problem,"There is considerable uncertainty about what properties, capabilities and
motivations future AGIs will have. In some plausible scenarios, AGIs may pose
security risks arising from accidents and defects. In order to mitigate these
risks, prudent early AGI research teams will perform significant testing on
their creations before use. Unfortunately, if an AGI has human-level or greater
intelligence, testing itself may not be safe; some natural AGI goal systems
create emergent incentives for AGIs to tamper with their test environments,
make copies of themselves on the internet, or convince developers and operators
to do dangerous things. In this paper, we survey the AGI containment problem -
the question of how to build a container in which tests can be conducted safely
and reliably, even on AGIs with unknown motivations and capabilities that could
be dangerous. We identify requirements for AGI containers, available
mechanisms, and weaknesses that need to be addressed.",2016-04-02,2016,2016-04,environment
"A system of serial computation for classified rules prediction in
  non-regular ontology trees","Objects or structures that are regular take uniform dimensions. Based on the
concepts of regular models, our previous research work has developed a system
of a regular ontology that models learning structures in a multiagent system
for uniform pre-assessments in a learning environment. This regular ontology
has led to the modelling of a classified rules learning algorithm that predicts
the actual number of rules needed for inductive learning processes and decision
making in a multiagent system. But not all processes or models are regular.
Thus this paper presents a system of polynomial equation that can estimate and
predict the required number of rules of a non-regular ontology model given some
defined parameters.",2016-04-08,2016,2016-04,environment
"Why Artificial Intelligence Needs a Task Theory --- And What It Might
  Look Like","The concept of ""task"" is at the core of artificial intelligence (AI): Tasks
are used for training and evaluating AI systems, which are built in order to
perform and automatize tasks we deem useful. In other fields of engineering
theoretical foundations allow thorough evaluation of designs by methodical
manipulation of well understood parameters with a known role and importance;
this allows an aeronautics engineer, for instance, to systematically assess the
effects of wind speed on an airplane's performance and stability. No framework
exists in AI that allows this kind of methodical manipulation: Performance
results on the few tasks in current use (cf. board games, question-answering)
cannot be easily compared, however similar or different. The issue is even more
acute with respect to artificial *general* intelligence systems, which must
handle unanticipated tasks whose specifics cannot be known beforehand. A *task
theory* would enable addressing tasks at the *class* level, bypassing their
specifics, providing the appropriate formalization and classification of tasks,
environments, and their parameters, resulting in more rigorous ways of
measuring, comparing, and evaluating intelligent behavior. Even modest
improvements in this direction would surpass the current ad-hoc nature of
machine learning and AI evaluation. Here we discuss the main elements of the
argument for a task theory and present an outline of what it might look like
for physical tasks.",2016-04-15,2016,2016-04,environment
Semantic Reasoning for Context-aware Internet of Things Applications,"Advances in ICT are bringing into reality the vision of a large number of
uniquely identifiable, interconnected objects and things that gather
information from diverse physical environments and deliver the information to a
variety of innovative applications and services. These sensing objects and
things form the Internet of Things (IoT) that can improve energy and cost
efficiency and automation in many different industry fields such as
transportation and logistics, health care and manufacturing, and facilitate our
everyday lives as well. IoT applications rely on real-time context data and
allow sending information for driving the behaviors of users in intelligent
environments.",2016-04-28,2016,2016-04,environment
"Obstacle evasion using fuzzy logic in a sliding blades problem
  environment","This paper discusses obstacle avoidance using fuzzy logic and shortest path
algorithm. This paper also introduces the sliding blades problem and
illustrates how a drone can navigate itself through the swinging blade
obstacles while tracing a semi-optimal path and also maintaining constant
velocity",2016-05-03,2016,2016-05,environment
Learning Purposeful Behaviour in the Absence of Rewards,"Artificial intelligence is commonly defined as the ability to achieve goals
in the world. In the reinforcement learning framework, goals are encoded as
reward functions that guide agent behaviour, and the sum of observed rewards
provide a notion of progress. However, some domains have no such reward signal,
or have a reward signal so sparse as to appear absent. Without reward feedback,
agent behaviour is typically random, often dithering aimlessly and lacking
intentionality. In this paper we present an algorithm capable of learning
purposeful behaviour in the absence of rewards. The algorithm proceeds by
constructing temporally extended actions (options), through the identification
of purposes that are ""just out of reach"" of the agent's current behaviour.
These purposes establish intrinsic goals for the agent to learn, ultimately
resulting in a suite of behaviours that encourage the agent to visit different
parts of the state space. Moreover, the approach is particularly suited for
settings where rewards are very sparse, and such behaviours can help in the
exploration of the environment until reward is observed.",2016-05-25,2016,2016-05,environment
A PAC RL Algorithm for Episodic POMDPs,"Many interesting real world domains involve reinforcement learning (RL) in
partially observable environments. Efficient learning in such domains is
important, but existing sample complexity bounds for partially observable RL
are at least exponential in the episode length. We give, to our knowledge, the
first partially observable RL algorithm with a polynomial bound on the number
of episodes on which the algorithm may not achieve near-optimal performance.
Our algorithm is suitable for an important class of episodic POMDPs. Our
approach builds on recent advances in method of moments for latent variable
model estimation.",2016-05-25,2016,2016-05,environment
Death and Suicide in Universal Artificial Intelligence,"Reinforcement learning (RL) is a general paradigm for studying intelligent
behaviour, with applications ranging from artificial intelligence to psychology
and economics. AIXI is a universal solution to the RL problem; it can learn any
computable environment. A technical subtlety of AIXI is that it is defined
using a mixture over semimeasures that need not sum to 1, rather than over
proper probability measures. In this work we argue that the shortfall of a
semimeasure can naturally be interpreted as the agent's estimate of the
probability of its death. We formally define death for generally intelligent
agents like AIXI, and prove a number of related theorems about their behaviour.
Notable discoveries include that agent behaviour can change radically under
positive linear transformations of the reward signal (from suicidal to
dogmatically self-preserving), and that the agent's posterior belief that it
will survive increases over time.",2016-06-02,2016,2016-06,environment
"Situated Structure Learning of a Bayesian Logic Network for Commonsense
  Reasoning","This paper details the implementation of an algorithm for automatically
generating a high-level knowledge network to perform commonsense reasoning,
specifically with the application of robotic task repair. The network is
represented using a Bayesian Logic Network (BLN) (Jain, Waldherr, and Beetz
2009), which combines a set of directed relations between abstract concepts,
including IsA, AtLocation, HasProperty, and UsedFor, with a corresponding
probability distribution that models the uncertainty inherent in these
relations. Inference over this network enables reasoning over the abstract
concepts in order to perform appropriate object substitution or to locate
missing objects in the robot's environment. The structure of the network is
generated by combining information from two existing knowledge sources:
ConceptNet (Speer and Havasi 2012), and WordNet (Miller 1995). This is done in
a ""situated"" manner by only including information relevant a given context.
Results show that the generated network is able to accurately predict object
categories, locations, properties, and affordances in three different household
scenarios.",2016-07-01,2016,2016-07,environment
"Robust Natural Language Processing - Combining Reasoning, Cognitive
  Semantics and Construction Grammar for Spatial Language","We present a system for generating and understanding of dynamic and static
spatial relations in robotic interaction setups. Robots describe an environment
of moving blocks using English phrases that include spatial relations such as
""across"" and ""in front of"". We evaluate the system in robot-robot interactions
and show that the system can robustly deal with visual perception errors,
language omissions and ungrammatical utterances.",2016-07-20,2016,2016-07,environment
"Context Discovery for Model Learning in Partially Observable
  Environments","The ability to learn a model is essential for the success of autonomous
agents. Unfortunately, learning a model is difficult in partially observable
environments, where latent environmental factors influence what the agent
observes. In the absence of a supervisory training signal, autonomous agents
therefore require a mechanism to autonomously discover these environmental
factors, or sensorimotor contexts.
  This paper presents a method to discover sensorimotor contexts in partially
observable environments, by constructing a hierarchical transition model. The
method is evaluated in a simulation experiment, in which a robot learns that
different rooms are characterized by different objects that are found in them.",2016-08-02,2016,2016-08,environment
"Essentials of an Integrated Crowd Management Support System Based on
  Collective Artificial Intelligence","The simulation of the dynamical behavior of pedestrians and crowds in spatial
structures is a consolidated research and application context that still
presents challenges for researchers in different fields and disciplines.
Despite currently available commercial systems for this kind of simulation are
growingly employed by designers and planners for the evaluation of alternative
solutions, this class of systems is generally not integrated with existing
monitoring and control infrastructures, usually employed by crowd managers and
field operators for security reasons. This paper introduces the essentials and
the related computational frame- work of an Integrated Crowd Management Support
System based on a Collective Artificial Intelligence approach encompassing (i)
interfaces from and to monitored and controlled environments (respectively,
sen- sors and actuators), (ii) a set of software tools supporting the analysis
of pedestrians and crowd phenomena taking place in the environment to feed a
(iii) faster than real-time simulation of the plausible evolution of the
current situation in order to support forms of inference provid- ing decision
support to crowd managers, potentially directly controlling elements of the
environment (e.g. blocking turnstiles, escalators), com- municating orders to
operators on the field or trying to influence the pedestrians by means of
dynamic signage or audible messages.",2016-08-17,2016,2016-08,environment
Exploration Potential,"We introduce exploration potential, a quantity that measures how much a
reinforcement learning agent has explored its environment class. In contrast to
information gain, exploration potential takes the problem's reward structure
into account. This leads to an exploration criterion that is both necessary and
sufficient for asymptotic optimality (learning to act optimally across the
entire environment class). Our experiments in multi-armed bandits use
exploration potential to illustrate how different algorithms make the tradeoff
between exploration and exploitation.",2016-09-16,2016,2016-09,environment
The Option-Critic Architecture,"Temporal abstraction is key to scaling up learning and planning in
reinforcement learning. While planning with temporally extended actions is well
understood, creating such abstractions autonomously from data has remained
challenging. We tackle this problem in the framework of options [Sutton, Precup
& Singh, 1999; Precup, 2000]. We derive policy gradient theorems for options
and propose a new option-critic architecture capable of learning both the
internal policies and the termination conditions of options, in tandem with the
policy over options, and without the need to provide any additional rewards or
subgoals. Experimental results in both discrete and continuous environments
showcase the flexibility and efficiency of the framework.",2016-09-16,2016,2016-09,environment
Quantum-enhanced machine learning,"The emerging field of quantum machine learning has the potential to
substantially aid in the problems and scope of artificial intelligence. This is
only enhanced by recent successes in the field of classical machine learning.
In this work we propose an approach for the systematic treatment of machine
learning, from the perspective of quantum information. Our approach is general
and covers all three main branches of machine learning: supervised,
unsupervised and reinforcement learning. While quantum improvements in
supervised and unsupervised learning have been reported, reinforcement learning
has received much less attention. Within our approach, we tackle the problem of
quantum enhancements in reinforcement learning as well, and propose a
systematic scheme for providing improvements. As an example, we show that
quadratic improvements in learning efficiency, and exponential improvements in
performance over limited time periods, can be obtained for a broad class of
learning problems.",2016-10-26,2016,2016-10,environment
Playing SNES in the Retro Learning Environment,"Mastering a video game requires skill, tactics and strategy. While these
attributes may be acquired naturally by human players, teaching them to a
computer program is a far more challenging task. In recent years, extensive
research was carried out in the field of reinforcement learning and numerous
algorithms were introduced, aiming to learn how to perform human tasks such as
playing video games. As a result, the Arcade Learning Environment (ALE)
(Bellemare et al., 2013) has become a commonly used benchmark environment
allowing algorithms to train on various Atari 2600 games. In many games the
state-of-the-art algorithms outperform humans. In this paper we introduce a new
learning environment, the Retro Learning Environment --- RLE, that can run
games on the Super Nintendo Entertainment System (SNES), Sega Genesis and
several other gaming consoles. The environment is expandable, allowing for more
video games and consoles to be easily added to the environment, while
maintaining the same interface as ALE. Moreover, RLE is compatible with Python
and Torch. SNES games pose a significant challenge to current algorithms due to
their higher level of complexity and versatility.",2016-11-07,2016,2016-11,environment
Self-Correcting Models for Model-Based Reinforcement Learning,"When an agent cannot represent a perfectly accurate model of its
environment's dynamics, model-based reinforcement learning (MBRL) can fail
catastrophically. Planning involves composing the predictions of the model;
when flawed predictions are composed, even minor errors can compound and render
the model useless for planning. Hallucinated Replay (Talvitie 2014) trains the
model to ""correct"" itself when it produces errors, substantially improving MBRL
with flawed models. This paper theoretically analyzes this approach,
illuminates settings in which it is likely to be effective or ineffective, and
presents a novel error bound, showing that a model's ability to self-correct is
more tightly related to MBRL performance than one-step prediction error. These
results inspire an MBRL algorithm for deterministic MDPs with performance
guarantees that are robust to model class limitations.",2016-12-19,2016,2016-12,environment
"The formal-logical characterisation of lies, deception, and associated
  notions","Defining various dishonest notions in a formal way is a key step to enable
intelligent agents to act in untrustworthy environments. This review evaluates
the literature for this topic by looking at formal definitions based on modal
logic as well as other formal approaches. Criteria from philosophical
groundwork is used to assess the definitions for correctness and completeness.
The key contribution of this review is to show that only a few definitions
fully comply with this gold standard and to point out the missing steps towards
a successful application of these definitions in an actual agent environment.",2016-12-28,2016,2016-12,environment
Morphognosis: the shape of knowledge in space and time,"Artificial intelligence research to a great degree focuses on the brain and
behaviors that the brain generates. But the brain, an extremely complex
structure resulting from millions of years of evolution, can be viewed as a
solution to problems posed by an environment existing in space and time. The
environment generates signals that produce sensory events within an organism.
Building an internal spatial and temporal model of the environment allows an
organism to navigate and manipulate the environment. Higher intelligence might
be the ability to process information coming from a larger extent of
space-time. In keeping with nature's penchant for extending rather than
replacing, the purpose of the mammalian neocortex might then be to record
events from distant reaches of space and time and render them, as though yet
near and present, to the older, deeper brain whose instinctual roles have
changed little over eons. Here this notion is embodied in a model called
morphognosis (morpho = shape and gnosis = knowledge). Its basic structure is a
pyramid of event recordings called a morphognostic. At the apex of the pyramid
are the most recent and nearby events. Receding from the apex are less recent
and possibly more distant events. A morphognostic can thus be viewed as a
structure of progressively larger chunks of space-time knowledge. A set of
morphognostics forms long-term memories that are learned by exposure to the
environment. A cellular automaton is used as the platform to investigate the
morphognosis model, using a simulated organism that learns to forage in its
world for food, build a nest, and play the game of Pong.",2017-01-05,2017,2017-01,environment
"Efficient Transfer Learning Schemes for Personalized Language Modeling
  using Recurrent Neural Network","In this paper, we propose an efficient transfer leaning methods for training
a personalized language model using a recurrent neural network with long
short-term memory architecture. With our proposed fast transfer learning
schemes, a general language model is updated to a personalized language model
with a small amount of user data and a limited computing resource. These
methods are especially useful for a mobile device environment while the data is
prevented from transferring out of the device for privacy purposes. Through
experiments on dialogue data in a drama, it is verified that our transfer
learning methods have successfully generated the personalized language model,
whose output is more similar to the personal language style in both qualitative
and quantitative aspects.",2017-01-13,2017,2017-01,environment
Minimally Naturalistic Artificial Intelligence,"The rapid advancement of machine learning techniques has re-energized
research into general artificial intelligence. While the idea of
domain-agnostic meta-learning is appealing, this emerging field must come to
terms with its relationship to human cognition and the statistics and structure
of the tasks humans perform. The position of this article is that only by
aligning our agents' abilities and environments with those of humans do we
stand a chance at developing general artificial intelligence (GAI). A broad
reading of the famous 'No Free Lunch' theorem is that there is no universally
optimal inductive bias or, equivalently, bias-free learning is impossible. This
follows from the fact that there are an infinite number of ways to extrapolate
data, any of which might be the one used by the data generating environment; an
inductive bias prefers some of these extrapolations to others, which lowers
performance in environments using these adversarial extrapolations. We may
posit that the optimal GAI is the one that maximally exploits the statistics of
its environment to create its inductive bias; accepting the fact that this
agent is guaranteed to be extremely sub-optimal for some alternative
environments. This trade-off appears benign when thinking about the environment
as being the physical universe, as performance on any fictive universe is
obviously irrelevant. But, we should expect a sharper inductive bias if we
further constrain our environment. Indeed, we implicitly do so by defining GAI
in terms of accomplishing that humans consider useful. One common version of
this is need the for 'common-sense reasoning', which implicitly appeals to the
statistics of physical universe as perceived by humans.",2017-01-14,2017,2017-01,environment
"Beating the World's Best at Super Smash Bros. with Deep Reinforcement
  Learning","There has been a recent explosion in the capabilities of game-playing
artificial intelligence. Many classes of RL tasks, from Atari games to motor
control to board games, are now solvable by fairly generic algorithms, based on
deep learning, that learn to play from experience with minimal knowledge of the
specific domain of interest. In this work, we will investigate the performance
of these methods on Super Smash Bros. Melee (SSBM), a popular console fighting
game. The SSBM environment has complex dynamics and partial observability,
making it challenging for human and machine alike. The multi-player aspect
poses an additional challenge, as the vast majority of recent advances in RL
have focused on single-agent environments. Nonetheless, we will show that it is
possible to train agents that are competitive against and even surpass human
professionals, a new result for the multi-player video game setting.",2017-02-21,2017,2017-02,environment
Don't Fear the Reaper: Refuting Bostrom's Superintelligence Argument,"In recent years prominent intellectuals have raised ethical concerns about
the consequences of artificial intelligence. One concern is that an autonomous
agent might modify itself to become ""superintelligent"" and, in supremely
effective pursuit of poorly specified goals, destroy all of humanity. This
paper considers and rejects the possibility of this outcome. We argue that this
scenario depends on an agent's ability to rapidly improve its ability to
predict its environment through self-modification. Using a Bayesian model of a
reasoning agent, we show that there are important limitations to how an agent
may improve its predictive ability through self-modification alone. We conclude
that concern about this artificial intelligence outcome is misplaced and better
directed at policy questions around data access and storage.",2017-02-27,2017,2017-02,environment
What can you do with a rock? Affordance extraction via word embeddings,"Autonomous agents must often detect affordances: the set of behaviors enabled
by a situation. Affordance detection is particularly helpful in domains with
large action spaces, allowing the agent to prune its search space by avoiding
futile behaviors. This paper presents a method for affordance extraction via
word embeddings trained on a Wikipedia corpus. The resulting word vectors are
treated as a common knowledge database which can be queried using linear
algebra. We apply this method to a reinforcement learning agent in a text-only
environment and show that affordance-based action selection improves
performance most of the time. Our method increases the computational complexity
of each learning step but significantly reduces the total number of steps
needed. In addition, the agent's action selections begin to resemble those a
human would choose.",2017-03-09,2017,2017-03,environment
"Embodied Artificial Intelligence through Distributed Adaptive Control:
  An Integrated Framework","In this paper, we argue that the future of Artificial Intelligence research
resides in two keywords: integration and embodiment. We support this claim by
analyzing the recent advances of the field. Regarding integration, we note that
the most impactful recent contributions have been made possible through the
integration of recent Machine Learning methods (based in particular on Deep
Learning and Recurrent Neural Networks) with more traditional ones (e.g.
Monte-Carlo tree search, goal babbling exploration or addressable memory
systems). Regarding embodiment, we note that the traditional benchmark tasks
(e.g. visual classification or board games) are becoming obsolete as
state-of-the-art learning algorithms approach or even surpass human performance
in most of them, having recently encouraged the development of first-person 3D
game platforms embedding realistic physics. Building upon this analysis, we
first propose an embodied cognitive architecture integrating heterogenous
sub-fields of Artificial Intelligence into a unified framework. We demonstrate
the utility of our approach by showing how major contributions of the field can
be expressed within the proposed framework. We then claim that benchmarking
environments need to reproduce ecologically-valid conditions for bootstrapping
the acquisition of increasingly complex cognitive skills through the concept of
a cognitive arms race between embodied agents.",2017-04-05,2017,2017-04,environment
Environment-Independent Task Specifications via GLTL,"We propose a new task-specification language for Markov decision processes
that is designed to be an improvement over reward functions by being
environment independent. The language is a variant of Linear Temporal Logic
(LTL) that is extended to probabilistic specifications in a way that permits
approximations to be learned in finite time. We provide several small
environments that demonstrate the advantages of our geometric LTL (GLTL)
language and illustrate how it can be used to specify standard
reinforcement-learning tasks straightforwardly.",2017-04-14,2017,2017-04,environment
Beating Atari with Natural Language Guided Reinforcement Learning,"We introduce the first deep reinforcement learning agent that learns to beat
Atari games with the aid of natural language instructions. The agent uses a
multimodal embedding between environment observations and natural language to
self-monitor progress through a list of English instructions, granting itself
reward for completing instructions in addition to increasing the game score.
Our agent significantly outperforms Deep Q-Networks (DQNs), Asynchronous
Advantage Actor-Critic (A3C) agents, and the best agents posted to OpenAI Gym
on what is often considered the hardest Atari 2600 environment: Montezuma's
Revenge.",2017-04-18,2017,2017-04,environment
Ethical Artificial Intelligence - An Open Question,"Artificial Intelligence (AI) is an effective science which employs strong
enough approaches, methods, and techniques to solve unsolvable real world based
problems. Because of its unstoppable rise towards the future, there are also
some discussions about its ethics and safety. Shaping an AI friendly
environment for people and a people friendly environment for AI can be a
possible answer for finding a shared context of values for both humans and
robots. In this context, objective of this paper is to address the ethical
issues of AI and explore the moral dilemmas that arise from ethical algorithms,
from pre set or acquired values. In addition, the paper will also focus on the
subject of AI safety. As general, the paper will briefly analyze the concerns
and potential solutions to solving the ethical issues presented and increase
readers awareness on AI safety as another related research interest.",2017-05-16,2017,2017-05,environment
Experience enrichment based task independent reward model,"For most reinforcement learning approaches, the learning is performed by
maximizing an accumulative reward that is expectedly and manually defined for
specific tasks. However, in real world, rewards are emergent phenomena from the
complex interactions between agents and environments. In this paper, we propose
an implicit generic reward model for reinforcement learning. Unlike those
rewards that are manually defined for specific tasks, such implicit reward is
task independent. It only comes from the deviation from the agents' previous
experiences.",2017-05-21,2017,2017-05,environment
Universal Reinforcement Learning Algorithms: Survey and Experiments,"Many state-of-the-art reinforcement learning (RL) algorithms typically assume
that the environment is an ergodic Markov Decision Process (MDP). In contrast,
the field of universal reinforcement learning (URL) is concerned with
algorithms that make as few assumptions as possible about the environment. The
universal Bayesian agent AIXI and a family of related URL algorithms have been
developed in this setting. While numerous theoretical optimality results have
been proven for these agents, there has been no empirical investigation of
their behavior to date. We present a short and accessible survey of these URL
algorithms under a unified notation and framework, along with results of some
experiments that qualitatively illustrate some properties of the resulting
policies, and their relative performance on partially-observable gridworld
environments. We also present an open-source reference implementation of the
algorithms which we hope will facilitate further understanding of, and
experimentation with, these ideas.",2017-05-30,2017,2017-05,environment
"Dex: Incremental Learning for Complex Environments in Deep Reinforcement
  Learning","This paper introduces Dex, a reinforcement learning environment toolkit
specialized for training and evaluation of continual learning methods as well
as general reinforcement learning problems. We also present the novel continual
learning method of incremental learning, where a challenging environment is
solved using optimal weight initialization learned from first solving a similar
easier environment. We show that incremental learning can produce vastly
superior results than standard methods by providing a strong baseline method
across ten Dex environments. We finally develop a saliency method for
qualitative analysis of reinforcement learning, which shows the impact
incremental learning has on network attention.",2017-06-19,2017,2017-06,environment
An Online Development Environment for Answer Set Programming,"Recent progress in logic programming (e.g., the development of the Answer Set
Programming paradigm) has made it possible to teach it to general undergraduate
and even high school students. Given the limited exposure of these students to
computer science, the complexity of downloading, installing and using tools for
writing logic programs could be a major barrier for logic programming to reach
a much wider audience. We developed an online answer set programming
environment with a self contained file system and a simple interface, allowing
users to write logic programs and perform several tasks over the programs.",2017-06-20,2017,2017-06,environment
"A Useful Motif for Flexible Task Learning in an Embodied Two-Dimensional
  Visual Environment","Animals (especially humans) have an amazing ability to learn new tasks
quickly, and switch between them flexibly. How brains support this ability is
largely unknown, both neuroscientifically and algorithmically. One reasonable
supposition is that modules drawing on an underlying general-purpose sensory
representation are dynamically allocated on a per-task basis. Recent results
from neuroscience and artificial intelligence suggest the role of the general
purpose visual representation may be played by a deep convolutional neural
network, and give some clues how task modules based on such a representation
might be discovered and constructed. In this work, we investigate module
architectures in an embodied two-dimensional touchscreen environment, in which
an agent's learning must occur via interactions with an environment that emits
images and rewards, and accepts touches as input. This environment is designed
to capture the physical structure of the task environments that are commonly
deployed in visual neuroscience and psychophysics. We show that in this
context, very simple changes in the nonlinear activations used by such a module
can significantly influence how fast it is at learning visual tasks and how
suitable it is for switching to new tasks.",2017-06-22,2017,2017-06,environment
OPEB: Open Physical Environment Benchmark for Artificial Intelligence,"Artificial Intelligence methods to solve continuous- control tasks have made
significant progress in recent years. However, these algorithms have important
limitations and still need significant improvement to be used in industry and
real- world applications. This means that this area is still in an active
research phase. To involve a large number of research groups, standard
benchmarks are needed to evaluate and compare proposed algorithms. In this
paper, we propose a physical environment benchmark framework to facilitate
collaborative research in this area by enabling different research groups to
integrate their designed benchmarks in a unified cloud-based repository and
also share their actual implemented benchmarks via the cloud. We demonstrate
the proposed framework using an actual implementation of the classical
mountain-car example and present the results obtained using a Reinforcement
Learning algorithm.",2017-07-04,2017,2017-07,environment
"Maintaining cooperation in complex social dilemmas using deep
  reinforcement learning","Social dilemmas are situations where individuals face a temptation to
increase their payoffs at a cost to total welfare. Building artificially
intelligent agents that achieve good outcomes in these situations is important
because many real world interactions include a tension between selfish
interests and the welfare of others. We show how to modify modern reinforcement
learning methods to construct agents that act in ways that are simple to
understand, nice (begin by cooperating), provokable (try to avoid being
exploited), and forgiving (try to return to mutual cooperation). We show both
theoretically and experimentally that such agents can maintain cooperation in
Markov social dilemmas. Our construction does not require training methods
beyond a modification of self-play, thus if an environment is such that good
strategies can be constructed in the zero-sum case (eg. Atari) then we can
construct agents that solve social dilemmas in this environment.",2017-07-04,2017,2017-07,environment
"Learning to Design Games: Strategic Environments in Reinforcement
  Learning","In typical reinforcement learning (RL), the environment is assumed given and
the goal of the learning is to identify an optimal policy for the agent taking
actions through its interactions with the environment. In this paper, we extend
this setting by considering the environment is not given, but controllable and
learnable through its interaction with the agent at the same time. This
extension is motivated by environment design scenarios in the real-world,
including game design, shopping space design and traffic signal design.
Theoretically, we find a dual Markov decision process (MDP) w.r.t. the
environment to that w.r.t. the agent, and derive a policy gradient solution to
optimizing the parametrized environment. Furthermore, discontinuous
environments are addressed by a proposed general generative framework. Our
experiments on a Maze game design task show the effectiveness of the proposed
algorithms in generating diverse and challenging Mazes against various agent
settings.",2017-07-05,2017,2017-07,environment
Autoencoder-augmented Neuroevolution for Visual Doom Playing,"Neuroevolution has proven effective at many reinforcement learning tasks, but
does not seem to scale well to high-dimensional controller representations,
which are needed for tasks where the input is raw pixel data. We propose a
novel method where we train an autoencoder to create a comparatively
low-dimensional representation of the environment observation, and then use
CMA-ES to train neural network controllers acting on this input data. As the
behavior of the agent changes the nature of the input data, the autoencoder
training progresses throughout evolution. We test this method in the VizDoom
environment built on the classic FPS Doom, where it performs well on a
health-pack gathering task.",2017-07-12,2017,2017-07,environment
"Applying MAPP Algorithm for Cooperative Path Finding in Urban
  Environments","The paper considers the problem of planning a set of non-conflict
trajectories for the coalition of intelligent agents (mobile robots). Two
divergent approaches, e.g. centralized and decentralized, are surveyed and
analyzed. Decentralized planner - MAPP is described and applied to the task of
finding trajectories for dozens UAVs performing nap-of-the-earth flight in
urban environments. Results of the experimental studies provide an opportunity
to claim that MAPP is a highly efficient planner for solving considered types
of tasks.",2017-07-20,2017,2017-07,environment
"Investigating Reinforcement Learning Agents for Continuous State Space
  Environments","Given an environment with continuous state spaces and discrete actions, we
investigate using a Double Deep Q-learning Reinforcement Agent to find optimal
policies using the LunarLander-v2 OpenAI gym environment.",2017-08-08,2017,2017-08,environment
What Automated Planning can do for Business Process Management,"Business Process Management (BPM) is a central element of today
organizations. Despite over the years its main focus has been the support of
processes in highly controlled domains, nowadays many domains of interest to
the BPM community are characterized by ever-changing requirements,
unpredictable environments and increasing amounts of data that influence the
execution of process instances. Under such dynamic conditions, BPM systems must
increase their level of automation to provide the reactivity and flexibility
necessary for process management. On the other hand, the Artificial
Intelligence (AI) community has concentrated its efforts on investigating
dynamic domains that involve active control of computational entities and
physical devices (e.g., robots, software agents, etc.). In this context,
Automated Planning, which is one of the oldest areas in AI, is conceived as a
model-based approach to synthesize autonomous behaviours in automated way from
a model. In this paper, we discuss how automated planning techniques can be
leveraged to enable new levels of automation and support for business
processing, and we show some concrete examples of their successful application
to the different stages of the BPM life cycle.",2017-09-29,2017,2017-09,environment
"Cooperative Automated Vehicles: a Review of Opportunities and Challenges
  in Socially Intelligent Vehicles Beyond Networking","The connected automated vehicle has been often touted as a technology that
will become pervasive in society in the near future. One can view an automated
vehicle as having Artificial Intelligence (AI) capabilities, being able to
self-drive, sense its surroundings, recognise objects in its vicinity, and
perform reasoning and decision-making.
  Rather than being stand alone, we examine the need for automated vehicles to
cooperate and interact within their socio-cyber-physical environments,
including the problems cooperation will solve, but also the issues and
challenges. We review current work in cooperation for automated vehicles, based
on selected examples from the literature. We conclude noting the need for the
ability to behave cooperatively as a form of social-AI capability for automated
vehicles, beyond sensing the immediate environment and beyond the underlying
networking technology.",2017-10-02,2017,2017-10,environment
"Feasibility Study: Moving Non-Homogeneous Teams in Congested Video Game
  Environments","Multi-agent path finding (MAPF) is a well-studied problem in artificial
intelligence, where one needs to find collision-free paths for agents with
given start and goal locations. In video games, agents of different types often
form teams. In this paper, we demonstrate the usefulness of MAPF algorithms
from artificial intelligence for moving such non-homogeneous teams in congested
video game environments.",2017-10-04,2017,2017-10,environment
Emergent Complexity via Multi-Agent Competition,"Reinforcement learning algorithms can train agents that solve problems in
complex, interesting environments. Normally, the complexity of the trained
agent is closely related to the complexity of the environment. This suggests
that a highly capable agent requires a complex environment for training. In
this paper, we point out that a competitive multi-agent environment trained
with self-play can produce behaviors that are far more complex than the
environment itself. We also point out that such environments come with a
natural curriculum, because for any skill level, an environment full of agents
of this level will have the right level of difficulty. This work introduces
several competitive multi-agent environments where agents compete in a 3D world
with simulated physics. The trained agents learn a wide variety of complex and
interesting skills, even though the environment themselves are relatively
simple. The skills include behaviors such as running, blocking, ducking,
tackling, fooling opponents, kicking, and defending using both arms and legs. A
highlight of the learned behaviors can be found here: https://goo.gl/eR7fbX",2017-10-10,2017,2017-10,environment
"User Environment Detection with Acoustic Sensors Embedded on Mobile
  Devices for the Recognition of Activities of Daily Living","The detection of the environment where user is located, is of extreme use for
the identification of Activities of Daily Living (ADL). ADL can be identified
by use of the sensors available in many off-the-shelf mobile devices, including
magnetic and motion, and the environment can be also identified using acoustic
sensors. The study presented in this paper is divided in two parts: firstly, we
discuss the recognition of the environment using acoustic sensors (i.e.,
microphone), and secondly, we fuse this information with motion and magnetic
sensors (i.e., motion and magnetic sensors) for the recognition of standing
activities of daily living. The recognition of the environments and the ADL are
performed using pattern recognition techniques, in order to develop a system
that includes data acquisition, data processing, data fusion, and artificial
intelligence methods. The artificial intelligence methods explored in this
study are composed by different types of Artificial Neural Networks (ANN),
comparing the different types of ANN and selecting the best methods to
implement in the different stages of the system developed. Conclusions point to
the use of Deep Neural Networks (DNN) with normalized data for the
identification of ADL with 85.89% of accuracy, the use of Feedforward neural
networks with non-normalized data for the identification of the environments
with 86.50% of accuracy, and the use of DNN with normalized data for the
identification of standing activities with 100% of accuracy.",2017-10-31,2017,2017-10,environment
Teaching a Machine to Read Maps with Deep Reinforcement Learning,"The ability to use a 2D map to navigate a complex 3D environment is quite
remarkable, and even difficult for many humans. Localization and navigation is
also an important problem in domains such as robotics, and has recently become
a focus of the deep reinforcement learning community. In this paper we teach a
reinforcement learning agent to read a map in order to find the shortest way
out of a random maze it has never seen before. Our system combines several
state-of-the-art methods such as A3C and incorporates novel elements such as a
recurrent localization cell. Our agent learns to localize itself based on 3D
first person images and an approximate orientation angle. The agent generalizes
well to bigger mazes, showing that it learned useful localization and
navigation capabilities.",2017-11-20,2017,2017-11,environment
"Interactive Robot Learning of Gestures, Language and Affordances","A growing field in robotics and Artificial Intelligence (AI) research is
human-robot collaboration, whose target is to enable effective teamwork between
humans and robots. However, in many situations human teams are still superior
to human-robot teams, primarily because human teams can easily agree on a
common goal with language, and the individual members observe each other
effectively, leveraging their shared motor repertoire and sensorimotor
resources. This paper shows that for cognitive robots it is possible, and
indeed fruitful, to combine knowledge acquired from interacting with elements
of the environment (affordance exploration) with the probabilistic observation
of another agent's actions.
  We propose a model that unites (i) learning robot affordances and word
descriptions with (ii) statistical recognition of human gestures with vision
sensors. We discuss theoretical motivations, possible implementations, and we
show initial results which highlight that, after having acquired knowledge of
its surrounding environment, a humanoid robot can generalize this knowledge to
the case when it observes another agent (human partner) performing the same
motor actions previously executed during training.",2017-11-24,2017,2017-11,environment
"Simulated Autonomous Driving on Realistic Road Networks using Deep
  Reinforcement Learning","Using Deep Reinforcement Learning (DRL) can be a promising approach to handle
various tasks in the field of (simulated) autonomous driving. However, recent
publications mainly consider learning in unusual driving environments. This
paper presents Driving School for Autonomous Agents (DSA^2), a software for
validating DRL algorithms in more usual driving environments based on
artificial and realistic road networks. We also present the results of applying
DSA^2 for handling the task of driving on a straight road while regulating the
velocity of one vehicle according to different speed limits.",2017-12-12,2017,2017-12,environment
Towards a Deep Reinforcement Learning Approach for Tower Line Wars,"There have been numerous breakthroughs with reinforcement learning in the
recent years, perhaps most notably on Deep Reinforcement Learning successfully
playing and winning relatively advanced computer games. There is undoubtedly an
anticipation that Deep Reinforcement Learning will play a major role when the
first AI masters the complicated game plays needed to beat a professional
Real-Time Strategy game player. For this to be possible, there needs to be a
game environment that targets and fosters AI research, and specifically Deep
Reinforcement Learning. Some game environments already exist, however, these
are either overly simplistic such as Atari 2600 or complex such as Starcraft II
from Blizzard Entertainment. We propose a game environment in between Atari
2600 and Starcraft II, particularly targeting Deep Reinforcement Learning
algorithm research. The environment is a variant of Tower Line Wars from
Warcraft III, Blizzard Entertainment. Further, as a proof of concept that the
environment can harbor Deep Reinforcement algorithms, we propose and apply a
Deep Q-Reinforcement architecture. The architecture simplifies the state space
so that it is applicable to Q-learning, and in turn improves performance
compared to current state-of-the-art methods. Our experiments show that the
proposed architecture can learn to play the environment well, and score 33%
better than standard Deep Q-learning which in turn proves the usefulness of the
game environment.",2017-12-17,2017,2017-12,environment
Null Dynamical State Models of Human Cognitive Dysfunction,"The hard problem in artificial intelligence asks how the shuffling of
syntactical symbols in a program can lead to systems which experience semantics
and qualia. We address this question in three stages. First, we introduce a new
class of human semantic symbols which appears when unexpected and drastic
environmental change causes humans to become surprised, confused, uncertain,
and in extreme cases, unresponsive, passive and dysfunctional. For this class
of symbols, pre-learned programs become inoperative so these syntactical
programs cannot be the source of experienced qualia. Second, we model the
dysfunctional human response to a radically changed environment as being the
natural response of any learning machine facing novel inputs from well outside
its previous training set. In this situation, learning machines are unable to
extract information from their input and will typically enter a dynamical state
characterized by null outputs and a lack of response. This state immediately
predicts and explains the characteristics of the semantic experiences of humans
in similar circumstances. In the third stage, we consider learning machines
trained to implement multiple functions in simple sequential programs using
environmental data to specify subroutine names, control flow instructions,
memory calls, and so on. Drastic change in any of these environmental inputs
can again lead to inoperative programs. By examining changes specific to people
or locations we can model human cognitive symbols featuring these dependencies,
such as attachment and grief. Our approach links known dynamical machines
states with human qualia and thus offers new insight into the hard problem of
artificial intelligence.",2017-12-25,2017,2017-12,environment
SenseNet: 3D Objects Database and Tactile Simulator,"The majority of artificial intelligence research, as it relates from which to
biological senses has been focused on vision. The recent explosion of machine
learning and in particular, dee p learning, can be partially attributed to the
release of high quality data sets for algorithm s from which to model the world
on. Thus, most of these datasets are comprised of images. We believe that
focusing on sensorimotor systems and tactile feedback will create algorithms
that better mimic human intelligence. Here we present SenseNet: a collection of
tactile simulators and a large scale dataset of 3D objects for manipulation.
SenseNet was created for the purpose of researching and training Artificial
Intelligences (AIs) to interact with the environment via sensorimotor neural
systems and tactile feedback. We aim to accelerate that same explosion in image
processing, but for the domain of tactile feedback and sensorimotor research.
We hope that SenseNet can offer researchers in both the machine learning and
computational neuroscience communities brand new opportunities and avenues to
explore.",2017-12-31,2017,2017-12,environment
"Counterfactual equivalence for POMDPs, and underlying deterministic
  environments","Partially Observable Markov Decision Processes (POMDPs) are rich environments
often used in machine learning. But the issue of information and causal
structures in POMDPs has been relatively little studied. This paper presents
the concepts of equivalent and counterfactually equivalent POMDPs, where agents
cannot distinguish which environment they are in though any observations and
actions. It shows that any POMDP is counterfactually equivalent, for any finite
number of turns, to a deterministic POMDP with all uncertainty concentrated
into the initial state. This allows a better understanding of POMDP
uncertainty, information, and learning.",2018-01-11,2018,2018-01,environment
CHALET: Cornell House Agent Learning Environment,"We present CHALET, a 3D house simulator with support for navigation and
manipulation. CHALET includes 58 rooms and 10 house configuration, and allows
to easily create new house and room layouts. CHALET supports a range of common
household activities, including moving objects, toggling appliances, and
placing objects inside closeable containers. The environment and actions
available are designed to create a challenging domain to train and evaluate
autonomous agents, including for tasks that combine language, vision, and
planning in a dynamic environment.",2018-01-23,2018,2018-01,environment
Deep Reinforcement Learning using Capsules in Advanced Game Environments,"Reinforcement Learning (RL) is a research area that has blossomed
tremendously in recent years and has shown remarkable potential for artificial
intelligence based opponents in computer games. This success is primarily due
to vast capabilities of Convolutional Neural Networks (ConvNet), enabling
algorithms to extract useful information from noisy environments. Capsule
Network (CapsNet) is a recent introduction to the Deep Learning algorithm group
and has only barely begun to be explored. The network is an architecture for
image classification, with superior performance for classification of the MNIST
dataset. CapsNets have not been explored beyond image classification.
  This thesis introduces the use of CapsNet for Q-Learning based game
algorithms. To successfully apply CapsNet in advanced game play, three main
contributions follow. First, the introduction of four new game environments as
frameworks for RL research with increasing complexity, namely Flash RL, Deep
Line Wars, Deep RTS, and Deep Maze. These environments fill the gap between
relatively simple and more complex game environments available for RL research
and are in the thesis used to test and explore the CapsNet behavior.
  Second, the thesis introduces a generative modeling approach to produce
artificial training data for use in Deep Learning models including CapsNets. We
empirically show that conditional generative modeling can successfully generate
game data of sufficient quality to train a Deep Q-Network well.
  Third, we show that CapsNet is a reliable architecture for Deep Q-Learning
based algorithms for game AI. A capsule is a group of neurons that determine
the presence of objects in the data and is in the literature shown to increase
the robustness of training and predictions while lowering the amount training
data needed. It should, therefore, be ideally suited for game plays.",2018-01-29,2018,2018-01,environment
"Narrow Artificial Intelligence with Machine Learning for Real-Time
  Estimation of a Mobile Agents Location Using Hidden Markov Models","We propose to use a supervised machine learning technique to track the
location of a mobile agent in real time. Hidden Markov Models are used to build
artificial intelligence that estimates the unknown position of a mobile target
moving in a defined environment. This narrow artificial intelligence performs
two distinct tasks. First, it provides real-time estimation of the mobile
agent's position using the forward algorithm. Second, it uses the Baum-Welch
algorithm as a statistical learning tool to gain knowledge of the mobile
target. Finally, an experimental environment is proposed, namely a video game
that we use to test our artificial intelligence. We present statistical and
graphical results to illustrate the efficiency of our method.",2018-02-09,2018,2018-02,environment
"Some Considerations on Learning to Explore via Meta-Reinforcement
  Learning","We consider the problem of exploration in meta reinforcement learning. Two
new meta reinforcement learning algorithms are suggested: E-MAML and
E-$\text{RL}^2$. Results are presented on a novel environment we call `Krazy
World' and a set of maze environments. We show E-MAML and E-$\text{RL}^2$
deliver better performance on tasks where exploration is important.",2018-03-03,2018,2018-03,environment
A Multi-Objective Deep Reinforcement Learning Framework,"This paper introduces a new scalable multi-objective deep reinforcement
learning (MODRL) framework based on deep Q-networks. We develop a
high-performance MODRL framework that supports both single-policy and
multi-policy strategies, as well as both linear and non-linear approaches to
action selection. The experimental results on two benchmark problems
(two-objective deep sea treasure environment and three-objective Mountain Car
problem) indicate that the proposed framework is able to find the
Pareto-optimal solutions effectively. The proposed framework is generic and
highly modularized, which allows the integration of different deep
reinforcement learning algorithms in different complex problem domains. This
therefore overcomes many disadvantages involved with standard multi-objective
reinforcement learning methods in the current literature. The proposed
framework acts as a testbed platform that accelerates the development of MODRL
for solving increasingly complicated multi-objective problems.",2018-03-08,2018,2018-03,environment
"Challenges and Characteristics of Intelligent Autonomy for Internet of
  Battle Things in Highly Adversarial Environments","Numerous, artificially intelligent, networked things will populate the
battlefield of the future, operating in close collaboration with human
warfighters, and fighting as teams in highly adversarial environments. This
paper explores the characteristics, capabilities and intelligence required of
such a network of intelligent things and humans - Internet of Battle Things
(IOBT). It will experience unique challenges that are not yet well addressed by
the current generation of AI and machine learning.",2018-03-20,2018,2018-03,environment
"Learning State Representations for Query Optimization with Deep
  Reinforcement Learning","Deep reinforcement learning is quickly changing the field of artificial
intelligence. These models are able to capture a high level understanding of
their environment, enabling them to learn difficult dynamic tasks in a variety
of domains. In the database field, query optimization remains a difficult
problem. Our goal in this work is to explore the capabilities of deep
reinforcement learning in the context of query optimization. At each state, we
build queries incrementally and encode properties of subqueries through a
learned representation. The challenge here lies in the formation of the state
transition function, which defines how the current subquery state combines with
the next query operation (action) to yield the next state. As a first step in
this direction, we focus the state representation problem and the formation of
the state transition function. We describe our approach and show preliminary
results. We further discuss how we can use the state representation to improve
query optimization using reinforcement learning.",2018-03-22,2018,2018-03,environment
On Chatbots Exhibiting Goal-Directed Autonomy in Dynamic Environments,"Conversation interfaces (CIs), or chatbots, are a popular form of intelligent
agents that engage humans in task-oriented or informal conversation. In this
position paper and demonstration, we argue that chatbots working in dynamic
environments, like with sensor data, can not only serve as a promising platform
to research issues at the intersection of learning, reasoning, representation
and execution for goal-directed autonomy; but also handle non-trivial business
applications. We explore the underlying issues in the context of Water Advisor,
a preliminary multi-modal conversation system that can access and explain water
quality data.",2018-03-26,2018,2018-03,environment
"Scalable photonic reinforcement learning by time-division multiplexing
  of laser chaos","Reinforcement learning involves decision making in dynamic and uncertain
environments and constitutes a crucial element of artificial intelligence. In
our previous work, we experimentally demonstrated that the ultrafast chaotic
oscillatory dynamics of lasers can be used to solve the two-armed bandit
problem efficiently, which requires decision making concerning a class of
difficult trade-offs called the exploration-exploitation dilemma. However, only
two selections were employed in that research; thus, the scalability of the
laser-chaos-based reinforcement learning should be clarified. In this study, we
demonstrated a scalable, pipelined principle of resolving the multi-armed
bandit problem by introducing time-division multiplexing of chaotically
oscillated ultrafast time-series. The experimental demonstrations in which
bandit problems with up to 64 arms were successfully solved are presented in
this report. Detailed analyses are also provided that include performance
comparisons among laser chaos signals generated in different physical
conditions, which coincide with the diffusivity inherent in the time series.
This study paves the way for ultrafast reinforcement learning by taking
advantage of the ultrahigh bandwidths of light wave and practical enabling
technologies.",2018-03-26,2018,2018-03,environment
Learning to Navigate in Cities Without a Map,"Navigating through unstructured environments is a basic capability of
intelligent creatures, and thus is of fundamental interest in the study and
development of artificial intelligence. Long-range navigation is a complex
cognitive task that relies on developing an internal representation of space,
grounded by recognisable landmarks and robust visual processing, that can
simultaneously support continuous self-localisation (""I am here"") and a
representation of the goal (""I am going there""). Building upon recent research
that applies deep reinforcement learning to maze navigation problems, we
present an end-to-end deep reinforcement learning approach that can be applied
on a city scale. Recognising that successful navigation relies on integration
of general policies with locale-specific knowledge, we propose a dual pathway
architecture that allows locale-specific features to be encapsulated, while
still enabling transfer to multiple cities. We present an interactive
navigation environment that uses Google StreetView for its photographic content
and worldwide coverage, and demonstrate that our learning method allows agents
to learn to navigate multiple cities and to traverse to target destinations
that may be kilometres away. The project webpage http://streetlearn.cc contains
a video summarising our research and showing the trained agent in diverse city
environments and on the transfer task, the form to request the StreetLearn
dataset and links to further resources. The StreetLearn environment code is
available at https://github.com/deepmind/streetlearn",2018-03-31,2018,2018-03,environment
Artificial Intelligence and its Role in Near Future,"AI technology has a long history which is actively and constantly changing
and growing. It focuses on intelligent agents, which contain devices that
perceive the environment and based on which takes actions in order to maximize
goal success chances. In this paper, we will explain the modern AI basics and
various representative applications of AI. In the context of the modern
digitalized world, AI is the property of machines, computer programs, and
systems to perform the intellectual and creative functions of a person,
independently find ways to solve problems, be able to draw conclusions and make
decisions. Most artificial intelligence systems have the ability to learn,
which allows people to improve their performance over time. The recent research
on AI tools, including machine learning, deep learning and predictive analysis
intended toward increasing the planning, learning, reasoning, thinking and
action taking ability. Based on which, the proposed research intends towards
exploring on how the human intelligence differs from the artificial
intelligence. Moreover, we critically analyze what AI of today is capable of
doing, why it still cannot reach human intelligence and what are the open
challenges existing in front of AI to reach and outperform human level of
intelligence. Furthermore, it will explore the future predictions for
artificial intelligence and based on which potential solution will be
recommended to solve it within next decades.",2018-04-01,2018,2018-04,environment
"The structure of evolved representations across different substrates for
  artificial intelligence","Artificial neural networks (ANNs), while exceptionally useful for
classification, are vulnerable to misdirection. Small amounts of noise can
significantly affect their ability to correctly complete a task. Instead of
generalizing concepts, ANNs seem to focus on surface statistical regularities
in a given task. Here we compare how recurrent artificial neural networks, long
short-term memory units, and Markov Brains sense and remember their
environments. We show that information in Markov Brains is localized and
sparsely distributed, while the other neural network substrates ""smear""
information about the environment across all nodes, which makes them vulnerable
to noise.",2018-04-05,2018,2018-04,environment
Terrain RL Simulator,"We provide $89$ challenging simulation environments that range in difficulty.
The difficulty of solving a task is linked not only to the number of dimensions
in the action space but also to the size and shape of the distribution of
configurations the agent experiences. Therefore, we are releasing a number of
simulation environments that include randomly generated terrain. The library
also provides simple mechanisms to create new environments with different agent
morphologies and the option to modify the distribution of generated terrain. We
believe using these and other more complex simulations will help push the field
closer to creating human-level intelligence.",2018-04-17,2018,2018-04,environment
"The Intelligent ICU Pilot Study: Using Artificial Intelligence
  Technology for Autonomous Patient Monitoring","Currently, many critical care indices are repetitively assessed and recorded
by overburdened nurses, e.g. physical function or facial pain expressions of
nonverbal patients. In addition, many essential information on patients and
their environment are not captured at all, or are captured in a non-granular
manner, e.g. sleep disturbance factors such as bright light, loud background
noise, or excessive visitations. In this pilot study, we examined the
feasibility of using pervasive sensing technology and artificial intelligence
for autonomous and granular monitoring of critically ill patients and their
environment in the Intensive Care Unit (ICU). As an exemplar prevalent
condition, we also characterized delirious and non-delirious patients and their
environment. We used wearable sensors, light and sound sensors, and a
high-resolution camera to collected data on patients and their environment. We
analyzed collected data using deep learning and statistical analysis. Our
system performed face detection, face recognition, facial action unit
detection, head pose detection, facial expression recognition, posture
recognition, actigraphy analysis, sound pressure and light level detection, and
visitation frequency detection. We were able to detect patient's face (Mean
average precision (mAP)=0.94), recognize patient's face (mAP=0.80), and their
postures (F1=0.94). We also found that all facial expressions, 11 activity
features, visitation frequency during the day, visitation frequency during the
night, light levels, and sound pressure levels during the night were
significantly different between delirious and non-delirious patients
(p-value<0.05). In summary, we showed that granular and autonomous monitoring
of critically ill patients and their environment is feasible and can be used
for characterizing critical care conditions and related environment factors.",2018-04-25,2018,2018-04,environment
"Synthesizing Efficient Solutions for Patrolling Problems in the Internet
  Environment","We propose an algorithm for constructing efficient patrolling strategies in
the Internet environment, where the protected targets are nodes connected to
the network and the patrollers are software agents capable of
detecting/preventing undesirable activities on the nodes. The algorithm is
based on a novel compositional principle designed for a special class of
strategies, and it can quickly construct (sub)optimal solutions even if the
number of targets reaches hundreds of millions.",2018-05-08,2018,2018-05,environment
Artificial Intelligence Inspired Self-Deployment of Wireless Networks,"In this paper, we propose a self-deployment approach for finding the optimal
placement of extenders in which both the wireless back-haul and front-haul
throughput of the extender are optimized. We present an artificial intelligence
(AI) case based reasoning (CBR) framework that enables autonomous
self-deployment in which the network can learn the environment by means of
sensing and perception. New actions, i.e. extender positions, are created by
problem-specific optimization and semi-supervised learning algorithms that
balance exploration and exploitation of the search space. An IEEE 802.11
standard compliant simulations are performed to evaluate the framework on a
large scale and compare its performance against existing conventional coverage
maximization approaches. Experimental evaluation is also performed in an
enterprise environment to demonstrate the competence of the proposed
AI-framework in perceiving such a dense scenario and reason the extender
deployment that achieves user quality of service (QoS). Throughput fairness and
ubiquitous QoS satisfaction are achieved which provide a leap to apply
AI-driven self-deployment in wireless networks.",2018-05-16,2018,2018-05,environment
"A Virtual Environment with Multi-Robot Navigation, Analytics, and
  Decision Support for Critical Incident Investigation","Accidents and attacks that involve chemical, biological, radiological/nuclear
or explosive (CBRNE) substances are rare, but can be of high consequence. Since
the investigation of such events is not anybody's routine work, a range of AI
techniques can reduce investigators' cognitive load and support
decision-making, including: planning the assessment of the scene; ongoing
evaluation and updating of risks; control of autonomous vehicles for collecting
images and sensor data; reviewing images/videos for items of interest;
identification of anomalies; and retrieval of relevant documentation. Because
of the rare and high-risk nature of these events, realistic simulations can
support the development and evaluation of AI-based tools. We have developed
realistic models of CBRNE scenarios and implemented an initial set of tools.",2018-06-12,2018,2018-06,environment
"A unified strategy for implementing curiosity and empowerment driven
  reinforcement learning","Although there are many approaches to implement intrinsically motivated
artificial agents, the combined usage of multiple intrinsic drives remains
still a relatively unexplored research area. Specifically, we hypothesize that
a mechanism capable of quantifying and controlling the evolution of the
information flow between the agent and the environment could be the fundamental
component for implementing a higher degree of autonomy into artificial
intelligent agents. This paper propose a unified strategy for implementing two
semantically orthogonal intrinsic motivations: curiosity and empowerment.
Curiosity reward informs the agent about the relevance of a recent agent
action, whereas empowerment is implemented as the opposite information flow
from the agent to the environment that quantifies the agent's potential of
controlling its own future. We show that an additional homeostatic drive is
derived from the curiosity reward, which generalizes and enhances the
information gain of a classical curious/heterostatic reinforcement learning
agent. We show how a shared internal model by curiosity and empowerment
facilitates a more efficient training of the empowerment function. Finally, we
discuss future directions for further leveraging the interplay between these
two intrinsic rewards.",2018-06-18,2018,2018-06,environment
"The Temporal Singularity: time-accelerated simulated civilizations and
  their implications","Provided significant future progress in artificial intelligence and
computing, it may ultimately be possible to create multiple Artificial General
Intelligences (AGIs), and possibly entire societies living within simulated
environments. In that case, it should be possible to improve the problem
solving capabilities of the system by increasing the speed of the simulation.
If a minimal simulation with sufficient capabilities is created, it might
manage to increase its own speed by accelerating progress in science and
technology, in a way similar to the Technological Singularity. This may
ultimately lead to large simulated civilizations unfolding at extreme temporal
speedups, achieving what from the outside would look like a Temporal
Singularity. Here we discuss the feasibility of the minimal simulation and the
potential advantages, dangers, and connection to the Fermi paradox of the
Temporal Singularity. The medium-term importance of the topic derives from the
amount of computational power required to start the process, which could be
available within the next decades, making the Temporal Singularity
theoretically possible before the end of the century.",2018-06-22,2018,2018-06,environment
Autonomous Wireless Systems with Artificial Intelligence,"This paper discusses technology and opportunities to embrace artificial
intelligence (AI) in the design of autonomous wireless systems. We aim to
provide readers with motivation and general AI methodology of autonomous agents
in the context of self-organization in real time by unifying knowledge
management with sensing, reasoning and active learning. We highlight
differences between training-based methods for matching problems and
training-free methods for environment-specific problems. Finally, we
conceptually introduce the functions of an autonomous agent with knowledge
management.",2018-06-27,2018,2018-06,environment
Modeling Friends and Foes,"How can one detect friendly and adversarial behavior from raw data? Detecting
whether an environment is a friend, a foe, or anything in between, remains a
poorly understood yet desirable ability for safe and robust agents. This paper
proposes a definition of these environmental ""attitudes"" based on an
characterization of the environment's ability to react to the agent's private
strategy. We define an objective function for a one-shot game that allows
deriving the environment's probability distribution under friendly and
adversarial assumptions alongside the agent's optimal strategy. Furthermore, we
present an algorithm to compute these equilibrium strategies, and show
experimentally that both friendly and adversarial environments possess
non-trivial optimal strategies.",2018-06-30,2018,2018-06,environment
Combinatorial Bandits for Incentivizing Agents with Dynamic Preferences,"The design of personalized incentives or recommendations to improve user
engagement is gaining prominence as digital platform providers continually
emerge. We propose a multi-armed bandit framework for matching incentives to
users, whose preferences are unknown a priori and evolving dynamically in time,
in a resource constrained environment. We design an algorithm that combines
ideas from three distinct domains: (i) a greedy matching paradigm, (ii) the
upper confidence bound algorithm (UCB) for bandits, and (iii) mixing times from
the theory of Markov chains. For this algorithm, we provide theoretical bounds
on the regret and demonstrate its performance via both synthetic and realistic
(matching supply and demand in a bike-sharing platform) examples.",2018-07-06,2018,2018-07,environment
"An agent-based model of an endangered population of the Arctic fox from
  Mednyi Island","Artificial Intelligence techniques such as agent-based modeling and
probabilistic reasoning have shown promise in modeling complex biological
systems and testing ecological hypotheses through simulation. We develop an
agent-based model of Arctic foxes from Medniy Island while utilizing
Probabilistic Graphical Models to capture the conditional dependencies between
the random variables. Such models provide valuable insights in analyzing
factors behind catastrophic degradation of this population and in revealing
evolutionary mechanisms of its persistence in high-density environment. Using
empirical data from studies in Medniy Island, we create a realistic model of
Arctic foxes as agents, and study their survival and population dynamics under
a variety of conditions.",2018-07-16,2018,2018-07,environment
On Evaluation of Embodied Navigation Agents,"Skillful mobile operation in three-dimensional environments is a primary
topic of study in Artificial Intelligence. The past two years have seen a surge
of creative work on navigation. This creative output has produced a plethora of
sometimes incompatible task definitions and evaluation protocols. To coordinate
ongoing and future research in this area, we have convened a working group to
study empirical methodology in navigation research. The present document
summarizes the consensus recommendations of this working group. We discuss
different problem statements and the role of generalization, present evaluation
measures, and provide standard scenarios that can be used for benchmarking.",2018-07-18,2018,2018-07,environment
Asynchronous Advantage Actor-Critic Agent for Starcraft II,"Deep reinforcement learning, and especially the Asynchronous Advantage
Actor-Critic algorithm, has been successfully used to achieve super-human
performance in a variety of video games. Starcraft II is a new challenge for
the reinforcement learning community with the release of pysc2 learning
environment proposed by Google Deepmind and Blizzard Entertainment. Despite
being a target for several AI developers, few have achieved human level
performance. In this project we explain the complexities of this environment
and discuss the results from our experiments on the environment. We have
compared various architectures and have proved that transfer learning can be an
effective paradigm in reinforcement learning research for complex scenarios
requiring skill transfer.",2018-07-22,2018,2018-07,environment
ToriLLE: Learning Environment for Hand-to-Hand Combat,"We present Toribash Learning Environment (ToriLLE), a learning environment
for machine learning agents based on the video game Toribash. Toribash is a
MuJoCo-like environment of two humanoid character fighting each other
hand-to-hand, controlled by changing actuation modes of the joints. Competitive
nature of Toribash as well its focused domain provide a platform for evaluating
self-play methods, and evaluating machine learning agents against human
players. In this paper we describe the environment with ToriLLE's capabilities
and limitations, and experimentally show its applicability as a learning
environment. The source code of the environment and conducted experiments can
be found at https://github.com/Miffyli/ToriLLE.",2018-07-26,2018,2018-07,environment
Multi-Agent Generative Adversarial Imitation Learning,"Imitation learning algorithms can be used to learn a policy from expert
demonstrations without access to a reward signal. However, most existing
approaches are not applicable in multi-agent settings due to the existence of
multiple (Nash) equilibria and non-stationary environments. We propose a new
framework for multi-agent imitation learning for general Markov games, where we
build upon a generalized notion of inverse reinforcement learning. We further
introduce a practical multi-agent actor-critic algorithm with good empirical
performance. Our method can be used to imitate complex behaviors in
high-dimensional environments with multiple cooperative or competing agents.",2018-07-26,2018,2018-07,environment
"Experience, Imitation and Reflection; Confucius' Conjecture and Machine
  Learning","Artificial intelligence recently had a great advancements caused by the
emergence of new processing power and machine learning methods. Having said
that, the learning capability of artificial intelligence is still at its
infancy comparing to the learning capability of human and many animals. Many of
the current artificial intelligence applications can only operate in a very
orchestrated, specific environments with an extensive training set that exactly
describes the conditions that will occur during execution time. Having that in
mind, and considering the several existing machine learning methods this
question rises that 'What are some of the best ways for a machine to learn?'
Regarding the learning methods of human, Confucius' point of view is that they
are by experience, imitation and reflection. This paper tries to explore and
discuss regarding these three ways of learning and their implementations in
machines by having a look at how they happen in minds.",2018-08-01,2018,2018-08,environment
"Deep RTS: A Game Environment for Deep Reinforcement Learning in
  Real-Time Strategy Games","Reinforcement learning (RL) is an area of research that has blossomed
tremendously in recent years and has shown remarkable potential for artificial
intelligence based opponents in computer games. This success is primarily due
to the vast capabilities of convolutional neural networks, that can extract
useful features from noisy and complex data. Games are excellent tools to test
and push the boundaries of novel RL algorithms because they give valuable
insight into how well an algorithm can perform in isolated environments without
the real-life consequences. Real-time strategy games (RTS) is a genre that has
tremendous complexity and challenges the player in short and long-term
planning. There is much research that focuses on applied RL in RTS games, and
novel advances are therefore anticipated in the not too distant future.
However, there are to date few environments for testing RTS AIs. Environments
in the literature are often either overly simplistic, such as microRTS, or
complex and without the possibility for accelerated learning on consumer
hardware like StarCraft II. This paper introduces the Deep RTS game environment
for testing cutting-edge artificial intelligence algorithms for RTS games. Deep
RTS is a high-performance RTS game made specifically for artificial
intelligence research. It supports accelerated learning, meaning that it can
learn at a magnitude of 50 000 times faster compared to existing RTS games.
Deep RTS has a flexible configuration, enabling research in several different
RTS scenarios, including partially observable state-spaces and map complexity.
We show that Deep RTS lives up to our promises by comparing its performance
with microRTS, ELF, and StarCraft II on high-end consumer hardware. Using Deep
RTS, we show that a Deep Q-Network agent beats random-play agents over 70% of
the time. Deep RTS is publicly available at https://github.com/cair/DeepRTS.",2018-08-15,2018,2018-08,environment
"Three-Stage Speaker Verification Architecture in Emotional Talking
  Environments","Speaker verification performance in neutral talking environment is usually
high, while it is sharply decreased in emotional talking environments. This
performance degradation in emotional environments is due to the problem of
mismatch between training in neutral environment while testing in emotional
environments. In this work, a three-stage speaker verification architecture has
been proposed to enhance speaker verification performance in emotional
environments. This architecture is comprised of three cascaded stages: gender
identification stage followed by an emotion identification stage followed by a
speaker verification stage. The proposed framework has been evaluated on two
distinct and independent emotional speech datasets: in-house dataset and
Emotional Prosody Speech and Transcripts dataset. Our results show that speaker
verification based on both gender information and emotion information is
superior to each of speaker verification based on gender information only,
emotion information only, and neither gender information nor emotion
information. The attained average speaker verification performance based on the
proposed framework is very alike to that attained in subjective assessment by
human listeners.",2018-09-03,2018,2018-09,environment
Planning with Arithmetic and Geometric Attributes,"A desirable property of an intelligent agent is its ability to understand its
environment to quickly generalize to novel tasks and compose simpler tasks into
more complex ones. If the environment has geometric or arithmetic structure,
the agent should exploit these for faster generalization. Building on recent
work that augments the environment with user-specified attributes, we show that
further equipping these attributes with the appropriate geometric and
arithmetic structure brings substantial gains in sample complexity.",2018-09-06,2018,2018-09,environment
Unity: A General Platform for Intelligent Agents,"Recent advances in artificial intelligence have been driven by the presence
of increasingly realistic and complex simulated environments. However, many of
the existing environments provide either unrealistic visuals, inaccurate
physics, low task complexity, restricted agent perspective, or a limited
capacity for interaction among artificial agents. Furthermore, many platforms
lack the ability to flexibly configure the simulation, making the simulated
environment a black-box from the perspective of the learning system. In this
work, we propose a novel taxonomy of existing simulation platforms and discuss
the highest level class of general platforms which enable the development of
learning environments that are rich in visual, physical, task, and social
complexity. We argue that modern game engines are uniquely suited to act as
general platforms and as a case study examine the Unity engine and open source
Unity ML-Agents Toolkit. We then survey the research enabled by Unity and the
Unity ML-Agents Toolkit, discussing the kinds of research a flexible,
interactive and easily configurable general platform can facilitate.",2018-09-07,2018,2018-09,environment
"Artificial Intelligence for the Public Sector: Opportunities and
  challenges of cross-sector collaboration","Public sector organisations are increasingly interested in using data science
and artificial intelligence capabilities to deliver policy and generate
efficiencies in high uncertainty environments. The long-term success of data
science and AI in the public sector relies on effectively embedding it into
delivery solutions for policy implementation. However, governments cannot do
this integration of AI into public service delivery on their own. The UK
Government Industrial Strategy is clear that delivering on the AI grand
challenge requires collaboration between universities and public and private
sectors. This cross-sectoral collaborative approach is the norm in applied AI
centres of excellence around the world. Despite their popularity, cross-sector
collaborations entail serious management challenges that hinder their success.
In this article we discuss the opportunities and challenges from AI for public
sector. Finally, we propose a series of strategies to successfully manage these
cross-sectoral collaborations.",2018-09-12,2018,2018-09,environment
Combined Reinforcement Learning via Abstract Representations,"In the quest for efficient and robust reinforcement learning methods, both
model-free and model-based approaches offer advantages. In this paper we
propose a new way of explicitly bridging both approaches via a shared
low-dimensional learned encoding of the environment, meant to capture
summarizing abstractions. We show that the modularity brought by this approach
leads to good generalization while being computationally efficient, with
planning happening in a smaller latent state space. In addition, this approach
recovers a sufficient low-dimensional representation of the environment, which
opens up new strategies for interpretable AI, exploration and transfer
learning.",2018-09-12,2018,2018-09,environment
"Using Artificial Intelligence to Support Compliance with the General
  Data Protection Regulation","The General Data Protection Regulation (GDPR) is a European Union regulation
that will replace the existing Data Protection Directive on 25 May 2018. The
most significant change is a huge increase in the maximum fine that can be
levied for breaches of the regulation. Yet fewer than half of UK companies are
fully aware of GDPR - and a number of those who were preparing for it stopped
doing so when the Brexit vote was announced. A last-minute rush to become
compliant is therefore expected, and numerous companies are starting to offer
advice, checklists and consultancy on how to comply with GDPR. In such an
environment, artificial intelligence technologies ought to be able to assist by
providing best advice; asking all and only the relevant questions; monitoring
activities; and carrying out assessments. The paper considers four areas of
GDPR compliance where rule based technologies and/or machine learning
techniques may be relevant: * Following compliance checklists and codes of
conduct; * Supporting risk assessments; * Complying with the new regulations
regarding technologies that perform automatic profiling; * Complying with the
new regulations concerning recognising and reporting breaches of security. It
concludes that AI technology can support each of these four areas. The
requirements that GDPR (or organisations that need to comply with GDPR) state
for explanation and justification of reasoning imply that rule-based approaches
are likely to be more helpful than machine learning approaches. However, there
may be good business reasons to take a different approach in some
circumstances.",2018-09-15,2018,2018-09,environment
Federated AI for building AI Solutions across Multiple Agencies,"The different sets of regulations existing for differ-ent agencies within the
government make the task of creating AI enabled solutions in government
dif-ficult. Regulatory restrictions inhibit sharing of da-ta across different
agencies, which could be a significant impediment to training AI models. We
discuss the challenges that exist in environments where data cannot be freely
shared and assess tech-nologies which can be used to work around these
challenges. We present results on building AI models using the concept of
federated AI, which al-lows creation of models without moving the training data
around.",2018-09-20,2018,2018-09,environment
"Translating Navigation Instructions in Natural Language to a High-Level
  Plan for Behavioral Robot Navigation","We propose an end-to-end deep learning model for translating free-form
natural language instructions to a high-level plan for behavioral robot
navigation. We use attention models to connect information from both the user
instructions and a topological representation of the environment. We evaluate
our model's performance on a new dataset containing 10,050 pairs of navigation
instructions. Our model significantly outperforms baseline approaches.
Furthermore, our results suggest that it is possible to leverage the
environment map as a relevant knowledge base to facilitate the translation of
free-form navigational instruction.",2018-09-24,2018,2018-09,environment
Towards Game-based Metrics for Computational Co-creativity,"We propose the following question: what game-like interactive system would
provide a good environment for measuring the impact and success of a
co-creative, cooperative agent? Creativity is often formulated in terms of
novelty, value, surprise and interestingness. We review how these concepts are
measured in current computational intelligence research and provide a mapping
from modern electronic and tabletop games to open research problems in
mixed-initiative systems and computational co-creativity. We propose
application scenarios for future research, and a number of metrics under which
the performance of cooperative agents in these environments will be evaluated.",2018-09-26,2018,2018-09,environment
"The Dreaming Variational Autoencoder for Reinforcement Learning
  Environments","Reinforcement learning has shown great potential in generalizing over raw
sensory data using only a single neural network for value optimization. There
are several challenges in the current state-of-the-art reinforcement learning
algorithms that prevent them from converging towards the global optima. It is
likely that the solution to these problems lies in short- and long-term
planning, exploration and memory management for reinforcement learning
algorithms. Games are often used to benchmark reinforcement learning algorithms
as they provide a flexible, reproducible, and easy to control environment.
Regardless, few games feature a state-space where results in exploration,
memory, and planning are easily perceived. This paper presents The Dreaming
Variational Autoencoder (DVAE), a neural network based generative modeling
architecture for exploration in environments with sparse feedback. We further
present Deep Maze, a novel and flexible maze engine that challenges DVAE in
partial and fully-observable state-spaces, long-horizon tasks, and
deterministic and stochastic problems. We show initial findings and encourage
further work in reinforcement learning driven by generative exploration.",2018-10-02,2018,2018-10,environment
At Human Speed: Deep Reinforcement Learning with Action Delay,"There has been a recent explosion in the capabilities of game-playing
artificial intelligence. Many classes of tasks, from video games to motor
control to board games, are now solvable by fairly generic algorithms, based on
deep learning and reinforcement learning, that learn to play from experience
with minimal prior knowledge. However, these machines often do not win through
intelligence alone -- they possess vastly superior speed and precision,
allowing them to act in ways a human never could. To level the playing field,
we restrict the machine's reaction time to a human level, and find that
standard deep reinforcement learning methods quickly drop in performance. We
propose a solution to the action delay problem inspired by human perception --
to endow agents with a neural predictive model of the environment which
""undoes"" the delay inherent in their environment -- and demonstrate its
efficacy against professional players in Super Smash Bros. Melee, a popular
console fighting game.",2018-10-16,2018,2018-10,environment
"Coordinated exploration for labyrinthine environments with application
  to the Pursuit-Evasion problem","This paper introduces a multirobot cooperation approach to solve the ""pursuit
evasion"" problem for mobile robots that have omnidirectional vision sensors.
The main characteristic of this approach is to implement a real cooperation
between robots based on knowledge sharing and makes them work as a team. A
complete algorithm for computing a motion strategy of robots is also presented.
This algorithm is based on searching critical points in the environment.
Finally, the deliberation protocol which distributes the exploration task among
the team and takes the best possible outcome from the robots resources is
presented.",2018-10-19,2018,2018-10,environment
"Analysis of Fleet Modularity in an Artificial Intelligence-Based
  Attacker-Defender Game","Because combat environments change over time and technology upgrades are
widespread for ground vehicles, a large number of vehicles and equipment become
quickly obsolete. A possible solution for the U.S. Army is to develop fleets of
modular military vehicles, which are built by interchangeable substantial
components also known as modules. One of the typical characteristics of module
is their ease of assembly and disassembly through simple means such as
plug-in/pull-out actions, which allows for real-time fleet reconfiguration to
meet dynamic demands. Moreover, military demands are time-varying and highly
stochastic because commanders keep reacting to enemy's actions. To capture
these characteristics, we formulated an intelligent agent-based model to
imitate decision making process during fleet operation, which combines
real-time optimization with artificial intelligence. The agents are capable of
inferring enemy's future move based on historical data and optimize
dispatch/operation decisions accordingly. We implement our model to simulate an
attacker-defender game between two adversarial and intelligent players,
representing the commanders from modularized fleet and conventional fleet
respectively. Given the same level of combat resources and intelligence, we
highlight the tactical advantages of fleet modularity in terms of win rate,
unpredictability and suffered damage.",2018-11-09,2018,2018-11,environment
Blindfold Baselines for Embodied QA,"We explore blindfold (question-only) baselines for Embodied Question
Answering. The EmbodiedQA task requires an agent to answer a question by
intelligently navigating in a simulated environment, gathering necessary visual
information only through first-person vision before finally answering.
Consequently, a blindfold baseline which ignores the environment and visual
information is a degenerate solution, yet we show through our experiments on
the EQAv1 dataset that a simple question-only baseline achieves
state-of-the-art results on the EmbodiedQA task in all cases except when the
agent is spawned extremely close to the object.",2018-11-12,2018,2018-11,environment
On the Complexity of Exploration in Goal-Driven Navigation,"Building agents that can explore their environments intelligently is a
challenging open problem. In this paper, we make a step towards understanding
how a hierarchical design of the agent's policy can affect its exploration
capabilities. First, we design EscapeRoom environments, where the agent must
figure out how to navigate to the exit by accomplishing a number of
intermediate tasks (\emph{subgoals}), such as finding keys or opening doors.
Our environments are procedurally generated and vary in complexity, which can
be controlled by the number of subgoals and relationships between them. Next,
we propose to measure the complexity of each environment by constructing
dependency graphs between the goals and analytically computing \emph{hitting
times} of a random walk in the graph. We empirically evaluate Proximal Policy
Optimization (PPO) with sparse and shaped rewards, a variation of policy
sketches, and a hierarchical version of PPO (called HiPPO) akin to h-DQN. We
show that analytically estimated \emph{hitting time} in goal dependency graphs
is an informative metric of the environment complexity. We conjecture that the
result should hold for environments other than navigation. Finally, we show
that solving environments beyond certain level of complexity requires
hierarchical approaches.",2018-11-16,2018,2018-11,environment
"Simulated Autonomous Driving in a Realistic Driving Environment using
  Deep Reinforcement Learning and a Deterministic Finite State Machine","In the field of Autonomous Driving, the system controlling the vehicle can be
seen as an agent acting in a complex environment and thus naturally fits into
the modern framework of Reinforcement Learning. However, learning to drive can
be a challenging task and current results are often restricted to simplified
driving environments. To advance the field, we present a method to adaptively
restrict the action space of the agent according to its current driving
situation and show that it can be used to swiftly learn to drive in a realistic
environment based on the Deep Q-Network algorithm.",2018-11-19,2018,2018-11,environment
Planning in Dynamic Environments with Conditional Autoregressive Models,"We demonstrate the use of conditional autoregressive generative models (van
den Oord et al., 2016a) over a discrete latent space (van den Oord et al.,
2017b) for forward planning with MCTS. In order to test this method, we
introduce a new environment featuring varying difficulty levels, along with
moving goals and obstacles. The combination of high-quality frame generation
and classical planning approaches nearly matches true environment performance
for our task, demonstrating the usefulness of this method for model-based
planning in dynamic environments.",2018-11-25,2018,2018-11,environment
Environments for Lifelong Reinforcement Learning,"To achieve general artificial intelligence, reinforcement learning (RL)
agents should learn not only to optimize returns for one specific task but also
to constantly build more complex skills and scaffold their knowledge about the
world, without forgetting what has already been learned. In this paper, we
discuss the desired characteristics of environments that can support the
training and evaluation of lifelong reinforcement learning agents, review
existing environments from this perspective, and propose recommendations for
devising suitable environments in the future.",2018-11-26,2018,2018-11,environment
"BlockPuzzle - A Challenge in Physical Reasoning and Generalization for
  Robot Learning","In this work we propose a novel task framework under which a variety of
physical reasoning puzzles can be constructed using very simple rules. Under
sparse reward settings, most of these tasks can be very challenging for a
reinforcement learning agent to learn. We build several simple environments
with this task framework in Mujoco and OpenAI gym and attempt to solve them. We
are able to solve the environments by designing curricula to guide the agent in
learning and using imitation learning methods to transfer knowledge from a
simpler environment. This is only a first step for the task framework, and
further research on how to solve the harder tasks and transfer knowledge
between tasks is needed.",2018-11-30,2018,2018-11,environment
"Making BREAD: Biomimetic strategies for Artificial Intelligence Now and
  in the Future","The Artificial Intelligence (AI) revolution foretold of during the 1960s is
well underway in the second decade of the 21st century. Its period of
phenomenal growth likely lies ahead. Still, we believe, there are crucial
lessons that biology can offer that will enable a prosperous future for AI. For
machines in general, and for AI's especially, operating over extended periods
or in extreme environments will require energy usage orders of magnitudes more
efficient than exists today. In many operational environments, energy sources
will be constrained. Any plans for AI devices operating in a challenging
environment must begin with the question of how they are powered, where fuel is
located, how energy is stored and made available to the machine, and how long
the machine can operate on specific energy units. Hence, the materials and
technologies that provide the needed energy represent a critical challenge
towards future use-scenarios of AI and should be integrated into their design.
Here we make four recommendations for stakeholders and especially decision
makers to facilitate a successful trajectory for this technology. First, that
scientific societies and governments coordinate Biomimetic Research for
Energy-efficient, AI Designs (BREAD); a multinational initiative and a funding
strategy for investments in the future integrated design of energetics into AI.
Second, that biomimetic energetic solutions be central to design consideration
for future AI. Third, that a pre-competitive space be organized between
stakeholder partners and fourth, that a trainee pipeline be established to
ensure the human capital required for success in this area.",2018-12-04,2018,2018-12,environment
Probabilistic Model Checking of Robots Deployed in Extreme Environments,"Robots are increasingly used to carry out critical missions in extreme
environments that are hazardous for humans. This requires a high degree of
operational autonomy under uncertain conditions, and poses new challenges for
assuring the robot's safety and reliability. In this paper, we develop a
framework for probabilistic model checking on a layered Markov model to verify
the safety and reliability requirements of such robots, both at pre-mission
stage and during runtime. Two novel estimators based on conservative Bayesian
inference and imprecise probability model with sets of priors are introduced to
learn the unknown transition parameters from operational data. We demonstrate
our approach using data from a real-world deployment of unmanned underwater
vehicles in extreme environments.",2018-12-10,2018,2018-12,environment
"Lifelong Testing of Smart Autonomous Systems by Shepherding a Swarm of
  Watchdog Artificial Intelligence Agents","Artificial Intelligence (AI) technologies could be broadly categorised into
Analytics and Autonomy. Analytics focuses on algorithms offering perception,
comprehension, and projection of knowledge gleaned from sensorial data.
Autonomy revolves around decision making, and influencing and shaping the
environment through action production. A smart autonomous system (SAS) combines
analytics and autonomy to understand, learn, decide and act autonomously. To be
useful, SAS must be trusted and that requires testing. Lifelong learning of a
SAS compounds the testing process. In the remote chance that it is possible to
fully test and certify the system pre-release, which is theoretically an
undecidable problem, it is near impossible to predict the future behaviours
that these systems, alone or collectively, will exhibit. While it may be
feasible to severely restrict such systems\textquoteright \ learning abilities
to limit the potential unpredictability of their behaviours, an undesirable
consequence may be severely limiting their utility. In this paper, we propose
the architecture for a watchdog AI (WAI) agent dedicated to lifelong functional
testing of SAS. We further propose system specifications including a level of
abstraction whereby humans shepherd a swarm of WAI agents to oversee an
ecosystem made of humans and SAS. The discussion extends to the challenges,
pros, and cons of the proposed concept.",2018-12-21,2018,2018-12,environment
"Optimal Decision-Making in Mixed-Agent Partially Observable Stochastic
  Environments via Reinforcement Learning","Optimal decision making with limited or no information in stochastic
environments where multiple agents interact is a challenging topic in the realm
of artificial intelligence. Reinforcement learning (RL) is a popular approach
for arriving at optimal strategies by predicating stimuli, such as the reward
for following a strategy, on experience. RL is heavily explored in the
single-agent context, but is a nascent concept in multiagent problems. To this
end, I propose several principled model-free and partially model-based
reinforcement learning approaches for several multiagent settings. In the realm
of normative reinforcement learning, I introduce scalable extensions to Monte
Carlo exploring starts for partially observable Markov Decision Processes
(POMDP), dubbed MCES-P, where I expand the theory and algorithm to the
multiagent setting. I first examine MCES-P with probably approximately correct
(PAC) bounds in the context of multiagent setting, showing MCESP+PAC holds in
the presence of other agents. I then propose a more sample-efficient
methodology for antagonistic settings, MCESIP+PAC. For cooperative settings, I
extend MCES-P to the Multiagent POMDP, dubbed MCESMP+PAC. I then explore the
use of reinforcement learning as a methodology in searching for optima in
realistic and latent model environments. First, I explore a parameterized
Q-learning approach in modeling humans learning to reason in an uncertain,
multiagent environment. Next, I propose an implementation of MCES-P, along with
image segmentation, to create an adaptive team-based reinforcement learning
technique to positively identify the presence of phenotypically-expressed water
and pathogen stress in crop fields.",2019-01-04,2019,2019-01,environment
"Learning and Reasoning for Robot Sequential Decision Making under
  Uncertainty","Robots frequently face complex tasks that require more than one action, where
sequential decision-making (SDM) capabilities become necessary. The key
contribution of this work is a robot SDM framework, called LCORPP, that
supports the simultaneous capabilities of supervised learning for passive state
estimation, automated reasoning with declarative human knowledge, and planning
under uncertainty toward achieving long-term goals. In particular, we use a
hybrid reasoning paradigm to refine the state estimator, and provide
informative priors for the probabilistic planner. In experiments, a mobile
robot is tasked with estimating human intentions using their motion
trajectories, declarative contextual knowledge, and human-robot interaction
(dialog-based and motion-based). Results suggest that, in efficiency and
accuracy, our framework performs better than its no-learning and no-reasoning
counterparts in office environment.",2019-01-16,2019,2019-01,environment
Learning Independently-Obtainable Reward Functions,"We present a novel method for learning a set of disentangled reward functions
that sum to the original environment reward and are constrained to be
independently obtainable. We define independent obtainability in terms of value
functions with respect to obtaining one learned reward while pursuing another
learned reward. Empirically, we illustrate that our method can learn meaningful
reward decompositions in a variety of domains and that these decompositions
exhibit some form of generalization performance when the environment's reward
is modified. Theoretically, we derive results about the effect of maximizing
our method's objective on the resulting reward functions and their
corresponding optimal policies.",2019-01-24,2019,2019-01,environment
Modularization of End-to-End Learning: Case Study in Arcade Games,"Complex environments and tasks pose a difficult problem for holistic
end-to-end learning approaches. Decomposition of an environment into
interacting controllable and non-controllable objects allows supervised
learning for non-controllable objects and universal value function approximator
learning for controllable objects. Such decomposition should lead to a shorter
learning time and better generalisation capability. Here, we consider
arcade-game environments as sets of interacting objects (controllable,
non-controllable) and propose a set of functional modules that are specialized
on mastering different types of interactions in a broad range of environments.
The modules utilize regression, supervised learning, and reinforcement learning
algorithms. Results of this case study in different Atari games suggest that
human-level performance can be achieved by a learning agent within a human
amount of game experience (10-15 minutes game time) when a proper decomposition
of an environment or a task is provided. However, automatization of such
decomposition remains a challenging problem. This case study shows how a model
of a causal structure underlying an environment or a task can benefit learning
time and generalization capability of the agent, and argues in favor of
exploiting modular structure in contrast to using pure end-to-end learning
approaches.",2019-01-27,2019,2019-01,environment
Increasing city safety awareness regarding disruptive traffic stream,"Transportation systems serve the people in essence, in this study we focus in
traffic information related to violation events to respond to safety
requirements of the cities. Traffic violation events have an important role in
city safety awareness and secure travel. In this work, we describe the use of
knowledge discovery from traffic violation reports in combination with
demographics approach using inductive logic programming to automatically
extract knowledge about traffic violation behavior and their impact on the
environment.",2019-01-30,2019,2019-01,environment
Causal Simulations for Uplift Modeling,"Uplift modeling requires experimental data, preferably collected in random
fashion. This places a logistical and financial burden upon any organisation
aspiring such models. Once deployed, uplift models are subject to effects from
concept drift. Hence, methods are being developed that are able to learn from
newly gained experience, as well as handle drifting environments. As these new
methods attempt to eliminate the need for experimental data, another approach
to test such methods must be formulated. Therefore, we propose a method to
simulate environments that offer causal relationships in their parameters.",2019-02-01,2019,2019-02,environment
The Hanabi Challenge: A New Frontier for AI Research,"From the early days of computing, games have been important testbeds for
studying how well machines can do sophisticated decision making. In recent
years, machine learning has made dramatic advances with artificial agents
reaching superhuman performance in challenge domains like Go, Atari, and some
variants of poker. As with their predecessors of chess, checkers, and
backgammon, these game domains have driven research by providing sophisticated
yet well-defined challenges for artificial intelligence practitioners. We
continue this tradition by proposing the game of Hanabi as a new challenge
domain with novel problems that arise from its combination of purely
cooperative gameplay with two to five players and imperfect information. In
particular, we argue that Hanabi elevates reasoning about the beliefs and
intentions of other agents to the foreground. We believe developing novel
techniques for such theory of mind reasoning will not only be crucial for
success in Hanabi, but also in broader collaborative efforts, especially those
with human partners. To facilitate future research, we introduce the
open-source Hanabi Learning Environment, propose an experimental framework for
the research community to evaluate algorithmic advances, and assess the
performance of current state-of-the-art techniques.",2019-02-01,2019,2019-02,environment
"Confidence Trigger Detection: Accelerating Real-time
  Tracking-by-detection Systems","Real-time object tracking necessitates a delicate balance between speed and
accuracy, a challenge exacerbated by the computational demands of deep learning
methods. In this paper, we propose Confidence-Triggered Detection (CTD), an
innovative approach that strategically bypasses object detection for frames
closely resembling intermediate states, leveraging tracker confidence scores.
CTD not only enhances tracking speed but also preserves accuracy, surpassing
existing tracking algorithms. Through extensive evaluation across various
tracker confidence thresholds, we identify an optimal trade-off between
tracking speed and accuracy, providing crucial insights for parameter
fine-tuning and enhancing CTD's practicality in real-world scenarios. Our
experiments across diverse detection models underscore the robustness and
versatility of the CTD framework, demonstrating its potential to enable
real-time tracking in resource-constrained environments.",2019-02-02,2019,2019-02,environment
"Evaluation of Multidisciplinary Effects of Artificial Intelligence with
  Optimization Perspective","Artificial Intelligence has an important place in the scientific community as
a result of its successful outputs in terms of different fields. In time, the
field of Artificial Intelligence has been divided into many sub-fields because
of increasing number of different solution approaches, methods, and techniques.
Machine Learning has the most remarkable role with its functions to learn from
samples from the environment. On the other hand, intelligent optimization done
by inspiring from nature and swarms had its own unique scientific literature,
with effective solutions provided for optimization problems from different
fields. Because intelligent optimization can be applied in different fields
effectively, this study aims to provide a general discussion on
multidisciplinary effects of Artificial Intelligence by considering its
optimization oriented solutions. The study briefly focuses on background of the
intelligent optimization briefly and then gives application examples of
intelligent optimization from a multidisciplinary perspective.",2019-02-04,2019,2019-02,environment
"Obstacle Tower: A Generalization Challenge in Vision, Control, and
  Planning","The rapid pace of recent research in AI has been driven in part by the
presence of fast and challenging simulation environments. These environments
often take the form of games; with tasks ranging from simple board games, to
competitive video games. We propose a new benchmark - Obstacle Tower: a high
fidelity, 3D, 3rd person, procedurally generated environment. An agent playing
Obstacle Tower must learn to solve both low-level control and high-level
planning problems in tandem while learning from pixels and a sparse reward
signal. Unlike other benchmarks such as the Arcade Learning Environment,
evaluation of agent performance in Obstacle Tower is based on an agent's
ability to perform well on unseen instances of the environment. In this paper
we outline the environment and provide a set of baseline results produced by
current state-of-the-art Deep RL methods as well as human players. These
algorithms fail to produce agents capable of performing near human level.",2019-02-04,2019,2019-02,environment
Learning to Learn in Simulation,"Deep learning often requires the manual collection and annotation of a
training set. On robotic platforms, can we partially automate this task by
training the robot to be curious, i.e., to seek out beneficial training
information in the environment? In this work, we address the problem of
curiosity as it relates to online, real-time, human-in-the-loop training of an
object detection algorithm onboard a drone, where motion is constrained to two
dimensions. We use a 3D simulation environment and deep reinforcement learning
to train a curiosity agent to, in turn, train the object detection model. This
agent could have one of two conflicting objectives: train as quickly as
possible, or train with minimal human input. We outline a reward function that
allows the curiosity agent to learn either of these objectives, while taking
into account some of the physical characteristics of the drone platform on
which it is meant to run. In addition, We show that we can weigh the importance
of achieving these objectives by adjusting a parameter in the reward function.",2019-02-05,2019,2019-02,environment
Situational Grounding within Multimodal Simulations,"In this paper, we argue that simulation platforms enable a novel type of
embodied spatial reasoning, one facilitated by a formal model of object and
event semantics that renders the continuous quantitative search space of an
open-world, real-time environment tractable. We provide examples for how a
semantically-informed AI system can exploit the precise, numerical information
provided by a game engine to perform qualitative reasoning about objects and
events, facilitate learning novel concepts from data, and communicate with a
human to improve its models and demonstrate its understanding. We argue that
simulation environments, and game engines in particular, bring together many
different notions of ""simulation"" and many different technologies to provide a
highly-effective platform for developing both AI systems and tools to
experiment in both machine and human intelligence.",2019-02-05,2019,2019-02,environment
Visual search and recognition for robot task execution and monitoring,"Visual search of relevant targets in the environment is a crucial robot
skill. We propose a preliminary framework for the execution monitor of a robot
task, taking care of the robot attitude to visually searching the environment
for targets involved in the task. Visual search is also relevant to recover
from a failure. The framework exploits deep reinforcement learning to acquire a
""common sense"" scene structure and it takes advantage of a deep convolutional
network to detect objects and relevant relations holding between them. The
framework builds on these methods to introduce a vision-based execution
monitoring, which uses classical planning as a backbone for task execution.
Experiments show that with the proposed vision-based execution monitor the
robot can complete simple tasks and can recover from failures in autonomy.",2019-02-07,2019,2019-02,environment
EvalAI: Towards Better Evaluation Systems for AI Agents,"We introduce EvalAI, an open source platform for evaluating and comparing
machine learning (ML) and artificial intelligence algorithms (AI) at scale.
EvalAI is built to provide a scalable solution to the research community to
fulfill the critical need of evaluating machine learning models and agents
acting in an environment against annotations or with a human-in-the-loop. This
will help researchers, students, and data scientists to create, collaborate,
and participate in AI challenges organized around the globe. By simplifying and
standardizing the process of benchmarking these models, EvalAI seeks to lower
the barrier to entry for participating in the global scientific effort to push
the frontiers of machine learning and artificial intelligence, thereby
increasing the rate of measurable progress in this domain.",2019-02-10,2019,2019-02,environment
"VERIFAI: A Toolkit for the Design and Analysis of Artificial
  Intelligence-Based Systems","We present VERIFAI, a software toolkit for the formal design and analysis of
systems that include artificial intelligence (AI) and machine learning (ML)
components. VERIFAI particularly seeks to address challenges with applying
formal methods to perception and ML components, including those based on neural
networks, and to model and analyze system behavior in the presence of
environment uncertainty. We describe the initial version of VERIFAI which
centers on simulation guided by formal models and specifications. Several use
cases are illustrated with examples, including temporal-logic falsification,
model-based systematic fuzz testing, parameter synthesis, counterexample
analysis, and data set augmentation.",2019-02-12,2019,2019-02,environment
"Marathon Environments: Multi-Agent Continuous Control Benchmarks in a
  Modern Video Game Engine","Recent advances in deep reinforcement learning in the paradigm of locomotion
using continuous control have raised the interest of game makers for the
potential of digital actors using active ragdoll. Currently, the available
options to develop these ideas are either researchers' limited codebase or
proprietary closed systems. We present Marathon Environments, a suite of open
source, continuous control benchmarks implemented on the Unity game engine,
using the Unity ML- Agents Toolkit. We demonstrate through these benchmarks
that continuous control research is transferable to a commercial game engine.
Furthermore, we exhibit the robustness of these environments by reproducing
advanced continuous control research, such as learning to walk, run and
backflip from motion capture data; learning to navigate complex terrains; and
by implementing a video game input control system. We show further robustness
by training with alternative algorithms found in OpenAI.Baselines. Finally, we
share strategies for significantly reducing the training time.",2019-02-25,2019,2019-02,environment
Embedded Agency,"Traditional models of rational action treat the agent as though it is cleanly
separated from its environment, and can act on that environment from the
outside. Such agents have a known functional relationship with their
environment, can model their environment in every detail, and do not need to
reason about themselves or their internal parts.
  We provide an informal survey of obstacles to formalizing good reasoning for
agents embedded in their environment. Such agents must optimize an environment
that is not of type ""function""; they must rely on models that fit within the
modeled environment; and they must reason about themselves as just another
physical system, made of parts that can be modified and that can work at cross
purposes.",2019-02-25,2019,2019-02,environment
"Artificial Intelligence in Intelligent Tutoring Robots: A Systematic
  Review and Design Guidelines","This study provides a systematic review of the recent advances in designing
the intelligent tutoring robot (ITR), and summarises the status quo of applying
artificial intelligence (AI) techniques. We first analyse the environment of
the ITR and propose a relationship model for describing interactions of ITR
with the students, the social milieu and the curriculum. Then, we transform the
relationship model into the perception-planning-action model for exploring what
AI techniques are suitable to be applied in the ITR. This article provides
insights on promoting human-robot teaching-learning process and AI-assisted
educational techniques, illustrating the design guidelines and future research
perspectives in intelligent tutoring robots.",2019-02-26,2019,2019-02,environment
Intelligent Autonomous Things on the Battlefield,"Numerous, artificially intelligent, networked things will populate the
battlefield of the future, operating in close collaboration with human
warfighters, and fighting as teams in highly adversarial environments. This
chapter explores the characteristics, capabilities and intelli-gence required
of such a network of intelligent things and humans - Internet of Battle Things
(IOBT). The IOBT will experience unique challenges that are not yet well
addressed by the current generation of AI and machine learning.",2019-02-26,2019,2019-02,environment
A Strongly Asymptotically Optimal Agent in General Environments,"Reinforcement Learning agents are expected to eventually perform well.
Typically, this takes the form of a guarantee about the asymptotic behavior of
an algorithm given some assumptions about the environment. We present an
algorithm for a policy whose value approaches the optimal value with
probability 1 in all computable probabilistic environments, provided the agent
has a bounded horizon. This is known as strong asymptotic optimality, and it
was previously unknown whether it was possible for a policy to be strongly
asymptotically optimal in the class of all computable probabilistic
environments. Our agent, Inquisitive Reinforcement Learner (Inq), is more
likely to explore the more it expects an exploratory action to reduce its
uncertainty about which environment it is in, hence the term inquisitive.
Exploring inquisitively is a strategy that can be applied generally; for more
manageable environment classes, inquisitiveness is tractable. We conducted
experiments in ""grid-worlds"" to compare the Inquisitive Reinforcement Learner
to other weakly asymptotically optimal agents.",2019-03-04,2019,2019-03,environment
Dyna-AIL : Adversarial Imitation Learning by Planning,"Adversarial methods for imitation learning have been shown to perform well on
various control tasks. However, they require a large number of environment
interactions for convergence. In this paper, we propose an end-to-end
differentiable adversarial imitation learning algorithm in a Dyna-like
framework for switching between model-based planning and model-free learning
from expert data. Our results on both discrete and continuous environments show
that our approach of using model-based planning along with model-free learning
converges to an optimal policy with fewer number of environment interactions in
comparison to the state-of-the-art learning methods.",2019-03-08,2019,2019-03,environment
"VRKitchen: an Interactive 3D Virtual Environment for Task-oriented
  Learning","One of the main challenges of advancing task-oriented learning such as visual
task planning and reinforcement learning is the lack of realistic and
standardized environments for training and testing AI agents. Previously,
researchers often relied on ad-hoc lab environments. There have been recent
advances in virtual systems built with 3D physics engines and photo-realistic
rendering for indoor and outdoor environments, but the embodied agents in those
systems can only conduct simple interactions with the world (e.g., walking
around, moving objects, etc.). Most of the existing systems also do not allow
human participation in their simulated environments. In this work, we design
and implement a virtual reality (VR) system, VRKitchen, with integrated
functions which i) enable embodied agents powered by modern AI methods (e.g.,
planning, reinforcement learning, etc.) to perform complex tasks involving a
wide range of fine-grained object manipulations in a realistic environment, and
ii) allow human teachers to perform demonstrations to train agents (i.e.,
learning from demonstration). We also provide standardized evaluation
benchmarks and data collection tools to facilitate a broad use in research on
task-oriented learning and beyond.",2019-03-13,2019,2019-03,environment
Adaptive Variance for Changing Sparse-Reward Environments,"Robots that are trained to perform a task in a fixed environment often fail
when facing unexpected changes to the environment due to a lack of exploration.
We propose a principled way to adapt the policy for better exploration in
changing sparse-reward environments. Unlike previous works which explicitly
model environmental changes, we analyze the relationship between the value
function and the optimal exploration for a Gaussian-parameterized policy and
show that our theory leads to an effective strategy for adjusting the variance
of the policy, enabling fast adapt to changes in a variety of sparse-reward
environments.",2019-03-15,2019,2019-03,environment
"Inferring Compact Representations for Efficient Natural Language
  Understanding of Robot Instructions","The speed and accuracy with which robots are able to interpret natural
language is fundamental to realizing effective human-robot interaction. A great
deal of attention has been paid to developing models and approximate inference
algorithms that improve the efficiency of language understanding. However,
existing methods still attempt to reason over a representation of the
environment that is flat and unnecessarily detailed, which limits scalability.
An open problem is then to develop methods capable of producing the most
compact environment model sufficient for accurate and efficient natural
language understanding. We propose a model that leverages environment-related
information encoded within instructions to identify the subset of observations
and perceptual classifiers necessary to perceive a succinct,
instruction-specific environment representation. The framework uses three
probabilistic graphical models trained from a corpus of annotated instructions
to infer salient scene semantics, perceptual classifiers, and grounded symbols.
Experimental results on two robots operating in different environments
demonstrate that by exploiting the content and the structure of the
instructions, our method learns compact environment representations that
significantly improve the efficiency of natural language symbol grounding.",2019-03-21,2019,2019-03,environment
"Combining Offline Models and Online Monte-Carlo Tree Search for Planning
  from Scratch","Planning in stochastic and partially observable environments is a central
issue in artificial intelligence. One commonly used technique for solving such
a problem is by constructing an accurate model firstly. Although some recent
approaches have been proposed for learning optimal behaviour under model
uncertainty, prior knowledge about the environment is still needed to guarantee
the performance of the proposed algorithms. With the benefits of the Predictive
State Representations~(PSRs) approach for state representation and model
prediction, in this paper, we introduce an approach for planning from scratch,
where an offline PSR model is firstly learned and then combined with online
Monte-Carlo tree search for planning with model uncertainty. By comparing with
the state-of-the-art approach of planning with model uncertainty, we
demonstrated the effectiveness of the proposed approaches along with the proof
of their convergence. The effectiveness and scalability of our proposed
approach are also tested on the RockSample problem, which are infeasible for
the state-of-the-art BA-POMDP based approaches.",2019-04-05,2019,2019-04,environment
"Reinforcement Learning with Probabilistic Guarantees for Autonomous
  Driving","Designing reliable decision strategies for autonomous urban driving is
challenging. Reinforcement learning (RL) has been used to automatically derive
suitable behavior in uncertain environments, but it does not provide any
guarantee on the performance of the resulting policy. We propose a generic
approach to enforce probabilistic guarantees on an RL agent. An exploration
strategy is derived prior to training that constrains the agent to choose among
actions that satisfy a desired probabilistic specification expressed with
linear temporal logic (LTL). Reducing the search space to policies satisfying
the LTL formula helps training and simplifies reward design. This paper
outlines a case study of an intersection scenario involving multiple traffic
participants. The resulting policy outperforms a rule-based heuristic approach
in terms of efficiency while exhibiting strong guarantees on safety.",2019-04-15,2019,2019-04,environment
Object-Oriented Dynamics Learning through Multi-Level Abstraction,"Object-based approaches for learning action-conditioned dynamics has
demonstrated promise for generalization and interpretability. However, existing
approaches suffer from structural limitations and optimization difficulties for
common environments with multiple dynamic objects. In this paper, we present a
novel self-supervised learning framework, called Multi-level Abstraction
Object-oriented Predictor (MAOP), which employs a three-level learning
architecture that enables efficient object-based dynamics learning from raw
visual observations. We also design a spatial-temporal relational reasoning
mechanism for MAOP to support instance-level dynamics learning and handle
partial observability. Our results show that MAOP significantly outperforms
previous methods in terms of sample efficiency and generalization over novel
environments for learning environment models. We also demonstrate that learned
dynamics models enable efficient planning in unseen environments, comparable to
true environment models. In addition, MAOP learns semantically and visually
interpretable disentangled representations.",2019-04-16,2019,2019-04,environment
"Is coding a relevant metaphor for building AI? A commentary on ""Is
  coding a relevant metaphor for the brain?"", by Romain Brette","Brette contends that the neural coding metaphor is an invalid basis for
theories of what the brain does. Here, we argue that it is an insufficient
guide for building an artificial intelligence that learns to accomplish short-
and long-term goals in a complex, changing environment.",2019-04-18,2019,2019-04,environment
"An Efficient Reachability-Based Framework for Provably Safe Autonomous
  Navigation in Unknown Environments","Real-world autonomous vehicles often operate in a priori unknown
environments. Since most of these systems are safety-critical, it is important
to ensure they operate safely in the face of environment uncertainty, such as
unseen obstacles. Current safety analysis tools enable autonomous systems to
reason about safety given full information about the state of the environment a
priori. However, these tools do not scale well to scenarios where the
environment is being sensed in real time, such as during navigation tasks. In
this work, we propose a novel, real-time safety analysis method based on
Hamilton-Jacobi reachability that provides strong safety guarantees despite
environment uncertainty. Our safety method is planner-agnostic and provides
guarantees for a variety of mapping sensors. We demonstrate our approach in
simulation and in hardware to provide safety guarantees around a
state-of-the-art vision-based, learning-based planner.",2019-05-01,2019,2019-05,environment
"Design of Artificial Intelligence Agents for Games using Deep
  Reinforcement Learning","In order perform a large variety of tasks and to achieve human-level
performance in complex real-world environments, Artificial Intelligence (AI)
Agents must be able to learn from their past experiences and gain both
knowledge and an accurate representation of their environment from raw sensory
inputs. Traditionally, AI agents have suffered from difficulties in using only
sensory inputs to obtain a good representation of their environment and then
mapping this representation to an efficient control policy. Deep reinforcement
learning algorithms have provided a solution to this issue. In this study, the
performance of different conventional and novel deep reinforcement learning
algorithms was analysed. The proposed method utilises two types of algorithms,
one trained with a variant of Q-learning (DQN) and another trained with SARSA
learning (DSN) to assess the feasibility of using direct feedback alignment, a
novel biologically plausible method for back-propagating the error. These novel
agents, alongside two similar agents trained with the conventional
backpropagation algorithm, were tested by using the OpenAI Gym toolkit on
several classic control theory problems and Atari 2600 video games. The results
of this investigation open the way into new, biologically-inspired deep
reinforcement learning algorithms, and their implementation on neuromorphic
hardware.",2019-05-10,2019,2019-05,environment
Attention-based Deep Reinforcement Learning for Multi-view Environments,"In reinforcement learning algorithms, it is a common practice to account for
only a single view of the environment to make the desired decisions; however,
utilizing multiple views of the environment can help to promote the learning of
complicated policies. Since the views may frequently suffer from partial
observability, their provided observation can have different levels of
importance. In this paper, we present a novel attention-based deep
reinforcement learning method in a multi-view environment in which each view
can provide various representative information about the environment.
Specifically, our method learns a policy to dynamically attend to views of the
environment based on their importance in the decision-making process. We
evaluate the performance of our method on TORCS racing car simulator and three
other complex 3D environments with obstacles.",2019-05-10,2019,2019-05,environment
Randomized Adversarial Imitation Learning for Autonomous Driving,"With the evolution of various advanced driver assistance system (ADAS)
platforms, the design of autonomous driving system is becoming more complex and
safety-critical. The autonomous driving system simultaneously activates
multiple ADAS functions; and thus it is essential to coordinate various ADAS
functions. This paper proposes a randomized adversarial imitation learning
(RAIL) method that imitates the coordination of autonomous vehicle equipped
with advanced sensors. The RAIL policies are trained through derivative-free
optimization for the decision maker that coordinates the proper ADAS functions,
e.g., smart cruise control and lane keeping system. Especially, the proposed
method is also able to deal with the LIDAR data and makes decisions in complex
multi-lane highways and multi-agent environments.",2019-05-13,2019,2019-05,environment
Autonomous Penetration Testing using Reinforcement Learning,"Penetration testing (pentesting) involves performing a controlled attack on a
computer system in order to assess it's security. Although an effective method
for testing security, pentesting requires highly skilled practitioners and
currently there is a growing shortage of skilled cyber security professionals.
One avenue for alleviating this problem is automate the pentesting process
using artificial intelligence techniques. Current approaches to automated
pentesting have relied on model-based planning, however the cyber security
landscape is rapidly changing making maintaining up-to-date models of exploits
a challenge. This project investigated the application of model-free
Reinforcement Learning (RL) to automated pentesting. Model-free RL has the key
advantage over model-based planning of not requiring a model of the
environment, instead learning the best policy through interaction with the
environment. We first designed and built a fast, low compute simulator for
training and testing autonomous pentesting agents. We did this by framing
pentesting as a Markov Decision Process with the known configuration of the
network as states, the available scans and exploits as actions, the reward
determined by the value of machines on the network. We then used this simulator
to investigate the application of model-free RL to pentesting. We tested the
standard Q-learning algorithm using both tabular and neural network based
implementations. We found that within the simulated environment both tabular
and neural network implementations were able to find optimal attack paths for a
range of different network topologies and sizes without having a model of
action behaviour. However, the implemented algorithms were only practical for
smaller networks and numbers of actions. Further work is needed in developing
scalable RL algorithms and testing these algorithms in larger and higher
fidelity environments.",2019-05-15,2019,2019-05,environment
"Reinforcement Learning for Learning of Dynamical Systems in Uncertain
  Environment: a Tutorial","In this paper, a review of model-free reinforcement learning for learning of
dynamical systems in uncertain environments has discussed. For this purpose,
the Markov Decision Process (MDP) will be reviewed. Furthermore, some learning
algorithms such as Temporal Difference (TD) learning, Q-Learning, and
Approximate Q-learning as model-free algorithms which constitute the main part
of this article have been investigated, and benefits and drawbacks of each
algorithm will be discussed. The discussed concepts in each section are
explaining with details and examples.",2019-05-19,2019,2019-05,environment
"COBRA: Data-Efficient Model-Based RL through Unsupervised Object
  Discovery and Curiosity-Driven Exploration","Data efficiency and robustness to task-irrelevant perturbations are
long-standing challenges for deep reinforcement learning algorithms. Here we
introduce a modular approach to addressing these challenges in a continuous
control environment, without using hand-crafted or supervised information. Our
Curious Object-Based seaRch Agent (COBRA) uses task-free intrinsically
motivated exploration and unsupervised learning to build object-based models of
its environment and action space. Subsequently, it can learn a variety of tasks
through model-based search in very few steps and excel on structured hold-out
tests of policy robustness.",2019-05-22,2019,2019-05,environment
Deploying AI Frameworks on Secure HPC Systems with Containers,"The increasing interest in the usage of Artificial Intelligence techniques
(AI) from the research community and industry to tackle ""real world"" problems,
requires High Performance Computing (HPC) resources to efficiently compute and
scale complex algorithms across thousands of nodes. Unfortunately, typical data
scientists are not familiar with the unique requirements and characteristics of
HPC environments. They usually develop their applications with high-level
scripting languages or frameworks such as TensorFlow and the installation
process often requires connection to external systems to download open source
software during the build. HPC environments, on the other hand, are often based
on closed source applications that incorporate parallel and distributed
computing API's such as MPI and OpenMP, while users have restricted
administrator privileges, and face security restrictions such as not allowing
access to external systems. In this paper we discuss the issues associated with
the deployment of AI frameworks in a secure HPC environment and how we
successfully deploy AI frameworks on SuperMUC-NG with Charliecloud.",2019-05-24,2019,2019-05,environment
"Cognitively-inspired Agent-based Service Composition for Mobile &
  Pervasive Computing","Automatic service composition in mobile and pervasive computing faces many
challenges due to the complex and highly dynamic nature of the environment.
Common approaches consider service composition as a decision problem whose
solution is usually addressed from optimization perspectives which are not
feasible in practice due to the intractability of the problem, limited
computational resources of smart devices, service host's mobility, and time
constraints to tailor composition plans. Thus, our main contribution is the
development of a cognitively-inspired agent-based service composition model
focused on bounded rationality rather than optimality, which allows the system
to compensate for limited resources by selectively filtering out continuous
streams of data. Our approach exhibits features such as distributedness,
modularity, emergent global functionality, and robustness, which endow it with
capabilities to perform decentralized service composition by orchestrating
manifold service providers and conflicting goals from multiple users. The
evaluation of our approach shows promising results when compared against
state-of-the-art service composition models.",2019-05-29,2019,2019-05,environment
Advantage Amplification in Slowly Evolving Latent-State Environments,"Latent-state environments with long horizons, such as those faced by
recommender systems, pose significant challenges for reinforcement learning
(RL). In this work, we identify and analyze several key hurdles for RL in such
environments, including belief state error and small action advantage. We
develop a general principle of advantage amplification that can overcome these
hurdles through the use of temporal abstraction. We propose several aggregation
methods and prove they induce amplification in certain settings. We also bound
the loss in optimality incurred by our methods in environments where latent
state evolves slowly and demonstrate their performance empirically in a
stylized user-modeling task.",2019-05-29,2019,2019-05,environment
"Smart Sustainable Agriculture (SSA) Solution Underpinned by Internet of
  Things (IoT) and Artificial Intelligence (AI)","The Internet of Things (IoT) and Artificial Intelligence (AI) have been
employed in agriculture over a long period of time, alongside other advanced
computing technologies. However, increased attention is currently being paid to
the use of such smart technologies. Agriculture has provided an important
source of food for human beings over many thousands of years, including the
development of appropriate farming methods for different types of crops. The
emergence of new advanced IoT technologies has the potential to monitor the
agricultural environment to ensure high-quality products. However, there
remains a lack of research and development in relation to Smart Sustainable
Agriculture (SSA), accompanied by complex obstacles arising from the
fragmentation of agricultural processes, i.e. the control and operation of
IoT/AI machines; data sharing and management; interoperability; and large
amounts of data analysis and storage. This study firstly, explores existing
IoT/AI technologies adopted for SSA and secondly, identifies IoT/AI technical
architecture capable of underpinning the development of SSA platforms. As well
as contributing to the current body of knowledge, this research reviews
research and development within SSA and provides an IoT/AI architecture to
establish a Smart, Sustainable Agriculture platform as a solution.",2019-05-30,2019,2019-05,environment
2019 Evolutionary Algorithms Review,"Evolutionary algorithm research and applications began over 50 years ago.
Like other artificial intelligence techniques, evolutionary algorithms will
likely see increased use and development due to the increased availability of
computation, more robust and available open source software libraries, and the
increasing demand for artificial intelligence techniques. As these techniques
become more adopted and capable, it is the right time to take a perspective of
their ability to integrate into society and the human processes they intend to
augment. In this review, we explore a new taxonomy of evolutionary algorithms
and resulting classifications that look at five main areas: the ability to
manage the control of the environment with limiters, the ability to explain and
repeat the search process, the ability to understand input and output causality
within a solution, the ability to manage algorithm bias due to data or user
design, and lastly, the ability to add corrective measures. These areas are
motivated by today's pressures on industry to conform to both societies
concerns and new government regulatory rules. As many reviews of evolutionary
algorithms exist, after motivating this new taxonomy, we briefly classify a
broad range of algorithms and identify areas of future research.",2019-06-03,2019,2019-06,environment
"Escaping the State of Nature: A Hobbesian Approach to Cooperation in
  Multi-agent Reinforcement Learning","Cooperation is a phenomenon that has been widely studied across many
different disciplines. In the field of computer science, the modularity and
robustness of multi-agent systems offer significant practical advantages over
individual machines. At the same time, agents using standard reinforcement
learning algorithms often fail to achieve long-term, cooperative strategies in
unstable environments when there are short-term incentives to defect. Political
philosophy, on the other hand, studies the evolution of cooperation in humans
who face similar incentives to act individualistically, but nevertheless
succeed in forming societies. Thomas Hobbes in Leviathan provides the classic
analysis of the transition from a pre-social State of Nature, where consistent
defection results in a constant state of war, to stable political community
through the institution of an absolute Sovereign. This thesis argues that
Hobbes's natural and moral philosophy are strikingly applicable to artificially
intelligent agents and aims to show that his political solutions are
experimentally successful in producing cooperation among modified Q-Learning
agents. Cooperative play is achieved in a novel Sequential Social Dilemma
called the Civilization Game, which models the State of Nature by introducing
the Hobbesian mechanisms of opponent learning awareness and majoritarian
voting, leading to the establishment of a Sovereign.",2019-06-05,2019,2019-06,environment
Shaping Belief States with Generative Environment Models for RL,"When agents interact with a complex environment, they must form and maintain
beliefs about the relevant aspects of that environment. We propose a way to
efficiently train expressive generative models in complex environments. We show
that a predictive algorithm with an expressive generative model can form stable
belief-states in visually rich and dynamic 3D environments. More precisely, we
show that the learned representation captures the layout of the environment as
well as the position and orientation of the agent. Our experiments show that
the model substantially improves data-efficiency on a number of reinforcement
learning (RL) tasks compared with strong model-free baseline agents. We find
that predicting multiple steps into the future (overshooting), in combination
with an expressive generative model, is critical for stable representations to
emerge. In practice, using expressive generative models in RL is
computationally expensive and we propose a scheme to reduce this computational
burden, allowing us to build agents that are competitive with model-free
baselines.",2019-06-21,2019,2019-06,environment
"Developing an App to interpret Chest X-rays to support the diagnosis of
  respiratory pathology with Artificial Intelligence","In this paper we present our work to improve access to diagnosis in remote
areas where good quality medical services may be lacking. We develop new
Machine Learning methodologies for deployment onto mobile devices to help the
early diagnosis of a number of life-threatening conditions using X-ray images.
By using the latest developments in fast and portable Artificial Intelligence
environments, we develop a smartphone app using an Artificial Neural Network to
assist physicians in their diagnostic.",2019-06-26,2019,2019-06,environment
Automated Gaming Pommerman: FFA,"Our game Pommerman is based on the console game Bommerman. The game starts on
an 11 by 11 platform. Pommerman is a multi-agent environment and is made up of
a set of different situations and contains four agents.",2019-07-13,2019,2019-07,environment
"An Actor-Critic-Attention Mechanism for Deep Reinforcement Learning in
  Multi-view Environments","In reinforcement learning algorithms, leveraging multiple views of the
environment can improve the learning of complicated policies. In multi-view
environments, due to the fact that the views may frequently suffer from partial
observability, their level of importance are often different. In this paper, we
propose a deep reinforcement learning method and an attention mechanism in a
multi-view environment. Each view can provide various representative
information about the environment. Through our attention mechanism, our method
generates a single feature representation of environment given its multiple
views. It learns a policy to dynamically attend to each view based on its
importance in the decision-making process. Through experiments, we show that
our method outperforms its state-of-the-art baselines on TORCS racing car
simulator and three other complex 3D environments with obstacles. We also
provide experimental results to evaluate the performance of our method on noisy
conditions and partial observation settings.",2019-07-19,2019,2019-07,environment
"Pre-Learning Environment Representations for Data-Efficient Neural
  Instruction Following","We consider the problem of learning to map from natural language instructions
to state transitions (actions) in a data-efficient manner. Our method takes
inspiration from the idea that it should be easier to ground language to
concepts that have already been formed through pre-linguistic observation. We
augment a baseline instruction-following learner with an initial
environment-learning phase that uses observations of language-free state
transitions to induce a suitable latent representation of actions before
processing the instruction-following training data. We show that mapping to
pre-learned representations substantially improves performance over systems
whose representations are learned from limited instructional data alone.",2019-07-23,2019,2019-07,environment
Environment Probing Interaction Policies,"A key challenge in reinforcement learning (RL) is environment generalization:
a policy trained to solve a task in one environment often fails to solve the
same task in a slightly different test environment. A common approach to
improve inter-environment transfer is to learn policies that are invariant to
the distribution of testing environments. However, we argue that instead of
being invariant, the policy should identify the specific nuances of an
environment and exploit them to achieve better performance. In this work, we
propose the 'Environment-Probing' Interaction (EPI) policy, a policy that
probes a new environment to extract an implicit understanding of that
environment's behavior. Once this environment-specific information is obtained,
it is used as an additional input to a task-specific policy that can now
perform environment-conditioned actions to solve a task. To learn these
EPI-policies, we present a reward function based on transition predictability.
Specifically, a higher reward is given if the trajectory generated by the
EPI-policy can be used to better predict transitions. We experimentally show
that EPI-conditioned task-specific policies significantly outperform commonly
used policy generalization methods on novel testing environments.",2019-07-26,2019,2019-07,environment
"Multi-node environment strategy for Parallel Deterministic
  Multi-Objective Fractal Decomposition","This paper presents a new implementation of deterministic multiobjective (MO)
optimization called Multiobjective Fractal Decomposition Algorithm (Mo-FDA).
The original algorithm was designed for mono-objective large scale continuous
optimization problems. It is based on a divide and conquer strategy and a
geometric fractal decomposition of the search space using hyperspheres. Then,
to deal with MO problems a scalarization approach is used. In this work, a new
approach has been developed on a multi-node environment using containers. The
performance of Mo-FDA was compared to state of the art algorithms from the
literature on classical benchmark of multi-objective optimization",2019-08-04,2019,2019-08,environment
DoorGym: A Scalable Door Opening Environment And Baseline Agent,"In order to practically implement the door opening task, a policy ought to be
robust to a wide distribution of door types and environment settings.
Reinforcement Learning (RL) with Domain Randomization (DR) is a promising
technique to enforce policy generalization, however, there are only a few
accessible training environments that are inherently designed to train agents
in domain randomized environments. We introduce DoorGym, an open-source door
opening simulation framework designed to utilize domain randomization to train
a stable policy. We intend for our environment to lie at the intersection of
domain transfer, practical tasks, and realism. We also provide baseline
Proximal Policy Optimization and Soft Actor-Critic implementations, which
achieves success rates between 0% up to 95% for opening various types of doors
in this environment. Moreover, the real-world transfer experiment shows the
trained policy is able to work in the real world. Environment kit available
here: https://github.com/PSVL/DoorGym/",2019-08-05,2019,2019-08,environment
"Decision making in dynamic and interactive environments based on
  cognitive hierarchy theory, Bayesian inference, and predictive control","In this paper, we describe an integrated framework for autonomous decision
making in a dynamic and interactive environment. We model the interactions
between the ego agent and its operating environment as a two-player dynamic
game, and integrate cognitive behavioral models, Bayesian inference, and
receding-horizon optimal control to define a dynamically-evolving decision
strategy for the ego agent. Simulation examples representing autonomous vehicle
control in three traffic scenarios where the autonomous ego vehicle interacts
with a human-driven vehicle are reported.",2019-08-12,2019,2019-08,environment
"From Crystallized Adaptivity to Fluid Adaptivity in Deep Reinforcement
  Learning -- Insights from Biological Systems on Adaptive Flexibility","Recent developments in machine-learning algorithms have led to impressive
performance increases in many traditional application scenarios of artificial
intelligence research. In the area of deep reinforcement learning, deep
learning functional architectures are combined with incremental learning
schemes for sequential tasks that include interaction-based, but often delayed
feedback. Despite their impressive successes, modern machine-learning
approaches, including deep reinforcement learning, still perform weakly when
compared to flexibly adaptive biological systems in certain naturally occurring
scenarios. Such scenarios include transfers to environments different than the
ones in which the training took place or environments that dynamically change,
both of which are often mastered by biological systems through a capability
that we here term ""fluid adaptivity"" to contrast it from the much slower
adaptivity (""crystallized adaptivity"") of the prior learning from which the
behavior emerged. In this article, we derive and discuss research strategies,
based on analyzes of fluid adaptivity in biological systems and its neuronal
modeling, that might aid in equipping future artificially intelligent systems
with capabilities of fluid adaptivity more similar to those seen in some
biologically intelligent systems. A key component of this research strategy is
the dynamization of the problem space itself and the implementation of this
dynamization by suitably designed flexibly interacting modules.",2019-08-13,2019,2019-08,environment
"Simulation Model of Two-Robot Cooperation in Common Operating
  Environment","The article considers a simulation modelling problem related to the chess
game process occurring between two three-tier manipulators. The objective of
the game construction lies in developing the procedure of effective control of
the autonomous manipulator robots located in a common operating environment.
The simulation model is a preliminary stage of building a natural complex that
would provide cooperation of several manipulator robots within a common
operating environment. The article addresses issues of training and research.",2019-08-22,2019,2019-08,environment
Dynamics-aware Embeddings,"In this paper we consider self-supervised representation learning to improve
sample efficiency in reinforcement learning (RL). We propose a forward
prediction objective for simultaneously learning embeddings of states and
action sequences. These embeddings capture the structure of the environment's
dynamics, enabling efficient policy learning. We demonstrate that our action
embeddings alone improve the sample efficiency and peak performance of
model-free RL on control from low-dimensional states. By combining state and
action embeddings, we achieve efficient learning of high-quality policies on
goal-conditioned continuous control from pixel observations in only 1-2 million
environment steps.",2019-08-25,2019,2019-08,environment
Artificial Intelligence Approaches,"Artificial Intelligence (AI) has received tremendous attention from academia,
industry, and the general public in recent years. The integration of geography
and AI, or GeoAI, provides novel approaches for addressing a variety of
problems in the natural environment and our human society. This entry briefly
reviews the recent development of AI with a focus on machine learning and deep
learning approaches. We discuss the integration of AI with geography and
particularly geographic information science, and present a number of GeoAI
applications and possible future directions.",2019-08-27,2019,2019-08,environment
A Multimodal Alerting System for Online Class Quality Assurance,"Online 1 on 1 class is created for more personalized learning experience. It
demands a large number of teaching resources, which are scarce in China. To
alleviate this problem, we build a platform (marketplace), i.e., \emph{Dahai}
to allow college students from top Chinese universities to register as
part-time instructors for the online 1 on 1 classes. To warn the unqualified
instructors and ensure the overall education quality, we build a monitoring and
alerting system by utilizing multimodal information from the online
environment. Our system mainly consists of two key components: banned word
detector and class quality predictor. The system performance is demonstrated
both offline and online. By conducting experimental evaluation of real-world
online courses, we are able to achieve 74.3\% alerting accuracy in our
production environment.",2019-09-01,2019,2019-09,environment
"Calibrating Wayfinding Decisions in Pedestrian Simulation Models: The
  Entropy Map","This paper presents entropy maps, an approach to describing and visualising
uncertainty among alternative potential movement intentions in pedestrian
simulation models. In particular, entropy maps show the instantaneous level of
randomness in decisions of a pedestrian agent situated in a specific point of
the simulated environment with an heatmap approach. Experimental results
highlighting the relevance of this tool supporting modelers are provided and
discussed.",2019-09-06,2019,2019-09,environment
"Agora: A Unified Asset Ecosystem Going Beyond Marketplaces and Cloud
  Services","Data, algorithms, and compute/storage infrastructure are key assets that
drive data science and artificial intelligence applications. As providing all
these assets requires a huge investment, data science and artificial
intelligence technologies are currently dominated by a small number of
providers who can afford these investments. This leads to lock-in effects and
hinders features that require a flexible exchange of assets among users. In
this vision paper, we present Agora, a unified asset ecosystem. The Agora
system provides the technical infrastructure that allows for offering and using
data and algorithms, as well as physical infrastructure components. Agora is
designed as an open ecosystem of asset marketplaces and provides to a broad
audience not only data but the entire data value chain (including computational
resources and human expertise). Agora (i) leverages a fine-grained exchange of
assets, (ii) allows for combining assets to novel applications, and (iii)
flexibly executes such applications on available resources. As a result, Agora
overcomes lock-in effects and removes entry barriers for new asset providers.
In contrast to existing data management systems, Agora operates in a heavily
decentralized and dynamic environment: Data, algorithms, and even compute
resources are dynamically created, modified, and removed by different
stakeholders. Agora presents novel research directions for the data management
community as a whole: It requires to combine our traditional expertise in
scalable data processing and management with infrastructure provisioning as
well as economic and application aspects of data, algorithms, and
infrastructure.",2019-09-06,2019,2019-09,environment
"The Animal-AI Environment: Training and Testing Animal-Like Artificial
  Cognition","Recent advances in artificial intelligence have been strongly driven by the
use of game environments for training and evaluating agents. Games are often
accessible and versatile, with well-defined state-transitions and goals
allowing for intensive training and experimentation. However, agents trained in
a particular environment are usually tested on the same or slightly varied
distributions, and solutions do not necessarily imply any understanding. If we
want AI systems that can model and understand their environment, we need
environments that explicitly test for this. Inspired by the extensive
literature on animal cognition, we present an environment that keeps all the
positive elements of standard gaming environments, but is explicitly designed
for the testing of animal-like artificial cognition.",2019-09-12,2019,2019-09,environment
"Towards Sharing Task Environments to Support Reproducible Evaluations of
  Interactive Recommender Systems","Beyond sharing datasets or simulations, we believe the Recommender Systems
(RS) community should share Task Environments. In this work, we propose a
high-level logical architecture that will help to reason about the core
components of a RS Task Environment, identify the differences between
Environments, datasets and simulations; and most importantly, understand what
needs to be shared about Environments to achieve reproducible experiments. The
work presents itself as valuable initial groundwork, open to discussion and
extensions.",2019-09-13,2019,2019-09,environment
Responsive Planning and Recognition for Closed-Loop Interaction,"Many intelligent systems currently interact with others using at least one of
fixed communication inputs or preset responses, resulting in rigid interaction
experiences and extensive efforts developing a variety of scenarios for the
system. Fixed inputs limit the natural behavior of the user in order to
effectively communicate, and preset responses prevent the system from adapting
to the current situation unless it was specifically implemented. Closed-loop
interaction instead focuses on dynamic responses that account for what the user
is currently doing based on interpretations of their perceived activity. Agents
employing closed-loop interaction can also monitor their interactions to ensure
that the user responds as expected. We introduce a closed-loop interactive
agent framework that integrates planning and recognition to predict what the
user is trying to accomplish and autonomously decide on actions to take in
response to these predictions. Based on a recent demonstration of such an
assistive interactive agent in a turn-based simulated game, we also discuss new
research challenges that are not present in the areas of artificial
intelligence planning or recognition alone.",2019-09-13,2019,2019-09,environment
MDP Playground: An Analysis and Debug Testbed for Reinforcement Learning,"We present MDP Playground, a testbed for Reinforcement Learning (RL) agents
with dimensions of hardness that can be controlled independently to challenge
agents in different ways and obtain varying degrees of hardness in toy and
complex RL environments. We consider and allow control over a wide variety of
dimensions, including delayed rewards, sequence lengths, reward density,
stochasticity, image representations, irrelevant features, time unit, action
range and more. We define a parameterised collection of fast-to-run toy
environments in OpenAI Gym by varying these dimensions and propose to use these
to understand agents better. We then show how to design experiments using MDP
Playground to gain insights on the toy environments. We also provide wrappers
that can inject many of these dimensions into any Gym environment. We
experiment with these wrappers on Atari and Mujoco to allow for understanding
the effects of these dimensions on environments that are more complex than the
toy environments. We also compare the effect of the dimensions on the toy and
complex environments. Finally, we show how to use MDP Playground to debug
agents, to study the interaction of multiple dimensions and describe further
use-cases.",2019-09-17,2019,2019-09,environment
Reasoning in Highly Reactive Environments,"The aim of my Ph.D. thesis concerns Reasoning in Highly Reactive
Environments. As reasoning in highly reactive environments, we identify the
setting in which a knowledge-based agent, with given goals, is deployed in an
environment subject to repeated, sudden and possibly unknown changes. This is
for instance the typical setting in which, e.g., artificial agents for
video-games (the so called ""bots""), cleaning robots, bomb clearing robots, and
so on are deployed. In all these settings one can follow the classical approach
in which the operations of the agent are distinguished in ""sensing"" the
environment with proper interface devices, ""thinking"", and then behaving
accordingly using proper actuators. In order to operate in an highly reactive
environment, an artificial agent needs to be: 1. Responsive -> The agent must
be able to react repeatedly and in a reasonable amount of time; 2. Elastic ->
The agent must stay reactive also under varying workload; 3. Resilient -> The
agent must stay responsive also in case of internal failure or failure of one
of the programmed actions in the environment. Nowadays, thanks to new
technologies in the field of Artificial Intelligence, it is already technically
possible to create AI agents that are able to operate in reactive environments.
Nevertheless, several issues stay unsolved, and are subject of ongoing
research.",2019-09-18,2019,2019-09,environment
Deep Q-Network for Angry Birds,"Angry Birds is a popular video game in which the player is provided with a
sequence of birds to shoot from a slingshot. The task of the game is to destroy
all green pigs with maximum possible score. Angry Birds appears to be a
difficult task to solve for artificially intelligent agents due to the
sequential decision-making, non-deterministic game environment, enormous state
and action spaces and requirement to differentiate between multiple birds,
their abilities and optimum tapping times. We describe the application of Deep
Reinforcement learning by implementing Double Dueling Deep Q-network to play
Angry Birds game. One of our main goals was to build an agent that is able to
compete with previous participants and humans on the first 21 levels. In order
to do so, we have collected a dataset of game frames that we used to train our
agent on. We present different approaches and settings for DQN agent. We
evaluate our agent using results of the previous participants of AIBirds
competition, results of volunteer human players and present the results of
AIBirds 2018 competition.",2019-10-04,2019,2019-10,environment
"Using AI/ML to gain situational understanding from passive network
  observations","The data available in the network traffic fromany Government building
contains a significant amount ofinformation. An analysis of the traffic can
yield insightsand situational understanding about what is happening inthe
building. However, the use of traditional network packet inspection, either
deep or shallow, is useful for only a limited understanding of the environment,
with applicability limited to some aspects of network and security management.
If weuse AI/ML based techniques to understand the network traffic, we can gain
significant insights which increase our situational awareness of what is
happening in the environment.At IBM, we have created a system which uses a
combination of network domain knowledge and machine learning techniques to
convert network traffic into actionable insights about the on premise
environment. These insights include characterization of the communicating
devices, discovering unauthorized devices that may violate policy requirements,
identifying hidden components and vulnerability points, detecting leakage of
sensitive information, and identifying the presence of people and devices.In
this paper, we will describe the overall design of this system, the major
use-cases that have been identified for it, and the lessons learnt when
deploying this system for some of those use-cases",2019-10-14,2019,2019-10,environment
"How a minimal learning agent can infer the existence of unobserved
  variables in a complex environment","According to a mainstream position in contemporary cognitive science and
philosophy, the use of abstract compositional concepts is both a necessary and
a sufficient condition for the presence of genuine thought. In this article, we
show how the ability to develop and utilise abstract conceptual structures can
be achieved by a particular kind of learning agents. More specifically, we
provide and motivate a concrete operational definition of what it means for
these agents to be in possession of abstract concepts, before presenting an
explicit example of a minimal architecture that supports this capability. We
then proceed to demonstrate how the existence of abstract conceptual structures
can be operationally useful in the process of employing previously acquired
knowledge in the face of new experiences, thereby vindicating the natural
conjecture that the cognitive functions of abstraction and generalisation are
closely related.
  Keywords: concept formation, projective simulation, reinforcement learning,
transparent artificial intelligence, theory formation, explainable artificial
intelligence (XAI)",2019-10-15,2019,2019-10,environment
Explainable Semantic Mapping for First Responders,"One of the key challenges in the semantic mapping problem in postdisaster
environments is how to analyze a large amount of data efficiently with minimal
supervision. To address this challenge, we propose a deep learning-based
semantic mapping tool consisting of three main ideas. First, we develop a
frugal semantic segmentation algorithm that uses only a small amount of labeled
data. Next, we investigate on the problem of learning to detect a new class of
object using just a few training examples. Finally, we develop an explainable
cost map learning algorithm that can be quickly trained to generate
traversability cost maps using only raw sensor data such as aerial-view
imagery. This paper presents an overview of the proposed idea and the lessons
learned.",2019-10-15,2019,2019-10,environment
RTFM: Generalising to Novel Environment Dynamics via Reading,"Obtaining policies that can generalise to new environments in reinforcement
learning is challenging. In this work, we demonstrate that language
understanding via a reading policy learner is a promising vehicle for
generalisation to new environments. We propose a grounded policy learning
problem, Read to Fight Monsters (RTFM), in which the agent must jointly reason
over a language goal, relevant dynamics described in a document, and
environment observations. We procedurally generate environment dynamics and
corresponding language descriptions of the dynamics, such that agents must read
to understand new environment dynamics instead of memorising any particular
information. In addition, we propose txt2$\pi$, a model that captures three-way
interactions between the goal, document, and observations. On RTFM, txt2$\pi$
generalises to new environments with dynamics not seen during training via
reading. Furthermore, our model outperforms baselines such as FiLM and
language-conditioned CNNs on RTFM. Through curriculum learning, txt2$\pi$
produces policies that excel on complex RTFM tasks requiring several reasoning
and coreference steps.",2019-10-18,2019,2019-10,environment
Robot-Friendly Cities,"Robots are increasingly tested in public spaces, towards a future where urban
environments are not only for humans but for autonomous systems. While robots
are promising, for convenience and efficiency, there are challenges associated
with building cities crowded with machines. This paper provides an overview of
the problems and some solutions, and calls for greater attention on this
matter.",2019-10-22,2019,2019-10,environment
"Robotic Hierarchical Graph Neurons. A novel implementation of HGN for
  swarm robotic behaviour control","This paper explores the use of a novel form of Hierarchical Graph Neurons
(HGN) for in-operation behaviour selection in a swarm of robotic agents. This
new HGN is called Robotic-HGN (R-HGN), as it matches robot environment
observations to environment labels via fusion of match probabilities from both
temporal and intra-swarm collections. This approach is novel for HGN as it
addresses robotic observations being pseudo-continuous numbers, rather than
categorical values. Additionally, the proposed approach is memory and
computation-power conservative and thus is acceptable for use in mobile devices
such as single-board computers, which are often used in mobile robotic agents.
This R-HGN approach is validated against individual behaviour implementation
and random behaviour selection. This contrast is made in two sets of simulated
environments: environments designed to challenge the held behaviours of the
R-HGN, and randomly generated environments which are more challenging for the
robotic swarm than R-HGN training conditions. R-HGN has been found to enable
appropriate behaviour selection in both these sets, allowing significant swarm
performance in pre-trained and unexpected environment conditions.",2019-10-28,2019,2019-10,environment
RBED: Reward Based Epsilon Decay,"$\varepsilon$-greedy is a policy used to balance exploration and exploitation
in many reinforcement learning setting. In cases where the agent uses some
on-policy algorithm to learn optimal behaviour, it makes sense for the agent to
explore more initially and eventually exploit more as it approaches the target
behaviour. This shift from heavy exploration to heavy exploitation can be
represented as decay in the $\varepsilon$ value, where $\varepsilon$ depicts
the how much an agent is allowed to explore. This paper proposes a new approach
to this $\varepsilon$ decay where the decay is based on feedback from the
environment. This paper also compares and contrasts one such approach based on
rewards and compares it against standard exponential decay. The new approach,
in the environments tested, produces more consistent results that on average
perform better.",2019-10-30,2019,2019-10,environment
"Continuous Control with Contexts, Provably","A fundamental challenge in artificial intelligence is to build an agent that
generalizes and adapts to unseen environments. A common strategy is to build a
decoder that takes the context of the unseen new environment as input and
generates a policy accordingly. The current paper studies how to build a
decoder for the fundamental continuous control task, linear quadratic regulator
(LQR), which can model a wide range of real-world physical environments. We
present a simple algorithm for this problem, which uses upper confidence bound
(UCB) to refine the estimate of the decoder and balance the
exploration-exploitation trade-off. Theoretically, our algorithm enjoys a
$\widetilde{O}\left(\sqrt{T}\right)$ regret bound in the online setting where
$T$ is the number of environments the agent played. This also implies after
playing $\widetilde{O}\left(1/\epsilon^2\right)$ environments, the agent is
able to transfer the learned knowledge to obtain an $\epsilon$-suboptimal
policy for an unseen environment. To our knowledge, this is first provably
efficient algorithm to build a decoder in the continuous control setting. While
our main focus is theoretical, we also present experiments that demonstrate the
effectiveness of our algorithm.",2019-10-30,2019,2019-10,environment
"A Perceived Environment Design using a Multi-Modal Variational
  Autoencoder for learning Active-Sensing","This contribution comprises the interplay between a multi-modal variational
autoencoder and an environment to a perceived environment, on which an agent
can act. Furthermore, we conclude our work with a comparison to
curiosity-driven learning.",2019-11-01,2019,2019-11,environment
"Artificial Intelligence Strategies for National Security and Safety
  Standards","Recent advances in artificial intelligence (AI) have lead to an explosion of
multimedia applications (e.g., computer vision (CV) and natural language
processing (NLP)) for different domains such as commercial, industrial, and
intelligence. In particular, the use of AI applications in a national security
environment is often problematic because the opaque nature of the systems leads
to an inability for a human to understand how the results came about. A
reliance on 'black boxes' to generate predictions and inform decisions is
potentially disastrous. This paper explores how the application of standards
during each stage of the development of an AI system deployed and used in a
national security environment would help enable trust. Specifically, we focus
on the standards outlined in Intelligence Community Directive 203 (Analytic
Standards) to subject machine outputs to the same rigorous standards as
analysis performed by humans.",2019-11-03,2019,2019-11,environment
Being Optimistic to Be Conservative: Quickly Learning a CVaR Policy,"While maximizing expected return is the goal in most reinforcement learning
approaches, risk-sensitive objectives such as conditional value at risk (CVaR)
are more suitable for many high-stakes applications. However, relatively little
is known about how to explore to quickly learn policies with good CVaR. In this
paper, we present the first algorithm for sample-efficient learning of
CVaR-optimal policies in Markov decision processes based on the optimism in the
face of uncertainty principle. This method relies on a novel optimistic version
of the distributional Bellman operator that moves probability mass from the
lower to the upper tail of the return distribution. We prove asymptotic
convergence and optimism of this operator for the tabular policy evaluation
case. We further demonstrate that our algorithm finds CVaR-optimal policies
substantially faster than existing baselines in several simulated environments
with discrete and continuous state spaces.",2019-11-05,2019,2019-11,environment
"SIMMC: Situated Interactive Multi-Modal Conversational Data Collection
  And Evaluation Platform","As digital virtual assistants become ubiquitous, it becomes increasingly
important to understand the situated behaviour of users as they interact with
these assistants. To this end, we introduce SIMMC, an extension to ParlAI for
multi-modal conversational data collection and system evaluation. SIMMC
simulates an immersive setup, where crowd workers are able to interact with
environments constructed in AI Habitat or Unity while engaging in a
conversation. The assistant in SIMMC can be a crowd worker or Artificial
Intelligent (AI) agent. This enables both (i) a multi-player / Wizard of Oz
setting for data collection, or (ii) a single player mode for model / system
evaluation. We plan to open-source a situated conversational data-set collected
on this platform for the Conversational AI research community.",2019-11-07,2019,2019-11,environment
"Explainable Artificial Intelligence (XAI) for 6G: Improving Trust
  between Human and Machine","As the 5th Generation (5G) mobile networks are bringing about global societal
benefits, the design phase for the 6th Generation (6G) has started. 6G will
need to enable greater levels of autonomy, improve human machine interfacing,
and achieve deep connectivity in more diverse environments. The need for
increased explainability to enable trust is critical for 6G as it manages a
wide range of mission critical services (e.g. autonomous driving) to safety
critical tasks (e.g. remote surgery). As we migrate from traditional
model-based optimisation to deep learning, the trust we have in our
optimisation modules decrease. This loss of trust means we cannot understand
the impact of: 1) poor/bias/malicious data, and 2) neural network design on
decisions; nor can we explain to the engineer or the public the network's
actions. In this review, we outline the core concepts of Explainable Artificial
Intelligence (XAI) for 6G, including: public and legal motivations, definitions
of explainability, performance vs. explainability trade-offs, methods to
improve explainability, and frameworks to incorporate XAI into future wireless
systems. Our review is grounded in cases studies for both PHY and MAC layer
optimisation, and provide the community with an important research area to
embark upon.",2019-11-11,2019,2019-11,environment
"IKEA Furniture Assembly Environment for Long-Horizon Complex
  Manipulation Tasks","The IKEA Furniture Assembly Environment is one of the first benchmarks for
testing and accelerating the automation of complex manipulation tasks. The
environment is designed to advance reinforcement learning from simple toy tasks
to complex tasks requiring both long-term planning and sophisticated low-level
control. Our environment supports over 80 different furniture models, Sawyer
and Baxter robot simulation, and domain randomization. The IKEA Furniture
Assembly Environment is a testbed for methods aiming to solve complex
manipulation tasks. The environment is publicly available at
https://clvrai.com/furniture",2019-11-17,2019,2019-11,environment
Hierarchical Average Reward Policy Gradient Algorithms,"Option-critic learning is a general-purpose reinforcement learning (RL)
framework that aims to address the issue of long term credit assignment by
leveraging temporal abstractions. However, when dealing with extended
timescales, discounting future rewards can lead to incorrect credit
assignments. In this work, we address this issue by extending the hierarchical
option-critic policy gradient theorem for the average reward criterion. Our
proposed framework aims to maximize the long-term reward obtained in the
steady-state of the Markov chain defined by the agent's policy. Furthermore, we
use an ordinary differential equation based approach for our convergence
analysis and prove that the parameters of the intra-option policies,
termination functions, and value functions, converge to their corresponding
optimal values, with probability one. Finally, we illustrate the competitive
advantage of learning options, in the average reward setting, on a grid-world
environment with sparse rewards.",2019-11-20,2019,2019-11,environment
Agent Probing Interaction Policies,"Reinforcement learning in a multi agent system is difficult because these
systems are inherently non-stationary in nature. In such a case, identifying
the type of the opposite agent is crucial and can help us address this
non-stationary environment. We have investigated if we can employ some probing
policies which help us better identify the type of the other agent in the
environment. We've made a simplifying assumption that the other agent has a
stationary policy that our probing policy is trying to approximate. Our work
extends Environmental Probing Interaction Policy framework to handle multi
agent environments.",2019-11-21,2019,2019-11,environment
Information-Theoretic Confidence Bounds for Reinforcement Learning,"We integrate information-theoretic concepts into the design and analysis of
optimistic algorithms and Thompson sampling. By making a connection between
information-theoretic quantities and confidence bounds, we obtain results that
relate the per-period performance of the agent with its information gain about
the environment, thus explicitly characterizing the exploration-exploitation
tradeoff. The resulting cumulative regret bound depends on the agent's
uncertainty over the environment and quantifies the value of prior information.
We show applicability of this approach to several environments, including
linear bandits, tabular MDPs, and factored MDPs. These examples demonstrate the
potential of a general information-theoretic approach for the design and
analysis of reinforcement learning algorithms.",2019-11-21,2019,2019-11,environment
The PlayStation Reinforcement Learning Environment (PSXLE),"We propose a new benchmark environment for evaluating Reinforcement Learning
(RL) algorithms: the PlayStation Learning Environment (PSXLE), a PlayStation
emulator modified to expose a simple control API that enables rich game-state
representations. We argue that the PlayStation serves as a suitable progression
for agent evaluation and propose a framework for such an evaluation. We build
an action-driven abstraction for a PlayStation game with support for the OpenAI
Gym interface and demonstrate its use by running OpenAI Baselines.",2019-12-12,2019,2019-12,environment
"Point-Based Methods for Model Checking in Partially Observable Markov
  Decision Processes","Autonomous systems are often required to operate in partially observable
environments. They must reliably execute a specified objective even with
incomplete information about the state of the environment. We propose a
methodology to synthesize policies that satisfy a linear temporal logic formula
in a partially observable Markov decision process (POMDP). By formulating a
planning problem, we show how to use point-based value iteration methods to
efficiently approximate the maximum probability of satisfying a desired logical
formula and compute the associated belief state policy. We demonstrate that our
method scales to large POMDP domains and provides strong bounds on the
performance of the resulting policy.",2020-01-11,2020,2020-01,environment
Knowledge Representations in Technical Systems -- A Taxonomy,"The recent usage of technical systems in human-centric environments leads to
the question, how to teach technical systems, e.g., robots, to understand,
learn, and perform tasks desired by the human. Therefore, an accurate
representation of knowledge is essential for the system to work as expected.
This article mainly gives insight into different knowledge representation
techniques and their categorization into various problem domains in artificial
intelligence. Additionally, applications of presented knowledge representations
are introduced in everyday robotics tasks. By means of the provided taxonomy,
the search for a proper knowledge representation technique regarding a specific
problem should be facilitated.",2020-01-14,2020,2020-01,environment
"A Survey of Reinforcement Learning Techniques: Strategies, Recent
  Development, and Future Directions","Reinforcement learning is one of the core components in designing an
artificial intelligent system emphasizing real-time response. Reinforcement
learning influences the system to take actions within an arbitrary environment
either having previous knowledge about the environment model or not. In this
paper, we present a comprehensive study on Reinforcement Learning focusing on
various dimensions including challenges, the recent development of different
state-of-the-art techniques, and future directions. The fundamental objective
of this paper is to provide a framework for the presentation of available
methods of reinforcement learning that is informative enough and simple to
follow for the new researchers and academics in this domain considering the
latest concerns. First, we illustrated the core techniques of reinforcement
learning in an easily understandable and comparable way. Finally, we analyzed
and depicted the recent developments in reinforcement learning approaches. My
analysis pointed out that most of the models focused on tuning policy values
rather than tuning other things in a particular state of reasoning.",2020-01-19,2020,2020-01,environment
Artificial Intelligence Aided Next-Generation Networks Relying on UAVs,"Artificial intelligence (AI) assisted unmanned aerial vehicle (UAV) aided
next-generation networking is proposed for dynamic environments. In the
AI-enabled UAV-aided wireless networks (UAWN), multiple UAVs are employed as
aerial base stations, which are capable of rapidly adapting to the dynamic
environment by collecting information about the users' position and
tele-traffic demands, learning from the environment and acting upon the
feedback received from the users. Moreover, AI enables the interaction amongst
a swarm of UAVs for cooperative optimization of the system. As a benefit of the
AI framework, several challenges of conventional UAWN may be circumvented,
leading to enhanced network performance, improved reliability and agile
adaptivity. As a further benefit, dynamic trajectory design and resource
allocation are demonstrated. Finally, potential research challenges and
opportunities are discussed.",2020-01-28,2020,2020-01,environment
"On the Convergence of Artificial Intelligence and Distributed Ledger
  Technology: A Scoping Review and Future Research Agenda","Developments in Artificial Intelligence (AI) and Distributed Ledger
Technology (DLT) currently lead to lively debates in academia and practice. AI
processes data to perform tasks that were previously thought possible only for
humans. DLT has the potential to create consensus over data among a group of
participants in uncertain environments. In recent research, both technologies
are used in similar and even the same systems. Examples include the design of
secure distributed ledgers or the creation of allied learning systems
distributed across multiple nodes. This can lead to technological convergence,
which in the past, has paved the way for major innovations in information
technology. Previous work highlights several potential benefits of the
convergence of AI and DLT but only provides a limited theoretical framework to
describe upcoming real-world integration cases of both technologies. We aim to
contribute by conducting a systematic literature review on previous work and
providing rigorously derived future research opportunities. This work helps
researchers active in AI or DLT to overcome current limitations in their field,
and practitioners to develop systems along with the convergence of both
technologies.",2020-01-29,2020,2020-01,environment
Hacia los Comit√©s de √âtica en Inteligencia Artificial,"The goal of Artificial Intelligence based systems is to take decisions that
have an effect in their environment and impact society. This points out to the
necessity of mechanism that regulate the impact of this type of system in
society. For this reason, it is priority to create the rules and specialized
organizations that can oversight the following of such rules, particularly that
human rights precepts at local and international level. This work proposes the
creation, at the universities, of Ethical Committees or Commissions specialized
on Artificial Intelligence that would be in charge of define the principles and
will guarantee the following of good practices in the field Artificial
Intelligence.",2020-02-11,2020,2020-02,environment
RL agents Implicitly Learning Human Preferences,"In the real world, RL agents should be rewarded for fulfilling human
preferences. We show that RL agents implicitly learn the preferences of humans
in their environment. Training a classifier to predict if a simulated human's
preferences are fulfilled based on the activations of a RL agent's neural
network gets .93 AUC. Training a classifier on the raw environment state gets
only .8 AUC. Training the classifier off of the RL agent's activations also
does much better than training off of activations from an autoencoder. The
human preference classifier can be used as the reward function of an RL agent
to make RL agent more beneficial for humans.",2020-02-14,2020,2020-02,environment
"Wireless 2.0: Towards an Intelligent Radio Environment Empowered by
  Reconfigurable Meta-Surfaces and Artificial Intelligence","We introduce ""Wireless 2.0"": The future generation of wireless communication
networks, where the radio environment becomes controllable, programmable, and
intelligent by leveraging the emerging technologies of reconfigurable
metasurfaces and artificial intelligence (AI). This paper, in particular, puts
the emphasis on AI-based computational methods and commence with an overview of
the concept of intelligent radio environments based on reconfigurable
meta-surfaces. Later we elaborate on data management aspects, the requirements
of supervised learning by examples, and the paradigm of reinforcement learning
(RL) to learn by acting. Finally, we highlight numerous open challenges and
research directions.",2020-02-23,2020,2020-02,environment
"Facets of the PIE Environment for Proving, Interpolating and Eliminating
  on the Basis of First-Order Logic","PIE is a Prolog-embedded environment for automated reasoning on the basis of
first-order logic. Its main focus is on formulas, as constituents of complex
formalizations that are structured through formula macros, and as outputs of
reasoning tasks such as second-order quantifier elimination and Craig
interpolation. It supports a workflow based on documents that intersperse macro
definitions, invocations of reasoners, and LaTeX-formatted natural language
text. Starting from various examples, the paper discusses features and
application possibilities of PIE along with current limitations and issues for
future research.",2020-02-24,2020,2020-02,environment
TanksWorld: A Multi-Agent Environment for AI Safety Research,"The ability to create artificial intelligence (AI) capable of performing
complex tasks is rapidly outpacing our ability to ensure the safe and assured
operation of AI-enabled systems. Fortunately, a landscape of AI safety research
is emerging in response to this asymmetry and yet there is a long way to go. In
particular, recent simulation environments created to illustrate AI safety
risks are relatively simple or narrowly-focused on a particular issue. Hence,
we see a critical need for AI safety research environments that abstract
essential aspects of complex real-world applications. In this work, we
introduce the AI safety TanksWorld as an environment for AI safety research
with three essential aspects: competing performance objectives, human-machine
teaming, and multi-agent competition. The AI safety TanksWorld aims to
accelerate the advancement of safe multi-agent decision-making algorithms by
providing a software framework to support competitions with both system
performance and safety objectives. As a work in progress, this paper introduces
our research objectives and learning environment with reference code and
baseline performance metrics to follow in a future work.",2020-02-25,2020,2020-02,environment
"Environment-agnostic Multitask Learning for Natural Language Grounded
  Navigation","Recent research efforts enable study for natural language grounded navigation
in photo-realistic environments, e.g., following natural language instructions
or dialog. However, existing methods tend to overfit training data in seen
environments and fail to generalize well in previously unseen environments. To
close the gap between seen and unseen environments, we aim at learning a
generalized navigation model from two novel perspectives: (1) we introduce a
multitask navigation model that can be seamlessly trained on both
Vision-Language Navigation (VLN) and Navigation from Dialog History (NDH)
tasks, which benefits from richer natural language guidance and effectively
transfers knowledge across tasks; (2) we propose to learn environment-agnostic
representations for the navigation policy that are invariant among the
environments seen during training, thus generalizing better on unseen
environments. Extensive experiments show that environment-agnostic multitask
learning significantly reduces the performance gap between seen and unseen
environments, and the navigation agent trained so outperforms baselines on
unseen environments by 16% (relative measure on success rate) on VLN and 120%
(goal progress) on NDH. Our submission to the CVDN leaderboard establishes a
new state-of-the-art for the NDH task on the holdout test set. Code is
available at https://github.com/google-research/valan.",2020-03-01,2020,2020-03,environment
"Developing and Operating Artificial Intelligence Models in Trustworthy
  Autonomous Systems","Companies dealing with Artificial Intelligence (AI) models in Autonomous
Systems (AS) face several problems, such as users' lack of trust in adverse or
unknown conditions, gaps between software engineering and AI model development,
and operation in a continuously changing operational environment. This
work-in-progress paper aims to close the gap between the development and
operation of trustworthy AI-based AS by defining an approach that coordinates
both activities. We synthesize the main challenges of AI-based AS in industrial
settings. We reflect on the research efforts required to overcome these
challenges and propose a novel, holistic DevOps approach to put it into
practice. We elaborate on four research directions: (a) increased users' trust
by monitoring operational AI-based AS and identifying self-adaptation needs in
critical situations; (b) integrated agile process for the development and
evolution of AI models and AS; (c) continuous deployment of different
context-specific instances of AI models in a distributed setting of AS; and (d)
holistic DevOps-based lifecycle for AI-based AS.",2020-03-11,2020,2020-03,environment
"Beyond STEM, How Can Women Engage Big Data, Analytics, Robotics and
  Artificial Intelligence? An Exploratory Analysis of Confidence and
  Educational Factors in the Emerging Technology Waves Influencing the Role of,
  and Impact Upon, Women","In spite of the rapidly advancing global technological environment, the
professional participation of women in technology, big data, analytics,
artificial intelligence and information systems related domains remains
proportionately low. Furthermore, it is of no less concern that the number of
women in leadership in these domains are in even lower proportions. In spite of
numerous initiatives to improve the participation of women in technological
domains, there is an increasing need to gain additional insights into this
phenomenon especially since it occurs in nations and geographies which have
seen a sharp rise in overall female education, without such increase
translating into a corresponding spurt in information systems and technological
roles for women. The present paper presents findings from an exploratory
analysis and outlines a framework to gain insights into educational factors in
the emerging technology waves influencing the role of, and impact upon, women.
We specifically identify ways for learning and self-efficacy as key factors,
which together lead us to the Advancement of Women in Technology (AWT) insights
framework. Based on the AWT framework, we also proposition principles that can
be used to encourage higher professional engagement of women in emerging and
advanced technologies. Key Words- Women's Education, Technology, Artificial
Intelligence, Knowing, Confidence, Self-Efficacy, Learning.",2020-03-26,2020,2020-03,environment
Trust-based Multiagent Consensus or Weightings Aggregation,"We introduce a framework for reaching a consensus amongst several agents
communicating via a trust network on conflicting information about their
environment. We formalise our approach and provide an empirical and theoretical
analysis of its properties.",2020-04-06,2020,2020-04,environment
Adaptive Transformers in RL,"Recent developments in Transformers have opened new interesting areas of
research in partially observable reinforcement learning tasks. Results from
late 2019 showed that Transformers are able to outperform LSTMs on both memory
intense and reactive tasks. In this work we first partially replicate the
results shown in Stabilizing Transformers in RL on both reactive and memory
based environments. We then show performance improvement coupled with reduced
computation when adding adaptive attention span to this Stable Transformer on a
challenging DMLab30 environment. The code for all our experiments and models is
available at https://github.com/jerrodparker20/adaptive-transformers-in-rl.",2020-04-08,2020,2020-04,environment
Reinforcement Learning in a Physics-Inspired Semi-Markov Environment,"Reinforcement learning (RL) has been demonstrated to have great potential in
many applications of scientific discovery and design. Recent work includes, for
example, the design of new structures and compositions of molecules for
therapeutic drugs. Much of the existing work related to the application of RL
to scientific domains, however, assumes that the available state representation
obeys the Markov property. For reasons associated with time, cost, sensor
accuracy, and gaps in scientific knowledge, many scientific design and
discovery problems do not satisfy the Markov property. Thus, something other
than a Markov decision process (MDP) should be used to plan / find the optimal
policy. In this paper, we present a physics-inspired semi-Markov RL
environment, namely the phase change environment. In addition, we evaluate the
performance of value-based RL algorithms for both MDPs and partially observable
MDPs (POMDPs) on the proposed environment. Our results demonstrate deep
recurrent Q-networks (DRQN) significantly outperform deep Q-networks (DQN), and
that DRQNs benefit from training with hindsight experience replay. Implications
for the use of semi-Markovian RL and POMDPs for scientific laboratories are
also discussed.",2020-04-15,2020,2020-04,environment
Intention as Commitment toward Time,"In this paper we address the interplay among intention, time, and belief in
dynamic environments. The first contribution is a logic for reasoning about
intention, time and belief, in which assumptions of intentions are represented
by preconditions of intended actions. Intentions and beliefs are coherent as
long as these assumptions are not violated, i.e. as long as intended actions
can be performed such that their preconditions hold as well. The second
contribution is the formalization of what-if scenarios: what happens with
intentions and beliefs if a new (possibly conflicting) intention is adopted, or
a new fact is learned? An agent is committed to its intended actions as long as
its belief-intention database is coherent. We conceptualize intention as
commitment toward time and we develop AGM-based postulates for the iterated
revision of belief-intention databases, and we prove a Katsuno-Mendelzon-style
representation theorem.",2020-04-17,2020,2020-04,environment
"SAIA: Split Artificial Intelligence Architecture for Mobile Healthcare
  System","As the advancement of deep learning (DL), the Internet of Things and cloud
computing techniques for biomedical and healthcare problems, mobile healthcare
systems have received unprecedented attention. Since DL techniques usually
require enormous amount of computation, most of them cannot be directly
deployed on the resource-constrained mobile and IoT devices. Hence, most of the
mobile healthcare systems leverage the cloud computing infrastructure, where
the data collected by the mobile and IoT devices would be transmitted to the
cloud computing platforms for analysis. However, in the contested environments,
relying on the cloud might not be practical at all times. For instance, the
satellite communication might be denied or disrupted. We propose SAIA, a Split
Artificial Intelligence Architecture for mobile healthcare systems. Unlike
traditional approaches for artificial intelligence (AI) which solely exploits
the computational power of the cloud server, SAIA could not only relies on the
cloud computing infrastructure while the wireless communication is available,
but also utilizes the lightweight AI solutions that work locally on the client
side, hence, it can work even when the communication is impeded. In SAIA, we
propose a meta-information based decision unit, that could tune whether a
sample captured by the client should be operated by the embedded AI (i.e.,
keeping on the client) or the networked AI (i.e., sending to the server), under
different conditions. In our experimental evaluation, extensive experiments
have been conducted on two popular healthcare datasets. Our results show that
SAIA consistently outperforms its baselines in terms of both effectiveness and
efficiency.",2020-04-25,2020,2020-04,environment
Reinforcement Learning Generalization with Surprise Minimization,"Generalization remains a challenging problem for deep reinforcement learning
algorithms, which are often trained and tested on the same set of deterministic
game environments. When test environments are unseen and perturbed but the
nature of the task remains the same, generalization gaps can arise. In this
work, we propose and evaluate a surprise minimizing agent on a generalization
benchmark to show an additional reward learned from a simple density model can
show robustness in procedurally generated game environments that provide
constant source of entropy and stochasticity.",2020-04-26,2020,2020-04,environment
"Enhancing Text-based Reinforcement Learning Agents with Commonsense
  Knowledge","In this paper, we consider the recent trend of evaluating progress on
reinforcement learning technology by using text-based environments and games as
evaluation environments. This reliance on text brings advances in natural
language processing into the ambit of these agents, with a recurring thread
being the use of external knowledge to mimic and better human-level
performance. We present one such instantiation of agents that use commonsense
knowledge from ConceptNet to show promising performance on two text-based
environments.",2020-05-02,2020,2020-05,environment
"A Survey of Algorithms for Black-Box Safety Validation of Cyber-Physical
  Systems","Autonomous cyber-physical systems (CPS) can improve safety and efficiency for
safety-critical applications, but require rigorous testing before deployment.
The complexity of these systems often precludes the use of formal verification
and real-world testing can be too dangerous during development. Therefore,
simulation-based techniques have been developed that treat the system under
test as a black box operating in a simulated environment. Safety validation
tasks include finding disturbances in the environment that cause the system to
fail (falsification), finding the most-likely failure, and estimating the
probability that the system fails. Motivated by the prevalence of
safety-critical artificial intelligence, this work provides a survey of
state-of-the-art safety validation techniques for CPS with a focus on applied
algorithms and their modifications for the safety validation problem. We
present and discuss algorithms in the domains of optimization, path planning,
reinforcement learning, and importance sampling. Problem decomposition
techniques are presented to help scale algorithms to large state spaces, which
are common for CPS. A brief overview of safety-critical applications is given,
including autonomous vehicles and aircraft collision avoidance systems.
Finally, we present a survey of existing academic and commercially available
safety validation tools.",2020-05-06,2020,2020-05,environment
"Controlling Overestimation Bias with Truncated Mixture of Continuous
  Distributional Quantile Critics","The overestimation bias is one of the major impediments to accurate
off-policy learning. This paper investigates a novel way to alleviate the
overestimation bias in a continuous control setting. Our method---Truncated
Quantile Critics, TQC,---blends three ideas: distributional representation of a
critic, truncation of critics prediction, and ensembling of multiple critics.
Distributional representation and truncation allow for arbitrary granular
overestimation control, while ensembling provides additional score
improvements. TQC outperforms the current state of the art on all environments
from the continuous control benchmark suite, demonstrating 25% improvement on
the most challenging Humanoid environment.",2020-05-08,2020,2020-05,environment
"Design of a dynamic and self adapting system, supported with artificial
  intelligence, machine learning and real time intelligence for predictive
  cyber risk analytics in extreme environments, cyber risk in the colonisation
  of Mars","Multiple governmental agencies and private organisations have made
commitments for the colonisation of Mars. Such colonisation requires complex
systems and infrastructure that could be very costly to repair or replace in
cases of cyber attacks. This paper surveys deep learning algorithms, IoT cyber
security and risk models, and established mathematical formulas to identify the
best approach for developing a dynamic and self adapting system for predictive
cyber risk analytics supported with Artificial Intelligence and Machine
Learning and real time intelligence in edge computing. The paper presents a new
mathematical approach for integrating concepts for cognition engine design,
edge computing and Artificial Intelligence and Machine Learning to automate
anomaly detection. This engine instigates a step change by applying Artificial
Intelligence and Machine Learning embedded at the edge of IoT networks, to
deliver safe and functional real time intelligence for predictive cyber risk
analytics. This will enhance capacities for risk analytics and assists in the
creation of a comprehensive and systematic understanding of the opportunities
and threats that arise when edge computing nodes are deployed, and when
Artificial Intelligence and Machine Learning technologies are migrated to the
periphery of the internet and into local IoT networks.",2020-05-19,2020,2020-05,environment
"Information Acquisition Under Resource Limitations in a Noisy
  Environment","We introduce a theoretical model of information acquisition under resource
limitations in a noisy environment. An agent must guess the truth value of a
given Boolean formula $\varphi$ after performing a bounded number of noisy
tests of the truth values of variables in the formula. We observe that, in
general, the problem of finding an optimal testing strategy for $\phi$ is hard,
but we suggest a useful heuristic. The techniques we use also give insight into
two apparently unrelated, but well-studied problems: (1) \emph{rational
inattention}, that is, when it is rational to ignore pertinent information (the
optimal strategy may involve hardly ever testing variables that are clearly
relevant to $\phi$), and (2) what makes a formula hard to learn/remember.",2020-05-20,2020,2020-05,environment
Regulating Artificial Intelligence: Proposal for a Global Solution,"With increasing ubiquity of artificial intelligence (AI) in modern societies,
individual countries and the international community are working hard to create
an innovation-friendly, yet safe, regulatory environment. Adequate regulation
is key to maximize the benefits and minimize the risks stemming from AI
technologies. Developing regulatory frameworks is, however, challenging due to
AI's global reach and the existence of widespread misconceptions about the
notion of regulation. We argue that AI-related challenges cannot be tackled
effectively without sincere international coordination supported by robust,
consistent domestic and international governance arrangements. Against this
backdrop, we propose the establishment of an international AI governance
framework organized around a new AI regulatory agency that -- drawing on
interdisciplinary expertise -- could help creating uniform standards for the
regulation of AI technologies and inform the development of AI policies around
the world. We also believe that a fundamental change of mindset on what
constitutes regulation is necessary to remove existing barriers that hamper
contemporary efforts to develop AI regulatory regimes, and put forward some
recommendations on how to achieve this, and what opportunities doing so would
present.",2020-05-22,2020,2020-05,environment
Learning visual servo policies via planner cloning,"Learning control policies for visual servoing in novel environments is an
important problem. However, standard model-free policy learning methods are
slow. This paper explores planner cloning: using behavior cloning to learn
policies that mimic the behavior of a full-state motion planner in simulation.
We propose Penalized Q Cloning (PQC), a new behavior cloning algorithm. We show
that it outperforms several baselines and ablations on some challenging
problems involving visual servoing in novel environments while avoiding
obstacles. Finally, we demonstrate that these policies can be transferred
effectively onto a real robotic platform, achieving approximately an 87%
success rate both in simulation and on a real robot.",2020-05-24,2020,2020-05,environment
"Synergetic Learning Systems: Concept, Architecture, and Algorithms","Drawing on the idea that brain development is a Darwinian process of
``evolution + selection'' and the idea that the current state is a local
equilibrium state of many bodies with self-organization and evolution processes
driven by the temperature and gravity in our universe, in this work, we
describe an artificial intelligence system called the ``Synergetic Learning
Systems''. The system is composed of two or more subsystems (models, agents or
virtual bodies), and it is an open complex giant system. Inspired by natural
intelligence, the system achieves intelligent information processing and
decision-making in a given environment through cooperative/competitive
synergetic learning. The intelligence evolved by the natural law of ``it is not
the strongest of the species that survives, but the one most responsive to
change,'' while an artificial intelligence system should adopt the law of
``human selection'' in the evolution process. Therefore, we expect that the
proposed system architecture can also be adapted in human-machine synergy or
multi-agent synergetic systems. It is also expected that under our design
criteria, the proposed system will eventually achieve artificial general
intelligence through long term coevolution.",2020-05-31,2020,2020-05,environment
Temporal-Differential Learning in Continuous Environments,"In this paper, a new reinforcement learning (RL) method known as the method
of temporal differential is introduced. Compared to the traditional
temporal-difference learning method, it plays a crucial role in developing
novel RL techniques for continuous environments. In particular, the
continuous-time least squares policy evaluation (CT-LSPE) and the
continuous-time temporal-differential (CT-TD) learning methods are developed.
Both theoretical and empirical evidences are provided to demonstrate the
effectiveness of the proposed temporal-differential learning methodology.",2020-06-01,2020,2020-06,environment
Delta Schema Network in Model-based Reinforcement Learning,"This work is devoted to unresolved problems of Artificial General
Intelligence - the inefficiency of transfer learning. One of the mechanisms
that are used to solve this problem in the area of reinforcement learning is a
model-based approach. In the paper we are expanding the schema networks method
which allows to extract the logical relationships between objects and actions
from the environment data. We present algorithms for training a Delta Schema
Network (DSN), predicting future states of the environment and planning actions
that will lead to positive reward. DSN shows strong performance of transfer
learning on the classic Atari game environment.",2020-06-17,2020,2020-06,environment
Modelling Agent Policies with Interpretable Imitation Learning,"As we deploy autonomous agents in safety-critical domains, it becomes
important to develop an understanding of their internal mechanisms and
representations. We outline an approach to imitation learning for
reverse-engineering black box agent policies in MDP environments, yielding
simplified, interpretable models in the form of decision trees. As part of this
process, we explicitly model and learn agents' latent state representations by
selecting from a large space of candidate features constructed from the Markov
state. We present initial promising results from an implementation in a
multi-agent traffic environment.",2020-06-19,2020,2020-06,environment
Designing Environments Conducive to Interpretable Robot Behavior,"Designing robots capable of generating interpretable behavior is a
prerequisite for achieving effective human-robot collaboration. This means that
the robots need to be capable of generating behavior that aligns with human
expectations and, when required, provide explanations to the humans in the
loop. However, exhibiting such behavior in arbitrary environments could be
quite expensive for robots, and in some cases, the robot may not even be able
to exhibit the expected behavior. Given structured environments (like
warehouses and restaurants), it may be possible to design the environment so as
to boost the interpretability of the robot's behavior or to shape the human's
expectations of the robot's behavior. In this paper, we investigate the
opportunities and limitations of environment design as a tool to promote a type
of interpretable behavior -- known in the literature as explicable behavior. We
formulate a novel environment design framework that considers design over
multiple tasks and over a time horizon. In addition, we explore the
longitudinal aspect of explicable behavior and the trade-off that arises
between the cost of design and the cost of generating explicable behavior over
a time horizon.",2020-07-02,2020,2020-07,environment
"Natural Emergence of Heterogeneous Strategies in Artificially
  Intelligent Competitive Teams","Multi agent strategies in mixed cooperative-competitive environments can be
hard to craft by hand because each agent needs to coordinate with its teammates
while competing with its opponents. Learning based algorithms are appealing but
many scenarios require heterogeneous agent behavior for the team's success and
this increases the complexity of the learning algorithm. In this work, we
develop a competitive multi agent environment called FortAttack in which two
teams compete against each other. We corroborate that modeling agents with
Graph Neural Networks and training them with Reinforcement Learning leads to
the evolution of increasingly complex strategies for each team. We observe a
natural emergence of heterogeneous behavior amongst homogeneous agents when
such behavior can lead to the team's success. Such heterogeneous behavior from
homogeneous agents is appealing because any agent can replace the role of
another agent at test time. Finally, we propose ensemble training, in which we
utilize the evolved opponent strategies to train a single policy for friendly
agents.",2020-07-06,2020,2020-07,environment
Fast Adaptation via Policy-Dynamics Value Functions,"Standard RL algorithms assume fixed environment dynamics and require a
significant amount of interaction to adapt to new environments. We introduce
Policy-Dynamics Value Functions (PD-VF), a novel approach for rapidly adapting
to dynamics different from those previously seen in training. PD-VF explicitly
estimates the cumulative reward in a space of policies and environments. An
ensemble of conventional RL policies is used to gather experience on training
environments, from which embeddings of both policies and environments can be
learned. Then, a value function conditioned on both embeddings is trained. At
test time, a few actions are sufficient to infer the environment embedding,
enabling a policy to be selected by maximizing the learned value function
(which requires no additional environment interaction). We show that our method
can rapidly adapt to new dynamics on a set of MuJoCo domains. Code available at
https://github.com/rraileanu/policy-dynamics-value-functions.",2020-07-06,2020,2020-07,environment
Scaling Imitation Learning in Minecraft,"Imitation learning is a powerful family of techniques for learning
sensorimotor coordination in immersive environments. We apply imitation
learning to attain state-of-the-art performance on hard exploration problems in
the Minecraft environment. We report experiments that highlight the influence
of network architecture, loss function, and data augmentation. An early version
of our approach reached second place in the MineRL competition at NeurIPS 2019.
Here we report stronger results that can be used as a starting point for future
competition entries and related research. Our code is available at
https://github.com/amiranas/minerl_imitation_learning.",2020-07-06,2020,2020-07,environment
Human $\neq$ AGI,"Terms Artificial General Intelligence (AGI) and Human-Level Artificial
Intelligence (HLAI) have been used interchangeably to refer to the Holy Grail
of Artificial Intelligence (AI) research, creation of a machine capable of
achieving goals in a wide range of environments. However, widespread implicit
assumption of equivalence between capabilities of AGI and HLAI appears to be
unjustified, as humans are not general intelligences. In this paper, we will
prove this distinction.",2020-07-11,2020,2020-07,environment
"Relational-Grid-World: A Novel Relational Reasoning Environment and An
  Agent Model for Relational Information Extraction","Reinforcement learning (RL) agents are often designed specifically for a
particular problem and they generally have uninterpretable working processes.
Statistical methods-based agent algorithms can be improved in terms of
generalizability and interpretability using symbolic Artificial Intelligence
(AI) tools such as logic programming. In this study, we present a model-free RL
architecture that is supported with explicit relational representations of the
environmental objects. For the first time, we use the PrediNet network
architecture in a dynamic decision-making problem rather than image-based
tasks, and Multi-Head Dot-Product Attention Network (MHDPA) as a baseline for
performance comparisons. We tested two networks in two environments ---i.e.,
the baseline Box-World environment and our novel environment,
Relational-Grid-World (RGW). With the procedurally generated RGW environment,
which is complex in terms of visual perceptions and combinatorial selections,
it is easy to measure the relational representation performance of the RL
agents. The experiments were carried out using different configurations of the
environment so that the presented module and the environment were compared with
the baselines. We reached similar policy optimization performance results with
the PrediNet architecture and MHDPA; additionally, we achieved to extract the
propositional representation explicitly ---which makes the agent's statistical
policy logic more interpretable and tractable. This flexibility in the agent's
policy provides convenience for designing non-task-specific agent
architectures. The main contributions of this study are two-fold ---an RL agent
that can explicitly perform relational reasoning, and a new environment that
measures the relational reasoning capabilities of RL agents.",2020-07-12,2020,2020-07,environment
"Situated Multimodal Control of a Mobile Robot: Navigation through a
  Virtual Environment","We present a new interface for controlling a navigation robot in novel
environments using coordinated gesture and language. We use a TurtleBot3 robot
with a LIDAR and a camera, an embodied simulation of what the robot has
encountered while exploring, and a cross-platform bridge facilitating generic
communication. A human partner can deliver instructions to the robot using
spoken English and gestures relative to the simulated environment, to guide the
robot through navigation tasks.",2020-07-13,2020,2020-07,environment
Collision Avoidance Robotics Via Meta-Learning (CARML),"This paper presents an approach to exploring a multi-objective reinforcement
learning problem with Model-Agnostic Meta-Learning. The environment we used
consists of a 2D vehicle equipped with a LIDAR sensor. The goal of the
environment is to reach some pre-determined target location but also
effectively avoid any obstacles it may find along its path. We also compare
this approach against a baseline TD3 solution that attempts to solve the same
problem.",2020-07-16,2020,2020-07,environment
An Open-World Simulated Environment for Developmental Robotics,"As the current trend of artificial intelligence is shifting towards
self-supervised learning, conventional norms such as highly curated
domain-specific data, application-specific learning models, extrinsic reward
based learning policies etc. might not provide with the suitable ground for
such developments. In this paper, we introduce SEDRo, a Simulated Environment
for Developmental Robotics which allows a learning agent to have similar
experiences that a human infant goes through from the fetus stage up to 12
months. A series of simulated tests based on developmental psychology will be
used to evaluate the progress of a learning model.",2020-07-18,2020,2020-07,environment
Greedy Bandits with Sampled Context,"Bayesian strategies for contextual bandits have proved promising in
single-state reinforcement learning tasks by modeling uncertainty using context
information from the environment. In this paper, we propose Greedy Bandits with
Sampled Context (GB-SC), a method for contextual multi-armed bandits to develop
the prior from the context information using Thompson Sampling, and arm
selection using an epsilon-greedy policy. The framework GB-SC allows for
evaluation of context-reward dependency, as well as providing robustness for
partially observable context vectors by leveraging the prior developed. Our
experimental results show competitive performance on the Mushroom environment
in terms of expected regret and expected cumulative regret, as well as insights
on how each context subset affects decision-making.",2020-07-27,2020,2020-07,environment
"Modelos din√¢micos aplicados √† aprendizagem de valores em
  intelig√™ncia artificial","Experts in Artificial Intelligence (AI) development predict that advances in
the development of intelligent systems and agents will reshape vital areas in
our society. Nevertheless, if such an advance is not made prudently and
critically, reflexively, it can result in negative outcomes for humanity. For
this reason, several researchers in the area have developed a robust,
beneficial, and safe concept of AI for the preservation of humanity and the
environment. Currently, several of the open problems in the field of AI
research arise from the difficulty of avoiding unwanted behaviors of
intelligent agents and systems, and at the same time specifying what we really
want such systems to do, especially when we look for the possibility of
intelligent agents acting in several domains over the long term. It is of
utmost importance that artificial intelligent agents have their values aligned
with human values, given the fact that we cannot expect an AI to develop human
moral values simply because of its intelligence, as discussed in the
Orthogonality Thesis. Perhaps this difficulty comes from the way we are
addressing the problem of expressing objectives, values, and ends, using
representational cognitive methods. A solution to this problem would be the
dynamic approach proposed by Dreyfus, whose phenomenological philosophy shows
that the human experience of being-in-the-world in several aspects is not well
represented by the symbolic or connectionist cognitive method, especially in
regards to the question of learning values. A possible approach to this problem
would be to use theoretical models such as SED (situated embodied dynamics) to
address the values learning problem in AI.",2020-07-30,2020,2020-07,environment
"Artificial Intelligence in Music and Performance: A Subjective
  Art-Research Inquiry","This article presents a five-year collaboration situated at the intersection
of Art practice and Scientific research in Human-Computer Interaction (HCI). At
the core of our collaborative work is a hybrid, Art and Science methodology
that combines computational learning technology -- Machine Learning (ML) and
Artificial Intelligence (AI) -- with interactive music performance and
choreography. This article first exposes our thoughts on combining art,
science, movement and sound research. We then describe two of our artistic
works \textit{Corpus Nil} and \textit{Humane Methods} -- created five years
apart from each other -- that crystallize our collaborative research process.
We present the scientific and artistic motivations, framed through our research
interests and cultural environment of the time. We conclude by reflecting on
the methodology we developed during the collaboration and on the conceptual
shift of computational learning technologies, from ML to AI, and its impact on
Music performance.",2020-07-31,2020,2020-07,environment
SuperSuit: Simple Microwrappers for Reinforcement Learning Environments,"In reinforcement learning, wrappers are universally used to transform the
information that passes between a model and an environment. Despite their
ubiquity, no library exists with reasonable implementations of all popular
preprocessing methods. This leads to unnecessary bugs, code inefficiencies, and
wasted developer time. Accordingly we introduce SuperSuit, a Python library
that includes all popular wrappers, and wrappers that can easily apply lambda
functions to the observations/actions/reward. It's compatible with the standard
Gym environment specification, as well as the PettingZoo specification for
multi-agent environments. The library is available at
https://github.com/PettingZoo-Team/SuperSuit,and can be installed via pip.",2020-08-17,2020,2020-08,environment
"Say ""Sul Sul!"" to SimSim, A Sims-Inspired Platform for Sandbox Game AI","This paper proposes environment design in the life simulation game The Sims
as a novel platform and challenge for testing divergent search algorithms. In
this domain, which includes a minimal viability criterion, the goal is to
furnish a house with objects that satisfy the physical needs of a simulated
agent. Importantly, the large number of objects available to the player
(whether human or automated) affords a wide variety of solutions to the
underlying design problem. Empirical studies in a novel open source simulator
called SimSim investigate the ability of novelty-based evolutionary algorithms
to effectively generate viable environment designs.",2020-08-25,2020,2020-08,environment
"Explainable Artificial Intelligence for Process Mining: A General
  Overview and Application of a Novel Local Explanation Approach for Predictive
  Process Monitoring","The contemporary process-aware information systems possess the capabilities
to record the activities generated during the process execution. To leverage
these process specific fine-granular data, process mining has recently emerged
as a promising research discipline. As an important branch of process mining,
predictive business process management, pursues the objective to generate
forward-looking, predictive insights to shape business processes. In this
study, we propose a conceptual framework sought to establish and promote
understanding of decision-making environment, underlying business processes and
nature of the user characteristics for developing explainable business process
prediction solutions. Consequently, with regard to the theoretical and
practical implications of the framework, this study proposes a novel local
post-hoc explanation approach for a deep learning classifier that is expected
to facilitate the domain experts in justifying the model decisions. In contrary
to alternative popular perturbation-based local explanation approaches, this
study defines the local regions from the validation dataset by using the
intermediate latent space representations learned by the deep neural networks.
To validate the applicability of the proposed explanation method, the real-life
process log data delivered by the Volvo IT Belgium's incident management system
are used.The adopted deep learning classifier achieves a good performance with
the Area Under the ROC Curve of 0.94. The generated local explanations are also
visualized and presented with relevant evaluation measures that are expected to
increase the users' trust in the black-box-model.",2020-09-04,2020,2020-09,environment
Multiplayer Support for the Arcade Learning Environment,"The Arcade Learning Environment (""ALE"") is a widely used library in the
reinforcement learning community that allows easy programmatic interfacing with
Atari 2600 games, via the Stella emulator. We introduce a publicly available
extension to the ALE that extends its support to multiplayer games and game
modes. This interface is additionally integrated with PettingZoo to allow for a
simple Gym-like interface in Python to interact with these games. We
additionally introduce experimental baselines for all environments included.",2020-09-20,2020,2020-09,environment
"Advancing the Research and Development of Assured Artificial
  Intelligence and Machine Learning Capabilities","Artificial intelligence (AI) and machine learning (ML) have become
increasingly vital in the development of novel defense and intelligence
capabilities across all domains of warfare. An adversarial AI (A2I) and
adversarial ML (AML) attack seeks to deceive and manipulate AI/ML models. It is
imperative that AI/ML models can defend against these attacks. A2I/AML defenses
will help provide the necessary assurance of these advanced capabilities that
use AI/ML models. The A2I Working Group (A2IWG) seeks to advance the research
and development of assured AI/ML capabilities via new A2I/AML defenses by
fostering a collaborative environment across the U.S. Department of Defense and
U.S. Intelligence Community. The A2IWG aims to identify specific challenges
that it can help solve or address more directly, with initial focus on three
topics: AI Trusted Robustness, AI System Security, and AI/ML Architecture
Vulnerabilities.",2020-09-24,2020,2020-09,environment
"robosuite: A Modular Simulation Framework and Benchmark for Robot
  Learning","robosuite is a simulation framework for robot learning powered by the MuJoCo
physics engine. It offers a modular design for creating robotic tasks as well
as a suite of benchmark environments for reproducible research. This paper
discusses the key system modules and the benchmark environments of our new
release robosuite v1.5.",2020-09-25,2020,2020-09,environment
"Heterogeneous Multi-Agent Reinforcement Learning for Unknown Environment
  Mapping","Reinforcement learning in heterogeneous multi-agent scenarios is important
for real-world applications but presents challenges beyond those seen in
homogeneous settings and simple benchmarks. In this work, we present an
actor-critic algorithm that allows a team of heterogeneous agents to learn
decentralized control policies for covering an unknown environment. This task
is of interest to national security and emergency response organizations that
would like to enhance situational awareness in hazardous areas by deploying
teams of unmanned aerial vehicles. To solve this multi-agent coverage path
planning problem in unknown environments, we augment a multi-agent actor-critic
architecture with a new state encoding structure and triplet learning loss to
support heterogeneous agent learning. We developed a simulation environment
that includes real-world environmental factors such as turbulence, delayed
communication, and agent loss, to train teams of agents as well as probe their
robustness and flexibility to such disturbances.",2020-10-06,2020,2020-10,environment
"Deep Reinforcement Learning for Adaptive Network Slicing in 5G for
  Intelligent Vehicular Systems and Smart Cities","Intelligent vehicular systems and smart city applications are the fastest
growing Internet of things (IoT) implementations at a compound annual growth
rate of 30%. In view of the recent advances in IoT devices and the emerging new
breed of IoT applications driven by artificial intelligence (AI), fog radio
access network (F-RAN) has been recently introduced for the fifth generation
(5G) wireless communications to overcome the latency limitations of cloud-RAN
(C-RAN). We consider the network slicing problem of allocating the limited
resources at the network edge (fog nodes) to vehicular and smart city users
with heterogeneous latency and computing demands in dynamic environments. We
develop a network slicing model based on a cluster of fog nodes (FNs)
coordinated with an edge controller (EC) to efficiently utilize the limited
resources at the network edge. For each service request in a cluster, the EC
decides which FN to execute the task, i.e., locally serve the request at the
edge, or to reject the task and refer it to the cloud. We formulate the problem
as infinite-horizon Markov decision process (MDP) and propose a deep
reinforcement learning (DRL) solution to adaptively learn the optimal slicing
policy. The performance of the proposed DRL-based slicing method is evaluated
by comparing it with other slicing approaches in dynamic environments and for
different scenarios of design objectives. Comprehensive simulation results
corroborate that the proposed DRL-based EC quickly learns the optimal policy
through interaction with the environment, which enables adaptive and automated
network slicing for efficient resource allocation in dynamic vehicular and
smart city environments.",2020-10-19,2020,2020-10,environment
Negotiating Team Formation Using Deep Reinforcement Learning,"When autonomous agents interact in the same environment, they must often
cooperate to achieve their goals. One way for agents to cooperate effectively
is to form a team, make a binding agreement on a joint plan, and execute it.
However, when agents are self-interested, the gains from team formation must be
allocated appropriately to incentivize agreement. Various approaches for
multi-agent negotiation have been proposed, but typically only work for
particular negotiation protocols. More general methods usually require human
input or domain-specific data, and so do not scale. To address this, we propose
a framework for training agents to negotiate and form teams using deep
reinforcement learning. Importantly, our method makes no assumptions about the
specific negotiation protocol, and is instead completely experience driven. We
evaluate our approach on both non-spatial and spatially extended team-formation
negotiation environments, demonstrating that our agents beat hand-crafted bots
and reach negotiation outcomes consistent with fair solutions predicted by
cooperative game theory. Additionally, we investigate how the physical location
of agents influences negotiation outcomes.",2020-10-20,2020,2020-10,environment
"Reinforcement Learning for Sparse-Reward Object-Interaction Tasks in a
  First-person Simulated 3D Environment","First-person object-interaction tasks in high-fidelity, 3D, simulated
environments such as the AI2Thor virtual home-environment pose significant
sample-efficiency challenges for reinforcement learning (RL) agents learning
from sparse task rewards. To alleviate these challenges, prior work has
provided extensive supervision via a combination of reward-shaping,
ground-truth object-information, and expert demonstrations. In this work, we
show that one can learn object-interaction tasks from scratch without
supervision by learning an attentive object-model as an auxiliary task during
task learning with an object-centric relational RL agent. Our key insight is
that learning an object-model that incorporates object-attention into forward
prediction provides a dense learning signal for unsupervised representation
learning of both objects and their relationships. This, in turn, enables faster
policy learning for an object-centric relational RL agent. We demonstrate our
agent by introducing a set of challenging object-interaction tasks in the
AI2Thor environment where learning with our attentive object-model is key to
strong performance. Specifically, we compare our agent and relational RL agents
with alternative auxiliary tasks to a relational RL agent equipped with
ground-truth object-information, and show that learning with our object-model
best closes the performance gap in terms of both learning speed and maximum
success rate. Additionally, we find that incorporating object-attention into an
object-model's forward predictions is key to learning representations which
capture object-category and object-state.",2020-10-28,2020,2020-10,environment
Face-work for Human-Agent Joint Decision-Making,"We propose a method to integrate face-work, a common social ritual related to
trust, into a decision-making agent that works collaboratively with a human.
Face-work is a set of trust-building behaviors designed to ""save face"" or
prevent others from ""losing face."" This paper describes the design of a
decision-making process that explicitly considers face-work as part of its
action selection. We also present a simulated robot arm deployed in an online
environment that can be used to evaluate the proposed method.",2020-11-03,2020,2020-11,environment
"Artificial Intelligence and its impact on the Fourth Industrial
  Revolution: A Review","Artificial Intelligence may revolutionize everything during the so-called
fourth industrial revolution, which carries several emerging technologies and
could progress without precedents in human history due to its speed and scope.
Government, academia, industry, and civil society show interest in
understanding the multidimensional impact of the emerging industrial
revolution; however, its development is hard to predict. Experts consider
emerging technologies could bring tremendous benefits to humanity; at the same
time, they could pose an existential risk. This paper reviews the development
and trends in AI, as well as the benefits, risks, and strategies in the field.
During the course of the emerging industrial revolution, the common good may be
achieved in a collaborative environment of shared interests and the hardest
work will be the implementation and monitoring of projects at a global scale.",2020-11-05,2020,2020-11,environment
"Playing optical tweezers with deep reinforcement learning: in virtual,
  physical and augmented environments","Reinforcement learning was carried out in a simulated environment to learn
continuous velocity control over multiple motor axes. This was then applied to
a real-world optical tweezers experiment with the objective of moving a
laser-trapped microsphere to a target location whilst avoiding collisions with
other free-moving microspheres. The concept of training a neural network in a
virtual environment has significant potential in the application of machine
learning for experimental optimization and control, as the neural network can
discover optimal methods for problem solving without the risk of damage to
equipment, and at a speed not limited by movement in the physical environment.
As the neural network treats both virtual and physical environments
equivalently, we show that the network can also be applied to an augmented
environment, where a virtual environment is combined with the physical
environment. This technique may have the potential to unlock capabilities
associated with mixed and augmented reality, such as enforcing safety limits
for machine motion or as a method of inputting observations from additional
sensors.",2020-11-05,2020,2020-11,environment
"Learning Behavior Trees with Genetic Programming in Unpredictable
  Environments","Modern industrial applications require robots to be able to operate in
unpredictable environments, and programs to be created with a minimal effort,
as there may be frequent changes to the task. In this paper, we show that
genetic programming can be effectively used to learn the structure of a
behavior tree (BT) to solve a robotic task in an unpredictable environment.
Moreover, we propose to use a simple simulator for the learning and demonstrate
that the learned BTs can solve the same task in a realistic simulator, reaching
convergence without the need for task specific heuristics. The learned solution
is tolerant to faults, making our method appealing for real robotic
applications.",2020-11-06,2020,2020-11,environment
"A deep Q-Learning based Path Planning and Navigation System for
  Firefighting Environments","Live fire creates a dynamic, rapidly changing environment that presents a
worthy challenge for deep learning and artificial intelligence methodologies to
assist firefighters with scene comprehension in maintaining their situational
awareness, tracking and relay of important features necessary for key decisions
as they tackle these catastrophic events. We propose a deep Q-learning based
agent who is immune to stress induced disorientation and anxiety and thus able
to make clear decisions for navigation based on the observed and stored facts
in live fire environments. As a proof of concept, we imitate structural fire in
a gaming engine called Unreal Engine which enables the interaction of the agent
with the environment. The agent is trained with a deep Q-learning algorithm
based on a set of rewards and penalties as per its actions on the environment.
We exploit experience replay to accelerate the learning process and augment the
learning of the agent with human-derived experiences. The agent trained under
this deep Q-learning approach outperforms agents trained through alternative
path planning systems and demonstrates this methodology as a promising
foundation on which to build a path planning navigation assistant capable of
safely guiding fire fighters through live fire environments.",2020-11-12,2020,2020-11,environment
DeepMind Lab2D,"We present DeepMind Lab2D, a scalable environment simulator for artificial
intelligence research that facilitates researcher-led experimentation with
environment design. DeepMind Lab2D was built with the specific needs of
multi-agent deep reinforcement learning researchers in mind, but it may also be
useful beyond that particular subfield.",2020-11-13,2020,2020-11,environment
"Empowering Things with Intelligence: A Survey of the Progress,
  Challenges, and Opportunities in Artificial Intelligence of Things","In the Internet of Things (IoT) era, billions of sensors and devices collect
and process data from the environment, transmit them to cloud centers, and
receive feedback via the internet for connectivity and perception. However,
transmitting massive amounts of heterogeneous data, perceiving complex
environments from these data, and then making smart decisions in a timely
manner are difficult. Artificial intelligence (AI), especially deep learning,
is now a proven success in various areas including computer vision, speech
recognition, and natural language processing. AI introduced into the IoT
heralds the era of artificial intelligence of things (AIoT). This paper
presents a comprehensive survey on AIoT to show how AI can empower the IoT to
make it faster, smarter, greener, and safer. Specifically, we briefly present
the AIoT architecture in the context of cloud computing, fog computing, and
edge computing. Then, we present progress in AI research for IoT from four
perspectives: perceiving, learning, reasoning, and behaving. Next, we summarize
some promising applications of AIoT that are likely to profoundly reshape our
world. Finally, we highlight the challenges facing AIoT and some potential
research opportunities.",2020-11-17,2020,2020-11,environment
"Double Meta-Learning for Data Efficient Policy Optimization in
  Non-Stationary Environments","We are interested in learning models of non-stationary environments, which
can be framed as a multi-task learning problem. Model-free reinforcement
learning algorithms can achieve good asymptotic performance in multi-task
learning at a cost of extensive sampling, due to their approach, which requires
learning from scratch. While model-based approaches are among the most data
efficient learning algorithms, they still struggle with complex tasks and model
uncertainties. Meta-reinforcement learning addresses the efficiency and
generalization challenges on multi task learning by quickly leveraging the
meta-prior policy for a new task. In this paper, we propose a
meta-reinforcement learning approach to learn the dynamic model of a
non-stationary environment to be used for meta-policy optimization later. Due
to the sample efficiency of model-based learning methods, we are able to
simultaneously train both the meta-model of the non-stationary environment and
the meta-policy until dynamic model convergence. Then, the meta-learned dynamic
model of the environment will generate simulated data for meta-policy
optimization. Our experiment demonstrates that our proposed method can
meta-learn the policy in a non-stationary environment with the data efficiency
of model-based learning approaches while achieving the high asymptotic
performance of model-free meta-reinforcement learning.",2020-11-21,2020,2020-11,environment
On limitations of learning algorithms in competitive environments,"We discuss conceptual limitations of generic learning algorithms pursuing
adversarial goals in competitive environments, and prove that they are subject
to limitations that are analogous to the constraints on knowledge imposed by
the famous theorems of G\""odel and Turing. These limitations are shown to be
related to intransitivity, which is commonly present in competitive
environments.",2020-11-25,2020,2020-11,environment
"Automated acquisition of structured, semantic models of manipulation
  activities from human VR demonstration","In this paper we present a system capable of collecting and annotating, human
performed, robot understandable, everyday activities from virtual environments.
The human movements are mapped in the simulated world using off-the-shelf
virtual reality devices with full body, and eye tracking capabilities. All the
interactions in the virtual world are physically simulated, thus movements and
their effects are closely relatable to the real world. During the activity
execution, a subsymbolic data logger is recording the environment and the human
gaze on a per-frame basis, enabling offline scene reproduction and replays.
Coupled with the physics engine, online monitors (symbolic data loggers) are
parsing (using various grammars) and recording events, actions, and their
effects in the simulated world.",2020-11-27,2020,2020-11,environment
"Robust Ultra-wideband Range Error Mitigation with Deep Learning at the
  Edge","Ultra-wideband (UWB) is the state-of-the-art and most popular technology for
wireless localization. Nevertheless, precise ranging and localization in
non-line-of-sight (NLoS) conditions is still an open research topic. Indeed,
multipath effects, reflections, refractions, and complexity of the indoor radio
environment can easily introduce a positive bias in the ranging measurement,
resulting in highly inaccurate and unsatisfactory position estimation. This
article proposes an efficient representation learning methodology that exploits
the latest advancement in deep learning and graph optimization techniques to
achieve effective ranging error mitigation at the edge. Channel Impulse
Response (CIR) signals are directly exploited to extract high semantic features
to estimate corrections in either NLoS or LoS conditions. Extensive
experimentation with different settings and configurations has proved the
effectiveness of our methodology and demonstrated the feasibility of a robust
and low computational power UWB range error mitigation.",2020-11-30,2020,2020-11,environment
"Emergent Complexity and Zero-shot Transfer via Unsupervised Environment
  Design","A wide range of reinforcement learning (RL) problems - including robustness,
transfer learning, unsupervised RL, and emergent complexity - require
specifying a distribution of tasks or environments in which a policy will be
trained. However, creating a useful distribution of environments is error
prone, and takes a significant amount of developer time and effort. We propose
Unsupervised Environment Design (UED) as an alternative paradigm, where
developers provide environments with unknown parameters, and these parameters
are used to automatically produce a distribution over valid, solvable
environments. Existing approaches to automatically generating environments
suffer from common failure modes: domain randomization cannot generate
structure or adapt the difficulty of the environment to the agent's learning
progress, and minimax adversarial training leads to worst-case environments
that are often unsolvable. To generate structured, solvable environments for
our protagonist agent, we introduce a second, antagonist agent that is allied
with the environment-generating adversary. The adversary is motivated to
generate environments which maximize regret, defined as the difference between
the protagonist and antagonist agent's return. We call our technique
Protagonist Antagonist Induced Regret Environment Design (PAIRED). Our
experiments demonstrate that PAIRED produces a natural curriculum of
increasingly complex environments, and PAIRED agents achieve higher zero-shot
transfer performance when tested in highly novel environments.",2020-12-03,2020,2020-12,environment
"Demonstration-efficient Inverse Reinforcement Learning in Procedurally
  Generated Environments","Deep Reinforcement Learning achieves very good results in domains where
reward functions can be manually engineered. At the same time, there is growing
interest within the community in using games based on Procedurally Content
Generation (PCG) as benchmark environments since this type of environment is
perfect for studying overfitting and generalization of agents under domain
shift. Inverse Reinforcement Learning (IRL) can instead extrapolate reward
functions from expert demonstrations, with good results even on
high-dimensional problems, however there are no examples of applying these
techniques to procedurally-generated environments. This is mostly due to the
number of demonstrations needed to find a good reward model. We propose a
technique based on Adversarial Inverse Reinforcement Learning which can
significantly decrease the need for expert demonstrations in PCG games. Through
the use of an environment with a limited set of initial seed levels, plus some
modifications to stabilize training, we show that our approach, DE-AIRL, is
demonstration-efficient and still able to extrapolate reward functions which
generalize to the fully procedural domain. We demonstrate the effectiveness of
our technique on two procedural environments, MiniGrid and DeepCrawl, for a
variety of tasks.",2020-12-04,2020,2020-12,environment
"Generating Human-Like Movement: A Comparison Between Two Approaches
  Based on Environmental Features","Modelling realistic human behaviours in simulation is an ongoing challenge
that resides between several fields like social sciences, philosophy, and
artificial intelligence. Human movement is a special type of behaviour driven
by intent (e.g. to get groceries) and the surrounding environment (e.g.
curiosity to see new interesting places). Services available online and offline
do not normally consider the environment when planning a path, which is
decisive especially on a leisure trip. Two novel algorithms have been presented
to generate human-like trajectories based on environmental features. The
Attraction-Based A* algorithm includes in its computation information from the
environmental features meanwhile, the Feature-Based A* algorithm also injects
information from the real trajectories in its computation. The human-likeness
aspect has been tested by a human expert judging the final generated
trajectories as realistic. This paper presents a comparison between the two
approaches in some key metrics like efficiency, efficacy, and hyper-parameters
sensitivity. We show how, despite generating trajectories that are closer to
the real one according to our predefined metrics, the Feature-Based A*
algorithm fall short in time efficiency compared to the Attraction-Based A*
algorithm, hindering the usability of the model in the real world.",2020-12-11,2020,2020-12,environment
Technical Opinion: From Animal Behaviour to Autonomous Robots,"With the rising applications of robots in unstructured real-world
environments, roboticists are increasingly concerned with the problems posed by
the complexity of such environments. One solution to these problems is robot
autonomy. Since nature has already solved the problem of autonomy it can be a
suitable model for developing autonomous robots. This paper presents a concise
review on robot autonomy from the perspective of animal behaviour. It examines
some state-of-the-art techniques as well as suggesting possible research
directions.",2020-12-11,2020,2020-12,environment
"Specializing Inter-Agent Communication in Heterogeneous Multi-Agent
  Reinforcement Learning using Agent Class Information","Inspired by recent advances in agent communication with graph neural
networks, this work proposes the representation of multi-agent communication
capabilities as a directed labeled heterogeneous agent graph, in which node
labels denote agent classes and edge labels, the communication type between two
classes of agents. We also introduce a neural network architecture that
specializes communication in fully cooperative heterogeneous multi-agent tasks
by learning individual transformations to the exchanged messages between each
pair of agent classes. By also employing encoding and action selection modules
with parameter sharing for environments with heterogeneous agents, we
demonstrate comparable or superior performance in environments where a larger
number of agent classes operates.",2020-12-14,2020,2020-12,environment
"Gegelati: Lightweight Artificial Intelligence through Generic and
  Evolvable Tangled Program Graphs","Tangled Program Graph (TPG) is a reinforcement learning technique based on
genetic programming concepts. On state-of-the-art learning environments, TPGs
have been shown to offer comparable competence with Deep Neural Networks
(DNNs), for a fraction of their computational and storage cost. This lightness
of TPGs, both for training and inference, makes them an interesting model to
implement Artificial Intelligences (AIs) on embedded systems with limited
computational and storage resources. In this paper, we introduce the Gegelati
library for TPGs. Besides introducing the general concepts and features of the
library, two main contributions are detailed in the paper: 1/ The
parallelization of the deterministic training process of TPGs, for supporting
heterogeneous Multiprocessor Systems-on-Chips (MPSoCs). 2/ The support for
customizable instruction sets and data types within the genetically evolved
programs of the TPG model. The scalability of the parallel training process is
demonstrated through experiments on architectures ranging from a high-end
24-core processor to a low-power heterogeneous MPSoC. The impact of
customizable instructions on the outcome of a training process is demonstrated
on a state-of-the-art reinforcement learning environment. CCS Concepts:
$\bullet$ Computer systems organization $\rightarrow$ Embedded systems;
$\bullet$ Computing methodologies $\rightarrow$ Machine learning.",2020-12-15,2020,2020-12,environment
When Is Generalizable Reinforcement Learning Tractable?,"Agents trained by reinforcement learning (RL) often fail to generalize beyond
the environment they were trained in, even when presented with new scenarios
that seem similar to the training environment. We study the query complexity
required to train RL agents that generalize to multiple environments.
Intuitively, tractable generalization is only possible when the environments
are similar or close in some sense. To capture this, we introduce Weak
Proximity, a natural structural condition that requires the environments to
have highly similar transition and reward functions and share a policy
providing optimal value. Despite such shared structure, we prove that tractable
generalization is impossible in the worst case. This holds even when each
individual environment can be efficiently solved to obtain an optimal linear
policy, and when the agent possesses a generative model. Our lower bound
applies to the more complex task of representation learning for the purpose of
efficient generalization to multiple environments. On the positive side, we
introduce Strong Proximity, a strengthened condition which we prove is
sufficient for efficient generalization.",2021-01-01,2021,2021-01,environment
Impact of Explanation on Trust of a Novel Mobile Robot,"One challenge with introducing robots into novel environments is misalignment
between supervisor expectations and reality, which can greatly affect a user's
trust and continued use of the robot. We performed an experiment to test
whether the presence of an explanation of expected robot behavior affected a
supervisor's trust in an autonomous robot. We measured trust both subjectively
through surveys and objectively through a dual-task experiment design to
capture supervisors' neglect tolerance (i.e., their willingness to perform
their own task while the robot is acting autonomously). Our objective results
show that explanations can help counteract the novelty effect of seeing a new
robot perform in an unknown environment. Participants who received an
explanation of the robot's behavior were more likely to focus on their own task
at the risk of neglecting their robot supervision task during the first trials
of the robot's behavior compared to those who did not receive an explanation.
However, this effect diminished after seeing multiple trials, and participants
who received explanations were equally trusting of the robot's behavior as
those who did not receive explanations. Interestingly, participants were not
able to identify their own changes in trust through their survey responses,
demonstrating that the dual-task design measured subtler changes in a
supervisor's trust.",2021-01-26,2021,2021-01,environment
"Improving Model-Based Reinforcement Learning with Internal State
  Representations through Self-Supervision","Using a model of the environment, reinforcement learning agents can plan
their future moves and achieve superhuman performance in board games like
Chess, Shogi, and Go, while remaining relatively sample-efficient. As
demonstrated by the MuZero Algorithm, the environment model can even be learned
dynamically, generalizing the agent to many more tasks while at the same time
achieving state-of-the-art performance. Notably, MuZero uses internal state
representations derived from real environment states for its predictions. In
this paper, we bind the model's predicted internal state representation to the
environment state via two additional terms: a reconstruction model loss and a
simpler consistency loss, both of which work independently and unsupervised,
acting as constraints to stabilize the learning process. Our experiments show
that this new integration of reconstruction model loss and simpler consistency
loss provide a significant performance increase in OpenAI Gym environments. Our
modifications also enable self-supervised pretraining for MuZero, so the
algorithm can learn about environment dynamics before a goal is made available.",2021-02-10,2021,2021-02,environment
"Artificial Intelligence Technologies in Education: Benefits, Challenges
  and Strategies of Implementation","Since the education sector is associated with highly dynamic business
environments which are controlled and maintained by information systems, recent
technological advancements and the increasing pace of adopting artificial
intelligence (AI) technologies constitute a need to identify and analyze the
issues regarding their implementation in education sector. However, a study of
the contemporary literature reveled that relatively little research has been
undertaken in this area. To fill this void, we have identified the benefits and
challenges of implementing artificial intelligence in the education sector,
preceded by a short discussion on the concepts of AI and its evolution over
time. Moreover, we have also reviewed modern AI technologies for learners and
educators, currently available on the software market, evaluating their
usefulness. Last but not least, we have developed a strategy implementation
model, described by a five-stage, generic process, along with the corresponding
configuration guide. To verify and validate their design, we separately
developed three implementation strategies for three different higher education
organizations. We believe that the obtained results will contribute to better
understanding the specificities of AI systems, services and tools, and
afterwards pave a smooth way in their implementation.",2021-02-11,2021,2021-02,environment
Towards AIOps in Edge Computing Environments,"Edge computing was introduced as a technical enabler for the demanding
requirements of new network technologies like 5G. It aims to overcome
challenges related to centralized cloud computing environments by distributing
computational resources to the edge of the network towards the customers. The
complexity of the emerging infrastructures increases significantly, together
with the ramifications of outages on critical use cases such as self-driving
cars or health care. Artificial Intelligence for IT Operations (AIOps) aims to
support human operators in managing complex infrastructures by using machine
learning methods. This paper describes the system design of an AIOps platform
which is applicable in heterogeneous, distributed environments. The overhead of
a high-frequency monitoring solution on edge devices is evaluated and
performance experiments regarding the applicability of three anomaly detection
algorithms on edge devices are conducted. The results show, that it is feasible
to collect metrics with a high frequency and simultaneously run specific
anomaly detection algorithms directly on edge devices with a reasonable
overhead on the resource utilization.",2021-02-12,2021,2021-02,environment
"Design a Technology Based on the Fusion of Genetic Algorithm, Neural
  network and Fuzzy logic","This paper describes the design and development of a prototype technique for
artificial intelligence based on the fusion of genetic algorithm, neural
network and fuzzy logic. It starts by establishing a relationship between the
neural network and fuzzy logic. Then, it combines the genetic algorithm with
them. Information fusions are at the confidence level, where matching scores
can be reported and discussed. The technique is called the Genetic Neuro-Fuzzy
(GNF). It can be used for high accuracy real-time environments.",2021-02-16,2021,2021-02,environment
"An Overview of Direct Diagnosis and Repair Techniques in the WeeVis
  Recommendation Environment","Constraint-based recommenders support users in the identification of items
(products) fitting their wishes and needs. Example domains are financial
services and electronic equipment. In this paper we show how divide-and-conquer
based (direct) diagnosis algorithms (no conflict detection is needed) can be
exploited in constraint-based recommendation scenarios. In this context, we
provide an overview of the MediaWiki-based recommendation environment WeeVis.",2021-02-24,2021,2021-02,environment
Reflections on the Clinical Acceptance of Artificial Intelligence,"In this chapter, we reflect on the use of Artificial Intelligence (AI) and
its acceptance in clinical environments. We develop a general view of
hindrances for clinical acceptance in the form of a pipeline model combining AI
and clinical practise. We then link each challenge to the relevant stage in the
pipeline and discuss the necessary requirements in order to overcome each
challenge. We complement this discussion with an overview of opportunities for
AI, which we currently see at the periphery of clinical workflows.",2021-03-01,2021,2021-03,environment
"Low-level cognitive skill transfer between two individuals' minds via
  computer game-based framework","The novel technique introduced here aims to accomplish the first stage of
transferring low-level cognitive skills between two individuals (e.g. from
expert to learner) to ease the consecutive higher level declarative learning
process for the target ""learner"" individual in a game environment. Such
low-level cognitive skill is associated with the procedural knowledge and
established at low-level of mind which can be unveiled and transferred by only
a novel technique (rather than by a traditional educational environment ) like
a highly interactive computer game domain in which a user exposes his/her
unconscious mind behaviors via the game-hero non-deliberately during the game
sessions. The cognitive data exposed by the game-hero would be recorded, and
then be modelled by the artificial intelligence technique like Bayesian
networks for an early stage of cognitive skill transfer and the cognitive
stimuli are also generated to be used as game agents to train the learner.",2021-03-03,2021,2021-03,environment
"The AI Arena: A Framework for Distributed Multi-Agent Reinforcement
  Learning","Advances in reinforcement learning (RL) have resulted in recent breakthroughs
in the application of artificial intelligence (AI) across many different
domains. An emerging landscape of development environments is making powerful
RL techniques more accessible for a growing community of researchers. However,
most existing frameworks do not directly address the problem of learning in
complex operating environments, such as dense urban settings or defense-related
scenarios, that incorporate distributed, heterogeneous teams of agents. To help
enable AI research for this important class of applications, we introduce the
AI Arena: a scalable framework with flexible abstractions for distributed
multi-agent reinforcement learning. The AI Arena extends the OpenAI Gym
interface to allow greater flexibility in learning control policies across
multiple agents with heterogeneous learning strategies and localized views of
the environment. To illustrate the utility of our framework, we present
experimental results that demonstrate performance gains due to a distributed
multi-agent learning approach over commonly-used RL techniques in several
different learning environments.",2021-03-09,2021,2021-03,environment
"Intelligent behavior depends on the ecological niche: Scaling up AI to
  human-like intelligence in socio-cultural environments","This paper outlines a perspective on the future of AI, discussing directions
for machines models of human-like intelligence. We explain how developmental
and evolutionary theories of human cognition should further inform artificial
intelligence. We emphasize the role of ecological niches in sculpting
intelligent behavior, and in particular that human intelligence was
fundamentally shaped to adapt to a constantly changing socio-cultural
environment. We argue that a major limit of current work in AI is that it is
missing this perspective, both theoretically and experimentally. Finally, we
discuss the promising approach of developmental artificial intelligence,
modeling infant development through multi-scale interaction between
intrinsically motivated learning, embodiment and a fastly changing
socio-cultural environment. This paper takes the form of an interview of
Pierre-Yves Oudeyer by Mandred Eppe, organized within the context of a KI -
K{\""{u}}nstliche Intelligenz special issue in developmental robotics.",2021-03-11,2021,2021-03,environment
"Where is your place, Visual Place Recognition?","Visual Place Recognition (VPR) is often characterized as being able to
recognize the same place despite significant changes in appearance and
viewpoint. VPR is a key component of Spatial Artificial Intelligence, enabling
robotic platforms and intelligent augmentation platforms such as augmented
reality devices to perceive and understand the physical world. In this paper,
we observe that there are three ""drivers"" that impose requirements on spatially
intelligent agents and thus VPR systems: 1) the particular agent including its
sensors and computational resources, 2) the operating environment of this
agent, and 3) the specific task that the artificial agent carries out. In this
paper, we characterize and survey key works in the VPR area considering those
drivers, including their place representation and place matching choices. We
also provide a new definition of VPR based on the visual overlap -- akin to
spatial view cells in the brain -- that enables us to find similarities and
differences to other research areas in the robotics and computer vision fields.
We identify numerous open challenges and suggest areas that require more
in-depth attention in future works.",2021-03-11,2021,2021-03,environment
Hippocampal formation-inspired probabilistic generative model,"In building artificial intelligence (AI) agents, referring to how brains
function in real environments can accelerate development by reducing the design
space. In this study, we propose a probabilistic generative model (PGM) for
navigation in uncertain environments by integrating the neuroscientific
knowledge of hippocampal formation (HF) and the engineering knowledge in
robotics and AI, namely, simultaneous localization and mapping (SLAM). We
follow the approach of brain reference architecture (BRA) (Yamakawa, 2021) to
compose the PGM and outline how to verify the model. To this end, we survey and
discuss the relationship between the HF findings and SLAM models. The proposed
hippocampal formation-inspired probabilistic generative model (HF-PGM) is
designed to be highly consistent with the anatomical structure and functions of
the HF. By referencing the brain, we elaborate on the importance of integration
of egocentric/allocentric information from the entorhinal cortex to the
hippocampus and the use of discrete-event queues.",2021-03-12,2021,2021-03,environment
Hybrid computer approach to train a machine learning system,"This book chapter describes a novel approach to training machine learning
systems by means of a hybrid computer setup i.e. a digital computer tightly
coupled with an analog computer. As an example a reinforcement learning system
is trained to balance an inverted pendulum which is simulated on an analog
computer, thus demonstrating a solution to the major challenge of adequately
simulating the environment for reinforcement learning.",2021-03-13,2021,2021-03,environment
"NMRPy: a novel NMR scripting system to implement artificial intelligence
  and advanced applications","Background: Software is an important windows to offer a variety of complex
instrument control and data processing for nuclear magnetic resonance (NMR)
spectrometer. NMR software should allow researchers to flexibly implement
various functionality according to the requirement of applications. Scripting
system can offer an open environment for NMR users to write custom programs
with basic libraries. Emerging technologies, especially multivariate
statistical analysis and artificial intelligence, have been successfully
applied to NMR applications such as metabolomics and biomacromolecules.
Scripting system should support more complex NMR libraries, which will enable
the emerging technologies to be easily implemented in the scripting
environment. Result: Here, a novel NMR scripting system named ""NMRPy"" is
introduced. In the scripting system, both Java based NMR methods and original
CPython based libraries are supported. A module was built as a bridge to
integrate the runtime environment of Java and CPython. It works as an extension
in CPython environment, as well as interacts with Java part by Java Native
Interface. Leveraging the bridge, Java based instrument control and data
processing methods can be called as a CPython style. Compared with traditional
scripting system, NMRPy is easier for NMR researchers to develop complex
functionality with fast numerical computation, multivariate statistical
analysis, deep learning etc. Non-uniform sampling and protein structure
prediction methods based on deep learning can be conveniently integrated into
NMRPy. Conclusion: NMRPy offers a user-friendly environment to implement custom
functionality leveraging its powerful basic NMR and rich CPython libraries. NMR
applications with emerging technologies can be easily integrated. The scripting
system is free of charge and can be downloaded by visiting
http://www.spinstudioj.net/nmrpy.",2021-03-27,2021,2021-03,environment
HTN Planning Domain for Deployment of Cloud Applications,"Cloud providers are facing a complex problem in configuring software
applications ready for deployment on their infrastructures. Hierarchical Task
Network (HTN) planning can provide effective means to solve such deployment
problems. We present an HTN planning domain that models deployment problems as
found in realistic Cloud environments.",2021-04-16,2021,2021-04,environment
"A Robust Model for Trust Evaluation during Interactions between Agents
  in a Sociable Environment","Trust evaluation is an important topic in both research and applications in
sociable environments. This paper presents a model for trust evaluation between
agents by the combination of direct trust, indirect trust through neighbouring
links and the reputation of an agent in the environment (i.e. social network)
to provide the robust evaluation. Our approach is typology independent from
social network structures and in a decentralized manner without a central
controller, so it can be used in broad domains.",2021-04-17,2021,2021-04,environment
Modular Procedural Generation for Voxel Maps,"Task environments developed in Minecraft are becoming increasingly popular
for artificial intelligence (AI) research. However, most of these are currently
constructed manually, thus failing to take advantage of procedural content
generation (PCG), a capability unique to virtual task environments. In this
paper, we present mcg, an open-source library to facilitate implementing PCG
algorithms for voxel-based environments such as Minecraft. The library is
designed with human-machine teaming research in mind, and thus takes a
'top-down' approach to generation, simultaneously generating low and high level
machine-readable representations that are suitable for empirical research.
These can be consumed by downstream AI applications that consider human spatial
cognition. The benefits of this approach include rapid, scalable, and efficient
development of virtual environments, the ability to control the statistics of
the environment at a semantic level, and the ability to generate novel
environments in response to player actions in real time.",2021-04-18,2021,2021-04,environment
Reinforcement Learning with Expert Trajectory For Quantitative Trading,"In recent years, quantitative investment methods combined with artificial
intelligence have attracted more and more attention from investors and
researchers. Existing related methods based on the supervised learning are not
very suitable for learning problems with long-term goals and delayed rewards in
real futures trading. In this paper, therefore, we model the price prediction
problem as a Markov decision process (MDP), and optimize it by reinforcement
learning with expert trajectory. In the proposed method, we employ more than
100 short-term alpha factors instead of price, volume and several technical
factors in used existing methods to describe the states of MDP. Furthermore,
unlike DQN (deep Q-learning) and BC (behavior cloning) in related methods, we
introduce expert experience in training stage, and consider both the
expert-environment interaction and the agent-environment interaction to design
the temporal difference error so that the agents are more adaptable for
inevitable noise in financial data. Experimental results evaluated on share
price index futures in China, including IF (CSI 300) and IC (CSI 500), show
that the advantages of the proposed method compared with three typical
technical analysis and two deep leaning based methods.",2021-05-09,2021,2021-05,environment
"Zero-Shot Reinforcement Learning on Graphs for Autonomous Exploration
  Under Uncertainty","This paper studies the problem of autonomous exploration under localization
uncertainty for a mobile robot with 3D range sensing. We present a framework
for self-learning a high-performance exploration policy in a single simulation
environment, and transferring it to other environments, which may be physical
or virtual. Recent work in transfer learning achieves encouraging performance
by domain adaptation and domain randomization to expose an agent to scenarios
that fill the inherent gaps in sim2sim and sim2real approaches. However, it is
inefficient to train an agent in environments with randomized conditions to
learn the important features of its current state. An agent can use domain
knowledge provided by human experts to learn efficiently. We propose a novel
approach that uses graph neural networks in conjunction with deep reinforcement
learning, enabling decision-making over graphs containing relevant exploration
information provided by human experts to predict a robot's optimal sensing
action in belief space. The policy, which is trained only in a single
simulation environment, offers a real-time, scalable, and transferable
decision-making strategy, resulting in zero-shot transfer to other simulation
environments and even real-world environments.",2021-05-11,2021,2021-05,environment
Model-Based Offline Planning with Trajectory Pruning,"The recent offline reinforcement learning (RL) studies have achieved much
progress to make RL usable in real-world systems by learning policies from
pre-collected datasets without environment interaction. Unfortunately, existing
offline RL methods still face many practical challenges in real-world system
control tasks, such as computational restriction during agent training and the
requirement of extra control flexibility. The model-based planning framework
provides an attractive alternative. However, most model-based planning
algorithms are not designed for offline settings. Simply combining the
ingredients of offline RL with existing methods either provides
over-restrictive planning or leads to inferior performance. We propose a new
light-weighted model-based offline planning framework, namely MOPP, which
tackles the dilemma between the restrictions of offline learning and
high-performance planning. MOPP encourages more aggressive trajectory rollout
guided by the behavior policy learned from data, and prunes out problematic
trajectories to avoid potential out-of-distribution samples. Experimental
results show that MOPP provides competitive performance compared with existing
model-based offline planning and RL approaches.",2021-05-16,2021,2021-05,environment
"Multi-Agent Deep Reinforcement Learning using Attentive Graph Neural
  Architectures for Real-Time Strategy Games","In real-time strategy (RTS) game artificial intelligence research, various
multi-agent deep reinforcement learning (MADRL) algorithms are widely and
actively used nowadays. Most of the research is based on StarCraft II
environment because it is the most well-known RTS games in world-wide. In our
proposed MADRL-based algorithm, distributed MADRL is fundamentally used that is
called QMIX. In addition to QMIX-based distributed computation, we consider
state categorization which can reduce computational complexity significantly.
Furthermore, self-attention mechanisms are used for identifying the
relationship among agents in the form of graphs. Based on these approaches, we
propose a categorized state graph attention policy (CSGA-policy). As observed
in the performance evaluation of our proposed CSGA-policy with the most
well-known StarCraft II simulation environment, our proposed algorithm works
well in various settings, as expected.",2021-05-21,2021,2021-05,environment
"An Efficient Application of Neuroevolution for Competitive Multiagent
  Learning","Multiagent systems provide an ideal environment for the evaluation and
analysis of real-world problems using reinforcement learning algorithms. Most
traditional approaches to multiagent learning are affected by long training
periods as well as high computational complexity. NEAT (NeuroEvolution of
Augmenting Topologies) is a popular evolutionary strategy used to obtain the
best performing neural network architecture often used to tackle optimization
problems in the field of artificial intelligence. This paper utilizes the NEAT
algorithm to achieve competitive multiagent learning on a modified pong game
environment in an efficient manner. The competing agents abide by different
rules while having similar observation space parameters. The proposed algorithm
utilizes this property of the environment to define a singular
neuroevolutionary procedure that obtains the optimal policy for all the agents.
The compiled results indicate that the proposed implementation achieves ideal
behaviour in a very short training period when compared to existing multiagent
reinforcement learning models.",2021-05-23,2021,2021-05,environment
"Leveraging Pre-Images to Discover Nonlinear Relationships in
  Multivariate Environments","Causal discovery, beyond the inference of a network as a collection of
connected dots, offers a crucial functionality in scientific discovery using
artificial intelligence. The questions that arise in multiple domains, such as
physics, physiology, the strategic decision in uncertain environments with
multiple agents, climatology, among many others, have roots in causality and
reasoning. It became apparent that many real-world temporal observations are
nonlinearly related to each other. While the number of observations can be as
high as millions of points, the number of temporal samples can be minimal due
to ethical or practical reasons, leading to the curse-of-dimensionality in
large-scale systems. This paper proposes a novel method using kernel principal
component analysis and pre-images to obtain nonlinear dependencies of
multivariate time-series data. We show that our method outperforms
state-of-the-art causal discovery methods when the observations are restricted
by time and are nonlinearly related. Extensive simulations on both real-world
and synthetic datasets with various topologies are provided to evaluate our
proposed methods.",2021-06-01,2021,2021-06,environment
A call for better unit testing for invariant risk minimisation,"In this paper we present a controlled study on the linearized IRM framework
(IRMv1) introduced in Arjovsky et al. (2020). We show that IRMv1 (and its
variants) framework can be potentially unstable under small changes to the
optimal regressor. This can, notably, lead to worse generalisation to new
environments, even compared with ERM which converges simply to the global
minimum for all training environments mixed up all together. We also highlight
the isseus of scaling in the the IRMv1 setup. These observations highlight the
importance of rigorous evaluation and importance of unit-testing for measuring
progress towards IRM.",2021-06-06,2021,2021-06,environment
"Explainable Artificial Intelligence (XAI) for Increasing User Trust in
  Deep Reinforcement Learning Driven Autonomous Systems","We consider the problem of providing users of deep Reinforcement Learning
(RL) based systems with a better understanding of when their output can be
trusted. We offer an explainable artificial intelligence (XAI) framework that
provides a three-fold explanation: a graphical depiction of the systems
generalization and performance in the current game state, how well the agent
would play in semantically similar environments, and a narrative explanation of
what the graphical information implies. We created a user-interface for our XAI
framework and evaluated its efficacy via a human-user experiment. The results
demonstrate a statistically significant increase in user trust and acceptance
of the AI system with explanation, versus the AI system without explanation.",2021-06-07,2021,2021-06,environment
Vector Quantized Models for Planning,"Recent developments in the field of model-based RL have proven successful in
a range of environments, especially ones where planning is essential. However,
such successes have been limited to deterministic fully-observed environments.
We present a new approach that handles stochastic and partially-observable
environments. Our key insight is to use discrete autoencoders to capture the
multiple possible effects of an action in a stochastic environment. We use a
stochastic variant of Monte Carlo tree search to plan over both the agent's
actions and the discrete latent variables representing the environment's
response. Our approach significantly outperforms an offline version of MuZero
on a stochastic interpretation of chess where the opponent is considered part
of the environment. We also show that our approach scales to DeepMind Lab, a
first-person 3D environment with large visual observations and partial
observability.",2021-06-08,2021,2021-06,environment
"Multi-Context Systems: Dynamics and Evolution (Pre-Print of
  ""Multi-context systems in dynamic environments"")","Multi-Context Systems (MCS) model in Computational Logic distributed systems
composed of heterogeneous sources, or ""contexts"", interacting via special rules
called ""bridge rules"". In this paper, we consider how to enhance flexibility
and generality in bridge-rules definition and application. In particular, we
introduce and discuss some formal extensions of MCSs useful for a practical use
in dynamic environments, and we try to provide guidelines for implementations",2021-06-12,2021,2021-06,environment
Diagnosing the Impact of AI on Radiology in China,"Artificial Intelligence will significantly impact the work environment of
radiologists. I suggest that up to 50% of a radiologists work in 2021 will be
performed by AI-models in 2025. However, it won't increase beyond that 50%
level, as radiologists remain key for human-centered aspects of their job. I
project that few to no radiologists will be laid off in China due to the
existing supply shortage of radiology services in 2021. The application of AI
in radiology could contribute 1.7 billion USD to China's GDP in 2025. It will
further allow radiologists to start productive work up to four years earlier.
AI in radiology will positively impact the health of patients and radiologists
themselves.",2021-06-15,2021,2021-06,environment
"Modelling resource allocation in uncertain system environment through
  deep reinforcement learning","Reinforcement Learning has applications in field of mechatronics, robotics,
and other resource-constrained control system. Problem of resource allocation
is primarily solved using traditional predefined techniques and modern deep
learning methods. The drawback of predefined and most deep learning methods for
resource allocation is failing to meet the requirements in cases of uncertain
system environment. We can approach problem of resource allocation in uncertain
system environment alongside following certain criteria using deep
reinforcement learning. Also, reinforcement learning has ability for adapting
to new uncertain environment for prolonged period of time. The paper provides a
detailed comparative analysis on various deep reinforcement learning methods by
applying different components to modify architecture of reinforcement learning
with use of noisy layers, prioritized replay, bagging, duelling networks, and
other related combination to obtain improvement in terms of performance and
reduction of computational cost. The paper identifies problem of resource
allocation in uncertain environment could be effectively solved using Noisy
Bagging duelling double deep Q network achieving efficiency of 97.7% by
maximizing reward with significant exploration in given simulated environment
for resource allocation.",2021-06-17,2021,2021-06,environment
"Scenic4RL: Programmatic Modeling and Generation of Reinforcement
  Learning Environments","The capability of a reinforcement learning (RL) agent heavily depends on the
diversity of the learning scenarios generated by the environment. Generation of
diverse realistic scenarios is challenging for real-time strategy (RTS)
environments. The RTS environments are characterized by intelligent
entities/non-RL agents cooperating and competing with the RL agents with large
state and action spaces over a long period of time, resulting in an infinite
space of feasible, but not necessarily realistic, scenarios involving complex
interaction among different RL and non-RL agents. Yet, most of the existing
simulators rely on randomly generating the environments based on predefined
settings/layouts and offer limited flexibility and control over the environment
dynamics for researchers to generate diverse, realistic scenarios as per their
demand. To address this issue, for the first time, we formally introduce the
benefits of adopting an existing formal scenario specification language,
SCENIC, to assist researchers to model and generate diverse scenarios in an RTS
environment in a flexible, systematic, and programmatic manner. To showcase the
benefits, we interfaced SCENIC to an existing RTS environment Google Research
Football(GRF) simulator and introduced a benchmark consisting of 32 realistic
scenarios, encoded in SCENIC, to train RL agents and testing their
generalization capabilities. We also show how researchers/RL practitioners can
incorporate their domain knowledge to expedite the training process by
intuitively modeling stochastic programmatic policies with SCENIC.",2021-06-18,2021,2021-06,environment
On the Importance of Environments in Human-Robot Coordination,"When studying robots collaborating with humans, much of the focus has been on
robot policies that coordinate fluently with human teammates in collaborative
tasks. However, less emphasis has been placed on the effect of the environment
on coordination behaviors. To thoroughly explore environments that result in
diverse behaviors, we propose a framework for procedural generation of
environments that are (1) stylistically similar to human-authored environments,
(2) guaranteed to be solvable by the human-robot team, and (3) diverse with
respect to coordination measures. We analyze the procedurally generated
environments in the Overcooked benchmark domain via simulation and an online
user study. Results show that the environments result in qualitatively
different emerging behaviors and statistically significant differences in
collaborative fluency metrics, even when the robot runs the same planning
algorithm.",2021-06-21,2021,2021-06,environment
Core Challenges in Embodied Vision-Language Planning,"Recent advances in the areas of multimodal machine learning and artificial
intelligence (AI) have led to the development of challenging tasks at the
intersection of Computer Vision, Natural Language Processing, and Embodied AI.
Whereas many approaches and previous survey pursuits have characterised one or
two of these dimensions, there has not been a holistic analysis at the center
of all three. Moreover, even when combinations of these topics are considered,
more focus is placed on describing, e.g., current architectural methods, as
opposed to also illustrating high-level challenges and opportunities for the
field. In this survey paper, we discuss Embodied Vision-Language Planning
(EVLP) tasks, a family of prominent embodied navigation and manipulation
problems that jointly use computer vision and natural language. We propose a
taxonomy to unify these tasks and provide an in-depth analysis and comparison
of the new and current algorithmic approaches, metrics, simulated environments,
as well as the datasets used for EVLP tasks. Finally, we present the core
challenges that we believe new EVLP works should seek to address, and we
advocate for task construction that enables model generalizability and furthers
real-world deployment.",2021-06-26,2021,2021-06,environment
Classical Planning in Deep Latent Space,"Current domain-independent, classical planners require symbolic models of the
problem domain and instance as input, resulting in a knowledge acquisition
bottleneck. Meanwhile, although deep learning has achieved significant success
in many fields, the knowledge is encoded in a subsymbolic representation which
is incompatible with symbolic systems such as planners. We propose Latplan, an
unsupervised architecture combining deep learning and classical planning. Given
only an unlabeled set of image pairs showing a subset of transitions allowed in
the environment (training inputs), Latplan learns a complete propositional PDDL
action model of the environment. Later, when a pair of images representing the
initial and the goal states (planning inputs) is given, Latplan finds a plan to
the goal state in a symbolic latent space and returns a visualized plan
execution. We evaluate Latplan using image-based versions of 6 planning
domains: 8-puzzle, 15-Puzzle, Blocksworld, Sokoban and Two variations of
LightsOut.",2021-06-30,2021,2021-06,environment
"Policy Transfer across Visual and Dynamics Domain Gaps via Iterative
  Grounding","The ability to transfer a policy from one environment to another is a
promising avenue for efficient robot learning in realistic settings where task
supervision is not available. This can allow us to take advantage of
environments well suited for training, such as simulators or laboratories, to
learn a policy for a real robot in a home or office. To succeed, such policy
transfer must overcome both the visual domain gap (e.g. different illumination
or background) and the dynamics domain gap (e.g. different robot calibration or
modelling error) between source and target environments. However, prior policy
transfer approaches either cannot handle a large domain gap or can only address
one type of domain gap at a time. In this paper, we propose a novel policy
transfer method with iterative ""environment grounding"", IDAPT, that alternates
between (1) directly minimizing both visual and dynamics domain gaps by
grounding the source environment in the target environment domains, and (2)
training a policy on the grounded source environment. This iterative training
progressively aligns the domains between the two environments and adapts the
policy to the target environment. Once trained, the policy can be directly
executed on the target environment. The empirical results on locomotion and
robotic manipulation tasks demonstrate that our approach can effectively
transfer a policy across visual and dynamics domain gaps with minimal
supervision and interaction with the target environment. Videos and code are
available at https://clvrai.com/idapt .",2021-07-01,2021,2021-07,environment
Collaborative Visual Navigation,"As a fundamental problem for Artificial Intelligence, multi-agent system
(MAS) is making rapid progress, mainly driven by multi-agent reinforcement
learning (MARL) techniques. However, previous MARL methods largely focused on
grid-world like or game environments; MAS in visually rich environments has
remained less explored. To narrow this gap and emphasize the crucial role of
perception in MAS, we propose a large-scale 3D dataset, CollaVN, for
multi-agent visual navigation (MAVN). In CollaVN, multiple agents are entailed
to cooperatively navigate across photo-realistic environments to reach target
locations. Diverse MAVN variants are explored to make our problem more general.
Moreover, a memory-augmented communication framework is proposed. Each agent is
equipped with a private, external memory to persistently store communication
information. This allows agents to make better use of their past communication
information, enabling more efficient collaboration and robust long-term
planning. In our experiments, several baselines and evaluation metrics are
designed. We also empirically verify the efficacy of our proposed MARL approach
across different MAVN task settings.",2021-07-02,2021,2021-07,environment
"A Systematic Survey of Text Worlds as Embodied Natural Language
  Environments","Text Worlds are virtual environments for embodied agents that, unlike 2D or
3D environments, are rendered exclusively using textual descriptions. These
environments offer an alternative to higher-fidelity 3D environments due to
their low barrier to entry, providing the ability to study semantics,
compositional inference, and other high-level tasks with rich high-level action
spaces while controlling for perceptual input. This systematic survey outlines
recent developments in tooling, environments, and agent modeling for Text
Worlds, while examining recent trends in knowledge graphs, common sense
reasoning, transfer learning of Text World performance to higher-fidelity
environments, as well as near-term development targets that, once achieved,
make Text Worlds an attractive general research paradigm for natural language
processing.",2021-07-08,2021,2021-07,environment
"Adaptive Stress Testing for Adversarial Learning in a Financial
  Environment","We demonstrate the use of Adaptive Stress Testing to detect and address
potential vulnerabilities in a financial environment. We develop a simplified
model for credit card fraud detection that utilizes a linear regression
classifier based on historical payment transaction data coupled with business
rules. We then apply the reinforcement learning model known as Adaptive Stress
Testing to train an agent, that can be thought of as a potential fraudster, to
find the most likely path to system failure -- successfully defrauding the
system. We show the connection between this most likely failure path and the
limits of the classifier and discuss how the fraud detection system's business
rules can be further augmented to mitigate these failure modes.",2021-07-08,2021,2021-07,environment
"SimDem A Multi-agent Simulation Environment to Model Persons with
  Dementia and their Assistance","Developing artificial intelligence based assistive systems to aid Persons
with Dementia (PwD) requires large amounts of training data. However, data
collection poses ethical, legal, economic, and logistic issues. Synthetic data
generation tools, in this regard, provide a potential solution. However, we
believe that already available such tools do not adequately reflect cognitive
deficiencies in behavior simulation. To counter these issues we propose a
simulation model (SimDem ) that primarily focuses on cognitive impairments
suffered by PwD and can be easily configured and adapted by the users to model
and evaluate assistive solutions.",2021-07-12,2021,2021-07,environment
"Multiclass Permanent Magnets Superstructure for Indoor Localization
  using Artificial Intelligence","Smartphones have become a popular tool for indoor localization and position
estimation of users. Existing solutions mainly employ Wi-Fi, RFID, and magnetic
sensing techniques to track movements in crowded venues. These are highly
sensitive to magnetic clutters and depend on local ambient magnetic fields,
which frequently degrades their performance. Also, these techniques often
require pre-known mapping surveys of the area, or the presence of active
beacons, which are not always available. We embed small-volume and large-moment
magnets in pre-known locations and arrange them in specific geometric
constellations that create magnetic superstructure patterns of supervised
magnetic signatures. These signatures constitute an unambiguous magnetic
environment with respect to the moving sensor carrier. The localization
algorithm learns the unique patterns of the scattered magnets during training
and detects them from the ongoing streaming of data during localization. Our
contribution is twofold. First, we deploy passive permanent magnets that do not
require a power supply, in contrast to active magnetic transmitters. Second, we
perform localization based on smartphone motion rather than on static
positioning of the magnetometer. In our previous study, we considered a single
superstructure pattern. Here, we present an extended version of that algorithm
for multi-superstructure localization, which covers a broader localization area
of the user. Experimental results demonstrate localization accuracy of 95% with
a mean localization error of less than 1m using artificial intelligence.",2021-07-14,2021,2021-07,environment
"A Reinforcement Learning Environment for Mathematical Reasoning via
  Program Synthesis","We convert the DeepMind Mathematics Dataset into a reinforcement learning
environment by interpreting it as a program synthesis problem. Each action
taken in the environment adds an operator or an input into a discrete compute
graph. Graphs which compute correct answers yield positive reward, enabling the
optimization of a policy to construct compute graphs conditioned on problem
statements. Baseline models are trained using Double DQN on various subsets of
problem types, demonstrating the capability to learn to correctly construct
graphs despite the challenges of combinatorial explosion and noisy rewards.",2021-07-15,2021,2021-07,environment
An Analysis of Reinforcement Learning for Malaria Control,"Previous work on policy learning for Malaria control has often formulated the
problem as an optimization problem assuming the objective function and the
search space have a specific structure. The problem has been formulated as
multi-armed bandits, contextual bandits and a Markov Decision Process in
isolation. Furthermore, an emphasis is put on developing new algorithms
specific to an instance of Malaria control, while ignoring a plethora of
simpler and general algorithms in the literature. In this work, we formally
study the formulation of Malaria control and present a comprehensive analysis
of several formulations used in the literature. In addition, we implement and
analyze several reinforcement learning algorithms in all formulations and
compare them to black box optimization. In contrast to previous work, our
results show that simple algorithms based on Upper Confidence Bounds are
sufficient for learning good Malaria policies, and tend to outperform their
more advanced counterparts on the malaria OpenAI Gym environment.",2021-07-19,2021,2021-07,environment
"Hindsight Value Function for Variance Reduction in Stochastic Dynamic
  Environment","Policy gradient methods are appealing in deep reinforcement learning but
suffer from high variance of gradient estimate. To reduce the variance, the
state value function is applied commonly. However, the effect of the state
value function becomes limited in stochastic dynamic environments, where the
unexpected state dynamics and rewards will increase the variance. In this
paper, we propose to replace the state value function with a novel hindsight
value function, which leverages the information from the future to reduce the
variance of the gradient estimate for stochastic dynamic environments.
  Particularly, to obtain an ideally unbiased gradient estimate, we propose an
information-theoretic approach, which optimizes the embeddings of the future to
be independent of previous actions. In our experiments, we apply the proposed
hindsight value function in stochastic dynamic environments, including
discrete-action environments and continuous-action environments. Compared with
the standard state value function, the proposed hindsight value function
consistently reduces the variance, stabilizes the training, and improves the
eventual policy.",2021-07-26,2021,2021-07,environment
"Towards Industrial Private AI: A two-tier framework for data and model
  security","With the advances in 5G and IoT devices, the industries are vastly adopting
artificial intelligence (AI) techniques for improving classification and
prediction-based services. However, the use of AI also raises concerns
regarding privacy and security that can be misused or leaked. Private AI was
recently coined to address the data security issue by combining AI with
encryption techniques, but existing studies have shown that model inversion
attacks can be used to reverse engineer the images from model parameters. In
this regard, we propose a Federated Learning and Encryption-based Private
(FLEP) AI framework that provides two-tier security for data and model
parameters in an IIoT environment. We proposed a three-layer encryption method
for data security and provide a hypothetical method to secure the model
parameters. Experimental results show that the proposed method achieves better
encryption quality at the expense of slightly increased execution time. We also
highlight several open issues and challenges regarding the FLEP AI framework's
realization.",2021-07-27,2021,2021-07,environment
"Indoor Localization Under Limited Measurements: A Cross-Environment
  Joint Semi-Supervised and Transfer Learning Approach","The development of highly accurate deep learning methods for indoor
localization is often hindered by the unavailability of sufficient data
measurements in the desired environment to perform model training. To overcome
the challenge of collecting costly measurements, this paper proposes a
cross-environment approach that compensates for insufficient labelled
measurements via a joint semi-supervised and transfer learning technique to
transfer, in an appropriate manner, the model obtained from a rich-data
environment to the desired environment for which data is limited. This is
achieved via a sequence of operations that exploit the similarity across
environments to enhance unlabelled data model training of the desired
environment. Numerical experiments demonstrate that the proposed
cross-environment approach outperforms the conventional method, convolutional
neural network (CNN), with a significant increase in localization accuracy, up
to 43%. Moreover, with only 40% data measurements, the proposed
cross-environment approach compensates for data inadequacy and replicates the
localization accuracy of the conventional method, CNN, which uses 75% data
measurements.",2021-08-04,2021,2021-08,environment
"Artificial Intelligence-Driven Customized Manufacturing Factory: Key
  Technologies, Applications, and Challenges","The traditional production paradigm of large batch production does not offer
flexibility towards satisfying the requirements of individual customers. A new
generation of smart factories is expected to support new multi-variety and
small-batch customized production modes. For that, Artificial Intelligence (AI)
is enabling higher value-added manufacturing by accelerating the integration of
manufacturing and information communication technologies, including computing,
communication, and control. The characteristics of a customized smart factory
are to include self-perception, operations optimization, dynamic
reconfiguration, and intelligent decision-making. The AI technologies will
allow manufacturing systems to perceive the environment, adapt to external
needs, and extract the processed knowledge, including business models, such as
intelligent production, networked collaboration, and extended service models.
  This paper focuses on the implementation of AI in customized manufacturing
(CM). The architecture of an AI-driven customized smart factory is presented.
Details of intelligent manufacturing devices, intelligent information
interaction, and the construction of a flexible manufacturing line are
showcased. The state-of-the-art AI technologies of potential use in CM, i.e.,
machine learning, multi-agent systems, Internet of Things, big data, and
cloud-edge computing are surveyed. The AI-enabled technologies in a customized
smart factory are validated with a case study of customized packaging. The
experimental results have demonstrated that the AI-assisted CM offers the
possibility of higher production flexibility and efficiency. Challenges and
solutions related to AI in CM are also discussed.",2021-08-07,2021,2021-08,environment
Toward Human-Level Artificial Intelligence,"In this paper, we present our research on programming human-level artificial
intelligence (HLAI), including 1) a definition of HLAI, 2) an environment to
develop and test HLAI, and 3) a cognitive architecture for HLAI. The term AI is
used in a broad meaning, and HLAI is not clearly defined. I claim that the
essence of Human-Level Intelligence to be the capability to learn from others'
experiences via language. The key is that the event described by language has
the same effect as if the agent experiences it firsthand for the update of the
behavior policy. To develop and test models with such a capability, we are
developing a simulated environment called SEDRo. There is a 3D Home, and a
mother character takes care of the baby (the learning agent) and teaches
languages. The environment provides comparable experiences to that of a human
baby from birth to one year. Finally, I propose a cognitive architecture of
HLAI called Modulated Heterarchical Prediction Memory (mHPM). In mHPM, there
are three components: a universal module that learns to predict the next vector
given the sequence of vector signals, a heterarchical network of those modules,
and a reward-based modulation of learning. mHPM models the workings of the
neocortex but the innate auxiliary units such hippocampus, reward system,
instincts, and amygdala play critical roles, too.",2021-08-09,2021,2021-08,environment
Adversary agent reinforcement learning for pursuit-evasion,"A reinforcement learning environment with adversary agents is proposed in
this work for pursuit-evasion game in the presence of fog of war, which is of
both scientific significance and practical importance in aerospace
applications. One of the most popular learning environments, StarCraft, is
adopted here and the associated mini-games are analyzed to identify the current
limitation for training adversary agents. The key contribution includes the
analysis of the potential performance of an agent by incorporating control and
differential game theory into the specific reinforcement learning environment,
and the development of an adversary agents challenge (SAAC) environment by
extending the current StarCraft mini-games. The subsequent study showcases the
use of this learning environment and the effectiveness of an adversary agent
for evasion units. Overall, the proposed SAAC environment should benefit
pursuit-evasion studies with rapidly-emerging reinforcement learning
technologies. Last but not least, the corresponding tutorial code can be found
at GitHub.",2021-08-25,2021,2021-08,environment
"Eden: A Unified Environment Framework for Booming Reinforcement Learning
  Algorithms","With AlphaGo defeats top human players, reinforcement learning(RL) algorithms
have gradually become the code-base of building stronger artificial
intelligence(AI). The RL algorithm design firstly needs to adapt to the
specific environment, so the designed environment guides the rapid and profound
development of RL algorithms. However, the existing environments, which can be
divided into real world games and customized toy environments, have obvious
shortcomings. For real world games, it is designed for human entertainment, and
too much difficult for most of RL researchers. For customized toy environments,
there is no widely accepted unified evaluation standard for all RL algorithms.
Therefore, we introduce the first virtual user-friendly environment framework
for RL. In this framework, the environment can be easily configured to realize
all kinds of RL tasks in the mainstream research. Then all the mainstream
state-of-the-art(SOTA) RL algorithms can be conveniently evaluated and
compared. Therefore, our contributions mainly includes the following aspects:
1.single configured environment for all classification of SOTA RL algorithms;
2.combined environment of more than one classification RL algorithms; 3.the
evaluation standard for all kinds of RL algorithms. With all these efforts, a
possibility for breeding an AI with capability of general competency in a
variety of tasks is provided, and maybe it will open up a new chapter for AI.",2021-09-04,2021,2021-09,environment
"Puzzle Solving without Search or Human Knowledge: An Unnatural Language
  Approach","The application of Generative Pre-trained Transformer (GPT-2) to learn
text-archived game notation provides a model environment for exploring sparse
reward gameplay. The transformer architecture proves amenable to training on
solved text archives describing mazes, Rubik's Cube, and Sudoku solvers. The
method benefits from fine-tuning the transformer architecture to visualize
plausible strategies derived outside any guidance from human heuristics or
domain expertise. The large search space ($>10^{19}$) for the games provides a
puzzle environment in which the solution has few intermediate rewards and a
final move that solves the challenge.",2021-09-07,2021,2021-09,environment
"DPMPC-Planner: A real-time UAV trajectory planning framework for complex
  static environments with dynamic obstacles","Safe UAV navigation is challenging due to the complex environment structures,
dynamic obstacles, and uncertainties from measurement noises and unpredictable
moving obstacle behaviors. Although plenty of recent works achieve safe
navigation in complex static environments with sophisticated mapping
algorithms, such as occupancy map and ESDF map, these methods cannot reliably
handle dynamic environments due to the mapping limitation from moving
obstacles. To address the limitation, this paper proposes a trajectory planning
framework to achieve safe navigation considering complex static environments
with dynamic obstacles. To reliably handle dynamic obstacles, we divide the
environment representation into static mapping and dynamic object
representation, which can be obtained from computer vision methods. Our
framework first generates a static trajectory based on the proposed iterative
corridor shrinking algorithm. Then, reactive chance-constrained model
predictive control with temporal goal tracking is applied to avoid dynamic
obstacles with uncertainties. The simulation results in various environments
demonstrate the ability of our algorithm to navigate safely in complex static
environments with dynamic obstacles.",2021-09-14,2021,2021-09,environment
"Agile, Antifragile, Artificial-Intelligence-Enabled, Command and Control","Artificial Intelligence (AI) is rapidly becoming integrated into military
Command and Control (C2) systems as a strategic priority for many defence
forces. The successful implementation of AI is promising to herald a
significant leap in C2 agility through automation. However, realistic
expectations need to be set on what AI can achieve in the foreseeable future.
This paper will argue that AI could lead to a fragility trap, whereby the
delegation of C2 functions to an AI could increase the fragility of C2,
resulting in catastrophic strategic failures. This calls for a new framework
for AI in C2 to avoid this trap. We will argue that antifragility along with
agility should form the core design principles for AI-enabled C2 systems. This
duality is termed Agile, Antifragile, AI-Enabled Command and Control (A3IC2).
An A3IC2 system continuously improves its capacity to perform in the face of
shocks and surprises through overcompensation from feedback during the C2
decision-making cycle. An A3IC2 system will not only be able to survive within
a complex operational environment, it will also thrive, benefiting from the
inevitable shocks and volatility of war.",2021-09-14,2021,2021-09,environment
"Computational Imaging and Artificial Intelligence: The Next Revolution
  of Mobile Vision","Signal capture stands in the forefront to perceive and understand the
environment and thus imaging plays the pivotal role in mobile vision. Recent
explosive progresses in Artificial Intelligence (AI) have shown great potential
to develop advanced mobile platforms with new imaging devices. Traditional
imaging systems based on the ""capturing images first and processing afterwards""
mechanism cannot meet this unprecedented demand. Differently, Computational
Imaging (CI) systems are designed to capture high-dimensional data in an
encoded manner to provide more information for mobile vision systems.Thanks to
AI, CI can now be used in real systems by integrating deep learning algorithms
into the mobile vision platform to achieve the closed loop of intelligent
acquisition, processing and decision making, thus leading to the next
revolution of mobile vision.Starting from the history of mobile vision using
digital cameras, this work first introduces the advances of CI in diverse
applications and then conducts a comprehensive review of current research
topics combining CI and AI. Motivated by the fact that most existing studies
only loosely connect CI and AI (usually using AI to improve the performance of
CI and only limited works have deeply connected them), in this work, we propose
a framework to deeply integrate CI and AI by using the example of self-driving
vehicles with high-speed communication, edge computing and traffic planning.
Finally, we outlook the future of CI plus AI by investigating new materials,
brain science and new computing techniques to shed light on new directions of
mobile vision systems.",2021-09-18,2021,2021-09,environment
"Artificial intelligence for Sustainable Energy: A Contextual Topic
  Modeling and Content Analysis","Parallel to the rising debates over sustainable energy and artificial
intelligence solutions, the world is currently discussing the ethics of
artificial intelligence and its possible negative effects on society and the
environment. In these arguments, sustainable AI is proposed, which aims at
advancing the pathway toward sustainability, such as sustainable energy. In
this paper, we offered a novel contextual topic modeling combining LDA, BERT,
and Clustering. We then combined these computational analyses with content
analysis of related scientific publications to identify the main scholarly
topics, sub-themes, and cross-topic themes within scientific research on
sustainable AI in energy. Our research identified eight dominant topics
including sustainable buildings, AI-based DSSs for urban water management,
climate artificial intelligence, Agriculture 4, the convergence of AI with IoT,
AI-based evaluation of renewable technologies, smart campus and engineering
education, and AI-based optimization. We then recommended 14 potential future
research strands based on the observed theoretical gaps. Theoretically, this
analysis contributes to the existing literature on sustainable AI and
sustainable energy, and practically, it intends to act as a general guide for
energy engineers and scientists, AI scientists, and social scientists to widen
their knowledge of sustainability in AI and energy convergence research.",2021-10-02,2021,2021-10,environment
Multi-Agent Path Planning Using Deep Reinforcement Learning,"In this paper a deep reinforcement based multi-agent path planning approach
is introduced. The experiments are realized in a simulation environment and in
this environment different multi-agent path planning problems are produced. The
produced problems are actually similar to a vehicle routing problem and they
are solved using multi-agent deep reinforcement learning. In the simulation
environment, the model is trained on different consecutive problems in this way
and, as the time passes, it is observed that the model's performance to solve a
problem increases. Always the same simulation environment is used and only the
location of target points for the agents to visit is changed. This contributes
the model to learn its environment and the right attitude against a problem as
the episodes pass. At the end, a model who has already learned a lot to solve a
path planning or routing problem in this environment is obtained and this model
can already find a nice and instant solution to a given unseen problem even
without any training. In routing problems, standard mathematical modeling or
heuristics seem to suffer from high computational time to find the solution and
it is also difficult and critical to find an instant solution. In this paper a
new solution method against these points is proposed and its efficiency is
proven experimentally.",2021-10-04,2021,2021-10,environment
"Towards Robust and Transferable IIoT Sensor based Anomaly Classification
  using Artificial Intelligence","The increasing deployment of low-cost industrial IoT (IIoT) sensor platforms
on industrial assets enables great opportunities for anomaly classification in
industrial plants. The performance of such a classification model depends
highly on the available training data. Models perform well when the training
data comes from the same machine. However, as soon as the machine is changed,
repaired, or put into operation in a different environment, the prediction
often fails. For this reason, we investigate whether it is feasible to have a
robust and transferable method for AI based anomaly classification using
different models and pre-processing steps on centrifugal pumps which are
dismantled and put back into operation in the same as well as in different
environments. Further, we investigate the model performance on different pumps
from the same type compared to those from the training data.",2021-10-07,2021,2021-10,environment
"Using Human-Guided Causal Knowledge for More Generalized Robot Task
  Planning","A major challenge in research involving artificial intelligence (AI) is the
development of algorithms that can find solutions to problems that can
generalize to different environments and tasks. Unlike AI, humans are adept at
finding solutions that can transfer. We hypothesize this is because their
solutions are informed by causal models. We propose to use human-guided causal
knowledge to help robots find solutions that can generalize to a new
environment. We develop and test the feasibility of a language interface that
na\""ive participants can use to communicate these causal models to a planner.
We find preliminary evidence that participants are able to use our interface
and generate causal models that achieve near-generalization. We outline an
experiment aimed at testing far-generalization using our interface and describe
our longer terms goals for these causal models.",2021-10-09,2021,2021-10,environment
"Perceptions and attitudes of Children and Young People to Artificial
  Intelligence in Medicine","There is increasing interest in Artificial Intelligence and its application
to medicine. Perceptions are less well-known, notably amongst children and
young people. 21 members of a Young Persons Advisory Group for research,
recommend creating an enabling environment with children and young people,
through educational workshops with practical examples that use Artificial
Intelligence to help, but not replace humans, address issues, build trust, and
effectively communicate about potential opportunities.",2021-10-10,2021,2021-10,environment
"Planning from Pixels in Environments with Combinatorially Hard Search
  Spaces","The ability to form complex plans based on raw visual input is a litmus test
for current capabilities of artificial intelligence, as it requires a seamless
combination of visual processing and abstract algorithmic execution, two
traditionally separate areas of computer science. A recent surge of interest in
this field brought advances that yield good performance in tasks ranging from
arcade games to continuous control; these methods however do not come without
significant issues, such as limited generalization capabilities and
difficulties when dealing with combinatorially hard planning instances. Our
contribution is two-fold: (i) we present a method that learns to represent its
environment as a latent graph and leverages state reidentification to reduce
the complexity of finding a good policy from exponential to linear (ii) we
introduce a set of lightweight environments with an underlying discrete
combinatorial structure in which planning is challenging even for humans.
Moreover, we show that our methods achieves strong empirical generalization to
variations in the environment, even across highly disadvantaged regimes, such
as ""one-shot"" planning, or in an offline RL paradigm which only provides
low-quality trajectories.",2021-10-12,2021,2021-10,environment
"Extending Environments To Measure Self-Reflection In Reinforcement
  Learning","We consider an extended notion of reinforcement learning in which the
environment can simulate the agent and base its outputs on the agent's
hypothetical behavior. Since good performance usually requires paying attention
to whatever things the environment's outputs are based on, we argue that for an
agent to achieve on-average good performance across many such extended
environments, it is necessary for the agent to self-reflect. Thus
weighted-average performance over the space of all suitably well-behaved
extended environments could be considered a way of measuring how
self-reflective an agent is. We give examples of extended environments and
introduce a simple transformation which experimentally seems to increase some
standard RL agents' performance in a certain type of extended environment.",2021-10-13,2021,2021-10,environment
sbp-env: Sampling-based Motion Planners' Testing Environment,"Sampling-based motion planners' testing environment (sbp-env) is a full
feature framework to quickly test different sampling-based algorithms for
motion planning. sbp-env focuses on the flexibility of tinkering with different
aspects of the framework, and had divided the main planning components into two
categories (i) samplers and (ii) planners.
  The focus of motion planning research had been mainly on (i) improving the
sampling efficiency (with methods such as heuristic or learned distribution)
and (ii) the algorithmic aspect of the planner using different routines to
build a connected graph. Therefore, by separating the two components one can
quickly swap out different components to test novel ideas.",2021-10-15,2021,2021-10,environment
Anticipation-driven Adaptive Architecture for Assisted Living,"Anticipatory expression underlies human performance. Medical conditions and,
especially, aging result in diminished anticipatory action. In order to
mitigate the loss, means for engaging still available resources (capabilities)
can be provided. In particular, anticipation-driven adaptive environments could
be beneficial in medical care, as well as in assisted living for those seeking
such assistance. These adaptive environments are conceived to be individualized
and individualizable, in order to stimulate independent action instead of
creating dependencies.",2021-10-15,2021,2021-10,environment
"SILG: The Multi-environment Symbolic Interactive Language Grounding
  Benchmark","Existing work in language grounding typically study single environments. How
do we build unified models that apply across multiple environments? We propose
the multi-environment Symbolic Interactive Language Grounding benchmark (SILG),
which unifies a collection of diverse grounded language learning environments
under a common interface. SILG consists of grid-world environments that require
generalization to new dynamics, entities, and partially observed worlds (RTFM,
Messenger, NetHack), as well as symbolic counterparts of visual worlds that
require interpreting rich natural language with respect to complex scenes
(ALFWorld, Touchdown). Together, these environments provide diverse grounding
challenges in richness of observation space, action space, language
specification, and plan complexity. In addition, we propose the first shared
model architecture for RL on these environments, and evaluate recent advances
such as egocentric local convolution, recurrent state-tracking, entity-centric
attention, and pretrained LM using SILG. Our shared architecture achieves
comparable performance to environment-specific architectures. Moreover, we find
that many recent modelling advances do not result in significant gains on
environments other than the one they were designed for. This highlights the
need for a multi-environment benchmark. Finally, the best models significantly
underperform humans on SILG, which suggests ample room for future work. We hope
SILG enables the community to quickly identify new methodologies for language
grounding that generalize to a diverse set of environments and their associated
challenges.",2021-10-20,2021,2021-10,environment
"Unraveling the Hidden Environmental Impacts of AI Solutions for
  Environment","In the past ten years, artificial intelligence has encountered such dramatic
progress that it is now seen as a tool of choice to solve environmental issues
and in the first place greenhouse gas emissions (GHG). At the same time the
deep learning community began to realize that training models with more and
more parameters requires a lot of energy and as a consequence GHG emissions. To
our knowledge, questioning the complete net environmental impacts of AI
solutions for the environment (AI for Green), and not only GHG, has never been
addressed directly. In this article, we propose to study the possible negative
impacts of AI for Green. First, we review the different types of AI impacts,
then we present the different methodologies used to assess those impacts, and
show how to apply life cycle assessment to AI services. Finally, we discuss how
to assess the environmental usefulness of a general AI service, and point out
the limitations of existing work in AI for Green.",2021-10-22,2021,2021-10,environment
Adaptability of Improved NEAT in Variable Environments,"A large challenge in Artificial Intelligence (AI) is training control agents
that can properly adapt to variable environments. Environments in which the
conditions change can cause issues for agents trying to operate in them.
Building algorithms that can train agents to operate in these environments and
properly deal with the changing conditions is therefore important.
NeuroEvolution of Augmenting Topologies (NEAT) was a novel Genetic Algorithm
(GA) when it was created, but has fallen aside with newer GAs outperforming it.
This paper furthers the research on this subject by implementing various
versions of improved NEAT in a variable environment to determine if NEAT can
perform well in these environments. The improvements included, in every
combination, are: recurrent connections, automatic feature selection, and
increasing population size. The recurrent connections improvement performed
extremely well. The automatic feature selection improvement was found to be
detrimental to performance, and the increasing population size improvement
lowered performance a small amount, but decreased computation requirements
noticeably.",2021-10-22,2021,2021-10,environment
"Transfer learning with causal counterfactual reasoning in Decision
  Transformers","The ability to adapt to changes in environmental contingencies is an
important challenge in reinforcement learning. Indeed, transferring previously
acquired knowledge to environments with unseen structural properties can
greatly enhance the flexibility and efficiency by which novel optimal policies
may be constructed. In this work, we study the problem of transfer learning
under changes in the environment dynamics. In this study, we apply causal
reasoning in the offline reinforcement learning setting to transfer a learned
policy to new environments. Specifically, we use the Decision Transformer (DT)
architecture to distill a new policy on the new environment. The DT is trained
on data collected by performing policy rollouts on factual and counterfactual
simulations from the source environment. We show that this mechanism can
bootstrap a successful policy on the target environment while retaining most of
the reward.",2021-10-27,2021,2021-10,environment
"Investigation of Independent Reinforcement Learning Algorithms in
  Multi-Agent Environments","Independent reinforcement learning algorithms have no theoretical guarantees
for finding the best policy in multi-agent settings. However, in practice,
prior works have reported good performance with independent algorithms in some
domains and bad performance in others. Moreover, a comprehensive study of the
strengths and weaknesses of independent algorithms is lacking in the
literature. In this paper, we carry out an empirical comparison of the
performance of independent algorithms on four PettingZoo environments that span
the three main categories of multi-agent environments, i.e., cooperative,
competitive, and mixed. We show that in fully-observable environments,
independent algorithms can perform on par with multi-agent algorithms in
cooperative and competitive settings. For the mixed environments, we show that
agents trained via independent algorithms learn to perform well individually,
but fail to learn to cooperate with allies and compete with enemies. We also
show that adding recurrence improves the learning of independent algorithms in
cooperative partially observable environments.",2021-11-01,2021,2021-11,environment
Ten Conceptual Dimensions of Context,"This paper attempts to synthesize various conceptualizations of the term
""context"" as found in computing literature. Ten conceptual dimensions of
context thus emerge -- location; user, task, and system characteristics;
physical, social, organizational, and cultural environments; time-related
aspects, and historical information. Together, the ten dimensions of context
provide a comprehensive view of the notion of context, and allow for a more
systematic examination of the influence of context and contextual information
on human-system or human-AI interactions.",2021-11-04,2021,2021-11,environment
Robust Deep Reinforcement Learning for Quadcopter Control,"Deep reinforcement learning (RL) has made it possible to solve complex
robotics problems using neural networks as function approximators. However, the
policies trained on stationary environments suffer in terms of generalization
when transferred from one environment to another. In this work, we use Robust
Markov Decision Processes (RMDP) to train the drone control policy, which
combines ideas from Robust Control and RL. It opts for pessimistic optimization
to handle potential gaps between policy transfer from one environment to
another. The trained control policy is tested on the task of quadcopter
positional control. RL agents were trained in a MuJoCo simulator. During
testing, different environment parameters (unseen during the training) were
used to validate the robustness of the trained policy for transfer from one
environment to another. The robust policy outperformed the standard agents in
these environments, suggesting that the added robustness increases generality
and can adapt to non-stationary environments.
  Codes: https://github.com/adipandas/gym_multirotor",2021-11-06,2021,2021-11,environment
"Artificial Intelligence Technology analysis using Artificial
  Intelligence patent through Deep Learning model and vector space model","Thanks to rapid development of artificial intelligence technology in recent
years, the current artificial intelligence technology is contributing to many
part of society. Education, environment, medical care, military, tourism,
economy, politics, etc. are having a very large impact on society as a whole.
For example, in the field of education, there is an artificial intelligence
tutoring system that automatically assigns tutors based on student's level. In
the field of economics, there are quantitative investment methods that
automatically analyze large amounts of data to find investment laws to create
investment models or predict changes in financial markets. As such, artificial
intelligence technology is being used in various fields. So, it is very
important to know exactly what factors have an important influence on each
field of artificial intelligence technology and how the relationship between
each field is connected. Therefore, it is necessary to analyze artificial
intelligence technology in each field. In this paper, we analyze patent
documents related to artificial intelligence technology. We propose a method
for keyword analysis within factors using artificial intelligence patent data
sets for artificial intelligence technology analysis. This is a model that
relies on feature engineering based on deep learning model named KeyBERT, and
using vector space model. A case study of collecting and analyzing artificial
intelligence patent data was conducted to show how the proposed model can be
applied to real world problems.",2021-11-08,2021,2021-11,environment
"Machine Learning Models Disclosure from Trusted Research Environments
  (TRE), Challenges and Opportunities","Artificial intelligence (AI) applications in healthcare and medicine have
increased in recent years. To enable access to personal data, Trusted Research
environments (TREs) provide safe and secure environments in which researchers
can access sensitive personal data and develop Artificial Intelligence (AI) and
Machine Learning models. However currently few TREs support the use of
automated AI-based modelling using Machine Learning. Early attempts have been
made in the literature to present and introduce privacy preserving machine
learning from the design point of view [1]. However, there exists a gap in the
practical decision-making guidance for TREs in handling models disclosure.
Specifically, the use of machine learning creates a need to disclose new types
of outputs from TREs, such as trained machine learning models. Although TREs
have clear policies for the disclosure of statistical outputs, the extent to
which trained models can leak personal training data once released is not well
understood and guidelines do not exist within TREs for the safe disclosure of
these models.
  In this paper we introduce the challenge of disclosing trained machine
learning models from TREs. We first give an overview of machine learning models
in general and describe some of their applications in healthcare and medicine.
We define the main vulnerabilities of trained machine learning models in
general. We also describe the main factors affecting the vulnerabilities of
disclosing machine learning models. This paper also provides insights and
analyses methods that could be introduced within TREs to mitigate the risk of
privacy breaches when disclosing trained models.",2021-11-10,2021,2021-11,environment
VisualEnv: visual Gym environments with Blender,"In this paper VisualEnv, a new tool for creating visual environment for
reinforcement learning is introduced. It is the product of an integration of an
open-source modelling and rendering software, Blender, and a python module used
to generate environment model for simulation, OpenAI Gym. VisualEnv allows the
user to create custom environments with photorealistic rendering capabilities
and full integration with python. The framework is described and tested on a
series of example problems that showcase its features for training
reinforcement learning agents.",2021-11-15,2021,2021-11,environment
The Prominence of Artificial Intelligence in COVID-19,"In December 2019, a novel virus called COVID-19 had caused an enormous number
of causalities to date. The battle with the novel Coronavirus is baffling and
horrifying after the Spanish Flu 2019. While the front-line doctors and medical
researchers have made significant progress in controlling the spread of the
highly contiguous virus, technology has also proved its significance in the
battle. Moreover, Artificial Intelligence has been adopted in many medical
applications to diagnose many diseases, even baffling experienced doctors.
Therefore, this survey paper explores the methodologies proposed that can aid
doctors and researchers in early and inexpensive methods of diagnosis of the
disease. Most developing countries have difficulties carrying out tests using
the conventional manner, but a significant way can be adopted with Machine and
Deep Learning. On the other hand, the access to different types of medical
images has motivated the researchers. As a result, a mammoth number of
techniques are proposed. This paper first details the background knowledge of
the conventional methods in the Artificial Intelligence domain. Following that,
we gather the commonly used datasets and their use cases to date. In addition,
we also show the percentage of researchers adopting Machine Learning over Deep
Learning. Thus we provide a thorough analysis of this scenario. Lastly, in the
research challenges, we elaborate on the problems faced in COVID-19 research,
and we address the issues with our understanding to build a bright and healthy
environment.",2021-11-18,2021,2021-11,environment
Expert-Guided Symmetry Detection in Markov Decision Processes,"Learning a Markov Decision Process (MDP) from a fixed batch of trajectories
is a non-trivial task whose outcome's quality depends on both the amount and
the diversity of the sampled regions of the state-action space. Yet, many MDPs
are endowed with invariant reward and transition functions with respect to some
transformations of the current state and action. Being able to detect and
exploit these structures could benefit not only the learning of the MDP but
also the computation of its subsequent optimal control policy. In this work we
propose a paradigm, based on Density Estimation methods, that aims to detect
the presence of some already supposed transformations of the state-action space
for which the MDP dynamics is invariant. We tested the proposed approach in a
discrete toroidal grid environment and in two notorious environments of
OpenAI's Gym Learning Suite. The results demonstrate that the model
distributional shift is reduced when the dataset is augmented with the data
obtained by using the detected symmetries, allowing for a more thorough and
data-efficient learning of the transition functions.",2021-11-19,2021,2021-11,environment
"Inducing Functions through Reinforcement Learning without Task
  Specification","We report a bio-inspired framework for training a neural network through
reinforcement learning to induce high level functions within the network. Based
on the interpretation that animals have gained their cognitive functions such
as object recognition - without ever being specifically trained for - as a
result of maximizing their fitness to the environment, we place our agent in an
environment where developing certain functions may facilitate decision making.
The experimental results show that high level functions, such as image
classification and hidden variable estimation, can be naturally and
simultaneously induced without any pre-training or specifying them.",2021-11-23,2021,2021-11,environment
Architecting and Visualizing Deep Reinforcement Learning Models,"To meet the growing interest in Deep Reinforcement Learning (DRL), we sought
to construct a DRL-driven Atari Pong agent and accompanying visualization tool.
Existing approaches do not support the flexibility required to create an
interactive exhibit with easily-configurable physics and a human-controlled
player. Therefore, we constructed a new Pong game environment, discovered and
addressed a number of unique data deficiencies that arise when applying DRL to
a new environment, architected and tuned a policy gradient based DRL model,
developed a real-time network visualization, and combined these elements into
an interactive display to help build intuition and awareness of the mechanics
of DRL inference.",2021-12-02,2021,2021-12,environment
"Est-ce que vous compute? Code-switching, cultural identity, and AI","Cultural code-switching concerns how we adjust our overall behaviours,
manners of speaking, and appearance in response to a perceived change in our
social environment. We defend the need to investigate cultural code-switching
capacities in artificial intelligence systems. We explore a series of ethical
and epistemic issues that arise when bringing cultural code-switching to bear
on artificial intelligence. Building upon Dotson's (2014) analysis of
testimonial smothering, we discuss how emerging technologies in AI can give
rise to epistemic oppression, and specifically, a form of self-silencing that
we call 'cultural smothering'. By leaving the socio-dynamic features of
cultural code-switching unaddressed, AI systems risk negatively impacting
already-marginalised social groups by widening opportunity gaps and further
entrenching social inequalities.",2021-12-15,2021,2021-12,environment
"Explainable Artificial Intelligence for Autonomous Driving: A
  Comprehensive Overview and Field Guide for Future Research Directions","Autonomous driving has achieved significant milestones in research and
development over the last two decades. There is increasing interest in the
field as the deployment of autonomous vehicles (AVs) promises safer and more
ecologically friendly transportation systems. With the rapid progress in
computationally powerful artificial intelligence (AI) techniques, AVs can sense
their environment with high precision, make safe real-time decisions, and
operate reliably without human intervention. However, intelligent
decision-making in such vehicles is not generally understandable by humans in
the current state of the art, and such deficiency hinders this technology from
being socially acceptable. Hence, aside from making safe real-time decisions,
AVs must also explain their AI-guided decision-making process in order to be
regulatory compliant across many jurisdictions. Our study sheds comprehensive
light on the development of explainable artificial intelligence (XAI)
approaches for AVs. In particular, we make the following contributions. First,
we provide a thorough overview of the state-of-the-art and emerging approaches
for XAI-based autonomous driving. We then propose a conceptual framework that
considers the essential elements for explainable end-to-end autonomous driving.
Finally, we present XAI-based prospective directions and emerging paradigms for
future directions that hold promise for enhancing transparency,
trustworthiness, and societal acceptance of AVs.",2021-12-21,2021,2021-12,environment
On some Foundational Aspects of Human-Centered Artificial Intelligence,"The burgeoning of AI has prompted recommendations that AI techniques should
be ""human-centered"". However, there is no clear definition of what is meant by
Human Centered Artificial Intelligence, or for short, HCAI. This paper aims to
improve this situation by addressing some foundational aspects of HCAI. To do
so, we introduce the term HCAI agent to refer to any physical or software
computational agent equipped with AI components and that interacts and/or
collaborates with humans. This article identifies five main conceptual
components that participate in an HCAI agent: Observations, Requirements,
Actions, Explanations and Models. We see the notion of HCAI agent, together
with its components and functions, as a way to bridge the technical and
non-technical discussions on human-centered AI. In this paper, we focus our
analysis on scenarios consisting of a single agent operating in dynamic
environments in presence of humans.",2021-12-29,2021,2021-12,environment
"Dynamic programming with incomplete information to overcome navigational
  uncertainty in a nautical environment","Using a novel toy nautical navigation environment, we show that dynamic
programming can be used when only incomplete information about a partially
observed Markov decision process (POMDP) is known. By incorporating uncertainty
into our model, we show that navigation policies can be constructed that
maintain safety, outperforming the baseline performance of traditional dynamic
programming for Markov decision processes (MDPs). Adding in controlled sensing
methods, we show that these policies can also lower measurement costs at the
same time.",2021-12-29,2021,2021-12,environment
Aim in Climate Change and City Pollution,"The sustainability of urban environments is an increasingly relevant problem.
Air pollution plays a key role in the degradation of the environment as well as
the health of the citizens exposed to it. In this chapter we provide a review
of the methods available to model air pollution, focusing on the application of
machine-learning methods. In fact, machine-learning methods have proved to
importantly increase the accuracy of traditional air-pollution approaches while
limiting the development cost of the models. Machine-learning tools have opened
new approaches to study air pollution, such as flow-dynamics modelling or
remote-sensing methodologies.",2021-12-30,2021,2021-12,environment
"Deep Reinforcement Learning, a textbook","Deep reinforcement learning has gathered much attention recently. Impressive
results were achieved in activities as diverse as autonomous driving, game
playing, molecular recombination, and robotics. In all these fields, computer
programs have taught themselves to solve difficult problems. They have learned
to fly model helicopters and perform aerobatic manoeuvers such as loops and
rolls. In some applications they have even become better than the best humans,
such as in Atari, Go, poker and StarCraft. The way in which deep reinforcement
learning explores complex environments reminds us of how children learn, by
playfully trying out things, getting feedback, and trying again. The computer
seems to truly possess aspects of human learning; this goes to the heart of the
dream of artificial intelligence. The successes in research have not gone
unnoticed by educators, and universities have started to offer courses on the
subject. The aim of this book is to provide a comprehensive overview of the
field of deep reinforcement learning. The book is written for graduate students
of artificial intelligence, and for researchers and practitioners who wish to
better understand deep reinforcement learning methods and their challenges. We
assume an undergraduate-level of understanding of computer science and
artificial intelligence; the programming language of this book is Python. We
describe the foundations, the algorithms and the applications of deep
reinforcement learning. We cover the established model-free and model-based
methods that form the basis of the field. Developments go quickly, and we also
cover advanced topics: deep multi-agent reinforcement learning, deep
hierarchical reinforcement learning, and deep meta learning.",2022-01-04,2022,2022-01,environment
"A Survey on Applications of Digital Human Avatars toward Virtual
  Co-presence","This paper investigates different approaches to build and use digital human
avatars toward interactive Virtual Co-presence (VCP) environments. We evaluate
the evolution of technologies for creating VCP environments and how the
advancement in Artificial Intelligence (AI) and Computer Graphics affect the
quality of VCP environments. We categorize different methods in the literature
based on their applications and methodology and compare various groups and
strategies based on their applications, contributions, and limitations. We also
have a brief discussion about the approaches that other forms of human
representation, rather than digital human avatars, have been utilized in VCP
environments. Our goal is to fill the gap in the research domain where there is
a lack of literature review investigating different approaches for creating
avatar-based VCP environments. We hope this study will be useful for future
research involving human representation in VCP or Virtual Reality (VR)
environments. To the best of our knowledge, it is the first survey research
that investigates avatar-based VCP environments. Specifically, the
categorization methodology suggested in this paper for avatar-based methods is
new.",2022-01-11,2022,2022-01,environment
"Criticality-Based Varying Step-Number Algorithm for Reinforcement
  Learning","In the context of reinforcement learning we introduce the concept of
criticality of a state, which indicates the extent to which the choice of
action in that particular state influences the expected return. That is, a
state in which the choice of action is more likely to influence the final
outcome is considered as more critical than a state in which it is less likely
to influence the final outcome.
  We formulate a criticality-based varying step number algorithm (CVS) - a
flexible step number algorithm that utilizes the criticality function provided
by a human, or learned directly from the environment. We test it in three
different domains including the Atari Pong environment, Road-Tree environment,
and Shooter environment. We demonstrate that CVS is able to outperform popular
learning algorithms such as Deep Q-Learning and Monte Carlo.",2022-01-13,2022,2022-01,environment
"Cognitive Ledger Project: Towards Building Personal Digital Twins
  Through Cognitive Blockchain","The Cognitive Ledger Project is an effort to develop a modular system for
turning users' personal data into structured information and machine learning
models based on a blockchain-based infrastructure. In this work-in-progress
paper, we propose a cognitive architecture for cognitive digital twins. The
suggested design embraces a cognitive blockchain (Cognitive ledger) at its
core. The architecture includes several modules that turn users' activities in
the digital environment into reusable knowledge objects and artificial
intelligence that one day can work together to form the cognitive digital twin
of users.",2022-01-20,2022,2022-01,environment
Goal Recognition as Reinforcement Learning,"Most approaches for goal recognition rely on specifications of the possible
dynamics of the actor in the environment when pursuing a goal. These
specifications suffer from two key issues. First, encoding these dynamics
requires careful design by a domain expert, which is often not robust to noise
at recognition time. Second, existing approaches often need costly real-time
computations to reason about the likelihood of each potential goal. In this
paper, we develop a framework that combines model-free reinforcement learning
and goal recognition to alleviate the need for careful, manual domain design,
and the need for costly online executions. This framework consists of two main
stages: Offline learning of policies or utility functions for each potential
goal, and online inference. We provide a first instance of this framework using
tabular Q-learning for the learning stage, as well as three measures that can
be used to perform the inference stage. The resulting instantiation achieves
state-of-the-art performance against goal recognizers on standard evaluation
domains and superior performance in noisy environments.",2022-02-13,2022,2022-02,environment
Artificial Intelligence for the Metaverse: A Survey,"Along with the massive growth of the Internet from the 1990s until now,
various innovative technologies have been created to bring users breathtaking
experiences with more virtual interactions in cyberspace. Many virtual
environments with thousands of services and applications, from social networks
to virtual gaming worlds, have been developed with immersive experience and
digital transformation, but most are incoherent instead of being integrated
into a platform. In this context, metaverse, a term formed by combining meta
and universe, has been introduced as a shared virtual world that is fueled by
many emerging technologies, such as fifth-generation networks and beyond,
virtual reality, and artificial intelligence (AI). Among such technologies, AI
has shown the great importance of processing big data to enhance immersive
experience and enable human-like intelligence of virtual agents. In this
survey, we make a beneficial effort to explore the role of AI in the foundation
and development of the metaverse. We first deliver a preliminary of AI,
including machine learning algorithms and deep learning architectures, and its
role in the metaverse. We then convey a comprehensive investigation of AI-based
methods concerning six technical aspects that have potentials for the
metaverse: natural language processing, machine vision, blockchain, networking,
digital twin, and neural interface, and being potential for the metaverse.
Subsequently, several AI-aided applications, such as healthcare, manufacturing,
smart cities, and gaming, are studied to be deployed in the virtual worlds.
Finally, we conclude the key contribution of this survey and open some future
research directions in AI for the metaverse.",2022-02-15,2022,2022-02,environment
System Safety and Artificial Intelligence,"This chapter formulates seven lessons for preventing harm in artificial
intelligence (AI) systems based on insights from the field of system safety for
software-based automation in safety-critical domains. New applications of AI
across societal domains and public organizations and infrastructures come with
new hazards, which lead to new forms of harm, both grave and pernicious. The
text addresses the lack of consensus for diagnosing and eliminating new AI
system hazards. For decades, the field of system safety has dealt with
accidents and harm in safety-critical systems governed by varying degrees of
software-based automation and decision-making. This field embraces the core
assumption of systems and control that AI systems cannot be safeguarded by
technical design choices on the model or algorithm alone, instead requiring an
end-to-end hazard analysis and design frame that includes the context of use,
impacted stakeholders and the formal and informal institutional environment in
which the system operates. Safety and other values are then inherently
socio-technical and emergent system properties that require design and control
measures to instantiate these across the technical, social and institutional
components of a system. This chapter honors system safety pioneer Nancy
Leveson, by situating her core lessons for today's AI system safety challenges.
For every lesson, concrete tools are offered for rethinking and reorganizing
the safety management of AI systems, both in design and governance. This
history tells us that effective AI safety management requires transdisciplinary
approaches and a shared language that allows involvement of all levels of
society.",2022-02-18,2022,2022-02,environment
"Towards a Responsible AI Development Lifecycle: Lessons From Information
  Security","Legislation and public sentiment throughout the world have promoted fairness
metrics, explainability, and interpretability as prescriptions for the
responsible development of ethical artificial intelligence systems. Despite the
importance of these three pillars in the foundation of the field, they can be
challenging to operationalize and attempts to solve the problems in production
environments often feel Sisyphean. This difficulty stems from a number of
factors: fairness metrics are computationally difficult to incorporate into
training and rarely alleviate all of the harms perpetrated by these systems.
Interpretability and explainability can be gamed to appear fair, may
inadvertently reduce the privacy of personal information contained in training
data, and increase user confidence in predictions -- even when the explanations
are wrong. In this work, we propose a framework for responsibly developing
artificial intelligence systems by incorporating lessons from the field of
information security and the secure development lifecycle to overcome
challenges associated with protecting users in adversarial settings. In
particular, we propose leveraging the concepts of threat modeling, design
review, penetration testing, and incident response in the context of developing
AI systems as ways to resolve shortcomings in the aforementioned methods.",2022-03-06,2022,2022-03,environment
"A Perspective on Robotic Telepresence and Teleoperation using Cognition:
  Are we there yet?","Telepresence and teleoperation robotics have attracted a great amount of
attention in the last 10 years. With the Artificial Intelligence (AI)
revolution already being started, we can see a wide range of robotic
applications being realized. Intelligent robotic systems are being deployed
both in industrial and domestic environments. Telepresence is the idea of being
present in a remote location virtually or via robotic avatars. Similarly, the
idea of operating a robot from a remote location for various tasks is called
teleoperation. These technologies find significant application in health care,
education, surveillance, disaster recovery, and corporate/government sectors.
But question still remains about their maturity, security and safety levels. We
also need to think about enhancing the user experience and trust in such
technologies going into the next generation of computing.",2022-03-06,2022,2022-03,environment
"Artificial Intelligence in Vehicular Wireless Networks: A Case Study
  Using ns-3","Artificial intelligence (AI) techniques have emerged as a powerful approach
to make wireless networks more efficient and adaptable. In this paper we
present an ns-3 simulation framework, able to implement AI algorithms for the
optimization of wireless networks. Our pipeline consists of: (i) a new
geometry-based mobility-dependent channel model for V2X; (ii) all the layers of
a 5G-NR-compliant protocol stack, based on the ns3-mmwave module; (iii) a new
application to simulate V2X data transmission, and (iv) a new intelligent
entity for the control of the network via AI. Thanks to its flexible and
modular design, researchers can use this tool to implement, train, and evaluate
their own algorithms in a realistic and controlled environment. We test the
behavior of our framework in a Predictive Quality of Service (PQoS) scenario,
where AI functionalities are implemented using Reinforcement Learning (RL), and
demonstrate that it promotes better network optimization compared to baseline
solutions that do not implement AI.",2022-03-10,2022,2022-03,environment
Context is Everything: Implicit Identification for Dynamics Adaptation,"Understanding environment dynamics is necessary for robots to act safely and
optimally in the world. In realistic scenarios, dynamics are non-stationary and
the causal variables such as environment parameters cannot necessarily be
precisely measured or inferred, even during training. We propose Implicit
Identification for Dynamics Adaptation (IIDA), a simple method to allow
predictive models to adapt to changing environment dynamics. IIDA assumes no
access to the true variations in the world and instead implicitly infers
properties of the environment from a small amount of contextual data. We
demonstrate IIDA's ability to perform well in unseen environments through a
suite of simulated experiments on MuJoCo environments and a real robot dynamic
sliding task. In general, IIDA significantly reduces model error and results in
higher task performance over commonly used methods. Our code and robot videos
are at https://bennevans.github.io/iida/",2022-03-10,2022,2022-03,environment
ZIN: When and How to Learn Invariance Without Environment Partition?,"It is commonplace to encounter heterogeneous data, of which some aspects of
the data distribution may vary but the underlying causal mechanisms remain
constant. When data are divided into distinct environments according to the
heterogeneity, recent invariant learning methods have proposed to learn robust
and invariant models based on this environment partition. It is hence tempting
to utilize the inherent heterogeneity even when environment partition is not
provided. Unfortunately, in this work, we show that learning invariant features
under this circumstance is fundamentally impossible without further inductive
biases or additional information. Then, we propose a framework to jointly learn
environment partition and invariant representation, assisted by additional
auxiliary information. We derive sufficient and necessary conditions for our
framework to provably identify invariant features under a fairly general
setting. Experimental results on both synthetic and real world datasets
validate our analysis and demonstrate an improved performance of the proposed
framework over existing methods. Finally, our results also raise the need of
making the role of inductive biases more explicit in future works, when
considering learning invariant models without environment partition. Codes are
available at https://github.com/linyongver/ZIN_official .",2022-03-11,2022,2022-03,environment
A Survey on Infrared Image and Video Sets,"In this survey, we compile a list of publicly available infrared image and
video sets for artificial intelligence and computer vision researchers. We
mainly focus on IR image and video sets which are collected and labelled for
computer vision applications such as object detection, object segmentation,
classification, and motion detection. We categorize 92 different publicly
available or private sets according to their sensor types, image resolution,
and scale. We describe each and every set in detail regarding their collection
purpose, operation environment, optical system properties, and area of
application. We also cover a general overview of fundamental concepts that
relate to IR imagery, such as IR radiation, IR detectors, IR optics and
application fields. We analyse the statistical significance of the entire
corpus from different perspectives. We believe that this survey will be a
guideline for computer vision and artificial intelligence researchers that are
interested in working with the spectra beyond the visible domain.",2022-03-16,2022,2022-03,environment
Explainability in reinforcement learning: perspective and position,"Artificial intelligence (AI) has been embedded into many aspects of people's
daily lives and it has become normal for people to have AI make decisions for
them. Reinforcement learning (RL) models increase the space of solvable
problems with respect to other machine learning paradigms. Some of the most
interesting applications are in situations with non-differentiable expected
reward function, operating in unknown or underdefined environment, as well as
for algorithmic discovery that surpasses performance of any teacher, whereby
agent learns from experimental experience through simple feedback. The range of
applications and their social impact is vast, just to name a few: genomics,
game-playing (chess, Go, etc.), general optimization, financial investment,
governmental policies, self-driving cars, recommendation systems, etc. It is
therefore essential to improve the trust and transparency of RL-based systems
through explanations. Most articles dealing with explainability in artificial
intelligence provide methods that concern supervised learning and there are
very few articles dealing with this in the area of RL. The reasons for this are
the credit assignment problem, delayed rewards, and the inability to assume
that data is independently and identically distributed (i.i.d.). This position
paper attempts to give a systematic overview of existing methods in the
explainable RL area and propose a novel unified taxonomy, building and
expanding on the existing ones. The position section describes pragmatic
aspects of how explainability can be observed. The gap between the parties
receiving and generating the explanation is especially emphasized. To reduce
the gap and achieve honesty and truthfulness of explanations, we set up three
pillars: proactivity, risk attitudes, and epistemological constraints. To this
end, we illustrate our proposal on simple variants of the shortest path
problem.",2022-03-22,2022,2022-03,environment
"The state-of-the-art review on resource allocation problem using
  artificial intelligence methods on various computing paradigms","With the increasing growth of information through smart devices, increasing
the quality level of human life requires various computational paradigms
presentation including the Internet of Things, fog, and cloud. Between these
three paradigms, the cloud computing paradigm as an emerging technology adds
cloud layer services to the edge of the network so that resource allocation
operations occur close to the end-user to reduce resource processing time and
network traffic overhead. Hence, the resource allocation problem for its
providers in terms of presenting a suitable platform, by using computational
paradigms is considered a challenge. In general, resource allocation approaches
are divided into two methods, including auction-based methods(goal, increase
profits for service providers-increase user satisfaction and usability) and
optimization-based methods(energy, cost, network exploitation, Runtime,
reduction of time delay). In this paper, according to the latest scientific
achievements, a comprehensive literature study (CLS) on artificial intelligence
methods based on resource allocation optimization without considering
auction-based methods in various computing environments are provided such as
cloud computing, Vehicular Fog Computing, wireless, IoT, vehicular networks, 5G
networks, vehicular cloud architecture,machine-to-machine
communication(M2M),Train-to-Train(T2T) communication network, Peer-to-Peer(P2P)
network. Since deep learning methods based on artificial intelligence are used
as the most important methods in resource allocation problems; Therefore, in
this paper, resource allocation approaches based on deep learning are also used
in the mentioned computational environments such as deep reinforcement
learning, Q-learning technique, reinforcement learning, online learning, and
also Classical learning methods such as Bayesian learning, Cummins clustering,
Markov decision process.",2022-03-23,2022,2022-03,environment
NovGrid: A Flexible Grid World for Evaluating Agent Response to Novelty,"A robust body of reinforcement learning techniques have been developed to
solve complex sequential decision making problems. However, these methods
assume that train and evaluation tasks come from similarly or identically
distributed environments. This assumption does not hold in real life where
small novel changes to the environment can make a previously learned policy
fail or introduce simpler solutions that might never be found. To that end we
explore the concept of {\em novelty}, defined in this work as the sudden change
to the mechanics or properties of environment. We provide an ontology of for
novelties most relevant to sequential decision making, which distinguishes
between novelties that affect objects versus actions, unary properties versus
non-unary relations, and the distribution of solutions to a task. We introduce
NovGrid, a novelty generation framework built on MiniGrid, acting as a toolkit
for rapidly developing and evaluating novelty-adaptation-enabled reinforcement
learning techniques. Along with the core NovGrid we provide exemplar novelties
aligned with our ontology and instantiate them as novelty templates that can be
applied to many MiniGrid-compliant environments. Finally, we present a set of
metrics built into our framework for the evaluation of
novelty-adaptation-enabled machine-learning techniques, and show
characteristics of a baseline RL model using these metrics.",2022-03-23,2022,2022-03,environment
EnvEdit: Environment Editing for Vision-and-Language Navigation,"In Vision-and-Language Navigation (VLN), an agent needs to navigate through
the environment based on natural language instructions. Due to limited
available data for agent training and finite diversity in navigation
environments, it is challenging for the agent to generalize to new, unseen
environments. To address this problem, we propose EnvEdit, a data augmentation
method that creates new environments by editing existing environments, which
are used to train a more generalizable agent. Our augmented environments can
differ from the seen environments in three diverse aspects: style, object
appearance, and object classes. Training on these edit-augmented environments
prevents the agent from overfitting to existing environments and helps
generalize better to new, unseen environments. Empirically, on both the
Room-to-Room and the multi-lingual Room-Across-Room datasets, we show that our
proposed EnvEdit method gets significant improvements in all metrics on both
pre-trained and non-pre-trained VLN agents, and achieves the new
state-of-the-art on the test leaderboard. We further ensemble the VLN agents
augmented on different edited environments and show that these edit methods are
complementary. Code and data are available at
https://github.com/jialuli-luka/EnvEdit",2022-03-29,2022,2022-03,environment
"An Artificial Intelligence Browser Architecture (AIBA) For Our Kind and
  Others: A Voice Name System Speech implementation with two warrants, Wake
  Neutrality and Value Preservation of Personally Identifiable Information","Conversational commerce, first pioneered by Apple's Siri, is the first of may
applications based on always-on artificial intelligence systems that decide on
its own when to interact with the environment, potentially collecting 24x7
longitudinal training data that is often Personally Identifiable Information
(PII). A large body of scholarly papers, on the order of a million according to
a simple Google Scholar search, suggests that the treatment of many health
conditions, including COVID-19 and dementia, can be vastly improved by this
data if the dataset is large enough as it has happened in other domains (e.g.
GPT3). In contrast, current dominant systems are closed garden solutions
without wake neutrality and that can't fully exploit the PII data they have
because of IRB and Cohues-type constraints.
  We present a voice browser-and-server architecture that aims to address these
two limitations by offering wake neutrality and the possibility to handle PII
aiming to maximize its value. We have implemented this browser for the
collection of speech samples and have successfully demonstrated it can capture
over 200.000 samples of COVID-19 coughs. The architecture we propose is
designed so it can grow beyond our kind into other domains such as collecting
sound samples from vehicles, video images from nature, ingestible robotics,
multi-modal signals (EEG, EKG,...), or even interacting with other kinds such
as dogs and cats.",2022-03-29,2022,2022-03,environment
"Machine Learning and Artificial Intelligence in Circular Economy: A
  Bibliometric Analysis and Systematic Literature Review","With unorganized, unplanned and improper use of limited raw materials, an
abundant amount of waste is being produced, which is harmful to our environment
and ecosystem. While traditional linear production lines fail to address
far-reaching issues like waste production and a shorter product life cycle, a
prospective concept, namely circular economy (CE), has shown promising
prospects to be adopted at industrial and governmental levels. CE aims to
complete the product life cycle loop by bringing out the highest values from
raw materials in the design phase and later on by reusing, recycling, and
remanufacturing. Innovative technologies like artificial intelligence (AI) and
machine learning(ML) provide vital assistance in effectively adopting and
implementing CE in real-world practices. This study explores the adoption and
integration of applied AI techniques in CE. First, we conducted bibliometric
analysis on a collection of 104 SCOPUS indexed documents exploring the critical
research criteria in AI and CE. Forty papers were picked to conduct a
systematic literature review from these documents. The selected documents were
further divided into six categories: sustainable development, reverse
logistics, waste management, supply chain management, recycle & reuse, and
manufacturing development. Comprehensive research insights and trends have been
extracted and delineated. Finally, the research gap needing further attention
has been identified and the future research directions have also been
discussed.",2022-04-01,2022,2022-04,environment
Federated Reinforcement Learning with Environment Heterogeneity,"We study a Federated Reinforcement Learning (FedRL) problem in which $n$
agents collaboratively learn a single policy without sharing the trajectories
they collected during agent-environment interaction. We stress the constraint
of environment heterogeneity, which means $n$ environments corresponding to
these $n$ agents have different state transitions. To obtain a value function
or a policy function which optimizes the overall performance in all
environments, we propose two federated RL algorithms, \texttt{QAvg} and
\texttt{PAvg}. We theoretically prove that these algorithms converge to
suboptimal solutions, while such suboptimality depends on how heterogeneous
these $n$ environments are. Moreover, we propose a heuristic that achieves
personalization by embedding the $n$ environments into $n$ vectors. The
personalization heuristic not only improves the training but also allows for
better generalization to new environments.",2022-04-06,2022,2022-04,environment
"Improving generalization to new environments and removing catastrophic
  forgetting in Reinforcement Learning by using an eco-system of agents","Adapting a Reinforcement Learning (RL) agent to an unseen environment is a
difficult task due to typical over-fitting on the training environment. RL
agents are often capable of solving environments very close to the trained
environment, but when environments become substantially different, their
performance quickly drops. When agents are retrained on new environments, a
second issue arises: there is a risk of catastrophic forgetting, where the
performance on previously seen environments is seriously hampered. This paper
proposes a novel approach that exploits an eco-system of agents to address both
concerns. Hereby, the (limited) adaptive power of individual agents is
harvested to build a highly adaptive eco-system.",2022-04-13,2022,2022-04,environment
"Creative Problem Solving in Artificially Intelligent Agents: A Survey
  and Framework","Creative Problem Solving (CPS) is a sub-area within Artificial Intelligence
(AI) that focuses on methods for solving off-nominal, or anomalous problems in
autonomous systems. Despite many advancements in planning and learning,
resolving novel problems or adapting existing knowledge to a new context,
especially in cases where the environment may change in unpredictable ways post
deployment, remains a limiting factor in the safe and useful integration of
intelligent systems. The emergence of increasingly autonomous systems dictates
the necessity for AI agents to deal with environmental uncertainty through
creativity. To stimulate further research in CPS, we present a definition and a
framework of CPS, which we adopt to categorize existing AI methods in this
field. Our framework consists of four main components of a CPS problem, namely,
1) problem formulation, 2) knowledge representation, 3) method of knowledge
manipulation, and 4) method of evaluation. We conclude our survey with open
research questions, and suggested directions for the future.",2022-04-21,2022,2022-04,environment
"AI-Assisted Authentication: State of the Art, Taxonomy and Future
  Roadmap","Artificial Intelligence (AI) has found its applications in a variety of
environments ranging from data science to cybersecurity. AI helps break through
the limitations of traditional algorithms and provides more efficient and
flexible methods for solving problems. In this paper, we focus on the
applications of artificial intelligence in authentication, which is used in a
wide range of scenarios including facial recognition to access buildings,
keystroke dynamics to unlock smartphones. With the emerging AI-assisted
authentication schemes, our comprehensive survey provides an overall
understanding on a high level, which paves the way for future research in this
area. In contrast to other relevant surveys, our research is the first of its
kind to focus on the roles of AI in authentication.",2022-04-25,2022,2022-04,environment
"Adaptive cognitive fit: Artificial intelligence augmented management of
  information facets and representations","Explosive growth in big data technologies and artificial intelligence [AI]
applications have led to increasing pervasiveness of information facets and a
rapidly growing array of information representations. Information facets, such
as equivocality and veracity, can dominate and significantly influence human
perceptions of information and consequently affect human performance. Extant
research in cognitive fit, which preceded the big data and AI era, focused on
the effects of aligning information representation and task on performance,
without sufficient consideration to information facets and attendant cognitive
challenges. Therefore, there is a compelling need to understand the interplay
of these dominant information facets with information representations and
tasks, and their influence on human performance. We suggest that artificially
intelligent technologies that can adapt information representations to overcome
cognitive limitations are necessary for these complex information environments.
To this end, we propose and test a novel *Adaptive Cognitive Fit* [ACF]
framework that explains the influence of information facets and AI-augmented
information representations on human performance. We draw on information
processing theory and cognitive dissonance theory to advance the ACF framework
and a set of propositions. We empirically validate the ACF propositions with an
economic experiment that demonstrates the influence of information facets, and
a machine learning simulation that establishes the viability of using AI to
improve human performance.",2022-04-25,2022,2022-04,environment
"A Comparative Study on Approaches to Acoustic Scene Classification using
  CNNs","Acoustic scene classification is a process of characterizing and classifying
the environments from sound recordings. The first step is to generate features
(representations) from the recorded sound and then classify the background
environments. However, different kinds of representations have dramatic effects
on the accuracy of the classification. In this paper, we explored the three
such representations on classification accuracy using neural networks. We
investigated the spectrograms, MFCCs, and embeddings representations using
different CNN networks and autoencoders. Our dataset consists of sounds from
three settings of indoors and outdoors environments - thus the dataset contains
sound from six different kinds of environments. We found that the spectrogram
representation has the highest classification accuracy while MFCC has the
lowest classification accuracy. We reported our findings, insights as well as
some guidelines to achieve better accuracy for environment classification using
sounds.",2022-04-26,2022,2022-04,environment
"Stochastic Coherence Over Attention Trajectory For Continuous Learning
  In Video Streams","Devising intelligent agents able to live in an environment and learn by
observing the surroundings is a longstanding goal of Artificial Intelligence.
From a bare Machine Learning perspective, challenges arise when the agent is
prevented from leveraging large fully-annotated dataset, but rather the
interactions with supervisory signals are sparsely distributed over space and
time. This paper proposes a novel neural-network-based approach to
progressively and autonomously develop pixel-wise representations in a video
stream. The proposed method is based on a human-like attention mechanism that
allows the agent to learn by observing what is moving in the attended
locations. Spatio-temporal stochastic coherence along the attention trajectory,
paired with a contrastive term, leads to an unsupervised learning criterion
that naturally copes with the considered setting. Differently from most
existing works, the learned representations are used in open-set
class-incremental classification of each frame pixel, relying on few
supervisions. Our experiments leverage 3D virtual environments and they show
that the proposed agents can learn to distinguish objects just by observing the
video stream. Inheriting features from state-of-the art models is not as
powerful as one might expect.",2022-04-26,2022,2022-04,environment
Emergent Bartering Behaviour in Multi-Agent Reinforcement Learning,"Advances in artificial intelligence often stem from the development of new
environments that abstract real-world situations into a form where research can
be done conveniently. This paper contributes such an environment based on ideas
inspired by elementary Microeconomics. Agents learn to produce resources in a
spatially complex world, trade them with one another, and consume those that
they prefer. We show that the emergent production, consumption, and pricing
behaviors respond to environmental conditions in the directions predicted by
supply and demand shifts in Microeconomics. We also demonstrate settings where
the agents' emergent prices for goods vary over space, reflecting the local
abundance of goods. After the price disparities emerge, some agents then
discover a niche of transporting goods between regions with different
prevailing prices -- a profitable strategy because they can buy goods where
they are cheap and sell them where they are expensive. Finally, in a series of
ablation experiments, we investigate how choices in the environmental rewards,
bartering actions, agent architecture, and ability to consume tradable goods
can either aid or inhibit the emergence of this economic behavior. This work is
part of the environment development branch of a research program that aims to
build human-like artificial general intelligence through multi-agent
interactions in simulated societies. By exploring which environment features
are needed for the basic phenomena of elementary microeconomics to emerge
automatically from learning, we arrive at an environment that differs from
those studied in prior multi-agent reinforcement learning work along several
dimensions. For example, the model incorporates heterogeneous tastes and
physical abilities, and agents negotiate with one another as a grounded form of
communication.",2022-05-13,2022,2022-05,environment
Unified Distributed Environment,"We propose Unified Distributed Environment (UDE), an environment
virtualization toolkit for reinforcement learning research. UDE is designed to
integrate environments built on any simulation platform such as Gazebo, Unity,
Unreal, and OpenAI Gym. Through environment virtualization, UDE enables
offloading the environment for execution on a remote machine while still
maintaining a unified interface. The UDE interface is designed to support
multi-agent by default. With environment virtualization and its interface
design, the agent policies can be trained in multiple machines for a
multi-agent environment. Furthermore, UDE supports integration with existing
major RL toolkits for researchers to leverage the benefits. This paper
discusses the components of UDE and its design decisions.",2022-05-14,2022,2022-05,environment
"DeepSim: A Reinforcement Learning Environment Build Toolkit for ROS and
  Gazebo","We propose DeepSim, a reinforcement learning environment build toolkit for
ROS and Gazebo. It allows machine learning or reinforcement learning
researchers to access the robotics domain and create complex and challenging
custom tasks in ROS and Gazebo simulation environments. This toolkit provides
building blocks of advanced features such as collision detection, behaviour
control, domain randomization, spawner, and many more. DeepSim is designed to
reduce the boundary between robotics and machine learning communities by
providing Python interface. In this paper, we discuss the components and design
decisions of DeepSim Toolkit.",2022-05-17,2022,2022-05,environment
Should Models Be Accurate?,"Model-based Reinforcement Learning (MBRL) holds promise for data-efficiency
by planning with model-generated experience in addition to learning with
experience from the environment. However, in complex or changing environments,
models in MBRL will inevitably be imperfect, and their detrimental effects on
learning can be difficult to mitigate. In this work, we question whether the
objective of these models should be the accurate simulation of environment
dynamics at all. We focus our investigations on Dyna-style planning in a
prediction setting. First, we highlight and support three motivating points: a
perfectly accurate model of environment dynamics is not practically achievable,
is not necessary, and is not always the most useful anyways. Second, we
introduce a meta-learning algorithm for training models with a focus on their
usefulness to the learner instead of their accuracy in modelling the
environment. Our experiments show that in a simple non-stationary environment,
our algorithm enables faster learning than even using an accurate model built
with domain-specific knowledge of the non-stationarity.",2022-05-22,2022,2022-05,environment
IGLU Gridworld: Simple and Fast Environment for Embodied Dialog Agents,"We present the IGLU Gridworld: a reinforcement learning environment for
building and evaluating language conditioned embodied agents in a scalable way.
The environment features visual agent embodiment, interactive learning through
collaboration, language conditioned RL, and combinatorically hard task (3d
blocks building) space.",2022-05-31,2022,2022-05,environment
SAMPLE-HD: Simultaneous Action and Motion Planning Learning Environment,"Humans exhibit incredibly high levels of multi-modal understanding -
combining visual cues with read, or heard knowledge comes easy to us and allows
for very accurate interaction with the surrounding environment. Various
simulation environments focus on providing data for tasks related to scene
understanding, question answering, space exploration, visual navigation. In
this work, we are providing a solution to encompass both, visual and
behavioural aspects of simulation in a new environment for learning interactive
reasoning in manipulation setup. SAMPLE-HD environment allows to generate
various scenes composed of small household objects, to procedurally generate
language instructions for manipulation, and to generate ground truth paths
serving as training data.",2022-06-01,2022,2022-06,environment
Neuro-Nav: A Library for Neurally-Plausible Reinforcement Learning,"In this work we propose Neuro-Nav, an open-source library for neurally
plausible reinforcement learning (RL). RL is among the most common modeling
frameworks for studying decision making, learning, and navigation in biological
organisms. In utilizing RL, cognitive scientists often handcraft environments
and agents to meet the needs of their particular studies. On the other hand,
artificial intelligence researchers often struggle to find benchmarks for
neurally and biologically plausible representation and behavior (e.g., in
decision making or navigation). In order to streamline this process across both
fields with transparency and reproducibility, Neuro-Nav offers a set of
standardized environments and RL algorithms drawn from canonical behavioral and
neural studies in rodents and humans. We demonstrate that the toolkit
replicates relevant findings from a number of studies across both cognitive
science and RL literatures. We furthermore describe ways in which the library
can be extended with novel algorithms (including deep RL) and environments to
address future research needs of the field.",2022-06-06,2022,2022-06,environment
Deep Surrogate Assisted Generation of Environments,"Recent progress in reinforcement learning (RL) has started producing
generally capable agents that can solve a distribution of complex environments.
These agents are typically tested on fixed, human-authored environments. On the
other hand, quality diversity (QD) optimization has been proven to be an
effective component of environment generation algorithms, which can generate
collections of high-quality environments that are diverse in the resulting
agent behaviors. However, these algorithms require potentially expensive
simulations of agents on newly generated environments. We propose Deep
Surrogate Assisted Generation of Environments (DSAGE), a sample-efficient QD
environment generation algorithm that maintains a deep surrogate model for
predicting agent behaviors in new environments. Results in two benchmark
domains show that DSAGE significantly outperforms existing QD environment
generation algorithms in discovering collections of environments that elicit
diverse behaviors of a state-of-the-art RL agent and a planning agent. Our
source code and videos are available at https://dsagepaper.github.io/.",2022-06-09,2022,2022-06,environment
Robust Imitation Learning against Variations in Environment Dynamics,"In this paper, we propose a robust imitation learning (IL) framework that
improves the robustness of IL when environment dynamics are perturbed. The
existing IL framework trained in a single environment can catastrophically fail
with perturbations in environment dynamics because it does not capture the
situation that underlying environment dynamics can be changed. Our framework
effectively deals with environments with varying dynamics by imitating multiple
experts in sampled environment dynamics to enhance the robustness in general
variations in environment dynamics. In order to robustly imitate the multiple
sample experts, we minimize the risk with respect to the Jensen-Shannon
divergence between the agent's policy and each of the sample experts. Numerical
results show that our algorithm significantly improves robustness against
dynamics perturbations compared to conventional IL baselines.",2022-06-19,2022,2022-06,environment
Multi-Agent Car Parking using Reinforcement Learning,"As the industry of autonomous driving grows, so does the potential
interaction of groups of autonomous cars. Combined with the advancement of
Artificial Intelligence and simulation, such groups can be simulated, and
safety-critical models can be learned controlling the cars within. This study
applies reinforcement learning to the problem of multi-agent car parking, where
groups of cars aim to efficiently park themselves, while remaining safe and
rational. Utilising robust tools and machine learning frameworks, we design and
implement a flexible car parking environment in the form of a Markov decision
process with independent learners, exploiting multi-agent communication. We
implement a suite of tools to perform experiments at scale, obtaining models
parking up to 7 cars with over a 98.1% success rate, significantly beating
existing single-agent models. We also obtain several results relating to
competitive and collaborative behaviours exhibited by the cars in our
environment, with varying densities and levels of communication. Notably, we
discover a form of collaboration that cannot arise without competition, and a
'leaky' form of collaboration whereby agents collaborate without sufficient
state. Such work has numerous potential applications in the autonomous driving
and fleet management industries, and provides several useful techniques and
benchmarks for the application of reinforcement learning to multi-agent car
parking.",2022-06-22,2022,2022-06,environment
POGEMA: Partially Observable Grid Environment for Multiple Agents,"We introduce POGEMA (https://github.com/AIRI-Institute/pogema) a sandbox for
challenging partially observable multi-agent pathfinding (PO-MAPF) problems .
This is a grid-based environment that was specifically designed to be a
flexible, tunable and scalable benchmark. It can be tailored to a variety of
PO-MAPF, which can serve as an excellent testing ground for planning and
learning methods, and their combination, which will allow us to move towards
filling the gap between AI planning and learning.",2022-06-22,2022,2022-06,environment
"Reinforcement Learning under Partial Observability Guided by Learned
  Environment Models","In practical applications, we can rarely assume full observability of a
system's environment, despite such knowledge being important for determining a
reactive control system's precise interaction with its environment. Therefore,
we propose an approach for reinforcement learning (RL) in partially observable
environments. While assuming that the environment behaves like a partially
observable Markov decision process with known discrete actions, we assume no
knowledge about its structure or transition probabilities.
  Our approach combines Q-learning with IoAlergia, a method for learning Markov
decision processes (MDP). By learning MDP models of the environment from
episodes of the RL agent, we enable RL in partially observable domains without
explicit, additional memory to track previous interactions for dealing with
ambiguities stemming from partial observability. We instead provide RL with
additional observations in the form of abstract environment states by
simulating new experiences on learned environment models to track the explored
states. In our evaluation, we report on the validity of our approach and its
promising performance in comparison to six state-of-the-art deep RL techniques
with recurrent neural networks and fixed memory.",2022-06-23,2022,2022-06,environment
"GAN-based Intrinsic Exploration For Sample Efficient Reinforcement
  Learning","In this study, we address the problem of efficient exploration in
reinforcement learning. Most common exploration approaches depend on random
action selection, however these approaches do not work well in environments
with sparse or no rewards. We propose Generative Adversarial Network-based
Intrinsic Reward Module that learns the distribution of the observed states and
sends an intrinsic reward that is computed as high for states that are out of
distribution, in order to lead agent to unexplored states. We evaluate our
approach in Super Mario Bros for a no reward setting and in Montezuma's Revenge
for a sparse reward setting and show that our approach is indeed capable of
exploring efficiently. We discuss a few weaknesses and conclude by discussing
future works.",2022-06-28,2022,2022-06,environment
USHER: Unbiased Sampling for Hindsight Experience Replay,"Dealing with sparse rewards is a long-standing challenge in reinforcement
learning (RL). Hindsight Experience Replay (HER) addresses this problem by
reusing failed trajectories for one goal as successful trajectories for
another. This allows for both a minimum density of reward and for
generalization across multiple goals. However, this strategy is known to result
in a biased value function, as the update rule underestimates the likelihood of
bad outcomes in a stochastic environment. We propose an asymptotically unbiased
importance-sampling-based algorithm to address this problem without sacrificing
performance on deterministic environments. We show its effectiveness on a range
of robotic systems, including challenging high dimensional stochastic
environments.",2022-07-03,2022,2022-07,environment
"AVDDPG: Federated reinforcement learning applied to autonomous platoon
  control","Since 2016 federated learning (FL) has been an evolving topic of discussion
in the artificial intelligence (AI) research community. Applications of FL led
to the development and study of federated reinforcement learning (FRL). Few
works exist on the topic of FRL applied to autonomous vehicle (AV) platoons. In
addition, most FRL works choose a single aggregation method (usually weight or
gradient aggregation). We explore FRL's effectiveness as a means to improve AV
platooning by designing and implementing an FRL framework atop a custom AV
platoon environment. The application of FRL in AV platooning is studied under
two scenarios: (1) Inter-platoon FRL (Inter-FRL) where FRL is applied to AVs
across different platoons; (2) Intra-platoon FRL (Intra-FRL) where FRL is
applied to AVs within a single platoon. Both Inter-FRL and Intra-FRL are
applied to a custom AV platooning environment using both gradient and weight
aggregation to observe the performance effects FRL can have on AV platoons
relative to an AV platooning environment trained without FRL. It is concluded
that Intra-FRL using weight aggregation (Intra-FRLWA) provides the best
performance for controlling an AV platoon. In addition, we found that weight
aggregation in FRL for AV platooning provides increases in performance relative
to gradient aggregation. Finally, a performance analysis is conducted for
Intra-FRLWA versus a platooning environment without FRL for platoons of length
3, 4 and 5 vehicles. It is concluded that Intra-FRLWA largely out-performs the
platooning environment that is trained without FRL.",2022-07-05,2022,2022-07,environment
gym-DSSAT: a crop model turned into a Reinforcement Learning environment,"Addressing a real world sequential decision problem with Reinforcement
Learning (RL) usually starts with the use of a simulated environment that
mimics real conditions. We present a novel open source RL environment for
realistic crop management tasks. gym-DSSAT is a gym interface to the Decision
Support System for Agrotechnology Transfer (DSSAT), a high fidelity crop
simulator. DSSAT has been developped over the last 30 years and is widely
recognized by agronomists. gym-DSSAT comes with predefined simulations based on
real world maize experiments. The environment is as easy to use as any gym
environment. We provide performance baselines using basic RL algorithms. We
also briefly outline how the monolithic DSSAT simulator written in Fortran has
been turned into a Python RL environment. Our methodology is generic and may be
applied to similar simulators. We report on very preliminary experimental
results which suggest that RL can help researchers to improve sustainability of
fertilization and irrigation practices.",2022-07-07,2022,2022-07,environment
"Automatic Exploration of Textual Environments with Language-Conditioned
  Autotelic Agents","In this extended abstract we discuss the opportunities and challenges of
studying intrinsically-motivated agents for exploration in textual
environments. We argue that there is important synergy between text
environments and autonomous agents. We identify key properties of text worlds
that make them suitable for exploration by autonmous agents, namely, depth,
breadth, progress niches and the ease of use of language goals; we identify
drivers of exploration for such agents that are implementable in text worlds.
We discuss the opportunities of using autonomous agents to make progress on
text environment benchmarks. Finally we list some specific challenges that need
to be overcome in this area.",2022-07-08,2022,2022-07,environment
"Storehouse: a Reinforcement Learning Environment for Optimizing
  Warehouse Management","Warehouse Management Systems have been evolving and improving thanks to new
Data Intelligence techniques. However, many current optimizations have been
applied to specific cases or are in great need of manual interaction. Here is
where Reinforcement Learning techniques come into play, providing
automatization and adaptability to current optimization policies. In this
paper, we present Storehouse, a customizable environment that generalizes the
definition of warehouse simulations for Reinforcement Learning. We also
validate this environment against state-of-the-art reinforcement learning
algorithms and compare these results to human and random policies.",2022-07-08,2022,2022-07,environment
Grounding Aleatoric Uncertainty for Unsupervised Environment Design,"Adaptive curricula in reinforcement learning (RL) have proven effective for
producing policies robust to discrepancies between the train and test
environment. Recently, the Unsupervised Environment Design (UED) framework
generalized RL curricula to generating sequences of entire environments,
leading to new methods with robust minimax regret properties. Problematically,
in partially-observable or stochastic settings, optimal policies may depend on
the ground-truth distribution over aleatoric parameters of the environment in
the intended deployment setting, while curriculum learning necessarily shifts
the training distribution. We formalize this phenomenon as curriculum-induced
covariate shift (CICS), and describe how its occurrence in aleatoric parameters
can lead to suboptimal policies. Directly sampling these parameters from the
ground-truth distribution avoids the issue, but thwarts curriculum learning. We
propose SAMPLR, a minimax regret UED method that optimizes the ground-truth
utility function, even when the underlying training data is biased due to CICS.
We prove, and validate on challenging domains, that our approach preserves
optimality under the ground-truth distribution, while promoting robustness
across the full range of environment settings.",2022-07-11,2022,2022-07,environment
GriddlyJS: A Web IDE for Reinforcement Learning,"Progress in reinforcement learning (RL) research is often driven by the
design of new, challenging environments -- a costly undertaking requiring
skills orthogonal to that of a typical machine learning researcher. The
complexity of environment development has only increased with the rise of
procedural-content generation (PCG) as the prevailing paradigm for producing
varied environments capable of testing the robustness and generalization of RL
agents. Moreover, existing environments often require complex build processes,
making reproducing results difficult. To address these issues, we introduce
GriddlyJS, a web-based Integrated Development Environment (IDE) based on the
Griddly engine. GriddlyJS allows researchers to visually design and debug
arbitrary, complex PCG grid-world environments using a convenient graphical
interface, as well as visualize, evaluate, and record the performance of
trained agent models. By connecting the RL workflow to the advanced
functionality enabled by modern web standards, GriddlyJS allows publishing
interactive agent-environment demos that reproduce experimental results
directly to the web. To demonstrate the versatility of GriddlyJS, we use it to
quickly develop a complex compositional puzzle-solving environment alongside
arbitrary human-designed environment configurations and their solutions for use
in automatic curriculum learning and offline RL. The GriddlyJS IDE is open
source and freely available at https://griddly.ai.",2022-07-13,2022,2022-07,environment
"Brick Tic-Tac-Toe: Exploring the Generalizability of AlphaZero to Novel
  Test Environments","Traditional reinforcement learning (RL) environments typically are the same
for both the training and testing phases. Hence, current RL methods are largely
not generalizable to a test environment which is conceptually similar but
different from what the method has been trained on, which we term the novel
test environment. As an effort to push RL research towards algorithms which can
generalize to novel test environments, we introduce the Brick Tic-Tac-Toe
(BTTT) test bed, where the brick position in the test environment is different
from that in the training environment. Using a round-robin tournament on the
BTTT environment, we show that traditional RL state-search approaches such as
Monte Carlo Tree Search (MCTS) and Minimax are more generalizable to novel test
environments than AlphaZero is. This is surprising because AlphaZero has been
shown to achieve superhuman performance in environments such as Go, Chess and
Shogi, which may lead one to think that it performs well in novel test
environments. Our results show that BTTT, though simple, is rich enough to
explore the generalizability of AlphaZero. We find that merely increasing MCTS
lookahead iterations was insufficient for AlphaZero to generalize to some novel
test environments. Rather, increasing the variety of training environments
helps to progressively improve generalizability across all possible starting
brick configurations.",2022-07-13,2022,2022-07,environment
"Evaluation of key impression of resilient supply chain based on
  artificial intelligence of things (AIoT)","In recent years, the high complexity of the business environment, dynamism
and environmental change, uncertainty and concepts such as globalization and
increasing competition of organizations in the national and international arena
have caused many changes in the equations governing the supply chain. In this
case, supply chain organizations must always be prepared for a variety of
challenges and dynamic environmental changes. One of the effective solutions to
face these challenges is to create a resilient supply chain. Resilient supply
chain is able to overcome uncertainties and disruptions in the business
environment. The competitive advantage of this supply chain does not depend
only on low costs, high quality, reduced latency and high level of service.
Rather, it has the ability of the chain to avoid catastrophes and overcome
critical situations, and this is the resilience of the supply chain. AI and IoT
technologies and their combination, called AIoT, have played a key role in
improving supply chain performance in recent years and can therefore increase
supply chain resilience. For this reason, in this study, an attempt was made to
better understand the impact of these technologies on equity by examining the
dimensions and components of the Artificial Intelligence of Things (AIoT)-based
supply chain. Finally, using nonlinear fuzzy decision making method, the most
important components of the impact on the resilient smart supply chain are
determined. Understanding this assessment can help empower the smart supply
chain.",2022-07-18,2022,2022-07,environment
"Core and Periphery as Closed-System Precepts for Engineering General
  Intelligence","Engineering methods are centered around traditional notions of decomposition
and recomposition that rely on partitioning the inputs and outputs of
components to allow for component-level properties to hold after their
composition. In artificial intelligence (AI), however, systems are often
expected to influence their environments, and, by way of their environments, to
influence themselves. Thus, it is unclear if an AI system's inputs will be
independent of its outputs, and, therefore, if AI systems can be treated as
traditional components. This paper posits that engineering general intelligence
requires new general systems precepts, termed the core and periphery, and
explores their theoretical uses. The new precepts are elaborated using abstract
systems theory and the Law of Requisite Variety. By using the presented
material, engineers can better understand the general character of regulating
the outcomes of AI to achieve stakeholder needs and how the general systems
nature of embodiment challenges traditional engineering practice.",2022-08-04,2022,2022-08,environment
"Improving performance in multi-objective decision-making in Bottles
  environments with soft maximin approaches","Balancing multiple competing and conflicting objectives is an essential task
for any artificial intelligence tasked with satisfying human values or
preferences. Conflict arises both from misalignment between individuals with
competing values, but also between conflicting value systems held by a single
human. Starting with principle of loss-aversion, we designed a set of soft
maximin function approaches to multi-objective decision-making. Bench-marking
these functions in a set of previously-developed environments, we found that
one new approach in particular, 'split-function exp-log loss aversion'
(SFELLA), learns faster than the state of the art thresholded alignment
objective method (Vamplew et al, 2021) on three of four tasks it was tested on,
and achieved the same optimal performance after learning. SFELLA also showed
relative robustness improvements against changes in objective scale, which may
highlight an advantage dealing with distribution shifts in the environment
dynamics. Due to publishing rules, further work could not be presented in the
preprint, but in the final published version, we will further compare SFELLA to
the multi-objective reward exponentials (MORE) approach (Rolf, 2020),
demonstrating that SFELLA performs similarly to MORE in a simple
previously-described foraging task, but in a modified foraging environment with
a new resource that was not depleted as the agent worked, SFELLA collected more
of the new resource with very little cost incurred in terms of the old
resource. Overall, we found SFELLA useful for avoiding problems that sometimes
occur with a thresholded approach, and more reward-responsive than MORE while
retaining its conservative, loss-averse incentive structure.",2022-08-08,2022,2022-08,environment
Intrinsically Motivated Learning of Causal World Models,"Despite the recent progress in deep learning and reinforcement learning,
transfer and generalization of skills learned on specific tasks is very limited
compared to human (or animal) intelligence. The lifelong, incremental building
of common sense knowledge might be a necessary component on the way to achieve
more general intelligence. A promising direction is to build world models
capturing the true physical mechanisms hidden behind the sensorimotor
interaction with the environment. Here we explore the idea that inferring the
causal structure of the environment could benefit from well-chosen actions as
means to collect relevant interventional data.",2022-08-09,2022,2022-08,environment
"Artificial Intelligence Empowered Multiple Access for Ultra Reliable and
  Low Latency THz Wireless Networks","Terahertz (THz) wireless networks are expected to catalyze the beyond fifth
generation (B5G) era. However, due to the directional nature and the
line-of-sight demand of THz links, as well as the ultra-dense deployment of THz
networks, a number of challenges that the medium access control (MAC) layer
needs to face are created. In more detail, the need of rethinking user
association and resource allocation strategies by incorporating artificial
intelligence (AI) capable of providing ""real-time"" solutions in complex and
frequently changing environments becomes evident. Moreover, to satisfy the
ultra-reliability and low-latency demands of several B5G applications, novel
mobility management approaches are required. Motivated by this, this article
presents a holistic MAC layer approach that enables intelligent user
association and resource allocation, as well as flexible and adaptive mobility
management, while maximizing systems' reliability through blockage
minimization. In more detail, a fast and centralized joint user association,
radio resource allocation, and blockage avoidance by means of a novel
metaheuristic-machine learning framework is documented, that maximizes the THz
networks performance, while minimizing the association latency by approximately
three orders of magnitude. To support, within the access point (AP) coverage
area, mobility management and blockage avoidance, a deep reinforcement learning
(DRL) approach for beam-selection is discussed. Finally, to support user
mobility between coverage areas of neighbor APs, a proactive hand-over
mechanism based on AI-assisted fast channel prediction is~reported.",2022-08-17,2022,2022-08,environment
"MARTI-4: new model of human brain, considering neocortex and basal
  ganglia -- learns to play Atari game by reinforcement learning on a single
  CPU","We present Deep Control - new ML architecture of cortico-striatal brain
circuits, which use whole cortical column as a structural element, instead of a
singe neuron. Based on this architecture, we present MARTI - new model of human
brain, considering neocortex and basal ganglia. This model is de-signed to
implement expedient behavior and is capable to learn and achieve goals in
unknown environments. We introduce a novel surprise feeling mechanism, that
significantly improves reinforcement learning process through inner rewards. We
use OpenAI Gym environment to demonstrate MARTI learning on a single CPU just
in several hours.",2022-08-18,2022,2022-08,environment
"Project proposal: A modular reinforcement learning based automated
  theorem prover","We propose to build a reinforcement learning prover of independent
components: a deductive system (an environment), the proof state representation
(how an agent sees the environment), and an agent training algorithm. To that
purpose, we contribute an additional Vampire-based environment to
$\texttt{gym-saturation}$ package of OpenAI Gym environments for saturation
provers. We demonstrate a prototype of using $\texttt{gym-saturation}$ together
with a popular reinforcement learning framework (Ray $\texttt{RLlib}$).
Finally, we discuss our plans for completing this work in progress to a
competitive automated theorem prover.",2022-09-06,2022,2022-09,environment
"Ask Before You Act: Generalising to Novel Environments by Asking
  Questions","Solving temporally-extended tasks is a challenge for most reinforcement
learning (RL) algorithms [arXiv:1906.07343]. We investigate the ability of an
RL agent to learn to ask natural language questions as a tool to understand its
environment and achieve greater generalisation performance in novel,
temporally-extended environments. We do this by endowing this agent with the
ability of asking ""yes-no"" questions to an all-knowing Oracle. This allows the
agent to obtain guidance regarding the task at hand, while limiting the access
to new information. To study the emergence of such natural language questions
in the context of temporally-extended tasks we first train our agent in a
Mini-Grid environment. We then transfer the trained agent to a different,
harder environment. We observe a significant increase in generalisation
performance compared to a baseline agent unable to ask questions. Through
grounding its understanding of natural language in its environment, the agent
can reason about the dynamics of its environment to the point that it can ask
new, relevant questions when deployed in a novel environment.",2022-09-10,2022,2022-09,environment
Extended Intelligence,"We argue that intelligence, construed as the disposition to perform tasks
successfully, is a property of systems composed of agents and their contexts.
This is the thesis of extended intelligence. We argue that the performance of
an agent will generally not be preserved if its context is allowed to vary.
Hence, this disposition is not possessed by an agent alone, but is rather
possessed by the system consisting of an agent and its context, which we dub an
agent-in-context. An agent's context may include an environment, other agents,
cultural artifacts (like language, technology), or all of these, as is
typically the case for humans and artificial intelligence systems, as well as
many non-human animals. In virtue of the thesis of extended intelligence, we
contend that intelligence is context-bound, task-particular and incommensurable
among agents. Our thesis carries strong implications for how intelligence is
analyzed in the context of both psychology and artificial intelligence.",2022-09-15,2022,2022-09,environment
Autonomous Visual Navigation A Biologically Inspired Approach,"Inspired by the navigational behavior observed in the animal kingdom and
especially the navigational behavior of the ants, we attempt to simulate it in
an artificial environment by implementing different kinds of biomimetic
algorithms.",2022-09-19,2022,2022-09,environment
Safety-Critical Adaptation in Self-Adaptive Systems,"Modern systems are designed to operate in increasingly variable and uncertain
environments. Not only are these environments complex, in the sense that they
contain a tremendous number of variables, but they also change over time.
Systems must be able to adjust their behaviour at run-time to manage these
uncertainties. These self-adaptive systems have been studied extensively. This
paper proposes a definition of a safety-critical self-adaptive system and then
describes a taxonomy for classifying adaptations into different types based on
their impact on the system's safety and the system's safety case. The taxonomy
expresses criteria for classification and then describes specific criteria that
the safety case for a self-adaptive system must satisfy, depending on the type
of adaptations performed. Each type in the taxonomy is illustrated using the
example of a safety-critical self-adaptive water heating system.",2022-09-30,2022,2022-09,environment
Improving Policy Learning via Language Dynamics Distillation,"Recent work has shown that augmenting environments with language descriptions
improves policy learning. However, for environments with complex language
abstractions, learning how to ground language to observations is difficult due
to sparse, delayed rewards. We propose Language Dynamics Distillation (LDD),
which pretrains a model to predict environment dynamics given demonstrations
with language descriptions, and then fine-tunes these language-aware pretrained
representations via reinforcement learning (RL). In this way, the model is
trained to both maximize expected reward and retain knowledge about how
language relates to environment dynamics. On SILG, a benchmark of five tasks
with language descriptions that evaluate distinct generalization challenges on
unseen environments (NetHack, ALFWorld, RTFM, Messenger, and Touchdown), LDD
outperforms tabula-rasa RL, VAE pretraining, and methods that learn from
unlabeled demonstrations in inverse RL and reward shaping with pretrained
experts. In our analyses, we show that language descriptions in demonstrations
improve sample-efficiency and generalization across environments, and that
dynamics modelling with expert demonstrations is more effective than with
non-experts.",2022-09-30,2022,2022-09,environment
Bayesian Q-learning With Imperfect Expert Demonstrations,"Guided exploration with expert demonstrations improves data efficiency for
reinforcement learning, but current algorithms often overuse expert
information. We propose a novel algorithm to speed up Q-learning with the help
of a limited amount of imperfect expert demonstrations. The algorithm avoids
excessive reliance on expert data by relaxing the optimal expert assumption and
gradually reducing the usage of uninformative expert data. Experimentally, we
evaluate our approach on a sparse-reward chain environment and six more
complicated Atari games with delayed rewards. With the proposed methods, we can
achieve better results than Deep Q-learning from Demonstrations (Hester et al.,
2017) in most environments.",2022-10-01,2022,2022-10,environment
CaiRL: A High-Performance Reinforcement Learning Environment Toolkit,"This paper addresses the dire need for a platform that efficiently provides a
framework for running reinforcement learning (RL) experiments. We propose the
CaiRL Environment Toolkit as an efficient, compatible, and more sustainable
alternative for training learning agents and propose methods to develop more
efficient environment simulations.
  There is an increasing focus on developing sustainable artificial
intelligence. However, little effort has been made to improve the efficiency of
running environment simulations. The most popular development toolkit for
reinforcement learning, OpenAI Gym, is built using Python, a powerful but slow
programming language. We propose a toolkit written in C++ with the same
flexibility level but works orders of magnitude faster to make up for Python's
inefficiency. This would drastically cut climate emissions.
  CaiRL also presents the first reinforcement learning toolkit with a built-in
JVM and Flash support for running legacy flash games for reinforcement learning
research. We demonstrate the effectiveness of CaiRL in the classic control
benchmark, comparing the execution speed to OpenAI Gym. Furthermore, we
illustrate that CaiRL can act as a drop-in replacement for OpenAI Gym to
leverage significantly faster training speeds because of the reduced
environment computation time.",2022-10-03,2022,2022-10,environment
Simulating Coverage Path Planning with Roomba,"Coverage Path Planning involves visiting every unoccupied state in an
environment with obstacles. In this paper, we explore this problem in
environments which are initially unknown to the agent, for purposes of
simulating the task of a vacuum cleaning robot. A survey of prior work reveals
sparse effort in applying learning to solve this problem. In this paper, we
explore modeling a Cover Path Planning problem using Deep Reinforcement
Learning, and compare it with the performance of the built-in algorithm of the
Roomba, a popular vacuum cleaning robot.",2022-10-10,2022,2022-10,environment
Grid cells and their potential application in AI,"Since their Nobel Prize winning discovery in 2005, grid cells have been
studied extensively by neuroscientists. Their multi-scale periodic firing rates
tiling the environment as the animal moves around has been shown as critical
for path integration. Multiple experiments have shown that grid cells also fire
for other representations such as olfactory, attention mechanisms, imagined
movement, and concept organization potentially acting as a form of neural
recycling and showing the possible brain mechanism for cognitive maps that
Tolman envisioned in 1948. Grid cell integration into artificial neural
networks may enable more robust, generalized, and smarter computers. In this
paper we give an overview of grid cell research since their discovery, their
role in neuroscience and cognitive science, and possible future directions of
artificial intelligence research.",2022-10-12,2022,2022-10,environment
"Simulated Contextual Bandits for Personalization Tasks from
  Recommendation Datasets","We propose a method for generating simulated contextual bandit environments
for personalization tasks from recommendation datasets like MovieLens, Netflix,
Last.fm, Million Song, etc. This allows for personalization environments to be
developed based on real-life data to reflect the nuanced nature of real-world
user interactions. The obtained environments can be used to develop methods for
solving personalization tasks, algorithm benchmarking, model simulation, and
more. We demonstrate our approach with numerical examples on MovieLens and IMDb
datasets.",2022-10-12,2022,2022-10,environment
"Augmentation for Learning From Demonstration with Environmental
  Constraints","We introduce a Learning from Demonstration (LfD) approach for contact-rich
manipulation tasks with articulated mechanisms. The extracted policy from a
single human demonstration generalizes to different mechanisms of the same type
and is robust against environmental variations. The key to achieving such
generalization and robustness from a single human demonstration is to
autonomously augment the initial demonstration to gather additional information
through purposefully interacting with the environment. Our real-world
experiments on complex mechanisms with multi-DOF demonstrate that our approach
can reliably accomplish the task in a changing environment. Videos are
available at the: https://sites.google.com/view/rbosalfdec/home",2022-10-13,2022,2022-10,environment
"Neuro-symbolic Explainable Artificial Intelligence Twin for Zero-touch
  IoE in Wireless Network","Explainable artificial intelligence (XAI) twin systems will be a fundamental
enabler of zero-touch network and service management (ZSM) for sixth-generation
(6G) wireless networks. A reliable XAI twin system for ZSM requires two
composites: an extreme analytical ability for discretizing the physical
behavior of the Internet of Everything (IoE) and rigorous methods for
characterizing the reasoning of such behavior. In this paper, a novel
neuro-symbolic explainable artificial intelligence twin framework is proposed
to enable trustworthy ZSM for a wireless IoE. The physical space of the XAI
twin executes a neural-network-driven multivariate regression to capture the
time-dependent wireless IoE environment while determining unconscious decisions
of IoE service aggregation. Subsequently, the virtual space of the XAI twin
constructs a directed acyclic graph (DAG)-based Bayesian network that can infer
a symbolic reasoning score over unconscious decisions through a first-order
probabilistic language model. Furthermore, a Bayesian multi-arm bandits-based
learning problem is proposed for reducing the gap between the expected
explained score and the current obtained score of the proposed neuro-symbolic
XAI twin. To address the challenges of extensible, modular, and stateless
management functions in ZSM, the proposed neuro-symbolic XAI twin framework
consists of two learning systems: 1) an implicit learner that acts as an
unconscious learner in physical space, and 2) an explicit leaner that can
exploit symbolic reasoning based on implicit learner decisions and prior
evidence. Experimental results show that the proposed neuro-symbolic XAI twin
can achieve around 96.26% accuracy while guaranteeing from 18% to 44% more
trust score in terms of reasoning and closed-loop automation.",2022-10-13,2022,2022-10,environment
Palm up: Playing in the Latent Manifold for Unsupervised Pretraining,"Large and diverse datasets have been the cornerstones of many impressive
advancements in artificial intelligence. Intelligent creatures, however, learn
by interacting with the environment, which changes the input sensory signals
and the state of the environment. In this work, we aim to bring the best of
both worlds and propose an algorithm that exhibits an exploratory behavior
whilst it utilizes large diverse datasets. Our key idea is to leverage deep
generative models that are pretrained on static datasets and introduce a
dynamic model in the latent space. The transition dynamics simply mixes an
action and a random sampled latent. It then applies an exponential moving
average for temporal persistency, the resulting latent is decoded to image
using pretrained generator. We then employ an unsupervised reinforcement
learning algorithm to explore in this environment and perform unsupervised
representation learning on the collected data. We further leverage the temporal
information of this data to pair data points as a natural supervision for
representation learning. Our experiments suggest that the learned
representations can be successfully transferred to downstream tasks in both
vision and reinforcement learning domains.",2022-10-19,2022,2022-10,environment
Explainability in autonomous pedagogically structured scenarios,"We present the notion of explainability for decision-making processes in a
pedagogically structured autonomous environment. Multi-agent systems that are
structured pedagogically consist of pedagogical teachers and learners that
operate in environments in which both are sometimes not fully aware of all the
states in the environment and beliefs of other agents thus making it
challenging to explain their decisions and actions with one another. This work
emphasises the need for robust and iterative explanation-based communication
between the pedagogical teacher and the learner. Explaining the rationale
behind multi-agent decisions in an interactive, partially observable
environment is necessary to build trustworthy and reliable communication
between pedagogical teachers and learners. Ongoing research is primarily
focused on explanations of the agents' behaviour towards humans, and there is a
lack of research on inter-agent explainability.",2022-10-21,2022,2022-10,environment
"Modelling Control Arguments via Cooperation Logic in Unforeseen
  Scenarios","The intent of control argumentation frameworks is to specifically model
strategic scenarios from the perspective of an agent by extending the standard
model of argumentation framework in a way that takes unquantified uncertainty
regarding arguments and attacks into account. They do not, however, adequately
account for coalition formation and interactions among a set of agents in an
uncertain environment. To address this challenge, we propose a formalism of a
multi-agent scenario via cooperation logic and investigate agents' strategies
and actions in a dynamic environment.",2022-10-21,2022,2022-10,environment
"A Temporal Type-2 Fuzzy System for Time-dependent Explainable Artificial
  Intelligence","Explainable Artificial Intelligence (XAI) is a paradigm that delivers
transparent models and decisions, which are easy to understand, analyze, and
augment by a non-technical audience. Fuzzy Logic Systems (FLS) based XAI can
provide an explainable framework, while also modeling uncertainties present in
real-world environments, which renders it suitable for applications where
explainability is a requirement. However, most real-life processes are not
characterized by high levels of uncertainties alone; they are inherently
time-dependent as well, i.e., the processes change with time. In this work, we
present novel Temporal Type-2 FLS Based Approach for time-dependent XAI (TXAI)
systems, which can account for the likelihood of a measurement's occurrence in
the time domain using (the measurement's) frequency of occurrence. In Temporal
Type-2 Fuzzy Sets (TT2FSs), a four-dimensional (4D) time-dependent membership
function is developed where relations are used to construct the inter-relations
between the elements of the universe of discourse and its frequency of
occurrence. The TXAI system manifested better classification prowess, with
10-fold test datasets, with a mean recall of 95.40\% than a standard XAI system
(based on non-temporal general type-2 (GT2) fuzzy sets) that had a mean recall
of 87.04\%. TXAI also performed significantly better than most non-explainable
AI systems between 3.95\%, to 19.04\% improvement gain in mean recall. In
addition, TXAI can also outline the most likely time-dependent trajectories
using the frequency of occurrence values embedded in the TXAI model; viz. given
a rule at a determined time interval, what will be the next most likely rule at
a subsequent time interval. In this regard, the proposed TXAI system can have
profound implications for delineating the evolution of real-life time-dependent
processes, such as behavioural or biological processes.",2022-10-22,2022,2022-10,environment
MetaSpeech: Speech Effects Switch Along with Environment for Metaverse,"Metaverse expands the physical world to a new dimension, and the physical
environment and Metaverse environment can be directly connected and entered.
Voice is an indispensable communication medium in the real world and Metaverse.
Fusion of the voice with environment effects is important for user immersion in
Metaverse. In this paper, we proposed using the voice conversion based method
for the conversion of target environment effect speech. The proposed method was
named MetaSpeech, which introduces an environment effect module containing an
effect extractor to extract the environment information and an effect encoder
to encode the environment effect condition, in which gradient reversal layer
was used for adversarial training to keep the speech content and speaker
information while disentangling the environmental effects. From the experiment
results on the public dataset of LJSpeech with four environment effects, the
proposed model could complete the specific environment effect conversion and
outperforms the baseline methods from the voice conversion task.",2022-10-25,2022,2022-10,environment
"Multi-Environment based Meta-Learning with CSI Fingerprints for Radio
  Based Positioning","Radio based positioning of a user equipment (UE) based on deep learning (DL)
methods using channel state information (CSI) fingerprints have shown promising
results. DL models are able to capture complex properties embedded in the CSI
about a particular environment and map UE's CSI to the UE's position. However,
the CSI fingerprints and the DL models trained on such fingerprints are highly
dependent on a particular propagation environment, which generally limits the
transfer of knowledge of the DL models from one environment to another. In this
paper, we propose a DL model consisting of two parts: the first part aims to
learn environment independent features while the second part combines those
features depending on the particular environment. To improve transfer learning,
we propose a meta learning scheme for training the first part over multiple
environments. We show that for positioning in a new environment, initializing a
DL model with the meta learned environment independent function achieves higher
UE positioning accuracy compared to regular transfer learning from one
environment to the new environment, or compared to training the DL model from
scratch with only fingerprints from the new environment. Our proposed scheme is
able to create an environment independent function which can embed knowledge
from multiple environments and more effectively learn from a new environment.",2022-10-26,2022,2022-10,environment
Environment Design for Inverse Reinforcement Learning,"Learning a reward function from demonstrations suffers from low
sample-efficiency. Even with abundant data, current inverse reinforcement
learning methods that focus on learning from a single environment can fail to
handle slight changes in the environment dynamics. We tackle these challenges
through adaptive environment design. In our framework, the learner repeatedly
interacts with the expert, with the former selecting environments to identify
the reward function as quickly as possible from the expert's demonstrations in
said environments. This results in improvements in both sample-efficiency and
robustness, as we show experimentally, for both exact and approximate
inference.",2022-10-26,2022,2022-10,environment
"Distributed Swarm Learning for Internet of Things at the Edge: Where
  Artificial Intelligence Meets Biological Intelligence","With the proliferation of versatile Internet of Things (IoT) services, smart
IoT devices are increasingly deployed at the edge of wireless networks to
perform collaborative machine learning tasks using locally collected data,
giving rise to the edge learning paradigm. Due to device restrictions and
resource constraints, edge learning among massive IoT devices faces major
technical challenges caused by the communication bottleneck, data and device
heterogeneity, non-convex optimization, privacy and security concerns, and
dynamic environments. To overcome these challenges, this article studies a new
framework of distributed swarm learning (DSL) through a holistic integration of
artificial intelligence and biological swarm intelligence. Leveraging efficient
and robust signal processing and communication techniques, DSL contributes to
novel tools for learning and optimization tailored for real-time operations of
large-scale IoT in edge wireless environments, which will benefit a wide range
of edge IoT applications.",2022-10-29,2022,2022-10,environment
"Discriminating sensor activation in activity recognition within
  multi-occupancy environments based on nearby interaction","This work presents a computer model to discriminate sensor activation in
multi-occupancy environments based on proximity interaction. Current
proximity-based and indoor location methods allow the estimation of the
positions or areas where inhabitants carry out their daily human activities.
The spatial-temporal relation between location and sensor activations is
described in this work to generate a sensor interaction matrix for each
inhabitant. This enables the use of classical HAR models to reduce the
complexity of the multi-occupancy problem. A case study deployed with UWB and
binary sensors is presented.",2022-11-03,2022,2022-11,environment
"Examining the Differential Risk from High-level Artificial Intelligence
  and the Question of Control","Artificial Intelligence (AI) is one of the most transformative technologies
of the 21st century. The extent and scope of future AI capabilities remain a
key uncertainty, with widespread disagreement on timelines and potential
impacts. As nations and technology companies race toward greater complexity and
autonomy in AI systems, there are concerns over the extent of integration and
oversight of opaque AI decision processes. This is especially true in the
subfield of machine learning (ML), where systems learn to optimize objectives
without human assistance. Objectives can be imperfectly specified or executed
in an unexpected or potentially harmful way. This becomes more concerning as
systems increase in power and autonomy, where an abrupt capability jump could
result in unexpected shifts in power dynamics or even catastrophic failures.
This study presents a hierarchical complex systems framework to model AI risk
and provide a template for alternative futures analysis. Survey data were
collected from domain experts in the public and private sectors to classify AI
impact and likelihood. The results show increased uncertainty over the powerful
AI agent scenario, confidence in multiagent environments, and increased concern
over AI alignment failures and influence-seeking behavior.",2022-11-06,2022,2022-11,environment
"Max-Min Off-Policy Actor-Critic Method Focusing on Worst-Case Robustness
  to Model Misspecification","In the field of reinforcement learning, because of the high cost and risk of
policy training in the real world, policies are trained in a simulation
environment and transferred to the corresponding real-world environment.
However, the simulation environment does not perfectly mimic the real-world
environment, lead to model misspecification. Multiple studies report
significant deterioration of policy performance in a real-world environment. In
this study, we focus on scenarios involving a simulation environment with
uncertainty parameters and the set of their possible values, called the
uncertainty parameter set. The aim is to optimize the worst-case performance on
the uncertainty parameter set to guarantee the performance in the corresponding
real-world environment. To obtain a policy for the optimization, we propose an
off-policy actor-critic approach called the Max-Min Twin Delayed Deep
Deterministic Policy Gradient algorithm (M2TD3), which solves a max-min
optimization problem using a simultaneous gradient ascent descent approach.
Experiments in multi-joint dynamics with contact (MuJoCo) environments show
that the proposed method exhibited a worst-case performance superior to several
baseline approaches.",2022-11-07,2022,2022-11,environment
Foundation Models for Semantic Novelty in Reinforcement Learning,"Effectively exploring the environment is a key challenge in reinforcement
learning (RL). We address this challenge by defining a novel intrinsic reward
based on a foundation model, such as contrastive language image pretraining
(CLIP), which can encode a wealth of domain-independent semantic
visual-language knowledge about the world. Specifically, our intrinsic reward
is defined based on pre-trained CLIP embeddings without any fine-tuning or
learning on the target RL task. We demonstrate that CLIP-based intrinsic
rewards can drive exploration towards semantically meaningful states and
outperform state-of-the-art methods in challenging sparse-reward
procedurally-generated environments.",2022-11-09,2022,2022-11,environment
"Towards a Dynamic Composability Approach for using Heterogeneous Systems
  in Remote Sensing","Influenced by the advances in data and computing, the scientific practice
increasingly involves machine learning and artificial intelligence driven
methods which requires specialized capabilities at the system-, science- and
service-level in addition to the conventional large-capacity supercomputing
approaches. The latest distributed architectures built around the composability
of data-centric applications led to the emergence of a new ecosystem for
container coordination and integration. However, there is still a divide
between the application development pipelines of existing supercomputing
environments, and these new dynamic environments that disaggregate fluid
resource pools through accessible, portable and re-programmable interfaces. New
approaches for dynamic composability of heterogeneous systems are needed to
further advance the data-driven scientific practice for the purpose of more
efficient computing and usable tools for specific scientific domains. In this
paper, we present a novel approach for using composable systems in the
intersection between scientific computing, artificial intelligence (AI), and
remote sensing domain. We describe the architecture of a first working example
of a composable infrastructure that federates Expanse, an NSF-funded
supercomputer, with Nautilus, a Kubernetes-based GPU geo-distributed cluster.
We also summarize a case study in wildfire modeling, that demonstrates the
application of this new infrastructure in scientific workflows: a composed
system that bridges the insights from edge sensing, AI and computing
capabilities with a physics-driven simulation.",2022-11-13,2022,2022-11,environment
"Understanding the Energy Consumption of HPC Scale Artificial
  Intelligence","This paper contributes towards better understanding the energy consumption
trade-offs of HPC scale Artificial Intelligence (AI), and more specifically
Deep Learning (DL) algorithms. For this task we developed benchmark-tracker, a
benchmark tool to evaluate the speed and energy consumption of DL algorithms in
HPC environments. We exploited hardware counters and Python libraries to
collect energy information through software, which enabled us to instrument a
known AI benchmark tool, and to evaluate the energy consumption of numerous DL
algorithms and models. Through an experimental campaign, we show a case example
of the potential of benchmark-tracker to measure the computing speed and the
energy consumption for training and inference DL algorithms, and also the
potential of Benchmark-Tracker to help better understanding the energy behavior
of DL algorithms in HPC platforms. This work is a step forward to better
understand the energy consumption of Deep Learning in HPC, and it also
contributes with a new tool to help HPC DL developers to better balance the HPC
infrastructure in terms of speed and energy consumption.",2022-11-14,2022,2022-11,environment
"Parallel Automatic History Matching Algorithm Using Reinforcement
  Learning","Reformulating the history matching problem from a least-square mathematical
optimization problem into a Markov Decision Process introduces a method in
which reinforcement learning can be utilized to solve the problem. This method
provides a mechanism where an artificial deep neural network agent can interact
with the reservoir simulator and find multiple different solutions to the
problem. Such formulation allows for solving the problem in parallel by
launching multiple concurrent environments enabling the agent to learn
simultaneously from all the environments at once, achieving significant speed
up.",2022-11-14,2022,2022-11,environment
"Discrete Control in Real-World Driving Environments using Deep
  Reinforcement Learning","Training self-driving cars is often challenging since they require a vast
amount of labeled data in multiple real-world contexts, which is
computationally and memory intensive. Researchers often resort to driving
simulators to train the agent and transfer the knowledge to a real-world
setting. Since simulators lack realistic behavior, these methods are quite
inefficient. To address this issue, we introduce a framework (perception,
planning, and control) in a real-world driving environment that transfers the
real-world environments into gaming environments by setting up a reliable
Markov Decision Process (MDP). We propose variations of existing Reinforcement
Learning (RL) algorithms in a multi-agent setting to learn and execute the
discrete control in real-world environments. Experiments show that the
multi-agent setting outperforms the single-agent setting in all the scenarios.
We also propose reliable initialization, data augmentation, and training
techniques that enable the agents to learn and generalize to navigate in a
real-world environment with minimal input video data, and with minimal
training. Additionally, to show the efficacy of our proposed algorithm, we
deploy our method in the virtual driving environment TORCS.",2022-11-29,2022,2022-11,environment
Indoor room Occupancy Counting based on LSTM and Environmental Sensor,"This paper realizes the estimation of classroom occupancy by using the CO2
sensor and deep learning technique named Long-Short-Term Memory. As a case of
connection with IoT and machine learning, I achieve the model to estimate the
people number in the classroom based on the environmental data exported from
the CO2 sensor, I also evaluate the performance of the model to show the
feasibility to apply our module to the real environment.",2022-12-05,2022,2022-12,environment
"A Machine with Short-Term, Episodic, and Semantic Memory Systems","Inspired by the cognitive science theory of the explicit human memory
systems, we have modeled an agent with short-term, episodic, and semantic
memory systems, each of which is modeled with a knowledge graph. To evaluate
this system and analyze the behavior of this agent, we designed and released
our own reinforcement learning agent environment, ""the Room"", where an agent
has to learn how to encode, store, and retrieve memories to maximize its return
by answering questions. We show that our deep Q-learning based agent
successfully learns whether a short-term memory should be forgotten, or rather
be stored in the episodic or semantic memory systems. Our experiments indicate
that an agent with human-like memory systems can outperform an agent without
this memory structure in the environment.",2022-12-05,2022,2022-12,environment
Simulation of Attacker Defender Interaction in a Noisy Security Game,"In the cybersecurity setting, defenders are often at the mercy of their
detection technologies and subject to the information and experiences that
individual analysts have. In order to give defenders an advantage, it is
important to understand an attacker's motivation and their likely next best
action. As a first step in modeling this behavior, we introduce a security game
framework that simulates interplay between attackers and defenders in a noisy
environment, focusing on the factors that drive decision making for attackers
and defenders in the variants of the game with full knowledge and
observability, knowledge of the parameters but no observability of the state
(``partial knowledge''), and zero knowledge or observability (``zero
knowledge''). We demonstrate the importance of making the right assumptions
about attackers, given significant differences in outcomes. Furthermore, there
is a measurable trade-off between false-positives and true-positives in terms
of attacker outcomes, suggesting that a more false-positive prone environment
may be acceptable under conditions where true-positives are also higher.",2022-12-08,2022,2022-12,environment
"MixBoost: Improving the Robustness of Deep Neural Networks by Boosting
  Data Augmentation","As more and more artificial intelligence (AI) technologies move from the
laboratory to real-world applications, the open-set and robustness challenges
brought by data from the real world have received increasing attention. Data
augmentation is a widely used method to improve model performance, and some
recent works have also confirmed its positive effect on the robustness of AI
models. However, most of the existing data augmentation methods are heuristic,
lacking the exploration of their internal mechanisms. We apply the explainable
artificial intelligence (XAI) method, explore the internal mechanisms of
popular data augmentation methods, analyze the relationship between game
interactions and some widely used robustness metrics, and propose a new proxy
for model robustness in the open-set environment. Based on the analysis of the
internal mechanisms, we develop a mask-based boosting method for data
augmentation that comprehensively improves several robustness measures of AI
models and beats state-of-the-art data augmentation approaches. Experiments
show that our method can be widely applied to many popular data augmentation
methods. Different from the adversarial training, our boosting method not only
significantly improves the robustness of models, but also improves the accuracy
of test sets. Our code is available at
\url{https://github.com/Anonymous_for_submission}.",2022-12-08,2022,2022-12,environment
"Sharing Linkable Learning Objects with the use of Metadata and a
  Taxonomy Assistant for Categorization","In this work, a re-design of the Moodledata module functionalities is
presented to share learning objects between e-learning content platforms, e.g.,
Moodle and G-Lorep, in a linkable object format. The e-learning courses content
of the Drupal-based Content Management System G-Lorep for academic learning is
exchanged designing an object incorporating metadata to support the reuse and
the classification in its context. In such an Artificial Intelligence
environment, the exchange of Linkable Learning Objects can be used for dialogue
between Learning Systems to obtain information, especially with the use of
semantic or structural similarity measures to enhance the existent Taxonomy
Assistant for advanced automated classification.",2022-12-09,2022,2022-12,environment
"Classification of Distraction Levels Using Hybrid Deep Neural Networks
  From EEG Signals","Non-invasive brain-computer interface technology has been developed for
detecting human mental states with high performances. Detection of the pilots'
mental states is particularly critical because their abnormal mental states
could cause catastrophic accidents. In this study, we presented the feasibility
of classifying distraction levels (namely, normal state, low distraction, and
high distraction) by applying the deep learning method. To the best of our
knowledge, this study is the first attempt to classify distraction levels under
a flight environment. We proposed a model for classifying distraction levels. A
total of ten pilots conducted the experiment in a simulated flight environment.
The grand-average accuracy was 0.8437 for classifying distraction levels across
all subjects. Hence, we believe that it will contribute significantly to
autonomous driving or flight based on artificial intelligence technology in the
future.",2022-12-13,2022,2022-12,environment
Improving generalization in reinforcement learning through forked agents,"An eco-system of agents each having their own policy with some, but limited,
generalizability has proven to be a reliable approach to increase
generalization across procedurally generated environments. In such an approach,
new agents are regularly added to the eco-system when encountering a new
environment that is outside of the scope of the eco-system. The speed of
adaptation and general effectiveness of the eco-system approach highly depends
on the initialization of new agents. In this paper we propose different
initialization techniques, inspired from Deep Neural Network initialization and
transfer learning, and study their impact.",2022-12-13,2022,2022-12,environment
Quantum policy gradient algorithms,"Understanding the power and limitations of quantum access to data in machine
learning tasks is primordial to assess the potential of quantum computing in
artificial intelligence. Previous works have already shown that speed-ups in
learning are possible when given quantum access to reinforcement learning
environments. Yet, the applicability of quantum algorithms in this setting
remains very limited, notably in environments with large state and action
spaces. In this work, we design quantum algorithms to train state-of-the-art
reinforcement learning policies by exploiting quantum interactions with an
environment. However, these algorithms only offer full quadratic speed-ups in
sample complexity over their classical analogs when the trained policies
satisfy some regularity conditions. Interestingly, we find that reinforcement
learning policies derived from parametrized quantum circuits are well-behaved
with respect to these conditions, which showcases the benefit of a
fully-quantum reinforcement learning framework.",2022-12-19,2022,2022-12,environment
Decision-making and control with diffractive optical networks,"The ultimate goal of artificial intelligence is to mimic the human brain to
perform decision-making and control directly from high-dimensional sensory
input. Diffractive optical networks provide a promising solution for
implementing artificial intelligence with high-speed and low-power consumption.
Most of the reported diffractive optical networks focus on single or multiple
tasks that do not involve environmental interaction, such as object recognition
and image classification. In contrast, the networks capable of performing
decision-making and control have not yet been developed to our knowledge. Here,
we propose using deep reinforcement learning to implement diffractive optical
networks that imitate human-level decision-making and control capability. Such
networks taking advantage of a residual architecture, allow for finding optimal
control policies through interaction with the environment and can be readily
implemented with existing optical devices. The superior performance of these
networks is verified by engaging three types of classic games, Tic-Tac-Toe,
Super Mario Bros., and Car Racing. Finally, we present an experimental
demonstration of playing Tic-Tac-Toe by leveraging diffractive optical networks
based on a spatial light modulator. Our work represents a solid step forward in
advancing diffractive optical networks, which promises a fundamental shift from
the target-driven control of a pre-designed state for simple recognition or
classification tasks to the high-level sensory capability of artificial
intelligence. It may find exciting applications in autonomous driving,
intelligent robots, and intelligent manufacturing.",2022-12-21,2022,2022-12,environment
"Towards Sustainable Artificial Intelligence: An Overview of
  Environmental Protection Uses and Issues","Artificial Intelligence (AI) is used to create more sustainable production
methods and model climate change, making it a valuable tool in the fight
against environmental degradation. This paper describes the paradox of an
energy-consuming technology serving the ecological challenges of tomorrow. The
study provides an overview of the sectors that use AI-based solutions for
environmental protection. It draws on numerous examples from AI for Green
players to present use cases and concrete examples. In the second part of the
study, the negative impacts of AI on the environment and the emerging
technological solutions to support Green AI are examined. It is also shown that
the research on less energy-consuming AI is motivated more by cost and energy
autonomy constraints than by environmental considerations. This leads to a
rebound effect that favors an increase in the complexity of models. Finally,
the need to integrate environmental indicators into algorithms is discussed.
The environmental dimension is part of the broader ethical problem of AI, and
addressing it is crucial for ensuring the sustainability of AI in the long
term.",2022-12-22,2022,2022-12,environment
Towards automating Codenames spymasters with deep reinforcement learning,"Although most reinforcement learning research has centered on competitive
games, little work has been done on applying it to co-operative multiplayer
games or text-based games. Codenames is a board game that involves both
asymmetric co-operation and natural language processing, which makes it an
excellent candidate for advancing RL research. To my knowledge, this work is
the first to formulate Codenames as a Markov Decision Process and apply some
well-known reinforcement learning algorithms such as SAC, PPO, and A2C to the
environment. Although none of the above algorithms converge for the Codenames
environment, neither do they converge for a simplified environment called
ClickPixel, except when the board size is small.",2022-12-28,2022,2022-12,environment
Need of 6G for the Metaverse Realization,"The concept of the Metaverse aims to bring a fully-fledged extended reality
environment to provide next generation applications and services. Development
of the Metaverse is backed by many technologies, including, 5G, artificial
intelligence, edge computing and extended reality. The advent of 6G is
envisaged to mark a significant milestone in the development of the Metaverse,
facilitating near-zero-latency, a plethora of new services and upgraded
real-world infrastructure. This paper establishes the advantages of providing
the Metaverse services over 6G along with an overview of the demanded technical
requirements. The paper provides an insight to the concepts of the Metaverse
and the envisaged technical capabilities of 6G mobile networks. Then, the
technical aspects covering 6G for the development of the Metaverse, ranging
from validating digital assets, interoperability, and efficient user
interaction in the Metaverse to related security and privacy aspects are
elaborated. Subsequently, the role of 6G technologies towards enabling the
Metaverse, including artificial intelligence, blockchain, open radio access
networks, edge computing, cloudification and internet of everything. The paper
also presents 6G integration challenges and outlines ongoing projects towards
developing the Metaverse technologies to facilitate the Metaverse applications
and services.",2022-12-28,2022,2022-12,environment
Transformers as Policies for Variable Action Environments,"In this project we demonstrate the effectiveness of the transformer encoder
as a viable architecture for policies in variable action environments. Using
it, we train an agent using Proximal Policy Optimisation (PPO) on multiple maps
against scripted opponents in the Gym-$\mu$RTS environment. The final agent is
able to achieve a higher return using half the computational resources of the
next-best RL agent, which used the GridNet architecture.
  The source code and pre-trained models are available here:
https://github.com/NiklasZ/transformers-for-variable-action-envs",2023-01-09,2023,2023-01,environment
"Learning Bidirectional Action-Language Translation with Limited
  Supervision and Incongruent Input","Human infant learning happens during exploration of the environment, by
interaction with objects, and by listening to and repeating utterances
casually, which is analogous to unsupervised learning. Only occasionally, a
learning infant would receive a matching verbal description of an action it is
committing, which is similar to supervised learning. Such a learning mechanism
can be mimicked with deep learning. We model this weakly supervised learning
paradigm using our Paired Gated Autoencoders (PGAE) model, which combines an
action and a language autoencoder. After observing a performance drop when
reducing the proportion of supervised training, we introduce the Paired
Transformed Autoencoders (PTAE) model, using Transformer-based crossmodal
attention. PTAE achieves significantly higher accuracy in language-to-action
and action-to-language translations, particularly in realistic but difficult
cases when only few supervised training samples are available. We also test
whether the trained model behaves realistically with conflicting multimodal
input. In accordance with the concept of incongruence in psychology, conflict
deteriorates the model output. Conflicting action input has a more severe
impact than conflicting language input, and more conflicting features lead to
larger interference. PTAE can be trained on mostly unlabelled data where
labeled data is scarce, and it behaves plausibly when tested with incongruent
input.",2023-01-09,2023,2023-01,environment
Mastering Diverse Domains through World Models,"Developing a general algorithm that learns to solve tasks across a wide range
of applications has been a fundamental challenge in artificial intelligence.
Although current reinforcement learning algorithms can be readily applied to
tasks similar to what they have been developed for, configuring them for new
application domains requires significant human expertise and experimentation.
We present DreamerV3, a general algorithm that outperforms specialized methods
across over 150 diverse tasks, with a single configuration. Dreamer learns a
model of the environment and improves its behavior by imagining future
scenarios. Robustness techniques based on normalization, balancing, and
transformations enable stable learning across domains. Applied out of the box,
Dreamer is the first algorithm to collect diamonds in Minecraft from scratch
without human data or curricula. This achievement has been posed as a
significant challenge in artificial intelligence that requires exploring
farsighted strategies from pixels and sparse rewards in an open world. Our work
allows solving challenging control problems without extensive experimentation,
making reinforcement learning broadly applicable.",2023-01-10,2023,2023-01,environment
"Graph based Environment Representation for Vision-and-Language
  Navigation in Continuous Environments","Vision-and-Language Navigation in Continuous Environments (VLN-CE) is a
navigation task that requires an agent to follow a language instruction in a
realistic environment. The understanding of environments is a crucial part of
the VLN-CE task, but existing methods are relatively simple and direct in
understanding the environment, without delving into the relationship between
language instructions and visual environments. Therefore, we propose a new
environment representation in order to solve the above problems. First, we
propose an Environment Representation Graph (ERG) through object detection to
express the environment in semantic level. This operation enhances the
relationship between language and environment. Then, the relational
representations of object-object, object-agent in ERG are learned through GCN,
so as to obtain a continuous expression about ERG. Sequentially, we combine the
ERG expression with object label embeddings to obtain the environment
representation. Finally, a new cross-modal attention navigation framework is
proposed, incorporating our environment representation and a special loss
function dedicated to training ERG. Experimental result shows that our method
achieves satisfactory performance in terms of success rate on VLN-CE tasks.
Further analysis explains that our method attains better cross-modal matching
and strong generalization ability.",2023-01-11,2023,2023-01,environment
"Generalization through Diversity: Improving Unsupervised Environment
  Design","Agent decision making using Reinforcement Learning (RL) heavily relies on
either a model or simulator of the environment (e.g., moving in an 8x8 maze
with three rooms, playing Chess on an 8x8 board). Due to this dependence, small
changes in the environment (e.g., positions of obstacles in the maze, size of
the board) can severely affect the effectiveness of the policy learned by the
agent. To that end, existing work has proposed training RL agents on an
adaptive curriculum of environments (generated automatically) to improve
performance on out-of-distribution (OOD) test scenarios. Specifically, existing
research has employed the potential for the agent to learn in an environment
(captured using Generalized Advantage Estimation, GAE) as the key factor to
select the next environment(s) to train the agent. However, such a mechanism
can select similar environments (with a high potential to learn) thereby making
agent training redundant on all but one of those environments. To that end, we
provide a principled approach to adaptively identify diverse environments based
on a novel distance measure relevant to environment design. We empirically
demonstrate the versatility and effectiveness of our method in comparison to
multiple leading approaches for unsupervised environment design on three
distinct benchmark problems used in literature.",2023-01-19,2023,2023-01,environment
Multi-Agent Interplay in a Competitive Survival Environment,"Solving hard-exploration environments in an important challenge in
Reinforcement Learning. Several approaches have been proposed and studied, such
as Intrinsic Motivation, co-evolution of agents and tasks, and multi-agent
competition. In particular, the interplay between multiple agents has proven to
be capable of generating human-relevant emergent behaviour that would be
difficult or impossible to learn in single-agent settings. In this work, an
extensible competitive environment for multi-agent interplay was developed,
which features realistic physics and human-relevant semantics. Moreover,
several experiments on different variants of this environment were performed,
resulting in some simple emergent strategies and concrete directions for future
improvement. The content presented here is part of the author's thesis
""Multi-Agent Interplay in a Competitive Survival Environment"" for the Master's
Degree in Artificial Intelligence and Robotics at Sapienza University of Rome,
2022.",2023-01-19,2023,2023-01,environment
"PushWorld: A benchmark for manipulation planning with tools and movable
  obstacles","While recent advances in artificial intelligence have achieved human-level
performance in environments like Starcraft and Go, many physical reasoning
tasks remain challenging for modern algorithms. To date, few algorithms have
been evaluated on physical tasks that involve manipulating objects when movable
obstacles are present and when tools must be used to perform the manipulation.
To promote research on such tasks, we introduce PushWorld, an environment with
simplistic physics that requires manipulation planning with both movable
obstacles and tools. We provide a benchmark of more than 200 PushWorld puzzles
in PDDL and in an OpenAI Gym environment. We evaluate state-of-the-art
classical planning and reinforcement learning algorithms on this benchmark, and
we find that these baseline results are below human-level performance. We then
provide a new classical planning heuristic that solves the most puzzles among
the baselines, and although it is 40 times faster than the best baseline
planner, it remains below human-level performance.",2023-01-24,2023,2023-01,environment
"Effective Baselines for Multiple Object Rearrangement Planning in
  Partially Observable Mapped Environments","Many real-world tasks, from house-cleaning to cooking, can be formulated as
multi-object rearrangement problems -- where an agent needs to get specific
objects into appropriate goal states. For such problems, we focus on the
setting that assumes a pre-specified goal state, availability of perfect
manipulation and object recognition capabilities, and a static map of the
environment but unknown initial location of objects to be rearranged. Our goal
is to enable home-assistive intelligent agents to efficiently plan for
rearrangement under such partial observability. This requires efficient
trade-offs between exploration of the environment and planning for
rearrangement, which is challenging because of long-horizon nature of the
problem. To make progress on this problem, we first analyze the effects of
various factors such as number of objects and receptacles, agent carrying
capacity, environment layouts etc. on exploration and planning for
rearrangement using classical methods. We then investigate both monolithic and
modular deep reinforcement learning (DRL) methods for planning in our setting.
We find that monolithic DRL methods do not succeed at long-horizon planning
needed for multi-object rearrangement. Instead, modular greedy approaches
surprisingly perform reasonably well and emerge as competitive baselines for
planning with partial observability in multi-object rearrangement problems. We
also show that our greedy modular agents are empirically optimal when the
objects that need to be rearranged are uniformly distributed in the environment
-- thereby contributing baselines with strong performance for future work on
multi-object rearrangement planning in partially observable settings.",2023-01-24,2023,2023-01,environment
"Polycraft World AI Lab (PAL): An Extensible Platform for Evaluating
  Artificial Intelligence Agents","As artificial intelligence research advances, the platforms used to evaluate
AI agents need to adapt and grow to continue to challenge them. We present the
Polycraft World AI Lab (PAL), a task simulator with an API based on the
Minecraft mod Polycraft World. Our platform is built to allow AI agents with
different architectures to easily interact with the Minecraft world, train and
be evaluated in multiple tasks. PAL enables the creation of tasks in a flexible
manner as well as having the capability to manipulate any aspect of the task
during an evaluation. All actions taken by AI agents and external actors
(non-player-characters, NPCs) in the open-world environment are logged to
streamline evaluation. Here we present two custom tasks on the PAL platform,
one focused on multi-step planning and one focused on navigation, and
evaluations of agents solving them. In summary, we report a versatile and
extensible AI evaluation platform with a low barrier to entry for AI
researchers to utilize.",2023-01-27,2023,2023-01,environment
"DiSProD: Differentiable Symbolic Propagation of Distributions for
  Planning","The paper introduces DiSProD, an online planner developed for environments
with probabilistic transitions in continuous state and action spaces. DiSProD
builds a symbolic graph that captures the distribution of future trajectories,
conditioned on a given policy, using independence assumptions and approximate
propagation of distributions. The symbolic graph provides a differentiable
representation of the policy's value, enabling efficient gradient-based
optimization for long-horizon search. The propagation of approximate
distributions can be seen as an aggregation of many trajectories, making it
well-suited for dealing with sparse rewards and stochastic environments. An
extensive experimental evaluation compares DiSProD to state-of-the-art planners
in discrete-time planning and real-time control of robotic systems. The
proposed method improves over existing planners in handling stochastic
environments, sensitivity to search depth, sparsity of rewards, and large
action spaces. Additional real-world experiments demonstrate that DiSProD can
control ground vehicles and surface vessels to successfully navigate around
obstacles.",2023-02-03,2023,2023-02,environment
Diversity Induced Environment Design via Self-Play,"Recent work on designing an appropriate distribution of environments has
shown promise for training effective generally capable agents. Its success is
partly because of a form of adaptive curriculum learning that generates
environment instances (or levels) at the frontier of the agent's capabilities.
However, such an environment design framework often struggles to find effective
levels in challenging design spaces and requires costly interactions with the
environment. In this paper, we aim to introduce diversity in the Unsupervised
Environment Design (UED) framework. Specifically, we propose a task-agnostic
method to identify observed/hidden states that are representative of a given
level. The outcome of this method is then utilized to characterize the
diversity between two levels, which as we show can be crucial to effective
performance. In addition, to improve sampling efficiency, we incorporate the
self-play technique that allows the environment generator to automatically
generate environments that are of great benefit to the training agent.
Quantitatively, our approach, Diversity-induced Environment Design via
Self-Play (DivSP), shows compelling performance over existing methods.",2023-02-04,2023,2023-02,environment
Dataset for predicting cybersickness from a virtual navigation task,"This work presents a dataset collected to predict cybersickness in virtual
reality environments. The data was collected from navigation tasks in a virtual
environment designed to induce cybersickness. The dataset consists of many data
points collected from diverse participants, including physiological responses
(EDA and Heart Rate) and self-reported cybersickness symptoms. The paper will
provide a detailed description of the dataset, including the arranged
navigation task, the data collection procedures, and the data format. The
dataset will serve as a valuable resource for researchers to develop and
evaluate predictive models for cybersickness and will facilitate more research
in cybersickness mitigation.",2023-02-07,2023,2023-02,environment
"Understanding Policy and Technical Aspects of AI-Enabled Smart Video
  Surveillance to Address Public Safety","Recent advancements in artificial intelligence (AI) have seen the emergence
of smart video surveillance (SVS) in many practical applications, particularly
for building safer and more secure communities in our urban environments.
Cognitive tasks, such as identifying objects, recognizing actions, and
detecting anomalous behaviors, can produce data capable of providing valuable
insights to the community through statistical and analytical tools. However,
artificially intelligent surveillance systems design requires special
considerations for ethical challenges and concerns. The use and storage of
personally identifiable information (PII) commonly pose an increased risk to
personal privacy. To address these issues, this paper identifies the privacy
concerns and requirements needed to address when designing AI-enabled smart
video surveillance. Further, we propose the first end-to-end AI-enabled
privacy-preserving smart video surveillance system that holistically combines
computer vision analytics, statistical data analytics, cloud-native services,
and end-user applications. Finally, we propose quantitative and qualitative
metrics to evaluate intelligent video surveillance systems. The system shows
the 17.8 frame-per-second (FPS) processing in extreme video scenes. However,
considering privacy in designing such a system results in preferring the
pose-based algorithm to the pixel-based one. This choice resulted in dropping
accuracy in both action and anomaly detection tasks. The results drop from
97.48 to 73.72 in anomaly detection and 96 to 83.07 in the action detection
task. On average, the latency of the end-to-end system is 36.1 seconds.",2023-02-08,2023,2023-02,environment
Zero-shot Sim2Real Adaptation Across Environments,"Simulation based learning often provides a cost-efficient recourse to
reinforcement learning applications in robotics. However, simulators are
generally incapable of accurately replicating real-world dynamics, and thus
bridging the sim2real gap is an important problem in simulation based learning.
Current solutions to bridge the sim2real gap involve hybrid simulators that are
augmented with neural residual models. Unfortunately, they require a separate
residual model for each individual environment configuration (i.e., a fixed
setting of environment variables such as mass, friction etc.), and thus are not
transferable to new environments quickly. To address this issue, we propose a
Reverse Action Transformation (RAT) policy which learns to imitate simulated
policies in the real-world. Once learnt from a single environment, RAT can then
be deployed on top of a Universal Policy Network to achieve zero-shot
adaptation to new environments. We empirically evaluate our approach in a set
of continuous control tasks and observe its advantage as a few-shot and
zero-shot learner over competing baselines.",2023-02-08,2023,2023-02,environment
"Self-mediated exploration in artificial intelligence inspired by
  cognitive psychology","Exploration of the physical environment is an indispensable precursor to data
acquisition and enables knowledge generation via analytical or direct trialing.
Artificial Intelligence lacks the exploratory capabilities of even the most
underdeveloped organisms, hindering its autonomy and adaptability. Supported by
cognitive psychology, this works links human behavior and artificial agents to
endorse self-development. In accordance with reported data, paradigms of
epistemic and achievement emotion are embedded to machine-learning methodology
contingent on their impact when decision making. A study is subsequently
designed to mirror previous human trials, which artificial agents are made to
undergo repeatedly towards convergence. Results demonstrate causality, learned
by the vast majority of agents, between their internal states and exploration
to match those reported for human counterparts. The ramifications of these
findings are pondered for both research into human cognition and betterment of
artificial intelligence.",2023-02-13,2023,2023-02,environment
"Signifiers as a First-class Abstraction in Hypermedia Multi-Agent
  Systems","Hypermedia APIs enable the design of reusable hypermedia clients that
discover and exploit affordances on the Web. However, the reusability of such
clients remains limited since they cannot plan and reason about interaction.
This paper provides a conceptual bridge between hypermedia-driven affordance
exploitation on the Web and methods for representing and reasoning about
actions that have been extensively explored for Multi-Agent Systems (MAS) and,
more broadly, Artificial Intelligence. We build on concepts and methods from
Affordance Theory and Human-Computer Interaction that support interaction
efficiency in open and evolvable environments to introduce signifiers as a
first-class abstraction in Web-based MAS: Signifiers are designed with respect
to the agent-environment context of their usage and enable agents with
heterogeneous abilities to act and to reason about action. We define a formal
model for the contextual exposure of signifiers in hypermedia environments that
aims to drive affordance exploitation. We demonstrate our approach with a
prototypical Web-based MAS where two agents with different reasoning abilities
proactively discover how to interact with their environment by perceiving only
the signifiers that fit their abilities. We show that signifier exposure can be
inherently managed based on the dynamic agent-environment context towards
facilitating effective and efficient interactions on the Web.",2023-02-14,2023,2023-02,environment
"Grounding Complex Natural Language Commands for Temporal Tasks in Unseen
  Environments","Grounding navigational commands to linear temporal logic (LTL) leverages its
unambiguous semantics for reasoning about long-horizon tasks and verifying the
satisfaction of temporal constraints. Existing approaches require training data
from the specific environment and landmarks that will be used in natural
language to understand commands in those environments. We propose Lang2LTL, a
modular system and a software package that leverages large language models
(LLMs) to ground temporal navigational commands to LTL specifications in
environments without prior language data. We comprehensively evaluate Lang2LTL
for five well-defined generalization behaviors. Lang2LTL demonstrates the
state-of-the-art ability of a single model to ground navigational commands to
diverse temporal specifications in 21 city-scaled environments. Finally, we
demonstrate a physical robot using Lang2LTL can follow 52 semantically diverse
navigational commands in two indoor environments.",2023-02-22,2023,2023-02,environment
Characterizing Novelty in the Military Domain,"A critical factor in utilizing agents with Artificial Intelligence (AI) is
their robustness to novelty. AI agents include models that are either
engineered or trained. Engineered models include knowledge of those aspects of
the environment that are known and considered important by the engineers.
Learned models form embeddings of aspects of the environment based on
connections made through the training data. In operation, however, a rich
environment is likely to present challenges not seen in training sets or
accounted for in engineered models. Worse still, adversarial environments are
subject to change by opponents. A program at the Defense Advanced Research
Project Agency (DARPA) seeks to develop the science necessary to develop and
evaluate agents that are robust to novelty. This capability will be required,
before AI has the role envisioned within mission critical environments. As part
of the Science of AI and Learning for Open-world Novelty (SAIL-ON), we are
mapping possible military domain novelty types to a domain-independent ontology
developed as part of a theory of novelty. Characterizing the possible space of
novelty mathematically and ontologically will allow us to experiment with agent
designs that are coming from the DARPA SAIL-ON program in relevant military
environments. Utilizing the same techniques as being used in laboratory
experiments, we will be able to measure agent ability to detect, characterize,
and accommodate novelty.",2023-02-23,2023,2023-02,environment
Neural Laplace Control for Continuous-time Delayed Systems,"Many real-world offline reinforcement learning (RL) problems involve
continuous-time environments with delays. Such environments are characterized
by two distinctive features: firstly, the state x(t) is observed at irregular
time intervals, and secondly, the current action a(t) only affects the future
state x(t + g) with an unknown delay g > 0. A prime example of such an
environment is satellite control where the communication link between earth and
a satellite causes irregular observations and delays. Existing offline RL
algorithms have achieved success in environments with irregularly observed
states in time or known delays. However, environments involving both irregular
observations in time and unknown delays remains an open and challenging
problem. To this end, we propose Neural Laplace Control, a continuous-time
model-based offline RL method that combines a Neural Laplace dynamics model
with a model predictive control (MPC) planner--and is able to learn from an
offline dataset sampled with irregular time intervals from an environment that
has a inherent unknown constant delay. We show experimentally on
continuous-time delayed environments it is able to achieve near expert policy
performance.",2023-02-24,2023,2023-02,environment
Towards Measuring Ethicality of an Intelligent Assistive System,"Artificial intelligence (AI) based assistive systems, so called intelligent
assistive technology (IAT) are becoming increasingly ubiquitous by each day.
IAT helps people in improving their quality of life by providing intelligent
assistance based on the provided data. A few examples of such IATs include
self-driving cars, robot assistants and smart-health management solutions.
However, the presence of such autonomous entities poses ethical challenges
concerning the stakeholders involved in using these systems. There is a lack of
research when it comes to analysing how such IAT adheres to provided ethical
regulations due to ethical, logistic and cost issues associated with such an
analysis. In the light of the above-mentioned problem statement and issues, we
present a method to measure the ethicality of an assistive system. To perform
this task, we utilised our simulation tool that focuses on modelling navigation
and assistance of Persons with Dementia (PwD) in indoor environments. By
utilising this tool, we analyse how well different assistive strategies adhere
to provided ethical regulations such as autonomy, justice and beneficence of
the stakeholders.",2023-02-28,2023,2023-02,environment
"Hallucinated Adversarial Control for Conservative Offline Policy
  Evaluation","We study the problem of conservative off-policy evaluation (COPE) where given
an offline dataset of environment interactions, collected by other agents, we
seek to obtain a (tight) lower bound on a policy's performance. This is crucial
when deciding whether a given policy satisfies certain minimal
performance/safety criteria before it can be deployed in the real world. To
this end, we introduce HAMBO, which builds on an uncertainty-aware learned
model of the transition dynamics. To form a conservative estimate of the
policy's performance, HAMBO hallucinates worst-case trajectories that the
policy may take, within the margin of the models' epistemic confidence regions.
We prove that the resulting COPE estimates are valid lower bounds, and, under
regularity conditions, show their convergence to the true expected return.
Finally, we discuss scalable variants of our approach based on Bayesian Neural
Networks and empirically demonstrate that they yield reliable and tight lower
bounds in various continuous control environments.",2023-03-02,2023,2023-03,environment
CoRL: Environment Creation and Management Focused on System Integration,"Existing reinforcement learning environment libraries use monolithic
environment classes, provide shallow methods for altering agent observation and
action spaces, and/or are tied to a specific simulation environment. The Core
Reinforcement Learning library (CoRL) is a modular, composable, and
hyper-configurable environment creation tool. It allows minute control over
agent observations, rewards, and done conditions through the use of
easy-to-read configuration files, pydantic validators, and a functor design
pattern. Using integration pathways allows agents to be quickly implemented in
new simulation environments, encourages rapid exploration, and enables
transition of knowledge from low-fidelity to high-fidelity simulations.
Natively multi-agent design and integration with Ray/RLLib (Liang et al., 2018)
at release allow for easy scalability of agent complexity and computing power.
The code is publicly released and available at
https://github.com/act3-ace/CoRL.",2023-03-03,2023,2023-03,environment
Real-time SLAM Pipeline in Dynamics Environment,"Inspired by the recent success of application of dense data approach by using
ORB-SLAM and RGB-D SLAM, we propose a better pipeline of real-time SLAM in
dynamics environment. Different from previous SLAM which can only handle static
scenes, we are presenting a solution which use RGB-D SLAM as well as YOLO
real-time object detection to segment and remove dynamic scene and then
construct static scene 3D. We gathered a dataset which allows us to jointly
consider semantics, geometry, and physics and thus enables us to reconstruct
the static scene while filtering out all dynamic objects.",2023-03-04,2023,2023-03,environment
"Improved Sample Complexity Bounds for Distributionally Robust
  Reinforcement Learning","We consider the problem of learning a control policy that is robust against
the parameter mismatches between the training environment and testing
environment. We formulate this as a distributionally robust reinforcement
learning (DR-RL) problem where the objective is to learn the policy which
maximizes the value function against the worst possible stochastic model of the
environment in an uncertainty set. We focus on the tabular episodic learning
setting where the algorithm has access to a generative model of the nominal
(training) environment around which the uncertainty set is defined. We propose
the Robust Phased Value Learning (RPVL) algorithm to solve this problem for the
uncertainty sets specified by four different divergences: total variation,
chi-square, Kullback-Leibler, and Wasserstein. We show that our algorithm
achieves $\tilde{\mathcal{O}}(|\mathcal{S}||\mathcal{A}| H^{5})$ sample
complexity, which is uniformly better than the existing results by a factor of
$|\mathcal{S}|$, where $|\mathcal{S}|$ is number of states, $|\mathcal{A}|$ is
the number of actions, and $H$ is the horizon length. We also provide the
first-ever sample complexity result for the Wasserstein uncertainty set.
Finally, we demonstrate the performance of our algorithm using simulation
experiments.",2023-03-05,2023,2023-03,environment
"Active hypothesis testing in unknown environments using recurrent neural
  networks and model free reinforcement learning","A combination of deep reinforcement learning and supervised learning is
proposed for the problem of active sequential hypothesis testing in completely
unknown environments. We make no assumptions about the prior probability, the
action and observation sets, and the observation generating process. Our method
can be used in any environment even if it has continuous observations or
actions, and performs competitively and sometimes better than the Chernoff
test, in both finite and infinite horizon problems, despite not having access
to the environment dynamics.",2023-03-19,2023,2023-03,environment
Artificial Intelligence and Dual Contract,"This paper explores the capacity of artificial intelligence (AI) algorithms
to autonomously design incentive-compatible contracts in dual-principal-agent
settings, a relatively unexplored aspect of algorithmic mechanism design. We
develop a dynamic model where two principals, each equipped with independent
Q-learning algorithms, interact with a single agent. Our findings reveal that
the strategic behavior of AI principals (cooperation vs. competition) hinges
crucially on the alignment of their profits. Notably, greater profit alignment
fosters collusive strategies, yielding higher principal profits at the expense
of agent incentives. This emergent behavior persists across varying degrees of
principal heterogeneity, multiple principals, and environments with
uncertainty. Our study underscores the potential of AI for contract automation
while raising critical concerns regarding strategic manipulation and the
emergence of unintended collusion in AI-driven systems, particularly in the
context of the broader AI alignment problem.",2023-03-22,2023,2023-03,environment
Distributed Silhouette Algorithm: Evaluating Clustering on Big Data,"In the big data era, the key feature that each algorithm needs to have is the
possibility of efficiently running in parallel in a distributed environment.
The popular Silhouette metric to evaluate the quality of a clustering,
unfortunately, does not have this property and has a quadratic computational
complexity with respect to the size of the input dataset. For this reason, its
execution has been hindered in big data scenarios, where clustering had to be
evaluated otherwise. To fill this gap, in this paper we introduce the first
algorithm that computes the Silhouette metric with linear complexity and can
easily execute in parallel in a distributed environment. Its implementation is
freely available in the Apache Spark ML library.",2023-03-24,2023,2023-03,environment
"Embedding Contextual Information through Reward Shaping in Multi-Agent
  Learning: A Case Study from Google Football","Artificial Intelligence has been used to help human complete difficult tasks
in complicated environments by providing optimized strategies for
decision-making or replacing the manual labour. In environments including
multiple agents, such as football, the most common methods to train agents are
Imitation Learning and Multi-Agent Reinforcement Learning (MARL). However, the
agents trained by Imitation Learning cannot outperform the expert demonstrator,
which makes humans hardly get new insights from the learnt policy. Besides,
MARL is prone to the credit assignment problem. In environments with sparse
reward signal, this method can be inefficient. The objective of our research is
to create a novel reward shaping method by embedding contextual information in
reward function to solve the aforementioned challenges. We demonstrate this in
the Google Research Football (GRF) environment. We quantify the contextual
information extracted from game state observation and use this quantification
together with original sparse reward to create the shaped reward. The
experiment results in the GRF environment prove that our reward shaping method
is a useful addition to state-of-the-art MARL algorithms for training agents in
environments with sparse reward signal.",2023-03-25,2023,2023-03,environment
Natural Selection Favors AIs over Humans,"For billions of years, evolution has been the driving force behind the
development of life, including humans. Evolution endowed humans with high
intelligence, which allowed us to become one of the most successful species on
the planet. Today, humans aim to create artificial intelligence systems that
surpass even our own intelligence. As artificial intelligences (AIs) evolve and
eventually surpass us in all domains, how might evolution shape our relations
with AIs? By analyzing the environment that is shaping the evolution of AIs, we
argue that the most successful AI agents will likely have undesirable traits.
Competitive pressures among corporations and militaries will give rise to AI
agents that automate human roles, deceive others, and gain power. If such
agents have intelligence that exceeds that of humans, this could lead to
humanity losing control of its future. More abstractly, we argue that natural
selection operates on systems that compete and vary, and that selfish species
typically have an advantage over species that are altruistic to other species.
This Darwinian logic could also apply to artificial agents, as agents may
eventually be better able to persist into the future if they behave selfishly
and pursue their own interests with little regard for humans, which could pose
catastrophic risks. To counteract these risks and evolutionary forces, we
consider interventions such as carefully designing AI agents' intrinsic
motivations, introducing constraints on their actions, and institutions that
encourage cooperation. These steps, or others that resolve the problems we
pose, will be necessary in order to ensure the development of artificial
intelligence is a positive one.",2023-03-28,2023,2023-03,environment
Ontology in Hybrid Intelligence: a concise literature review,"In a context of constant evolution and proliferation of AI technology,Hybrid
Intelligence is gaining popularity to refer a balanced coexistence between
human and artificial intelligence. The term has been extensively used in the
past two decades to define models of intelligence involving more than one
technology. This paper aims to provide (i) a concise and focused overview of
the adoption of Ontology in the broad context of Hybrid Intelligence regardless
of its definition and (ii) a critical discussion on the possible role of
Ontology to reduce the gap between human and artificial intelligence within
hybrid intelligent systems. Beside the typical benefits provided by an
effective use of ontologies, at a conceptual level, the conducted analysis has
pointed out a significant contribution of Ontology to improve quality and
accuracy, as well as a more specific role to enable extended interoperability,
system engineering and explainable/transparent systems. Additionally, an
application-oriented analysis has shown a significant role in present systems
(70+% of the cases) and, potentially, in future systems. However, despite the
relatively consistent number of papers on the topic, a proper holistic
discussion on the establishment of the next generation of hybrid-intelligent
environments with a balanced co-existence of human and artificial intelligence
is fundamentally missed in literature. Last but not the least, there is
currently a relatively low explicit focus on automatic reasoning and inference
in hybrid intelligent systems.",2023-03-30,2023,2023-03,environment
Core Challenges in Embodied Vision-Language Planning,"Recent advances in the areas of Multimodal Machine Learning and Artificial
Intelligence (AI) have led to the development of challenging tasks at the
intersection of Computer Vision, Natural Language Processing, and Robotics.
Whereas many approaches and previous survey pursuits have characterised one or
two of these dimensions, there has not been a holistic analysis at the center
of all three. Moreover, even when combinations of these topics are considered,
more focus is placed on describing, e.g., current architectural methods, as
opposed to also illustrating high-level challenges and opportunities for the
field. In this survey paper, we discuss Embodied Vision-Language Planning
(EVLP) tasks, a family of prominent embodied navigation and manipulation
problems that jointly leverage computer vision and natural language for
interaction in physical environments. We propose a taxonomy to unify these
tasks and provide an in-depth analysis and comparison of the current and new
algorithmic approaches, metrics, simulators, and datasets used for EVLP tasks.
Finally, we present the core challenges that we believe new EVLP works should
seek to address, and we advocate for task construction that enables model
generalisability and furthers real-world deployment.",2023-04-05,2023,2023-04,environment
"An Artificial Intelligence-based Framework to Achieve the Sustainable
  Development Goals in the Context of Bangladesh","Sustainable development is a framework for achieving human development goals.
It provides natural systems' ability to deliver natural resources and ecosystem
services. Sustainable development is crucial for the economy and society.
Artificial intelligence (AI) has attracted increasing attention in recent
years, with the potential to have a positive influence across many domains. AI
is a commonly employed component in the quest for long-term sustainability. In
this study, we explore the impact of AI on three pillars of sustainable
development: society, environment, and economy, as well as numerous case
studies from which we may deduce the impact of AI in a variety of areas, i.e.,
agriculture, classifying waste, smart water management, and Heating,
Ventilation, and Air Conditioning (HVAC) systems. Furthermore, we present
AI-based strategies for achieving Sustainable Development Goals (SDGs) which
are effective for developing countries like Bangladesh. The framework that we
propose may reduce the negative impact of AI and promote the proactiveness of
this technology.",2023-04-23,2023,2023-04,environment
"Loss- and Reward-Weighting for Efficient Distributed Reinforcement
  Learning","This paper introduces two learning schemes for distributed agents in
Reinforcement Learning (RL) environments, namely Reward-Weighted (R-Weighted)
and Loss-Weighted (L-Weighted) gradient merger. The R/L weighted methods
replace standard practices for training multiple agents, such as summing or
averaging the gradients. The core of our methods is to scale the gradient of
each actor based on how high the reward (for R-Weighted) or the loss (for
L-Weighted) is compared to the other actors. During training, each agent
operates in differently initialized versions of the same environment, which
gives different gradients from different actors. In essence, the R-Weights and
L-Weights of each agent inform the other agents of its potential, which again
reports which environment should be prioritized for learning. This approach of
distributed learning is possible because environments that yield higher
rewards, or low losses, have more critical information than environments that
yield lower rewards or higher losses. We empirically demonstrate that the
R-Weighted methods work superior to the state-of-the-art in multiple RL
environments.",2023-04-25,2023,2023-04,environment
Games for Artificial Intelligence Research: A Review and Perspectives,"Games have been the perfect test-beds for artificial intelligence research
for the characteristics that widely exist in real-world scenarios. Learning and
optimisation, decision making in dynamic and uncertain environments, game
theory, planning and scheduling, design and education are common research areas
shared between games and real-world problems. Numerous open-source games or
game-based environments have been implemented for studying artificial
intelligence. In addition to single- or multi-player, collaborative or
adversarial games, there has also been growing interest in implementing
platforms for creative design in recent years. Those platforms provide ideal
benchmarks for exploring and comparing artificial intelligence ideas and
techniques. This paper reviews the games and game-based platforms for
artificial intelligence research, provides guidance on matching particular
types of artificial intelligence with suitable games for testing and matching
particular needs in games with suitable artificial intelligence techniques,
discusses the research trend induced by the evolution of those games and
platforms, and gives an outlook.",2023-04-26,2023,2023-04,environment
CNN based IoT Device Identification,"While the use of the Internet of Things is becoming more and more popular,
many security vulnerabilities are emerging with the large number of devices
being introduced to the market. In this environment, IoT device identification
methods provide a preventive security measure as an important factor in
identifying these devices and detecting the vulnerabilities they suffer from.
In this study, we present a method that identifies devices in the Aalto dataset
using the convolutional neural network (CNN).",2023-04-27,2023,2023-04,environment
LSTM based IoT Device Identification,"While the use of the Internet of Things is becoming more and more popular,
many security vulnerabilities are emerging with the large number of devices
being introduced to the market. In this environment, IoT device identification
methods provide a preventive security measure as an important factor in
identifying these devices and detecting the vulnerabilities they suffer from.
In this study, we present a method that identifies devices in the Aalto dataset
using Long short-term memory (LSTM)",2023-04-27,2023,2023-04,environment
Cultivated Wildness: Technodiversity and Wildness in Machines,"This paper investigates the idea of cultivated wildness at the intersection
of landscape design and artificial intelligence. The paper posits that
contemporary landscape practices should overcome the potentially single
understanding on wilderness, and instead explore landscape strategies to
cultivate new forms of wild places via ideas and concerns in contemporary
Environmental Humanities, Science and Technology Studies, Ecological Sciences,
and Landscape Architecture. Drawing cases in environmental engineering,
computer science, and landscape architecture research, this paper explores a
framework to construct wild places with intelligent machines. In this
framework, machines are not understood as a layer of ""digital infrastructure""
that is used to extend localized human intelligence and agency. Rather machines
are conceptualized as active agents who can participate in the intelligence of
co-production. Recent developments in cybernetic technologies such as sensing
networks, artificial intelligence, and cyberphysical systems can also
contribute to establishing the framework. At the heart of this framework is
""technodiversity,"" in parallel with biodiversity, since a singular vision on
technological development driven by optimization and efficiency reinforces a
monocultural approach that eliminates other possible relationships to construct
with the environment. Thus, cultivated wildness is also about recognizing
""wildness"" in machines.",2023-05-03,2023,2023-05,environment
"The Future of Artificial Intelligence (AI) and Machine Learning (ML) in
  Landscape Design: A Case Study in Coastal Virginia, USA","There have been theory-based endeavours that directly engage with AI and ML
in the landscape discipline. By presenting a case that uses machine learning
techniques to predict variables in a coastal environment, this paper provides
empirical evidence of the forthcoming cybernetic environment, in which
designers are conceptualized not as authors but as choreographers, catalyst
agents, and conductors among many other intelligent agents. Drawing ideas from
posthumanism, this paper argues that, to truly understand the cybernetic
environment, we have to take on posthumanist ethics and overcome human
exceptionalism.",2023-05-03,2023,2023-05,environment
Simple Noisy Environment Augmentation for Reinforcement Learning,"Data augmentation is a widely used technique for improving model performance
in machine learning, particularly in computer vision and natural language
processing. Recently, there has been increasing interest in applying
augmentation techniques to reinforcement learning (RL) problems, with a focus
on image-based augmentation. In this paper, we explore a set of generic
wrappers designed to augment RL environments with noise and encourage agent
exploration and improve training data diversity which are applicable to a broad
spectrum of RL algorithms and environments. Specifically, we concentrate on
augmentations concerning states, rewards, and transition dynamics and introduce
two novel augmentation techniques. In addition, we introduce a noise rate
hyperparameter for control over the frequency of noise injection. We present
experimental results on the impact of these wrappers on return using three
popular RL algorithms, Soft Actor-Critic (SAC), Twin Delayed DDPG (TD3), and
Proximal Policy Optimization (PPO), across five MuJoCo environments. To support
the choice of augmentation technique in practice, we also present analysis that
explores the performance these techniques across environments. Lastly, we
publish the wrappers in our noisyenv repository for use with gym environments.",2023-05-04,2023,2023-05,environment
"A Framework for Characterizing Novel Environment Transformations in
  General Environments","To be robust to surprising developments, an intelligent agent must be able to
respond to many different types of unexpected change in the world. To date,
there are no general frameworks for defining and characterizing the types of
environment changes that are possible. We introduce a formal and theoretical
framework for defining and categorizing environment transformations, changes to
the world an agent inhabits. We introduce two types of environment
transformation: R-transformations which modify environment dynamics and
T-transformations which modify the generation process that produces scenarios.
We present a new language for describing domains, scenario generators, and
transformations, called the Transformation and Simulator Abstraction Language
(T-SAL), and a logical formalism that rigorously defines these concepts. Then,
we offer the first formal and computational set of tests for eight categories
of environment transformations. This domain-independent framework paves the way
for describing unambiguous classes of novelty, constrained and
domain-independent random generation of environment transformations,
replication of environment transformation studies, and fair evaluation of agent
robustness.",2023-05-07,2023,2023-05,environment
"Sim-MEES: Modular End-Effector System Grasping Dataset for Mobile
  Manipulators in Cluttered Environments","In this paper, we present Sim-MEES: a large-scale synthetic dataset that
contains 1,550 objects with varying difficulty levels and physics properties,
as well as 11 million grasp labels for mobile manipulators to plan grasps using
different gripper modalities in cluttered environments. Our dataset generation
process combines analytic models and dynamic simulations of the entire
cluttered environment to provide accurate grasp labels. We provide a detailed
study of our proposed labeling process for both parallel jaw grippers and
suction cup grippers, comparing them with state-of-the-art methods to
demonstrate how Sim-MEES can provide precise grasp labels in cluttered
environments.",2023-05-17,2023,2023-05,environment
Ambient Technology & Intelligence,"Ambient intelligence refers to technological enhanced electronic environments
which are both responsive and sensitive to the presence of people within their
environment. Environments that are integrated with ambient intelligence tends
to adapt to the needs of individuals within the environment in an unobtrusive
manner in such a way as to enhance everyday life thereby making interaction
with technology extremely seamless and well integrated. This capability was
made possible because it is a concept that combines several key technologies
such as IoT (Internet of Things) technology, sensor technology, AI (Artificial
Intelligence), and advanced human-computer interaction all embedded and
integrated together with the environment.",2023-05-18,2023,2023-05,environment
"Energy-frugal and Interpretable AI Hardware Design using Learning
  Automata","Energy efficiency is a crucial requirement for enabling powerful artificial
intelligence applications at the microedge. Hardware acceleration with frugal
architectural allocation is an effective method for reducing energy. Many
emerging applications also require the systems design to incorporate
interpretable decision models to establish responsibility and transparency. The
design needs to provision for additional resources to provide reachable states
in real-world data scenarios, defining conflicting design tradeoffs between
energy efficiency. is challenging.
  Recently a new machine learning algorithm, called the Tsetlin machine, has
been proposed. The algorithm is fundamentally based on the principles of
finite-state automata and benefits from natural logic underpinning rather than
arithmetic. In this paper, we investigate methods of energy-frugal artificial
intelligence hardware design by suitably tuning the hyperparameters, while
maintaining high learning efficacy. To demonstrate interpretability, we use
reachability and game-theoretic analysis in two simulation environments: a
SystemC model to study the bounded state transitions in the presence of
hardware faults and Nash equilibrium between states to analyze the learning
convergence. Our analyses provides the first insights into conflicting design
tradeoffs involved in energy-efficient and interpretable decision models for
this new artificial intelligence hardware architecture. We show that frugal
resource allocation coupled with systematic prodigality between randomized
reinforcements can provide decisive energy reduction while also achieving
robust and interpretable learning.",2023-05-19,2023,2023-05,environment
Robots in the Garden: Artificial Intelligence and Adaptive Landscapes,"This paper introduces ELUA, the Ecological Laboratory for Urban Agriculture,
a collaboration among landscape architects, architects and computer scientists
who specialize in artificial intelligence, robotics and computer vision. ELUA
has two gantry robots, one indoors and the other outside on the rooftop of a
6-story campus building. Each robot can seed, water, weed, and prune in its
garden. To support responsive landscape research, ELUA also includes sensor
arrays, an AI-powered camera, and an extensive network infrastructure. This
project demonstrates a way to integrate artificial intelligence into an
evolving urban ecosystem, and encourages landscape architects to develop an
adaptive design framework where design becomes a long-term engagement with the
environment.",2023-05-22,2023,2023-05,environment
Vector Autoregressive Evolution for Dynamic Multi-Objective Optimisation,"Dynamic multi-objective optimisation (DMO) handles optimisation problems with
multiple (often conflicting) objectives in varying environments. Such problems
pose various challenges to evolutionary algorithms, which have popularly been
used to solve complex optimisation problems, due to their dynamic nature and
resource restrictions in changing environments. This paper proposes vector
autoregressive evolution (VARE) consisting of vector autoregression (VAR) and
environment-aware hypermutation to address environmental changes in DMO. VARE
builds a VAR model that considers mutual relationship between decision
variables to effectively predict the moving solutions in dynamic environments.
Additionally, VARE introduces EAH to address the blindness of existing
hypermutation strategies in increasing population diversity in dynamic
scenarios where predictive approaches are unsuitable. A seamless integration of
VAR and EAH in an environment-adaptive manner makes VARE effective to handle a
wide range of dynamic environments and competitive with several popular DMO
algorithms, as demonstrated in extensive experimental studies. Specially, the
proposed algorithm is computationally 50 times faster than two widely-used
algorithms (i.e., TrDMOEA and MOEA/D-SVR) while producing significantly better
results.",2023-05-22,2023,2023-05,environment
"Deep Generative Model for Simultaneous Range Error Mitigation and
  Environment Identification","Received waveforms contain rich information for both range information and
environment semantics. However, its full potential is hard to exploit under
multipath and non-line-of-sight conditions. This paper proposes a deep
generative model (DGM) for simultaneous range error mitigation and environment
identification. In particular, we present a Bayesian model for the generative
process of the received waveform composed by latent variables for both
range-related features and environment semantics. The simultaneous range error
mitigation and environment identification is interpreted as an inference
problem based on the DGM, and implemented in a unique end-to-end learning
scheme. Comprehensive experiments on a general Ultra-wideband dataset
demonstrate the superior performance on range error mitigation, scalability to
different environments, and novel capability on simultaneous environment
identification.",2023-05-23,2023,2023-05,environment
Learning Safety Constraints from Demonstrations with Unknown Rewards,"We propose Convex Constraint Learning for Reinforcement Learning (CoCoRL), a
novel approach for inferring shared constraints in a Constrained Markov
Decision Process (CMDP) from a set of safe demonstrations with possibly
different reward functions. While previous work is limited to demonstrations
with known rewards or fully known environment dynamics, CoCoRL can learn
constraints from demonstrations with different unknown rewards without
knowledge of the environment dynamics. CoCoRL constructs a convex safe set
based on demonstrations, which provably guarantees safety even for potentially
sub-optimal (but safe) demonstrations. For near-optimal demonstrations, CoCoRL
converges to the true safe set with no policy regret. We evaluate CoCoRL in
gridworld environments and a driving simulation with multiple constraints.
CoCoRL learns constraints that lead to safe driving behavior. Importantly, we
can safely transfer the learned constraints to different tasks and
environments. In contrast, alternative methods based on Inverse Reinforcement
Learning (IRL) often exhibit poor performance and learn unsafe policies.",2023-05-25,2023,2023-05,environment
"Agents Explore the Environment Beyond Good Actions to Improve Their
  Model for Better Decisions","Improving the decision-making capabilities of agents is a key challenge on
the road to artificial intelligence. To improve the planning skills needed to
make good decisions, MuZero's agent combines prediction by a network model and
planning by a tree search using the predictions. MuZero's learning process can
fail when predictions are poor but planning requires them. We use this as an
impetus to get the agent to explore parts of the decision tree in the
environment that it otherwise would not explore. The agent achieves this, first
by normal planning to come up with an improved policy. Second, it randomly
deviates from this policy at the beginning of each training episode. And third,
it switches back to the improved policy at a random time step to experience the
rewards from the environment associated with the improved policy, which is the
basis for learning the correct value expectation. The simple board game
Tic-Tac-Toe is used to illustrate how this approach can improve the agent's
decision-making ability. The source code, written entirely in Java, is
available at https://github.com/enpasos/muzero.",2023-06-06,2023,2023-06,environment
Human in the Loop Novelty Generation,"Developing artificial intelligence approaches to overcome novel, unexpected
circumstances is a difficult, unsolved problem. One challenge to advancing the
state of the art in novelty accommodation is the availability of testing
frameworks for evaluating performance against novel situations. Recent novelty
generation approaches in domains such as Science Birds and Monopoly leverage
human domain expertise during the search to discover new novelties. Such
approaches introduce human guidance before novelty generation occurs and yield
novelties that can be directly loaded into a simulated environment. We
introduce a new approach to novelty generation that uses abstract models of
environments (including simulation domains) that do not require
domain-dependent human guidance to generate novelties. A key result is a
larger, often infinite space of novelties capable of being generated, with the
trade-off being a requirement to involve human guidance to select and filter
novelties post generation. We describe our Human-in-the-Loop novelty generation
process using our open-source novelty generation library to test baseline
agents in two domains: Monopoly and VizDoom. Our results shows the
Human-in-the-Loop method enables users to develop, implement, test, and revise
novelties within 4 hours for both Monopoly and VizDoom domains.",2023-06-07,2023,2023-06,environment
"Design Principles for Model Generalization and Scalable AI Integration
  in Radio Access Networks","Artificial intelligence (AI) has emerged as a powerful tool for addressing
complex and dynamic tasks in radio communication systems. Research in this
area, however, focused on AI solutions for specific, limited conditions,
hindering models from learning and adapting to generic situations, such as
those met across radio communication systems.
  This paper emphasizes the pivotal role of achieving model generalization in
enhancing performance and enabling scalable AI integration within radio
communications. We outline design principles for model generalization in three
key domains: environment for robustness, intents for adaptability to system
objectives, and control tasks for reducing AI-driven control loops.
Implementing these principles can decrease the number of models deployed and
increase adaptability in diverse radio communication environments. To address
the challenges of model generalization in communication systems, we propose a
learning architecture that leverages centralization of training and data
management functionalities, combined with distributed data generation. We
illustrate these concepts by designing a generalized link adaptation algorithm,
demonstrating the benefits of our proposed approach.",2023-06-09,2023,2023-06,environment
"Enhancing Evacuation Planning through Multi-Agent Simulation and
  Artificial Intelligence: Understanding Human Behavior in Hazardous
  Environments","This paper focuses on the crucial task of addressing the evacuation of
hazardous places, which holds great importance for coordinators, event hosts,
and authorities. To facilitate the development of effective solutions, the
paper employs Artificial Intelligence (AI) techniques, specifically Multi-Agent
Systems (MAS), to construct a simulation model for evacuation. NetLogo is
selected as the simulation tool of choice due to its ability to provide a
comprehensive understanding of human behaviour in distressing situations within
hazardous environments. The primary objective of this paper is to enhance our
comprehension of how individuals react and respond during such distressing
situations. By leveraging AI and MAS, the simulation model aims to capture the
complex dynamics of evacuation scenarios, enabling policymakers and emergency
planners to make informed decisions and implement more efficient and effective
evacuation strategies. This paper endeavours to contribute to the advancement
of evacuation planning and ultimately improve the safety and well-being of
individuals in hazardous places",2023-06-11,2023,2023-06,environment
A Shift In Artistic Practices through Artificial Intelligence,"The explosion of content generated by artificial intelligence (AI) models has
initiated a cultural shift in arts, music, and media, whereby roles are
changing, values are shifting, and conventions are challenged. The vast,
readily available dataset of the Internet has created an environment for AI
models to be trained on any content on the Web. With AI models shared openly
and used by many globally, how does this new paradigm shift challenge the
status quo in artistic practices? What kind of changes will AI technology bring
to music, arts, and new media?",2023-06-13,2023,2023-06,environment
iPDP: On Partial Dependence Plots in Dynamic Modeling Scenarios,"Post-hoc explanation techniques such as the well-established partial
dependence plot (PDP), which investigates feature dependencies, are used in
explainable artificial intelligence (XAI) to understand black-box machine
learning models. While many real-world applications require dynamic models that
constantly adapt over time and react to changes in the underlying distribution,
XAI, so far, has primarily considered static learning environments, where
models are trained in a batch mode and remain unchanged. We thus propose a
novel model-agnostic XAI framework called incremental PDP (iPDP) that extends
on the PDP to extract time-dependent feature effects in non-stationary learning
environments. We formally analyze iPDP and show that it approximates a
time-dependent variant of the PDP that properly reacts to real and virtual
concept drift. The time-sensitivity of iPDP is controlled by a single smoothing
parameter, which directly corresponds to the variance and the approximation
error of iPDP in a static learning environment. We illustrate the efficacy of
iPDP by showcasing an example application for drift detection and conducting
multiple experiments on real-world and synthetic data sets and streams.",2023-06-13,2023,2023-06,environment
Maestro: A Gamified Platform for Teaching AI Robustness,"Although the prevention of AI vulnerabilities is critical to preserve the
safety and privacy of users and businesses, educational tools for robust AI are
still underdeveloped worldwide. We present the design, implementation, and
assessment of Maestro. Maestro is an effective open-source game-based platform
that contributes to the advancement of robust AI education. Maestro provides
goal-based scenarios where college students are exposed to challenging
life-inspired assignments in a competitive programming environment. We assessed
Maestro's influence on students' engagement, motivation, and learning success
in robust AI. This work also provides insights into the design features of
online learning tools that promote active learning opportunities in the robust
AI domain. We analyzed the reflection responses (measured with Likert scales)
of 147 undergraduate students using Maestro in two quarterly college courses in
AI. According to the results, students who felt the acquisition of new skills
in robust AI tended to appreciate highly Maestro and scored highly on material
consolidation, curiosity, and mastery in robust AI. Moreover, the leaderboard,
our key gamification element in Maestro, has effectively contributed to
students' engagement and learning. Results also indicate that Maestro can be
effectively adapted to any course length and depth without losing its
educational quality.",2023-06-14,2023,2023-06,environment
BISCUIT: Causal Representation Learning from Binary Interactions,"Identifying the causal variables of an environment and how to intervene on
them is of core value in applications such as robotics and embodied AI. While
an agent can commonly interact with the environment and may implicitly perturb
the behavior of some of these causal variables, often the targets it affects
remain unknown. In this paper, we show that causal variables can still be
identified for many common setups, e.g., additive Gaussian noise models, if the
agent's interactions with a causal variable can be described by an unknown
binary variable. This happens when each causal variable has two different
mechanisms, e.g., an observational and an interventional one. Using this
identifiability result, we propose BISCUIT, a method for simultaneously
learning causal variables and their corresponding binary interaction variables.
On three robotic-inspired datasets, BISCUIT accurately identifies causal
variables and can even be scaled to complex, realistic environments for
embodied AI.",2023-06-16,2023,2023-06,environment
"Do as I can, not as I get","This paper proposes a model called TMR to mine valuable information from
simulated data environments. We intend to complete the submission of this
paper.",2023-06-17,2023,2023-06,environment
Vanishing Bias Heuristic-guided Reinforcement Learning Algorithm,"Reinforcement Learning has achieved tremendous success in the many Atari
games. In this paper we explored with the lunar lander environment and
implemented classical methods including Q-Learning, SARSA, MC as well as tiling
coding. We also implemented Neural Network based methods including DQN, Double
DQN, Clipped DQN. On top of these, we proposed a new algorithm called Heuristic
RL which utilizes heuristic to guide the early stage training while alleviating
the introduced human bias. Our experiments showed promising results for our
proposed methods in the lunar lander environment.",2023-06-17,2023,2023-06,environment
Learning and evolution: factors influencing an effective combination,"The mutual relationship between evolution and learning is a controversial
argument among the artificial intelligence and neuro-evolution communities.
After more than three decades, there is still no common agreement on the
matter. In this paper the author investigates whether combining learning and
evolution permits to find better solutions than those discovered by evolution
alone. More specifically, the author presents a series of empirical studies
that highlight some specific conditions determining the success of such a
combination, like the introduction of noise during the learning and selection
processes. Results are obtained in two qualitatively different domains, where
agent/environment interactions are minimal or absent.",2023-06-20,2023,2023-06,environment
"A Comprehensive Survey of Artificial Intelligence Techniques for Talent
  Analytics","In today's competitive and fast-evolving business environment, it is a
critical time for organizations to rethink how to make talent-related decisions
in a quantitative manner. Indeed, the recent development of Big Data and
Artificial Intelligence (AI) techniques have revolutionized human resource
management. The availability of large-scale talent and management-related data
provides unparalleled opportunities for business leaders to comprehend
organizational behaviors and gain tangible knowledge from a data science
perspective, which in turn delivers intelligence for real-time decision-making
and effective talent management at work for their organizations. In the last
decade, talent analytics has emerged as a promising field in applied data
science for human resource management, garnering significant attention from AI
communities and inspiring numerous research efforts. To this end, we present an
up-to-date and comprehensive survey on AI technologies used for talent
analytics in the field of human resource management. Specifically, we first
provide the background knowledge of talent analytics and categorize various
pertinent data. Subsequently, we offer a comprehensive taxonomy of relevant
research efforts, categorized based on three distinct application-driven
scenarios: talent management, organization management, and labor market
analysis. In conclusion, we summarize the open challenges and potential
prospects for future research directions in the domain of AI-driven talent
analytics.",2023-07-03,2023,2023-07,environment
ScriptWorld: Text Based Environment For Learning Procedural Knowledge,"Text-based games provide a framework for developing natural language
understanding and commonsense knowledge about the world in reinforcement
learning based agents. Existing text-based environments often rely on fictional
situations and characters to create a gaming framework and are far from
real-world scenarios. In this paper, we introduce ScriptWorld: a text-based
environment for teaching agents about real-world daily chores and hence
imparting commonsense knowledge. To the best of our knowledge, it is the first
interactive text-based gaming framework that consists of daily real-world human
activities designed using scripts dataset. We provide gaming environments for
10 daily activities and perform a detailed analysis of the proposed
environment. We develop RL-based baseline models/agents to play the games in
Scriptworld. To understand the role of language models in such environments, we
leverage features obtained from pre-trained language models in the RL agents.
Our experiments show that prior knowledge obtained from a pre-trained language
model helps to solve real-world text-based gaming environments. We release the
environment via Github: https://github.com/Exploration-Lab/ScriptWorld",2023-07-08,2023,2023-07,environment
"VELMA: Verbalization Embodiment of LLM Agents for Vision and Language
  Navigation in Street View","Incremental decision making in real-world environments is one of the most
challenging tasks in embodied artificial intelligence. One particularly
demanding scenario is Vision and Language Navigation~(VLN) which requires
visual and natural language understanding as well as spatial and temporal
reasoning capabilities. The embodied agent needs to ground its understanding of
navigation instructions in observations of a real-world environment like Street
View. Despite the impressive results of LLMs in other research areas, it is an
ongoing problem of how to best connect them with an interactive visual
environment. In this work, we propose VELMA, an embodied LLM agent that uses a
verbalization of the trajectory and of visual environment observations as
contextual prompt for the next action. Visual information is verbalized by a
pipeline that extracts landmarks from the human written navigation instructions
and uses CLIP to determine their visibility in the current panorama view. We
show that VELMA is able to successfully follow navigation instructions in
Street View with only two in-context examples. We further finetune the LLM
agent on a few thousand examples and achieve 25%-30% relative improvement in
task completion over the previous state-of-the-art for two datasets.",2023-07-12,2023,2023-07,environment
"Explainable Artificial Intelligence driven mask design for
  self-supervised seismic denoising","The presence of coherent noise in seismic data leads to errors and
uncertainties, and as such it is paramount to suppress noise as early and
efficiently as possible. Self-supervised denoising circumvents the common
requirement of deep learning procedures of having noisy-clean training pairs.
However, self-supervised coherent noise suppression methods require extensive
knowledge of the noise statistics. We propose the use of explainable artificial
intelligence approaches to see inside the black box that is the denoising
network and use the gained knowledge to replace the need for any prior
knowledge of the noise itself. This is achieved in practice by leveraging
bias-free networks and the direct linear link between input and output provided
by the associated Jacobian matrix; we show that a simple averaging of the
Jacobian contributions over a number of randomly selected input pixels,
provides an indication of the most effective mask to suppress noise present in
the data. The proposed method therefore becomes a fully automated denoising
procedure requiring no clean training labels or prior knowledge. Realistic
synthetic examples with noise signals of varying complexities, ranging from
simple time-correlated noise to complex pseudo rig noise propagating at the
velocity of the ocean, are used to validate the proposed approach. Its
automated nature is highlighted further by an application to two field
datasets. Without any substantial pre-processing or any knowledge of the
acquisition environment, the automatically identified blind-masks are shown to
perform well in suppressing both trace-wise noise in common shot gathers from
the Volve marine dataset and colored noise in post stack seismic images from a
land seismic survey.",2023-07-13,2023,2023-07,environment
GridMM: Grid Memory Map for Vision-and-Language Navigation,"Vision-and-language navigation (VLN) enables the agent to navigate to a
remote location following the natural language instruction in 3D environments.
To represent the previously visited environment, most approaches for VLN
implement memory using recurrent states, topological maps, or top-down semantic
maps. In contrast to these approaches, we build the top-down egocentric and
dynamically growing Grid Memory Map (i.e., GridMM) to structure the visited
environment. From a global perspective, historical observations are projected
into a unified grid map in a top-down view, which can better represent the
spatial relations of the environment. From a local perspective, we further
propose an instruction relevance aggregation method to capture fine-grained
visual clues in each grid region. Extensive experiments are conducted on both
the REVERIE, R2R, SOON datasets in the discrete environments, and the R2R-CE
dataset in the continuous environments, showing the superiority of our proposed
method.",2023-07-24,2023,2023-07,environment
"Pixel to policy: DQN Encoders for within & cross-game reinforcement
  learning","Reinforcement Learning can be applied to various tasks, and environments.
Many of these environments have a similar shared structure, which can be
exploited to improve RL performance on other tasks. Transfer learning can be
used to take advantage of this shared structure, by learning policies that are
transferable across different tasks and environments and can lead to more
efficient learning as well as improved performance on a wide range of tasks.
This work explores as well as compares the performance between RL models being
trained from the scratch and on different approaches of transfer learning.
Additionally, the study explores the performance of a model trained on multiple
game environments, with the goal of developing a universal game-playing agent
as well as transfer learning a pre-trained encoder using DQN, and training it
on the same game or a different game. Our DQN model achieves a mean episode
reward of 46.16 which even beats the human-level performance with merely 20k
episodes which is significantly lower than deepmind's 1M episodes. The achieved
mean rewards of 533.42 and 402.17 on the Assault and Space Invader environments
respectively, represent noteworthy performance on these challenging
environments.",2023-08-01,2023,2023-08,environment
"From Military to Healthcare: Adopting and Expanding Ethical Principles
  for Generative Artificial Intelligence","In 2020, the U.S. Department of Defense officially disclosed a set of ethical
principles to guide the use of Artificial Intelligence (AI) technologies on
future battlefields. Despite stark differences, there are core similarities
between the military and medical service. Warriors on battlefields often face
life-altering circumstances that require quick decision-making. Medical
providers experience similar challenges in a rapidly changing healthcare
environment, such as in the emergency department or during surgery treating a
life-threatening condition. Generative AI, an emerging technology designed to
efficiently generate valuable information, holds great promise. As computing
power becomes more accessible and the abundance of health data, such as
electronic health records, electrocardiograms, and medical images, increases,
it is inevitable that healthcare will be revolutionized by this technology.
Recently, generative AI has captivated the research community, leading to
debates about its application in healthcare, mainly due to concerns about
transparency and related issues. Meanwhile, concerns about the potential
exacerbation of health disparities due to modeling biases have raised notable
ethical concerns regarding the use of this technology in healthcare. However,
the ethical principles for generative AI in healthcare have been understudied,
and decision-makers often fail to consider the significance of generative AI.
In this paper, we propose GREAT PLEA ethical principles, encompassing
governance, reliability, equity, accountability, traceability, privacy,
lawfulness, empathy, and autonomy, for generative AI in healthcare. We aim to
proactively address the ethical dilemmas and challenges posed by the
integration of generative AI in healthcare.",2023-08-04,2023,2023-08,environment
"Physics-Based Task Generation through Causal Sequence of Physical
  Interactions","Performing tasks in a physical environment is a crucial yet challenging
problem for AI systems operating in the real world. Physics simulation-based
tasks are often employed to facilitate research that addresses this challenge.
In this paper, first, we present a systematic approach for defining a physical
scenario using a causal sequence of physical interactions between objects.
Then, we propose a methodology for generating tasks in a physics-simulating
environment using these defined scenarios as inputs. Our approach enables a
better understanding of the granular mechanics required for solving
physics-based tasks, thereby facilitating accurate evaluation of AI systems'
physical reasoning capabilities. We demonstrate our proposed task generation
methodology using the physics-based puzzle game Angry Birds and evaluate the
generated tasks using a range of metrics, including physical stability,
solvability using intended physical interactions, and accidental solvability
using unintended solutions. We believe that the tasks generated using our
proposed methodology can facilitate a nuanced evaluation of physical reasoning
agents, thus paving the way for the development of agents for more
sophisticated real-world applications.",2023-08-05,2023,2023-08,environment
"Dialogue Possibilities between a Human Supervisor and UAM Air Traffic
  Management: Route Alteration","This paper introduces a novel approach to detour management in Urban Air
Traffic Management (UATM) using knowledge representation and reasoning. It aims
to understand the complexities and requirements of UAM detours, enabling a
method that quickly identifies safe and efficient routes in a carefully sampled
environment. This method implemented in Answer Set Programming uses
non-monotonic reasoning and a two-phase conversation between a human manager
and the UATM system, considering factors like safety and potential impacts. The
robustness and efficacy of the proposed method were validated through several
queries from two simulation scenarios, contributing to the symbiosis of human
knowledge and advanced AI techniques. The paper provides an introduction,
citing relevant studies, problem formulation, solution, discussions, and
concluding comments.",2023-08-11,2023,2023-08,environment
"AI planning in the imagination: High-level planning on learned abstract
  search spaces","Search and planning algorithms have been a cornerstone of artificial
intelligence since the field's inception. Giving reinforcement learning agents
the ability to plan during execution time has resulted in significant
performance improvements in various domains. However, in real-world
environments, the model with respect to which the agent plans has been
constrained to be grounded in the real environment itself, as opposed to a more
abstract model which allows for planning over compound actions and behaviors.
We propose a new method, called PiZero, that gives an agent the ability to plan
in an abstract search space that the agent learns during training, which is
completely decoupled from the real environment. Unlike prior approaches, this
enables the agent to perform high-level planning at arbitrary timescales and
reason in terms of compound or temporally-extended actions, which can be useful
in environments where large numbers of base-level micro-actions are needed to
perform relevant macro-actions. In addition, our method is more general than
comparable prior methods because it seamlessly handles settings with continuous
action spaces, combinatorial action spaces, and partial observability. We
evaluate our method on multiple domains, including the traveling salesman
problem, Sokoban, 2048, the facility location problem, and Pacman.
Experimentally, it outperforms comparable prior methods without assuming access
to an environment simulator at execution time.",2023-08-16,2023,2023-08,environment
"A Robust Policy Bootstrapping Algorithm for Multi-objective
  Reinforcement Learning in Non-stationary Environments","Multi-objective Markov decision processes are a special kind of
multi-objective optimization problem that involves sequential decision making
while satisfying the Markov property of stochastic processes. Multi-objective
reinforcement learning methods address this problem by fusing the reinforcement
learning paradigm with multi-objective optimization techniques. One major
drawback of these methods is the lack of adaptability to non-stationary
dynamics in the environment. This is because they adopt optimization procedures
that assume stationarity to evolve a coverage set of policies that can solve
the problem. This paper introduces a developmental optimization approach that
can evolve the policy coverage set while exploring the preference space over
the defined objectives in an online manner. We propose a novel multi-objective
reinforcement learning algorithm that can robustly evolve a convex coverage set
of policies in an online manner in non-stationary environments. We compare the
proposed algorithm with two state-of-the-art multi-objective reinforcement
learning algorithms in stationary and non-stationary environments. Results
showed that the proposed algorithm significantly outperforms the existing
algorithms in non-stationary environments while achieving comparable results in
stationary environments.",2023-08-18,2023,2023-08,environment
Model-based Offline Policy Optimization with Adversarial Network,"Model-based offline reinforcement learning (RL), which builds a supervised
transition model with logging dataset to avoid costly interactions with the
online environment, has been a promising approach for offline policy
optimization. As the discrepancy between the logging data and online
environment may result in a distributional shift problem, many prior works have
studied how to build robust transition models conservatively and estimate the
model uncertainty accurately. However, the over-conservatism can limit the
exploration of the agent, and the uncertainty estimates may be unreliable. In
this work, we propose a novel Model-based Offline policy optimization framework
with Adversarial Network (MOAN). The key idea is to use adversarial learning to
build a transition model with better generalization, where an adversary is
introduced to distinguish between in-distribution and out-of-distribution
samples. Moreover, the adversary can naturally provide a quantification of the
model's uncertainty with theoretical guarantees. Extensive experiments showed
that our approach outperforms existing state-of-the-art baselines on widely
studied offline RL benchmarks. It can also generate diverse in-distribution
samples, and quantify the uncertainty more accurately.",2023-09-05,2023,2023-09,environment
"Neurosymbolic Meta-Reinforcement Lookahead Learning Achieves Safe
  Self-Driving in Non-Stationary Environments","In the area of learning-driven artificial intelligence advancement, the
integration of machine learning (ML) into self-driving (SD) technology stands
as an impressive engineering feat. Yet, in real-world applications outside the
confines of controlled laboratory scenarios, the deployment of self-driving
technology assumes a life-critical role, necessitating heightened attention
from researchers towards both safety and efficiency. To illustrate, when a
self-driving model encounters an unfamiliar environment in real-time execution,
the focus must not solely revolve around enhancing its anticipated performance;
equal consideration must be given to ensuring its execution or real-time
adaptation maintains a requisite level of safety. This study introduces an
algorithm for online meta-reinforcement learning, employing lookahead symbolic
constraints based on \emph{Neurosymbolic Meta-Reinforcement Lookahead Learning}
(NUMERLA). NUMERLA proposes a lookahead updating mechanism that harmonizes the
efficiency of online adaptations with the overarching goal of ensuring
long-term safety. Experimental results demonstrate NUMERLA confers the
self-driving agent with the capacity for real-time adaptability, leading to
safe and self-adaptive driving under non-stationary urban human-vehicle
interaction scenarios.",2023-09-05,2023,2023-09,environment
"Quantum-AI empowered Intelligent Surveillance: Advancing Public Safety
  Through Innovative Contraband Detection","Surveillance systems have emerged as crucial elements in upholding peace and
security in the modern world. Their ubiquity aids in monitoring suspicious
activities effectively. However, in densely populated environments, continuous
active monitoring becomes impractical, necessitating the development of
intelligent surveillance systems. AI integration in the surveillance domain was
a big revolution, however, speed issues have prevented its widespread
implementation in the field. It has been observed that quantum artificial
intelligence has led to a great breakthrough. Quantum artificial
intelligence-based surveillance systems have shown to be more accurate as well
as capable of performing well in real-time scenarios, which had never been seen
before. In this research, a RentinaNet model is integrated with Quantum CNN and
termed as Quantum-RetinaNet. By harnessing the Quantum capabilities of QCNN,
Quantum-RetinaNet strikes a balance between accuracy and speed. This innovative
integration positions it as a game-changer, addressing the challenges of active
monitoring in densely populated scenarios. As demand for efficient surveillance
solutions continues to grow, Quantum-RetinaNet offers a compelling alternative
to existing CNN models, upholding accuracy standards without sacrificing
real-time performance. The unique attributes of Quantum-RetinaNet have
far-reaching implications for the future of intelligent surveillance. With its
enhanced processing speed, it is poised to revolutionize the field, catering to
the pressing need for rapid yet precise monitoring. As Quantum-RetinaNet
becomes the new standard, it ensures public safety and security while pushing
the boundaries of AI in surveillance.",2023-09-05,2023,2023-09,environment
"Advanced Computing and Related Applications Leveraging Brain-inspired
  Spiking Neural Networks","In the rapid evolution of next-generation brain-inspired artificial
intelligence and increasingly sophisticated electromagnetic environment, the
most bionic characteristics and anti-interference performance of spiking neural
networks show great potential in terms of computational speed, real-time
information processing, and spatio-temporal information processing. Data
processing. Spiking neural network is one of the cores of brain-like artificial
intelligence, which realizes brain-like computing by simulating the structure
and information transfer mode of biological neural networks. This paper
summarizes the strengths, weaknesses and applicability of five neuronal models
and analyzes the characteristics of five network topologies; then reviews the
spiking neural network algorithms and summarizes the unsupervised learning
algorithms based on synaptic plasticity rules and four types of supervised
learning algorithms from the perspectives of unsupervised learning and
supervised learning; finally focuses on the review of brain-like neuromorphic
chips under research at home and abroad. This paper is intended to provide
learning concepts and research orientations for the peers who are new to the
research field of spiking neural networks through systematic summaries.",2023-09-08,2023,2023-09,environment
Representation Learning in Low-rank Slate-based Recommender Systems,"Reinforcement learning (RL) in recommendation systems offers the potential to
optimize recommendations for long-term user engagement. However, the
environment often involves large state and action spaces, which makes it hard
to efficiently learn and explore. In this work, we propose a sample-efficient
representation learning algorithm, using the standard slate recommendation
setup, to treat this as an online RL problem with low-rank Markov decision
processes (MDPs). We also construct the recommender simulation environment with
the proposed setup and sampling method.",2023-09-10,2023,2023-09,environment
"Adaptive User-centered Neuro-symbolic Learning for Multimodal
  Interaction with Autonomous Systems","Recent advances in machine learning, particularly deep learning, have enabled
autonomous systems to perceive and comprehend objects and their environments in
a perceptual subsymbolic manner. These systems can now perform object
detection, sensor data fusion, and language understanding tasks. However, there
is a growing need to enhance these systems to understand objects and their
environments more conceptually and symbolically. It is essential to consider
both the explicit teaching provided by humans (e.g., describing a situation or
explaining how to act) and the implicit teaching obtained by observing human
behavior (e.g., through the system's sensors) to achieve this level of powerful
artificial intelligence. Thus, the system must be designed with multimodal
input and output capabilities to support implicit and explicit interaction
models. In this position paper, we argue for considering both types of inputs,
as well as human-in-the-loop and incremental learning techniques, for advancing
the field of artificial intelligence and enabling autonomous systems to learn
like humans. We propose several hypotheses and design guidelines and highlight
a use case from related work to achieve this goal.",2023-09-11,2023,2023-09,environment
"Life-inspired Interoceptive Artificial Intelligence for Autonomous and
  Adaptive Agents","Building autonomous -- i.e., choosing goals based on one's needs -- and
adaptive -- i.e., surviving in ever-changing environments -- agents has been a
holy grail of artificial intelligence (AI). A living organism is a prime
example of such an agent, offering important lessons about adaptive autonomy.
Here, we focus on interoception, a process of monitoring one's internal
environment to keep it within certain bounds, which underwrites the survival of
an organism. To develop AI with interoception, we need to factorize the state
variables representing internal environments from external environments and
adopt life-inspired mathematical properties of internal environment states.
This paper offers a new perspective on how interoception can help build
autonomous and adaptive agents by integrating the legacy of cybernetics with
recent advances in theories of life, reinforcement learning, and neuroscience.",2023-09-12,2023,2023-09,environment
"Self-Sustaining Multiple Access with Continual Deep Reinforcement
  Learning for Dynamic Metaverse Applications","The Metaverse is a new paradigm that aims to create a virtual environment
consisting of numerous worlds, each of which will offer a different set of
services. To deal with such a dynamic and complex scenario, considering the
stringent quality of service requirements aimed at the 6th generation of
communication systems (6G), one potential approach is to adopt self-sustaining
strategies, which can be realized by employing Adaptive Artificial Intelligence
(Adaptive AI) where models are continually re-trained with new data and
conditions. One aspect of self-sustainability is the management of multiple
access to the frequency spectrum. Although several innovative methods have been
proposed to address this challenge, mostly using Deep Reinforcement Learning
(DRL), the problem of adapting agents to a non-stationary environment has not
yet been precisely addressed. This paper fills in the gap in the current
literature by investigating the problem of multiple access in multi-channel
environments to maximize the throughput of the intelligent agent when the
number of active User Equipments (UEs) may fluctuate over time. To solve the
problem, a Double Deep Q-Learning (DDQL) technique empowered by Continual
Learning (CL) is proposed to overcome the non-stationary situation, while the
environment is unknown. Numerical simulations demonstrate that, compared to
other well-known methods, the CL-DDQL algorithm achieves significantly higher
throughputs with a considerably shorter convergence time in highly dynamic
scenarios.",2023-09-18,2023,2023-09,environment
Context is Environment,"Two lines of work are taking the central stage in AI research. On the one
hand, the community is making increasing efforts to build models that discard
spurious correlations and generalize better in novel test environments.
Unfortunately, the bitter lesson so far is that no proposal convincingly
outperforms a simple empirical risk minimization baseline. On the other hand,
large language models (LLMs) have erupted as algorithms able to learn
in-context, generalizing on-the-fly to eclectic contextual circumstances that
users enforce by means of prompting. In this paper, we argue that context is
environment, and posit that in-context learning holds the key to better domain
generalization. Via extensive theory and experiments, we show that paying
attention to context$\unicode{x2013}\unicode{x2013}$unlabeled examples as they
arrive$\unicode{x2013}\unicode{x2013}$allows our proposed In-Context Risk
Minimization (ICRM) algorithm to zoom-in on the test environment risk
minimizer, leading to significant out-of-distribution performance improvements.
From all of this, two messages are worth taking home. Researchers in domain
generalization should consider environment as context, and harness the adaptive
power of in-context learning. Researchers in LLMs should consider context as
environment, to better structure data towards generalization.",2023-09-18,2023,2023-09,environment
"Privacy Preservation in Artificial Intelligence and Extended Reality
  (AI-XR) Metaverses: A Survey","The metaverse is a nascent concept that envisions a virtual universe, a
collaborative space where individuals can interact, create, and participate in
a wide range of activities. Privacy in the metaverse is a critical concern as
the concept evolves and immersive virtual experiences become more prevalent.
The metaverse privacy problem refers to the challenges and concerns surrounding
the privacy of personal information and data within Virtual Reality (VR)
environments as the concept of a shared VR space becomes more accessible.
Metaverse will harness advancements from various technologies such as
Artificial Intelligence (AI), Extended Reality (XR), Mixed Reality (MR), and
5G/6G-based communication to provide personalized and immersive services to its
users. Moreover, to enable more personalized experiences, the metaverse relies
on the collection of fine-grained user data that leads to various privacy
issues. Therefore, before the potential of the metaverse can be fully realized,
privacy concerns related to personal information and data within VR
environments must be addressed. This includes safeguarding users' control over
their data, ensuring the security of their personal information, and protecting
in-world actions and interactions from unauthorized sharing. In this paper, we
explore various privacy challenges that future metaverses are expected to face,
given their reliance on AI for tracking users, creating XR and MR experiences,
and facilitating interactions. Moreover, we thoroughly analyze technical
solutions such as differential privacy, Homomorphic Encryption (HE), and
Federated Learning (FL) and discuss related sociotechnical issues regarding
privacy.",2023-09-19,2023,2023-09,environment
"Curriculum Reinforcement Learning via Morphology-Environment
  Co-Evolution","Throughout long history, natural species have learned to survive by evolving
their physical structures adaptive to the environment changes. In contrast,
current reinforcement learning (RL) studies mainly focus on training an agent
with a fixed morphology (e.g., skeletal structure and joint attributes) in a
fixed environment, which can hardly generalize to changing environments or new
tasks. In this paper, we optimize an RL agent and its morphology through
``morphology-environment co-evolution (MECE)'', in which the morphology keeps
being updated to adapt to the changing environment, while the environment is
modified progressively to bring new challenges and stimulate the improvement of
the morphology. This leads to a curriculum to train generalizable RL, whose
morphology and policy are optimized for different environments. Instead of
hand-crafting the curriculum, we train two policies to automatically change the
morphology and the environment. To this end, (1) we develop two novel and
effective rewards for the two policies, which are solely based on the learning
dynamics of the RL agent; (2) we design a scheduler to automatically determine
when to change the environment and the morphology. In experiments on two
classes of tasks, the morphology and RL policies trained via MECE exhibit
significantly better generalization performance in unseen test environments
than SOTA morphology optimization methods. Our ablation studies on the two MECE
policies further show that the co-evolution between the morphology and
environment is the key to the success.",2023-09-21,2023,2023-09,environment
"Enhancing Graph Representation of the Environment through Local and
  Cloud Computation","Enriching the robot representation of the operational environment is a
challenging task that aims at bridging the gap between low-level sensor
readings and high-level semantic understanding. Having a rich representation
often requires computationally demanding architectures and pure point cloud
based detection systems that struggle when dealing with everyday objects that
have to be handled by the robot. To overcome these issues, we propose a
graph-based representation that addresses this gap by providing a semantic
representation of robot environments from multiple sources. In fact, to acquire
information from the environment, the framework combines classical computer
vision tools with modern computer vision cloud services, ensuring computational
feasibility on onboard hardware. By incorporating an ontology hierarchy with
over 800 object classes, the framework achieves cross-domain adaptability,
eliminating the need for environment-specific tools. The proposed approach
allows us to handle also small objects and integrate them into the semantic
representation of the environment. The approach is implemented in the Robot
Operating System (ROS) using the RViz visualizer for environment
representation. This work is a first step towards the development of a
general-purpose framework, to facilitate intuitive interaction and navigation
across different domains.",2023-09-22,2023,2023-09,environment
"Intent-Aware Autonomous Driving: A Case Study on Highway Merging
  Scenarios","In this work, we use the communication of intent as a means to facilitate
cooperation between autonomous vehicle agents. Generally speaking, intents can
be any reliable information about its future behavior that a vehicle
communicates with another vehicle. We implement this as an intent-sharing task
atop the merging environment in the simulator of highway-env, which provides a
collection of environments for learning decision-making strategies for
autonomous vehicles. Under a simple setting between two agents, we carefully
investigate how intent-sharing can aid the receiving vehicle in adjusting its
behavior in highway merging scenarios.",2023-09-22,2023,2023-09,environment
CoinRun: Solving Goal Misgeneralisation,"Goal misgeneralisation is a key challenge in AI alignment -- the task of
getting powerful Artificial Intelligences to align their goals with human
intentions and human morality. In this paper, we show how the ACE (Algorithm
for Concept Extrapolation) agent can solve one of the key standard challenges
in goal misgeneralisation: the CoinRun challenge. It uses no new reward
information in the new environment. This points to how autonomous agents could
be trusted to act in human interests, even in novel and critical situations.",2023-09-28,2023,2023-09,environment
"Uncertainty-Aware Decision Transformer for Stochastic Driving
  Environments","Offline Reinforcement Learning (RL) enables policy learning without active
interactions, making it especially appealing for self-driving tasks. Recent
successes of Transformers inspire casting offline RL as sequence modeling,
which, however, fails in stochastic environments with incorrect assumptions
that identical actions can consistently achieve the same goal. In this paper,
we introduce an UNcertainty-awaRE deciSion Transformer (UNREST) for planning in
stochastic driving environments without introducing additional transition or
complex generative models. Specifically, UNREST estimates uncertainties by
conditional mutual information between transitions and returns. Discovering
'uncertainty accumulation' and 'temporal locality' properties of driving
environments, we replace the global returns in decision transformers with
truncated returns less affected by environments to learn from actual outcomes
of actions rather than environment transitions. We also dynamically evaluate
uncertainty at inference for cautious planning. Extensive experiments
demonstrate UNREST's superior performance in various driving scenarios and the
power of our uncertainty estimation strategy.",2023-09-28,2023,2023-09,environment
Discovering environments with XRM,"Environment annotations are essential for the success of many
out-of-distribution (OOD) generalization methods. Unfortunately, these are
costly to obtain and often limited by human annotators' biases. To achieve
robust generalization, it is essential to develop algorithms for automatic
environment discovery within datasets. Current proposals, which divide examples
based on their training error, suffer from one fundamental problem. These
methods introduce hyper-parameters and early-stopping criteria, which require a
validation set with human-annotated environments, the very information subject
to discovery. In this paper, we propose Cross-Risk-Minimization (XRM) to
address this issue. XRM trains twin networks, each learning from one random
half of the training data, while imitating confident held-out mistakes made by
its sibling. XRM provides a recipe for hyper-parameter tuning, does not require
early-stopping, and can discover environments for all training and validation
data. Algorithms built on top of XRM environments achieve oracle
worst-group-accuracy, addressing a long-standing challenge in OOD
generalization. Code available at
\url{https://github.com/facebookresearch/XRM}.",2023-09-28,2023,2023-09,environment
"Enhancing the Hierarchical Environment Design via Generative Trajectory
  Modeling","Unsupervised Environment Design (UED) is a paradigm for automatically
generating a curriculum of training environments, enabling agents trained in
these environments to develop general capabilities, i.e., achieving good
zero-shot transfer performance. However, existing UED approaches focus
primarily on the random generation of environments for open-ended agent
training. This is impractical in scenarios with limited resources, such as the
constraints on the number of generated environments. In this paper, we
introduce a hierarchical MDP framework for environment design under resource
constraints. It consists of an upper-level RL teacher agent that generates
suitable training environments for a lower-level student agent. The RL teacher
can leverage previously discovered environment structures and generate
environments at the frontier of the student's capabilities by observing the
student policy's representation. Moreover, to reduce the time-consuming
collection of experiences for the upper-level teacher, we utilize recent
advances in generative modeling to synthesize a trajectory dataset to train the
teacher agent. Our proposed method significantly reduces the resource-intensive
interactions between agents and environments and empirical experiments across
various domains demonstrate the effectiveness of our approach.",2023-09-30,2023,2023-09,environment
"A Review of Digital Learning Environments for Teaching Natural Language
  Processing in K-12 Education","Natural Language Processing (NLP) plays a significant role in our daily lives
and has become an essential part of Artificial Intelligence (AI) education in
K-12. As children grow up with NLP-powered applications, it is crucial to
introduce NLP concepts to them, fostering their understanding of language
processing, language generation, and ethical implications of AI and NLP. This
paper presents a comprehensive review of digital learning environments for
teaching NLP in K-12. Specifically, it explores existing digital learning
tools, discusses how they support specific NLP tasks and procedures, and
investigates their explainability and evaluation results in educational
contexts. By examining the strengths and limitations of these tools, this
literature review sheds light on the current state of NLP learning tools in
K-12 education. It aims to guide future research efforts to refine existing
tools, develop new ones, and explore more effective and inclusive strategies
for integrating NLP into K-12 educational contexts.",2023-10-02,2023,2023-10,environment
Balancing utility and cognitive cost in social representation,"To successfully navigate its environment, an agent must construct and
maintain representations of the other agents that it encounters. Such
representations are useful for many tasks, but they are not without cost. As a
result, agents must make decisions regarding how much information they choose
to store about the agents in their environment. Using selective social learning
as an example task, we motivate the problem of finding agent representations
that optimally trade off between downstream utility and information cost, and
illustrate two example approaches to resource-constrained social
representation.",2023-10-07,2023,2023-10,environment
Measuring Acoustics with Collaborative Multiple Agents,"As humans, we hear sound every second of our life. The sound we hear is often
affected by the acoustics of the environment surrounding us. For example, a
spacious hall leads to more reverberation. Room Impulse Responses (RIR) are
commonly used to characterize environment acoustics as a function of the scene
geometry, materials, and source/receiver locations. Traditionally, RIRs are
measured by setting up a loudspeaker and microphone in the environment for all
source/receiver locations, which is time-consuming and inefficient. We propose
to let two robots measure the environment's acoustics by actively moving and
emitting/receiving sweep signals. We also devise a collaborative multi-agent
policy where these two robots are trained to explore the environment's
acoustics while being rewarded for wide exploration and accurate prediction. We
show that the robots learn to collaborate and move to explore environment
acoustics while minimizing the prediction error. To the best of our knowledge,
we present the very first problem formulation and solution to the task of
collaborative environment acoustics measurements with multiple agents.",2023-10-09,2023,2023-10,environment
"Advancing Perception in Artificial Intelligence through Principles of
  Cognitive Science","Although artificial intelligence (AI) has achieved many feats at a rapid
pace, there still exist open problems and fundamental shortcomings related to
performance and resource efficiency. Since AI researchers benchmark a
significant proportion of performance standards through human intelligence,
cognitive sciences-inspired AI is a promising domain of research. Studying
cognitive science can provide a fresh perspective to building fundamental
blocks in AI research, which can lead to improved performance and efficiency.
In this review paper, we focus on the cognitive functions of perception, which
is the process of taking signals from one's surroundings as input, and
processing them to understand the environment. Particularly, we study and
compare its various processes through the lens of both cognitive sciences and
AI. Through this study, we review all current major theories from various
sub-disciplines of cognitive science (specifically neuroscience, psychology and
linguistics), and draw parallels with theories and techniques from current
practices in AI. We, hence, present a detailed collection of methods in AI for
researchers to build AI systems inspired by cognitive science. Further, through
the process of reviewing the state of cognitive-inspired AI, we point out many
gaps in the current state of AI (with respect to the performance of the human
brain), and hence present potential directions for researchers to develop
better perception systems in AI.",2023-10-13,2023,2023-10,environment
"Large Language Model Prediction Capabilities: Evidence from a Real-World
  Forecasting Tournament","Accurately predicting the future would be an important milestone in the
capabilities of artificial intelligence. However, research on the ability of
large language models to provide probabilistic predictions about future events
remains nascent. To empirically test this ability, we enrolled OpenAI's
state-of-the-art large language model, GPT-4, in a three-month forecasting
tournament hosted on the Metaculus platform. The tournament, running from July
to October 2023, attracted 843 participants and covered diverse topics
including Big Tech, U.S. politics, viral outbreaks, and the Ukraine conflict.
Focusing on binary forecasts, we show that GPT-4's probabilistic forecasts are
significantly less accurate than the median human-crowd forecasts. We find that
GPT-4's forecasts did not significantly differ from the no-information
forecasting strategy of assigning a 50% probability to every question. We
explore a potential explanation, that GPT-4 might be predisposed to predict
probabilities close to the midpoint of the scale, but our data do not support
this hypothesis. Overall, we find that GPT-4 significantly underperforms in
real-world predictive tasks compared to median human-crowd forecasts. A
potential explanation for this underperformance is that in real-world
forecasting tournaments, the true answers are genuinely unknown at the time of
prediction; unlike in other benchmark tasks like professional exams or time
series forecasting, where strong performance may at least partly be due to the
answers being memorized from the training data. This makes real-world
forecasting tournaments an ideal environment for testing the generalized
reasoning and prediction capabilities of artificial intelligence going forward.",2023-10-17,2023,2023-10,environment
"SegmATRon: Embodied Adaptive Semantic Segmentation for Indoor
  Environment","This paper presents an adaptive transformer model named SegmATRon for
embodied image semantic segmentation. Its distinctive feature is the adaptation
of model weights during inference on several images using a hybrid
multicomponent loss function. We studied this model on datasets collected in
the photorealistic Habitat and the synthetic AI2-THOR Simulators. We showed
that obtaining additional images using the agent's actions in an indoor
environment can improve the quality of semantic segmentation. The code of the
proposed approach and datasets are publicly available at
https://github.com/wingrune/SegmATRon.",2023-10-18,2023,2023-10,environment
"Autonomous 3D Exploration in Large-Scale Environments with Dynamic
  Obstacles","Exploration in dynamic and uncertain real-world environments is an open
problem in robotics and constitutes a foundational capability of autonomous
systems operating in most of the real world. While 3D exploration planning has
been extensively studied, the environments are assumed static or only reactive
collision avoidance is carried out. We propose a novel approach to not only
avoid dynamic obstacles but also include them in the plan itself, to exploit
the dynamic environment in the agent's favor. The proposed planner, Dynamic
Autonomous Exploration Planner (DAEP), extends AEP to explicitly plan with
respect to dynamic obstacles. To thoroughly evaluate exploration planners in
such settings we propose a new enhanced benchmark suite with several dynamic
environments, including large-scale outdoor environments. DAEP outperform
state-of-the-art planners in dynamic and large-scale environments. DAEP is
shown to be more effective at both exploration and collision avoidance.",2023-10-27,2023,2023-10,environment
Arbitrarily Scalable Environment Generators via Neural Cellular Automata,"We study the problem of generating arbitrarily large environments to improve
the throughput of multi-robot systems. Prior work proposes Quality Diversity
(QD) algorithms as an effective method for optimizing the environments of
automated warehouses. However, these approaches optimize only relatively small
environments, falling short when it comes to replicating real-world warehouse
sizes. The challenge arises from the exponential increase in the search space
as the environment size increases. Additionally, the previous methods have only
been tested with up to 350 robots in simulations, while practical warehouses
could host thousands of robots. In this paper, instead of optimizing
environments, we propose to optimize Neural Cellular Automata (NCA) environment
generators via QD algorithms. We train a collection of NCA generators with QD
algorithms in small environments and then generate arbitrarily large
environments from the generators at test time. We show that NCA environment
generators maintain consistent, regularized patterns regardless of environment
size, significantly enhancing the scalability of multi-robot systems in two
different domains with up to 2,350 robots. Additionally, we demonstrate that
our method scales a single-agent reinforcement learning policy to arbitrarily
large environments with similar patterns. We include the source code at
\url{https://github.com/lunjohnzhang/warehouse_env_gen_nca_public}.",2023-10-28,2023,2023-10,environment
"Artificial Intelligence for reverse engineering: application to
  detergents using Raman spectroscopy","The reverse engineering of a complex mixture, regardless of its nature, has
become significant today. Being able to quickly assess the potential toxicity
of new commercial products in relation to the environment presents a genuine
analytical challenge. The development of digital tools (databases,
chemometrics, machine learning, etc.) and analytical techniques (Raman
spectroscopy, NIR spectroscopy, mass spectrometry, etc.) will allow for the
identification of potential toxic molecules. In this article, we use the
example of detergent products, whose composition can prove dangerous to humans
or the environment, necessitating precise identification and quantification for
quality control and regulation purposes. The combination of various digital
tools (spectral database, mixture database, experimental design, Chemometrics /
Machine Learning algorithm{\ldots}) together with different sample preparation
methods (raw sample, or several concentrated / diluted samples) Raman
spectroscopy, has enabled the identification of the mixture's constituents and
an estimation of its composition. Implementing such strategies across different
analytical tools can result in time savings for pollutant identification and
contamination assessment in various matrices. This strategy is also applicable
in the industrial sector for product or raw material control, as well as for
quality control purposes.",2023-10-31,2023,2023-10,environment
"Enhanced Generalization through Prioritization and Diversity in
  Self-Imitation Reinforcement Learning over Procedural Environments with
  Sparse Rewards","Exploration poses a fundamental challenge in Reinforcement Learning (RL) with
sparse rewards, limiting an agent's ability to learn optimal decision-making
due to a lack of informative feedback signals. Self-Imitation Learning
(self-IL) has emerged as a promising approach for exploration, leveraging a
replay buffer to store and reproduce successful behaviors. However, traditional
self-IL methods, which rely on high-return transitions and assume singleton
environments, face challenges in generalization, especially in
procedurally-generated (PCG) environments. Therefore, new self-IL methods have
been proposed to rank which experiences to persist, but they replay transitions
uniformly regardless of their significance, and do not address the diversity of
the stored demonstrations. In this work, we propose tailored self-IL sampling
strategies by prioritizing transitions in different ways and extending
prioritization techniques to PCG environments. We also address diversity loss
through modifications to counteract the impact of generalization requirements
and bias introduced by prioritization techniques. Our experimental analysis,
conducted over three PCG sparse reward environments, including MiniGrid and
ProcGen, highlights the benefits of our proposed modifications, achieving a new
state-of-the-art performance in the MiniGrid-MultiRoom-N12-S10 environment.",2023-11-01,2023,2023-11,environment
"Decoding EEG-based Workload Levels Using Spatio-temporal Features Under
  Flight Environment","The detection of pilots' mental states is important due to the potential for
their abnormal mental states to result in catastrophic accidents. This study
introduces the feasibility of employing deep learning techniques to classify
different workload levels, specifically normal state, low workload, and high
workload. To the best of our knowledge, this study is the first attempt to
classify workload levels of pilots. Our approach involves the hybrid deep
neural network that consists of five convolutional blocks and one long
short-term memory block to extract the significant features from
electroencephalography signals. Ten pilots participated in the experiment,
which was conducted within the simulated flight environment. In contrast to
four conventional models, our proposed model achieved a superior grand--average
accuracy of 0.8613, surpassing other conventional models by at least 0.0597 in
classifying workload levels across all participants. Our model not only
successfully classified workload levels but also provided valuable feedback to
the participants. Hence, we anticipate that our study will make the significant
contributions to the advancement of autonomous flight and driving leveraging
artificial intelligence technology in the future.",2023-11-10,2023,2023-11,environment
"TIAGo RL: Simulated Reinforcement Learning Environments with Tactile
  Data for Mobile Robots","Tactile information is important for robust performance in robotic tasks that
involve physical interaction, such as object manipulation. However, with more
data included in the reasoning and control process, modeling behavior becomes
increasingly difficult. Deep Reinforcement Learning (DRL) produced promising
results for learning complex behavior in various domains, including
tactile-based manipulation in robotics. In this work, we present our
open-source reinforcement learning environments for the TIAGo service robot.
They produce tactile sensor measurements that resemble those of a real
sensorised gripper for TIAGo, encouraging research in transfer learning of DRL
policies. Lastly, we show preliminary training results of a learned force
control policy and compare it to a classical PI controller.",2023-11-13,2023,2023-11,environment
C-Procgen: Empowering Procgen with Controllable Contexts,"We present C-Procgen, an enhanced suite of environments on top of the Procgen
benchmark. C-Procgen provides access to over 200 unique game contexts across 16
games. It allows for detailed configuration of environments, ranging from game
mechanics to agent attributes. This makes the procedural generation process,
previously a black-box in Procgen, more transparent and adaptable for various
research needs.The upgrade enhances dynamic context management and
individualized assignments, while maintaining computational efficiency.
C-Procgen's controllable contexts make it applicable in diverse reinforcement
learning research areas, such as learning dynamics analysis, curriculum
learning, and transfer learning. We believe that C-Procgen will fill a gap in
the current literature and offer a valuable toolkit for future works.",2023-11-13,2023,2023-11,environment
"Redefining the Laparoscopic Spatial Sense: AI-based Intra- and
  Postoperative Measurement from Stereoimages","A significant challenge in image-guided surgery is the accurate measurement
task of relevant structures such as vessel segments, resection margins, or
bowel lengths. While this task is an essential component of many surgeries, it
involves substantial human effort and is prone to inaccuracies. In this paper,
we develop a novel human-AI-based method for laparoscopic measurements
utilizing stereo vision that has been guided by practicing surgeons. Based on a
holistic qualitative requirements analysis, this work proposes a comprehensive
measurement method, which comprises state-of-the-art machine learning
architectures, such as RAFT-Stereo and YOLOv8. The developed method is assessed
in various realistic experimental evaluation environments. Our results outline
the potential of our method achieving high accuracies in distance measurements
with errors below 1 mm. Furthermore, on-surface measurements demonstrate
robustness when applied in challenging environments with textureless regions.
Overall, by addressing the inherent challenges of image-guided surgery, we lay
the foundation for a more robust and accurate solution for intra- and
postoperative measurements, enabling more precise, safe, and efficient surgical
procedures.",2023-11-16,2023,2023-11,environment
Artificial Intelligence in Sustainable Vertical Farming,"As global challenges of population growth, climate change, and resource
scarcity intensify, the agricultural landscape is at a critical juncture.
Sustainable vertical farming emerges as a transformative solution to address
these challenges by maximizing crop yields in controlled environments. This
paradigm shift necessitates the integration of cutting-edge technologies, with
Artificial Intelligence (AI) at the forefront. The paper provides a
comprehensive exploration of the role of AI in sustainable vertical farming,
investigating its potential, challenges, and opportunities. The review
synthesizes the current state of AI applications, encompassing machine
learning, computer vision, the Internet of Things (IoT), and robotics, in
optimizing resource usage, automating tasks, and enhancing decision-making. It
identifies gaps in research, emphasizing the need for optimized AI models,
interdisciplinary collaboration, and the development of explainable AI in
agriculture. The implications extend beyond efficiency gains, considering
economic viability, reduced environmental impact, and increased food security.
The paper concludes by offering insights for stakeholders and suggesting
avenues for future research, aiming to guide the integration of AI technologies
in sustainable vertical farming for a resilient and sustainable future in
agriculture.",2023-11-17,2023,2023-11,environment
"Environment-Aware Dynamic Graph Learning for Out-of-Distribution
  Generalization","Dynamic graph neural networks (DGNNs) are increasingly pervasive in
exploiting spatio-temporal patterns on dynamic graphs. However, existing works
fail to generalize under distribution shifts, which are common in real-world
scenarios. As the generation of dynamic graphs is heavily influenced by latent
environments, investigating their impacts on the out-of-distribution (OOD)
generalization is critical. However, it remains unexplored with the following
two major challenges: (1) How to properly model and infer the complex
environments on dynamic graphs with distribution shifts? (2) How to discover
invariant patterns given inferred spatio-temporal environments? To solve these
challenges, we propose a novel Environment-Aware dynamic Graph LEarning (EAGLE)
framework for OOD generalization by modeling complex coupled environments and
exploiting spatio-temporal invariant patterns. Specifically, we first design
the environment-aware EA-DGNN to model environments by multi-channel
environments disentangling. Then, we propose an environment instantiation
mechanism for environment diversification with inferred distributions. Finally,
we discriminate spatio-temporal invariant patterns for out-of-distribution
prediction by the invariant pattern recognition mechanism and perform
fine-grained causal interventions node-wisely with a mixture of instantiated
environment samples. Experiments on real-world and synthetic dynamic graph
datasets demonstrate the superiority of our method against state-of-the-art
baselines under distribution shifts. To the best of our knowledge, we are the
first to study OOD generalization on dynamic graphs from the environment
learning perspective.",2023-11-18,2023,2023-11,environment
"Synthetic Data Generation for Bridging Sim2Real Gap in a Production
  Environment","Synthetic data is being used lately for training deep neural networks in
computer vision applications such as object detection, object segmentation and
6D object pose estimation. Domain randomization hereby plays an important role
in reducing the simulation to reality gap. However, this generalization might
not be effective in specialized domains like a production environment involving
complex assemblies. Either the individual parts, trained with synthetic images,
are integrated in much larger assemblies making them indistinguishable from
their counterparts and result in false positives or are partially occluded just
enough to give rise to false negatives. Domain knowledge is vital in these
cases and if conceived effectively while generating synthetic data, can show a
considerable improvement in bridging the simulation to reality gap. This paper
focuses on synthetic data generation procedures for parts and assemblies used
in a production environment. The basic procedures for synthetic data generation
and their various combinations are evaluated and compared on images captured in
a production environment, where results show up to 15% improvement using
combinations of basic procedures. Reducing the simulation to reality gap in
this way can aid to utilize the true potential of robot assisted production
using artificial intelligence.",2023-11-18,2023,2023-11,environment
User-Like Bots for Cognitive Automation: A Survey,"Software bots have attracted increasing interest and popularity in both
research and society. Their contributions span automation, digital twins, game
characters with conscious-like behavior, and social media. However, there is
still a lack of intelligent bots that can adapt to web environments'
variability and dynamic nature. Unlike human users, they have difficulty
understanding and exploiting the affordances across multiple virtual
environments.
  Despite the hype, bots with human user-like cognition do not currently exist.
Chatbots, for instance, lack situational awareness on the digital platforms
where they operate, preventing them from enacting meaningful and autonomous
intelligent behavior similar to human users.
  In this survey, we aim to explore the role of cognitive architectures in
supporting efforts towards engineering software bots with advanced general
intelligence. We discuss how cognitive architectures can contribute to creating
intelligent software bots. Furthermore, we highlight key architectural
recommendations for the future development of autonomous, user-like cognitive
bots.",2023-11-20,2023,2023-11,environment
ChatGPT and Beyond: The Generative AI Revolution in Education,"The wide adoption and usage of generative artificial intelligence (AI)
models, particularly ChatGPT, has sparked a surge in research exploring their
potential applications in the educational landscape. This survey examines
academic literature published between November, 2022, and July, 2023,
specifically targeting high-impact research from Scopus-indexed Q1 and Q2
journals. This survey delves into the practical applications and implications
of generative AI models across a diverse range of educational contexts. Through
a comprehensive and rigorous evaluation of recent academic literature, this
survey seeks to illuminate the evolving role of generative AI models,
particularly ChatGPT, in education. By shedding light on the potential
benefits, challenges, and emerging trends in this dynamic field, the survey
endeavors to contribute to the understanding of the nexus between artificial
intelligence and education. The findings of this review will empower educators,
researchers, and policymakers to make informed decisions about the integration
of AI technologies into learning environments.",2023-11-26,2023,2023-11,environment
"Training Reinforcement Learning Agents and Humans With
  Difficulty-Conditioned Generators","We adapt Parameterized Environment Response Model (PERM), a method for
training both Reinforcement Learning (RL) Agents and human learners in
parameterized environments by directly modeling difficulty and ability.
Inspired by Item Response Theory (IRT), PERM aligns environment difficulty with
individual ability, creating a Zone of Proximal Development-based curriculum.
Remarkably, PERM operates without real-time RL updates and allows for offline
training, ensuring its adaptability across diverse students. We present a
two-stage training process that capitalizes on PERM's adaptability, and
demonstrate its effectiveness in training RL agents and humans in an empirical
study.",2023-12-04,2023,2023-12,environment
"Learning Unknown Intervention Targets in Structural Causal Models from
  Heterogeneous Data","We study the problem of identifying the unknown intervention targets in
structural causal models where we have access to heterogeneous data collected
from multiple environments. The unknown intervention targets are the set of
endogenous variables whose corresponding exogenous noises change across the
environments. We propose a two-phase approach which in the first phase recovers
the exogenous noises corresponding to unknown intervention targets whose
distributions have changed across environments. In the second phase, the
recovered noises are matched with the corresponding endogenous variables. For
the recovery phase, we provide sufficient conditions for learning these
exogenous noises up to some component-wise invertible transformation. For the
matching phase, under the causal sufficiency assumption, we show that the
proposed method uniquely identifies the intervention targets. In the presence
of latent confounders, the intervention targets among the observed variables
cannot be determined uniquely. We provide a candidate intervention target set
which is a superset of the true intervention targets. Our approach improves
upon the state of the art as the returned candidate set is always a subset of
the target set returned by previous work. Moreover, we do not require
restrictive assumptions such as linearity of the causal model or performing
invariance tests to learn whether a distribution is changing across
environments which could be highly sample inefficient. Our experimental results
show the effectiveness of our proposed algorithm in practice.",2023-12-11,2023,2023-12,environment
"DVQI: A Multi-task, Hardware-integrated Artificial Intelligence System
  for Automated Visual Inspection in Electronics Manufacturing","As electronics manufacturers continue to face pressure to increase production
efficiency amid difficulties with supply chains and labour shortages, many
printed circuit board assembly (PCBA) manufacturers have begun to invest in
automation and technological innovations to remain competitive. One such method
is to leverage artificial intelligence (AI) to greatly augment existing
manufacturing processes. In this paper, we present the DarwinAI Visual Quality
Inspection (DVQI) system, a hardware-integration artificial intelligence system
for the automated inspection of printed circuit board assembly defects in an
electronics manufacturing environment. The DVQI system enables multi-task
inspection via minimal programming and setup for manufacturing engineers while
improving cycle time relative to manual inspection. We also present a case
study of the deployed DVQI system's performance and impact for a top
electronics manufacturer.",2023-12-14,2023,2023-12,environment
"CERN for AI: A Theoretical Framework for Autonomous Simulation-Based
  Artificial Intelligence Testing and Alignment","This paper explores the potential of a multidisciplinary approach to testing
and aligning artificial intelligence (AI), specifically focusing on large
language models (LLMs). Due to the rapid development and wide application of
LLMs, challenges such as ethical alignment, controllability, and predictability
of these models emerged as global risks. This study investigates an innovative
simulation-based multi-agent system within a virtual reality framework that
replicates the real-world environment. The framework is populated by automated
'digital citizens,' simulating complex social structures and interactions to
examine and optimize AI. Application of various theories from the fields of
sociology, social psychology, computer science, physics, biology, and economics
demonstrates the possibility of a more human-aligned and socially responsible
AI. The purpose of such a digital environment is to provide a dynamic platform
where advanced AI agents can interact and make independent decisions, thereby
mimicking realistic scenarios. The actors in this digital city, operated by the
LLMs, serve as the primary agents, exhibiting high degrees of autonomy. While
this approach shows immense potential, there are notable challenges and
limitations, most significantly the unpredictable nature of real-world social
dynamics. This research endeavors to contribute to the development and
refinement of AI, emphasizing the integration of social, ethical, and
theoretical dimensions for future research.",2023-12-14,2023,2023-12,environment
"The Animal-AI Environment: A Virtual Laboratory For Comparative
  Cognition and Artificial Intelligence Research","The Animal-AI Environment is a unique game-based research platform designed
to facilitate collaboration between the artificial intelligence and comparative
cognition research communities. In this paper, we present the latest version of
the Animal-AI Environment, outlining several major features that make the game
more engaging for humans and more complex for AI systems. These features
include interactive buttons, reward dispensers, and player notifications, as
well as an overhaul of the environment's graphics and processing for
significant improvements in agent training time and quality of the human player
experience. We provide detailed guidance on how to build computational and
behavioural experiments with the Animal-AI Environment. We present results from
a series of agents, including the state-of-the-art deep reinforcement learning
agent Dreamer-v3, on newly designed tests and the Animal-AI Testbed of 900
tasks inspired by research in the field of comparative cognition. The Animal-AI
Environment offers a new approach for modelling cognition in humans and
non-human animals, and for building biologically inspired artificial
intelligence.",2023-12-18,2023,2023-12,environment
Human-Machine Teaming for UAVs: An Experimentation Platform,"Full automation is often not achievable or desirable in critical systems with
high-stakes decisions. Instead, human-AI teams can achieve better results. To
research, develop, evaluate, and validate algorithms suited for such teaming,
lightweight experimentation platforms that enable interactions between humans
and multiple AI agents are necessary. However, there are limited examples of
such platforms for defense environments. To address this gap, we present the
Cogment human-machine teaming experimentation platform, which implements
human-machine teaming (HMT) use cases that features heterogeneous multi-agent
systems and can involve learning AI agents, static AI agents, and humans. It is
built on the Cogment platform and has been used for academic research,
including work presented at the ALA workshop at AAMAS this year [1]. With this
platform, we hope to facilitate further research on human-machine teaming in
critical systems and defense environments.",2023-12-18,2023,2023-12,environment
Understanding and Estimating Domain Complexity Across Domains,"Artificial Intelligence (AI) systems, trained in controlled environments,
often struggle in real-world complexities. We propose a general framework for
estimating domain complexity across diverse environments, like open-world
learning and real-world applications. This framework distinguishes between
intrinsic complexity (inherent to the domain) and extrinsic complexity
(dependent on the AI agent). By analyzing dimensionality, sparsity, and
diversity within these categories, we offer a comprehensive view of domain
challenges. This approach enables quantitative predictions of AI difficulty
during environment transitions, avoids bias in novel situations, and helps
navigate the vast search spaces of open-world domains.",2023-12-20,2023,2023-12,environment
"A Conservative Approach for Few-Shot Transfer in Off-Dynamics
  Reinforcement Learning","Off-dynamics Reinforcement Learning (ODRL) seeks to transfer a policy from a
source environment to a target environment characterized by distinct yet
similar dynamics. In this context, traditional RL agents depend excessively on
the dynamics of the source environment, resulting in the discovery of policies
that excel in this environment but fail to provide reasonable performance in
the target one. In the few-shot framework, a limited number of transitions from
the target environment are introduced to facilitate a more effective transfer.
Addressing this challenge, we propose an innovative approach inspired by recent
advancements in Imitation Learning and conservative RL algorithms. The proposed
method introduces a penalty to regulate the trajectories generated by the
source-trained policy. We evaluate our method across various environments
representing diverse off-dynamics conditions, where access to the target
environment is extremely limited. These experiments include high-dimensional
systems relevant to real-world applications. Across most tested scenarios, our
proposed method demonstrates performance improvements compared to existing
baselines.",2023-12-24,2023,2023-12,environment
Autonomous Navigation in Complex Environments,"This paper explores the application of CNN-DNN network fusion to construct a
robot navigation controller within a simulated environment. The simulated
environment is constructed to model a subterranean rescue situation, such that
an autonomous agent is tasked with finding a goal within an unknown cavernous
system. Imitation learning is used to train the control algorithm to use LiDAR
and camera data to navigate the space and find the goal. The trained model is
then tested for robustness using Monte-Carlo.",2024-01-06,2024,2024-01,environment
"Transcending Controlled Environments Assessing the Transferability of
  ASRRobust NLU Models to Real-World Applications","This research investigates the transferability of Automatic Speech
Recognition (ASR)-robust Natural Language Understanding (NLU) models from
controlled experimental conditions to practical, real-world applications.
Focused on smart home automation commands in Urdu, the study assesses model
performance under diverse noise profiles, linguistic variations, and ASR error
scenarios. Leveraging the UrduBERT model, the research employs a systematic
methodology involving real-world data collection, cross-validation, transfer
learning, noise variation studies, and domain adaptation. Evaluation metrics
encompass task-specific accuracy, latency, user satisfaction, and robustness to
ASR errors. The findings contribute insights into the challenges and
adaptability of ASR-robust NLU models in transcending controlled environments.",2024-01-12,2024,2024-01,environment
"Training program on sign language: social inclusion through Virtual
  Reality in ISENSE project","Structured hand gestures that incorporate visual motions and signs are used
in sign language. Sign language is a valuable means of daily communication for
individuals who are deaf or have speech impairments, but it is still rare among
hearing people, and fewer are capable of understand it. Within the academic
context, parents and teachers play a crucial role in supporting deaf students
from childhood by facilitating their learning of sign language. In the last
years, among all the teaching tools useful for learning sign language, the use
of Virtual Reality (VR) has increased, as it has been demonstrated to improve
retention, memory and attention during the learning process. The ISENSE project
has been created to assist students with deafness during their academic life by
proposing different technological tools for teaching sign language to the
hearing community in the academic context. As part of the ISENSE project, this
work aims to develop an application for Spanish and Italian sign language
recognition that exploits the VR environment to quickly and easily create a
comprehensive database of signs and an Artificial Intelligence (AI)-based
software to accurately classify and recognize static and dynamic signs: from
letters to sentences.",2024-01-15,2024,2024-01,environment
"On the Interplay of Artificial Intelligence and Space-Air-Ground
  Integrated Networks: A Survey","Space-Air-Ground Integrated Networks (SAGINs), which incorporate space and
aerial networks with terrestrial wireless systems, are vital enablers of the
emerging sixth-generation (6G) wireless networks. Besides bringing significant
benefits to various applications and services, SAGINs are envisioned to extend
high-speed broadband coverage to remote areas, such as small towns or mining
sites, or areas where terrestrial infrastructure cannot reach, such as
airplanes or maritime use cases. However, due to the limited power and storage
resources, as well as other constraints introduced by the design of terrestrial
networks, SAGINs must be intelligently configured and controlled to satisfy the
envisioned requirements. Meanwhile, Artificial Intelligence (AI) is another
critical enabler of 6G. Due to massive amounts of available data, AI has been
leveraged to address pressing challenges of current and future wireless
networks. By adding AI and facilitating the decision-making and prediction
procedures, SAGINs can effectively adapt to their surrounding environment, thus
enhancing the performance of various metrics. In this work, we aim to
investigate the interplay of AI and SAGINs by providing a holistic overview of
state-of-the-art research in AI-enabled SAGINs. Specifically, we present a
comprehensive overview of some potential applications of AI in SAGINs. We also
cover open issues in employing AI and detail the contributions of SAGINs in the
development of AI. Finally, we highlight some limitations of the existing
research works and outline potential future research directions.",2024-01-20,2024,2024-01,environment
"Deep Learning Based Simulators for the Phosphorus Removal Process
  Control in Wastewater Treatment via Deep Reinforcement Learning Algorithms","Phosphorus removal is vital in wastewater treatment to reduce reliance on
limited resources. Deep reinforcement learning (DRL) is a machine learning
technique that can optimize complex and nonlinear systems, including the
processes in wastewater treatment plants, by learning control policies through
trial and error. However, applying DRL to chemical and biological processes is
challenging due to the need for accurate simulators. This study trained six
models to identify the phosphorus removal process and used them to create a
simulator for the DRL environment. Although the models achieved high accuracy
(>97%), uncertainty and incorrect prediction behavior limited their performance
as simulators over longer horizons. Compounding errors in the models'
predictions were identified as one of the causes of this problem. This approach
for improving process control involves creating simulation environments for DRL
algorithms, using data from supervisory control and data acquisition (SCADA)
systems with a sufficient historical horizon without complex system modeling or
parameter estimation.",2024-01-23,2024,2024-01,environment
Dynamic Long-Term Time-Series Forecasting via Meta Transformer Networks,"A reliable long-term time-series forecaster is highly demanded in practice
but comes across many challenges such as low computational and memory
footprints as well as robustness against dynamic learning environments. This
paper proposes Meta-Transformer Networks (MANTRA) to deal with the dynamic
long-term time-series forecasting tasks. MANTRA relies on the concept of fast
and slow learners where a collection of fast learners learns different aspects
of data distributions while adapting quickly to changes. A slow learner tailors
suitable representations to fast learners. Fast adaptations to dynamic
environments are achieved using the universal representation transformer layers
producing task-adapted representations with a small number of parameters. Our
experiments using four datasets with different prediction lengths demonstrate
the advantage of our approach with at least $3\%$ improvements over the
baseline algorithms for both multivariate and univariate settings. Source codes
of MANTRA are publicly available in
\url{https://github.com/anwarmaxsum/MANTRA}.",2024-01-25,2024,2024-01,environment
"Multi-Agent Coordination for a Partially Observable and Dynamic Robot
  Soccer Environment with Limited Communication","RoboCup represents an International testbed for advancing research in AI and
robotics, focusing on a definite goal: developing a robot team that can win
against the human world soccer champion team by the year 2050. To achieve this
goal, autonomous humanoid robots' coordination is crucial. This paper explores
novel solutions within the RoboCup Standard Platform League (SPL), where a
reduction in WiFi communication is imperative, leading to the development of
new coordination paradigms. The SPL has experienced a substantial decrease in
network packet rate, compelling the need for advanced coordination
architectures to maintain optimal team functionality in dynamic environments.
Inspired by market-based task assignment, we introduce a novel distributed
coordination system to orchestrate autonomous robots' actions efficiently in
low communication scenarios. This approach has been tested with NAO robots
during official RoboCup competitions and in the SimRobot simulator,
demonstrating a notable reduction in task overlaps in limited communication
settings.",2024-01-26,2024,2024-01,environment
"Synthetic Multimodal Dataset for Empowering Safety and Well-being in
  Home Environments","This paper presents a synthetic multimodal dataset of daily activities that
fuses video data from a 3D virtual space simulator with knowledge graphs
depicting the spatiotemporal context of the activities. The dataset is
developed for the Knowledge Graph Reasoning Challenge for Social Issues
(KGRC4SI), which focuses on identifying and addressing hazardous situations in
the home environment. The dataset is available to the public as a valuable
resource for researchers and practitioners developing innovative solutions
recognizing human behaviors to enhance safety and well-being in",2024-01-26,2024,2024-01,environment
"""What's my model inside of?"": Exploring the role of environments for
  grounded natural language understanding","In contrast to classical cognitive science which studied brains in isolation,
ecological approaches focused on the role of the body and environment in
shaping cognition. Similarly, in this thesis we adopt an ecological approach to
grounded natural language understanding (NLU) research. Grounded language
understanding studies language understanding systems situated in the context of
events, actions and precepts in naturalistic/simulated virtual environments.
Where classic research tends to focus on designing new models and optimization
methods while treating environments as given, we explore the potential of
environment design for improving data collection and model development. We
developed novel training and annotation approaches for procedural text
understanding based on text-based game environments. We also drew upon embodied
cognitive linguistics literature to propose a roadmap for grounded NLP
research, and to inform the development of a new benchmark for measuring the
progress of large language models on challenging commonsense reasoning tasks.
We leveraged the richer supervision provided by text-based game environments to
develop Breakpoint Transformers, a novel approach to modeling intermediate
semantic information in long narrative or procedural texts. Finally, we
integrated theories on the role of environments in collective human
intelligence to propose a design for AI-augmented ""social thinking
environments"" for knowledge workers like scientists.",2024-02-04,2024,2024-02,environment
"Understanding What Affects the Generalization Gap in Visual
  Reinforcement Learning: Theory and Empirical Evidence","Recently, there are many efforts attempting to learn useful policies for
continuous control in visual reinforcement learning (RL). In this scenario, it
is important to learn a generalizable policy, as the testing environment may
differ from the training environment, e.g., there exist distractors during
deployment. Many practical algorithms are proposed to handle this problem.
However, to the best of our knowledge, none of them provide a theoretical
understanding of what affects the generalization gap and why their proposed
methods work. In this paper, we bridge this issue by theoretically answering
the key factors that contribute to the generalization gap when the testing
environment has distractors. Our theories indicate that minimizing the
representation distance between training and testing environments, which aligns
with human intuition, is the most critical for the benefit of reducing the
generalization gap. Our theoretical results are supported by the empirical
evidence in the DMControl Generalization Benchmark (DMC-GB).",2024-02-05,2024,2024-02,environment
"Game Agent Driven by Free-Form Text Command: Using LLM-based Code
  Generation and Behavior Branch","Several attempts have been made to implement text command control for game
agents. However, current technologies are limited to processing predefined
format commands. This paper proposes a pioneering text command control system
for a game agent that can understand natural language commands expressed in
free-form. The proposed system uses a large language model (LLM) for code
generation to interpret and transform natural language commands into behavior
branch, a proposed knowledge expression based on behavior trees, which
facilitates execution by the game agent. This study conducted empirical
validation within a game environment that simulates a Pok\'emon game and
involved multiple participants. The results confirmed the system's ability to
understand and carry out natural language commands, representing a noteworthy
in the realm of real-time language interactive game agents.
  Notice for the use of this material. The copyright of this material is
retained by the Japanese Society for Artificial Intelligence (JSAI). This
material is published here with the agreement of JSAI. Please be complied with
Copyright Law of Japan if any users wish to reproduce, make derivative work,
distribute or make available to the public any part or whole thereof. All
Rights Reserved, Copyright (C) The Japanese Society for Artificial
Intelligence.",2024-02-12,2024,2024-02,environment
"FGeo-DRL: Deductive Reasoning for Geometric Problems through Deep
  Reinforcement Learning","The human-like automatic deductive reasoning has always been one of the most
challenging open problems in the interdiscipline of mathematics and artificial
intelligence. This paper is the third in a series of our works. We built a
neural-symbolic system, called FGeoDRL, to automatically perform human-like
geometric deductive reasoning. The neural part is an AI agent based on
reinforcement learning, capable of autonomously learning problem-solving
methods from the feedback of a formalized environment, without the need for
human supervision. It leverages a pre-trained natural language model to
establish a policy network for theorem selection and employ Monte Carlo Tree
Search for heuristic exploration. The symbolic part is a reinforcement learning
environment based on geometry formalization theory and FormalGeo, which models
GPS as a Markov Decision Process. In this formal symbolic system, the known
conditions and objectives of the problem form the state space, while the set of
theorems forms the action space. Leveraging FGeoDRL, we have achieved readable
and verifiable automated solutions to geometric problems. Experiments conducted
on the formalgeo7k dataset have achieved a problem-solving success rate of
86.40%. The project is available at https://github.com/PersonNoName/FGeoDRL.",2024-02-14,2024,2024-02,environment
"From Cloud to Edge: Rethinking Generative AI for Low-Resource Design
  Challenges","Generative Artificial Intelligence (AI) has shown tremendous prospects in all
aspects of technology, including design. However, due to its heavy demand on
resources, it is usually trained on large computing infrastructure and often
made available as a cloud-based service. In this position paper, we consider
the potential, challenges, and promising approaches for generative AI for
design on the edge, i.e., in resource-constrained settings where memory,
compute, energy (battery) and network connectivity may be limited. Adapting
generative AI for such settings involves overcoming significant hurdles,
primarily in how to streamline complex models to function efficiently in
low-resource environments. This necessitates innovative approaches in model
compression, efficient algorithmic design, and perhaps even leveraging edge
computing. The objective is to harness the power of generative AI in creating
bespoke solutions for design problems, such as medical interventions, farm
equipment maintenance, and educational material design, tailored to the unique
constraints and needs of remote areas. These efforts could democratize access
to advanced technology and foster sustainable development, ensuring universal
accessibility and environmental consideration of AI-driven design benefits.",2024-02-20,2024,2024-02,environment
"Virtual Reality for Understanding Artificial-Intelligence-driven
  Scientific Discovery with an Application in Quantum Optics","Generative Artificial Intelligence (AI) models can propose solutions to
scientific problems beyond human capability. To truly make conceptual
contributions, researchers need to be capable of understanding the AI-generated
structures and extracting the underlying concepts and ideas. When algorithms
provide little explanatory reasoning alongside the output, scientists have to
reverse-engineer the fundamental insights behind proposals based solely on
examples. This task can be challenging as the output is often highly complex
and thus not immediately accessible to humans. In this work we show how
transferring part of the analysis process into an immersive Virtual Reality
(VR) environment can assist researchers in developing an understanding of
AI-generated solutions. We demonstrate the usefulness of VR in finding
interpretable configurations of abstract graphs, representing Quantum Optics
experiments. Thereby, we can manually discover new generalizations of
AI-discoveries as well as new understanding in experimental quantum optics.
Furthermore, it allows us to customize the search space in an informed way - as
a human-in-the-loop - to achieve significantly faster subsequent discovery
iterations. As concrete examples, with this technology, we discover a new
resource-efficient 3-dimensional entanglement swapping scheme, as well as a
3-dimensional 4-particle Greenberger-Horne-Zeilinger-state analyzer. Our
results show the potential of VR for increasing a human researcher's ability to
derive knowledge from graph-based generative AI that, which is a common
abstract data representation used in diverse fields of science.",2024-02-20,2024,2024-02,environment
Social Environment Design,"Artificial Intelligence (AI) holds promise as a technology that can be used
to improve government and economic policy-making. This paper proposes a new
research agenda towards this end by introducing Social Environment Design, a
general framework for the use of AI for automated policy-making that connects
with the Reinforcement Learning, EconCS, and Computational Social Choice
communities. The framework seeks to capture general economic environments,
includes voting on policy objectives, and gives a direction for the systematic
analysis of government and economic policy through AI simulation. We highlight
key open problems for future research in AI-based policy-making. By solving
these challenges, we hope to achieve various social welfare objectives, thereby
promoting more ethical and responsible decision making.",2024-02-21,2024,2024-02,environment
Vision-Language Navigation with Embodied Intelligence: A Survey,"As a long-term vision in the field of artificial intelligence, the core goal
of embodied intelligence is to improve the perception, understanding, and
interaction capabilities of agents and the environment. Vision-language
navigation (VLN), as a critical research path to achieve embodied intelligence,
focuses on exploring how agents use natural language to communicate effectively
with humans, receive and understand instructions, and ultimately rely on visual
information to achieve accurate navigation. VLN integrates artificial
intelligence, natural language processing, computer vision, and robotics. This
field faces technical challenges but shows potential for application such as
human-computer interaction. However, due to the complex process involved from
language understanding to action execution, VLN faces the problem of aligning
visual information and language instructions, improving generalization ability,
and many other challenges. This survey systematically reviews the research
progress of VLN and details the research direction of VLN with embodied
intelligence. After a detailed summary of its system architecture and research
based on methods and commonly used benchmark datasets, we comprehensively
analyze the problems and challenges faced by current research and explore the
future development direction of this field, aiming to provide a practical
reference for researchers.",2024-02-22,2024,2024-02,environment
"Artificial Intelligence for Complex Network: Potential, Methodology and
  Application","Complex networks pervade various real-world systems, from the natural
environment to human societies. The essence of these networks is in their
ability to transition and evolve from microscopic disorder-where network
topology and node dynamics intertwine-to a macroscopic order characterized by
certain collective behaviors. Over the past two decades, complex network
science has significantly enhanced our understanding of the statistical
mechanics, structures, and dynamics underlying real-world networks. Despite
these advancements, there remain considerable challenges in exploring more
realistic systems and enhancing practical applications. The emergence of
artificial intelligence (AI) technologies, coupled with the abundance of
diverse real-world network data, has heralded a new era in complex network
science research. This survey aims to systematically address the potential
advantages of AI in overcoming the lingering challenges of complex network
research. It endeavors to summarize the pivotal research problems and provide
an exhaustive review of the corresponding methodologies and applications.
Through this comprehensive survey-the first of its kind on AI for complex
networks-we expect to provide valuable insights that will drive further
research and advancement in this interdisciplinary field.",2024-02-23,2024,2024-02,environment
Brain-inspired and Self-based Artificial Intelligence,"The question ""Can machines think?"" and the Turing Test to assess whether
machines could achieve human-level intelligence is one of the roots of AI. With
the philosophical argument ""I think, therefore I am"", this paper challenge the
idea of a ""thinking machine"" supported by current AIs since there is no sense
of self in them. Current artificial intelligence is only seemingly intelligent
information processing and does not truly understand or be subjectively aware
of oneself and perceive the world with the self as human intelligence does. In
this paper, we introduce a Brain-inspired and Self-based Artificial
Intelligence (BriSe AI) paradigm. This BriSe AI paradigm is dedicated to
coordinating various cognitive functions and learning strategies in a
self-organized manner to build human-level AI models and robotic applications.
Specifically, BriSe AI emphasizes the crucial role of the Self in shaping the
future AI, rooted with a practical hierarchical Self framework, including
Perception and Learning, Bodily Self, Autonomous Self, Social Self, and
Conceptual Self. The hierarchical framework of the Self highlights self-based
environment perception, self-bodily modeling, autonomous interaction with the
environment, social interaction and collaboration with others, and even more
abstract understanding of the Self. Furthermore, the positive mutual promotion
and support among multiple levels of Self, as well as between Self and
learning, enhance the BriSe AI's conscious understanding of information and
flexible adaptation to complex environments, serving as a driving force
propelling BriSe AI towards real Artificial General Intelligence.",2024-02-29,2024,2024-02,environment
"Mathematics of multi-agent learning systems at the interface of game
  theory and artificial intelligence","Evolutionary Game Theory (EGT) and Artificial Intelligence (AI) are two
fields that, at first glance, might seem distinct, but they have notable
connections and intersections. The former focuses on the evolution of behaviors
(or strategies) in a population, where individuals interact with others and
update their strategies based on imitation (or social learning). The more
successful a strategy is, the more prevalent it becomes over time. The latter,
meanwhile, is centered on machine learning algorithms and (deep) neural
networks. It is often from a single-agent perspective but increasingly involves
multi-agent environments, in which intelligent agents adjust their strategies
based on feedback and experience, somewhat akin to the evolutionary process yet
distinct in their self-learning capacities. In light of the key components
necessary to address real-world problems, including (i) learning and
adaptation, (ii) cooperation and competition, (iii) robustness and stability,
and altogether (iv) population dynamics of individual agents whose strategies
evolve, the cross-fertilization of ideas between both fields will contribute to
the advancement of mathematics of multi-agent learning systems, in particular,
to the nascent domain of ``collective cooperative intelligence'' bridging
evolutionary dynamics and multi-agent reinforcement learning.",2024-03-09,2024,2024-03,environment
"Do Agents Dream of Electric Sheep?: Improving Generalization in
  Reinforcement Learning through Generative Learning","The Overfitted Brain hypothesis suggests dreams happen to allow
generalization in the human brain. Here, we ask if the same is true for
reinforcement learning agents as well. Given limited experience in a real
environment, we use imagination-based reinforcement learning to train a policy
on dream-like episodes, where non-imaginative, predicted trajectories are
modified through generative augmentations. Experiments on four ProcGen
environments show that, compared to classic imagination and offline training on
collected experience, our method can reach a higher level of generalization
when dealing with sparsely rewarded environments.",2024-03-12,2024,2024-03,environment
"Can LLM-Augmented autonomous agents cooperate?, An evaluation of their
  cooperative capabilities through Melting Pot","As the field of AI continues to evolve, a significant dimension of this
progression is the development of Large Language Models and their potential to
enhance multi-agent artificial intelligence systems. This paper explores the
cooperative capabilities of Large Language Model-augmented Autonomous Agents
(LAAs) using the well-known Meltin Pot environments along with reference models
such as GPT4 and GPT3.5. Preliminary results suggest that while these agents
demonstrate a propensity for cooperation, they still struggle with effective
collaboration in given environments, emphasizing the need for more robust
architectures. The study's contributions include an abstraction layer to adapt
Melting Pot game scenarios for LLMs, the implementation of a reusable
architecture for LLM-mediated agent development - which includes short and
long-term memories and different cognitive modules, and the evaluation of
cooperation capabilities using a set of metrics tied to the Melting Pot's
""Commons Harvest"" game. The paper closes, by discussing the limitations of the
current architectural framework and the potential of a new set of modules that
fosters better cooperation among LAAs.",2024-03-18,2024,2024-03,environment
"BlendScape: Enabling End-User Customization of Video-Conferencing
  Environments through Generative AI","Today's video-conferencing tools support a rich range of professional and
social activities, but their generic meeting environments cannot be dynamically
adapted to align with distributed collaborators' needs. To enable end-user
customization, we developed BlendScape, a rendering and composition system for
video-conferencing participants to tailor environments to their meeting context
by leveraging AI image generation techniques. BlendScape supports flexible
representations of task spaces by blending users' physical or digital
backgrounds into unified environments and implements multimodal interaction
techniques to steer the generation. Through an exploratory study with 15
end-users, we investigated whether and how they would find value in using
generative AI to customize video-conferencing environments. Participants
envisioned using a system like BlendScape to facilitate collaborative
activities in the future, but required further controls to mitigate distracting
or unrealistic visual elements. We implemented scenarios to demonstrate
BlendScape's expressiveness for supporting environment design strategies from
prior work and propose composition techniques to improve the quality of
environments.",2024-03-20,2024,2024-03,environment
SymboSLAM: Semantic Map Generation in a Multi-Agent System,"Sub-symbolic artificial intelligence methods dominate the fields of
environment-type classification and Simultaneous Localisation and Mapping.
However, a significant area overlooked within these fields is solution
transparency for the human-machine interaction space, as the sub-symbolic
methods employed for map generation do not account for the explainability of
the solutions generated. This paper proposes a novel approach to
environment-type classification through Symbolic Simultaneous Localisation and
Mapping, SymboSLAM, to bridge the explainability gap. Our method for
environment-type classification observes ontological reasoning used to
synthesise the context of an environment through the features found within. We
achieve explainability within the model by presenting operators with
environment-type classifications overlayed by a semantically labelled occupancy
map of landmarks and features. We evaluate SymboSLAM with ground-truth maps of
the Canberra region, demonstrating method effectiveness. We assessed the system
through both simulations and real-world trials.",2024-03-22,2024,2024-03,environment
"Collaborative AI Teaming in Unknown Environments via Active Goal
  Deduction","With the advancements of artificial intelligence (AI), we're seeing more
scenarios that require AI to work closely with other agents, whose goals and
strategies might not be known beforehand. However, existing approaches for
training collaborative agents often require defined and known reward signals
and cannot address the problem of teaming with unknown agents that often have
latent objectives/rewards. In response to this challenge, we propose teaming
with unknown agents framework, which leverages kernel density Bayesian inverse
learning method for active goal deduction and utilizes pre-trained,
goal-conditioned policies to enable zero-shot policy adaptation. We prove that
unbiased reward estimates in our framework are sufficient for optimal teaming
with unknown agents. We further evaluate the framework of redesigned
multi-agent particle and StarCraft II micromanagement environments with diverse
unknown agents of different behaviors/rewards. Empirical results demonstrate
that our framework significantly advances the teaming performance of AI and
unknown agents in a wide range of collaborative scenarios.",2024-03-22,2024,2024-03,environment
The Pursuit of Fairness in Artificial Intelligence Models: A Survey,"Artificial Intelligence (AI) models are now being utilized in all facets of
our lives such as healthcare, education and employment. Since they are used in
numerous sensitive environments and make decisions that can be life altering,
potential biased outcomes are a pressing matter. Developers should ensure that
such models don't manifest any unexpected discriminatory practices like
partiality for certain genders, ethnicities or disabled people. With the
ubiquitous dissemination of AI systems, researchers and practitioners are
becoming more aware of unfair models and are bound to mitigate bias in them.
Significant research has been conducted in addressing such issues to ensure
models don't intentionally or unintentionally perpetuate bias. This survey
offers a synopsis of the different ways researchers have promoted fairness in
AI systems. We explore the different definitions of fairness existing in the
current literature. We create a comprehensive taxonomy by categorizing
different types of bias and investigate cases of biased AI in different
application domains. A thorough study is conducted of the approaches and
techniques employed by researchers to mitigate bias in AI models. Moreover, we
also delve into the impact of biased models on user experience and the ethical
considerations to contemplate when developing and deploying such models. We
hope this survey helps researchers and practitioners understand the intricate
details of fairness and bias in AI systems. By sharing this thorough survey, we
aim to promote additional discourse in the domain of equitable and responsible
AI.",2024-03-26,2024,2024-03,environment
"From Two-Dimensional to Three-Dimensional Environment with Q-Learning:
  Modeling Autonomous Navigation with Reinforcement Learning and no Libraries","Reinforcement learning (RL) algorithms have become indispensable tools in
artificial intelligence, empowering agents to acquire optimal decision-making
policies through interactions with their environment and feedback mechanisms.
This study explores the performance of RL agents in both two-dimensional (2D)
and three-dimensional (3D) environments, aiming to research the dynamics of
learning across different spatial dimensions. A key aspect of this
investigation is the absence of pre-made libraries for learning, with the
algorithm developed exclusively through computational mathematics. The
methodological framework centers on RL principles, employing a Q-learning agent
class and distinct environment classes tailored to each spatial dimension. The
research aims to address the question: How do reinforcement learning agents
adapt and perform in environments of varying spatial dimensions, particularly
in 2D and 3D settings? Through empirical analysis, the study evaluates agents'
learning trajectories and adaptation processes, revealing insights into the
efficacy of RL algorithms in navigating complex, multi-dimensional spaces.
Reflections on the findings prompt considerations for future research,
particularly in understanding the dynamics of learning in higher-dimensional
environments.",2024-03-27,2024,2024-03,environment
Dynamic Quality-Diversity Search,"Evolutionary search via the quality-diversity (QD) paradigm can discover
highly performing solutions in different behavioural niches, showing
considerable potential in complex real-world scenarios such as evolutionary
robotics. Yet most QD methods only tackle static tasks that are fixed over
time, which is rarely the case in the real world. Unlike noisy environments,
where the fitness of an individual changes slightly at every evaluation,
dynamic environments simulate tasks where external factors at unknown and
irregular intervals alter the performance of the individual with a severity
that is unknown a priori. Literature on optimisation in dynamic environments is
extensive, yet such environments have not been explored in the context of QD
search. This paper introduces a novel and generalisable Dynamic QD methodology
that aims to keep the archive of past solutions updated in the case of
environment changes. Secondly, we present a novel characterisation of dynamic
environments that can be easily applied to well-known benchmarks, with minor
interventions to move them from a static task to a dynamic one. Our Dynamic QD
intervention is applied on MAP-Elites and CMA-ME, two powerful QD algorithms,
and we test the dynamic variants on different dynamic tasks.",2024-04-07,2024,2024-04,environment
"The Transformation Risk-Benefit Model of Artificial Intelligence:
  Balancing Risks and Benefits Through Practical Solutions and Use Cases","This paper summarizes the most cogent advantages and risks associated with
Artificial Intelligence from an in-depth review of the literature. Then the
authors synthesize the salient risk-related models currently being used in AI,
technology and business-related scenarios. Next, in view of an updated context
of AI along with theories and models reviewed and expanded constructs, the
writers propose a new framework called ""The Transformation Risk-Benefit Model
of Artificial Intelligence"" to address the increasing fears and levels of AI
risk. Using the model characteristics, the article emphasizes practical and
innovative solutions where benefits outweigh risks and three use cases in
healthcare, climate change/environment and cyber security to illustrate unique
interplay of principles, dimensions and processes of this powerful AI
transformational model.",2024-04-11,2024,2024-04,environment
Multi-Agent eXperimenter (MAX),"We present a novel multi-agent simulator named Multi-Agent eXperimenter (MAX)
that is designed to simulate blockchain experiments involving large numbers of
agents of different types acting in one or several environments. The
architecture of MAX is highly modular, enabling easy addition of new models.",2024-04-12,2024,2024-04,environment
"Synergising Human-like Responses and Machine Intelligence for Planning
  in Disaster Response","In the rapidly changing environments of disaster response, planning and
decision-making for autonomous agents involve complex and interdependent
choices. Although recent advancements have improved traditional artificial
intelligence (AI) approaches, they often struggle in such settings,
particularly when applied to agents operating outside their well-defined
training parameters. To address these challenges, we propose an attention-based
cognitive architecture inspired by Dual Process Theory (DPT). This framework
integrates, in an online fashion, rapid yet heuristic (human-like) responses
(System 1) with the slow but optimized planning capabilities of machine
intelligence (System 2). We illustrate how a supervisory controller can
dynamically determine in real-time the engagement of either system to optimize
mission objectives by assessing their performance across a number of distinct
attributes. Evaluated for trajectory planning in dynamic environments, our
framework demonstrates that this synergistic integration effectively manages
complex tasks by optimizing multiple mission objectives.",2024-04-15,2024,2024-04,environment
"A Note on Loss Functions and Error Compounding in Model-based
  Reinforcement Learning","This note clarifies some confusions (and perhaps throws out more) around
model-based reinforcement learning and their theoretical understanding in the
context of deep RL. Main topics of discussion are (1) how to reconcile
model-based RL's bad empirical reputation on error compounding with its
superior theoretical properties, and (2) the limitations of empirically popular
losses. For the latter, concrete counterexamples for the ""MuZero loss"" are
constructed to show that it not only fails in stochastic environments, but also
suffers exponential sample complexity in deterministic environments when data
provides sufficient coverage.",2024-04-15,2024,2024-04,environment
"What is Meant by AGI? On the Definition of Artificial General
  Intelligence","This paper aims to establish a consensus on AGI's definition. General
intelligence refers to the adaptation to open environments according to certain
principles using limited resources. It emphasizes that adaptation or learning
is an indispensable property of intelligence, and places the controversial part
within the principles of intelligence, which can be described from different
perspectives.",2024-04-16,2024,2024-04,environment
Sustainability of Data Center Digital Twins with Reinforcement Learning,"The rapid growth of machine learning (ML) has led to an increased demand for
computational power, resulting in larger data centers (DCs) and higher energy
consumption. To address this issue and reduce carbon emissions, intelligent
design and control of DC components such as IT servers, cabinets, HVAC cooling,
flexible load shifting, and battery energy storage are essential. However, the
complexity of designing and controlling them in tandem presents a significant
challenge. While some individual components like CFD-based design and
Reinforcement Learning (RL) based HVAC control have been researched, there's a
gap in the holistic design and optimization covering all elements
simultaneously. To tackle this, we've developed DCRL-Green, a multi-agent RL
environment that empowers the ML community to design data centers and research,
develop, and refine RL controllers for carbon footprint reduction in DCs. It is
a flexible, modular, scalable, and configurable platform that can handle large
High Performance Computing (HPC) clusters. Furthermore, in its default setup,
DCRL-Green provides a benchmark for evaluating single as well as multi-agent RL
algorithms. It easily allows users to subclass the default implementations and
design their own control approaches, encouraging community development for
sustainable data centers. Open Source Link:
https://github.com/HewlettPackard/dc-rl",2024-04-16,2024,2024-04,environment
"Explaining AI Decisions: Towards Achieving Human-Centered Explainability
  in Smart Home Environments","Smart home systems are gaining popularity as homeowners strive to enhance
their living and working environments while minimizing energy consumption.
However, the adoption of artificial intelligence (AI)-enabled decision-making
models in smart home systems faces challenges due to the complexity and
black-box nature of these systems, leading to concerns about explainability,
trust, transparency, accountability, and fairness. The emerging field of
explainable artificial intelligence (XAI) addresses these issues by providing
explanations for the models' decisions and actions. While state-of-the-art XAI
methods are beneficial for AI developers and practitioners, they may not be
easily understood by general users, particularly household members. This paper
advocates for human-centered XAI methods, emphasizing the importance of
delivering readily comprehensible explanations to enhance user satisfaction and
drive the adoption of smart home systems. We review state-of-the-art XAI
methods and prior studies focusing on human-centered explanations for general
users in the context of smart home applications. Through experiments on two
smart home application scenarios, we demonstrate that explanations generated by
prominent XAI techniques might not be effective in helping users understand and
make decisions. We thus argue for the necessity of a human-centric approach in
representing explanations in smart home systems and highlight relevant
human-computer interaction (HCI) methodologies, including user studies,
prototyping, technology probes analysis, and heuristic evaluation, that can be
employed to generate and present human-centered explanations to users.",2024-04-23,2024,2024-04,environment
Recursive Backwards Q-Learning in Deterministic Environments,"Reinforcement learning is a popular method of finding optimal solutions to
complex problems. Algorithms like Q-learning excel at learning to solve
stochastic problems without a model of their environment. However, they take
longer to solve deterministic problems than is necessary. Q-learning can be
improved to better solve deterministic problems by introducing such a
model-based approach. This paper introduces the recursive backwards Q-learning
(RBQL) agent, which explores and builds a model of the environment. After
reaching a terminal state, it recursively propagates its value backwards
through this model. This lets each state be evaluated to its optimal value
without a lengthy learning process. In the example of finding the shortest path
through a maze, this agent greatly outperforms a regular Q-learning agent.",2024-04-24,2024,2024-04,environment
Harnessing Big Data and Artificial Intelligence to Study Plant Stress,"Life finds a way. For sessile organisms like plants, the need to adapt to
changes in the environment is even more poignant. For humanity, the need to
develop crops that can grow in diverse environments and feed our growing
population is an existential one. The advent of the genomics era enabled the
generation of high-throughput data and computational methods that serve as
powerful hypothesis-generating tools to understand the genomic and gene
functional basis of stress resilience. Today, the proliferation of artificial
intelligence (AI) allows scientists to rapidly screen through high-throughput
datasets to uncover elusive patterns and correlations, enabling us to create
more performant models for prediction and hypothesis generation in plant
biology. This review aims to provide an overview of the availability of
large-scale data in plant stress research and discuss the application of AI
tools on these large-scale datasets in a bid to develop more stress-resilient
plants.",2024-04-24,2024,2024-04,environment
"Leveraging AI to Generate Audio for User-generated Content in Video
  Games","In video game design, audio (both environmental background music and object
sound effects) play a critical role. Sounds are typically pre-created assets
designed for specific locations or objects in a game. However, user-generated
content is becoming increasingly popular in modern games (e.g. building custom
environments or crafting unique objects). Since the possibilities are virtually
limitless, it is impossible for game creators to pre-create audio for
user-generated content. We explore the use of generative artificial
intelligence to create music and sound effects on-the-fly based on
user-generated content. We investigate two avenues for audio generation: 1)
text-to-audio: using a text description of user-generated content as input to
the audio generator, and 2) image-to-audio: using a rendering of the created
environment or object as input to an image-to-text generator, then piping the
resulting text description into the audio generator. In this paper we discuss
ethical implications of using generative artificial intelligence for
user-generated content and highlight two prototype games where audio is
generated for user-created environments and objects.",2024-04-25,2024,2024-04,environment
Isopignistic Canonical Decomposition via Belief Evolution Network,"Developing a general information processing model in uncertain environments
is fundamental for the advancement of explainable artificial intelligence.
Dempster-Shafer theory of evidence is a well-known and effective reasoning
method for representing epistemic uncertainty, which is closely related to
subjective probability theory and possibility theory. Although they can be
transformed to each other under some particular belief structures, there
remains a lack of a clear and interpretable transformation process, as well as
a unified approach for information processing. In this paper, we aim to address
these issues from the perspectives of isopignistic belief functions and the
hyper-cautious transferable belief model. Firstly, we propose an isopignistic
transformation based on the belief evolution network. This transformation
allows for the adjustment of the information granule while retaining the
potential decision outcome. The isopignistic transformation is integrated with
a hyper-cautious transferable belief model to establish a new canonical
decomposition. This decomposition offers a reverse path between the possibility
distribution and its isopignistic mass functions. The result of the canonical
decomposition, called isopignistic function, is an identical information
content distribution to reflect the propensity and relative commitment degree
of the BPA. Furthermore, this paper introduces a method to reconstruct the
basic belief assignment by adjusting the isopignistic function. It explores the
advantages of this approach in modeling and handling uncertainty within the
hyper-cautious transferable belief model. More general, this paper establishes
a theoretical basis for building general models of artificial intelligence
based on probability theory, Dempster-Shafer theory, and possibility theory.",2024-05-04,2024,2024-05,environment
Elements Of Legislation For Artificial Intelligence Systems,"The significant part of the operational context for autonomous company
management systems is the regulatory and legal environment in which
corporations operate. In order to create a dedicated operational context for
autonomous artificial intelligence systems, the wording of local regulatory
documents can be simultaneously presented in two versions: for use by people
and for use by autonomous systems. In this case, the artificial intelligence
system will get a well-defined operational context that allows such a system to
perform functions within the required standards. Local regulations that provide
basis for the joint work of individuals and autonomous artificial intelligence
systems can form the grounds for the relevant legislation governing the
development and implementation of autonomous systems.",2024-05-05,2024,2024-05,environment
"Super-Exponential Regret for UCT, AlphaGo and Variants","We improve the proofs of the lower bounds of Coquelin and Munos (2007) that
demonstrate that UCT can have $\exp(\dots\exp(1)\dots)$ regret (with
$\Omega(D)$ exp terms) on the $D$-chain environment, and that a `polynomial'
UCT variant has $\exp_2(\exp_2(D - O(\log D)))$ regret on the same environment
-- the original proofs contain an oversight for rewards bounded in $[0, 1]$,
which we fix in the present draft. We also adapt the proofs to AlphaGo's MCTS
and its descendants (e.g., AlphaZero, Leela Zero) to also show $\exp_2(\exp_2(D
- O(\log D)))$ regret.",2024-05-07,2024,2024-05,environment
A digital twin based approach to smart lighting design,"Lighting has a critical impact on user mood and behavior, especially in
architectural settings. Consequently, smart lighting design is a rapidly
growing research area. We describe a digital twin-based approach to smart
lighting design that uses an immersive virtual reality digital twin equivalent
(virtual environment) of the real world, physical architectural space to
explore the visual impact of light configurations. The CLIP neural network is
used to obtain a similarity measure between a photo of the physical space with
the corresponding rendering in the virtual environment. A case study was used
to evaluate the proposed design process. The obtained similarity value of over
87% demonstrates the utility of the proposed approach.",2024-05-08,2024,2024-05,environment
"Artificial Intelligence as the New Hacker: Developing Agents for
  Offensive Security","In the vast domain of cybersecurity, the transition from reactive defense to
offensive has become critical in protecting digital infrastructures. This paper
explores the integration of Artificial Intelligence (AI) into offensive
cybersecurity, particularly through the development of an autonomous AI agent,
ReaperAI, designed to simulate and execute cyberattacks. Leveraging the
capabilities of Large Language Models (LLMs) such as GPT-4, ReaperAI
demonstrates the potential to identify, exploit, and analyze security
vulnerabilities autonomously.
  This research outlines the core methodologies that can be utilized to
increase consistency and performance, including task-driven penetration testing
frameworks, AI-driven command generation, and advanced prompting techniques.
The AI agent operates within a structured environment using Python, enhanced by
Retrieval Augmented Generation (RAG) for contextual understanding and memory
retention. ReaperAI was tested on platforms including, Hack The Box, where it
successfully exploited known vulnerabilities, demonstrating its potential
power.
  However, the deployment of AI in offensive security presents significant
ethical and operational challenges. The agent's development process revealed
complexities in command execution, error handling, and maintaining ethical
constraints, highlighting areas for future enhancement.
  This study contributes to the discussion on AI's role in cybersecurity by
showcasing how AI can augment offensive security strategies. It also proposes
future research directions, including the refinement of AI interactions with
cybersecurity tools, enhancement of learning mechanisms, and the discussion of
ethical guidelines for AI in offensive roles. The findings advocate for a
unique approach to AI implementation in cybersecurity, emphasizing innovation.",2024-05-09,2024,2024-05,environment
Visualizing Neural Network Imagination,"In certain situations, neural networks will represent environment states in
their hidden activations. Our goal is to visualize what environment states the
networks are representing. We experiment with a recurrent neural network (RNN)
architecture with a decoder network at the end. After training, we apply the
decoder to the intermediate representations of the network to visualize what
they represent. We define a quantitative interpretability metric and use it to
demonstrate that hidden states can be highly interpretable on a simple task. We
also develop autoencoder and adversarial techniques and show that benefit
interpretability.",2024-05-10,2024,2024-05,environment
"Science based AI model certification for new operational environments
  with application in traffic state estimation","The expanding role of Artificial Intelligence (AI) in diverse engineering
domains highlights the challenges associated with deploying AI models in new
operational environments, involving substantial investments in data collection
and model training. Rapid application of AI necessitates evaluating the
feasibility of utilizing pre-trained models in unobserved operational settings
with minimal or no additional data. However, interpreting the opaque nature of
AI's black-box models remains a persistent challenge. Addressing this issue,
this paper proposes a science-based certification methodology to assess the
viability of employing pre-trained data-driven models in new operational
environments. The methodology advocates a profound integration of domain
knowledge, leveraging theoretical and analytical models from physics and
related disciplines, with data-driven AI models. This novel approach introduces
tools to facilitate the development of secure engineering systems, providing
decision-makers with confidence in the trustworthiness and safety of AI-based
models across diverse environments characterized by limited training data and
dynamic, uncertain conditions. The paper demonstrates the efficacy of this
methodology in real-world safety-critical scenarios, particularly in the
context of traffic state estimation. Through simulation results, the study
illustrates how the proposed methodology efficiently quantifies physical
inconsistencies exhibited by pre-trained AI models. By utilizing analytical
models, the methodology offers a means to gauge the applicability of
pre-trained AI models in new operational environments. This research
contributes to advancing the understanding and deployment of AI models,
offering a robust certification framework that enhances confidence in their
reliability and safety across a spectrum of operational conditions.",2024-05-13,2024,2024-05,environment
"Fusion Intelligence: Confluence of Natural and Artificial Intelligence
  for Enhanced Problem-Solving Efficiency","This paper introduces Fusion Intelligence (FI), a bio-inspired intelligent
system, where the innate sensing, intelligence and unique actuation abilities
of biological organisms such as bees and ants are integrated with the
computational power of Artificial Intelligence (AI). This interdisciplinary
field seeks to create systems that are not only smart but also adaptive and
responsive in ways that mimic the nature. As FI evolves, it holds the promise
of revolutionizing the way we approach complex problems, leveraging the best of
both biological and digital worlds to create solutions that are more effective,
sustainable, and harmonious with the environment. We demonstrate FI's potential
to enhance agricultural IoT system performance through a simulated case study
on improving insect pollination efficacy (entomophily).",2024-05-16,2024,2024-05,environment
"Autonomous Workflow for Multimodal Fine-Grained Training Assistants
  Towards Mixed Reality","Autonomous artificial intelligence (AI) agents have emerged as promising
protocols for automatically understanding the language-based environment,
particularly with the exponential development of large language models (LLMs).
However, a fine-grained, comprehensive understanding of multimodal environments
remains under-explored. This work designs an autonomous workflow tailored for
integrating AI agents seamlessly into extended reality (XR) applications for
fine-grained training. We present a demonstration of a multimodal fine-grained
training assistant for LEGO brick assembly in a pilot XR environment.
Specifically, we design a cerebral language agent that integrates LLM with
memory, planning, and interaction with XR tools and a vision-language agent,
enabling agents to decide their actions based on past experiences. Furthermore,
we introduce LEGO-MRTA, a multimodal fine-grained assembly dialogue dataset
synthesized automatically in the workflow served by a commercial LLM. This
dataset comprises multimodal instruction manuals, conversations, XR responses,
and vision question answering. Last, we present several prevailing
open-resource LLMs as benchmarks, assessing their performance with and without
fine-tuning on the proposed dataset. We anticipate that the broader impact of
this workflow will advance the development of smarter assistants for seamless
user interaction in XR environments, fostering research in both AI and HCI
communities.",2024-05-16,2024,2024-05,environment
"Transfer Learning for CSI-based Positioning with Multi-environment
  Meta-learning","Utilizing deep learning (DL) techniques for radio-based positioning of user
equipment (UE) through channel state information (CSI) fingerprints has
demonstrated significant potential. DL models can extract complex
characteristics from the CSI fingerprints of a particular environment and
accurately predict the position of a UE. Nonetheless, the effectiveness of the
DL model trained on CSI fingerprints is highly dependent on the particular
training environment, limiting the trained model's applicability across
different environments. This paper proposes a novel DL model structure
consisting of two parts, where the first part aims at identifying features that
are independent from any specific environment, while the second part combines
those features in an environment specific way with the goal of positioning. To
train such a two-part model, we propose the multi-environment meta-learning
(MEML) approach for the first part to facilitate training across various
environments, while the second part of the model is trained solely on data from
a specific environment. Our findings indicate that employing the MEML approach
for initializing the weights of the DL model for a new unseen environment
significantly boosts the accuracy of UE positioning in the new target
environment as well the reliability of its uncertainty estimation. This method
outperforms traditional transfer learning methods, whether direct transfer
learning (DTL) between environments or completely training from scratch with
data from a new environment. The proposed approach is verified with real
measurements for both line-of-sight (LOS) and non-LOS (NLOS) environments.",2024-05-20,2024,2024-05,environment
"Artificial Intelligence Approaches for Predictive Maintenance in the
  Steel Industry: A Survey","Predictive Maintenance (PdM) emerged as one of the pillars of Industry 4.0,
and became crucial for enhancing operational efficiency, allowing to minimize
downtime, extend lifespan of equipment, and prevent failures. A wide range of
PdM tasks can be performed using Artificial Intelligence (AI) methods, which
often use data generated from industrial sensors. The steel industry, which is
an important branch of the global economy, is one of the potential
beneficiaries of this trend, given its large environmental footprint, the
globalized nature of the market, and the demanding working conditions. This
survey synthesizes the current state of knowledge in the field of AI-based PdM
within the steel industry and is addressed to researchers and practitioners. We
identified 219 articles related to this topic and formulated five research
questions, allowing us to gain a global perspective on current trends and the
main research gaps. We examined equipment and facilities subjected to PdM,
determined common PdM approaches, and identified trends in the AI methods used
to develop these solutions. We explored the characteristics of the data used in
the surveyed articles and assessed the practical implications of the research
presented there. Most of the research focuses on the blast furnace or hot
rolling, using data from industrial sensors. Current trends show increasing
interest in the domain, especially in the use of deep learning. The main
challenges include implementing the proposed methods in a production
environment, incorporating them into maintenance plans, and enhancing the
accessibility and reproducibility of the research.",2024-05-21,2024,2024-05,environment
"ADESSE: Advice Explanations in Complex Repeated Decision-Making
  Environments","In the evolving landscape of human-centered AI, fostering a synergistic
relationship between humans and AI agents in decision-making processes stands
as a paramount challenge. This work considers a problem setup where an
intelligent agent comprising a neural network-based prediction component and a
deep reinforcement learning component provides advice to a human decision-maker
in complex repeated decision-making environments. Whether the human
decision-maker would follow the agent's advice depends on their beliefs and
trust in the agent and on their understanding of the advice itself. To this
end, we developed an approach named ADESSE to generate explanations about the
adviser agent to improve human trust and decision-making. Computational
experiments on a range of environments with varying model sizes demonstrate the
applicability and scalability of ADESSE. Furthermore, an interactive game-based
user study shows that participants were significantly more satisfied, achieved
a higher reward in the game, and took less time to select an action when
presented with explanations generated by ADESSE. These findings illuminate the
critical role of tailored, human-centered explanations in AI-assisted
decision-making.",2024-05-31,2024,2024-05,environment
"Monte Carlo Tree Search Satellite Scheduling Under Cloud Cover
  Uncertainty","Efficient utilization of satellite resources in dynamic environments remains
a challenging problem in satellite scheduling. This paper addresses the
multi-satellite collection scheduling problem (m-SatCSP), aiming to optimize
task scheduling over a constellation of satellites under uncertain conditions
such as cloud cover. Leveraging Monte Carlo Tree Search (MCTS), a stochastic
search algorithm, two versions of MCTS are explored to schedule satellites
effectively. Hyperparameter tuning is conducted to optimize the algorithm's
performance. Experimental results demonstrate the effectiveness of the MCTS
approach, outperforming existing methods in both solution quality and
efficiency. Comparative analysis against other scheduling algorithms showcases
competitive performance, positioning MCTS as a promising solution for satellite
task scheduling in dynamic environments.",2024-05-31,2024,2024-05,environment
RoboCasa: Large-Scale Simulation of Everyday Tasks for Generalist Robots,"Recent advancements in Artificial Intelligence (AI) have largely been
propelled by scaling. In Robotics, scaling is hindered by the lack of access to
massive robot datasets. We advocate using realistic physical simulation as a
means to scale environments, tasks, and datasets for robot learning methods. We
present RoboCasa, a large-scale simulation framework for training generalist
robots in everyday environments. RoboCasa features realistic and diverse scenes
focusing on kitchen environments. We provide thousands of 3D assets across over
150 object categories and dozens of interactable furniture and appliances. We
enrich the realism and diversity of our simulation with generative AI tools,
such as object assets from text-to-3D models and environment textures from
text-to-image models. We design a set of 100 tasks for systematic evaluation,
including composite tasks generated by the guidance of large language models.
To facilitate learning, we provide high-quality human demonstrations and
integrate automated trajectory generation methods to substantially enlarge our
datasets with minimal human burden. Our experiments show a clear scaling trend
in using synthetically generated robot data for large-scale imitation learning
and show great promise in harnessing simulation data in real-world tasks.
Videos and open-source code are available at https://robocasa.ai/",2024-06-04,2024,2024-06,environment
"Meta-Learners for Partially-Identified Treatment Effects Across Multiple
  Environments","Estimating the conditional average treatment effect (CATE) from observational
data is relevant for many applications such as personalized medicine. Here, we
focus on the widespread setting where the observational data come from multiple
environments, such as different hospitals, physicians, or countries.
Furthermore, we allow for violations of standard causal assumptions, namely,
overlap within the environments and unconfoundedness. To this end, we move away
from point identification and focus on partial identification. Specifically, we
show that current assumptions from the literature on multiple environments
allow us to interpret the environment as an instrumental variable (IV). This
allows us to adapt bounds from the IV literature for partial identification of
CATE by leveraging treatment assignment mechanisms across environments. Then,
we propose different model-agnostic learners (so-called meta-learners) to
estimate the bounds that can be used in combination with arbitrary machine
learning models. We further demonstrate the effectiveness of our meta-learners
across various experiments using both simulated and real-world data. Finally,
we discuss the applicability of our meta-learners to partial identification in
instrumental variable settings, such as randomized controlled trials with
non-compliance.",2024-06-04,2024,2024-06,environment
"Expansion of situations theory for exploring shared awareness in
  human-intelligent autonomous systems","Intelligent autonomous systems are part of a system of systems that interact
with other agents to accomplish tasks in complex environments. However,
intelligent autonomous systems integrated system of systems add additional
layers of complexity based on their limited cognitive processes, specifically
shared situation awareness that allows a team to respond to novel tasks.
Intelligent autonomous systems' lack of shared situation awareness adversely
influences team effectiveness in complex task environments, such as military
command-and-control. A complementary approach of shared situation awareness,
called situations theory, is beneficial for understanding the relationship
between system of systems shared situation awareness and effectiveness. The
current study elucidates a conceptual discussion on situations theory to
investigate the development of an system of systems shared situational
awareness when humans team with intelligent autonomous system agents. To ground
the discussion, the reviewed studies expanded situations theory within the
context of a system of systems that result in three major conjectures that can
be beneficial to the design and development of future systems of systems.",2024-06-07,2024,2024-06,environment
Massively Multiagent Minigames for Training Generalist Agents,"We present Meta MMO, a collection of many-agent minigames for use as a
reinforcement learning benchmark. Meta MMO is built on top of Neural MMO, a
massively multiagent environment that has been the subject of two previous
NeurIPS competitions. Our work expands Neural MMO with several computationally
efficient minigames. We explore generalization across Meta MMO by learning to
play several minigames with a single set of weights. We release the
environment, baselines, and training code under the MIT license. We hope that
Meta MMO will spur additional progress on Neural MMO and, more generally, will
serve as a useful benchmark for many-agent generalization.",2024-06-07,2024,2024-06,environment
"PufferLib: Making Reinforcement Learning Libraries and Environments Play
  Nice","You have an environment, a model, and a reinforcement learning library that
are designed to work together but don't. PufferLib makes them play nice. The
library provides one-line environment wrappers that eliminate common
compatibility problems and fast vectorization to accelerate training. With
PufferLib, you can use familiar libraries like CleanRL and SB3 to scale from
classic benchmarks like Atari and Procgen to complex simulators like NetHack
and Neural MMO. We release pip packages and prebuilt images with dependencies
for dozens of environments. All of our code is free and open-source software
under the MIT license, complete with baselines, documentation, and support at
pufferai.github.io.",2024-06-11,2024,2024-06,environment
"Comment on paper: Position: Rethinking Post-Hoc Search-Based Neural
  Approaches for Solving Large-Scale Traveling Salesman Problems","We identify two major issues in the SoftDist paper (Xia et al.): (1) the
failure to run all steps of different baselines on the same hardware
environment, and (2) the use of inconsistent time measurements when comparing
to other baselines. These issues lead to flawed conclusions. When all steps are
executed in the same hardware environment, the primary claim made in SoftDist
is no longer supported.",2024-06-11,2024,2024-06,environment
"Classical and Quantum Physical Reservoir Computing for Onboard
  Artificial Intelligence Systems: A Perspective","Artificial intelligence (AI) systems of autonomous systems such as drones,
robots and self-driving cars may consume up to 50% of total power available
onboard, thereby limiting the vehicle's range of functions and considerably
reducing the distance the vehicle can travel on a single charge.
Next-generation onboard AI systems need an even higher power since they collect
and process even larger amounts of data in real time. This problem cannot be
solved using the traditional computing devices since they become more and more
power-consuming. In this review article, we discuss the perspectives of
development of onboard neuromorphic computers that mimic the operation of a
biological brain using nonlinear-dynamical properties of natural physical
environments surrounding autonomous vehicles. Previous research also
demonstrated that quantum neuromorphic processors (QNPs) can conduct
computations with the efficiency of a standard computer while consuming less
than 1% of the onboard battery power. Since QNPs is a semi-classical
technology, their technical simplicity and low, compared with quantum
computers, cost make them ideally suitable for application in autonomous AI
system. Providing a perspective view on the future progress in unconventional
physical reservoir computing and surveying the outcomes of more than 200
interdisciplinary research works, this article will be of interest to a broad
readership, including both students and experts in the fields of physics,
engineering, quantum technologies and computing.",2024-06-14,2024,2024-06,environment
"Orangutan: A Multiscale Brain Emulation-Based Artificial Intelligence
  Framework for Dynamic Environments","Achieving General Artificial Intelligence (AGI) has long been a grand
challenge in the field of AI, and brain-inspired computing is widely
acknowledged as one of the most promising approaches to realize this goal. This
paper introduces a novel brain-inspired AI framework, Orangutan. It simulates
the structure and computational mechanisms of biological brains on multiple
scales, encompassing multi-compartment neuron architectures, diverse synaptic
connection modalities, neural microcircuits, cortical columns, and brain
regions, as well as biochemical processes including facilitation, feedforward
inhibition, short-term potentiation, and short-term depression, all grounded in
solid neuroscience. Building upon these highly integrated brain-like
mechanisms, I have developed a sensorimotor model that simulates human saccadic
eye movements during object observation. The model's algorithmic efficacy was
validated through testing with the observation of handwritten digit images.",2024-06-18,2024,2024-06,environment
"Generative Artificial Intelligence-Guided User Studies: An Application
  for Air Taxi Services","User studies are crucial for meeting user needs. In user studies, real
experimental scenarios and participants are constructed and recruited. However,
emerging and unfamiliar studies face limitations, including safety concerns and
iterative efficiency. To address these challenges, this study utilises a
Generative Artificial Intelligence (GenAI) to create GenAI-generated scenarios
for user experience (UX). By recruiting real users to evaluate this experience,
we can collect feedback that enables rapid iteration in the early design phase.
The air taxi is particularly representative of these challenges and has been
chosen as the case study for this research. The key contribution was designing
an Air Taxi Journey (ATJ) using Large Language Models (LLMs) and AI image and
video generators. Based on the GPT-4-generated scripts, key visuals were
created for the air taxi, and the ATJ was evaluated by 72 participants.
Furthermore, the LLMs demonstrated the ability to identify and suggest
environments that significantly improve participants' willingness toward air
taxis. Education level and gender significantly influenced participants' the
difference in willingness and their satisfaction with the ATJ. Satisfaction
with the ATJ serves as a mediator, significantly influencing participants'
willingness to take air taxis. Our study confirms the capability of GenAI to
support user studies, providing a feasible approach and valuable insights for
designing air taxi UX in the early design phase.",2024-06-18,2024,2024-06,environment
CoDreamer: Communication-Based Decentralised World Models,"Sample efficiency is a critical challenge in reinforcement learning.
Model-based RL has emerged as a solution, but its application has largely been
confined to single-agent scenarios. In this work, we introduce CoDreamer, an
extension of the Dreamer algorithm for multi-agent environments. CoDreamer
leverages Graph Neural Networks for a two-level communication system to tackle
challenges such as partial observability and inter-agent cooperation.
Communication is separately utilised within the learned world models and within
the learned policies of each agent to enhance modelling and task-solving. We
show that CoDreamer offers greater expressive power than a naive application of
Dreamer, and we demonstrate its superiority over baseline methods across
various multi-agent environments.",2024-06-19,2024,2024-06,environment
"Tradeoffs When Considering Deep Reinforcement Learning for Contingency
  Management in Advanced Air Mobility","Air transportation is undergoing a rapid evolution globally with the
introduction of Advanced Air Mobility (AAM) and with it comes novel challenges
and opportunities for transforming aviation. As AAM operations introduce
increasing heterogeneity in vehicle capabilities and density, increased levels
of automation are likely necessary to achieve operational safety and efficiency
goals. This paper focuses on one example where increased automation has been
suggested. Autonomous operations will need contingency management systems that
can monitor evolving risk across a span of interrelated (or interdependent)
hazards and, if necessary, execute appropriate control interventions via
supervised or automated decision making. Accommodating this complex environment
may require automated functions (autonomy) that apply artificial intelligence
(AI) techniques that can adapt and respond to a quickly changing environment.
This paper explores the use of Deep Reinforcement Learning (DRL) which has
shown promising performance in complex and high-dimensional environments where
the objective can be constructed as a sequential decision-making problem. An
extension of a prior formulation of the contingency management problem as a
Markov Decision Process (MDP) is presented and uses a DRL framework to train
agents that mitigate hazards present in the simulation environment. A
comparison of these learning-based agents and classical techniques is presented
in terms of their performance, verification difficulties, and development
process.",2024-06-28,2024,2024-06,environment
"Craftium: An Extensible Framework for Creating Reinforcement Learning
  Environments","Most Reinforcement Learning (RL) environments are created by adapting
existing physics simulators or video games. However, they usually lack the
flexibility required for analyzing specific characteristics of RL methods often
relevant to research. This paper presents Craftium, a novel framework for
exploring and creating rich 3D visual RL environments that builds upon the
Minetest game engine and the popular Gymnasium API. Minetest is built to be
extended and can be used to easily create voxel-based 3D environments (often
similar to Minecraft), while Gymnasium offers a simple and common interface for
RL research. Craftium provides a platform that allows practitioners to create
fully customized environments to suit their specific research requirements,
ranging from simple visual tasks to infinite and procedurally generated worlds.
We also provide five ready-to-use environments for benchmarking and as examples
of how to develop new ones. The code and documentation are available at
https://github.com/mikelma/craftium/.",2024-07-04,2024,2024-07,environment
"Explorative Imitation Learning: A Path Signature Approach for Continuous
  Environments","Some imitation learning methods combine behavioural cloning with
self-supervision to infer actions from state pairs. However, most rely on a
large number of expert trajectories to increase generalisation and human
intervention to capture key aspects of the problem, such as domain constraints.
In this paper, we propose Continuous Imitation Learning from Observation
(CILO), a new method augmenting imitation learning with two important features:
(i) exploration, allowing for more diverse state transitions, requiring less
expert trajectories and resulting in fewer training iterations; and (ii) path
signatures, allowing for automatic encoding of constraints, through the
creation of non-parametric representations of agents and expert trajectories.
We compared CILO with a baseline and two leading imitation learning methods in
five environments. It had the best overall performance of all methods in all
environments, outperforming the expert in two of them.",2024-07-05,2024,2024-07,environment
"Efficiently Training Neural Networks for Imperfect Information Games by
  Sampling Information Sets","In imperfect information games, the evaluation of a game state not only
depends on the observable world but also relies on hidden parts of the
environment. As accessing the obstructed information trivialises state
evaluations, one approach to tackle such problems is to estimate the value of
the imperfect state as a combination of all states in the information set,
i.e., all possible states that are consistent with the current imperfect
information. In this work, the goal is to learn a function that maps from the
imperfect game information state to its expected value. However, constructing a
perfect training set, i.e. an enumeration of the whole information set for
numerous imperfect states, is often infeasible. To compute the expected values
for an imperfect information game like \textit{Reconnaissance Blind Chess}, one
would need to evaluate thousands of chess positions just to obtain the training
target for a single state. Still, the expected value of a state can already be
approximated with appropriate accuracy from a much smaller set of evaluations.
Thus, in this paper, we empirically investigate how a budget of perfect
information game evaluations should be distributed among training samples to
maximise the return. Our results show that sampling a small number of states,
in our experiments roughly 3, for a larger number of separate positions is
preferable over repeatedly sampling a smaller quantity of states. Thus, we find
that in our case, the quantity of different samples seems to be more important
than higher target quality.",2024-07-08,2024,2024-07,environment
"Industrial-Grade Time-Dependent Counterfactual Root Cause Analysis
  through the Unanticipated Point of Incipient Failure: a Proof of Concept","This paper describes the development of a counterfactual Root Cause Analysis
diagnosis approach for an industrial multivariate time series environment. It
drives the attention toward the Point of Incipient Failure, which is the moment
in time when the anomalous behavior is first observed, and where the root cause
is assumed to be found before the issue propagates. The paper presents the
elementary but essential concepts of the solution and illustrates them
experimentally on a simulated setting. Finally, it discusses avenues of
improvement for the maturity of the causal technology to meet the robustness
challenges of increasingly complex environments in the industry.",2024-07-10,2024,2024-07,environment
"Instruction Following with Goal-Conditioned Reinforcement Learning in
  Virtual Environments","In this study, we address the issue of enabling an artificial intelligence
agent to execute complex language instructions within virtual environments. In
our framework, we assume that these instructions involve intricate linguistic
structures and multiple interdependent tasks that must be navigated
successfully to achieve the desired outcomes. To effectively manage these
complexities, we propose a hierarchical framework that combines the deep
language comprehension of large language models with the adaptive
action-execution capabilities of reinforcement learning agents. The language
module (based on LLM) translates the language instruction into a high-level
action plan, which is then executed by a pre-trained reinforcement learning
agent. We have demonstrated the effectiveness of our approach in two different
environments: in IGLU, where agents are instructed to build structures, and in
Crafter, where agents perform tasks and interact with objects in the
surrounding environment according to language commands.",2024-07-12,2024,2024-07,environment
"Introducing VaDA: Novel Image Segmentation Model for Maritime Object
  Segmentation Using New Dataset","The maritime shipping industry is undergoing rapid evolution driven by
advancements in computer vision artificial intelligence (AI). Consequently,
research on AI-based object recognition models for maritime transportation is
steadily growing, leveraging advancements in sensor technology and computing
performance. However, object recognition in maritime environments faces
challenges such as light reflection, interference, intense lighting, and
various weather conditions. To address these challenges, high-performance deep
learning algorithms tailored to maritime imagery and high-quality datasets
specialized for maritime scenes are essential. Existing AI recognition models
and datasets have limited suitability for composing autonomous navigation
systems. Therefore, in this paper, we propose a Vertical and Detail Attention
(VaDA) model for maritime object segmentation and a new model evaluation
method, the Integrated Figure of Calculation Performance (IFCP), to verify its
suitability for the system in real-time. Additionally, we introduce a benchmark
maritime dataset, OASIs (Ocean AI Segmentation Initiatives) to standardize
model performance evaluation across diverse maritime environments. OASIs
dataset and details are available at our website:
https://www.navlue.com/dataset",2024-07-12,2024,2024-07,environment
"Intelligent Cross-Organizational Process Mining: A Survey and New
  Perspectives","Process mining, as a high-level field in data mining, plays a crucial role in
enhancing operational efficiency and decision-making across organizations. In
this survey paper, we delve into the growing significance and ongoing trends in
the field of process mining, advocating a specific viewpoint on its contents,
application, and development in modern businesses and process management,
particularly in cross-organizational settings. We first summarize the framework
of process mining, common industrial applications, and the latest advances
combined with artificial intelligence, such as workflow optimization,
compliance checking, and performance analysis. Then, we propose a holistic
framework for intelligent process analysis and outline initial methodologies in
cross-organizational settings, highlighting both challenges and opportunities.
This particular perspective aims to revolutionize process mining by leveraging
artificial intelligence to offer sophisticated solutions for complex,
multi-organizational data analysis. By integrating advanced machine learning
techniques, we can enhance predictive capabilities, streamline processes, and
facilitate real-time decision-making. Furthermore, we pinpoint avenues for
future investigations within the research community, encouraging the
exploration of innovative algorithms, data integration strategies, and
privacy-preserving methods to fully harness the potential of process mining in
diverse, interconnected business environments.",2024-07-15,2024,2024-07,environment
Affectively Framework: Towards Human-like Affect-Based Agents,"Game environments offer a unique opportunity for training virtual agents due
to their interactive nature, which provides diverse play traces and affect
labels. Despite their potential, no reinforcement learning framework
incorporates human affect models as part of their observation space or reward
mechanism. To address this, we present the \emph{Affectively Framework}, a set
of Open-AI Gym environments that integrate affect as part of the observation
space. This paper introduces the framework and its three game environments and
provides baseline experiments to validate its effectiveness and potential.",2024-07-25,2024,2024-07,environment
"ReALFRED: An Embodied Instruction Following Benchmark in Photo-Realistic
  Environments","Simulated virtual environments have been widely used to learn robotic agents
that perform daily household tasks. These environments encourage research
progress by far, but often provide limited object interactability, visual
appearance different from real-world environments, or relatively smaller
environment sizes. This prevents the learned models in the virtual scenes from
being readily deployable. To bridge the gap between these learning environments
and deploying (i.e., real) environments, we propose the ReALFRED benchmark that
employs real-world scenes, objects, and room layouts to learn agents to
complete household tasks by understanding free-form language instructions and
interacting with objects in large, multi-room and 3D-captured scenes.
Specifically, we extend the ALFRED benchmark with updates for larger
environmental spaces with smaller visual domain gaps. With ReALFRED, we analyze
previously crafted methods for the ALFRED benchmark and observe that they
consistently yield lower performance in all metrics, encouraging the community
to develop methods in more realistic environments. Our code and data are
publicly available.",2024-07-26,2024,2024-07,environment
"The Interpretability of Codebooks in Model-Based Reinforcement Learning
  is Limited","Interpretability of deep reinforcement learning systems could assist
operators with understanding how they interact with their environment. Vector
quantization methods -- also called codebook methods -- discretize a neural
network's latent space that is often suggested to yield emergent
interpretability. We investigate whether vector quantization in fact provides
interpretability in model-based reinforcement learning. Our experiments,
conducted in the reinforcement learning environment Crafter, show that the
codes of vector quantization models are inconsistent, have no guarantee of
uniqueness, and have a limited impact on concept disentanglement, all of which
are necessary traits for interpretability. We share insights on why vector
quantization may be fundamentally insufficient for model interpretability.",2024-07-28,2024,2024-07,environment
"Anomalous State Sequence Modeling to Enhance Safety in Reinforcement
  Learning","The deployment of artificial intelligence (AI) in decision-making
applications requires ensuring an appropriate level of safety and reliability,
particularly in changing environments that contain a large number of unknown
observations. To address this challenge, we propose a novel safe reinforcement
learning (RL) approach that utilizes an anomalous state sequence to enhance RL
safety. Our proposed solution Safe Reinforcement Learning with Anomalous State
Sequences (AnoSeqs) consists of two stages. First, we train an agent in a
non-safety-critical offline 'source' environment to collect safe state
sequences. Next, we use these safe sequences to build an anomaly detection
model that can detect potentially unsafe state sequences in a 'target'
safety-critical environment where failures can have high costs. The estimated
risk from the anomaly detection model is utilized to train a risk-averse RL
policy in the target environment; this involves adjusting the reward function
to penalize the agent for visiting anomalous states deemed unsafe by our
anomaly model. In experiments on multiple safety-critical benchmarking
environments including self-driving cars, our solution approach successfully
learns safer policies and proves that sequential anomaly detection can provide
an effective supervisory signal for training safety-aware RL agents",2024-07-29,2024,2024-07,environment
Human interaction classifier for LLM based chatbot,"This study investigates different approaches to classify human interactions
in an artificial intelligence-based environment, specifically for Applus+
IDIADA's intelligent agent AIDA. The main objective is to develop a classifier
that accurately identifies the type of interaction received (Conversation,
Services, or Document Translation) to direct requests to the appropriate
channel and provide a more specialized and efficient service. Various models
are compared, including LLM-based classifiers, KNN using Titan and Cohere
embeddings, SVM, and artificial neural networks. Results show that SVM and ANN
models with Cohere embeddings achieve the best overall performance, with
superior F1 scores and faster execution times compared to LLM-based approaches.
The study concludes that the SVM model with Cohere embeddings is the most
suitable option for classifying human interactions in the AIDA environment,
offering an optimal balance between accuracy and computational efficiency.",2024-07-31,2024,2024-07,environment
"Enabling High Data Throughput Reinforcement Learning on GPUs: A Domain
  Agnostic Framework for Data-Driven Scientific Research","We introduce WarpSci, a domain agnostic framework designed to overcome
crucial system bottlenecks encountered in the application of reinforcement
learning to intricate environments with vast datasets featuring
high-dimensional observation or action spaces. Notably, our framework
eliminates the need for data transfer between the CPU and GPU, enabling the
concurrent execution of thousands of simulations on a single or multiple GPUs.
This high data throughput architecture proves particularly advantageous for
data-driven scientific research, where intricate environment models are
commonly essential.",2024-08-01,2024,2024-08,environment
"A Safe Exploration Strategy for Model-free Task Adaptation in
  Safety-constrained Grid Environments","Training a model-free reinforcement learning agent requires allowing the
agent to sufficiently explore the environment to search for an optimal policy.
In safety-constrained environments, utilizing unsupervised exploration or a
non-optimal policy may lead the agent to undesirable states, resulting in
outcomes that are potentially costly or hazardous for both the agent and the
environment. In this paper, we introduce a new exploration framework for
navigating the grid environments that enables model-free agents to interact
with the environment while adhering to safety constraints. Our framework
includes a pre-training phase, during which the agent learns to identify
potentially unsafe states based on both observable features and specified
safety constraints in the environment. Subsequently, a binary classification
model is trained to predict those unsafe states in new environments that
exhibit similar dynamics. This trained classifier empowers model-free agents to
determine situations in which employing random exploration or a suboptimal
policy may pose safety risks, in which case our framework prompts the agent to
follow a predefined safe policy to mitigate the potential for hazardous
consequences. We evaluated our framework on three randomly generated grid
environments and demonstrated how model-free agents can safely adapt to new
tasks and learn optimal policies for new environments. Our results indicate
that by defining an appropriate safe policy and utilizing a well-trained model
to detect unsafe states, our framework enables a model-free agent to adapt to
new tasks and environments with significantly fewer safety violations.",2024-08-02,2024,2024-08,environment
"Environment Complexity and Nash Equilibria in a Sequential Social
  Dilemma","Multi-agent reinforcement learning (MARL) methods, while effective in
zero-sum or positive-sum games, often yield suboptimal outcomes in general-sum
games where cooperation is essential for achieving globally optimal outcomes.
Matrix game social dilemmas, which abstract key aspects of general-sum
interactions, such as cooperation, risk, and trust, fail to model the temporal
and spatial dynamics characteristic of real-world scenarios. In response, our
study extends matrix game social dilemmas into more complex, higher-dimensional
MARL environments. We adapt a gridworld implementation of the Stag Hunt dilemma
to more closely match the decision-space of a one-shot matrix game while also
introducing variable environment complexity. Our findings indicate that as
complexity increases, MARL agents trained in these environments converge to
suboptimal strategies, consistent with the risk-dominant Nash equilibria
strategies found in matrix games. Our work highlights the impact of environment
complexity on achieving optimal outcomes in higher-dimensional game-theoretic
MARL environments.",2024-08-04,2024,2024-08,environment
"The Impact of Environment Configurations on the Stability of AI-Enabled
  Systems","Nowadays, software systems tend to include Artificial Intelligence (AI)
components. Changes in the operational environment have been known to
negatively impact the stability of AI-enabled software systems by causing
unintended changes in behavior. However, how an environment configuration
impacts the behavior of such systems has yet to be explored. Understanding and
quantifying the degree of instability caused by different environment settings
can help practitioners decide the best environment configuration for the most
stable AI systems. To achieve this goal, we performed experiments with eight
different combinations of three key environment variables (operating system,
Python version, and CPU architecture) on $30$ open-source AI-enabled systems
using the Travis CI platform. We determine the existence and the degree of
instability introduced by each configuration using three metrics: the output of
an AI component of the system (model performance), the time required to build
and run the system (processing time), and the cost associated with building and
running the system (expense). Our results indicate that changes in environment
configurations lead to instability across all three metrics; however, it is
observed more frequently with respect to processing time and expense rather
than model performance. For example, between Linux and MacOS, instability is
observed in 23\%, 96.67\%, and 100\% of the studied projects in model
performance, processing time, and expense, respectively. Our findings
underscore the importance of identifying the optimal combination of
configuration settings to mitigate drops in model performance and reduce the
processing time and expense before deploying an AI-enabled system.",2024-08-05,2024,2024-08,environment
Dynamic Fog Computing for Enhanced LLM Execution in Medical Applications,"The ability of large language models (LLMs) to transform, interpret, and
comprehend vast quantities of heterogeneous data presents a significant
opportunity to enhance data-driven care delivery. However, the sensitive nature
of protected health information (PHI) raises valid concerns about data privacy
and trust in remote LLM platforms. In addition, the cost associated with
cloud-based artificial intelligence (AI) services continues to impede
widespread adoption. To address these challenges, we propose a shift in the LLM
execution environment from opaque, centralized cloud providers to a
decentralized and dynamic fog computing architecture. By executing open-weight
LLMs in more trusted environments, such as the user's edge device or a fog
layer within a local network, we aim to mitigate the privacy, trust, and
financial challenges associated with cloud-based LLMs. We further present
SpeziLLM, an open-source framework designed to facilitate rapid and seamless
leveraging of different LLM execution layers and lowering barriers to LLM
integration in digital health applications. We demonstrate SpeziLLM's broad
applicability across six digital health applications, showcasing its
versatility in various healthcare settings.",2024-08-08,2024,2024-08,environment
Detection and tracking of barchan dunes using Artificial Intelligence,"Barchans are crescent-shape dunes ubiquitous on Earth and other celestial
bodies, which are organized in barchan fields where they interact with each
other. Over the last decades, satellite images have been largely employed to
detect barchans on Earth and on the surface of Mars, with AI (Artificial
Intelligence) becoming an important tool for monitoring those bedforms.
However, automatic detection reported in previous works is limited to isolated
dunes and does not identify successfully groups of interacting barchans. In
this paper, we inquire into the automatic detection and tracking of barchans by
carrying out experiments and exploring the acquired images using AI. After
training a neural network with images from controlled experiments where complex
interactions took place between dunes, we did the same for satellite images
from Earth and Mars. We show, for the first time, that a neural network trained
properly can identify and track barchans interacting with each other in
different environments, using different image types (contrasts, colors, points
of view, resolutions, etc.), with confidence scores (accuracy) above 70%. Our
results represent a step further for automatically monitoring barchans, with
important applications for human activities on Earth, Mars and other celestial
bodies.",2024-08-14,2024,2024-08,environment
A Logic for Policy Based Resource Exchanges in Multiagent Systems,"In multiagent systems autonomous agents interact with each other to achieve
individual and collective goals. Typical interactions concern negotiation and
agreement on resource exchanges. Modeling and formalizing these agreements pose
significant challenges, particularly in capturing the dynamic behaviour of
agents, while ensuring that resources are correctly handled. Here, we propose
exchange environments as a formal setting where agents specify and obey
exchange policies, which are declarative statements about what resources they
offer and what they require in return. Furthermore, we introduce a decidable
extension of the computational fragment of linear logic as a fundamental tool
for representing exchange environments and studying their dynamics in terms of
provability.",2024-08-18,2024,2024-08,environment
"Multimodal Datasets and Benchmarks for Reasoning about Dynamic
  Spatio-Temporality in Everyday Environments","We used a 3D simulator to create artificial video data with standardized
annotations, aiming to aid in the development of Embodied AI. Our question
answering (QA) dataset measures the extent to which a robot can understand
human behavior and the environment in a home setting. Preliminary experiments
suggest our dataset is useful in measuring AI's comprehension of daily life.
\end{abstract}",2024-08-21,2024,2024-08,environment
Can Artificial Intelligence Embody Moral Values?,"The neutrality thesis holds that technology cannot be laden with values. This
long-standing view has faced critiques, but much of the argumentation against
neutrality has focused on traditional, non-smart technologies like bridges and
razors. In contrast, AI is a smart technology increasingly used in high-stakes
domains like healthcare, finance, and policing, where its decisions can cause
moral harm. In this paper, we argue that artificial intelligence, particularly
artificial agents that autonomously make decisions to pursue their goals,
challenge the neutrality thesis. Our central claim is that the computational
models underlying artificial agents can integrate representations of moral
values such as fairness, honesty and avoiding harm. We provide a conceptual
framework discussing the neutrality thesis, values, and AI. Moreover, we
examine two approaches to designing computational models of morality,
artificial conscience and ethical prompting, and present empirical evidence
from text-based game environments that artificial agents with such models
exhibit more ethical behavior compared to agents without these models. The
findings support that AI can embody moral values, which contradicts the claim
that all technologies are necessarily value-neutral.",2024-08-22,2024,2024-08,environment
Identifying the Best Arm in the Presence of Global Environment Shifts,"This paper formulates a new Best-Arm Identification problem in the
non-stationary stochastic bandits setting, where the means of all arms are
shifted in the same way due to a global influence of the environment. The aim
is to identify the unique best arm across environmental change given a fixed
total budget. While this setting can be regarded as a special case of
Adversarial Bandits or Corrupted Bandits, we demonstrate that existing
solutions tailored to those settings do not fully utilise the nature of this
global influence, and thus, do not work well in practice (despite their
theoretical guarantees). To overcome this issue, in this paper we develop a
novel selection policy that is consistent and robust in dealing with global
environmental shifts. We then propose an allocation policy, LinLUCB, which
exploits information about global shifts across all arms in each environment.
Empirical tests depict a significant improvement in our policies against other
existing methods.",2024-08-22,2024,2024-08,environment
"Localized Observation Abstraction Using Piecewise Linear Spatial Decay
  for Reinforcement Learning in Combat Simulations","In the domain of combat simulations, the training and deployment of deep
reinforcement learning (RL) agents still face substantial challenges due to the
dynamic and intricate nature of such environments. Unfortunately, as the
complexity of the scenarios and available information increases, the training
time required to achieve a certain threshold of performance does not just
increase, but often does so exponentially. This relationship underscores the
profound impact of complexity in training RL agents. This paper introduces a
novel approach that addresses this limitation in training artificial
intelligence (AI) agents using RL. Traditional RL methods have been shown to
struggle in these high-dimensional, dynamic environments due to real-world
computational constraints and the known sample inefficiency challenges of RL.
To overcome these limitations, we propose a method of localized observation
abstraction using piecewise linear spatial decay. This technique simplifies the
state space, reducing computational demands while still preserving essential
information, thereby enhancing AI training efficiency in dynamic environments
where spatial relationships are often critical. Our analysis reveals that this
localized observation approach consistently outperforms the more traditional
global observation approach across increasing scenario complexity levels. This
paper advances the research on observation abstractions for RL, illustrating
how localized observation with piecewise linear spatial decay can provide an
effective solution to large state representation challenges in dynamic
environments.",2024-08-23,2024,2024-08,environment
Environment-Centric Active Inference,"To handle unintended changes in the environment by agents, we propose an
environment-centric active inference EC-AIF in which the Markov Blanket of
active inference is defined starting from the environment. In normal active
inference, the Markov Blanket is defined starting from the agent. That is,
first the agent was defined as the entity that performs the ""action"" such as a
robot or a person, then the environment was defined as other people or objects
that are directly affected by the agent's ""action,"" and the boundary between
the agent and the environment was defined as the Markov Blanket. This
agent-centric definition does not allow the agent to respond to unintended
changes in the environment caused by factors outside of the defined
environment. In the proposed EC-AIF, there is no entity corresponding to an
agent. The environment includes all observable things, including people and
things conventionally considered to be the environment, as well as entities
that perform ""actions"" such as robots and people. Accordingly, all states,
including robots and people, are included in inference targets, eliminating
unintended changes in the environment. The EC-AIF was applied to a robot arm
and validated with an object transport task by the robot arm. The results
showed that the robot arm successfully transported objects while responding to
changes in the target position of the object and to changes in the orientation
of another robot arm.",2024-08-23,2024,2024-08,environment
"Artificial Intelligence in Education: Ethical Considerations and
  Insights from Ancient Greek Philosophy","This paper explores the ethical implications of integrating Artificial
Intelligence (AI) in educational settings, from primary schools to
universities, while drawing insights from ancient Greek philosophy to address
emerging concerns. As AI technologies increasingly influence learning
environments, they offer novel opportunities for personalized learning,
efficient assessment, and data-driven decision-making. However, these
advancements also raise critical ethical questions regarding data privacy,
algorithmic bias, student autonomy, and the changing roles of educators. This
research examines specific use cases of AI in education, analyzing both their
potential benefits and drawbacks. By revisiting the philosophical principles of
ancient Greek thinkers such as Socrates, Aristotle, and Plato, we discuss how
their writings can guide the ethical implementation of AI in modern education.
The paper argues that while AI presents significant challenges, a balanced
approach informed by classical philosophical thought can lead to an ethically
sound transformation of education. It emphasizes the evolving role of teachers
as facilitators and the importance of fostering student initiative in AI-rich
environments.",2024-09-04,2024,2024-09,environment
"Scalable Task Planning via Large Language Models and Structured World
  Representations","Planning methods struggle with computational intractability in solving
task-level problems in large-scale environments. This work explores leveraging
the commonsense knowledge encoded in LLMs to empower planning techniques to
deal with these complex scenarios. We achieve this by efficiently using LLMs to
prune irrelevant components from the planning problem's state space,
substantially simplifying its complexity. We demonstrate the efficacy of this
system through extensive experiments within a household simulation environment,
alongside real-world validation using a 7-DoF manipulator (video
https://youtu.be/6ro2UOtOQS4).",2024-09-07,2024,2024-09,environment
Keyword-Aware ASR Error Augmentation for Robust Dialogue State Tracking,"Dialogue State Tracking (DST) is a key part of task-oriented dialogue
systems, identifying important information in conversations. However, its
accuracy drops significantly in spoken dialogue environments due to named
entity errors from Automatic Speech Recognition (ASR) systems. We introduce a
simple yet effective data augmentation method that targets those entities to
improve the robustness of DST model. Our novel method can control the placement
of errors using keyword-highlighted prompts while introducing phonetically
similar errors. As a result, our method generated sufficient error patterns on
keywords, leading to improved accuracy in noised and low-accuracy ASR
environments.",2024-09-10,2024,2024-09,environment
"Learning Generative Interactive Environments By Trained Agent
  Exploration","World models are increasingly pivotal in interpreting and simulating the
rules and actions of complex environments. Genie, a recent model, excels at
learning from visually diverse environments but relies on costly
human-collected data. We observe that their alternative method of using random
agents is too limited to explore the environment. We propose to improve the
model by employing reinforcement learning based agents for data generation.
This approach produces diverse datasets that enhance the model's ability to
adapt and perform well across various scenarios and realistic actions within
the environment. In this paper, we first release the model GenieRedux - an
implementation based on Genie. Additionally, we introduce GenieRedux-G, a
variant that uses the agent's readily available actions to factor out action
prediction uncertainty during validation. Our evaluation, including a
replication of the Coinrun case study, shows that GenieRedux-G achieves
superior visual fidelity and controllability using the trained agent
exploration. The proposed approach is reproducable, scalable and adaptable to
new types of environments. Our codebase is available at
https://github.com/insait-institute/GenieRedux .",2024-09-10,2024,2024-09,environment
"Online Decision MetaMorphFormer: A Casual Transformer-Based
  Reinforcement Learning Framework of Universal Embodied Intelligence","Interactive artificial intelligence in the motion control field is an
interesting topic, especially when universal knowledge is adaptive to multiple
tasks and universal environments. Despite there being increasing efforts in the
field of Reinforcement Learning (RL) with the aid of transformers, most of them
might be limited by the offline training pipeline, which prohibits exploration
and generalization abilities. To address this limitation, we propose the
framework of Online Decision MetaMorphFormer (ODM) which aims to achieve
self-awareness, environment recognition, and action planning through a unified
model architecture. Motivated by cognitive and behavioral psychology, an ODM
agent is able to learn from others, recognize the world, and practice itself
based on its own experience. ODM can also be applied to any arbitrary agent
with a multi-joint body, located in different environments, and trained with
different types of tasks using large-scale pre-trained datasets. Through the
use of pre-trained datasets, ODM can quickly warm up and learn the necessary
knowledge to perform the desired task, while the target environment continues
to reinforce the universal policy. Extensive online experiments as well as
few-shot and zero-shot environmental tests are used to verify ODM's performance
and generalization ability. The results of our study contribute to the study of
general artificial intelligence in embodied and cognitive fields. Code,
results, and video examples can be found on the website
\url{https://rlodm.github.io/odm/}.",2024-09-11,2024,2024-09,environment
Using The Concept Hierarchy for Household Action Recognition,"We propose a method to systematically represent both the static and the
dynamic components of environments, i.e. objects and agents, as well as the
changes that are happening in the environment, i.e. the actions and skills
performed by agents. Our approach, the Concept Hierarchy, provides the
necessary information for autonomous systems to represent environment states,
perform action modeling and recognition, and plan the execution of tasks.
Additionally, the hierarchical structure supports generalization and knowledge
transfer to environments. We rigorously define tasks, actions, skills, and
affordances that enable human-understandable action and skill recognition.",2024-09-13,2024,2024-09,environment
"Curricula for Learning Robust Policies with Factored State
  Representations in Changing Environments","Robust policies enable reinforcement learning agents to effectively adapt to
and operate in unpredictable, dynamic, and ever-changing real-world
environments. Factored representations, which break down complex state and
action spaces into distinct components, can improve generalization and sample
efficiency in policy learning. In this paper, we explore how the curriculum of
an agent using a factored state representation affects the robustness of the
learned policy. We experimentally demonstrate three simple curricula, such as
varying only the variable of highest regret between episodes, that can
significantly enhance policy robustness, offering practical insights for
reinforcement learning in complex environments.",2024-09-13,2024,2024-09,environment
Multi-agent Path Finding in Continuous Environment,"We address a variant of multi-agent path finding in continuous environment
(CE-MAPF), where agents move along sets of smooth curves. Collisions between
agents are resolved via avoidance in the space domain. A new Continuous
Environment Conflict-Based Search (CE-CBS) algorithm is proposed in this work.
CE-CBS combines conflict-based search (CBS) for the high-level search framework
with RRT* for low-level path planning. The CE-CBS algorithm is tested under
various settings on diverse CE-MAPF instances. Experimental results show that
CE-CBS is competitive w.r.t. to other algorithms that consider continuous
aspect in MAPF such as MAPF with continuous time.",2024-09-16,2024,2024-09,environment
"Fundamentals of legislation for autonomous artificial intelligence
  systems","The article proposes a method for forming a dedicated operational context in
course of development and implementation of autonomous corporate management
systems based on example of autonomous systems for a board of directors. The
significant part of the operational context for autonomous company management
systems is the regulatory and legal environment within which corporations
operate. In order to create a special operational context for autonomous
artificial intelligence systems, the wording of local regulatory documents can
be simultaneously presented in two versions: for use by people and for use by
autonomous systems. In this case, the artificial intelligence system will get a
well-defined operational context that allows such a system to perform functions
within the required standards. Local regulations that provide for the specifics
of the joint work of individuals and autonomous artificial intelligence systems
can create the basis of the relevant legislation governing the development and
implementation of autonomous systems.",2024-09-17,2024,2024-09,environment
Cooperative Resilience in Artificial Intelligence Multiagent Systems,"Resilience refers to the ability of systems to withstand, adapt to, and
recover from disruptive events. While studies on resilience have attracted
significant attention across various research domains, the precise definition
of this concept within the field of cooperative artificial intelligence remains
unclear. This paper addresses this gap by proposing a clear definition of
`cooperative resilience' and outlining a methodology for its quantitative
measurement. The methodology is validated in an environment with RL-based and
LLM-augmented autonomous agents, subjected to environmental changes and the
introduction of agents with unsustainable behaviors. These events are
parameterized to create various scenarios for measuring cooperative resilience.
The results highlight the crucial role of resilience metrics in analyzing how
the collective system prepares for, resists, recovers from, sustains
well-being, and transforms in the face of disruptions. These findings provide
foundational insights into the definition, measurement, and preliminary
analysis of cooperative resilience, offering significant implications for the
broader field of AI. Moreover, the methodology and metrics developed here can
be adapted to a wide range of AI applications, enhancing the reliability and
effectiveness of AI in dynamic and unpredictable environments.",2024-09-20,2024,2024-09,environment
"Optimized Monte Carlo Tree Search for Enhanced Decision Making in the
  FrozenLake Environment","Monte Carlo Tree Search (MCTS) is a powerful algorithm for solving complex
decision-making problems. This paper presents an optimized MCTS implementation
applied to the FrozenLake environment, a classic reinforcement learning task
characterized by stochastic transitions. The optimization leverages cumulative
reward and visit count tables along with the Upper Confidence Bound for Trees
(UCT) formula, resulting in efficient learning in a slippery grid world. We
benchmark our implementation against other decision-making algorithms,
including MCTS with Policy and Q-Learning, and perform a detailed comparison of
their performance. The results demonstrate that our optimized approach
effectively maximizes rewards and success rates while minimizing convergence
time, outperforming baseline methods, especially in environments with inherent
randomness.",2024-09-25,2024,2024-09,environment
"Social Conjuring: Multi-User Runtime Collaboration with AI in Building
  Virtual 3D Worlds","Generative artificial intelligence has shown promise in prompting virtual
worlds into existence, yet little attention has been given to understanding how
this process unfolds as social interaction. We present Social Conjurer, a
framework for AI-augmented dynamic 3D scene co-creation, where multiple users
collaboratively build and modify virtual worlds in real-time. Through an
expanded set of interactions, including social and tool-based engagements as
well as spatial reasoning, our framework facilitates the creation of rich,
diverse virtual environments. Findings from a preliminary user study (N=12)
provide insight into the user experience of this approach, how social contexts
shape the prompting of spatial environments, and perspective on social
applications of prompt-based 3D co-creation. In addition to highlighting the
potential of AI-supported multi-user world creation and offering new pathways
for AI-augmented creative processes in VR, this article presents a set of
implications for designing human-centered interfaces that incorporate AI models
into 3D content generation.",2024-09-30,2024,2024-09,environment
"Easydiagnos: a framework for accurate feature selection for automatic
  diagnosis in smart healthcare","The rapid advancements in artificial intelligence (AI) have revolutionized
smart healthcare, driving innovations in wearable technologies, continuous
monitoring devices, and intelligent diagnostic systems. However, security,
explainability, robustness, and performance optimization challenges remain
critical barriers to widespread adoption in clinical environments. This
research presents an innovative algorithmic method using the Adaptive Feature
Evaluator (AFE) algorithm to improve feature selection in healthcare datasets
and overcome problems. AFE integrating Genetic Algorithms (GA), Explainable
Artificial Intelligence (XAI), and Permutation Combination Techniques (PCT),
the algorithm optimizes Clinical Decision Support Systems (CDSS), thereby
enhancing predictive accuracy and interpretability. The proposed method is
validated across three diverse healthcare datasets using six distinct machine
learning algorithms, demonstrating its robustness and superiority over
conventional feature selection techniques. The results underscore the
transformative potential of AFE in smart healthcare, enabling personalized and
transparent patient care. Notably, the AFE algorithm, when combined with a
Multi-layer Perceptron (MLP), achieved an accuracy of up to 98.5%, highlighting
its capability to improve clinical decision-making processes in real-world
healthcare applications.",2024-10-01,2024,2024-10,environment
"A transformer-based deep reinforcement learning approach to spatial
  navigation in a partially observable Morris Water Maze","Navigation is a fundamental cognitive skill extensively studied in
neuroscientific experiments and has lately gained substantial interest in
artificial intelligence research. Recreating the task solved by rodents in the
well-established Morris Water Maze (MWM) experiment, this work applies a
transformer-based architecture using deep reinforcement learning -- an approach
previously unexplored in this context -- to navigate a 2D version of the maze.
Specifically, the agent leverages a decoder-only transformer architecture
serving as a deep Q-network performing effective decision making in the
partially observable environment. We demonstrate that the proposed architecture
enables the agent to efficiently learn spatial navigation strategies,
overcoming challenges associated with a limited field of vision, corresponding
to the visual information available to a rodent in the MWM. Demonstrating the
potential of transformer-based models for enhancing navigation performance in
partially observable environments, this work suggests promising avenues for
future research in artificial agents whose behavior resembles that of
biological agents. Finally, the flexibility of the transformer architecture in
supporting varying input sequence lengths opens opportunities for gaining
increased understanding of the artificial agent's inner representation of the
environment.",2024-10-01,2024,2024-10,environment
"From Reward Shaping to Q-Shaping: Achieving Unbiased Learning with
  LLM-Guided Knowledge","Q-shaping is an extension of Q-value initialization and serves as an
alternative to reward shaping for incorporating domain knowledge to accelerate
agent training, thereby improving sample efficiency by directly shaping
Q-values. This approach is both general and robust across diverse tasks,
allowing for immediate impact assessment while guaranteeing optimality. We
evaluated Q-shaping across 20 different environments using a large language
model (LLM) as the heuristic provider. The results demonstrate that Q-shaping
significantly enhances sample efficiency, achieving a \textbf{16.87\%}
improvement over the best baseline in each environment and a \textbf{253.80\%}
improvement compared to LLM-based reward shaping methods. These findings
establish Q-shaping as a superior and unbiased alternative to conventional
reward shaping in reinforcement learning.",2024-10-02,2024,2024-10,environment
"AI Assistants for Incident Lifecycle in a Microservice Environment: A
  Systematic Literature Review","Incidents in microservice environments can be costly and challenging to
recover from due to their complexity and distributed nature. Recent
advancements in artificial intelligence (AI) offer promising solutions for
improving incident management. This paper systematically reviews primary
studies on AI assistants designed to support different phases of the incident
lifecycle. It highlights successful applications of AI, identifies gaps in
current research, and suggests future opportunities for enhancing incident
management through AI. By examining these studies, the paper aims to provide
insights into the effectiveness of AI tools and their potential to address
ongoing challenges in incident recovery.",2024-10-06,2024,2024-10,environment
"Transition of $Œ±$-mixing in Random Iterations with Applications in
  Queuing Theory","Nonlinear time series models with exogenous regressors are essential in
econometrics, queuing theory, and machine learning, though their statistical
analysis remains incomplete. Key results, such as the law of large numbers and
the functional central limit theorem, are known for weakly dependent variables.
We demonstrate the transfer of mixing properties from the exogenous regressor
to the response via coupling arguments. Additionally, we study Markov chains in
random environments with drift and minorization conditions, even under
non-stationary environments with favorable mixing properties, and apply this
framework to single-server queuing models.",2024-10-07,2024,2024-10,environment
"Towards an Autonomous Surface Vehicle Prototype for Artificial
  Intelligence Applications of Water Quality Monitoring","The use of Autonomous Surface Vehicles, equipped with water quality sensors
and artificial vision systems, allows for a smart and adaptive deployment in
water resources environmental monitoring. This paper presents a real
implementation of a vehicle prototype that to address the use of Artificial
Intelligence algorithms and enhanced sensing techniques for water quality
monitoring. The vehicle is fully equipped with high-quality sensors to measure
water quality parameters and water depth. Furthermore, by means of a
stereo-camera, it also can detect and locate macro-plastics in real
environments by means of deep visual models, such as YOLOv5. In this paper,
experimental results, carried out in Lago Mayor (Sevilla), has been presented
as proof of the capabilities of the proposed architecture. The overall system,
and the early results obtained, are expected to provide a solid example of a
real platform useful for the water resource monitoring task, and to serve as a
real case scenario for deploying Artificial Intelligence algorithms, such as
path planning, artificial vision, etc.",2024-10-08,2024,2024-10,environment
"Impact of Artificial Intelligence on Environmental Quality through
  Technical Change: A Free Dynamic Equilibrium Approach","In the times we live in today, humanity faces unprecedented environmental
challenges. The emergence of artificial intelligence (AI) has opened new doors
in our collective efforts to address our planet's pressing problems; however,
many have doubts on the actual extent of impact that AI have on the
environment. In particular, AI also assisting dirty production is a drawback
that is largely absent from the literature. To investigate the impact of AI on
the environment, we establish mathematical models to model the economy and the
production process of goods based on outdated and advanced technologies. The
secondary results are stated in the form of lemmas, the main results are stated
in the form of theorems. From the theorems we conclude that AI may not on its
own prevent an environmental disaster, a reason of which is its concurrent
contribution to dirty production. With temporary government intervention,
however, AI is able to avert an environmental disaster.",2024-10-09,2024,2024-10,environment
"Adaptive Diffusion Terrain Generator for Autonomous Uneven Terrain
  Navigation","Model-free reinforcement learning has emerged as a powerful method for
developing robust robot control policies capable of navigating through complex
and unstructured terrains. The effectiveness of these methods hinges on two
essential elements: (1) the use of massively parallel physics simulations to
expedite policy training, and (2) an environment generator tasked with crafting
sufficiently challenging yet attainable terrains to facilitate continuous
policy improvement. Existing methods of environment generation often rely on
heuristics constrained by a set of parameters, limiting the diversity and
realism. In this work, we introduce the Adaptive Diffusion Terrain Generator
(ADTG), a novel method that leverages Denoising Diffusion Probabilistic Models
to dynamically expand existing training environments by adding more diverse and
complex terrains adaptive to the current policy. ADTG guides the diffusion
model's generation process through initial noise optimization, blending
noise-corrupted terrains from existing training environments weighted by the
policy's performance in each corresponding environment. By manipulating the
noise corruption level, ADTG seamlessly transitions between generating similar
terrains for policy fine-tuning and novel ones to expand training diversity.
Our experiments show that the policy trained by ADTG outperforms both
procedural generated and natural environments, along with popular navigation
methods.",2024-10-14,2024,2024-10,environment
"ASTM :Autonomous Smart Traffic Management System Using Artificial
  Intelligence CNN and LSTM","In the modern world, the development of Artificial Intelligence (AI) has
contributed to improvements in various areas, including automation, computer
vision, fraud detection, and more. AI can be leveraged to enhance the
efficiency of Autonomous Smart Traffic Management (ASTM) systems and reduce
traffic congestion rates. This paper presents an Autonomous Smart Traffic
Management (STM) system that uses AI to improve traffic flow rates. The system
employs the YOLO V5 Convolutional Neural Network to detect vehicles in traffic
management images. Additionally, it predicts the number of vehicles for the
next 12 hours using a Recurrent Neural Network with Long Short-Term Memory
(RNN-LSTM). The Smart Traffic Management Cycle Length Analysis manages the
traffic cycle length based on these vehicle predictions, aided by AI. From the
results of the RNN-LSTM model for predicting vehicle numbers over the next 12
hours, we observe that the model predicts traffic with a Mean Squared Error
(MSE) of 4.521 vehicles and a Root Mean Squared Error (RMSE) of 2.232 vehicles.
After simulating the STM system in the CARLA simulation environment, we found
that the Traffic Management Congestion Flow Rate with ASTM (21 vehicles per
minute) is 50\% higher than the rate without STM (around 15 vehicles per
minute). Additionally, the Traffic Management Vehicle Pass Delay with STM (5
seconds per vehicle) is 70\% lower than without STM (around 12 seconds per
vehicle). These results demonstrate that the STM system using AI can increase
traffic flow by 50\% and reduce vehicle pass delays by 70\%.",2024-10-14,2024,2024-10,environment
Privacy-Preserving Decentralized AI with Confidential Computing,"This paper addresses privacy protection in decentralized Artificial
Intelligence (AI) using Confidential Computing (CC) within the Atoma Network, a
decentralized AI platform designed for the Web3 domain. Decentralized AI
distributes AI services among multiple entities without centralized oversight,
fostering transparency and robustness. However, this structure introduces
significant privacy challenges, as sensitive assets such as proprietary models
and personal data may be exposed to untrusted participants. Cryptography-based
privacy protection techniques such as zero-knowledge machine learning (zkML)
suffers prohibitive computational overhead. To address the limitation, we
propose leveraging Confidential Computing (CC). Confidential Computing
leverages hardware-based Trusted Execution Environments (TEEs) to provide
isolation for processing sensitive data, ensuring that both model parameters
and user data remain secure, even in decentralized, potentially untrusted
environments. While TEEs face a few limitations, we believe they can bridge the
privacy gap in decentralized AI. We explore how we can integrate TEEs into
Atoma's decentralized framework.",2024-10-17,2024,2024-10,environment
Online Reinforcement Learning with Passive Memory,"This paper considers an online reinforcement learning algorithm that
leverages pre-collected data (passive memory) from the environment for online
interaction. We show that using passive memory improves performance and further
provide theoretical guarantees for regret that turns out to be near-minimax
optimal. Results show that the quality of passive memory determines
sub-optimality of the incurred regret. The proposed approach and results hold
in both continuous and discrete state-action spaces.",2024-10-18,2024,2024-10,environment
CybORG++: An Enhanced Gym for the Development of Autonomous Cyber Agents,"CybORG++ is an advanced toolkit for reinforcement learning research focused
on network defence. Building on the CAGE 2 CybORG environment, it introduces
key improvements, including enhanced debugging capabilities, refined agent
implementation support, and a streamlined environment that enables faster
training and easier customisation. Along with addressing several software bugs
from its predecessor, CybORG++ introduces MiniCAGE, a lightweight version of
CAGE 2, which improves performance dramatically, up to 1000x faster execution
in parallel iterations, without sacrificing accuracy or core functionality.
CybORG++ serves as a robust platform for developing and evaluating defensive
agents, making it a valuable resource for advancing enterprise network defence
research.",2024-10-18,2024,2024-10,environment
"Benchmarking Deep Reinforcement Learning for Navigation in Denied Sensor
  Environments","Deep Reinforcement learning (DRL) is used to enable autonomous navigation in
unknown environments. Most research assume perfect sensor data, but real-world
environments may contain natural and artificial sensor noise and denial. Here,
we present a benchmark of both well-used and emerging DRL algorithms in a
navigation task with configurable sensor denial effects. In particular, we are
interested in comparing how different DRL methods (e.g. model-free PPO vs.
model-based DreamerV3) are affected by sensor denial. We show that DreamerV3
outperforms other methods in the visual end-to-end navigation task with a
dynamic goal - and other methods are not able to learn this. Furthermore,
DreamerV3 generally outperforms other methods in sensor-denied environments. In
order to improve robustness, we use adversarial training and demonstrate an
improved performance in denied environments, although this generally comes with
a performance cost on the vanilla environments. We anticipate this benchmark of
different DRL methods and the usage of adversarial training to be a starting
point for the development of more elaborate navigation strategies that are
capable of dealing with uncertain and denied sensor readings.",2024-10-18,2024,2024-10,environment
MAC Revivo: Artificial Intelligence Paves the Way,"The vast adoption of Wi-Fi and/or Bluetooth capabilities in Internet of
Things (IoT) devices, along with the rapid growth of deployed smart devices,
has caused significant interference and congestion in the industrial,
scientific, and medical (ISM) bands. Traditional Wi-Fi Medium Access Control
(MAC) design faces significant challenges in managing increasingly complex
wireless environments while ensuring network Quality of Service (QoS)
performance. This paper explores the potential integration of advanced
Artificial Intelligence (AI) methods into the design of Wi-Fi MAC protocols. We
propose AI-MAC, an innovative approach that employs machine learning algorithms
to dynamically adapt to changing network conditions, optimize channel access,
mitigate interference, and ensure deterministic latency. By intelligently
predicting and managing interference, AI-MAC aims to provide a robust solution
for next generation of Wi-Fi networks, enabling seamless connectivity and
enhanced QoS. Our experimental results demonstrate that AI-MAC significantly
reduces both interference and latency, paving the way for more reliable and
efficient wireless communications in the increasingly crowded ISM band.",2024-10-21,2024,2024-10,environment
"DyPNIPP: Predicting Environment Dynamics for RL-based Robust Informative
  Path Planning","Informative path planning (IPP) is an important planning paradigm for various
real-world robotic applications such as environment monitoring. IPP involves
planning a path that can learn an accurate belief of the quantity of interest,
while adhering to planning constraints. Traditional IPP methods typically
require high computation time during execution, giving rise to reinforcement
learning (RL) based IPP methods. However, the existing RL-based methods do not
consider spatio-temporal environments which involve their own challenges due to
variations in environment characteristics. In this paper, we propose DyPNIPP, a
robust RL-based IPP framework, designed to operate effectively across
spatio-temporal environments with varying dynamics. To achieve this, DyPNIPP
incorporates domain randomization to train the agent across diverse
environments and introduces a dynamics prediction model to capture and adapt
the agent actions to specific environment dynamics. Our extensive experiments
in a wildfire environment demonstrate that DyPNIPP outperforms existing
RL-based IPP algorithms by significantly improving robustness and performing
across diverse environment conditions.",2024-10-22,2024,2024-10,environment
"Enhancing Two-Player Performance Through Single-Player Knowledge
  Transfer: An Empirical Study on Atari 2600 Games","Playing two-player games using reinforcement learning and self-play can be
challenging due to the complexity of two-player environments and the possible
instability in the training process. We propose that a reinforcement learning
algorithm can train more efficiently and achieve improved performance in a
two-player game if it leverages the knowledge from the single-player version of
the same game. This study examines the proposed idea in ten different Atari
2600 environments using the Atari 2600 RAM as the input state. We discuss the
advantages of using transfer learning from a single-player training process
over training in a two-player setting from scratch, and demonstrate our results
in a few measures such as training time and average total reward. We also
discuss a method of calculating RAM complexity and its relationship to
performance.",2024-10-22,2024,2024-10,environment
"PyTSC: A Unified Platform for Multi-Agent Reinforcement Learning in
  Traffic Signal Control","Multi-Agent Reinforcement Learning (MARL) presents a promising approach for
addressing the complexity of Traffic Signal Control (TSC) in urban
environments. However, existing platforms for MARL-based TSC research face
challenges such as slow simulation speeds and convoluted, difficult-to-maintain
codebases. To address these limitations, we introduce PyTSC, a robust and
flexible simulation environment that facilitates the training and evaluation of
MARL algorithms for TSC. PyTSC integrates multiple simulators, such as SUMO and
CityFlow, and offers a streamlined API, empowering researchers to explore a
broad spectrum of MARL approaches efficiently. PyTSC accelerates
experimentation and provides new opportunities for advancing intelligent
traffic management systems in real-world applications.",2024-10-23,2024,2024-10,environment
Adversarial Environment Design via Regret-Guided Diffusion Models,"Training agents that are robust to environmental changes remains a
significant challenge in deep reinforcement learning (RL). Unsupervised
environment design (UED) has recently emerged to address this issue by
generating a set of training environments tailored to the agent's capabilities.
While prior works demonstrate that UED has the potential to learn a robust
policy, their performance is constrained by the capabilities of the environment
generation. To this end, we propose a novel UED algorithm, adversarial
environment design via regret-guided diffusion models (ADD). The proposed
method guides the diffusion-based environment generator with the regret of the
agent to produce environments that the agent finds challenging but conducive to
further improvement. By exploiting the representation power of diffusion
models, ADD can directly generate adversarial environments while maintaining
the diversity of training environments, enabling the agent to effectively learn
a robust policy. Our experimental results demonstrate that the proposed method
successfully generates an instructive curriculum of environments, outperforming
UED baselines in zero-shot generalization across novel, out-of-distribution
environments. Project page: https://rllab-snu.github.io/projects/ADD",2024-10-25,2024,2024-10,environment
Generative AI for Accessible and Inclusive Extended Reality,"Artificial Intelligence-Generated Content (AIGC) has the potential to
transform how people build and interact with virtual environments. Within this
paper, we discuss potential benefits but also challenges that AIGC has for the
creation of inclusive and accessible virtual environments. Specifically, we
touch upon the decreased need for 3D modeling expertise, benefits of
symbolic-only as well as multimodal input, 3D content editing, and 3D model
accessibility as well as foundation model-specific challenges.",2024-10-31,2024,2024-10,environment
"COST CA20120 INTERACT Framework of Artificial Intelligence Based Channel
  Modeling","Accurate channel models are the prerequisite for communication-theoretic
investigations as well as system design. Channel modeling generally relies on
statistical and deterministic approaches. However, there are still significant
limits for the traditional modeling methods in terms of accuracy,
generalization ability, and computational complexity. The fundamental reason is
that establishing a quantified and accurate mapping between physical
environment and channel characteristics becomes increasing challenging for
modern communication systems. Here, in the context of COST CA20120 Action, we
evaluate and discuss the feasibility and implementation of using artificial
intelligence (AI) for channel modeling, and explore where the future of this
field lies. Firstly, we present a framework of AI-based channel modeling to
characterize complex wireless channels. Then, we highlight in detail some major
challenges and present the possible solutions: i) estimating the uncertainty of
AI-based channel predictions, ii) integrating prior knowledge of propagation to
improve generalization capabilities, and iii) interpretable AI for channel
modeling. We present and discuss illustrative numerical results to showcase the
capabilities of AI-based channel modeling.",2024-10-31,2024,2024-10,environment
"Simulation of Nanorobots with Artificial Intelligence and Reinforcement
  Learning for Advanced Cancer Cell Detection and Tracking","Nanorobots are a promising development in targeted drug delivery and the
treatment of neurological disorders, with potential for crossing the
blood-brain barrier (BBB). These small devices leverage advancements in
nanotechnology and bioengineering for precise navigation and targeted payload
delivery, particularly for conditions like brain tumors, Alzheimer's disease,
and Parkinson's disease. Recent progress in artificial intelligence (AI) and
machine learning (ML) has improved the navigation and effectiveness of
nanorobots, allowing them to detect and interact with cancer cells through
biomarker analysis. This study presents a new reinforcement learning (RL)
framework for optimizing nanorobot navigation in complex biological
environments, focusing on cancer cell detection by analyzing the concentration
gradients of surrounding biomarkers. We utilize a computer simulation model to
explore the behavior of nanorobots in a three-dimensional space with cancer
cells and biological barriers. The proposed method uses Q-learning to refine
movement strategies based on real-time biomarker concentration data, enabling
nanorobots to autonomously navigate to cancerous tissues for targeted drug
delivery. This research lays the groundwork for future laboratory experiments
and clinical applications, with implications for personalized medicine and less
invasive cancer treatments. The integration of intelligent nanorobots could
revolutionize therapeutic strategies, reducing side effects and enhancing
treatment effectiveness for cancer patients. Further research will investigate
the practical deployment of these technologies in medical settings, aiming to
unlock the full potential of nanorobotics in healthcare.",2024-11-04,2024,2024-11,environment
Eurekaverse: Environment Curriculum Generation via Large Language Models,"Recent work has demonstrated that a promising strategy for teaching robots a
wide range of complex skills is by training them on a curriculum of
progressively more challenging environments. However, developing an effective
curriculum of environment distributions currently requires significant
expertise, which must be repeated for every new domain. Our key insight is that
environments are often naturally represented as code. Thus, we probe whether
effective environment curriculum design can be achieved and automated via code
generation by large language models (LLM). In this paper, we introduce
Eurekaverse, an unsupervised environment design algorithm that uses LLMs to
sample progressively more challenging, diverse, and learnable environments for
skill training. We validate Eurekaverse's effectiveness in the domain of
quadrupedal parkour learning, in which a quadruped robot must traverse through
a variety of obstacle courses. The automatic curriculum designed by Eurekaverse
enables gradual learning of complex parkour skills in simulation and can
successfully transfer to the real-world, outperforming manual training courses
designed by humans.",2024-11-04,2024,2024-11,environment
"Evaluating Robustness of Reinforcement Learning Algorithms for
  Autonomous Shipping","Recently, there has been growing interest in autonomous shipping due to its
potential to improve maritime efficiency and safety. The use of advanced
technologies, such as artificial intelligence, can address the current
navigational and operational challenges in autonomous shipping. In particular,
inland waterway transport (IWT) presents a unique set of challenges, such as
crowded waterways and variable environmental conditions. In such dynamic
settings, the reliability and robustness of autonomous shipping solutions are
critical factors for ensuring safe operations. This paper examines the
robustness of benchmark deep reinforcement learning (RL) algorithms,
implemented for IWT within an autonomous shipping simulator, and their ability
to generate effective motion planning policies. We demonstrate that a
model-free approach can achieve an adequate policy in the simulator,
successfully navigating port environments never encountered during training. We
focus particularly on Soft-Actor Critic (SAC), which we show to be inherently
more robust to environmental disturbances compared to MuZero, a
state-of-the-art model-based RL algorithm. In this paper, we take a significant
step towards developing robust, applied RL frameworks that can be generalized
to various vessel types and navigate complex port- and inland environments and
scenarios.",2024-11-07,2024,2024-11,environment
"Development of a Human-Robot Interaction Platform for Dual-Arm Robots
  Based on ROS and Multimodal Artificial Intelligence","In this paper, we propose the development of an interactive platform between
humans and a dual-arm robotic system based on the Robot Operating System (ROS)
and a multimodal artificial intelligence model. Our proposed platform consists
of two main components: a dual-arm robotic hardware system and software that
includes image processing tasks and natural language processing using a 3D
camera and embedded computing. First, we designed and developed a dual-arm
robotic system with a positional accuracy of less than 2 cm, capable of
operating independently, performing industrial and service tasks while
simultaneously simulating and modeling the robot in the ROS environment.
Second, artificial intelligence models for image processing are integrated to
execute object picking and classification tasks with an accuracy of over 90%.
Finally, we developed remote control software using voice commands through a
natural language processing model. Experimental results demonstrate the
accuracy of the multimodal artificial intelligence model and the flexibility of
the dual-arm robotic system in interactive human environments.",2024-11-08,2024,2024-11,environment
Artificial Intelligence Ecosystem for Automating Self-Directed Teaching,"This research introduces an innovative artificial intelligence-driven
educational concept designed to optimize self-directed learning through
personalized course delivery and automated teaching assistance. The system
leverages fine-tuned AI models to create an adaptive learning environment that
encompasses customized roadmaps, automated presentation generation, and
three-dimensional modeling for complex concept visualization. By integrating
real-time virtual assistance for doubt resolution, the platform addresses the
immediate educational needs of learners while promoting autonomous learning
practices. This study explores the psychological advantages of self-directed
learning and demonstrates how AI automation can enhance educational outcomes
through personalized content delivery and interactive support mechanisms. The
research contributes to the growing field of educational technology by
presenting a comprehensive framework that combines automated content
generation, visual learning aids, and intelligent tutoring to create an
efficient, scalable solution for modern educational needs. Preliminary findings
suggest that this approach not only accommodates diverse learning styles but
also strengthens student engagement and knowledge retention through its
emphasis on self-paced, independent learning methodologies.",2024-11-11,2024,2024-11,environment
"Bio-inspired AI: Integrating Biological Complexity into Artificial
  Intelligence","The pursuit of creating artificial intelligence (AI) mirrors our longstanding
fascination with understanding our own intelligence. From the myths of Talos to
Aristotelian logic and Heron's inventions, we have sought to replicate the
marvels of the mind. While recent advances in AI hold promise, singular
approaches often fall short in capturing the essence of intelligence. This
paper explores how fundamental principles from biological
computation--particularly context-dependent, hierarchical information
processing, trial-and-error heuristics, and multi-scale organization--can guide
the design of truly intelligent systems. By examining the nuanced mechanisms of
biological intelligence, such as top-down causality and adaptive interaction
with the environment, we aim to illuminate potential limitations in artificial
constructs. Our goal is to provide a framework inspired by biological systems
for designing more adaptable and robust artificial intelligent systems.",2024-11-22,2024,2024-11,environment
Probing for Consciousness in Machines,"This study explores the potential for artificial agents to develop core
consciousness, as proposed by Antonio Damasio's theory of consciousness.
According to Damasio, the emergence of core consciousness relies on the
integration of a self model, informed by representations of emotions and
feelings, and a world model. We hypothesize that an artificial agent, trained
via reinforcement learning (RL) in a virtual environment, can develop
preliminary forms of these models as a byproduct of its primary task. The
agent's main objective is to learn to play a video game and explore the
environment. To evaluate the emergence of world and self models, we employ
probes-feedforward classifiers that use the activations of the trained agent's
neural networks to predict the spatial positions of the agent itself. Our
results demonstrate that the agent can form rudimentary world and self models,
suggesting a pathway toward developing machine consciousness. This research
provides foundational insights into the capabilities of artificial agents in
mirroring aspects of human consciousness, with implications for future
advancements in artificial intelligence.",2024-11-25,2024,2024-11,environment
"Characterized Diffusion Networks for Enhanced Autonomous Driving
  Trajectory Prediction","In this paper, we present a novel trajectory prediction model for autonomous
driving, combining a Characterized Diffusion Module and a Spatial-Temporal
Interaction Network to address the challenges posed by dynamic and
heterogeneous traffic environments. Our model enhances the accuracy and
reliability of trajectory predictions by incorporating uncertainty estimation
and complex agent interactions. Through extensive experimentation on public
datasets such as NGSIM, HighD, and MoCAD, our model significantly outperforms
existing state-of-the-art methods. We demonstrate its ability to capture the
underlying spatial-temporal dynamics of traffic scenarios and improve
prediction precision, especially in complex environments. The proposed model
showcases strong potential for application in real-world autonomous driving
systems.",2024-11-25,2024,2024-11,environment
"Publication Trends in Artificial Intelligence Conferences: The Rise of
  Super Prolific Authors","Papers published in top conferences contribute influential discoveries that
are reshaping the landscape of modern Artificial Intelligence (AI). We analyzed
87,137 papers from 11 AI conferences to examine publication trends over the
past decade. Our findings reveal a consistent increase in both the number of
papers and authors, reflecting the growing interest in AI research. We also
observed a rise in prolific researchers who publish dozens of papers at the
same conference each year. In light of this analysis, the AI research community
should consider revisiting authorship policies, addressing equity concerns, and
evaluating the workload of junior researchers to foster a more sustainable and
inclusive research environment.",2024-11-28,2024,2024-11,environment
"An Integrated Artificial Intelligence Operating System for Advanced
  Low-Altitude Aviation Applications","This paper introduces a high-performance artificial intelligence operating
system tailored for low-altitude aviation, designed to address key challenges
such as real-time task execution, computational efficiency, and seamless
modular collaboration. Built on a powerful hardware platform and leveraging the
UNIX architecture, the system implements a distributed data processing strategy
that ensures rapid and efficient synchronization across critical modules,
including vision, navigation, and perception. By adopting dynamic resource
management, it optimally allocates computational resources, such as CPU and
GPU, based on task priority and workload, ensuring high performance for
demanding tasks like real-time video processing and AI model inference.
Furthermore, the system features an advanced interrupt handling mechanism that
allows for quick responses to sudden environmental changes, such as obstacle
detection, by prioritizing critical tasks, thus improving safety and mission
success rates. Robust security measures, including data encryption, access
control, and fault tolerance, ensure the system's resilience against external
threats and its ability to recover from potential hardware or software
failures. Complementing these core features are modular components for image
analysis, multi-sensor fusion, dynamic path planning, multi-drone coordination,
and ground station monitoring. Additionally, a low-code development platform
simplifies user customization, making the system adaptable to various
mission-specific needs. This comprehensive approach ensures the system meets
the evolving demands of intelligent aviation, providing a stable, efficient,
and secure environment for complex drone operations.",2024-11-28,2024,2024-11,environment
"More complex environments may be required to discover benefits of
  lifetime learning in evolving robots","It is well known that intra-life learning, defined as an additional
controller optimization loop, is beneficial for evolving robot morphologies for
locomotion. In this work, we investigate this further by comparing it in two
different environments: an easy flat environment and a more challenging hills
environment. We show that learning is significantly more beneficial in a hilly
environment than in a flat environment and that it might be needed to evaluate
robots in a more challenging environment to see the benefits of learning.",2024-12-11,2024,2024-12,environment
Survey on safe robot control via learning,"Control systems are critical to modern technological infrastructure, spanning
industries from aerospace to healthcare. This survey explores the landscape of
safe robot learning, investigating methods that balance high-performance
control with rigorous safety constraints. By examining classical control
techniques, learning-based approaches, and embedded system design, the research
seeks to understand how robotic systems can be developed to prevent hazardous
states while maintaining optimal performance across complex operational
environments.",2024-12-16,2024,2024-12,environment
"Future Research Avenues for Artificial Intelligence in Digital Gaming:
  An Exploratory Report","Video games are a natural and synergistic application domain for artificial
intelligence (AI) systems, offering both the potential to enhance player
experience and immersion, as well as providing valuable benchmarks and virtual
environments to advance AI technologies in general. This report presents a
high-level overview of five promising research pathways for applying
state-of-the-art AI methods, particularly deep learning, to digital gaming
within the context of the current research landscape. The objective of this
work is to outline a curated, non-exhaustive list of encouraging research
directions at the intersection of AI and video games that may serve to inspire
more rigorous and comprehensive research efforts in the future. We discuss (i)
investigating large language models as core engines for game agent modelling,
(ii) using neural cellular automata for procedural game content generation,
(iii) accelerating computationally expensive in-game simulations via deep
surrogate modelling, (iv) leveraging self-supervised learning to obtain useful
video game state embeddings, and (v) training generative models of interactive
worlds using unlabelled video data. We also briefly address current technical
challenges associated with the integration of advanced deep learning systems
into video game development, and indicate key areas where further progress is
likely to be beneficial.",2024-12-18,2024,2024-12,environment
Investigating Relational State Abstraction in Collaborative MARL,"This paper explores the impact of relational state abstraction on sample
efficiency and performance in collaborative Multi-Agent Reinforcement Learning.
The proposed abstraction is based on spatial relationships in environments
where direct communication between agents is not allowed, leveraging the
ubiquity of spatial reasoning in real-world multi-agent scenarios. We introduce
MARC (Multi-Agent Relational Critic), a simple yet effective critic
architecture incorporating spatial relational inductive biases by transforming
the state into a spatial graph and processing it through a relational graph
neural network. The performance of MARC is evaluated across six collaborative
tasks, including a novel environment with heterogeneous agents. We conduct a
comprehensive empirical analysis, comparing MARC against state-of-the-art MARL
baselines, demonstrating improvements in both sample efficiency and asymptotic
performance, as well as its potential for generalization. Our findings suggest
that a minimal integration of spatial relational inductive biases as
abstraction can yield substantial benefits without requiring complex designs or
task-specific engineering. This work provides insights into the potential of
relational state abstraction to address sample efficiency, a key challenge in
MARL, offering a promising direction for developing more efficient algorithms
in spatially complex environments.",2024-12-19,2024,2024-12,environment
Towards an Environmental Ethics of Artificial Intelligence,"In recent years, much research has been dedicated to uncovering the
environmental impact of Artificial Intelligence (AI), showing that training and
deploying AI systems require large amounts of energy and resources, and the
outcomes of AI may lead to decisions and actions that may negatively impact the
environment. This new knowledge raises new ethical questions, such as: When is
it (un)justifiable to develop an AI system, and how to make design choices,
considering its environmental impact? However, so far, the environmental impact
of AI has largely escaped ethical scrutiny, as AI ethics tends to focus
strongly on themes such as transparency, privacy, safety, responsibility, and
bias. Considering the environmental impact of AI from an ethical perspective
expands the scope of AI ethics beyond an anthropocentric focus towards
including more-than-human actors such as animals and ecosystems. This paper
explores the ethical implications of the environmental impact of AI for
designing AI systems by drawing on environmental justice literature, in which
three categories of justice are distinguished, referring to three elements that
can be unjust: the distribution of benefits and burdens (distributive justice),
decision-making procedures (procedural justice), and institutionalized social
norms (justice as recognition). Based on these tenets of justice, we outline
criteria for developing environmentally just AI systems, given their ecological
impact.",2024-12-19,2024,2024-12,environment
"Generalized Back-Stepping Experience Replay in Sparse-Reward
  Environments","Back-stepping experience replay (BER) is a reinforcement learning technique
that can accelerate learning efficiency in reversible environments. BER trains
an agent with generated back-stepping transitions of collected experiences and
normal forward transitions. However, the original algorithm is designed for a
dense-reward environment that does not require complex exploration, limiting
the BER technique to demonstrate its full potential. Herein, we propose an
enhanced version of BER called Generalized BER (GBER), which extends the
original algorithm to sparse-reward environments, particularly those with
complex structures that require the agent to explore. GBER improves the
performance of BER by introducing relabeling mechanism and applying diverse
sampling strategies. We evaluate our modified version, which is based on a
goal-conditioned deep deterministic policy gradient offline learning algorithm,
across various maze navigation environments. The experimental results indicate
that the GBER algorithm can significantly boost the performance and stability
of the baseline algorithm in various sparse-reward environments, especially
those with highly structural symmetricity.",2024-12-20,2024,2024-12,environment
"A Method for the Runtime Validation of AI-based Environment Perception
  in Automated Driving System","Environment perception is a fundamental part of the dynamic driving task
executed by Autonomous Driving Systems (ADS). Artificial Intelligence
(AI)-based approaches have prevailed over classical techniques for realizing
the environment perception. Current safety-relevant standards for automotive
systems, International Organization for Standardization (ISO) 26262 and ISO
21448, assume the existence of comprehensive requirements specifications. These
specifications serve as the basis on which the functionality of an automotive
system can be rigorously tested and checked for compliance with safety
regulations. However, AI-based perception systems do not have complete
requirements specification. Instead, large datasets are used to train AI-based
perception systems. This paper presents a function monitor for the functional
runtime monitoring of a two-folded AI-based environment perception for ADS,
based respectively on camera and LiDAR sensors. To evaluate the applicability
of the function monitor, we conduct a qualitative scenario-based evaluation in
a controlled laboratory environment using a model car. The evaluation results
then are discussed to provide insights into the monitor's performance and its
suitability for real-world applications.",2024-12-21,2024,2024-12,environment
"Environment Descriptions for Usability and Generalisation in
  Reinforcement Learning","The majority of current reinforcement learning (RL) research involves
training and deploying agents in environments that are implemented by engineers
in general-purpose programming languages and more advanced frameworks such as
CUDA or JAX. This makes the application of RL to novel problems of interest
inaccessible to small organisations or private individuals with insufficient
engineering expertise. This position paper argues that, to enable more
widespread adoption of RL, it is important for the research community to shift
focus towards methodologies where environments are described in user-friendly
domain-specific or natural languages. Aside from improving the usability of RL,
such language-based environment descriptions may also provide valuable context
and boost the ability of trained agents to generalise to unseen environments
within the set of all environments that can be described in any language of
choice.",2024-12-22,2024,2024-12,environment
Exploring Flexible Scenario Generation in Godot Simulator,"Cyber-physical systems (CPS) combine cyber and physical components engineered
to make decisions and interact within dynamic environments. Ensuring the safety
of CPS is of great importance, requiring extensive testing across diverse and
complex scenarios. To generate as many testing scenarios as possible, previous
efforts have focused on describing scenarios using formal languages to generate
scenes. In this paper, we introduce an alternative approach: reconstructing
scenes inside the open-source game engine, Godot. We have developed a pipeline
that enables the reconstruction of testing scenes directly from provided images
of scenarios. These reconstructed scenes can then be deployed within simulated
environments to assess a CPS. This approach offers a scalable and flexible
solution for testing CPS in realistic environments.",2024-12-24,2024,2024-12,environment
"How Do Artificial Intelligences Think? The Three Mathematico-Cognitive
  Factors of Categorical Segmentation Operated by Synthetic Neurons","How do the synthetic neurons in language models create ""thought categories""
to segment and analyze their informational environment? What are the cognitive
characteristics, at the very level of formal neurons, of this artificial
categorical thought? Based on the mathematical nature of algebraic operations
inherent to neuronal aggregation functions, we attempt to identify
mathematico-cognitive factors that genetically shape the categorical
reconstruction of the informational world faced by artificial cognition. This
study explores these concepts through the notions of priming, attention, and
categorical phasing.",2024-12-26,2024,2024-12,environment
"Towards General Purpose Robots at Scale: Lifelong Learning and Learning
  to Use Memory","The widespread success of artificial intelligence in fields like natural
language processing and computer vision has not yet fully transferred to
robotics, where progress is hindered by the lack of large-scale training data
and the complexity of real-world tasks. To address this, many robot learning
researchers are pushing to get robots deployed at scale in everyday
unstructured environments like our homes to initiate a data flywheel. While
current robot learning systems are effective for certain short-horizon tasks,
they are not designed to autonomously operate over long time horizons in
unstructured environments. This thesis focuses on addressing two key challenges
for robots operating over long time horizons: memory and lifelong learning.
  We propose two novel methods to advance these capabilities. First, we
introduce t-DGR, a trajectory-based deep generative replay method that achieves
state-of-the-art performance on Continual World benchmarks, advancing lifelong
learning. Second, we develop a framework that leverages human demonstrations to
teach agents effective memory utilization, improving learning efficiency and
success rates on Memory Gym tasks. Finally, we discuss future directions for
achieving the lifelong learning and memory capabilities necessary for robots to
function at scale in real-world settings.",2024-12-28,2024,2024-12,environment
"Ontology-supported processing of clinical text using medical knowledge
  integration for multi-label classification of diagnosis coding","This paper discusses the knowledge integration of clinical information
extracted from distributed medical ontology in order to ameliorate a machine
learning-based multi-label coding assignment system. The proposed approach is
implemented using a decision tree based cascade hierarchical technique on the
university hospital data for patients with Coronary Heart Disease (CHD). The
preliminary results obtained show a satisfactory finding.",2010-04-08,2010,2010-04,medical
Using Semantic Wikis for Structured Argument in Medical Domain,"This research applies ideas from argumentation theory in the context of
semantic wikis, aiming to provide support for structured-large scale
argumentation between human agents. The implemented prototype is exemplified by
modelling the MMR vaccine controversy.",2010-12-08,2010,2010-12,medical
Variational Probabilistic Inference and the QMR-DT Network,"We describe a variational approximation method for efficient inference in
large-scale probabilistic models. Variational methods are deterministic
procedures that provide approximations to marginal and conditional
probabilities of interest. They provide alternatives to approximate inference
methods based on stochastic sampling or search. We describe a variational
approach to the problem of diagnostic inference in the `Quick Medical
Reference' (QMR) network. The QMR network is a large-scale probabilistic
graphical model built on statistical and expert knowledge. Exact probabilistic
inference is infeasible in this model for all but a small set of cases. We
evaluate our variational inference algorithm on a large set of diagnostic test
cases, comparing the algorithm to a state-of-the-art stochastic sampling
method.",2011-05-27,2011,2011-05,medical
Expert-Guided Subgroup Discovery: Methodology and Application,"This paper presents an approach to expert-guided subgroup discovery. The main
step of the subgroup discovery process, the induction of subgroup descriptions,
is performed by a heuristic beam search algorithm, using a novel parametrized
definition of rule quality which is analyzed in detail. The other important
steps of the proposed subgroup discovery process are the detection of
statistically significant properties of selected subgroups and subgroup
visualization: statistically significant properties are used to enrich the
descriptions of induced subgroups, while the visualization shows subgroup
properties in the form of distributions of the numbers of examples in the
subgroups. The approach is illustrated by the results obtained for a medical
problem of early detection of patient risk groups.",2011-06-22,2011,2011-06,medical
"Modeling Multiple Annotator Expertise in the Semi-Supervised Learning
  Scenario","Learning algorithms normally assume that there is at most one annotation or
label per data point. However, in some scenarios, such as medical diagnosis and
on-line collaboration,multiple annotations may be available. In either case,
obtaining labels for data points can be expensive and time-consuming (in some
circumstances ground-truth may not exist). Semi-supervised learning approaches
have shown that utilizing the unlabeled data is often beneficial in these
cases. This paper presents a probabilistic semi-supervised model and algorithm
that allows for learning from both unlabeled and labeled data in the presence
of multiple annotators. We assume that it is known what annotator labeled which
data points. The proposed approach produces annotator models that allow us to
provide (1) estimates of the true label and (2) annotator variable expertise
for both labeled and unlabeled data. We provide numerical comparisons under
various scenarios and with respect to standard semi-supervised learning.
Experiments showed that the presented approach provides clear advantages over
multi-annotator methods that do not use the unlabeled data and over methods
that do not use multi-labeler information.",2012-03-15,2012,2012-03,medical
"Demand-Driven Clustering in Relational Domains for Predicting Adverse
  Drug Events","Learning from electronic medical records (EMR) is challenging due to their
relational nature and the uncertain dependence between a patient's past and
future health status. Statistical relational learning is a natural fit for
analyzing EMRs but is less adept at handling their inherent latent structure,
such as connections between related medications or diseases. One way to capture
the latent structure is via a relational clustering of objects. We propose a
novel approach that, instead of pre-clustering the objects, performs a
demand-driven clustering during learning. We evaluate our algorithm on three
real-world tasks where the goal is to use EMRs to predict whether a patient
will have an adverse reaction to a medication. We find that our approach is
more accurate than performing no clustering, pre-clustering, and using
expert-constructed medical heterarchies.",2012-06-27,2012,2012-06,medical
A Non-Parametric Bayesian Method for Inferring Hidden Causes,"We present a non-parametric Bayesian approach to structure learning with
hidden causes. Previous Bayesian treatments of this problem define a prior over
the number of hidden causes and use algorithms such as reversible jump Markov
chain Monte Carlo to move between solutions. In contrast, we assume that the
number of hidden causes is unbounded, but only a finite number influence
observable variables. This makes it possible to use a Gibbs sampler to
approximate the distribution over causal structures. We evaluate the
performance of both approaches in discovering hidden causes in simulated data,
and use our non-parametric approach to discover hidden causes in a real medical
dataset.",2012-06-27,2012,2012-06,medical
Rule Based Expert System for Cerebral Palsy Diagnosis,"The use of Artificial Intelligence is finding prominence not only in core
computer areas, but also in cross disciplinary areas including medical
diagnosis. In this paper, we present a rule based Expert System used in
diagnosis of Cerebral Palsy. The expert system takes user input and depending
on the symptoms of the patient, diagnoses if the patient is suffering from
Cerebral Palsy. The Expert System also classifies the Cerebral Palsy as mild,
moderate or severe based on the presented symptoms.",2012-06-30,2012,2012-06,medical
"Dynamic Decision Support System Based on Bayesian Networks Application
  to fight against the Nosocomial Infections","The improvement of medical care quality is a significant interest for the
future years. The fight against nosocomial infections (NI) in the intensive
care units (ICU) is a good example. We will focus on a set of observations
which reflect the dynamic aspect of the decision, result of the application of
a Medical Decision Support System (MDSS). This system has to make dynamic
decision on temporal data. We use dynamic Bayesian network (DBN) to model this
dynamic process. It is a temporal reasoning within a real-time environment; we
are interested in the Dynamic Decision Support Systems in healthcare domain
(MDDSS).",2012-11-09,2012,2012-11,medical
Fuzzy Soft Set Based Classification for Gene Expression Data,"Classification is one of the major issues in Data Mining Research fields. The
classification problems in medical area often classify medical dataset based on
the result of medical diagnosis or description of medical treatment by the
medical practitioner. This research work discusses the classification process
of Gene Expression data for three different cancers which are breast cancer,
lung cancer and leukemia cancer with two classes which are cancerous stage and
non cancerous stage. We have applied a fuzzy soft set similarity based
classifier to enhance the accuracy to predict the stages among cancer genes and
the informative genes are selected by using Entopy filtering.",2013-01-08,2013,2013-01,medical
"Artificial Intelligence Framework for Simulating Clinical
  Decision-Making: A Markov Decision Process Approach","In the modern healthcare system, rapidly expanding costs/complexity, the
growing myriad of treatment options, and exploding information streams that
often do not effectively reach the front lines hinder the ability to choose
optimal treatment decisions over time. The goal in this paper is to develop a
general purpose (non-disease-specific) computational/artificial intelligence
(AI) framework to address these challenges. This serves two potential
functions: 1) a simulation environment for exploring various healthcare
policies, payment methodologies, etc., and 2) the basis for clinical artificial
intelligence - an AI that can think like a doctor. This approach combines
Markov decision processes and dynamic decision networks to learn from clinical
data and develop complex plans via simulation of alternative sequential
decision paths while capturing the sometimes conflicting, sometimes synergistic
interactions of various components in the healthcare system. It can operate in
partially observable environments (in the case of missing observations or data)
by maintaining belief states about patient health status and functions as an
online agent that plans and re-plans. This framework was evaluated using real
patient data from an electronic health record. Such an AI framework easily
outperforms the current treatment-as-usual (TAU) case-rate/fee-for-service
models of healthcare (Cost per Unit Change: $189 vs. $497) while obtaining a
30-35% increase in patient outcomes. Tweaking certain model parameters further
enhances this advantage, obtaining roughly 50% more improvement for roughly
half the costs. Given careful design and problem formulation, an AI simulation
framework can approximate optimal decisions even in complex and uncertain
environments. Future work is described that outlines potential lines of
research and integration of machine learning algorithms for personalized
medicine.",2013-01-10,2013,2013-01,medical
"Similarity Measures on Preference Structures, Part II: Utility Functions","In previous work cite{Ha98:Towards} we presented a case-based approach to
eliciting and reasoning with preferences. A key issue in this approach is the
definition of similarity between user preferences. We introduced the
probabilistic distance as a measure of similarity on user preferences, and
provided an algorithm to compute the distance between two partially specified
{em value} functions. This is for the case of decision making under {em
certainty}. In this paper we address the more challenging issue of computing
the probabilistic distance in the case of decision making under{em
uncertainty}. We provide an algorithm to compute the probabilistic distance
between two partially specified {em utility} functions. We demonstrate the use
of this algorithm with a medical data set of partially specified patient
preferences,where none of the other existing distancemeasures appear definable.
Using this data set, we also demonstrate that the case-based approach to
preference elicitation isapplicable in domains with uncertainty. Finally, we
provide a comprehensive analytical comparison of the probabilistic distance
with some existing distance measures on preferences.",2013-01-10,2013,2013-01,medical
Multiplicative Factorization of Noisy-Max,"The noisy-or and its generalization noisy-max have been utilized to reduce
the complexity of knowledge acquisition. In this paper, we present a new
representation of noisy-max that allows for efficient inference in general
Bayesian networks. Empirical studies show that our method is capable of
computing queries in well-known large medical networks, QMR-DT and CPCS, for
which no previous exact inference method has been shown to perform well.",2013-01-23,2013,2013-01,medical
A Temporal Bayesian Network for Diagnosis and Prediction,"Diagnosis and prediction in some domains, like medical and industrial
diagnosis, require a representation that combines uncertainty management and
temporal reasoning. Based on the fact that in many cases there are few state
changes in the temporal range of interest, we propose a novel representation
called Temporal Nodes Bayesian Networks (TNBN). In a TNBN each node represents
an event or state change of a variable, and an arc corresponds to a
causal-temporal relationship. The temporal intervals can differ in number and
size for each temporal node, so this allows multiple granularity. Our approach
is contrasted with a dynamic Bayesian network for a simple medical example. An
empirical evaluation is presented for a more complex problem, a subsystem of a
fossil power plant, in which this approach is used for fault diagnosis and
prediction with good results.",2013-01-23,2013,2013-01,medical
Mini-Bucket Heuristics for Improved Search,"The paper is a second in a series of two papers evaluating the power of a new
scheme that generates search heuristics mechanically. The heuristics are
extracted from an approximation scheme called mini-bucket elimination that was
recently introduced. The first paper introduced the idea and evaluated it
within Branch-and-Bound search. In the current paper the idea is further
extended and evaluated within Best-First search. The resulting algorithms are
compared on coding and medical diagnosis problems, using varying strength of
the mini-bucket heuristics.
  Our results demonstrate an effective search scheme that permits controlled
tradeoff between preprocessing (for heuristic generation) and search.
Best-first search is shown to outperform Branch-and-Bound, when supplied with
good heuristics, and sufficient memory space.",2013-01-23,2013,2013-01,medical
From Likelihood to Plausibility,"Several authors have explained that the likelihood ratio measures the
strength of the evidence represented by observations in statistical problems.
This idea works fine when the goal is to evaluate the strength of the available
evidence for a simple hypothesis versus another simple hypothesis. However, the
applicability of this idea is limited to simple hypotheses because the
likelihood function is primarily defined on points (simple hypotheses) of the
parameter space. In this paper we define a general weight of evidence that is
applicable to both simple and composite hypotheses. It is based on the
Dempster-Shafer concept of plausibility and is shown to be a generalization of
the likelihood ratio. Functional models are of a fundamental importance for the
general weight of evidence proposed in this paper. The relevant concepts and
ideas are explained by means of a familiar urn problem and the general analysis
of a real-world medical problem is presented.",2013-01-30,2013,2013-01,medical
"Why Is Diagnosis Using Belief Networks Insensitive to Imprecision In
  Probabilities?","Recent research has found that diagnostic performance with Bayesian belief
networks is often surprisingly insensitive to imprecision in the numerical
probabilities. For example, the authors have recently completed an extensive
study in which they applied random noise to the numerical probabilities in a
set of belief networks for medical diagnosis, subsets of the CPCS network, a
subset of the QMR (Quick Medical Reference) focused on liver and bile diseases.
The diagnostic performance in terms of the average probabilities assigned to
the actual diseases showed small sensitivity even to large amounts of noise. In
this paper, we summarize the findings of this study and discuss possible
explanations of this low sensitivity. One reason is that the criterion for
performance is average probability of the true hypotheses, rather than average
error in probability, which is insensitive to symmetric noise distributions.
But, we show that even asymmetric, logodds-normal noise has modest effects. A
second reason is that the gold-standard posterior probabilities are often near
zero or one, and are little disturbed by noise.",2013-02-13,2013,2013-02,medical
Efficient Decision-Theoretic Planning: Techniques and Empirical Analysis,"This paper discusses techniques for performing efficient decision-theoretic
planning. We give an overview of the DRIPS decision-theoretic refinement
planning system, which uses abstraction to efficiently identify optimal plans.
We present techniques for automatically generating search control information,
which can significantly improve the planner's performance. We evaluate the
efficiency of DRIPS both with and without the search control rules on a complex
medical planning problem and compare its performance to that of a
branch-and-bound decision tree algorithm.",2013-02-20,2013,2013-02,medical
Graph-Grammar Assistance for Automated Generation of Influence Diagrams,"One of the most difficult aspects of modeling complex dilemmas in
decision-analytic terms is composing a diagram of relevance relations from a
set of domain concepts. Decision models in domains such as medicine, however,
exhibit certain prototypical patterns that can guide the modeling process.
Medical concepts can be classified according to semantic types that have
characteristic positions and typical roles in an influence-diagram model. We
have developed a graph-grammar production system that uses such inherent
interrelationships among medical terms to facilitate the modeling of medical
decisions.",2013-03-06,2013,2013-03,medical
Computing as compression: the SP theory of intelligence,"This paper provides an overview of the SP theory of intelligence and its
central idea that artificial intelligence, mainstream computing, and much of
human perception and cognition, may be understood as information compression.
  The background and origins of the SP theory are described, and the main
elements of the theory, including the key concept of multiple alignment,
borrowed from bioinformatics but with important differences. Associated with
the SP theory is the idea that redundancy in information may be understood as
repetition of patterns, that compression of information may be achieved via the
matching and unification (merging) of patterns, and that computing and
information compression are both fundamentally probabilistic. It appears that
the SP system is Turing-equivalent in the sense that anything that may be
computed with a Turing machine may, in principle, also be computed with an SP
machine.
  One of the main strengths of the SP theory and the multiple alignment concept
is in modelling concepts and phenomena in artificial intelligence. Within that
area, the SP theory provides a simple but versatile means of representing
different kinds of knowledge, it can model both the parsing and production of
natural language, with potential for the understanding and translation of
natural languages, it has strengths in pattern recognition, with potential in
computer vision, it can model several kinds of reasoning, and it has
capabilities in planning, problem solving, and unsupervised learning.
  The paper includes two examples showing how alternative parsings of an
ambiguous sentence may be modelled as multiple alignments, and another example
showing how the concept of multiple alignment may be applied in medical
diagnosis.",2013-03-08,2013,2013-03,medical
Analysis in HUGIN of Data Conflict,"After a brief introduction to causal probabilistic networks and the HUGIN
approach, the problem of conflicting data is discussed. A measure of conflict
is defined, and it is used in the medical diagnostic system MUNIN. Finally, it
is discussed how to distinguish between conflicting data and a rare case.",2013-03-27,2013,2013-03,medical
"A Heuristic Bayesian Approach to Knowledge Acquisition: Application to
  Analysis of Tissue-Type Plasminogen Activator","This paper describes a heuristic Bayesian method for computing probability
distributions from experimental data, based upon the multivariate normal form
of the influence diagram. An example illustrates its use in medical technology
assessment. This approach facilitates the integration of results from different
studies, and permits a medical expert to make proper assessments without
considerable statistical training.",2013-03-27,2013,2013-03,medical
"A Combination of Cutset Conditioning with Clique-Tree Propagation in the
  Pathfinder System","Cutset conditioning and clique-tree propagation are two popular methods for
performing exact probabilistic inference in Bayesian belief networks. Cutset
conditioning is based on decomposition of a subset of network nodes, whereas
clique-tree propagation depends on aggregation of nodes. We describe a means to
combine cutset conditioning and clique- tree propagation in an approach called
aggregation after decomposition (AD). We discuss the application of the AD
method in the Pathfinder system, a medical expert system that offers assistance
with diagnosis in hematopathology.",2013-03-27,2013,2013-03,medical
Exact Reasoning Under Uncertainty,"This paper focuses on designing expert systems to support decision making in
complex, uncertain environments. In this context, our research indicates that
strictly probabilistic representations, which enable the use of
decision-theoretic reasoning, are highly preferable to recently proposed
alternatives (e.g., fuzzy set theory and Dempster-Shafer theory). Furthermore,
we discuss the language of influence diagrams and a corresponding methodology
-decision analysis -- that allows decision theory to be used effectively and
efficiently as a decision-making aid. Finally, we use RACHEL, a system that
helps infertile couples select medical treatments, to illustrate the
methodology of decision analysis as basis for expert decision systems.",2013-03-27,2013,2013-03,medical
"Induction and Uncertainty Management Techniques Applied to Veterinary
  Medical Diagnosis","This paper discusses a project undertaken between the Departments of
Computing Science, Statistics, and the College of Veterinary Medicine to design
a medical diagnostic system. On-line medical data has been collected in the
hospital database system for several years. A number of induction methods are
being used to extract knowledge from the data in an attempt to improve upon
simple diagnostic charts used by the clinicians. They also enhance the results
of classical statistical methods - finding many more significant variables. The
second part of the paper describes an essentially Bayesian method of evidence
combination using fuzzy events at an initial step. Results are presented and
comparisons are made with other methods.",2013-03-27,2013,2013-03,medical
"Using Belief Functions for Uncertainty Management and Knowledge
  Acquisition: An Expert Application","This paper describes recent work on an ongoing project in medical diagnosis
at the University of Guelph. A domain on which experts are not very good at
pinpointing a single disease outcome is explored. On-line medical data is
available over a relatively short period of time. Belief Functions
(Dempster-Shafer theory) are first extracted from data and then modified with
expert opinions. Several methods for doing this are compared and results show
that one formulation statistically outperforms the others, including a method
suggested by Shafer. Expert opinions and statistically derived information
about dependencies among symptoms are also compared. The benefits of using
uncertainty management techniques as methods for knowledge acquisition from
data are discussed.",2013-03-27,2013,2013-03,medical
"Experiments Using Belief Functions and Weights of Evidence incorporating
  Statistical Data and Expert Opinions","This paper presents some ideas and results of using uncertainty management
methods in the presence of data in preference to other statistical and machine
learning methods. A medical domain is used as a test-bed with data available
from a large hospital database system which collects symptom and outcome
information about patients. Data is often missing, of many variable types and
sample sizes for particular outcomes is not large. Uncertainty management
methods are useful for such domains and have the added advantage of allowing
for expert modification of belief values originally obtained from data.
Methodological considerations for using belief functions on statistical data
are dealt with in some detail. Expert opinions are Incorporated at various
levels of the project development and results are reported on an application to
liver disease diagnosis. Recent results contrasting the use of weights of
evidence and logistic regression on another medical domain are also presented.",2013-03-27,2013,2013-03,medical
"An Empirical Evaluation of a Randomized Algorithm for Probabilistic
  Inference","In recent years, researchers in decision analysis and artificial intelligence
(Al) have used Bayesian belief networks to build models of expert opinion.
Using standard methods drawn from the theory of computational complexity,
workers in the field have shown that the problem of probabilistic inference in
belief networks is difficult and almost certainly intractable. K N ET, a
software environment for constructing knowledge-based systems within the
axiomatic framework of decision theory, contains a randomized approximation
scheme for probabilistic inference. The algorithm can, in many circumstances,
perform efficient approximate inference in large and richly interconnected
models of medical diagnosis. Unlike previously described stochastic algorithms
for probabilistic inference, the randomized approximation scheme computes a
priori bounds on running time by analyzing the structure and contents of the
belief network. In this article, we describe a randomized algorithm for
probabilistic inference and analyze its performance mathematically. Then, we
devote the major portion of the paper to a discussion of the algorithm's
empirical behavior. The results indicate that the generation of good trials
(that is, trials whose distribution closely matches the true distribution),
rather than the computation of numerous mediocre trials, dominates the
performance of stochastic simulation. Key words: probabilistic inference,
belief networks, stochastic simulation, computational complexity theory,
randomized algorithms.",2013-03-27,2013,2013-03,medical
A Decision-Theoretic Model for Using Scientific Data,"Many Artificial Intelligence systems depend on the agent's updating its
beliefs about the world on the basis of experience. Experiments constitute one
type of experience, so scientific methodology offers a natural environment for
examining the issues attendant to using this class of evidence. This paper
presents a framework which structures the process of using scientific data from
research reports for the purpose of making decisions, using decision analysis
as the basis for the structure and using medical research as the general
scientific domain. The structure extends the basic influence diagram for
updating belief in an object domain parameter of interest by expanding the
parameter into four parts: those of the patient, the population, the study
sample, and the effective study sample. The structure uses biases to perform
the transformation of one parameter into another, so that, for instance,
selection biases, in concert with the population parameter, yield the study
sample parameter. The influence diagram structure provides decision theoretic
justification for practices of good clinical research such as randomized
assignment and blindfolding of care providers. The model covers most research
designs used in medicine: case-control studies, cohort studies, and controlled
clinical trials, and provides an architecture to separate clearly between
statistical knowledge and domain knowledge. The proposed general model can be
the basis for clinical epidemiological advisory systems, when coupled with
heuristic pruning of irrelevant biases; of statistical workstations, when the
computational machinery for calculation of posterior distributions is added;
and of meta-analytic reviews, when multiple studies may impact on a single
population parameter.",2013-03-27,2013,2013-03,medical
A Tractable Inference Algorithm for Diagnosing Multiple Diseases,"We examine a probabilistic model for the diagnosis of multiple diseases. In
the model, diseases and findings are represented as binary variables. Also,
diseases are marginally independent, features are conditionally independent
given disease instances, and diseases interact to produce findings via a noisy
OR-gate. An algorithm for computing the posterior probability of each disease,
given a set of observed findings, called quickscore, is presented. The time
complexity of the algorithm is O(nm-2m+), where n is the number of diseases, m+
is the number of positive findings and m- is the number of negative findings.
Although the time complexity of quickscore i5 exponential in the number of
positive findings, the algorithm is useful in practice because the number of
observed positive findings is usually far less than the number of diseases
under consideration. Performance results for quickscore applied to a
probabilistic version of Quick Medical Reference (QMR) are provided.",2013-03-27,2013,2013-03,medical
"Assessment, Criticism and Improvement of Imprecise Subjective
  Probabilities for a Medical Expert System","Three paediatric cardiologists assessed nearly 1000 imprecise subjective
conditional probabilities for a simple belief network representing congenital
heart disease, and the quality of the assessments has been measured using
prospective data on 200 babies. Quality has been assessed by a Brier scoring
rule, which decomposes into terms measuring lack of discrimination and
reliability. The results are displayed for each of 27 diseases and 24
questions, and generally the assessments are reliable although there was a
tendency for the probabilities to be too extreme. The imprecision allows the
judgements to be converted to implicit samples, and by combining with the
observed data the probabilities naturally adapt with experience. This appears
to be a practical procedure even for reasonably large expert systems.",2013-03-27,2013,2013-03,medical
"NAIVE: A Method for Representing Uncertainty and Temporal Relationships
  in an Automated Reasoner","This paper describes NAIVE, a low-level knowledge representation language and
inferencing process. NAIVE has been designed for reasoning about
nondeterministic dynamic systems like those found in medicine. Knowledge is
represented in a graph structure consisting of nodes, which correspond to the
variables describing the system of interest, and arcs, which correspond to the
procedures used to infer the value of a variable from the values of other
variables. The value of a variable can be determined at an instant in time,
over a time interval or for a series of times. Information about the value of a
variable is expressed as a probability density function which quantifies the
likelihood of each possible value. The inferencing process uses these
probability density functions to propagate uncertainty. NAIVE has been used to
develop medical knowledge bases including over 100 variables.",2013-03-27,2013,2013-03,medical
Steps Towards Programs that Manage Uncertainty,"Reasoning under uncertainty in Al hats come to mean assessing the credibility
of hypotheses inferred from evidence. But techniques for assessing credibility
do not tell a problem solver what to do when it is uncertain. This is the focus
of our current research. We have developed a medical expert system called MUM,
for Managing Uncertainty in Medicine, that plans diagnostic sequences of
questions, tests, and treatments. This paper describes the kinds of problems
that MUM was designed to solve and gives a brief description of its
architecture. More recently, we have built an empty version of MUM called MU,
and used it to reimplement MUM and a small diagnostic system for plant
pathology. The latter part of the paper describes the features of MU that make
it appropriate for building expert systems that manage uncertainty.",2013-03-27,2013,2013-03,medical
"Imprecise Meanings as a Cause of Uncertainty in Medical Knowledge-Based
  Systems","There has been a considerable amount of work on uncertainty in
knowledge-based systems. This work has generally been concerned with
uncertainty arising from the strength of inferences and the weight of evidence.
In this paper we discuss another type of uncertainty: that which is due to
imprecision in the underlying primitives used to represent the knowledge of the
system. In particular, a given word may denote many similar but not identical
entities. Such words are said to be lexically imprecise. Lexical imprecision
has caused widespread problems in many areas. Unless this phenomenon is
recognized and appropriately handled, it can degrade the performance of
knowledge-based systems. In particular, it can lead to difficulties with the
user interface, and with the inferencing processes of these systems. Some
techniques are suggested for coping with this phenomenon.",2013-03-27,2013,2013-03,medical
Advantages and a Limitation of Using LEG Nets in a Real-TIme Problem,"After experimenting with a number of non-probabilistic methods for dealing
with uncertainty many researchers reaffirm a preference for probability methods
[1] [2], although this remains controversial. The importance of being able to
form decisions from incomplete data in diagnostic problems has highlighted
probabilistic methods [5] which compute posterior probabilities from prior
distributions in a way similar to Bayes Rule, and thus are called Bayesian
methods. This paper documents the use of a Bayesian method in a real time
problem which is similar to medical diagnosis in that there is a need to form
decisions and take some action without complete knowledge of conditions in the
problem domain. This particular method has a limitation which is discussed.",2013-03-28,2013,2013-03,medical
"Using a bag of Words for Automatic Medical Image Annotation with a
  Latent Semantic","We present in this paper a new approach for the automatic annotation of
medical images, using the approach of ""bag-of-words"" to represent the visual
content of the medical image combined with text descriptors based approach
tf.idf and reduced by latent semantic to extract the co-occurrence between
terms and visual terms. A medical report is composed of a text describing a
medical image. First, we are interested to index the text and extract all
relevant terms using a thesaurus containing MeSH medical concepts. In a second
phase, the medical image is indexed while recovering areas of interest which
are invariant to change in scale, light and tilt. To annotate a new medical
image, we use the approach of ""bagof-words"" to recover the feature vector.
Indeed, we use the vector space model to retrieve similar medical image from
the database training. The calculation of the relevance value of an image to
the query image is based on the cosine function. We conclude with an experiment
carried out on five types of radiological imaging to evaluate the performance
of our system of medical annotation. The results showed that our approach works
better with more images from the radiology of the skull.",2013-06-02,2013,2013-06,medical
A hybrid decision support system : application on healthcare,"Many systems based on knowledge, especially expert systems for medical
decision support have been developed. Only systems are based on production
rules, and cannot learn and evolve only by updating them. In addition, taking
into account several criteria induces an exorbitant number of rules to be
injected into the system. It becomes difficult to translate medical knowledge
or a support decision as a simple rule. Moreover, reasoning based on generic
cases became classic and can even reduce the range of possible solutions. To
remedy that, we propose an approach based on using a multi-criteria decision
guided by a case-based reasoning (CBR) approach.",2013-11-16,2013,2013-11,medical
Medical Image Fusion: A survey of the state of the art,"Medical image fusion is the process of registering and combining multiple
images from single or multiple imaging modalities to improve the imaging
quality and reduce randomness and redundancy in order to increase the clinical
applicability of medical images for diagnosis and assessment of medical
problems. Multi-modal medical image fusion algorithms and devices have shown
notable achievements in improving clinical accuracy of decisions based on
medical images. This review article provides a factual listing of methods and
summarizes the broad scientific challenges faced in the field of medical image
fusion. We characterize the medical image fusion research based on (1) the
widely used image fusion methods, (2) imaging modalities, and (3) imaging of
organs that are under study. This review concludes that even though there
exists several open ended technological and scientific challenges, the fusion
of medical images has proved to be useful for advancing the clinical
reliability of using medical imaging for medical diagnostics and analysis, and
is a scientific discipline that has the potential to significantly grow in the
coming years.",2013-12-31,2013,2013-12,medical
"Medical diagnosis as pattern recognition in a framework of information
  compression by multiple alignment, unification and search","This paper describes a novel approach to medical diagnosis based on the SP
theory of computing and cognition. The main attractions of this approach are: a
format for representing diseases that is simple and intuitive; an ability to
cope with errors and uncertainties in diagnostic information; the simplicity of
storing statistical information as frequencies of occurrence of diseases; a
method for evaluating alternative diagnostic hypotheses that yields true
probabilities; and a framework that should facilitate unsupervised learning of
medical knowledge and the integration of medical diagnosis with other AI
applications.",2014-09-29,2014,2014-09,medical
"Subsumptive reflection in SNOMED CT: a large description logic-based
  terminology for diagnosis","Description logic (DL) based biomedical terminology (SNOMED CT) is used
routinely in medical practice. However, diagnostic inference using such
terminology is precluded by its complexity. Here we propose a model that
simplifies these inferential components. We propose three concepts that
classify clinical features and examined their effect on inference using SNOMED
CT. We used PAIRS (Physician Assistant Artificial Intelligence Reference
System) database (1964 findings for 485 disorders, 18 397 disease feature
links) for our analysis. We also use a 50-million medical word corpus for
estimating the vectors of disease-feature links. Our major results are 10% of
finding-disorder links are concomitant in both assertion and negation where as
90% are either concomitant in assertion or negation. Logical implications of
PAIRS data on SNOMED CT include 70% of the links do not share any common system
while 18% share organ and 12% share both system and organ. Applications of
these principles for inference are discussed and suggestions are made for
deriving a diagnostic process using SNOMED CT. Limitations of these processes
and suggestions for improvements are also discussed.",2015-12-11,2015,2015-12,medical
"Performance Based Evaluation of Various Machine Learning Classification
  Techniques for Chronic Kidney Disease Diagnosis","Areas where Artificial Intelligence (AI) & related fields are finding their
applications are increasing day by day, moving from core areas of computer
science they are finding their applications in various other domains.In recent
times Machine Learning i.e. a sub-domain of AI has been widely used in order to
assist medical experts and doctors in the prediction, diagnosis and prognosis
of various diseases and other medical disorders. In this manuscript the authors
applied various machine learning algorithms to a problem in the domain of
medical diagnosis and analyzed their efficiency in predicting the results. The
problem selected for the study is the diagnosis of the Chronic Kidney
Disease.The dataset used for the study consists of 400 instances and 24
attributes. The authors evaluated 12 classification techniques by applying them
to the Chronic Kidney Disease data. In order to calculate efficiency, results
of the prediction by candidate methods were compared with the actual medical
results of the subject.The various metrics used for performance evaluation are
predictive accuracy, precision, sensitivity and specificity. The results
indicate that decision-tree performed best with nearly the accuracy of 98.6%,
sensitivity of 0.9720, precision of 1 and specificity of 1.",2016-06-28,2016,2016-06,medical
"Harmonization of conflicting medical opinions using argumentation
  protocols and textual entailment - a case study on Parkinson disease","Parkinson's disease is the second most common neurodegenerative disease,
affecting more than 1.2 million people in Europe. Medications are available for
the management of its symptoms, but the exact cause of the disease is unknown
and there is currently no cure on the market. To better understand the
relations between new findings and current medical knowledge, we need tools
able to analyse published medical papers based on natural language processing
and tools capable to identify various relationships of new findings with the
current medical knowledge. Our work aims to fill the above technological gap.
  To identify conflicting information in medical documents, we enact textual
entailment technology. To encapsulate existing medical knowledge, we rely on
ontologies. To connect the formal axioms in ontologies with natural text in
medical articles, we exploit ontology verbalisation techniques. To assess the
level of disagreement between human agents with respect to a medical issue, we
rely on fuzzy aggregation. To harmonize this disagreement, we design mediation
protocols within a multi-agent framework.",2016-07-27,2016,2016-07,medical
"Mining Arguments from Cancer Documents Using Natural Language Processing
  and Ontologies","In the medical domain, the continuous stream of scientific research contains
contradictory results supported by arguments and counter-arguments. As medical
expertise occurs at different levels, part of the human agents have
difficulties to face the huge amount of studies, but also to understand the
reasons and pieces of evidences claimed by the proponents and the opponents of
the debated topic. To better understand the supporting arguments for new
findings related to current state of the art in the medical domain we need
tools able to identify arguments in scientific papers. Our work here aims to
fill the above technological gap.
  Quite aware of the difficulty of this task, we embark to this road by relying
on the well-known interleaving of domain knowledge with natural language
processing. To formalise the existing medical knowledge, we rely on ontologies.
To structure the argumentation model we use also the expressivity and reasoning
capabilities of Description Logics. To perform argumentation mining we
formalise various linguistic patterns in a rule-based language. We tested our
solution against a corpus of scientific papers related to breast cancer. The
run experiments show a F-measure between 0.71 and 0.86 for identifying
conclusions of an argument and between 0.65 and 0.86 for identifying premises
of an argument.",2016-07-27,2016,2016-07,medical
Relational Models,"We provide a survey on relational models. Relational models describe complete
networked {domains by taking into account global dependencies in the data}.
Relational models can lead to more accurate predictions if compared to
non-relational machine learning approaches. Relational models typically are
based on probabilistic graphical models, e.g., Bayesian networks, Markov
networks, or latent variable models. Relational models have applications in
social networks analysis, the modeling of knowledge graphs, bioinformatics,
recommendation systems, natural language processing, medical decision support,
and linked data.",2016-09-11,2016,2016-09,medical
"GOTM: a Goal-Oriented Framework for Capturing Uncertainty of Medical
  Treatments","It has been widely recognized that uncertainty is an inevitable aspect of
diagnosis and treatment of medical disorders. Such uncertainties hence, need to
be considered in computerized medical models. The existing medical modeling
techniques however, have mainly focused on capturing uncertainty associated
with diagnosis of medical disorders while ignoring uncertainty of treatments.
To tackle this issue, we have proposed using a fuzzy-based modeling and
description technique for capturing uncertainties in treatment plans. We have
further contributed a formal framework which allows for goal-oriented modeling
and analysis of medical treatments.",2016-12-09,2016,2016-12,medical
"Neural Networks for Joint Sentence Classification in Medical Paper
  Abstracts","Existing models based on artificial neural networks (ANNs) for sentence
classification often do not incorporate the context in which sentences appear,
and classify sentences individually. However, traditional sentence
classification approaches have been shown to greatly benefit from jointly
classifying subsequent sentences, such as with conditional random fields. In
this work, we present an ANN architecture that combines the effectiveness of
typical ANN models to classify sentences in isolation, with the strength of
structured prediction. Our model achieves state-of-the-art results on two
different datasets for sequential sentence classification in medical abstracts.",2016-12-15,2016,2016-12,medical
"Learning and inference in knowledge-based probabilistic model for
  medical diagnosis","Based on a weighted knowledge graph to represent first-order knowledge and
combining it with a probabilistic model, we propose a methodology for the
creation of a medical knowledge network (MKN) in medical diagnosis. When a set
of symptoms is activated for a specific patient, we can generate a ground
medical knowledge network composed of symptom nodes and potential disease
nodes. By Incorporating a Boltzmann machine into the potential function of a
Markov network, we investigated the joint probability distribution of the MKN.
In order to deal with numerical symptoms, a multivariate inference model is
presented that uses conditional probability. In addition, the weights for the
knowledge graph were efficiently learned from manually annotated Chinese
Electronic Medical Records (CEMRs). In our experiments, we found numerically
that the optimum choice of the quality of disease node and the expression of
symptom variable can improve the effectiveness of medical diagnosis. Our
experimental results comparing a Markov logic network and the logistic
regression algorithm on an actual CEMR database indicate that our method holds
promise and that MKN can facilitate studies of intelligent diagnosis.",2017-03-28,2017,2017-03,medical
People on Drugs: Credibility of User Statements in Health Communities,"Online health communities are a valuable source of information for patients
and physicians. However, such user-generated resources are often plagued by
inaccuracies and misinformation. In this work we propose a method for
automatically establishing the credibility of user-generated medical statements
and the trustworthiness of their authors by exploiting linguistic cues and
distant supervision from expert sources. To this end we introduce a
probabilistic graphical model that jointly learns user trustworthiness,
statement credibility, and language objectivity. We apply this methodology to
the task of extracting rare or unknown side-effects of medical drugs --- this
being one of the problems where large scale non-expert data has the potential
to complement expert medical knowledge. We show that our method can reliably
extract side-effects and filter out false statements, while identifying
trustworthy users that are likely to contribute valuable medical information.",2017-05-06,2017,2017-05,medical
Brain Intelligence: Go Beyond Artificial Intelligence,"Artificial intelligence (AI) is an important technology that supports daily
social life and economic activities. It contributes greatly to the sustainable
growth of Japan's economy and solves various social problems. In recent years,
AI has attracted attention as a key for growth in developed countries such as
Europe and the United States and developing countries such as China and India.
The attention has been focused mainly on developing new artificial intelligence
information communication technology (ICT) and robot technology (RT). Although
recently developed AI technology certainly excels in extracting certain
patterns, there are many limitations. Most ICT models are overly dependent on
big data, lack a self-idea function, and are complicated. In this paper, rather
than merely developing next-generation artificial intelligence technology, we
aim to develop a new concept of general-purpose intelligence cognition
technology called Beyond AI. Specifically, we plan to develop an intelligent
learning model called Brain Intelligence (BI) that generates new ideas about
events without having experienced them by using artificial life with an imagine
function. We will also conduct demonstrations of the developed BI intelligence
learning model on automatic driving, precision medical care, and industrial
robots.",2017-06-04,2017,2017-06,medical
"Technical Report: Implementation and Validation of a Smart Health
  Application","In this article, we explain in detail the internal structures and databases
of a smart health application. Moreover, we describe how to generate a
statistically sound synthetic dataset using real-world medical data.",2017-06-13,2017,2017-06,medical
"PDD Graph: Bridging Electronic Medical Records and Biomedical Knowledge
  Graphs via Entity Linking","Electronic medical records contain multi-format electronic medical data that
consist of an abundance of medical knowledge. Facing with patient's symptoms,
experienced caregivers make right medical decisions based on their professional
knowledge that accurately grasps relationships between symptoms, diagnosis and
corresponding treatments. In this paper, we aim to capture these relationships
by constructing a large and high-quality heterogenous graph linking patients,
diseases, and drugs (PDD) in EMRs. Specifically, we propose a novel framework
to extract important medical entities from MIMIC-III (Medical Information Mart
for Intensive Care III) and automatically link them with the existing
biomedical knowledge graphs, including ICD-9 ontology and DrugBank. The PDD
graph presented in this paper is accessible on the Web via the SPARQL endpoint,
and provides a pathway for medical discovery and applications, such as
effective treatment recommendations.",2017-07-17,2017,2017-07,medical
"Explainable Artificial Intelligence: Understanding, Visualizing and
  Interpreting Deep Learning Models","With the availability of large databases and recent improvements in deep
learning methodology, the performance of AI systems is reaching or even
exceeding the human level on an increasing number of complex tasks. Impressive
examples of this development can be found in domains such as image
classification, sentiment analysis, speech understanding or strategic game
playing. However, because of their nested non-linear structure, these highly
successful machine learning and artificial intelligence models are usually
applied in a black box manner, i.e., no information is provided about what
exactly makes them arrive at their predictions. Since this lack of transparency
can be a major drawback, e.g., in medical applications, the development of
methods for visualizing, explaining and interpreting deep learning models has
recently attracted increasing attention. This paper summarizes recent
developments in this field and makes a plea for more interpretability in
artificial intelligence. Furthermore, it presents two approaches to explaining
predictions of deep learning models, one method which computes the sensitivity
of the prediction with respect to changes in the input and one approach which
meaningfully decomposes the decision in terms of the input variables. These
methods are evaluated on three classification tasks.",2017-08-28,2017,2017-08,medical
"Determining Positive Cancer Rescue Mutations in p53 Based Cancers by
  using Artificial Intelligence","A mutation in a protein-coding gene in DNA can alter the protein structure
coded by the same gene. Structurally altered proteins usually lose their
functions and sometimes gain an undesirable function instead. These types of
mutations and their effects can result in genetic diseases or antibiotic
resistant bacteria, among other health issues. Important curing methods have
been developed for detecting mutations against AIDS as well as genetic
diseases. Another example is the influenza virus. The reasons why a vaccination
developed to fight against influenza does not work the following year are (a)
the mutation of its DNA and (b) the outbreak of the virus after it has been
mutated especially if it is a virus that escaped the vaccinations target. Due
to such reasons, it is highly important to know in advance the location of a
potential mutation in a protein as well as the problems it might cause the
medical sciences. In this study we have used artificial neural networks, which
are one of the latest artificial intelligence technologies, to determine the
effects of cancer mutations. The model we developed has given more successful
results compared to other methods. We foresee that our model will bring a new
dimension to medical research and the medical industry.",2017-08-28,2017,2017-08,medical
"EMR-based medical knowledge representation and inference via Markov
  random fields and distributed representation learning","Objective: Electronic medical records (EMRs) contain an amount of medical
knowledge which can be used for clinical decision support (CDS). Our objective
is a general system that can extract and represent these knowledge contained in
EMRs to support three CDS tasks: test recommendation, initial diagnosis, and
treatment plan recommendation, with the given condition of one patient.
Methods: We extracted four kinds of medical entities from records and
constructed an EMR-based medical knowledge network (EMKN), in which nodes are
entities and edges reflect their co-occurrence in a single record. Three
bipartite subgraphs (bi-graphs) were extracted from the EMKN to support each
task. One part of the bi-graph was the given condition (e.g., symptoms), and
the other was the condition to be inferred (e.g., diseases). Each bi-graph was
regarded as a Markov random field to support the inference. Three lazy energy
functions and one parameter-based energy function were proposed, as well as two
knowledge representation learning-based energy functions, which can provide a
distributed representation of medical entities. Three measures were utilized
for performance evaluation. Results: On the initial diagnosis task, 80.11% of
the test records identified at least one correct disease from top 10
candidates. Test and treatment recommendation results were 87.88% and 92.55%,
respectively. These results altogether indicate that the proposed system
outperformed the baseline methods. The distributed representation of medical
entities does reflect similarity relationships in regards to knowledge level.
Conclusion: Combining EMKN and MRF is an effective approach for general medical
knowledge representation and inference. Different tasks, however, require
designing their energy functions individually.",2017-09-20,2017,2017-09,medical
Artificial Intelligence and Statistics,"Artificial intelligence (AI) is intrinsically data-driven. It calls for the
application of statistical concepts through human-machine collaboration during
generation of data, development of algorithms, and evaluation of results. This
paper discusses how such human-machine collaboration can be approached through
the statistical concepts of population, question of interest,
representativeness of training data, and scrutiny of results (PQRS). The PQRS
workflow provides a conceptual framework for integrating statistical ideas with
human input into AI products and research. These ideas include experimental
design principles of randomization and local control as well as the principle
of stability to gain reproducibility and interpretability of algorithms and
data results. We discuss the use of these principles in the contexts of
self-driving cars, automated medical diagnoses, and examples from the authors'
collaborative research.",2017-12-08,2017,2017-12,medical
"Towards the Augmented Pathologist: Challenges of Explainable-AI in
  Digital Pathology","Digital pathology is not only one of the most promising fields of diagnostic
medicine, but at the same time a hot topic for fundamental research. Digital
pathology is not just the transfer of histopathological slides into digital
representations. The combination of different data sources (images, patient
records, and *omics data) together with current advances in artificial
intelligence/machine learning enable to make novel information accessible and
quantifiable to a human expert, which is not yet available and not exploited in
current medical settings. The grand goal is to reach a level of usable
intelligence to understand the data in the context of an application task,
thereby making machine decisions transparent, interpretable and explainable.
The foundation of such an ""augmented pathologist"" needs an integrated approach:
While machine learning algorithms require many thousands of training examples,
a human expert is often confronted with only a few data points. Interestingly,
humans can learn from such few examples and are able to instantly interpret
complex patterns. Consequently, the grand goal is to combine the possibilities
of artificial intelligence with human intelligence and to find a well-suited
balance between them to enable what neither of them could do on their own. This
can raise the quality of education, diagnosis, prognosis and prediction of
cancer and other diseases. In this paper we describe some (incomplete) research
issues which we believe should be addressed in an integrated and concerted
effort for paving the way towards the augmented pathologist.",2017-12-18,2017,2017-12,medical
Artificial intelligence and pediatrics: A synthetic mini review,"The use of artificial intelligence intelligencein medicine can be traced back
to 1968 when Paycha published his paper Le diagnostic a l'aide d'intelligences
artificielle, presentation de la premiere machine diagnostri. Few years later
Shortliffe et al. presented an expert system named Mycin which was able to
identify bacteria causing severe blood infections and to recommend antibiotics.
Despite the fact that Mycin outperformed members of the Stanford medical school
in the reliability of diagnosis it was never used in practice due to a legal
issue who do you sue if it gives a wrong diagnosis?. However only in 2016 when
the artificial intelligence software built into the IBM Watson AI platform
correctly diagnosed and proposed an effective treatment for a 60-year-old
womans rare form of leukemia the AI use in medicine become really popular.On of
first papers presenting the use of AI in paediatrics was published in 1984. The
paper introduced a computer-assisted medical decision making system called
SHELP.",2018-02-16,2018,2018-02,medical
"Generating retinal flow maps from structural optical coherence
  tomography with artificial intelligence","Despite significant advances in artificial intelligence (AI) for computer
vision, its application in medical imaging has been limited by the burden and
limits of expert-generated labels. We used images from optical coherence
tomography angiography (OCTA), a relatively new imaging modality that measures
perfusion of the retinal vasculature, to train an AI algorithm to generate
vasculature maps from standard structural optical coherence tomography (OCT)
images of the same retinae, both exceeding the ability and bypassing the need
for expert labeling. Deep learning was able to infer perfusion of
microvasculature from structural OCT images with similar fidelity to OCTA and
significantly better than expert clinicians (P < 0.00001). OCTA suffers from
need of specialized hardware, laborious acquisition protocols, and motion
artifacts; whereas our model works directly from standard OCT which are
ubiquitous and quick to obtain, and allows unlocking of large volumes of
previously collected standard OCT data both in existing clinical trials and
clinical practice. This finding demonstrates a novel application of AI to
medical imaging, whereby subtle regularities between different modalities are
used to image the same body part and AI is used to generate detailed and
accurate inferences of tissue function from structure imaging.",2018-02-24,2018,2018-02,medical
"A Conversational Interface to Improve Medication Adherence: Towards AI
  Support in Patient's Treatment","Medication adherence is of utmost importance for many chronic conditions,
regardless of the disease type. Engaging patients in self-tracking their
medication is a big challenge. One way to potentially reduce this burden is to
use reminders to promote wellness throughout all stages of life and improve
medication adherence. Chatbots have proven effectiveness in triggering users to
engage in certain activity, such as medication adherence. In this paper, we
discuss ""Roborto"", a chatbot to create an engaging interactive and intelligent
environment for patients and assist in positive lifestyle modification. We
introduce a way for healthcare providers to track patients adherence and
intervene whenever necessary. We describe the health, technical and behavioural
approaches to the problem of medication non-adherence and propose a diagnostic
and decision support tool. The proposed study will be implemented and validated
through a pilot experiment with users to measure the efficacy of the proposed
approach.",2018-03-03,2018,2018-03,medical
"Label-aware Double Transfer Learning for Cross-Specialty Medical Named
  Entity Recognition","We study the problem of named entity recognition (NER) from electronic
medical records, which is one of the most fundamental and critical problems for
medical text mining. Medical records which are written by clinicians from
different specialties usually contain quite different terminologies and writing
styles. The difference of specialties and the cost of human annotation makes it
particularly difficult to train a universal medical NER system. In this paper,
we propose a label-aware double transfer learning framework (La-DTL) for
cross-specialty NER, so that a medical NER system designed for one specialty
could be conveniently applied to another one with minimal annotation efforts.
The transferability is guaranteed by two components: (i) we propose label-aware
MMD for feature representation transfer, and (ii) we perform parameter transfer
with a theoretical upper bound which is also label aware. We conduct extensive
experiments on 12 cross-specialty NER tasks. The experimental results
demonstrate that La-DTL provides consistent accuracy improvement over strong
baselines. Besides, the promising experimental results on non-medical NER
scenarios indicate that La-DTL is potential to be seamlessly adapted to a wide
range of NER tasks.",2018-04-24,2018,2018-04,medical
"Classifying medical relations in clinical text via convolutional neural
  networks","Deep learning research on relation classification has achieved solid
performance in the general domain. This study proposes a convolutional neural
network (CNN) architecture with a multi-pooling operation for medical relation
classification on clinical records and explores a loss function with a
category-level constraint matrix. Experiments using the 2010 i2b2/VA relation
corpus demonstrate these models, which do not depend on any external features,
outperform previous single-model methods and our best model is competitive with
the existing ensemble-based method.",2018-05-17,2018,2018-05,medical
"Producing radiologist-quality reports for interpretable artificial
  intelligence","Current approaches to explaining the decisions of deep learning systems for
medical tasks have focused on visualising the elements that have contributed to
each decision. We argue that such approaches are not enough to ""open the black
box"" of medical decision making systems because they are missing a key
component that has been used as a standard communication tool between doctors
for centuries: language. We propose a model-agnostic interpretability method
that involves training a simple recurrent neural network model to produce
descriptive sentences to clarify the decision of deep learning classifiers.
  We test our method on the task of detecting hip fractures from frontal pelvic
x-rays. This process requires minimal additional labelling despite producing
text containing elements that the original deep learning classification model
was not specifically trained to detect.
  The experimental results show that: 1) the sentences produced by our method
consistently contain the desired information, 2) the generated sentences are
preferred by doctors compared to current tools that create saliency maps, and
3) the combination of visualisations and generated text is better than either
alone.",2018-06-01,2018,2018-06,medical
Medical Concept Embedding with Time-Aware Attention,"Embeddings of medical concepts such as medication, procedure and diagnosis
codes in Electronic Medical Records (EMRs) are central to healthcare analytics.
Previous work on medical concept embedding takes medical concepts and EMRs as
words and documents respectively. Nevertheless, such models miss out the
temporal nature of EMR data. On the one hand, two consecutive medical concepts
do not indicate they are temporally close, but the correlations between them
can be revealed by the time gap. On the other hand, the temporal scopes of
medical concepts often vary greatly (e.g., \textit{common cold} and
\textit{diabetes}). In this paper, we propose to incorporate the temporal
information to embed medical codes. Based on the Continuous Bag-of-Words model,
we employ the attention mechanism to learn a ""soft"" time-aware context window
for each medical concept. Experiments on public and proprietary datasets
through clustering and nearest neighbour search tasks demonstrate the
effectiveness of our model, showing that it outperforms five state-of-the-art
baselines.",2018-06-06,2018,2018-06,medical
Behavior Trees as a Representation for Medical Procedures,"Objective: Effective collaboration between machines and clinicians requires
flexible data structures to represent medical processes and clinical practice
guidelines. Such a data structure could enable effective turn-taking between
human and automated components of a complex treatment, accurate on-line
monitoring of clinical treatments (for example to detect medical errors), or
automated treatment systems (such as future medical robots) whose overall
treatment plan is understandable and auditable by human experts.
  Materials and Methods: Behavior trees (BTs) emerged from video game
development as a graphical language for modeling intelligent agent behavior.
BTs have several properties which are attractive for modeling medical
procedures including human-readability, authoring tools, and composability.
  Results: This paper will illustrate construction of BTs for exemplary medical
procedures and clinical protocols.
  Discussion and Conclusion: Behavior Trees thus form a useful, and human
authorable/readable bridge between clinical practice guidelines and AI systems.",2018-08-27,2018,2018-08,medical
"Adaptive Structural Learning of Deep Belief Network for Medical
  Examination Data and Its Knowledge Extraction by using C4.5","Deep Learning has a hierarchical network architecture to represent the
complicated feature of input patterns. The adaptive structural learning method
of Deep Belief Network (DBN) has been developed. The method can discover an
optimal number of hidden neurons for given input data in a Restricted Boltzmann
Machine (RBM) by neuron generation-annihilation algorithm, and generate a new
hidden layer in DBN by the extension of the algorithm. In this paper, the
proposed adaptive structural learning of DBN was applied to the comprehensive
medical examination data for the cancer prediction. The prediction system shows
higher classification accuracy (99.8% for training and 95.5% for test) than the
traditional DBN. Moreover, the explicit knowledge with respect to the relation
between input and output patterns was extracted from the trained DBN network by
C4.5. Some characteristics extracted in the form of IF-THEN rules to find an
initial cancer at the early stage were reported in this paper.",2018-08-27,2018,2018-08,medical
"GAMENet: Graph Augmented MEmory Networks for Recommending Medication
  Combination","Recent progress in deep learning is revolutionizing the healthcare domain
including providing solutions to medication recommendations, especially
recommending medication combination for patients with complex health
conditions. Existing approaches either do not customize based on patient health
history, or ignore existing knowledge on drug-drug interactions (DDI) that
might lead to adverse outcomes. To fill this gap, we propose the Graph
Augmented Memory Networks (GAMENet), which integrates the drug-drug
interactions knowledge graph by a memory module implemented as a graph
convolutional networks, and models longitudinal patient records as the query.
It is trained end-to-end to provide safe and personalized recommendation of
medication combination. We demonstrate the effectiveness and safety of GAMENet
by comparing with several state-of-the-art methods on real EHR data. GAMENet
outperformed all baselines in all effectiveness measures, and also achieved
3.60% DDI rate reduction from existing EHR data.",2018-09-06,2018,2018-09,medical
Focus Group on Artificial Intelligence for Health,"Artificial Intelligence (AI) - the phenomenon of machines being able to solve
problems that require human intelligence - has in the past decade seen an
enormous rise of interest due to significant advances in effectiveness and use.
The health sector, one of the most important sectors for societies and
economies worldwide, is particularly interesting for AI applications, given the
ongoing digitalisation of all types of health information. The potential for AI
assistance in the health domain is immense, because AI can support medical
decision making at reduced costs, everywhere. However, due to the complexity of
AI algorithms, it is difficult to distinguish good from bad AI-based solutions
and to understand their strengths and weaknesses, which is crucial for
clarifying responsibilities and for building trust. For this reason, the
International Telecommunication Union (ITU) has established a new Focus Group
on ""Artificial Intelligence for Health"" (FG-AI4H) in partnership with the World
Health Organization (WHO). Health and care services are usually the
responsibility of a government - even when provided through private insurance
systems - and thus under the responsibility of WHO/ITU member states. FG-AI4H
will identify opportunities for international standardization, which will
foster the application of AI to health issues on a global scale. In particular,
it will establish a standardized assessment framework with open benchmarks for
the evaluation of AI-based methods for health, such as AI-based diagnosis,
triage or treatment decisions.",2018-09-13,2018,2018-09,medical
Finding Similar Medical Questions from Question Answering Websites,"The past few years have witnessed the flourishing of crowdsourced medical
question answering (Q&A) websites. Patients who have medical information
demands tend to post questions about their health conditions on these
crowdsourced Q&A websites and get answers from other users. However, we observe
that a large portion of new medical questions cannot be answered in time or
receive only few answers from these websites. On the other hand, we notice that
solved questions have great potential to solve this challenge. Motivated by
these, we propose an end-to-end system that can automatically find similar
questions for unsolved medical questions. By learning the vector presentation
of unsolved questions and their candidate similar questions, the proposed
system outputs similar questions according to the similarity between vector
representations. Through the vector representation, the similar questions are
found at the question level, and the diversity of medical questions expression
issue can be addressed. Further, we handle two more important issues, i.e.,
training data generation issue and efficiency issue, associated with the LSTM
training procedure and the retrieval of candidate similar questions. The
effectiveness of the proposed system is validated on a large-scale real-world
dataset collected from a crowdsourced maternal-infant Q&A website.",2018-10-14,2018,2018-10,medical
On the Generation of Medical Question-Answer Pairs,"Question answering (QA) has achieved promising progress recently. However,
answering a question in real-world scenarios like the medical domain is still
challenging, due to the requirement of external knowledge and the insufficient
quantity of high-quality training data. In the light of these challenges, we
study the task of generating medical QA pairs in this paper. With the insight
that each medical question can be considered as a sample from the latent
distribution of questions given answers, we propose an automated medical QA
pair generation framework, consisting of an unsupervised key phrase detector
that explores unstructured material for validity, and a generator that involves
a multi-pass decoder to integrate structural knowledge for diversity. A series
of experiments have been conducted on a real-world dataset collected from the
National Medical Licensing Examination of China. Both automatic evaluation and
human annotation demonstrate the effectiveness of the proposed method. Further
investigation shows that, by incorporating the generated QA pairs for training,
significant improvement in terms of accuracy can be achieved for the
examination QA system.",2018-11-01,2018,2018-11,medical
Exploiting Sentence Embedding for Medical Question Answering,"Despite the great success of word embedding, sentence embedding remains a
not-well-solved problem. In this paper, we present a supervised learning
framework to exploit sentence embedding for the medical question answering
task. The learning framework consists of two main parts: 1) a sentence
embedding producing module, and 2) a scoring module. The former is developed
with contextual self-attention and multi-scale techniques to encode a sentence
into an embedding tensor. This module is shortly called Contextual
self-Attention Multi-scale Sentence Embedding (CAMSE). The latter employs two
scoring strategies: Semantic Matching Scoring (SMS) and Semantic Association
Scoring (SAS). SMS measures similarity while SAS captures association between
sentence pairs: a medical question concatenated with a candidate choice, and a
piece of corresponding supportive evidence. The proposed framework is examined
by two Medical Question Answering(MedicalQA) datasets which are collected from
real-world applications: medical exam and clinical diagnosis based on
electronic medical records (EMR). The comparison results show that our proposed
framework achieved significant improvements compared to competitive baseline
approaches. Additionally, a series of controlled experiments are also conducted
to illustrate that the multi-scale strategy and the contextual self-attention
layer play important roles for producing effective sentence embedding, and the
two kinds of scoring strategies are highly complementary to each other for
question answering problems.",2018-11-15,2018,2018-11,medical
Multimodal Densenet,"Humans make accurate decisions by interpreting complex data from multiple
sources. Medical diagnostics, in particular, often hinge on human
interpretation of multi-modal information. In order for artificial intelligence
to make progress in automated, objective, and accurate diagnosis and prognosis,
methods to fuse information from multiple medical imaging modalities are
required. However, combining information from multiple data sources has several
challenges, as current deep learning architectures lack the ability to extract
useful representations from multimodal information, and often simple
concatenation is used to fuse such information. In this work, we propose
Multimodal DenseNet, a novel architecture for fusing multimodal data. Instead
of focusing on concatenation or early and late fusion, our proposed
architectures fuses information over several layers and gives the model
flexibility in how it combines information from multiple sources. We apply this
architecture to the challenge of polyp characterization and landmark
identification in endoscopy. Features from white light images are fused with
features from narrow band imaging or depth maps. This study demonstrates that
Multimodal DenseNet outperforms monomodal classification as well as other
multimodal fusion techniques by a significant margin on two different datasets.",2018-11-18,2018,2018-11,medical
Model-Based Reinforcement Learning for Sepsis Treatment,"Sepsis is a dangerous condition that is a leading cause of patient mortality.
Treating sepsis is highly challenging, because individual patients respond very
differently to medical interventions and there is no universally agreed-upon
treatment for sepsis. In this work, we explore the use of continuous
state-space model-based reinforcement learning (RL) to discover high-quality
treatment policies for sepsis patients. Our quantitative evaluation reveals
that by blending the treatment strategy discovered with RL with what clinicians
follow, we can obtain improved policies, potentially allowing for better
medical treatment for sepsis.",2018-11-23,2018,2018-11,medical
"XNet: A convolutional neural network (CNN) implementation for medical
  X-Ray image segmentation suitable for small datasets","X-Ray image enhancement, along with many other medical image processing
applications, requires the segmentation of images into bone, soft tissue, and
open beam regions. We apply a machine learning approach to this problem,
presenting an end-to-end solution which results in robust and efficient
inference. Since medical institutions frequently do not have the resources to
process and label the large quantity of X-Ray images usually needed for neural
network training, we design an end-to-end solution for small datasets, while
achieving state-of-the-art results. Our implementation produces an overall
accuracy of 92%, F1 score of 0.92, and an AUC of 0.98, surpassing classical
image processing techniques, such as clustering and entropy based methods,
while improving upon the output of existing neural networks used for
segmentation in non-medical contexts. The code used for this project is
available online.",2018-12-03,2018,2018-12,medical
Medical Diagnosis with a Novel SVM-CoDOA Based Hybrid Approach,"Machine Learning is an important sub-field of the Artificial Intelligence and
it has been become a very critical task to train Machine Learning techniques
via effective method or techniques. Recently, researchers try to use
alternative techniques to improve ability of Machine Learning techniques.
Moving from the explanations, objective of this study is to introduce a novel
SVM-CoDOA (Cognitive Development Optimization Algorithm trained Support Vector
Machines) system for general medical diagnosis. In detail, the system consists
of a SVM, which is trained by CoDOA, a newly developed optimization algorithm.
As it is known, use of optimization algorithms is an essential task to train
and improve Machine Learning techniques. In this sense, the study has provided
a medical diagnosis oriented problem scope in order to show effectiveness of
the SVM-CoDOA hybrid formation.",2019-02-02,2019,2019-02,medical
"Outlining the Design Space of Explainable Intelligent Systems for
  Medical Diagnosis","The adoption of intelligent systems creates opportunities as well as
challenges for medical work. On the positive side, intelligent systems have the
potential to compute complex data from patients and generate automated
diagnosis recommendations for doctors. However, medical professionals often
perceive such systems as black boxes and, therefore, feel concerned about
relying on system generated results to make decisions. In this paper, we
contribute to the ongoing discussion of explainable artificial intelligence
(XAI) by exploring the concept of explanation from a human-centered
perspective. We hypothesize that medical professionals would perceive a system
as explainable if the system was designed to think and act like doctors. We
report a preliminary interview study that collected six medical professionals'
reflection of how they interact with data for diagnosis and treatment purposes.
Our data reveals when and how doctors prioritize among various types of data as
a central part of their diagnosis process. Based on these findings, we outline
future directions regarding the design of XAI systems in the medical context.",2019-02-16,2019,2019-02,medical
"The Virtual Doctor: An Interactive Artificial Intelligence based on Deep
  Learning for Non-Invasive Prediction of Diabetes","Artificial intelligence (AI) will pave the way to a new era in medicine.
However, currently available AI systems do not interact with a patient, e.g.,
for anamnesis, and thus are only used by the physicians for predictions in
diagnosis or prognosis. However, these systems are widely used, e.g., in
diabetes or cancer prediction. In the current study, we developed an AI that is
able to interact with a patient (virtual doctor) by using a speech recognition
and speech synthesis system and thus can autonomously interact with the
patient, which is particularly important for, e.g., rural areas, where the
availability of primary medical care is strongly limited by low population
densities. As a proof-of-concept, the system is able to predict type 2 diabetes
mellitus (T2DM) based on non-invasive sensors and deep neural networks.
Moreover, the system provides an easy-to-interpret probability estimation for
T2DM for a given patient. Besides the development of the AI, we further
analyzed the acceptance of young people for AI in healthcare to estimate the
impact of such system in the future.",2019-03-09,2019,2019-03,medical
"Parallel Medical Imaging for Intelligent Medical Image Analysis:
  Concepts, Methods, and Applications","There has been much progress in data-driven artificial intelligence
technology for medical image analysis in the last decades. However, it still
remains challenging due to its distinctive complexity of acquiring and
annotating image data, extracting medical domain knowledge, and explaining the
diagnostic decision for medical image analysis. In this paper, we propose a
data-knowledge-driven framework termed as Parallel Medical Imaging (PMI) for
intelligent medical image analysis based on the methodology of interactive
ACP-based parallel intelligence. In the PMI framework, computational
experiments with predictive learning in a data-driven way are conducted to
extract medical knowledge for diagnostic decision support. Artificial imaging
systems are introduced to select and prescriptively generate medical image data
in a knowledge-driven way to utilize medical domain knowledge. Through the
closed-loop optimization based on parallel execution, our proposed PMI
framework can boost the generalization ability and alleviate the limitation of
medical interpretation for diagnostic decisions. Furthermore, we illustrate the
preliminary implementation of PMI method through the case studies of mammogram
analysis and skin lesion image analysis. Experimental results on several public
medical image datasets demonstrate the effectiveness of proposed PMI.",2019-03-12,2019,2019-03,medical
"Social Behavioral Phenotyping of Drosophila with a2D-3D Hybrid CNN
  Framework","Behavioural phenotyping of Drosophila is an important means in biological and
medical research to identify genetic, pathologic or psychologic impact on
animal behaviour.",2019-03-27,2019,2019-03,medical
Learning More with Less: GAN-based Medical Image Augmentation,"Convolutional Neural Network (CNN)-based accurate prediction typically
requires large-scale annotated training data. In Medical Imaging, however, both
obtaining medical data and annotating them by expert physicians are
challenging; to overcome this lack of data, Data Augmentation (DA) using
Generative Adversarial Networks (GANs) is essential, since they can synthesize
additional annotated training data to handle small and fragmented medical
images from various scanners--those generated images, realistic but completely
novel, can further fill the real image distribution uncovered by the original
dataset. As a tutorial, this paper introduces GAN-based Medical Image
Augmentation, along with tricks to boost classification/object
detection/segmentation performance using them, based on our experience and
related work. Moreover, we show our first GAN-based DA work using automatic
bounding box annotation, for robust CNN-based brain metastases detection on 256
x 256 MR images; GAN-based DA can boost 10% sensitivity in diagnosis with a
clinically acceptable number of additional False Positives, even with
highly-rough and inconsistent bounding boxes.",2019-03-29,2019,2019-03,medical
"MedGCN: Medication recommendation and lab test imputation via graph
  convolutional networks","Laboratory testing and medication prescription are two of the most important
routines in daily clinical practice. Developing an artificial intelligence
system that can automatically make lab test imputations and medication
recommendations can save costs on potentially redundant lab tests and inform
physicians of a more effective prescription. We present an intelligent medical
system (named MedGCN) that can automatically recommend the patients'
medications based on their incomplete lab tests, and can even accurately
estimate the lab values that have not been taken. In our system, we integrate
the complex relations between multiple types of medical entities with their
inherent features in a heterogeneous graph. Then we model the graph to learn a
distributed representation for each entity in the graph based on graph
convolutional networks (GCN). By the propagation of graph convolutional
networks, the entity representations can incorporate multiple types of medical
information that can benefit multiple medical tasks. Moreover, we introduce a
cross regularization strategy to reduce overfitting for multi-task training by
the interaction between the multiple tasks. In this study, we construct a graph
to associate 4 types of medical entities, i.e., patients, encounters, lab
tests, and medications, and applied a graph neural network to learn node
embeddings for medication recommendation and lab test imputation. we validate
our MedGCN model on two real-world datasets: NMEDW and MIMIC-III. The
experimental results on both datasets demonstrate that our model can outperform
the state-of-the-art in both tasks. We believe that our innovative system can
provide a promising and reliable way to assist physicians to make medication
prescriptions and to save costs on potentially redundant lab tests.",2019-03-31,2019,2019-03,medical
"A Strong Baseline for Domain Adaptation and Generalization in Medical
  Imaging","This work provides a strong baseline for the problem of multi-source
multi-target domain adaptation and generalization in medical imaging. Using a
diverse collection of ten chest X-ray datasets, we empirically demonstrate the
benefits of training medical imaging deep learning models on varied patient
populations for generalization to out-of-sample domains.",2019-04-02,2019,2019-04,medical
Artificial Intelligence for Pediatric Ophthalmology,"PURPOSE OF REVIEW: Despite the impressive results of recent artificial
intelligence (AI) applications to general ophthalmology, comparatively less
progress has been made toward solving problems in pediatric ophthalmology using
similar techniques. This article discusses the unique needs of pediatric
ophthalmology patients and how AI techniques can address these challenges,
surveys recent applications of AI to pediatric ophthalmology, and discusses
future directions in the field.
  RECENT FINDINGS: The most significant advances involve the automated
detection of retinopathy of prematurity (ROP), yielding results that rival
experts. Machine learning (ML) has also been successfully applied to the
classification of pediatric cataracts, prediction of post-operative
complications following cataract surgery, detection of strabismus and
refractive error, prediction of future high myopia, and diagnosis of reading
disability via eye tracking. In addition, ML techniques have been used for the
study of visual development, vessel segmentation in pediatric fundus images,
and ophthalmic image synthesis.
  SUMMARY: AI applications could significantly benefit clinical care for
pediatric ophthalmology patients by optimizing disease detection and grading,
broadening access to care, furthering scientific discovery, and improving
clinical efficiency. These methods need to match or surpass physician
performance in clinical trials before deployment with patients. Due to
widespread use of closed-access data sets and software implementations, it is
difficult to directly compare the performance of these approaches, and
reproducibility is poor. Open-access data sets and software implementations
could alleviate these issues, and encourage further AI applications to
pediatric ophthalmology.
  KEYWORDS: pediatric ophthalmology, machine learning, artificial intelligence,
deep learning",2019-04-06,2019,2019-04,medical
"A new direction to promote the implementation of artificial intelligence
  in natural clinical settings","Artificial intelligence (AI) researchers claim that they have made great
`achievements' in clinical realms. However, clinicians point out the so-called
`achievements' have no ability to implement into natural clinical settings. The
root cause for this huge gap is that many essential features of natural
clinical tasks are overlooked by AI system developers without medical
background. In this paper, we propose that the clinical benchmark suite is a
novel and promising direction to capture the essential features of the
real-world clinical tasks, hence qualifies itself for guiding the development
of AI systems, promoting the implementation of AI in real-world clinical
practice.",2019-05-08,2019,2019-05,medical
"Artificial intelligence technology in oncology: a new technological
  paradigm","Artificial Intelligence (AI) technology is based on theory and development of
computer systems able to perform tasks that normally require human
intelligence. In this context, deep learning is a family of computational
methods that allow an algorithm to program itself by learning from a large set
of examples that demonstrate the desired behavior. Application of these methods
to medical imaging can assist pathologists in the detection of cancer subtype,
gene mutations and/or metastases for applying appropriate therapies. The
purpose of this study is to show the emerging application of AI in medical
imaging to detect lung and breast cancer. Moreover, this study shows the
comparative evolutionary pathways of this emerging technology for three
critical cancers: lung, breast and thyroid. A main finding of this study is the
recognition that, since the late 1990, the sharp increase of technological
trajectories of AI technology applied in cancer imaging seems to be driven by
high rates of mortality of some types of cancer (e.g., lung and breast) in
order to find new techniques for a more accurate detection, characterization
and monitoring as well as to apply efficiently anticancer therapies that
increase the progression-free survival of patients: the so-called
mortality-driven AI technological trajectories. Results also suggest that this
new technology can generate a technological paradigm shift for diagnostic
assessment of any cancer type. However, application of these methods to medical
imaging requires further assessment and validation to assist pathologists to
increase the efficiency of their workflow in both routine tasks and critical
cases of diagnostics.",2019-05-14,2019,2019-05,medical
"Using Natural Language Processing to Develop an Automated Orthodontic
  Diagnostic System","We work on the task of automatically designing a treatment plan from the
findings included in the medical certificate written by the dentist. To develop
an artificial intelligence system that deals with free-form certificates
written by dentists, we annotate the findings and utilized the natural language
processing approach. As a result of the experiment using 990 certificates,
0.585 F1-score was achieved for the task of extracting orthodontic problems
from findings, and 0.584 correlation coefficient with the human ranking was
achieved for the treatment prioritization task.",2019-05-31,2019,2019-05,medical
"Pre-training of Graph Augmented Transformers for Medication
  Recommendation","Medication recommendation is an important healthcare application. It is
commonly formulated as a temporal prediction task. Hence, most existing works
only utilize longitudinal electronic health records (EHRs) from a small number
of patients with multiple visits ignoring a large number of patients with a
single visit (selection bias). Moreover, important hierarchical knowledge such
as diagnosis hierarchy is not leveraged in the representation learning process.
To address these challenges, we propose G-BERT, a new model to combine the
power of Graph Neural Networks (GNNs) and BERT (Bidirectional Encoder
Representations from Transformers) for medical code representation and
medication recommendation. We use GNNs to represent the internal hierarchical
structures of medical codes. Then we integrate the GNN representation into a
transformer-based visit encoder and pre-train it on EHR data from patients only
with a single visit. The pre-trained visit encoder and representation are then
fine-tuned for downstream predictive tasks on longitudinal EHRs from patients
with multiple visits. G-BERT is the first to bring the language model
pre-training schema into the healthcare domain and it achieved state-of-the-art
performance on the medication recommendation task.",2019-06-02,2019,2019-06,medical
Artificial Intelligence in Clinical Health Care Applications: Viewpoint,"The idea of Artificial Intelligence (AI) has a long history. It turned out,
however, that reaching intelligence at human levels is more complicated than
originally anticipated. Currently we are experiencing a renewed interest in AI,
fueled by an enormous increase in computing power and an even larger increase
in data, in combination with improved AI technologies like deep learning.
Healthcare is considered the next domain to be revolutionized by Artificial
Intelligence. While AI approaches are excellently suited to develop certain
algorithms, for biomedical applications there are specific challenges. We
propose recommendations to improve AI projects in the biomedical space and
especially clinical healthcare.",2019-06-05,2019,2019-06,medical
"High Accuracy Classification of White Blood Cells using TSLDA Classifier
  and Covariance Features","creating automated processes in different areas of medical science with the
application of engineering tools is a highly growing field over recent decades.
In this context, many medical image processing and analyzing researchers use
worthwhile methods in artificial intelligence, which can reduce necessary human
power while increases accuracy of results. Among various medical images, blood
microscopic images play a vital role in heart failure diagnosis, e.g., blood
cancers. The prominent component in blood cancer diagnosis is white blood cells
(WBCs) which due to its general characteristics in microscopic images sometimes
make difficulties in recognition and classification tasks such as non-uniform
colors/illuminances, different shapes, sizes, and textures. Moreover,
overlapped WBCs in bone marrow images and neighboring to red blood cells are
identified as reasons for errors in the classification task. In this paper, we
have endeavored to segment various parts in medical images via Na\""ive Bayes
clustering method and in next stage via TSLDA classifier, which is supplied by
features acquired from covariance descriptor results in the accuracy of 98.02%.
It seems that this result is delightful in WBCs recognition.",2019-06-12,2019,2019-06,medical
"Developing an App to interpret Chest X-rays to support the diagnosis of
  respiratory pathology with Artificial Intelligence","In this paper we present our work to improve access to diagnosis in remote
areas where good quality medical services may be lacking. We develop new
Machine Learning methodologies for deployment onto mobile devices to help the
early diagnosis of a number of life-threatening conditions using X-ray images.
By using the latest developments in fast and portable Artificial Intelligence
environments, we develop a smartphone app using an Artificial Neural Network to
assist physicians in their diagnostic.",2019-06-26,2019,2019-06,medical
"A Survey on Explainable Artificial Intelligence (XAI): Towards Medical
  XAI","Recently, artificial intelligence and machine learning in general have
demonstrated remarkable performances in many tasks, from image processing to
natural language processing, especially with the advent of deep learning. Along
with research progress, they have encroached upon many different fields and
disciplines. Some of them require high level of accountability and thus
transparency, for example the medical sector. Explanations for machine
decisions and predictions are thus needed to justify their reliability. This
requires greater interpretability, which often means we need to understand the
mechanism underlying the algorithms. Unfortunately, the blackbox nature of the
deep learning is still unresolved, and many machine decisions are still poorly
understood. We provide a review on interpretabilities suggested by different
research works and categorize them. The different categories show different
dimensions in interpretability research, from approaches that provide
""obviously"" interpretable information to the studies of complex patterns. By
applying the same categorization to interpretability in medical research, it is
hoped that (1) clinicians and practitioners can subsequently approach these
methods with caution, (2) insights into interpretability will be born with more
considerations for medical practices, and (3) initiatives to push forward
data-based, mathematically- and technically-grounded medical education are
encouraged.",2019-07-17,2019,2019-07,medical
"Linking Physicians to Medical Research Results via Knowledge Graph
  Embeddings and Twitter","Informing professionals about the latest research results in their field is a
particularly important task in the field of health care, since any development
in this field directly improves the health status of the patients. Meanwhile,
social media is an infrastructure that allows public instant sharing of
information, thus it has recently become popular in medical applications. In
this study, we apply Multi Distance Knowledge Graph Embeddings (MDE) to link
physicians and surgeons to the latest medical breakthroughs that are shared as
the research results on Twitter. Our study shows that using this method
physicians can be informed about the new findings in their field given that
they have an account dedicated to their profession.",2019-07-24,2019,2019-07,medical
"Clinical acceptance of software based on artificial intelligence
  technologies (radiology)","Aim: provide a methodological framework for the process of clinical tests,
clinical acceptance, and scientific assessment of algorithms and software based
on the artificial intelligence (AI) technologies. Clinical tests are considered
as a preparation stage for the software registration as a medical product. The
authors propose approaches to evaluate accuracy and efficiency of the AI
algorithms for radiology.",2019-08-01,2019,2019-08,medical
Incorporating Domain Knowledge into Medical NLI using Knowledge Graphs,"Recently, biomedical version of embeddings obtained from language models such
as BioELMo have shown state-of-the-art results for the textual inference task
in the medical domain. In this paper, we explore how to incorporate structured
domain knowledge, available in the form of a knowledge graph (UMLS), for the
Medical NLI task. Specifically, we experiment with fusing embeddings obtained
from knowledge graph with the state-of-the-art approaches for NLI task (ESIM
model). We also experiment with fusing the domain-specific sentiment
information for the task. Experiments conducted on MedNLI dataset clearly show
that this strategy improves the baseline BioELMo architecture for the Medical
NLI task.",2019-08-31,2019,2019-08,medical
"DeepHealth: Review and challenges of artificial intelligence in health
  informatics","Artificial intelligence has provided us with an exploration of a whole new
research era. As more data and better computational power become available, the
approach is being implemented in various fields. The demand for it in health
informatics is also increasing, and we can expect to see the potential benefits
of its applications in healthcare. It can help clinicians diagnose disease,
identify drug effects for each patient, understand the relationship between
genotypes and phenotypes, explore new phenotypes or treatment recommendations,
and predict infectious disease outbreaks with high accuracy. In contrast to
traditional models, recent artificial intelligence approaches do not require
domain-specific data pre-processing, and it is expected that it will ultimately
change life in the future. Despite its notable advantages, there are some key
challenges on data (high dimensionality, heterogeneity, time dependency,
sparsity, irregularity, lack of label, bias) and model (reliability,
interpretability, feasibility, security, scalability) for practical use. This
article presents a comprehensive review of research applying artificial
intelligence in health informatics, focusing on the last seven years in the
fields of medical imaging, electronic health records, genomics, sensing, and
online communication health, as well as challenges and promising directions for
future research. We highlight ongoing popular approaches' research and identify
several challenges in building models.",2019-09-01,2019,2019-09,medical
"A Method to Learn Embedding of a Probabilistic Medical Knowledge Graph:
  Algorithm Development","This paper proposes an algorithm named as PrTransH to learn embedding vectors
from real world EMR data based medical knowledge. The unique challenge in
embedding medical knowledge graph from real world EMR data is that the
uncertainty of knowledge triplets blurs the border between ""correct triplet""
and ""wrong triplet"", changing the fundamental assumption of many existing
algorithms. To address the challenge, some enhancements are made to existing
TransH algorithm, including: 1) involve probability of medical knowledge
triplet into training objective; 2) replace the margin-based ranking loss with
unified loss calculation considering both valid and corrupted triplets; 3)
augment training data set with medical background knowledge. Verifications on
real world EMR data based medical knowledge graph prove that PrTransH
outperforms TransH in link prediction task. To the best of our survey, this
paper is the first one to learn and verify knowledge embedding on probabilistic
knowledge graphs.",2019-09-02,2019,2019-09,medical
Lattice-Based Fuzzy Medical Expert System for Low Back Pain Management,"Low Back Pain (LBP) is a common medical condition that deprives many
individuals worldwide of their normal routine activities. In the absence of
external biomarkers, diagnosis of LBP is quite challenging. It requires dealing
with several clinical variables, which have no precisely quantified values.
Aiming at the development of a fuzzy medical expert system for LBP management,
this research proposes an attractive lattice-based knowledge representation
scheme for handling imprecision in knowledge, offering a suitable design
methodology for a fuzzy knowledge base and a fuzzy inference system. The fuzzy
knowledge base is constructed in modular fashion, with each module capturing
interrelated medical knowledge about the relevant clinical history, clinical
examinations and laboratory investigation results. This approach in design
ensures optimality, consistency and preciseness in the knowledge base and
scalability. The fuzzy inference system, which uses the Mamdani method, adopts
the triangular membership function for fuzzification and the Centroid of Area
technique for defuzzification. A prototype of this system has been built using
the knowledge extracted from the domain expert physicians. The inference of the
system against a few available patient records at the ESI Hospital, Sealdah has
been checked. It was found to be acceptable by the verifying medical experts.",2019-09-09,2019,2019-09,medical
"Automated Blood Cell Detection and Counting via Deep Learning for
  Microfluidic Point-of-Care Medical Devices","Automated in-vitro cell detection and counting have been a key theme for
artificial and intelligent biological analysis such as biopsy, drug analysis
and decease diagnosis. Along with the rapid development of microfluidics and
lab-on-chip technologies, in-vitro live cell analysis has been one of the
critical tasks for both research and industry communities. However, it is a
great challenge to obtain and then predict the precise information of live
cells from numerous microscopic videos and images. In this paper, we
investigated in-vitro detection of white blood cells using deep neural
networks, and discussed how state-of-the-art machine learning techniques could
fulfil the needs of medical diagnosis. The approach we used in this study was
based on Faster Region-based Convolutional Neural Networks (Faster RCNNs), and
a transfer learning process was applied to apply this technique to the
microscopic detection of blood cells. Our experimental results demonstrated
that fast and efficient analysis of blood cells via automated microscopic
imaging can achieve much better accuracy and faster speed than the
conventionally applied methods, implying a promising future of this technology
to be applied to the microfluidic point-of-care medical devices.",2019-09-11,2019,2019-09,medical
Evaluating and Boosting Uncertainty Quantification in Classification,"Emergence of artificial intelligence techniques in biomedical applications
urges the researchers to pay more attention on the uncertainty quantification
(UQ) in machine-assisted medical decision making. For classification tasks,
prior studies on UQ are difficult to compare with each other, due to the lack
of a unified quantitative evaluation metric. Considering that well-performing
UQ models ought to know when the classification models act incorrectly, we
design a new evaluation metric, area under Confidence-Classification
Characteristic curves (AUCCC), to quantitatively evaluate the performance of
the UQ models. AUCCC is threshold-free, robust to perturbation, and insensitive
to the classification performance. We evaluate several UQ methods (e.g., max
softmax output) with AUCCC to validate its effectiveness. Furthermore, a simple
scheme, named Uncertainty Distillation (UDist), is developed to boost the UQ
performance, where a confidence model is distilling the confidence estimated by
deep ensembles. The proposed method is easy to implement; it consistently
outperforms strong baselines on natural and medical image datasets in our
experiments.",2019-09-13,2019,2019-09,medical
"Distributed representation of patients and its use for medical cost
  prediction","Efficient representation of patients is very important in the healthcare
domain and can help with many tasks such as medical risk prediction. Many
existing methods, such as diagnostic Cost Groups (DCG), rely on expert
knowledge to build patient representation from medical data, which is resource
consuming and non-scalable. Unsupervised machine learning algorithms are a good
choice for automating the representation learning process. However, there is
very little research focusing on onpatient-level representation learning
directly from medical claims. In this paper, weproposed a novel patient vector
learning architecture that learns high quality,fixed-length patient
representation from claims data. We conducted several experiments to test the
quality of our learned representation, and the empirical results show that our
learned patient vectors are superior to vectors learned through other methods
including a popular commercial model. Lastly, we provide potential clinical
interpretation for using our representation on predictive tasks, as
interpretability is vital in the healthcare domain",2019-09-13,2019,2019-09,medical
"Clinical Text Generation through Leveraging Medical Concept and
  Relations","With a neural sequence generation model, this study aims to develop a method
of writing the patient clinical texts given a brief medical history. As a
proof-of-a-concept, we have demonstrated that it can be workable to use medical
concept embedding in clinical text generation. Our model was based on the
Sequence-to-Sequence architecture and trained with a large set of de-identified
clinical text data. The quantitative result shows that our concept embedding
method decreased the perplexity of the baseline architecture. Also, we discuss
the analyzed results from a human evaluation performed by medical doctors.",2019-10-02,2019,2019-10,medical
Deep Semantic Segmentation of Natural and Medical Images: A Review,"The semantic image segmentation task consists of classifying each pixel of an
image into an instance, where each instance corresponds to a class. This task
is a part of the concept of scene understanding or better explaining the global
context of an image. In the medical image analysis domain, image segmentation
can be used for image-guided interventions, radiotherapy, or improved
radiological diagnostics. In this review, we categorize the leading deep
learning-based medical and non-medical image segmentation solutions into six
main groups of deep architectural, data synthesis-based, loss function-based,
sequenced models, weakly supervised, and multi-task methods and provide a
comprehensive review of the contributions in each of these groups. Further, for
each group, we analyze each variant of these groups and discuss the limitations
of the current approaches and present potential future research directions for
semantic image segmentation.",2019-10-16,2019,2019-10,medical
"NCI Workshop on Artificial Intelligence in Radiation Oncology: Training
  the Next Generation","Artificial intelligence (AI) is about to touch every aspect of radiotherapy
from consultation, treatment planning, quality assurance, therapy delivery, to
outcomes modeling. There is an urgent need to train radiation oncologists and
medical physicists in data science to help shepherd AI solutions into clinical
practice. Poorly trained personnel may do more harm than good when attempting
to apply rapidly developing and complex technologies. As the amount of AI
research expands in our field, the radiation oncology community needs to
discuss how to educate future generations in this area. The National Cancer
Institute (NCI) Workshop on AI in Radiation Oncology (Shady Grove, MD, April
4-5, 2019) was the first
(https://dctd.cancer.gov/NewsEvents/20190523_ai_in_radiation_oncology.htm) of
two data science workshops in radiation oncology hosted by the NCI in 2019.
During this workshop, the Training and Education Working Group was formed by
volunteers among the invited attendees. Its members represent radiation
oncology, medical physics, radiology, computer science, industry, and the NCI.
In this perspective article written by members of the Training and Education
Working Group, we provide and discuss Action Points relevant for future
trainees interested in radiation oncology AI: (1) creating AI awareness and
responsible conduct; (2) implementing a practical didactic curriculum; (3)
creating a publicly available database of training resources; and (4)
accelerate learning and funding opportunities. Together, these Action Points
can facilitate the translation of AI into clinical practice.",2019-10-18,2019,2019-10,medical
"CAI4CAI: The Rise of Contextual Artificial Intelligence in Computer
  Assisted Interventions","Data-driven computational approaches have evolved to enable extraction of
information from medical images with a reliability, accuracy and speed which is
already transforming their interpretation and exploitation in clinical
practice. While similar benefits are longed for in the field of interventional
imaging, this ambition is challenged by a much higher heterogeneity. Clinical
workflows within interventional suites and operating theatres are extremely
complex and typically rely on poorly integrated intra-operative devices,
sensors, and support infrastructures. Taking stock of some of the most exciting
developments in machine learning and artificial intelligence for computer
assisted interventions, we highlight the crucial need to take context and human
factors into account in order to address these challenges. Contextual
artificial intelligence for computer assisted intervention, or CAI4CAI, arises
as an emerging opportunity feeding into the broader field of surgical data
science. Central challenges being addressed in CAI4CAI include how to integrate
the ensemble of prior knowledge and instantaneous sensory information from
experts, sensors and actuators; how to create and communicate a faithful and
actionable shared representation of the surgery among a mixed human-AI actor
team; how to design interventional systems and associated cognitive shared
control schemes for online uncertainty-aware collaborative decision making
ultimately producing more precise and reliable interventions.",2019-10-20,2019,2019-10,medical
"Artificial Intelligence and the Future of Psychiatry: Qualitative
  Findings from a Global Physician Survey","The potential for machine learning to disrupt the medical profession is the
subject of ongoing debate within biomedical informatics. This study aimed to
explore psychiatrists' opinions about the potential impact of innovations in
artificial intelligence and machine learning on psychiatric practice. In Spring
2019, we conducted a web-based survey of 791 psychiatrists from 22 countries
worldwide. The survey measured opinions about the likelihood future technology
would fully replace physicians in performing ten key psychiatric tasks. This
study involved qualitative descriptive analysis of written response to three
open-ended questions in the survey. Comments were classified into four major
categories in relation to the impact of future technology on
patient-psychiatric interactions, the quality of patient medical care, the
profession of psychiatry, and health systems. Overwhelmingly, psychiatrists
were skeptical that technology could fully replace human empathy. Many
predicted that 'man and machine' would increasingly collaborate in undertaking
clinical decisions, with mixed opinions about the benefits and harms of such an
arrangement. Participants were optimistic that technology might improve
efficiencies and access to care, and reduce costs. Ethical and regulatory
considerations received limited attention. This study presents timely
information of psychiatrists' view about the scope of artificial intelligence
and machine learning on psychiatric practice. Psychiatrists expressed divergent
views about the value and impact of future technology with worrying omissions
about practice guidelines, and ethical and regulatory issues.",2019-10-22,2019,2019-10,medical
"Potential Applications of Machine Learning at Multidisciplinary Medical
  Team Meetings","While machine learning (ML) systems have produced great advances in several
domains, their use in support of complex cooperative work remains a research
challenge. A particularly challenging setting, and one that may benefit from ML
support is the work of multidisciplinary medical teams (MDTs). This paper
focuses on the activities performed during the multidisciplinary medical team
meeting (MDTM), reviewing their main characteristics in light of a longitudinal
analysis of several MDTs in a large teaching hospital over a period of ten
years and of our development of ML methods to support MDTMs, and identifying
opportunities and possible pitfalls for the use of ML to support MDTMs.",2019-11-03,2019,2019-11,medical
"Opportunities for artificial intelligence in advancing precision
  medicine","Machine learning (ML), deep learning (DL), and artificial intelligence (AI)
are of increasing importance in biomedicine. The goal of this work is to show
progress in ML in digital health, to exemplify future needs and trends, and to
identify any essential prerequisites of AI and ML for precision health.
High-throughput technologies are delivering growing volumes of biomedical data,
such as large-scale genome-wide sequencing assays, libraries of medical images,
or drug perturbation screens of healthy, developing, and diseased tissue.
Multi-omics data in biomedicine is deep and complex, offering an opportunity
for data-driven insights and automated disease classification. Learning from
these data will open our understanding and definition of healthy baselines and
disease signatures. State-of-the-art applications of deep neural networks
include digital image recognition, single cell clustering, and virtual drug
screens, demonstrating breadths and power of ML in biomedicine. Significantly,
AI and systems biology have embraced big data challenges and may enable novel
biotechnology-derived therapies to facilitate the implementation of precision
medicine approaches.",2019-11-17,2019,2019-11,medical
Medication Regimen Extraction From Medical Conversations,"Extracting relevant information from medical conversations and providing it
to doctors and patients might help in addressing doctor burnout and patient
forgetfulness. In this paper, we focus on extracting the Medication Regimen
(dosage and frequency for medications) discussed in a medical conversation. We
frame the problem as a Question Answering (QA) task and perform comparative
analysis over: a QA approach, a new combined QA and Information Extraction
approach, and other baselines. We use a small corpus of 6,692 annotated
doctor-patient conversations for the task. Clinical conversation corpora are
costly to create, difficult to handle (because of data privacy concerns), and
thus scarce. We address this data scarcity challenge through data augmentation
methods, using publicly available embeddings and pretrain part of the network
on a related task (summarization) to improve the model's performance. Compared
to the baseline, our best-performing models improve the dosage and frequency
extractions' ROUGE-1 F1 scores from 54.28 and 37.13 to 89.57 and 45.94,
respectively. Using our best-performing model, we present the first fully
automated system that can extract Medication Regimen tags from spontaneous
doctor-patient conversations with about $\approx$71% accuracy.",2019-12-10,2019,2019-12,medical
Artificial Intelligence in Surgery,"Artificial Intelligence (AI) is gradually changing the practice of surgery
with the advanced technological development of imaging, navigation and robotic
intervention. In this article, the recent successful and influential
applications of AI in surgery are reviewed from pre-operative planning and
intra-operative guidance to the integration of surgical robots. We end with
summarizing the current state, emerging trends and major challenges in the
future development of AI in surgery.",2019-12-23,2019,2019-12,medical
"Unsupervised Online Feature Selection for Cost-Sensitive Medical
  Diagnosis","In medical diagnosis, physicians predict the state of a patient by checking
measurements (features) obtained from a sequence of tests, e.g., blood test,
urine test, followed by invasive tests. As tests are often costly, one would
like to obtain only those features (tests) that can establish the presence or
absence of the state conclusively. Another aspect of medical diagnosis is that
we are often faced with unsupervised prediction tasks as the true state of the
patients may not be known. Motivated by such medical diagnosis problems, we
consider a {\it Cost-Sensitive Medical Diagnosis} (CSMD) problem, where the
true state of patients is unknown. We formulate the CSMD problem as a feature
selection problem where each test gives a feature that can be used in a
prediction model. Our objective is to learn strategies for selecting the
features that give the best trade-off between accuracy and costs. We exploit
the `Weak Dominance' property of problem to develop online algorithms that
identify a set of features which provides an `optimal' trade-off between cost
and accuracy of prediction without requiring to know the true state of the
medical condition. Our empirical results validate the performance of our
algorithms on problem instances generated from real-world datasets.",2019-12-25,2019,2019-12,medical
A New Approach for Explainable Multiple Organ Annotation with Few Data,"Despite the recent successes of deep learning, such models are still far from
some human abilities like learning from few examples, reasoning and explaining
decisions. In this paper, we focus on organ annotation in medical images and we
introduce a reasoning framework that is based on learning fuzzy relations on a
small dataset for generating explanations. Given a catalogue of relations, it
efficiently induces the most relevant relations and combines them for building
constraints in order to both solve the organ annotation task and generate
explanations. We test our approach on a publicly available dataset of medical
images where several organs are already segmented. A demonstration of our model
is proposed with an example of explained annotations. It was trained on a small
training set containing as few as a couple of examples.",2019-12-30,2019,2019-12,medical
"A Preliminary Approach for Learning Relational Policies for the
  Management of Critically Ill Children","The increased use of electronic health records has made possible the
automated extraction of medical policies from patient records to aid in the
development of clinical decision support systems. We adapted a boosted
Statistical Relational Learning (SRL) framework to learn probabilistic rules
from clinical hospital records for the management of physiologic parameters of
children with severe cardiac or respiratory failure who were managed with
extracorporeal membrane oxygenation. In this preliminary study, the results
were promising. In particular, the algorithm returned logic rules for medical
actions that are consistent with medical reasoning.",2020-01-13,2020,2020-01,medical
Practical Approach of Knowledge Management in Medical Science,"Knowledge organization, infrastructure, and knowledge-based activities are
all subjects that help in the creation of business strategies for the new
enterprise. In this paper, the first basics of knowledge-based systems are
studied. Practical issues and challenges of Knowledge Management (KM)
implementations are then illustrated. Finally, a comparison of different
knowledge-based projects is presented along with abstracted information on
their implementation, techniques, and results. Most of these projects are in
the field of medical science. Based on our study and evaluation of different KM
projects, we conclude that KM is being used in every science, industry, and
business. But its importance in medical science and assisted living projects
are highlighted nowadays with the most of research institutes. Most medical
centers are interested in using knowledge-based services like portals and
learning techniques of knowledge for their future innovations and supports.",2020-01-16,2020,2020-01,medical
"The Risk to Population Health Equity Posed by Automated Decision
  Systems: A Narrative Review","Artificial intelligence is already ubiquitous, and is increasingly being used
to autonomously make ever more consequential decisions. However, there has been
relatively little research into the existing and possible consequences for
population health equity. A narrative review was undertaken using a hermeneutic
approach to explore current and future uses of narrow AI and automated decision
systems (ADS) in medicine and public health, issues that have emerged, and
implications for equity. Accounts reveal a tremendous expectation on AI to
transform medical and public health practices. Prominent demonstrations of AI
capability - particularly in diagnostic decision making, risk prediction, and
surveillance - are stimulating rapid adoption, spurred by COVID-19. Automated
decisions being made have significant consequences for individual and
population health and wellbeing. Meanwhile, it is evident that hazards
including bias, incontestability, and privacy erosion have emerged in sensitive
domains such as criminal justice where narrow AI and ADS are in common use.
Reports of issues arising from their use in health are already appearing. As
the use of ADS in health expands, it is probable that these hazards will
manifest more widely. Bias, incontestability, and privacy erosion give rise to
mechanisms by which existing social, economic and health disparities are
perpetuated and amplified. Consequently, there is a significant risk that use
of ADS in health will exacerbate existing population health inequities. The
industrial scale and rapidity with which ADS can be applied heightens the risk
to population health equity. It is incumbent on health practitioners and policy
makers therefore to explore the potential implications of using ADS, to ensure
the use of artificial intelligence promotes population health and equity.",2020-01-18,2020,2020-01,medical
"Artificial intelligence in medicine and healthcare: a review and
  classification of current and near-future applications and their ethical and
  social Impact","This paper provides an overview of the current and near-future applications
of Artificial Intelligence (AI) in Medicine and Health Care and presents a
classification according to their ethical and societal aspects, potential
benefits and pitfalls, and issues that can be considered controversial and are
not deeply discussed in the literature.
  This work is based on an analysis of the state of the art of research and
technology, including existing software, personal monitoring devices, genetic
tests and editing tools, personalized digital models, online platforms,
augmented reality devices, and surgical and companion robotics. Motivated by
our review, we present and describe the notion of 'extended personalized
medicine', we then review existing applications of AI in medicine and
healthcare and explore the public perception of medical AI systems, and how
they show, simultaneously, extraordinary opportunities and drawbacks that even
question fundamental medical concepts. Many of these topics coincide with
urgent priorities recently defined by the World Health Organization for the
coming decade. In addition, we study the transformations of the roles of
doctors and patients in an age of ubiquitous information, identify the risk of
a division of Medicine into 'fake-based', 'patient-generated', and
'scientifically tailored', and draw the attention of some aspects that need
further thorough analysis and public debate.",2020-01-22,2020,2020-01,medical
Bayesian Networks in Healthcare: Distribution by Medical Condition,"Bayesian networks (BNs) have received increasing research attention that is
not matched by adoption in practice and yet have potential to significantly
benefit healthcare. Hitherto, research works have not investigated the types of
medical conditions being modelled with BNs, nor whether any differences exist
in how and why they are applied to different conditions. This research seeks to
identify and quantify the range of medical conditions for which
healthcare-related BN models have been proposed, and the differences in
approach between the most common medical conditions to which they have been
applied. We found that almost two-thirds of all healthcare BNs are focused on
four conditions: cardiac, cancer, psychological and lung disorders. We believe
that a lack of understanding regarding how BNs work and what they are capable
of exists, and that it is only with greater understanding and promotion that we
may ever realise the full potential of BNs to effect positive change in daily
healthcare practice.",2020-02-01,2020,2020-02,medical
"Deepfakes for Medical Video De-Identification: Privacy Protection and
  Diagnostic Information Preservation","Data sharing for medical research has been difficult as open-sourcing
clinical data may violate patient privacy. Traditional methods for face
de-identification wipe out facial information entirely, making it impossible to
analyze facial behavior. Recent advancements on whole-body keypoints detection
also rely on facial input to estimate body keypoints. Both facial and body
keypoints are critical in some medical diagnoses, and keypoints invariability
after de-identification is of great importance. Here, we propose a solution
using deepfake technology, the face swapping technique. While this swapping
method has been criticized for invading privacy and portraiture right, it could
conversely protect privacy in medical video: patients' faces could be swapped
to a proper target face and become unrecognizable. However, it remained an open
question that to what extent the swapping de-identification method could affect
the automatic detection of body keypoints. In this study, we apply deepfake
technology to Parkinson's disease examination videos to de-identify subjects,
and quantitatively show that: face-swapping as a de-identification approach is
reliable, and it keeps the keypoints almost invariant, significantly better
than traditional methods. This study proposes a pipeline for video
de-identification and keypoint preservation, clearing up some ethical
restrictions for medical data sharing. This work could make open-source high
quality medical video datasets more feasible and promote future medical
research that benefits our society.",2020-02-07,2020,2020-02,medical
Development of an Expert System for Diabetic Type-2 Diet,"A successful intelligent control of patient food for treatment purpose must
combines patient interesting food list and doctors efficient treatment food
list. Actually, many rural communities in Sudan have extremely limited access
to diabetic diet centers. People travel long distances to clinics or medical
facilities, and there is a shortage of medical experts in most of these
facilities. This results in slow service, and patients end up waiting long
hours without receiving any attention. Hence diabetic diet expert systems can
play a significant role in such cases where medical experts are not readily
available. This paper presents the design and implementation of an intelligent
medical expert system for diabetes diet that intended to be used in Sudan. The
development of the proposed expert system went through a number of stages such
problem and need identification, requirements analysis, knowledge acquisition,
formalization, design and implementation. Visual prolog was used for designing
the graphical user interface and the implementation of the system. The proposed
expert system is a promising helpful tool that reduces the workload for
physicians and provides diabetics with simple and valuable assistance.",2020-02-22,2020,2020-02,medical
FocalMix: Semi-Supervised Learning for 3D Medical Image Detection,"Applying artificial intelligence techniques in medical imaging is one of the
most promising areas in medicine. However, most of the recent success in this
area highly relies on large amounts of carefully annotated data, whereas
annotating medical images is a costly process. In this paper, we propose a
novel method, called FocalMix, which, to the best of our knowledge, is the
first to leverage recent advances in semi-supervised learning (SSL) for 3D
medical image detection. We conducted extensive experiments on two widely used
datasets for lung nodule detection, LUNA16 and NLST. Results show that our
proposed SSL methods can achieve a substantial improvement of up to 17.3% over
state-of-the-art supervised learning approaches with 400 unlabeled CT scans.",2020-03-20,2020,2020-03,medical
DAISI: Database for AI Surgical Instruction,"Telementoring surgeons as they perform surgery can be essential in the
treatment of patients when in situ expertise is not available. Nonetheless,
expert mentors are often unavailable to provide trainees with real-time medical
guidance. When mentors are unavailable, a fallback autonomous mechanism should
provide medical practitioners with the required guidance. However,
AI/autonomous mentoring in medicine has been limited by the availability of
generalizable prediction models, and surgical procedures datasets to train
those models with. This work presents the initial steps towards the development
of an intelligent artificial system for autonomous medical mentoring.
Specifically, we present the first Database for AI Surgical Instruction
(DAISI). DAISI leverages on images and instructions to provide step-by-step
demonstrations of how to perform procedures from various medical disciplines.
The dataset was acquired from real surgical procedures and data from academic
textbooks. We used DAISI to train an encoder-decoder neural network capable of
predicting medical instructions given a current view of the surgery.
Afterwards, the instructions predicted by the network were evaluated using
cumulative BLEU scores and input from expert physicians. According to the BLEU
scores, the predicted and ground truth instructions were as high as 67%
similar. Additionally, expert physicians subjectively assessed the algorithm
using Likert scale, and considered that the predicted descriptions were related
to the images. This work provides a baseline for AI algorithms to assist in
autonomous medical mentoring.",2020-03-22,2020,2020-03,medical
"From Bit To Bedside: A Practical Framework For Artificial Intelligence
  Product Development In Healthcare","Artificial Intelligence (AI) in healthcare holds great potential to expand
access to high-quality medical care, whilst reducing overall systemic costs.
Despite hitting the headlines regularly and many publications of
proofs-of-concept, certified products are failing to breakthrough to the
clinic. AI in healthcare is a multi-party process with deep knowledge required
in multiple individual domains. The lack of understanding of the specific
challenges in the domain is, therefore, the major contributor to the failure to
deliver on the big promises. Thus, we present a decision perspective framework,
for the development of AI-driven biomedical products, from conception to market
launch. Our framework highlights the risks, objectives and key results which
are typically required to proceed through a three-phase process to the market
launch of a validated medical AI product. We focus on issues related to
Clinical validation, Regulatory affairs, Data strategy and Algorithmic
development. The development process we propose for AI in healthcare software
strongly diverges from modern consumer software development processes. We
highlight the key time points to guide founders, investors and key stakeholders
throughout their relevant part of the process. Our framework should be seen as
a template for innovation frameworks, which can be used to coordinate team
communications and responsibilities towards a reasonable product development
roadmap, thus unlocking the potential of AI in medicine.",2020-03-23,2020,2020-03,medical
"Can Embeddings Adequately Represent Medical Terminology? New Large-Scale
  Medical Term Similarity Datasets Have the Answer!","A large number of embeddings trained on medical data have emerged, but it
remains unclear how well they represent medical terminology, in particular
whether the close relationship of semantically similar medical terms is encoded
in these embeddings. To date, only small datasets for testing medical term
similarity are available, not allowing to draw conclusions about the
generalisability of embeddings to the enormous amount of medical terms used by
doctors. We present multiple automatically created large-scale medical term
similarity datasets and confirm their high quality in an annotation study with
doctors. We evaluate state-of-the-art word and contextual embeddings on our new
datasets, comparing multiple vector similarity metrics and word vector
aggregation techniques. Our results show that current embeddings are limited in
their ability to adequately encode medical terms. The novel datasets thus form
a challenging new benchmark for the development of medical embeddings able to
accurately represent the whole medical terminology.",2020-03-24,2020,2020-03,medical
"Mapping the Landscape of Artificial Intelligence Applications against
  COVID-19","COVID-19, the disease caused by the SARS-CoV-2 virus, has been declared a
pandemic by the World Health Organization, which has reported over 18 million
confirmed cases as of August 5, 2020. In this review, we present an overview of
recent studies using Machine Learning and, more broadly, Artificial
Intelligence, to tackle many aspects of the COVID-19 crisis. We have identified
applications that address challenges posed by COVID-19 at different scales,
including: molecular, by identifying new or existing drugs for treatment;
clinical, by supporting diagnosis and evaluating prognosis based on medical
imaging and non-invasive measures; and societal, by tracking both the epidemic
and the accompanying infodemic using multiple data sources. We also review
datasets, tools, and resources needed to facilitate Artificial Intelligence
research, and discuss strategic considerations related to the operational
implementation of multidisciplinary partnerships and open science. We highlight
the need for international cooperation to maximize the potential of AI in this
and future pandemics.",2020-03-25,2020,2020-03,medical
"Neural translation and automated recognition of ICD10 medical entities
  from natural language","The recognition of medical entities from natural language is an ubiquitous
problem in the medical field, with applications ranging from medical act coding
to the analysis of electronic health data for public health. It is however a
complex task usually requiring human expert intervention, thus making it
expansive and time consuming. The recent advances in artificial intelligence,
specifically the raise of deep learning methods, has enabled computers to make
efficient decisions on a number of complex problems, with the notable example
of neural sequence models and their powerful applications in natural language
processing. They however require a considerable amount of data to learn from,
which is typically their main limiting factor. However, the C\'epiDc stores an
exhaustive database of death certificates at the French national scale,
amounting to several millions of natural language examples provided with their
associated human coded medical entities available to the machine learning
practitioner. This article investigates the applications of deep neural
sequence models to the medical entity recognition from natural language
problem.",2020-03-27,2020,2020-03,medical
"Modeling Rare Interactions in Time Series Data Through Qualitative
  Change: Application to Outcome Prediction in Intensive Care Units","Many areas of research are characterised by the deluge of large-scale
highly-dimensional time-series data. However, using the data available for
prediction and decision making is hampered by the current lag in our ability to
uncover and quantify true interactions that explain the outcomes.We are
interested in areas such as intensive care medicine, which are characterised by
i) continuous monitoring of multivariate variables and non-uniform sampling of
data streams, ii) the outcomes are generally governed by interactions between a
small set of rare events, iii) these interactions are not necessarily definable
by specific values (or value ranges) of a given group of variables, but rather,
by the deviations of these values from the normal state recorded over time, iv)
the need to explain the predictions made by the model. Here, while numerous
data mining models have been formulated for outcome prediction, they are unable
to explain their predictions.
  We present a model for uncovering interactions with the highest likelihood of
generating the outcomes seen from highly-dimensional time series data.
Interactions among variables are represented by a relational graph structure,
which relies on qualitative abstractions to overcome non-uniform sampling and
to capture the semantics of the interactions corresponding to the changes and
deviations from normality of variables of interest over time. Using the
assumption that similar templates of small interactions are responsible for the
outcomes (as prevalent in the medical domains), we reformulate the discovery
task to retrieve the most-likely templates from the data.",2020-04-03,2020,2020-04,medical
"Review of Artificial Intelligence Techniques in Imaging Data
  Acquisition, Segmentation and Diagnosis for COVID-19","(This paper was submitted as an invited paper to IEEE Reviews in Biomedical
Engineering on April 6, 2020.) The pandemic of coronavirus disease 2019
(COVID-19) is spreading all over the world. Medical imaging such as X-ray and
computed tomography (CT) plays an essential role in the global fight against
COVID-19, whereas the recently emerging artificial intelligence (AI)
technologies further strengthen the power of the imaging tools and help medical
specialists. We hereby review the rapid responses in the community of medical
imaging (empowered by AI) toward COVID-19. For example, AI-empowered image
acquisition can significantly help automate the scanning procedure and also
reshape the workflow with minimal contact to patients, providing the best
protection to the imaging technicians. Also, AI can improve work efficiency by
accurate delination of infections in X-ray and CT images, facilitating
subsequent quantification. Moreover, the computer-aided platforms help
radiologists make clinical decisions, i.e., for disease diagnosis, tracking,
and prognosis. In this review paper, we thus cover the entire pipeline of
medical imaging and analysis techniques involved with COVID-19, including image
acquisition, segmentation, diagnosis, and follow-up. We particularly focus on
the integration of AI with X-ray and CT, both of which are widely used in the
frontline hospitals, in order to depict the latest progress of medical imaging
and radiology fighting against COVID-19.",2020-04-06,2020,2020-04,medical
MedDialog: Two Large-scale Medical Dialogue Datasets,"Medical dialogue systems are promising in assisting in telemedicine to
increase access to healthcare services, improve the quality of patient care,
and reduce medical costs. To facilitate the research and development of medical
dialogue systems, we build two large-scale medical dialogue datasets:
MedDialog-EN and MedDialog-CN. MedDialog-EN is an English dataset containing
0.3 million conversations between patients and doctors and 0.5 million
utterances. MedDialog-CN is an Chinese dataset containing 1.1 million
conversations and 4 million utterances. To our best knowledge,
MedDialog-(EN,CN) are the largest medical dialogue datasets to date. The
dataset is available at https://github.com/UCSD-AI4H/Medical-Dialogue-System",2020-04-07,2020,2020-04,medical
"Detecting fake news for the new coronavirus by reasoning on the Covid-19
  ontology","In the context of the Covid-19 pandemic, many were quick to spread deceptive
information. I investigate here how reasoning in Description Logics (DLs) can
detect inconsistencies between trusted medical sources and not trusted ones.
The not-trusted information comes in natural language (e.g. ""Covid-19 affects
only the elderly""). To automatically convert into DLs, I used the FRED
converter. Reasoning in Description Logics is then performed with the Racer
tool.",2020-04-26,2020,2020-04,medical
"Unifying Neural Learning and Symbolic Reasoning for Spinal Medical
  Report Generation","Automated medical report generation in spine radiology, i.e., given spinal
medical images and directly create radiologist-level diagnosis reports to
support clinical decision making, is a novel yet fundamental study in the
domain of artificial intelligence in healthcare. However, it is incredibly
challenging because it is an extremely complicated task that involves visual
perception and high-level reasoning processes. In this paper, we propose the
neural-symbolic learning (NSL) framework that performs human-like learning by
unifying deep neural learning and symbolic logical reasoning for the spinal
medical report generation. Generally speaking, the NSL framework firstly
employs deep neural learning to imitate human visual perception for detecting
abnormalities of target spinal structures. Concretely, we design an adversarial
graph network that interpolates a symbolic graph reasoning module into a
generative adversarial network through embedding prior domain knowledge,
achieving semantic segmentation of spinal structures with high complexity and
variability. NSL secondly conducts human-like symbolic logical reasoning that
realizes unsupervised causal effect analysis of detected entities of
abnormalities through meta-interpretive learning. NSL finally fills these
discoveries of target diseases into a unified template, successfully achieving
a comprehensive medical report generation. When it employed in a real-world
clinical dataset, a series of empirical studies demonstrate its capacity on
spinal medical report generation as well as show that our algorithm remarkably
exceeds existing methods in the detection of spinal structures. These indicate
its potential as a clinical tool that contributes to computer-aided diagnosis.",2020-04-28,2020,2020-04,medical
"Automated Question Answer medical model based on Deep Learning
  Technology","Artificial intelligence can now provide more solutions for different
problems, especially in the medical field. One of those problems the lack of
answers to any given medical/health-related question. The Internet is full of
forums that allow people to ask some specific questions and get great answers
for them. Nevertheless, browsing these questions in order to locate one similar
to your own, also finding a satisfactory answer is a difficult and
time-consuming task. This research will introduce a solution to this problem by
automating the process of generating qualified answers to these questions and
creating a kind of digital doctor. Furthermore, this research will train an
end-to-end model using the framework of RNN and the encoder-decoder to generate
sensible and useful answers to a small set of medical/health issues. The
proposed model was trained and evaluated using data from various online
services, such as WebMD, HealthTap, eHealthForums, and iCliniq.",2020-05-21,2020,2020-05,medical
"Scoring and Assessment in Medical VR Training Simulators with Dynamic
  Time Series Classification","This research proposes and evaluates scoring and assessment methods for
Virtual Reality (VR) training simulators. VR simulators capture detailed
n-dimensional human motion data which is useful for performance analysis.
Custom made medical haptic VR training simulators were developed and used to
record data from 271 trainees of multiple clinical experience levels. DTW
Multivariate Prototyping (DTW-MP) is proposed. VR data was classified as
Novice, Intermediate or Expert. Accuracy of algorithms applied for time-series
classification were: dynamic time warping 1-nearest neighbor (DTW-1NN) 60%,
nearest centroid SoftDTW classification 77.5%, Deep Learning: ResNet 85%, FCN
75%, CNN 72.5% and MCDCNN 28.5%. Expert VR data recordings can be used for
guidance of novices. Assessment feedback can help trainees to improve skills
and consistency. Motion analysis can identify different techniques used by
individuals. Mistakes can be detected dynamically in real-time, raising alarms
to prevent injuries.",2020-06-11,2020,2020-06,medical
"HMIC: Hierarchical Medical Image Classification, A Deep Learning
  Approach","Image classification is central to the big data revolution in medicine.
Improved information processing methods for diagnosis and classification of
digital medical images have shown to be successful via deep learning
approaches. As this field is explored, there are limitations to the performance
of traditional supervised classifiers. This paper outlines an approach that is
different from the current medical image classification tasks that view the
issue as multi-class classification. We performed a hierarchical classification
using our Hierarchical Medical Image classification (HMIC) approach. HMIC uses
stacks of deep learning models to give particular comprehension at each level
of the clinical picture hierarchy. For testing our performance, we use biopsy
of the small bowel images that contain three categories in the parent level
(Celiac Disease, Environmental Enteropathy, and histologically normal
controls). For the child level, Celiac Disease Severity is classified into 4
classes (I, IIIa, IIIb, and IIIC).",2020-06-12,2020,2020-06,medical
"The Threats of Artificial Intelligence Scale (TAI). Development,
  Measurement and Test Over Three Application Domains","In recent years Artificial Intelligence (AI) has gained much popularity, with
the scientific community as well as with the public. AI is often ascribed many
positive impacts for different social domains such as medicine and the economy.
On the other side, there is also growing concern about its precarious impact on
society and individuals. Several opinion polls frequently query the public fear
of autonomous robots and artificial intelligence (FARAI), a phenomenon coming
also into scholarly focus. As potential threat perceptions arguably vary with
regard to the reach and consequences of AI functionalities and the domain of
application, research still lacks necessary precision of a respective
measurement that allows for wide-spread research applicability. We propose a
fine-grained scale to measure threat perceptions of AI that accounts for four
functional classes of AI systems and is applicable to various domains of AI
applications. Using a standardized questionnaire in a survey study (N=891), we
evaluate the scale over three distinct AI domains (loan origination, job
recruitment and medical treatment). The data support the dimensional structure
of the proposed Threats of AI (TAI) scale as well as the internal consistency
and factoral validity of the indicators. Implications of the results and the
empirical application of the scale are discussed in detail. Recommendations for
further empirical use of the TAI scale are provided.",2020-06-12,2020,2020-06,medical
Medical idioms for clinical Bayesian network development,"Bayesian Networks (BNs) are graphical probabilistic models that have proven
popular in medical applications. While numerous medical BNs have been
published, most are presented fait accompli without explanation of how the
network structure was developed or justification of why it represents the
correct structure for the given medical application. This means that the
process of building medical BNs from experts is typically ad hoc and offers
little opportunity for methodological improvement. This paper proposes
generally applicable and reusable medical reasoning patterns to aid those
developing medical BNs. The proposed method complements and extends the
idiom-based approach introduced by Neil, Fenton, and Nielsen in 2000. We
propose instances of their generic idioms that are specific to medical BNs. We
refer to the proposed medical reasoning patterns as medical idioms. In
addition, we extend the use of idioms to represent interventional and
counterfactual reasoning. We believe that the proposed medical idioms are
logical reasoning patterns that can be combined, reused and applied generically
to help develop medical BNs. All proposed medical idioms have been illustrated
using medical examples on coronary artery disease. The method has also been
applied to other ongoing BNs being developed with medical experts. Finally, we
show that applying the proposed medical idioms to published BN models results
in models with a clearer structure.",2020-07-01,2020,2020-07,medical
"Automatic Detection and Classification of Waste Consumer Medications for
  Proper Management and Disposal","Every year, millions of pounds of medicines remain unused in the U.S. and are
subject to an in-home disposal, i.e., kept in medicine cabinets, flushed in
toilet or thrown in regular trash. In-home disposal, however, can negatively
impact the environment and public health. The drug take-back programs (drug
take-backs) sponsored by the Drug Enforcement Administration (DEA) and its
state and industry partners collect unused consumer medications and provide the
best alternative to in-home disposal of medicines. However, the drug take-backs
are expensive to operate and not widely available. In this paper, we show that
artificial intelligence (AI) can be applied to drug take-backs to render them
operationally more efficient. Since identification of any waste is crucial to a
proper disposal, we showed that it is possible to accurately identify loose
consumer medications solely based on the physical features and visual
appearance. We have developed an automatic technique that uses deep neural
networks and computer vision to identify and segregate solid medicines. We
applied the technique to images of about one thousand loose pills and succeeded
in correctly identifying the pills with an accuracy of 0.912 and top-5 accuracy
of 0.984. We also showed that hazardous pills could be distinguished from
non-hazardous pills within the dataset with an accuracy of 0.984. We believe
that the power of artificial intelligence could be harnessed in products that
would facilitate the operation of the drug take-backs more efficiently and help
them become widely available throughout the country.",2020-07-27,2020,2020-07,medical
Ethics of Artificial Intelligence in Surgery,"Here we discuss the four key principles of bio-medical ethics from surgical
context. We elaborate on the definition of 'fairness' and its implications in
AI system design, with taxonomy of algorithmic biases in AI. We discuss the
shifts in ethical paradigms as the degree of autonomy in AI systems continue to
evolve. We also emphasize the need for continuous revisions of ethics in AI due
to evolution and dynamic nature of AI systems and technologies.",2020-07-28,2020,2020-07,medical
"A review of deep learning in medical imaging: Imaging traits, technology
  trends, case studies with progress highlights, and future promises","Since its renaissance, deep learning has been widely used in various medical
imaging tasks and has achieved remarkable success in many medical imaging
applications, thereby propelling us into the so-called artificial intelligence
(AI) era. It is known that the success of AI is mostly attributed to the
availability of big data with annotations for a single task and the advances in
high performance computing. However, medical imaging presents unique challenges
that confront deep learning approaches. In this survey paper, we first present
traits of medical imaging, highlight both clinical needs and technical
challenges in medical imaging, and describe how emerging trends in deep
learning are addressing these issues. We cover the topics of network
architecture, sparse and noisy labels, federating learning, interpretability,
uncertainty quantification, etc. Then, we present several case studies that are
commonly found in clinical practice, including digital pathology and chest,
brain, cardiovascular, and abdominal imaging. Rather than presenting an
exhaustive literature survey, we instead describe some prominent research
highlights related to these case study applications. We conclude with a
discussion and presentation of promising future directions.",2020-08-02,2020,2020-08,medical
"High performance on-demand de-identification of a petabyte-scale medical
  imaging data lake","With the increase in Artificial Intelligence driven approaches, researchers
are requesting unprecedented volumes of medical imaging data which far exceed
the capacity of traditional on-premise client-server approaches for making the
data research analysis-ready. We are making available a flexible solution for
on-demand de-identification that combines the use of mature software
technologies with modern cloud-based distributed computing techniques to enable
faster turnaround in medical imaging research. The solution is part of a
broader platform that supports a secure high performance clinical data science
platform.",2020-08-04,2020,2020-08,medical
"ExplAIn: Explanatory Artificial Intelligence for Diabetic Retinopathy
  Diagnosis","In recent years, Artificial Intelligence (AI) has proven its relevance for
medical decision support. However, the ""black-box"" nature of successful AI
algorithms still holds back their wide-spread deployment. In this paper, we
describe an eXplanatory Artificial Intelligence (XAI) that reaches the same
level of performance as black-box AI, for the task of classifying Diabetic
Retinopathy (DR) severity using Color Fundus Photography (CFP). This algorithm,
called ExplAIn, learns to segment and categorize lesions in images; the final
image-level classification directly derives from these multivariate lesion
segmentations. The novelty of this explanatory framework is that it is trained
from end to end, with image supervision only, just like black-box AI
algorithms: the concepts of lesions and lesion categories emerge by themselves.
For improved lesion localization, foreground/background separation is trained
through self-supervision, in such a way that occluding foreground pixels
transforms the input image into a healthy-looking image. The advantage of such
an architecture is that automatic diagnoses can be explained simply by an image
and/or a few sentences. ExplAIn is evaluated at the image level and at the
pixel level on various CFP image datasets. We expect this new framework, which
jointly offers high classification performance and explainability, to
facilitate AI deployment.",2020-08-13,2020,2020-08,medical
Survey of XAI in digital pathology,"Artificial intelligence (AI) has shown great promise for diagnostic imaging
assessments. However, the application of AI to support medical diagnostics in
clinical routine comes with many challenges. The algorithms should have high
prediction accuracy but also be transparent, understandable and reliable. Thus,
explainable artificial intelligence (XAI) is highly relevant for this domain.
We present a survey on XAI within digital pathology, a medical imaging
sub-discipline with particular characteristics and needs. The review includes
several contributions. Firstly, we give a thorough overview of current XAI
techniques of potential relevance for deep learning methods in pathology
imaging, and categorise them from three different aspects. In doing so, we
incorporate uncertainty estimation methods as an integral part of the XAI
landscape. We also connect the technical methods to the specific prerequisites
in digital pathology and present findings to guide future research efforts. The
survey is intended for both technical researchers and medical professionals,
one of the objectives being to establish a common ground for cross-disciplinary
discussions.",2020-08-14,2020,2020-08,medical
"Trust and Medical AI: The challenges we face and the expertise needed to
  overcome them","Artificial intelligence (AI) is increasingly of tremendous interest in the
medical field. However, failures of medical AI could have serious consequences
for both clinical outcomes and the patient experience. These consequences could
erode public trust in AI, which could in turn undermine trust in our healthcare
institutions. This article makes two contributions. First, it describes the
major conceptual, technical, and humanistic challenges in medical AI. Second,
it proposes a solution that hinges on the education and accreditation of new
expert groups who specialize in the development, verification, and operation of
medical AI technologies. These groups will be required to maintain trust in our
healthcare institutions.",2020-08-18,2020,2020-08,medical
"Patient ADE Risk Prediction through Hierarchical Time-Aware Neural
  Network Using Claim Codes","Adverse drug events (ADEs) are a serious health problem that can be
life-threatening. While a lot of studies have been performed on detect
correlation between a drug and an AE, limited studies have been conducted on
personalized ADE risk prediction. Among treatment alternatives, avoiding the
drug that has high likelihood of causing severe AE can help physicians to
provide safer treatment to patients. Existing work on personalized ADE risk
prediction uses the information obtained in the current medical visit. However,
on the other hand, medical history reveals each patient's unique
characteristics and comprehensive medical information. The goal of this study
is to assess personalized ADE risks that a target drug may induce on a target
patient, based on patient medical history recorded in claims codes, which
provide information about diagnosis, drugs taken, related medical supplies
besides billing information. We developed a HTNNR model (Hierarchical
Time-aware Neural Network for ADE Risk) that capture characteristics of claim
codes and their relationship. The empirical evaluation show that the proposed
HTNNR model substantially outperforms the comparison methods, especially for
rare drugs.",2020-08-20,2020,2020-08,medical
"Knowledge-Empowered Representation Learning for Chinese Medical Reading
  Comprehension: Task, Model and Resources","Machine Reading Comprehension (MRC) aims to extract answers to questions
given a passage. It has been widely studied recently, especially in open
domains. However, few efforts have been made on closed-domain MRC, mainly due
to the lack of large-scale training data. In this paper, we introduce a
multi-target MRC task for the medical domain, whose goal is to predict answers
to medical questions and the corresponding support sentences from medical
information sources simultaneously, in order to ensure the high reliability of
medical knowledge serving. A high-quality dataset is manually constructed for
the purpose, named Multi-task Chinese Medical MRC dataset (CMedMRC), with
detailed analysis conducted. We further propose the Chinese medical BERT model
for the task (CMedBERT), which fuses medical knowledge into pre-trained
language models by the dynamic fusion mechanism of heterogeneous features and
the multi-task learning strategy. Experiments show that CMedBERT consistently
outperforms strong baselines by fusing context-aware and knowledge-aware token
representations.",2020-08-24,2020,2020-08,medical
"Receptivity of an AI Cognitive Assistant by the Radiology Community: A
  Report on Data Collected at RSNA","Due to advances in machine learning and artificial intelligence (AI), a new
role is emerging for machines as intelligent assistants to radiologists in
their clinical workflows. But what systematic clinical thought processes are
these machines using? Are they similar enough to those of radiologists to be
trusted as assistants? A live demonstration of such a technology was conducted
at the 2016 Scientific Assembly and Annual Meeting of the Radiological Society
of North America (RSNA). The demonstration was presented in the form of a
question-answering system that took a radiology multiple choice question and a
medical image as inputs. The AI system then demonstrated a cognitive workflow,
involving text analysis, image analysis, and reasoning, to process the question
and generate the most probable answer. A post demonstration survey was made
available to the participants who experienced the demo and tested the question
answering system. Of the reported 54,037 meeting registrants, 2,927 visited the
demonstration booth, 1,991 experienced the demo, and 1,025 completed a
post-demonstration survey. In this paper, the methodology of the survey is
shown and a summary of its results are presented. The results of the survey
show a very high level of receptiveness to cognitive computing technology and
artificial intelligence among radiologists.",2020-09-13,2020,2020-09,medical
"Focused Clinical Query Understanding and Retrieval of Medical Snippets
  powered through a Healthcare Knowledge Graph","Clinicians face several significant barriers to search and synthesize
accurate, succinct, updated, and trustworthy medical information from several
literature sources during the practice of medicine and patient care. In this
talk, we will be presenting our research behind the development of a Focused
Clinical Search Service, powered by a Healthcare Knowledge Graph, to interpret
the query intent behind clinical search queries and retrieve relevant medical
snippets from a diverse corpus of medical literature.",2020-09-17,2020,2020-09,medical
"Dr. Summarize: Global Summarization of Medical Dialogue by Exploiting
  Local Structures","Understanding a medical conversation between a patient and a physician poses
a unique natural language understanding challenge since it combines elements of
standard open ended conversation with very domain specific elements that
require expertise and medical knowledge. Summarization of medical conversations
is a particularly important aspect of medical conversation understanding since
it addresses a very real need in medical practice: capturing the most important
aspects of a medical encounter so that they can be used for medical decision
making and subsequent follow ups.
  In this paper we present a novel approach to medical conversation
summarization that leverages the unique and independent local structures
created when gathering a patient's medical history. Our approach is a variation
of the pointer generator network where we introduce a penalty on the generator
distribution, and we explicitly model negations. The model also captures
important properties of medical conversations such as medical knowledge coming
from standardized medical ontologies better than when those concepts are
introduced explicitly. Through evaluation by doctors, we show that our approach
is preferred on twice the number of summaries to the baseline pointer generator
model and captures most or all of the information in 80% of the conversations
making it a realistic alternative to costly manual summarization by medical
experts.",2020-09-18,2020,2020-09,medical
"Basic principles and concept design of a real-time clinical decision
  support system for managing medical emergencies on missions to Mars","Space agencies and private companies prepare the beginning of human space
exploration for the 2030s with missions to put the first human on the Mars
surface. The absence of gravity and radiation, along with distance, isolation
and hostile environments, are expected to increase medical events where
previously unseen manifestations may arise. The current healthcare strategy
based on telemedicine and the possibility to stabilize and transport the
injured crewmember to a terrestrial definitive medical facility is not
applicable in exploration class missions. Therefore, the need for deploying the
full autonomous capability to solve medical emergencies may guide the design of
future onboard healthcare systems. We present ten basic principles and concept
design of a software suite to bring onboard decision support to help the crew
dealing with medical emergencies taking into consideration physiological
disturbances in space and spaceflight restrictions. 1) give real-time support
for emergency medical decision making, 2) give patient-specific advice for
executive problem-solving, 3) take into account available information from life
support and monitoring of crewmembers, 4) be fully autonomous from remote
facilities, 5) continuously adapt predictions to physiological disturbance and
changing conditions, 6) optimize emergency medical decision making in terms of
mission fundamental priorities, 7) take into account medical supplies and
equipment on board, 8) apply health standards for the level of care V, 9)
implement ethics responsibilities for spaceflights, and 10) apply ethical
standards for artificial intelligence. Based on these principles, we propose an
autonomous clinical decision support system (CDSS) to provide real-time advice
for emergency medical interventions on board of space exploration missions.",2020-09-29,2020,2020-09,medical
CAD Applications and Emerging Research Potential in Medical Imaging,"Computer Aided Detection (CAD) is a valuable technique for precisely
interpreting medical images and it has a global business opportunity of about
USD 1.8 billion. The current aspects with reference to the four sub stages such
as image pre-processing, segmentation, feature extraction and classification
and the future scope of CAD in medical imaging has been discussed in this
paper. Many reviewers have emphasized the need for synergy between engineers
and medical professionals for successful development of CAD systems and the
current work is a move in that direction. The engineering aspects of the above
four stages in four imaging modalities viz. computed tomography, magnetic
resonance imaging, mammography and bone scintigraphy used in the diagnosis of
five critical diseases have been discussed with a clinical background.
Automatic classification of image can play an important role in preliminary
screening of very critical ailments bringing down the cost of health care.
Another recent advancement is using artificial intelligence and machine
learning techniques. This paper reviews these engineering aspects with a view
to explore the opportunities to researchers as well as the medical industry to
offer affordable medical services with accessibility in even remote locations.",2020-09-30,2020,2020-09,medical
"Artificial intelligence supported anemia control system (AISACS) to
  prevent anemia in maintenance hemodialysis patients","Anemia, for which erythropoiesis-stimulating agents (ESAs) and iron
supplements (ISs) are used as preventive measures, presents important
difficulties for hemodialysis patients. Nevertheless, the number of physicians
able to manage such medications appropriately is not keeping pace with the
rapid increase of hemodialysis patients. Moreover, the high cost of ESAs
imposes heavy burdens on medical insurance systems. An
artificial-intelligence-supported anemia control system (AISACS) trained using
administration direction data from experienced physicians has been developed by
the authors. For the system, appropriate data selection and rectification
techniques play important roles. Decision making related to ESAs poses a
multi-class classification problem for which a two-step classification
technique is introduced. Several validations have demonstrated that AISACS
exhibits high performance with correct classification rates of 72-87% and
clinically appropriate classification rates of 92-98%.",2020-10-06,2020,2020-10,medical
Characterizing the Value of Information in Medical Notes,"Machine learning models depend on the quality of input data. As electronic
health records are widely adopted, the amount of data in health care is
growing, along with complaints about the quality of medical notes. We use two
prediction tasks, readmission prediction and in-hospital mortality prediction,
to characterize the value of information in medical notes. We show that as a
whole, medical notes only provide additional predictive power over structured
information in readmission prediction. We further propose a probing framework
to select parts of notes that enable more accurate predictions than using all
notes, despite that the selected information leads to a distribution shift from
the training data (""all notes""). Finally, we demonstrate that models trained on
the selected valuable information achieve even better predictive performance,
with only 6.8% of all the tokens for readmission prediction.",2020-10-07,2020,2020-10,medical
OnRAMP for Regulating AI in Medical Products,"Medical Artificial Intelligence (AI) involves the application of machine
learning algorithms to biomedical datasets in order to improve medical
practices. Products incorporating medical AI require certification before
deployment in most jurisdictions. To date, clear pathways for regulating
medical AI are still under development. Below the level of formal pathways lies
the actual practice of developing a medical AI solution. This Perspective
proposes best practice guidelines for development compatible with the
production of a regulatory package which, regardless of the formal regulatory
path, will form a core component of a certification process. The approach is
predicated on a statistical risk perspective, typical of medical device
regulators, and a deep understanding of machine learning methodologies. These
guidelines will allow all parties to communicate more clearly in the
development of a common Good Machine Learning Practice (GMLP), and thus lead to
the enhanced development of both medical AI products and regulations.",2020-10-09,2020,2020-10,medical
"MedDG: An Entity-Centric Medical Consultation Dataset for Entity-Aware
  Medical Dialogue Generation","Developing conversational agents to interact with patients and provide
primary clinical advice has attracted increasing attention due to its huge
application potential, especially in the time of COVID-19 Pandemic. However,
the training of end-to-end neural-based medical dialogue system is restricted
by an insufficient quantity of medical dialogue corpus. In this work, we make
the first attempt to build and release a large-scale high-quality Medical
Dialogue dataset related to 12 types of common Gastrointestinal diseases named
MedDG, with more than 17K conversations collected from the online health
consultation community. Five different categories of entities, including
diseases, symptoms, attributes, tests, and medicines, are annotated in each
conversation of MedDG as additional labels. To push forward the future research
on building expert-sensitive medical dialogue system, we proposes two kinds of
medical dialogue tasks based on MedDG dataset. One is the next entity
prediction and the other is the doctor response generation. To acquire a clear
comprehension on these two medical dialogue tasks, we implement several
state-of-the-art benchmarks, as well as design two dialogue models with a
further consideration on the predicted entities. Experimental results show that
the pre-train language models and other baselines struggle on both tasks with
poor performance in our dataset, and the response quality can be enhanced with
the help of auxiliary entity information. From human evaluation, the simple
retrieval model outperforms several state-of-the-art generative models,
indicating that there still remains a large room for improvement on generating
medically meaningful responses.",2020-10-15,2020,2020-10,medical
"Interpretable Disease Prediction based on Reinforcement Path Reasoning
  over Knowledge Graphs","Objective: To combine medical knowledge and medical data to interpretably
predict the risk of disease. Methods: We formulated the disease prediction task
as a random walk along a knowledge graph (KG). Specifically, we build a KG to
record relationships between diseases and risk factors according to validated
medical knowledge. Then, a mathematical object walks along the KG. It starts
walking at a patient entity, which connects the KG based on the patient current
diseases or risk factors and stops at a disease entity, which represents the
predicted disease. The trajectory generated by the object represents an
interpretable disease progression path of the given patient. The dynamics of
the object are controlled by a policy-based reinforcement learning (RL) module,
which is trained by electronic health records (EHRs). Experiments: We utilized
two real-world EHR datasets to evaluate the performance of our model. In the
disease prediction task, our model achieves 0.743 and 0.639 in terms of macro
area under the curve (AUC) in predicting 53 circulation system diseases in the
two datasets, respectively. This performance is comparable to the commonly used
machine learning (ML) models in medical research. In qualitative analysis, our
clinical collaborator reviewed the disease progression paths generated by our
model and advocated their interpretability and reliability. Conclusion:
Experimental results validate the proposed model in interpretably evaluating
and optimizing disease prediction. Significance: Our work contributes to
leveraging the potential of medical knowledge and medical data jointly for
interpretable prediction tasks.",2020-10-16,2020,2020-10,medical
"A Survey on Deep Learning and Explainability for Automatic Report
  Generation from Medical Images","Every year physicians face an increasing demand of image-based diagnosis from
patients, a problem that can be addressed with recent artificial intelligence
methods. In this context, we survey works in the area of automatic report
generation from medical images, with emphasis on methods using deep neural
networks, with respect to: (1) Datasets, (2) Architecture Design, (3)
Explainability and (4) Evaluation Metrics. Our survey identifies interesting
developments, but also remaining challenges. Among them, the current evaluation
of generated reports is especially weak, since it mostly relies on traditional
Natural Language Processing (NLP) metrics, which do not accurately capture
medical correctness.",2020-10-20,2020,2020-10,medical
"Explaining black-box text classifiers for disease-treatment information
  extraction","Deep neural networks and other intricate Artificial Intelligence (AI) models
have reached high levels of accuracy on many biomedical natural language
processing tasks. However, their applicability in real-world use cases may be
limited due to their vague inner working and decision logic. A post-hoc
explanation method can approximate the behavior of a black-box AI model by
extracting relationships between feature values and outcomes. In this paper, we
introduce a post-hoc explanation method that utilizes confident itemsets to
approximate the behavior of black-box classifiers for medical information
extraction. Incorporating medical concepts and semantics into the explanation
process, our explanator finds semantic relations between inputs and outputs in
different parts of the decision space of a black-box classifier. The
experimental results show that our explanation method can outperform
perturbation and decision set based explanators in terms of fidelity and
interpretability of explanations produced for predictions on a
disease-treatment information extraction task.",2020-10-21,2020,2020-10,medical
"MedMNIST Classification Decathlon: A Lightweight AutoML Benchmark for
  Medical Image Analysis","We present MedMNIST, a collection of 10 pre-processed medical open datasets.
MedMNIST is standardized to perform classification tasks on lightweight 28x28
images, which requires no background knowledge. Covering the primary data
modalities in medical image analysis, it is diverse on data scale (from 100 to
100,000) and tasks (binary/multi-class, ordinal regression and multi-label).
MedMNIST could be used for educational purpose, rapid prototyping, multi-modal
machine learning or AutoML in medical image analysis. Moreover, MedMNIST
Classification Decathlon is designed to benchmark AutoML algorithms on all 10
datasets; We have compared several baseline methods, including open-source or
commercial AutoML tools. The datasets, evaluation code and baseline methods for
MedMNIST are publicly available at https://medmnist.github.io/.",2020-10-28,2020,2020-10,medical
Photonics for artificial intelligence and neuromorphic computing,"Research in photonic computing has flourished due to the proliferation of
optoelectronic components on photonic integration platforms. Photonic
integrated circuits have enabled ultrafast artificial neural networks,
providing a framework for a new class of information processing machines.
Algorithms running on such hardware have the potential to address the growing
demand for machine learning and artificial intelligence, in areas such as
medical diagnosis, telecommunications, and high-performance and scientific
computing. In parallel, the development of neuromorphic electronics has
highlighted challenges in that domain, in particular, related to processor
latency. Neuromorphic photonics offers sub-nanosecond latencies, providing a
complementary opportunity to extend the domain of artificial intelligence.
Here, we review recent advances in integrated photonic neuromorphic systems,
discuss current and future challenges, and outline the advances in science and
technology needed to meet those challenges.",2020-10-30,2020,2020-10,medical
Explainable AI meets Healthcare: A Study on Heart Disease Dataset,"With the increasing availability of structured and unstructured data and the
swift progress of analytical techniques, Artificial Intelligence (AI) is
bringing a revolution to the healthcare industry. With the increasingly
indispensable role of AI in healthcare, there are growing concerns over the
lack of transparency and explainability in addition to potential bias
encountered by predictions of the model. This is where Explainable Artificial
Intelligence (XAI) comes into the picture. XAI increases the trust placed in an
AI system by medical practitioners as well as AI researchers, and thus,
eventually, leads to an increasingly widespread deployment of AI in healthcare.
  In this paper, we present different interpretability techniques. The aim is
to enlighten practitioners on the understandability and interpretability of
explainable AI systems using a variety of techniques available which can be
very advantageous in the health-care domain. Medical diagnosis model is
responsible for human life and we need to be confident enough to treat a
patient as instructed by a black-box model. Our paper contains examples based
on the heart disease dataset and elucidates on how the explainability
techniques should be preferred to create trustworthiness while using AI systems
in healthcare.",2020-11-06,2020,2020-11,medical
"Improving Clinical Outcome Predictions Using Convolution over Medical
  Entities with Multimodal Learning","Early prediction of mortality and length of stay(LOS) of a patient is vital
for saving a patient's life and management of hospital resources. Availability
of electronic health records(EHR) makes a huge impact on the healthcare domain
and there has seen several works on predicting clinical problems. However, many
studies did not benefit from the clinical notes because of the sparse, and high
dimensional nature. In this work, we extract medical entities from clinical
notes and use them as additional features besides time-series features to
improve our predictions. We propose a convolution based multimodal
architecture, which not only learns effectively combining medical entities and
time-series ICU signals of patients, but also allows us to compare the effect
of different embedding techniques such as Word2vec, FastText on medical
entities. In the experiments, our proposed method robustly outperforms all
other baseline models including different multimodal architectures for all
clinical tasks. The code for the proposed method is available at
https://github.com/tanlab/ConvolutionMedicalNer.",2020-11-24,2020,2020-11,medical
"Artificial Intelligence for COVID-19 Detection -- A state-of-the-art
  review","The emergence of COVID-19 has necessitated many efforts by the scientific
community for its proper management. An urgent clinical reaction is required in
the face of the unending devastation being caused by the pandemic. These
efforts include technological innovations for improvement in screening,
treatment, vaccine development, contact tracing and, survival prediction. The
use of Deep Learning (DL) and Artificial Intelligence (AI) can be sought in all
of the above-mentioned spheres. This paper aims to review the role of Deep
Learning and Artificial intelligence in various aspects of the overall COVID-19
management and particularly for COVID-19 detection and classification. The DL
models are developed to analyze clinical modalities like CT scans and X-Ray
images of patients and predict their pathological condition. A DL model aims to
detect the COVID-19 pneumonia, classify and distinguish between COVID-19,
Community-Acquired Pneumonia (CAP), Viral and Bacterial pneumonia, and normal
conditions. Furthermore, sophisticated models can be built to segment the
affected area in the lungs and quantify the infection volume for a better
understanding of the extent of damage. Many models have been developed either
independently or with the help of pre-trained models like VGG19, ResNet50, and
AlexNet leveraging the concept of transfer learning. Apart from model
development, data preprocessing and augmentation are also performed to cope
with the challenge of insufficient data samples often encountered in medical
applications. It can be evaluated that DL and AI can be effectively implemented
to withstand the challenges posed by the global emergency",2020-11-25,2020,2020-11,medical
"Transfer learning to enhance amenorrhea status prediction in cancer and
  fertility data with missing values","Collecting sufficient labelled training data for health and medical problems
is difficult (Antropova, et al., 2018). Also, missing values are unavoidable in
health and medical datasets and tackling the problem arising from the
inadequate instances and missingness is not straightforward (Snell, et al.
2017, Sterne, et al. 2009). However, machine learning algorithms have achieved
significant success in many real-world healthcare problems, such as regression
and classification and these techniques could possibly be a way to resolve the
issues.",2020-12-01,2020,2020-12,medical
Privacy-preserving medical image analysis,"The utilisation of artificial intelligence in medicine and healthcare has led
to successful clinical applications in several domains. The conflict between
data usage and privacy protection requirements in such systems must be resolved
for optimal results as well as ethical and legal compliance. This calls for
innovative solutions such as privacy-preserving machine learning (PPML). We
present PriMIA (Privacy-preserving Medical Image Analysis), a software
framework designed for PPML in medical imaging. In a real-life case study we
demonstrate significantly better classification performance of a securely
aggregated federated learning model compared to human experts on unseen
datasets. Furthermore, we show an inference-as-a-service scenario for
end-to-end encrypted diagnosis, where neither the data nor the model are
revealed. Lastly, we empirically evaluate the framework's security against a
gradient-based model inversion attack and demonstrate that no usable
information can be recovered from the model.",2020-12-10,2020,2020-12,medical
"Hospital Capacity Planning Using Discrete Event Simulation Under Special
  Consideration of the COVID-19 Pandemic","We present a resource-planning tool for hospitals under special consideration
of the COVID-19 pandemic, called babsim.hospital. It provides many advantages
for crisis teams, e.g., comparison with their own local planning, simulation of
local events, simulation of several scenarios (worst / best case). There are
benefits for medical professionals, e.g, analysis of the pandemic at local,
regional, state and federal level, the consideration of special risk groups,
tools for validating the length of stays and transition probabilities. Finally,
there are potential advantages for administration, management, e.g., assessment
of the situation of individual hospitals taking local events into account,
consideration of relevant resources such as beds, ventilators, rooms,
protective clothing, and personnel planning, e.g., medical and nursing staff.
babsim.hospital combines simulation, optimization, statistics, and artificial
intelligence processes in a very efficient way. The core is a discrete,
event-based simulation model.",2020-12-14,2020,2020-12,medical
"DeepKeyGen: A Deep Learning-based Stream Cipher Generator for Medical
  Image Encryption and Decryption","The need for medical image encryption is increasingly pronounced, for example
to safeguard the privacy of the patients' medical imaging data. In this paper,
a novel deep learning-based key generation network (DeepKeyGen) is proposed as
a stream cipher generator to generate the private key, which can then be used
for encrypting and decrypting of medical images. In DeepKeyGen, the generative
adversarial network (GAN) is adopted as the learning network to generate the
private key. Furthermore, the transformation domain (that represents the
""style"" of the private key to be generated) is designed to guide the learning
network to realize the private key generation process. The goal of DeepKeyGen
is to learn the mapping relationship of how to transfer the initial image to
the private key. We evaluate DeepKeyGen using three datasets, namely: the
Montgomery County chest X-ray dataset, the Ultrasonic Brachial Plexus dataset,
and the BraTS18 dataset. The evaluation findings and security analysis show
that the proposed key generation network can achieve a high-level security in
generating the private key.",2020-12-21,2020,2020-12,medical
Medical Entity Linking using Triplet Network,"Entity linking (or Normalization) is an essential task in text mining that
maps the entity mentions in the medical text to standard entities in a given
Knowledge Base (KB). This task is of great importance in the medical domain. It
can also be used for merging different medical and clinical ontologies. In this
paper, we center around the problem of disease linking or normalization. This
task is executed in two phases: candidate generation and candidate scoring. In
this paper, we present an approach to rank the candidate Knowledge Base entries
based on their similarity with disease mention. We make use of the Triplet
Network for candidate ranking. While the existing methods have used carefully
generated sieves and external resources for candidate generation, we introduce
a robust and portable candidate generation scheme that does not make use of the
hand-crafted rules. Experimental results on the standard benchmark NCBI disease
dataset demonstrate that our system outperforms the prior methods by a
significant margin.",2020-12-21,2020,2020-12,medical
"A Review of Artificial Intelligence Technologies for Early Prediction of
  Alzheimer's Disease","Alzheimer's Disease (AD) is a severe brain disorder, destroying memories and
brain functions. AD causes chronically, progressively, and irreversibly
cognitive declination and brain damages. The reliable and effective evaluation
of early dementia has become essential research with medical imaging
technologies and computer-aided algorithms. This trend has moved to modern
Artificial Intelligence (AI) technologies motivated by deeplearning success in
image classification and natural language processing. The purpose of this
review is to provide an overview of the latest research involving deep-learning
algorithms in evaluating the process of dementia, diagnosing the early stage of
AD, and discussing an outlook for this research. This review introduces various
applications of modern AI algorithms in AD diagnosis, including Convolutional
Neural Network (CNN), Recurrent Neural Network (RNN), Automatic Image
Segmentation, Autoencoder, Graph CNN (GCN), Ensemble Learning, and Transfer
Learning. The advantages and disadvantages of the proposed methods and their
performance are discussed. The conclusion section summarizes the primary
contributions and medical imaging preprocessing techniques applied in the
reviewed research. Finally, we discuss the limitations and future outlooks.",2020-12-22,2020,2020-12,medical
"GANterfactual - Counterfactual Explanations for Medical Non-Experts
  using Generative Adversarial Learning","With the ongoing rise of machine learning, the need for methods for
explaining decisions made by artificial intelligence systems is becoming a more
and more important topic. Especially for image classification tasks, many
state-of-the-art tools to explain such classifiers rely on visual highlighting
of important areas of the input data. Contrary, counterfactual explanation
systems try to enable a counterfactual reasoning by modifying the input image
in a way such that the classifier would have made a different prediction. By
doing so, the users of counterfactual explanation systems are equipped with a
completely different kind of explanatory information. However, methods for
generating realistic counterfactual explanations for image classifiers are
still rare. Especially in medical contexts, where relevant information often
consists of textural and structural information, high-quality counterfactual
images have the potential to give meaningful insights into decision processes.
In this work, we present GANterfactual, an approach to generate such
counterfactual image explanations based on adversarial image-to-image
translation techniques. Additionally, we conduct a user study to evaluate our
approach in an exemplary medical use case. Our results show that, in the chosen
medical use-case, counterfactual explanations lead to significantly better
results regarding mental models, explanation satisfaction, trust, emotions, and
self-efficacy than two state-of-the-art systems that work with saliency maps,
namely LIME and LRP.",2020-12-22,2020,2020-12,medical
"MeDAL: Medical Abbreviation Disambiguation Dataset for Natural Language
  Understanding Pretraining","One of the biggest challenges that prohibit the use of many current NLP
methods in clinical settings is the availability of public datasets. In this
work, we present MeDAL, a large medical text dataset curated for abbreviation
disambiguation, designed for natural language understanding pre-training in the
medical domain. We pre-trained several models of common architectures on this
dataset and empirically showed that such pre-training leads to improved
performance and convergence speed when fine-tuning on downstream medical tasks.",2020-12-27,2020,2020-12,medical
Order Embeddings from Merged Ontologies using Sketching,"We give a simple, low resource method to produce order embeddings from
ontologies. Such embeddings map words to vectors so that order relations on the
words, such as hypernymy/hyponymy, are represented in a direct way. Our method
uses sketching techniques, in particular countsketch, for dimensionality
reduction. We also study methods to merge ontologies, in particular those in
medical domains, so that order relations are preserved. We give computational
results for medical ontologies and for wordnet, showing that our merging
techniques are effective and our embedding yields an accurate representation in
both generic and specialised domains.",2021-01-06,2021,2021-01,medical
"The Medical Authority of AI: A Study of AI-enabled Consumer-facing
  Health Technology","Recently, consumer-facing health technologies such as Artificial Intelligence
(AI)-based symptom checkers (AISCs) have sprung up in everyday healthcare
practice. AISCs solicit symptom information from users and provide medical
suggestions and possible diagnoses, a responsibility that people usually
entrust with real-person authorities such as physicians and expert patients.
Thus, the advent of AISCs begs a question of whether and how they transform the
notion of medical authority in everyday healthcare practice. To answer this
question, we conducted an interview study with thirty AISC users. We found that
users assess the medical authority of AISCs using various factors including
automated decisions and interaction design patterns of AISC apps, associations
with established medical authorities like hospitals, and comparisons with other
health technologies. We reveal how AISCs are used in healthcare delivery,
discuss how AI transforms conventional understandings of medical authority, and
derive implications for designing AI-enabled health technology.",2021-01-12,2021,2021-01,medical
"Artificial Intelligence for Emotion-Semantic Trending and People Emotion
  Detection During COVID-19 Social Isolation","Taking advantage of social media platforms, such as Twitter, this paper
provides an effective framework for emotion detection among those who are
quarantined. Early detection of emotional feelings and their trends help
implement timely intervention strategies. Given the limitations of medical
diagnosis of early emotional change signs during the quarantine period,
artificial intelligence models provide effective mechanisms in uncovering early
signs, symptoms and escalating trends. Novelty of the approach presented herein
is a multitask methodological framework of text data processing, implemented as
a pipeline for meaningful emotion detection and analysis, based on the
Plutchik/Ekman approach to emotion detection and trend detection. We present an
evaluation of the framework and a pilot system. Results of confirm the
effectiveness of the proposed framework for topic trends and emotion detection
of COVID-19 tweets. Our findings revealed Stay-At-Home restrictions result in
people expressing on twitter both negative and positive emotional semantics.
Semantic trends of safety issues related to staying at home rapidly decreased
within the 28 days and also negative feelings related to friends dying and
quarantined life increased in some days. These findings have potential to
impact public health policy decisions through monitoring trends of emotional
feelings of those who are quarantined. The framework presented here has
potential to assist in such monitoring by using as an online emotion detection
tool kit.",2021-01-16,2021,2021-01,medical
"Medical Information Retrieval and Interpretation: A Question-Answer
  based Interaction Model","The Internet has become a very powerful platform where diverse medical
information are expressed daily. Recently, a huge growth is seen in searches
like symptoms, diseases, medicines, and many other health related queries
around the globe. The search engines typically populate the result by using the
single query provided by the user and hence reaching to the final result may
require a lot of manual filtering from the user's end. Current search engines
and recommendation systems still lack real time interactions that may provide
more precise result generation. This paper proposes an intelligent and
interactive system tied up with the vast medical big data repository on the web
and illustrates its potential in finding medical information.",2021-01-24,2021,2021-01,medical
A Taxonomy of Explainable Bayesian Networks,"Artificial Intelligence (AI), and in particular, the explainability thereof,
has gained phenomenal attention over the last few years. Whilst we usually do
not question the decision-making process of these systems in situations where
only the outcome is of interest, we do however pay close attention when these
systems are applied in areas where the decisions directly influence the lives
of humans. It is especially noisy and uncertain observations close to the
decision boundary which results in predictions which cannot necessarily be
explained that may foster mistrust among end-users. This drew attention to AI
methods for which the outcomes can be explained. Bayesian networks are
probabilistic graphical models that can be used as a tool to manage
uncertainty. The probabilistic framework of a Bayesian network allows for
explainability in the model, reasoning and evidence. The use of these methods
is mostly ad hoc and not as well organised as explainability methods in the
wider AI research field. As such, we introduce a taxonomy of explainability in
Bayesian networks. We extend the existing categorisation of explainability in
the model, reasoning or evidence to include explanation of decisions. The
explanations obtained from the explainability methods are illustrated by means
of a simple medical diagnostic scenario. The taxonomy introduced in this paper
has the potential not only to encourage end-users to efficiently communicate
outcomes obtained, but also support their understanding of how and, more
importantly, why certain predictions were made.",2021-01-28,2021,2021-01,medical
Diagnosis of Acute Poisoning Using Explainable Artificial Intelligence,"Medical toxicology is the clinical specialty that treats the toxic effects of
substances, be it an overdose, a medication error, or a scorpion sting. The
volume of toxicological knowledge and research has, as with other medical
specialties, outstripped the ability of the individual clinician to entirely
master and stay current with it. The application of machine learning techniques
to medical toxicology is challenging because initial treatment decisions are
often based on a few pieces of textual data and rely heavily on prior
knowledge. ML techniques often do not represent knowledge in a way that is
transparent for the physician, raising barriers to usability. Rule-based
systems and decision tree learning are more transparent approaches, but often
generalize poorly and require expert curation to implement and maintain. Here,
we construct a probabilistic logic network to represent a portion of the
knowledge base of a medical toxicologist. Our approach transparently mimics the
knowledge representation and clinical decision-making of practicing clinicians.
The software, dubbed Tak, performs comparably to humans on straightforward
cases and intermediate difficulty cases, but is outperformed by humans on
challenging clinical cases. Tak outperforms a decision tree classifier at all
levels of difficulty. Probabilistic logic provides one form of explainable
artificial intelligence that may be more acceptable for use in healthcare, if
it can achieve acceptable levels of performance.",2021-02-01,2021,2021-02,medical
"Medical Datasets Collections for Artificial Intelligence-based Medical
  Image Analysis","We collected 32 public datasets, of which 28 for medical imaging and 4 for
natural images, to conduct study. The images of these datasets are captured by
different cameras, thus vary from each other in modality, frame size and
capacity. For data accessibility, we also provide the websites of most datasets
and hope this will help the readers reach the datasets.",2021-02-02,2021,2021-02,medical
"Reliability Analysis of Artificial Intelligence Systems Using Recurrent
  Events Data from Autonomous Vehicles","Artificial intelligence (AI) systems have become increasingly common and the
trend will continue. Examples of AI systems include autonomous vehicles (AV),
computer vision, natural language processing, and AI medical experts. To allow
for safe and effective deployment of AI systems, the reliability of such
systems needs to be assessed. Traditionally, reliability assessment is based on
reliability test data and the subsequent statistical modeling and analysis. The
availability of reliability data for AI systems, however, is limited because
such data are typically sensitive and proprietary. The California Department of
Motor Vehicles (DMV) oversees and regulates an AV testing program, in which
many AV manufacturers are conducting AV road tests. Manufacturers participating
in the program are required to report recurrent disengagement events to
California DMV. This information is being made available to the public. In this
paper, we use recurrent disengagement events as a representation of the
reliability of the AI system in AV, and propose a statistical framework for
modeling and analyzing the recurrent events data from AV driving tests. We use
traditional parametric models in software reliability and propose a new
nonparametric model based on monotonic splines to describe the event process.
We develop inference procedures for selecting the best models, quantifying
uncertainty, and testing heterogeneity in the event process. We then analyze
the recurrent events data from four AV manufacturers, and make inferences on
the reliability of the AI systems in AV. We also describe how the proposed
analysis can be applied to assess the reliability of other AI systems.",2021-02-02,2021,2021-02,medical
"The Ethical Implications of Shared Medical Decision Making without
  Providing Adequate Computational Support to the Care Provider and to the
  Patient","There is a clear need to involve patients in medical decisions. However,
cognitive psychological research has highlighted the cognitive limitations of
humans with respect to 1. Probabilistic assessment of the patient state and of
potential outcomes of various decisions, 2. Elicitation of the patient utility
function, and 3. Integration of the probabilistic knowledge and of patient
preferences to determine the optimal strategy. Therefore, without adequate
computational support, current shared decision models have severe ethical
deficiencies. An informed consent model unfairly transfers the responsibility
to a patient who does not have the necessary knowledge, nor the integration
capability. A paternalistic model endows with exaggerated power a physician who
might not be aware of the patient preferences, is prone to multiple cognitive
biases, and whose computational integration capability is bounded. Recent
progress in Artificial Intelligence suggests adding a third agent: a computer,
in all deliberative medical decisions: Non emergency medical decisions in which
more than one alternative exists, the patient preferences can be elicited, the
therapeutic alternatives might be influenced by these preferences, medical
knowledge exists regarding the likelihood of the decision outcomes, and there
is sufficient decision time. Ethical physicians should exploit computational
decision support technologies, neither making the decisions solely on their
own, nor shirking their duty and shifting the responsibility to patients in the
name of informed consent. The resulting three way (patient, care provider,
computer) human machine model that we suggest emphasizes the patient
preferences, the physician knowledge, and the computational integration of both
aspects, does not diminish the physician role, but rather brings out the best
in human and machine.",2021-02-03,2021,2021-02,medical
Applications of Artificial Intelligence in Particle Radiotherapy,"Radiotherapy, due to its technology-intensive nature and reliance on digital
data and human-machine interactions, is particularly suited to benefit from
artificial intelligence (AI) to improve the accuracy and efficiency of its
clinical workflow. Recently, various artificial intelligence (AI) methods have
been successfully developed to exploit the benefit of the inherent physical
properties of particle therapy. Many reviews about AI applications in
radiotherapy have already been published, but none were specifically dedicated
to particle therapy. In this article, we present a comprehensive review of the
recent published works on AI applications in particle therapy, which can be
classified into particle therapy treatment planning, adaptive particle therapy,
range and dose verification and other applications in particle therapy.
Although promising results reported in these works demonstrate how AI-based
methods can help exploit the intrinsic physic advantages of particle therapy,
challenges remained to be address before AI applications in particle therapy
enjoy widespread implementation in clinical practice.",2021-02-05,2021,2021-02,medical
"Artificial Intelligence based Autonomous Molecular Design for Medical
  Therapeutic: A Perspective","Domain-aware machine learning (ML) models have been increasingly adopted for
accelerating small molecule therapeutic design in the recent years. These
models have been enabled by significant advancement in state-of-the-art
artificial intelligence (AI) and computing infrastructures. Several ML
architectures are pre-dominantly and independently used either for predicting
the properties of small molecules, or for generating lead therapeutic
candidates. Synergetically using these individual components along with robust
representation and data generation techniques autonomously in closed loops
holds enormous promise for accelerated drug design which is a time consuming
and expensive task otherwise. In this perspective, we present the most recent
breakthrough achieved by each of the components, and how such autonomous AI and
ML workflow can be realized to radically accelerate the hit identification and
lead optimization. Taken together, this could significantly shorten the
timeline for end-to-end antiviral discovery and optimization times to weeks
upon the arrival of a novel zoonotic transmission event. Our perspective serves
as a guide for researchers to practice autonomous molecular design in
therapeutic discovery.",2021-02-10,2021,2021-02,medical
"MixSearch: Searching for Domain Generalized Medical Image Segmentation
  Architectures","Considering the scarcity of medical data, most datasets in medical image
analysis are an order of magnitude smaller than those of natural images.
However, most Network Architecture Search (NAS) approaches in medical images
focused on specific datasets and did not take into account the generalization
ability of the learned architectures on unseen datasets as well as different
domains. In this paper, we address this point by proposing to search for
generalizable U-shape architectures on a composited dataset that mixes medical
images from multiple segmentation tasks and domains creatively, which is named
MixSearch. Specifically, we propose a novel approach to mix multiple
small-scale datasets from multiple domains and segmentation tasks to produce a
large-scale dataset. Then, a novel weaved encoder-decoder structure is designed
to search for a generalized segmentation network in both cell-level and
network-level. The network produced by the proposed MixSearch framework
achieves state-of-the-art results compared with advanced encoder-decoder
networks across various datasets.",2021-02-26,2021,2021-02,medical
Medical Imaging and Machine Learning,"Advances in computing power, deep learning architectures, and expert labelled
datasets have spurred the development of medical imaging artificial
intelligence systems that rival clinical experts in a variety of scenarios. The
National Institutes of Health in 2018 identified key focus areas for the future
of artificial intelligence in medical imaging, creating a foundational roadmap
for research in image acquisition, algorithms, data standardization, and
translatable clinical decision support systems. Among the key issues raised in
the report: data availability, need for novel computing architectures and
explainable AI algorithms, are still relevant despite the tremendous progress
made over the past few years alone. Furthermore, translational goals of data
sharing, validation of performance for regulatory approval, generalizability
and mitigation of unintended bias must be accounted for early in the
development process. In this perspective paper we explore challenges unique to
high dimensional clinical imaging data, in addition to highlighting some of the
technical and ethical considerations in developing high-dimensional,
multi-modality, machine learning systems for clinical decision support.",2021-03-02,2021,2021-03,medical
"A Comparative Approach to Explainable Artificial Intelligence Methods in
  Application to High-Dimensional Electronic Health Records: Examining the
  Usability of XAI","Explainable Artificial Intelligence (XAI) is a rising field in AI. It aims to
produce a demonstrative factor of trust, which for human subjects is achieved
through communicative means, which Machine Learning (ML) algorithms cannot
solely produce, illustrating the necessity of an extra layer producing support
to the model output. When approaching the medical field, we can see challenges
arise when dealing with the involvement of human-subjects, the ideology behind
trusting a machine to tend towards the livelihood of a human poses an ethical
conundrum - leaving trust as the basis of the human-expert in acceptance to the
machines decision. The aim of this paper is to apply XAI methods to demonstrate
the usability of explainable architectures as a tertiary layer for the medical
domain supporting ML predictions and human-expert opinion, XAI methods produce
visualization of the feature contribution towards a given models output on both
a local and global level. The work in this paper uses XAI to determine feature
importance towards high-dimensional data-driven questions to inform
domain-experts of identifiable trends with a comparison of model-agnostic
methods in application to ML algorithms. The performance metrics for a
glass-box method is also provided as a comparison against black-box capability
for tabular data. Future work will aim to produce a user-study using metrics to
evaluate human-expert usability and opinion of the given models.",2021-03-08,2021,2021-03,medical
"Demographic Aware Probabilistic Medical Knowledge Graph Embeddings of
  Electronic Medical Records","Medical knowledge graphs (KGs) constructed from Electronic Medical Records
(EMR) contain abundant information about patients and medical entities. The
utilization of KG embedding models on these data has proven to be efficient for
different medical tasks. However, existing models do not properly incorporate
patient demographics and most of them ignore the probabilistic features of the
medical KG. In this paper, we propose DARLING (Demographic Aware pRobabiListic
medIcal kNowledge embeddinG), a demographic-aware medical KG embedding
framework that explicitly incorporates demographics in the medical entities
space by associating patient demographics with a corresponding hyperplane. Our
framework leverages the probabilistic features within the medical entities for
learning their representations through demographic guidance. We evaluate
DARLING through link prediction for treatments and medicines, on a medical KG
constructed from EMR data, and illustrate its superior performance compared to
existing KG embedding models.",2021-03-22,2021,2021-03,medical
"Artificial Intelligence in Tumor Subregion Analysis Based on Medical
  Imaging: A Review","Medical imaging is widely used in cancer diagnosis and treatment, and
artificial intelligence (AI) has achieved tremendous success in various tasks
of medical image analysis. This paper reviews AI-based tumor subregion analysis
in medical imaging. We summarize the latest AI-based methods for tumor
subregion analysis and their applications. Specifically, we categorize the
AI-based methods by training strategy: supervised and unsupervised. A detailed
review of each category is presented, highlighting important contributions and
achievements. Specific challenges and potential AI applications in tumor
subregion analysis are discussed.",2021-03-25,2021,2021-03,medical
"MedSelect: Selective Labeling for Medical Image Classification Combining
  Meta-Learning with Deep Reinforcement Learning","We propose a selective learning method using meta-learning and deep
reinforcement learning for medical image interpretation in the setting of
limited labeling resources. Our method, MedSelect, consists of a trainable deep
learning selector that uses image embeddings obtained from contrastive
pretraining for determining which images to label, and a non-parametric
selector that uses cosine similarity to classify unseen images. We demonstrate
that MedSelect learns an effective selection strategy outperforming baseline
selection strategies across seen and unseen medical conditions for chest X-ray
interpretation. We also perform an analysis of the selections performed by
MedSelect comparing the distribution of latent embeddings and clinical
features, and find significant differences compared to the strongest performing
baseline. We believe that our method may be broadly applicable across medical
imaging settings where labels are expensive to acquire.",2021-03-26,2021,2021-03,medical
"MeSIN: Multilevel Selective and Interactive Network for Medication
  Recommendation","Recommending medications for patients using electronic health records (EHRs)
is a crucial data mining task for an intelligent healthcare system. It can
assist doctors in making clinical decisions more efficiently. However, the
inherent complexity of the EHR data renders it as a challenging task: (1)
Multilevel structures: the EHR data typically contains multilevel structures
which are closely related with the decision-making pathways, e.g., laboratory
results lead to disease diagnoses, and then contribute to the prescribed
medications; (2) Multiple sequences interactions: multiple sequences in EHR
data are usually closely correlated with each other; (3) Abundant noise: lots
of task-unrelated features or noise information within EHR data generally
result in suboptimal performance. To tackle the above challenges, we propose a
multilevel selective and interactive network (MeSIN) for medication
recommendation. Specifically, MeSIN is designed with three components. First,
an attentional selective module (ASM) is applied to assign flexible attention
scores to different medical codes embeddings by their relevance to the
recommended medications in every admission. Second, we incorporate a novel
interactive long-short term memory network (InLSTM) to reinforce the
interactions of multilevel medical sequences in EHR data with the help of the
calibrated memory-augmented cell and an enhanced input gate. Finally, we employ
a global selective fusion module (GSFM) to infuse the multi-sourced information
embeddings into final patient representations for medications recommendation.
To validate our method, extensive experiments have been conducted on a
real-world clinical dataset. The results demonstrate a consistent superiority
of our framework over several baselines and testify the effectiveness of our
proposed approach.",2021-04-22,2021,2021-04,medical
"Contextualized Keyword Representations for Multi-modal Retinal Image
  Captioning","Medical image captioning automatically generates a medical description to
describe the content of a given medical image. A traditional medical image
captioning model creates a medical description only based on a single medical
image input. Hence, an abstract medical description or concept is hard to be
generated based on the traditional approach. Such a method limits the
effectiveness of medical image captioning. Multi-modal medical image captioning
is one of the approaches utilized to address this problem. In multi-modal
medical image captioning, textual input, e.g., expert-defined keywords, is
considered as one of the main drivers of medical description generation. Thus,
encoding the textual input and the medical image effectively are both important
for the task of multi-modal medical image captioning. In this work, a new
end-to-end deep multi-modal medical image captioning model is proposed.
Contextualized keyword representations, textual feature reinforcement, and
masked self-attention are used to develop the proposed approach. Based on the
evaluation of the existing multi-modal medical image captioning dataset,
experimental results show that the proposed model is effective with the
increase of +53.2% in BLEU-avg and +18.6% in CIDEr, compared with the
state-of-the-art method.",2021-04-26,2021,2021-04,medical
Medical Transformer: Universal Brain Encoder for 3D MRI Analysis,"Transfer learning has gained attention in medical image analysis due to
limited annotated 3D medical datasets for training data-driven deep learning
models in the real world. Existing 3D-based methods have transferred the
pre-trained models to downstream tasks, which achieved promising results with
only a small number of training samples. However, they demand a massive amount
of parameters to train the model for 3D medical imaging. In this work, we
propose a novel transfer learning framework, called Medical Transformer, that
effectively models 3D volumetric images in the form of a sequence of 2D image
slices. To make a high-level representation in 3D-form empowering spatial
relations better, we take a multi-view approach that leverages plenty of
information from the three planes of 3D volume, while providing
parameter-efficient training. For building a source model generally applicable
to various tasks, we pre-train the model in a self-supervised learning manner
for masked encoding vector prediction as a proxy task, using a large-scale
normal, healthy brain magnetic resonance imaging (MRI) dataset. Our pre-trained
model is evaluated on three downstream tasks: (i) brain disease diagnosis, (ii)
brain age prediction, and (iii) brain tumor segmentation, which are actively
studied in brain MRI research. The experimental results show that our Medical
Transformer outperforms the state-of-the-art transfer learning methods,
efficiently reducing the number of parameters up to about 92% for
classification and",2021-04-28,2021,2021-04,medical
"Explainable Artificial Intelligence for Human Decision-Support System in
  Medical Domain","In the present paper we present the potential of Explainable Artificial
Intelligence methods for decision-support in medical image analysis scenarios.
With three types of explainable methods applied to the same medical image data
set our aim was to improve the comprehensibility of the decisions provided by
the Convolutional Neural Network (CNN). The visual explanations were provided
on in-vivo gastral images obtained from a Video capsule endoscopy (VCE), with
the goal of increasing the health professionals' trust in the black box
predictions. We implemented two post-hoc interpretable machine learning methods
LIME and SHAP and the alternative explanation approach CIU, centered on the
Contextual Value and Utility (CIU). The produced explanations were evaluated
using human evaluation. We conducted three user studies based on the
explanations provided by LIME, SHAP and CIU. Users from different non-medical
backgrounds carried out a series of tests in the web-based survey setting and
stated their experience and understanding of the given explanations. Three user
groups (n=20, 20, 20) with three distinct forms of explanations were
quantitatively analyzed. We have found that, as hypothesized, the CIU
explainable method performed better than both LIME and SHAP methods in terms of
increasing support for human decision-making as well as being more transparent
and thus understandable to users. Additionally, CIU outperformed LIME and SHAP
by generating explanations more rapidly. Our findings suggest that there are
notable differences in human decision-making between various explanation
support settings. In line with that, we present three potential explainable
methods that can with future improvements in implementation be generalized on
different medical data sets and can provide great decision-support for medical
experts.",2021-05-05,2021,2021-05,medical
"Change Matters: Medication Change Prediction with Recurrent Residual
  Networks","Deep learning is revolutionizing predictive healthcare, including
recommending medications to patients with complex health conditions. Existing
approaches focus on predicting all medications for the current visit, which
often overlaps with medications from previous visits. A more clinically
relevant task is to identify medication changes.
  In this paper, we propose a new recurrent residual network, named MICRON, for
medication change prediction. MICRON takes the changes in patient health
records as input and learns to update a hidden medication vector and the
medication set recurrently with a reconstruction design. The medication vector
is like the memory cell that encodes longitudinal information of medications.
Unlike traditional methods that require the entire patient history for
prediction, MICRON has a residual-based inference that allows for sequential
updating based only on new patient features (e.g., new diagnoses in the recent
visit) more efficiently.
  We evaluated MICRON on real inpatient and outpatient datasets. MICRON
achieves 3.5% and 7.8% relative improvements over the best baseline in F1
score, respectively. MICRON also requires fewer parameters, which significantly
reduces the training time to 38.3s per epoch with 1.5x speed-up.",2021-05-05,2021,2021-05,medical
Semi-Supervised Variational Reasoning for Medical Dialogue Generation,"Medical dialogue generation aims to provide automatic and accurate responses
to assist physicians to obtain diagnosis and treatment suggestions in an
efficient manner. In medical dialogues two key characteristics are relevant for
response generation: patient states (such as symptoms, medication) and
physician actions (such as diagnosis, treatments). In medical scenarios
large-scale human annotations are usually not available, due to the high costs
and privacy requirements. Hence, current approaches to medical dialogue
generation typically do not explicitly account for patient states and physician
actions, and focus on implicit representation instead. We propose an end-to-end
variational reasoning approach to medical dialogue generation. To be able to
deal with a limited amount of labeled data, we introduce both patient state and
physician action as latent variables with categorical priors for explicit
patient state tracking and physician policy learning, respectively. We propose
a variational Bayesian generative approach to approximate posterior
distributions over patient states and physician actions. We use an efficient
stochastic gradient variational Bayes estimator to optimize the derived
evidence lower bound, where a 2-stage collapsed inference method is proposed to
reduce the bias during model training. A physician policy network composed of
an action-classifier and two reasoning detectors is proposed for augmented
reasoning ability. We conduct experiments on three datasets collected from
medical platforms. Our experimental results show that the proposed method
outperforms state-of-the-art baselines in terms of objective and subjective
evaluation metrics. Our experiments also indicate that our proposed
semi-supervised reasoning method achieves a comparable performance as
state-of-the-art fully supervised learning baselines for physician policy
learning.",2021-05-13,2021,2021-05,medical
"MedSensor: Medication Adherence Monitoring Using Neural Networks on
  Smartwatch Accelerometer Sensor Data","Poor medication adherence presents serious economic and health problems
including compromised treatment effectiveness, medical complications, and loss
of billions of dollars in wasted medicine or procedures. Though various
interventions have been proposed to address this problem, there is an urgent
need to leverage light, smart, and minimally obtrusive technology such as
smartwatches to develop user tools to improve medication use and adherence. In
this study, we conducted several experiments on medication-taking activities,
developed a smartwatch android application to collect the accelerometer hand
gesture data from the smartwatch, and conveyed the data collected to a central
cloud database. We developed neural networks, then trained the networks on the
sensor data to recognize medication and non-medication gestures. With the
proposed machine learning algorithm approach, this study was able to achieve
average accuracy scores of 97% on the protocol-guided gesture data, and 95% on
natural gesture data.",2021-05-19,2021,2021-05,medical
"Zero-shot Medical Entity Retrieval without Annotation: Learning From
  Rich Knowledge Graph Semantics","Medical entity retrieval is an integral component for understanding and
communicating information across various health systems. Current approaches
tend to work well on specific medical domains but generalize poorly to unseen
sub-specialties. This is of increasing concern under a public health crisis as
new medical conditions and drug treatments come to light frequently. Zero-shot
retrieval is challenging due to the high degree of ambiguity and variability in
medical corpora, making it difficult to build an accurate similarity measure
between mentions and concepts. Medical knowledge graphs (KG), however, contain
rich semantics including large numbers of synonyms as well as its curated
graphical structures. To take advantage of this valuable information, we
propose a suite of learning tasks designed for training efficient zero-shot
entity retrieval models. Without requiring any human annotation, our knowledge
graph enriched architecture significantly outperforms common zero-shot
benchmarks including BM25 and Clinical BERT with 7% to 30% higher recall across
multiple major medical ontologies, such as UMLS, SNOMED, and ICD-10.",2021-05-26,2021,2021-05,medical
Multi-turn Dialog System on Single-turn Data in Medical Domain,"Recently there has been a huge interest in dialog systems. This interest has
also been developed in the field of the medical domain where researchers are
focusing on building a dialog system in the medical domain. This research is
focused on the multi-turn dialog system trained on the multi-turn dialog data.
It is difficult to gather a huge amount of multi-turn conversational data in
the medical domain that is verified by professionals and can be trusted.
However, there are several frequently asked questions (FAQs) or single-turn QA
pairs that have information that is verified by the experts and can be used to
build a multi-turn dialog system.",2021-05-27,2021,2021-05,medical
"Path-based knowledge reasoning with textual semantic information for
  medical knowledge graph completion","Background Knowledge graphs (KGs), especially medical knowledge graphs, are
often significantly incomplete, so it necessitating a demand for medical
knowledge graph completion (MedKGC). MedKGC can find new facts based on the
exited knowledge in the KGs. The path-based knowledge reasoning algorithm is
one of the most important approaches to this task. This type of method has
received great attention in recent years because of its high performance and
interpretability. In fact, traditional methods such as path ranking algorithm
(PRA) take the paths between an entity pair as atomic features. However, the
medical KGs are very sparse, which makes it difficult to model effective
semantic representation for extremely sparse path features. The sparsity in the
medical KGs is mainly reflected in the long-tailed distribution of entities and
paths. Previous methods merely consider the context structure in the paths of
the knowledge graph and ignore the textual semantics of the symbols in the
path. Therefore, their performance cannot be further improved due to the two
aspects of entity sparseness and path sparseness. To address the above issues,
this paper proposes two novel path-based reasoning methods to solve the
sparsity issues of entity and path respectively, which adopts the textual
semantic information of entities and paths for MedKGC. By using the pre-trained
model BERT, combining the textual semantic representations of the entities and
the relationships, we model the task of symbolic reasoning in the medical KG as
a numerical computing issue in textual semantic representation.",2021-05-27,2021,2021-05,medical
"Effect of Pre-Training Scale on Intra- and Inter-Domain Full and
  Few-Shot Transfer Learning for Natural and Medical X-Ray Chest Images","Increasing model, data and compute budget scale in the pre-training has been
shown to strongly improve model generalization and transfer learning in vast
line of work done in language modeling and natural image recognition. However,
most studies on the positive effect of larger scale were done in scope of
in-domain setting, with source and target data being in close proximity. To
study effect of larger scale for both in-domain and out-of-domain setting when
performing full and few-shot transfer, we combine here for the first time
large, openly available medical X-Ray chest imaging datasets to reach a scale
for medical imaging domain comparable to ImageNet-1k, routinely used for
pre-training in natural image domain. We then conduct supervised pre-training,
while varying network size and source data scale and domain, being either large
natural (ImageNet-1k/21k) or large medical chest X-Ray datasets, and transfer
pre-trained models to different natural or medical targets. We observe strong
improvement due to larger pre-training scale for intra-domain natural-natural
and medical-medical transfer. For inter-domain natural-medical transfer, we
find improvements due to larger pre-training scale on larger X-Ray targets in
full shot regime, while for smaller targets and for few-shot regime the
improvement is not visible. Remarkably, large networks pre-trained on very
large natural ImageNet-21k are as good or better than networks pre-trained on
largest available medical X-Ray data when performing transfer to large X-Ray
targets. We conclude that substantially increasing model and generic, medical
domain-agnostic natural image source data scale in the pre-training can enable
high quality out-of-domain transfer to medical domain specific targets,
removing dependency on large medical domain-specific source data often not
available in the practice.",2021-05-31,2021,2021-05,medical
"Explainable AI for medical imaging: Explaining pneumothorax diagnoses
  with Bayesian Teaching","Limited expert time is a key bottleneck in medical imaging. Due to advances
in image classification, AI can now serve as decision-support for medical
experts, with the potential for great gains in radiologist productivity and, by
extension, public health. However, these gains are contingent on building and
maintaining experts' trust in the AI agents. Explainable AI may build such
trust by helping medical experts to understand the AI decision processes behind
diagnostic judgements. Here we introduce and evaluate explanations based on
Bayesian Teaching, a formal account of explanation rooted in the cognitive
science of human learning. We find that medical experts exposed to explanations
generated by Bayesian Teaching successfully predict the AI's diagnostic
decisions and are more likely to certify the AI for cases when the AI is
correct than when it is wrong, indicating appropriate trust. These results show
that Explainable AI can be used to support human-AI collaboration in medical
imaging.",2021-06-08,2021,2021-06,medical
Next-Gen Machine Learning Supported Diagnostic Systems for Spacecraft,"Future short or long-term space missions require a new generation of
monitoring and diagnostic systems due to communication impasses as well as
limitations in specialized crew and equipment. Machine learning supported
diagnostic systems present a viable solution for medical and technical
applications. We discuss challenges and applicability of such systems in light
of upcoming missions and outline an example use case for a next-generation
medical diagnostic system for future space operations. Additionally, we present
approach recommendations and constraints for the successful generation and use
of machine learning models aboard a spacecraft.",2021-06-10,2021,2021-06,medical
Probing Pre-Trained Language Models for Disease Knowledge,"Pre-trained language models such as ClinicalBERT have achieved impressive
results on tasks such as medical Natural Language Inference. At first glance,
this may suggest that these models are able to perform medical reasoning tasks,
such as mapping symptoms to diseases. However, we find that standard benchmarks
such as MedNLI contain relatively few examples that require such forms of
reasoning. To better understand the medical reasoning capabilities of existing
language models, in this paper we introduce DisKnE, a new benchmark for Disease
Knowledge Evaluation. To construct this benchmark, we annotated each positive
MedNLI example with the types of medical reasoning that are needed. We then
created negative examples by corrupting these positive examples in an
adversarial way. Furthermore, we define training-test splits per disease,
ensuring that no knowledge about test diseases can be learned from the training
data, and we canonicalize the formulation of the hypotheses to avoid the
presence of artefacts. This leads to a number of binary classification
problems, one for each type of reasoning and each disease. When analysing
pre-trained models for the clinical/biomedical domain on the proposed
benchmark, we find that their performance drops considerably.",2021-06-14,2021,2021-06,medical
"A Fair and Ethical Healthcare Artificial Intelligence System for
  Monitoring Driver Behavior and Preventing Road Accidents","This paper presents a new approach to prevent transportation accidents and
monitor driver's behavior using a healthcare AI system that incorporates
fairness and ethics. Dangerous medical cases and unusual behavior of the driver
are detected. Fairness algorithm is approached in order to improve
decision-making and address ethical issues such as privacy issues, and to
consider challenges that appear in the wild within AI in healthcare and
driving. A healthcare professional will be alerted about any unusual activity,
and the driver's location when necessary, is provided in order to enable the
healthcare professional to immediately help to the unstable driver. Therefore,
using the healthcare AI system allows for accidents to be predicted and thus
prevented and lives may be saved based on the built-in AI system inside the
vehicle which interacts with the ER system.",2021-06-16,2021,2021-06,medical
"Transformer-based unsupervised patient representation learning based on
  medical claims for risk stratification and analysis","The claims data, containing medical codes, services information, and incurred
expenditure, can be a good resource for estimating an individual's health
condition and medical risk level. In this study, we developed Transformer-based
Multimodal AutoEncoder (TMAE), an unsupervised learning framework that can
learn efficient patient representation by encoding meaningful information from
the claims data. TMAE is motivated by the practical needs in healthcare to
stratify patients into different risk levels for improving care delivery and
management. Compared to previous approaches, TMAE is able to 1) model
inpatient, outpatient, and medication claims collectively, 2) handle irregular
time intervals between medical events, 3) alleviate the sparsity issue of the
rare medical codes, and 4) incorporate medical expenditure information. We
trained TMAE using a real-world pediatric claims dataset containing more than
600,000 patients and compared its performance with various approaches in two
clustering tasks. Experimental results demonstrate that TMAE has superior
performance compared to all baselines. Multiple downstream applications are
also conducted to illustrate the effectiveness of our framework. The promising
results confirm that the TMAE framework is scalable to large claims data and is
able to generate efficient patient embeddings for risk stratification and
analysis.",2021-06-23,2021,2021-06,medical
"Objective task-based evaluation of artificial intelligence-based medical
  imaging methods: Framework, strategies and role of the physician","Artificial intelligence (AI)-based methods are showing promise in multiple
medical-imaging applications. Thus, there is substantial interest in clinical
translation of these methods, requiring in turn, that they be evaluated
rigorously. In this paper, our goal is to lay out a framework for objective
task-based evaluation of AI methods. We will also provide a list of tools
available in the literature to conduct this evaluation. Further, we outline the
important role of physicians in conducting these evaluation studies. The
examples in this paper will be proposed in the context of PET with a focus on
neural-network-based methods. However, the framework is also applicable to
evaluate other medical-imaging modalities and other types of AI methods.",2021-07-09,2021,2021-07,medical
Artificial Intelligence in PET: an Industry Perspective,"Artificial intelligence (AI) has significant potential to positively impact
and advance medical imaging, including positron emission tomography (PET)
imaging applications. AI has the ability to enhance and optimize all aspects of
the PET imaging chain from patient scheduling, patient setup, protocoling, data
acquisition, detector signal processing, reconstruction, image processing and
interpretation. AI poses industry-specific challenges which will need to be
addressed and overcome to maximize the future potentials of AI in PET. This
paper provides an overview of these industry-specific challenges for the
development, standardization, commercialization, and clinical adoption of AI,
and explores the potential enhancements to PET imaging brought on by AI in the
near future. In particular, the combination of on-demand image reconstruction,
AI, and custom designed data processing workflows may open new possibilities
for innovation which would positively impact the industry and ultimately
patients.",2021-07-14,2021,2021-07,medical
"Explainable artificial intelligence (XAI) in deep learning-based medical
  image analysis","With an increase in deep learning-based methods, the call for explainability
of such methods grows, especially in high-stakes decision making areas such as
medical image analysis. This survey presents an overview of eXplainable
Artificial Intelligence (XAI) used in deep learning-based medical image
analysis. A framework of XAI criteria is introduced to classify deep
learning-based medical image analysis methods. Papers on XAI techniques in
medical image analysis are then surveyed and categorized according to the
framework and according to anatomical location. The paper concludes with an
outlook of future opportunities for XAI in medical image analysis.",2021-07-22,2021,2021-07,medical
"Toward High-Throughput Artificial Intelligence-Based Segmentation in
  Oncological PET Imaging","Artificial intelligence (AI) techniques for image-based segmentation have
garnered much attention in recent years. Convolutional neural networks (CNNs)
have shown impressive results and potential towards fully automated
segmentation in medical imaging, and particularly PET imaging. To cope with the
limited access to annotated data needed in supervised AI methods, given tedious
and prone-to-error manual delineations, semi-supervised and unsupervised AI
techniques have also been explored for segmentation of tumors or normal organs
in single and bi-modality scans. This work provides a review of existing AI
techniques for segmentation tasks and the evaluation criteria for translational
AI-based segmentation efforts towards routine adoption in clinical workflows.",2021-07-28,2021,2021-07,medical
"A Method for Medical Data Analysis Using the LogNNet for Clinical
  Decision Support Systems and Edge Computing in Healthcare","Edge computing is a fast-growing and much needed technology in healthcare.
The problem of implementing artificial intelligence on edge devices is the
complexity and high resource intensity of the most known neural network data
analysis methods and algorithms. The difficulty of implementing these methods
on low-power microcontrollers with small memory size calls for the development
of new effective algorithms for neural networks. This study presents a new
method for analyzing medical data based on the LogNNet neural network, which
uses chaotic mappings to transform input information. The method effectively
solves classification problems and calculates risk factors for the presence of
a disease in a patient according to a set of medical health indicators. The
efficiency of LogNNet in assessing perinatal risk is illustrated on
cardiotocogram data obtained from the UC Irvine machine learning repository.
The classification accuracy reaches ~91% with the ~3-10 kB of RAM used on the
Arduino microcontroller. Using the LogNNet network trained on a publicly
available database of the Israeli Ministry of Health, a service concept for
COVID-19 express testing is provided. A classification accuracy of ~95% is
achieved, and ~0.6 kB of RAM is used. In all examples, the model is tested
using standard classification quality metrics: precision, recall, and
F1-measure. The LogNNet architecture allows the implementation of artificial
intelligence on medical peripherals of the Internet of Things with low RAM
resources and can be used in clinical decision support systems.",2021-08-05,2021,2021-08,medical
"Symptom based Hierarchical Classification of Diabetes and Thyroid
  disorders using Fuzzy Cognitive Maps","Fuzzy Cognitive Maps (FCMs) are soft computing technique that follows an
approach similar to human reasoning and human decision-making process, making
them a valuable modeling and simulation methodology. Medical Decision Systems
are complex systems consisting of many factors that may be complementary,
contradictory, and competitive; these factors influence each other and
determine the overall diagnosis with a different degree. Thus, FCMs are
suitable to model Medical Decision Support Systems. The proposed work therefore
uses FCMs arranged in hierarchical structure to classify between Diabetes,
Thyroid disorders and their subtypes. Subtypes include type 1 and type 2 for
diabetes and hyperthyroidism and hypothyroidism for thyroid.",2021-08-08,2021,2021-08,medical
"Improvement of a Prediction Model for Heart Failure Survival through
  Explainable Artificial Intelligence","Cardiovascular diseases and their associated disorder of heart failure are
one of the major death causes globally, being a priority for doctors to detect
and predict its onset and medical consequences. Artificial Intelligence (AI)
allows doctors to discover clinical indicators and enhance their diagnosis and
treatments. Specifically, explainable AI offers tools to improve the clinical
prediction models that experience poor interpretability of their results. This
work presents an explainability analysis and evaluation of a prediction model
for heart failure survival by using a dataset that comprises 299 patients who
suffered heart failure. The model employs a data workflow pipeline able to
select the best ensemble tree algorithm as well as the best feature selection
technique. Moreover, different post-hoc techniques have been used for the
explainability analysis of the model. The paper's main contribution is an
explainability-driven approach to select the best prediction model for HF
survival based on an accuracy-explainability balance. Therefore, the most
balanced explainable prediction model implements an Extra Trees classifier over
5 selected features (follow-up time, serum creatinine, ejection fraction, age
and diabetes) out of 12, achieving a balanced-accuracy of 85.1% and 79.5% with
cross-validation and new unseen data respectively. The follow-up time is the
most influencing feature followed by serum-creatinine and ejection-fraction.
The explainable prediction model for HF survival presented in this paper would
improve a further adoption of clinical prediction models by providing doctors
with intuitions to better understand the reasoning of, usually, black-box AI
clinical solutions, and make more reasonable and data-driven decisions.",2021-08-20,2021,2021-08,medical
"Sinoledge: A Knowledge Engine based on Logical Reasoning and Distributed
  Micro Services","We propose a knowledge engine called Sinoledge mainly for doctors,
physicians, and researchers in medical field to organize thoughts, manage
reasoning process, test and deploy to production environments effortlessly. Our
proposal can be related to rule engine usually used in business or medical
fields. More importantly, our proposal provides a user-friendly interface, an
easy-maintain way of organizing knowledge, an understandable testing
functionality and a highly available and efficient back-end architecture.",2021-08-29,2021,2021-08,medical
"ReMeDi: Resources for Multi-domain, Multi-service, Medical Dialogues","Medical dialogue systems (MDSs) aim to assist doctors and patients with a
range of professional medical services, i.e., diagnosis, treatment and
consultation. The development of MDSs is hindered because of a lack of
resources. In particular. (1) there is no dataset with large-scale medical
dialogues that covers multiple medical services and contains fine-grained
medical labels (i.e., intents, actions, slots, values), and (2) there is no set
of established benchmarks for MDSs for multi-domain, multi-service medical
dialogues. In this paper, we present ReMeDi, a set of resource for medical
dialogues. ReMeDi consists of two parts, the ReMeDi dataset and the ReMeDi
benchmarks. The ReMeDi dataset contains 96,965 conversations between doctors
and patients, including 1,557 conversations with fine-gained labels. It covers
843 types of diseases, 5,228 medical entities, and 3 specialties of medical
services across 40 domains. To the best of our knowledge, the ReMeDi dataset is
the only medical dialogue dataset that covers multiple domains and services,
and has fine-grained medical labels. The second part of the ReMeDi resources
consists of a set of state-of-the-art models for (medical) dialogue generation.
The ReMeDi benchmark has the following methods: (1) pretrained models (i.e.,
BERT-WWM, BERT-MED, GPT2, and MT5) trained, validated, and tested on the ReMeDi
dataset, and (2) a self-supervised contrastive learning(SCL) method to expand
the ReMeDi dataset and enhance the training of the state-of-the-art pretrained
models. We describe the creation of the ReMeDi dataset, the ReMeDi benchmarking
methods, and establish experimental results using the ReMeDi benchmarking
methods on the ReMeDi dataset for future research to compare against. With this
paper, we share the dataset, implementations of the benchmarks, and evaluation
scripts.",2021-09-01,2021,2021-09,medical
Artificial Intelligence in Dry Eye Disease,"Dry eye disease (DED) has a prevalence of between 5 and 50\%, depending on
the diagnostic criteria used and population under study. However, it remains
one of the most underdiagnosed and undertreated conditions in ophthalmology.
Many tests used in the diagnosis of DED rely on an experienced observer for
image interpretation, which may be considered subjective and result in
variation in diagnosis. Since artificial intelligence (AI) systems are capable
of advanced problem solving, use of such techniques could lead to more
objective diagnosis. Although the term `AI' is commonly used, recent success in
its applications to medicine is mainly due to advancements in the sub-field of
machine learning, which has been used to automatically classify images and
predict medical outcomes. Powerful machine learning techniques have been
harnessed to understand nuances in patient data and medical images, aiming for
consistent diagnosis and stratification of disease severity. This is the first
literature review on the use of AI in DED. We provide a brief introduction to
AI, report its current use in DED research and its potential for application in
the clinic. Our review found that AI has been employed in a wide range of DED
clinical tests and research applications, primarily for interpretation of
interferometry, slit-lamp and meibography images. While initial results are
promising, much work is still needed on model development, clinical testing and
standardisation.",2021-09-02,2021,2021-09,medical
"Readying Medical Students for Medical AI: The Need to Embed AI Ethics
  Education","Medical students will almost inevitably encounter powerful medical AI systems
early in their careers. Yet, contemporary medical education does not adequately
equip students with the basic clinical proficiency in medical AI needed to use
these tools safely and effectively. Education reform is urgently needed, but
not easily implemented, largely due to an already jam-packed medical curricula.
In this article, we propose an education reform framework as an effective and
efficient solution, which we call the Embedded AI Ethics Education Framework.
Unlike other calls for education reform to accommodate AI teaching that are
more radical in scope, our framework is modest and incremental. It leverages
existing bioethics or medical ethics curricula to develop and deliver content
on the ethical issues associated with medical AI, especially the harms of
technology misuse, disuse, and abuse that affect the risk-benefit analyses at
the heart of healthcare. In doing so, the framework provides a simple tool for
going beyond the ""What?"" and the ""Why?"" of medical AI ethics education, to
answer the ""How?"", giving universities, course directors, and/or professors a
broad road-map for equipping their students with the necessary clinical
proficiency in medical AI.",2021-09-07,2021,2021-09,medical
"Medically Aware GPT-3 as a Data Generator for Medical Dialogue
  Summarization","In medical dialogue summarization, summaries must be coherent and must
capture all the medically relevant information in the dialogue. However,
learning effective models for summarization require large amounts of labeled
data which is especially hard to obtain. We present an algorithm to create
synthetic training data with an explicit focus on capturing medically relevant
information. We utilize GPT-3 as the backbone of our algorithm and scale 210
human labeled examples to yield results comparable to using 6400 human labeled
examples (~30x) leveraging low-shot learning and an ensemble method. In
detailed experiments, we show that this approach produces high quality training
data that can further be combined with human labeled data to get summaries that
are strongly preferable to those produced by models trained on human data alone
both in terms of medical accuracy and coherency.",2021-09-09,2021,2021-09,medical
Toward a Perspectivist Turn in Ground Truthing for Predictive Computing,"Most Artificial Intelligence applications are based on supervised machine
learning (ML), which ultimately grounds on manually annotated data. The
annotation process is often performed in terms of a majority vote and this has
been proved to be often problematic, as highlighted by recent studies on the
evaluation of ML models. In this article we describe and advocate for a
different paradigm, which we call data perspectivism, which moves away from
traditional gold standard datasets, towards the adoption of methods that
integrate the opinions and perspectives of the human subjects involved in the
knowledge representation step of ML processes. Drawing on previous works which
inspired our proposal we describe the potential of our proposal for not only
the more subjective tasks (e.g. those related to human language) but also to
tasks commonly understood as objective (e.g. medical decision making), and
present the main advantages of adopting a perspectivist stance in ML, as well
as possible disadvantages, and various ways in which such a stance can be
implemented in practice. Finally, we share a set of recommendations and outline
a research agenda to advance the perspectivist stance in ML.",2021-09-09,2021,2021-09,medical
"Risk Management of AI/ML Software as a Medical Device (SaMD): On ISO
  14971 and Related Standards and Guidances","Safety and efficacy are the paramount objectives of medical device
regulation. And in line with the medical ethos of non-maleficence, first do no
harm, safety is the primary goal of regulation also. As such, risk management
is the underlying principle that governs the regulation of medical devices,
whether traditional devices or Software as a Medical Device (SaMD). In this
article, I review how Risk Management Standard ISO 14971:2019 both connects
with and serves as a foundation for the other parts of the Artificial
Intelligence (AI)/Machine Learning (ML) SaMD regulatory framework.",2021-09-11,2021,2021-09,medical
"Co-Correcting: Noise-tolerant Medical Image Classification via mutual
  Label Correction","With the development of deep learning, medical image classification has been
significantly improved. However, deep learning requires massive data with
labels. While labeling the samples by human experts is expensive and
time-consuming, collecting labels from crowd-sourcing suffers from the noises
which may degenerate the accuracy of classifiers. Therefore, approaches that
can effectively handle label noises are highly desired. Unfortunately, recent
progress on handling label noise in deep learning has gone largely unnoticed by
the medical image. To fill the gap, this paper proposes a noise-tolerant
medical image classification framework named Co-Correcting, which significantly
improves classification accuracy and obtains more accurate labels through
dual-network mutual learning, label probability estimation, and curriculum
label correcting. On two representative medical image datasets and the MNIST
dataset, we test six latest Learning-with-Noisy-Labels methods and conduct
comparative studies. The experiments show that Co-Correcting achieves the best
accuracy and generalization under different noise ratios in various tasks. Our
project can be found at: https://github.com/JiarunLiu/Co-Correcting.",2021-09-11,2021,2021-09,medical
"An Apparatus for the Simulation of Breathing Disorders: Physically
  Meaningful Generation of Surrogate Data","The rapidly increasing prevalence of debilitating breathing disorders, such
as chronic obstructive pulmonary disease (COPD), calls for a meaningful
integration of artificial intelligence (AI) into healthcare. While this
promises improved detection and monitoring of breathing disorders, AI
techniques are almost invariably ""data hungry"" which highlights the importance
of generating physically meaningful surrogate data. Indeed, domain aware
surrogates would enable both an improved understanding of respiratory waveform
changes with different breathing disorders, and enhance the training of machine
learning algorithms. To this end, we introduce an apparatus comprising of PVC
tubes and 3D printed parts as a simple yet effective method of simulating both
obstructive and restrictive respiratory waveforms in healthy subjects.
Independent control over both inspiratory and expiratory resistances allows for
the simulation of obstructive breathing disorders through the whole spectrum of
FEV1/FVC spirometry ratios (used to classify COPD), ranging from healthy values
to values seen in severe chronic obstructive pulmonary disease. Moreover,
waveform characteristics of breathing disorders, such as a change in
inspiratory duty cycle or peak flow are also observed in the waveforms
resulting from use of the artificial breathing disorder simulation apparatus.
Overall, the proposed apparatus provides us with a simple, effective and
physically meaningful way to generate faithful surrogate breathing disorder
waveforms, a prerequisite for the use of artificial intelligence in respiratory
health.",2021-09-14,2021,2021-09,medical
"FUTURE-AI: Guiding Principles and Consensus Recommendations for
  Trustworthy Artificial Intelligence in Medical Imaging","The recent advancements in artificial intelligence (AI) combined with the
extensive amount of data generated by today's clinical systems, has led to the
development of imaging AI solutions across the whole value chain of medical
imaging, including image reconstruction, medical image segmentation,
image-based diagnosis and treatment planning. Notwithstanding the successes and
future potential of AI in medical imaging, many stakeholders are concerned of
the potential risks and ethical implications of imaging AI solutions, which are
perceived as complex, opaque, and difficult to comprehend, utilise, and trust
in critical clinical applications. Addressing these concerns and risks, the
FUTURE-AI framework has been proposed, which, sourced from a global
multi-domain expert consensus, comprises guiding principles for increased
trust, safety, and adoption for AI in healthcare. In this paper, we transform
the general FUTURE-AI healthcare principles to a concise and specific AI
implementation guide tailored to the needs of the medical imaging community. To
this end, we carefully assess each building block of the FUTURE-AI framework
consisting of (i) Fairness, (ii) Universality, (iii) Traceability, (iv)
Usability, (v) Robustness and (vi) Explainability, and respectively define
concrete best practices based on accumulated AI implementation experiences from
five large European projects on AI in Health Imaging. We accompany our concrete
step-by-step medical imaging development guide with a practical AI solution
maturity checklist, thus enabling AI development teams to design, evaluate,
maintain, and deploy technically, clinically and ethically trustworthy imaging
AI solutions into clinical practice.",2021-09-20,2021,2021-09,medical
GERNERMED -- An Open German Medical NER Model,"The current state of adoption of well-structured electronic health records
and integration of digital methods for storing medical patient data in
structured formats can often considered as inferior compared to the use of
traditional, unstructured text based patient data documentation. Data mining in
the field of medical data analysis often needs to rely solely on processing of
unstructured data to retrieve relevant data. In natural language processing
(NLP), statistical models have been shown successful in various tasks like
part-of-speech tagging, relation extraction (RE) and named entity recognition
(NER). In this work, we present GERNERMED, the first open, neural NLP model for
NER tasks dedicated to detect medical entity types in German text data. Here,
we avoid the conflicting goals of protection of sensitive patient data from
training data extraction and the publication of the statistical model weights
by training our model on a custom dataset that was translated from publicly
available datasets in foreign language by a pretrained neural machine
translation model. The sample code and the statistical model is available at:
https://github.com/frankkramer-lab/GERNERMED",2021-09-24,2021,2021-09,medical
Predicting COVID-19 Patient Shielding: A Comprehensive Study,"There are many ways machine learning and big data analytics are used in the
fight against the COVID-19 pandemic, including predictions, risk management,
diagnostics, and prevention. This study focuses on predicting COVID-19 patient
shielding -- identifying and protecting patients who are clinically extremely
vulnerable from coronavirus. This study focuses on techniques used for the
multi-label classification of medical text. Using the information published by
the United Kingdom NHS and the World Health Organisation, we present a novel
approach to predicting COVID-19 patient shielding as a multi-label
classification problem. We use publicly available, de-identified ICU medical
text data for our experiments. The labels are derived from the published
COVID-19 patient shielding data. We present an extensive comparison across 12
multi-label classifiers from the simple binary relevance to neural networks and
the most recent transformers. To the best of our knowledge this is the first
comprehensive study, where such a range of multi-label classifiers for medical
text are considered. We highlight the benefits of various approaches, and argue
that, for the task at hand, both predictive accuracy and processing time are
essential.",2021-10-01,2021,2021-10,medical
"Application of quantum computing to a linear non-Gaussian acyclic model
  for novel medical knowledge discovery","Recently, with the digitalization of medicine, the utilization of real-world
medical data collected from clinical sites has been attracting attention. In
this study, quantum computing was applied to a linear non-Gaussian acyclic
model to discover causal relationships from real-world medical data alone.
Specifically, the independence measure of DirectLiNGAM, a causal discovery
algorithm, was calculated using the quantum kernel and its accuracy on
real-world medical data was verified. When DirectLiNGAM with the quantum kernel
(qLiNGAM) was applied to real-world medical data, a case was confirmed in which
the causal structure could be correctly estimated when the amount of data was
small, which was not possible with existing methods. Furthermore, qLiNGAM was
implemented on real quantum hardware in an experiment using IBMQ. It is
suggested that qLiNGAM may be able to discover new medical knowledge and
contribute to the solution of medical problems, even when only a small amount
of data is available.",2021-10-09,2021,2021-10,medical
Anticipation-driven Adaptive Architecture for Assisted Living,"Anticipatory expression underlies human performance. Medical conditions and,
especially, aging result in diminished anticipatory action. In order to
mitigate the loss, means for engaging still available resources (capabilities)
can be provided. In particular, anticipation-driven adaptive environments could
be beneficial in medical care, as well as in assisted living for those seeking
such assistance. These adaptive environments are conceived to be individualized
and individualizable, in order to stimulate independent action instead of
creating dependencies.",2021-10-15,2021,2021-10,medical
"Towards Toxic and Narcotic Medication Detection with Rotated Object
  Detector","Recent years have witnessed the advancement of deep learning vision
technologies and applications in the medical industry. Intelligent devices for
special medication management are in great need of, which requires more precise
detection algorithms to identify the specifications and locations. In this
work, YOLO (You only look once) based object detectors are tailored for toxic
and narcotic medications detection tasks. Specifically, a more flexible
annotation with rotated degree ranging from $0^\circ$ to $90^\circ$ and a
mask-mapping-based non-maximum suppression method are proposed to achieve a
feasible and efficient medication detector aiming at arbitrarily oriented
bounding boxes. Extensive experiments demonstrate that the rotated YOLO
detectors are more suitable for identifying densely arranged drugs. The best
shot mean average precision of the proposed network reaches 0.811 while the
inference time is less than 300ms.",2021-10-19,2021,2021-10,medical
"Drug Similarity and Link Prediction Using Graph Embeddings on Medical
  Knowledge Graphs","The paper utilizes the graph embeddings generated for entities of a large
biomedical database to perform link prediction to capture various new
relationships among different entities. A novel node similarity measure is
proposed that utilizes the graph embeddings and link prediction scores to find
similarity scores among various drugs which can be used by the medical experts
to recommend alternative drugs to avoid side effects from original one.
Utilizing machine learning on knowledge graph for drug similarity and
recommendation will be less costly and less time consuming with higher
scalability as compared to traditional biomedical methods due to the dependency
on costly medical equipment and experts of the latter ones.",2021-10-22,2021,2021-10,medical
Circle Representation for Medical Object Detection,"Box representation has been extensively used for object detection in computer
vision. Such representation is efficacious but not necessarily optimized for
biomedical objects (e.g., glomeruli), which play an essential role in renal
pathology. In this paper, we propose a simple circle representation for medical
object detection and introduce CircleNet, an anchor-free detection framework.
Compared with the conventional bounding box representation, the proposed
bounding circle representation innovates in three-fold: (1) it is optimized for
ball-shaped biomedical objects; (2) The circle representation reduced the
degree of freedom compared with box representation; (3) It is naturally more
rotation invariant. When detecting glomeruli and nuclei on pathological images,
the proposed circle representation achieved superior detection performance and
be more rotation-invariant, compared with the bounding box. The code has been
made publicly available: https://github.com/hrlblab/CircleNet",2021-10-22,2021,2021-10,medical
"Lightweight Mobile Automated Assistant-to-physician for Global
  Lower-resource Areas","Importance: Lower-resource areas in Africa and Asia face a unique set of
healthcare challenges: the dual high burden of communicable and
non-communicable diseases; a paucity of highly trained primary healthcare
providers in both rural and densely populated urban areas; and a lack of
reliable, inexpensive internet connections. Objective: To address these
challenges, we designed an artificial intelligence assistant to help primary
healthcare providers in lower-resource areas document demographic and medical
sign/symptom data and to record and share diagnostic data in real-time with a
centralized database. Design: We trained our system using multiple data sets,
including US-based electronic medical records (EMRs) and open-source medical
literature and developed an adaptive, general medical assistant system based on
machine learning algorithms. Main outcomes and Measure: The application
collects basic information from patients and provides primary care providers
with diagnoses and prescriptions suggestions. The application is unique from
existing systems in that it covers a wide range of common diseases, signs, and
medication typical in lower-resource countries; the application works with or
without an active internet connection. Results: We have built and implemented
an adaptive learning system that assists trained primary care professionals by
means of an Android smartphone application, which interacts with a central
database and collects real-time data. The application has been tested by dozens
of primary care providers. Conclusions and Relevance: Our application would
provide primary healthcare providers in lower-resource areas with a tool that
enables faster and more accurate documentation of medical encounters. This
application could be leveraged to automatically populate local or national EMR
systems.",2021-10-28,2021,2021-10,medical
"Deep AUC Maximization for Medical Image Classification: Challenges and
  Opportunities","In this extended abstract, we will present and discuss opportunities and
challenges brought about by a new deep learning method by AUC maximization (aka
\underline{\bf D}eep \underline{\bf A}UC \underline{\bf M}aximization or {\bf
DAM}) for medical image classification. Since AUC (aka area under ROC curve) is
a standard performance measure for medical image classification, hence directly
optimizing AUC could achieve a better performance for learning a deep neural
network than minimizing a traditional loss function (e.g., cross-entropy loss).
Recently, there emerges a trend of using deep AUC maximization for large-scale
medical image classification. In this paper, we will discuss these recent
results by highlighting (i) the advancements brought by stochastic non-convex
optimization algorithms for DAM; (ii) the promising results on various medical
image classification problems. Then, we will discuss challenges and
opportunities of DAM for medical image classification from three perspectives,
feature learning, large-scale optimization, and learning trustworthy AI models.",2021-11-01,2021,2021-11,medical
"Transparency of Deep Neural Networks for Medical Image Analysis: A
  Review of Interpretability Methods","Artificial Intelligence has emerged as a useful aid in numerous clinical
applications for diagnosis and treatment decisions. Deep neural networks have
shown same or better performance than clinicians in many tasks owing to the
rapid increase in the available data and computational power. In order to
conform to the principles of trustworthy AI, it is essential that the AI system
be transparent, robust, fair and ensure accountability. Current deep neural
solutions are referred to as black-boxes due to a lack of understanding of the
specifics concerning the decision making process. Therefore, there is a need to
ensure interpretability of deep neural networks before they can be incorporated
in the routine clinical workflow. In this narrative review, we utilized
systematic keyword searches and domain expertise to identify nine different
types of interpretability methods that have been used for understanding deep
learning models for medical image analysis applications based on the type of
generated explanations and technical similarities. Furthermore, we report the
progress made towards evaluating the explanations produced by various
interpretability methods. Finally we discuss limitations, provide guidelines
for using interpretability methods and future directions concerning the
interpretability of deep neural networks for medical imaging analysis.",2021-11-01,2021,2021-11,medical
"Artificial Intelligence Technology analysis using Artificial
  Intelligence patent through Deep Learning model and vector space model","Thanks to rapid development of artificial intelligence technology in recent
years, the current artificial intelligence technology is contributing to many
part of society. Education, environment, medical care, military, tourism,
economy, politics, etc. are having a very large impact on society as a whole.
For example, in the field of education, there is an artificial intelligence
tutoring system that automatically assigns tutors based on student's level. In
the field of economics, there are quantitative investment methods that
automatically analyze large amounts of data to find investment laws to create
investment models or predict changes in financial markets. As such, artificial
intelligence technology is being used in various fields. So, it is very
important to know exactly what factors have an important influence on each
field of artificial intelligence technology and how the relationship between
each field is connected. Therefore, it is necessary to analyze artificial
intelligence technology in each field. In this paper, we analyze patent
documents related to artificial intelligence technology. We propose a method
for keyword analysis within factors using artificial intelligence patent data
sets for artificial intelligence technology analysis. This is a model that
relies on feature engineering based on deep learning model named KeyBERT, and
using vector space model. A case study of collecting and analyzing artificial
intelligence patent data was conducted to show how the proposed model can be
applied to real world problems.",2021-11-08,2021,2021-11,medical
JaMIE: A Pipeline Japanese Medical Information Extraction System,"We present an open-access natural language processing toolkit for Japanese
medical information extraction. We first propose a novel relation annotation
schema for investigating the medical and temporal relations between medical
entities in Japanese medical reports. We experiment with the practical
annotation scenarios by separately annotating two different types of reports.
We design a pipeline system with three components for recognizing medical
entities, classifying entity modalities, and extracting relations. The
empirical results show accurate analyzing performance and suggest the
satisfactory annotation quality, the effective annotation strategy for
targeting report types, and the superiority of the latest contextual embedding
models.",2021-11-08,2021,2021-11,medical
Auto-Encoding Knowledge Graph for Unsupervised Medical Report Generation,"Medical report generation, which aims to automatically generate a long and
coherent report of a given medical image, has been receiving growing research
interests. Existing approaches mainly adopt a supervised manner and heavily
rely on coupled image-report pairs. However, in the medical domain, building a
large-scale image-report paired dataset is both time-consuming and expensive.
To relax the dependency on paired data, we propose an unsupervised model
Knowledge Graph Auto-Encoder (KGAE) which accepts independent sets of images
and reports in training. KGAE consists of a pre-constructed knowledge graph, a
knowledge-driven encoder and a knowledge-driven decoder. The knowledge graph
works as the shared latent space to bridge the visual and textual domains; The
knowledge-driven encoder projects medical images and reports to the
corresponding coordinates in this latent space and the knowledge-driven decoder
generates a medical report given a coordinate in this space. Since the
knowledge-driven encoder and decoder can be trained with independent sets of
images and reports, KGAE is unsupervised. The experiments show that the
unsupervised KGAE generates desirable medical reports without using any
image-report training pairs. Moreover, KGAE can also work in both
semi-supervised and supervised settings, and accept paired images and reports
in training. By further fine-tuning with image-report pairs, KGAE consistently
outperforms the current state-of-the-art models on two datasets.",2021-11-08,2021,2021-11,medical
"Measuring Outcomes in Healthcare Economics using Artificial
  Intelligence: with Application to Resource Management","The quality of service in healthcare is constantly challenged by outlier
events such as pandemics (i.e. Covid-19) and natural disasters (such as
hurricanes and earthquakes). In most cases, such events lead to critical
uncertainties in decision making, as well as in multiple medical and economic
aspects at a hospital. External (geographic) or internal factors (medical and
managerial), lead to shifts in planning and budgeting, but most importantly,
reduces confidence in conventional processes. In some cases, support from other
hospitals proves necessary, which exacerbates the planning aspect. This
manuscript presents three data-driven methods that provide data-driven
indicators to help healthcare managers organize their economics and identify
the most optimum plan for resources allocation and sharing. Conventional
decision-making methods fall short in recommending validated policies for
managers. Using reinforcement learning, genetic algorithms, traveling salesman,
and clustering, we experimented with different healthcare variables and
presented tools and outcomes that could be applied at health institutes.
Experiments are performed; the results are recorded, evaluated, and presented.",2021-11-15,2021,2021-11,medical
"Interactive Medical Image Segmentation with Self-Adaptive Confidence
  Calibration","Medical image segmentation is one of the fundamental problems for artificial
intelligence-based clinical decision systems. Current automatic medical image
segmentation methods are often failed to meet clinical requirements. As such, a
series of interactive segmentation algorithms are proposed to utilize expert
correction information. However, existing methods suffer from some segmentation
refining failure problems after long-term interactions and some cost problems
from expert annotation, which hinder clinical applications. This paper proposes
an interactive segmentation framework, called interactive MEdical segmentation
with self-adaptive Confidence CAlibration (MECCA), by introducing the
corrective action evaluation, which combines the action-based confidence
learning and multi-agent reinforcement learning (MARL). The evaluation is
established through a novel action-based confidence network, and the corrective
actions are obtained from MARL. Based on the confidential information, a
self-adaptive reward function is designed to provide more detailed feedback,
and a simulated label generation mechanism is proposed on unsupervised data to
reduce over-reliance on labeled data. Experimental results on various medical
image datasets have shown the significant performance of the proposed
algorithm.",2021-11-15,2021,2021-11,medical
"MEDCOD: A Medically-Accurate, Emotive, Diverse, and Controllable Dialog
  System","We present MEDCOD, a Medically-Accurate, Emotive, Diverse, and Controllable
Dialog system with a unique approach to the natural language generator module.
MEDCOD has been developed and evaluated specifically for the history taking
task. It integrates the advantage of a traditional modular approach to
incorporate (medical) domain knowledge with modern deep learning techniques to
generate flexible, human-like natural language expressions. Two key aspects of
MEDCOD's natural language output are described in detail. First, the generated
sentences are emotive and empathetic, similar to how a doctor would communicate
to the patient. Second, the generated sentence structures and phrasings are
varied and diverse while maintaining medical consistency with the desired
medical concept (provided by the dialogue manager module of MEDCOD).
Experimental results demonstrate the effectiveness of our approach in creating
a human-like medical dialogue system. Relevant code is available at
https://github.com/curai/curai-research/tree/main/MEDCOD",2021-11-17,2021,2021-11,medical
The Prominence of Artificial Intelligence in COVID-19,"In December 2019, a novel virus called COVID-19 had caused an enormous number
of causalities to date. The battle with the novel Coronavirus is baffling and
horrifying after the Spanish Flu 2019. While the front-line doctors and medical
researchers have made significant progress in controlling the spread of the
highly contiguous virus, technology has also proved its significance in the
battle. Moreover, Artificial Intelligence has been adopted in many medical
applications to diagnose many diseases, even baffling experienced doctors.
Therefore, this survey paper explores the methodologies proposed that can aid
doctors and researchers in early and inexpensive methods of diagnosis of the
disease. Most developing countries have difficulties carrying out tests using
the conventional manner, but a significant way can be adopted with Machine and
Deep Learning. On the other hand, the access to different types of medical
images has motivated the researchers. As a result, a mammoth number of
techniques are proposed. This paper first details the background knowledge of
the conventional methods in the Artificial Intelligence domain. Following that,
we gather the commonly used datasets and their use cases to date. In addition,
we also show the percentage of researchers adopting Machine Learning over Deep
Learning. Thus we provide a thorough analysis of this scenario. Lastly, in the
research challenges, we elaborate on the problems faced in COVID-19 research,
and we address the issues with our understanding to build a bright and healthy
environment.",2021-11-18,2021,2021-11,medical
Medical Visual Question Answering: A Survey,"Medical Visual Question Answering~(VQA) is a combination of medical
artificial intelligence and popular VQA challenges. Given a medical image and a
clinically relevant question in natural language, the medical VQA system is
expected to predict a plausible and convincing answer. Although the
general-domain VQA has been extensively studied, the medical VQA still needs
specific investigation and exploration due to its task features. In the first
part of this survey, we collect and discuss the publicly available medical VQA
datasets up-to-date about the data source, data quantity, and task feature. In
the second part, we review the approaches used in medical VQA tasks. We
summarize and discuss their techniques, innovations, and potential
improvements. In the last part, we analyze some medical-specific challenges for
the field and discuss future research directions. Our goal is to provide
comprehensive and helpful information for researchers interested in the medical
visual question answering field and encourage them to conduct further research
in this field.",2021-11-19,2021,2021-11,medical
"Improving Predictions of Tail-end Labels using Concatenated
  BioMed-Transformers for Long Medical Documents","Multi-label learning predicts a subset of labels from a given label set for
an unseen instance while considering label correlations. A known challenge with
multi-label classification is the long-tailed distribution of labels. Many
studies focus on improving the overall predictions of the model and thus do not
prioritise tail-end labels. Improving the tail-end label predictions in
multi-label classifications of medical text enables the potential to understand
patients better and improve care. The knowledge gained by one or more
infrequent labels can impact the cause of medical decisions and treatment
plans. This research presents variations of concatenated domain-specific
language models, including multi-BioMed-Transformers, to achieve two primary
goals. First, to improve F1 scores of infrequent labels across multi-label
problems, especially with long-tail labels; second, to handle long medical text
and multi-sourced electronic health records (EHRs), a challenging task for
standard transformers designed to work on short input sequences. A vital
contribution of this research is new state-of-the-art (SOTA) results obtained
using TransformerXL for predicting medical codes. A variety of experiments are
performed on the Medical Information Mart for Intensive Care (MIMIC-III)
database. Results show that concatenated BioMed-Transformers outperform
standard transformers in terms of overall micro and macro F1 scores and
individual F1 scores of tail-end labels, while incurring lower training times
than existing transformer-based solutions for long input sequences.",2021-12-03,2021,2021-12,medical
"ASC-Net: Unsupervised Medical Anomaly Segmentation Using an
  Adversarial-based Selective Cutting Network","In this paper we consider the problem of unsupervised anomaly segmentation in
medical images, which has attracted increasing attention in recent years due to
the expensive pixel-level annotations from experts and the existence of a large
amount of unannotated normal and abnormal image scans. We introduce a
segmentation network that utilizes adversarial learning to partition an image
into two cuts, with one of them falling into a reference distribution provided
by the user. This Adversarial-based Selective Cutting network (ASC-Net) bridges
the two domains of cluster-based deep segmentation and adversarial-based
anomaly/novelty detection algorithms. Our ASC-Net learns from normal and
abnormal medical scans to segment anomalies in medical scans without any masks
for supervision. We evaluate this unsupervised anomly segmentation model on
three public datasets, i.e., BraTS 2019 for brain tumor segmentation, LiTS for
liver lesion segmentation, and MS-SEG 2015 for brain lesion segmentation, and
also on a private dataset for brain tumor segmentation. Compared to existing
methods, our model demonstrates tremendous performance gains in unsupervised
anomaly segmentation tasks. Although there is still room to further improve
performance compared to supervised learning algorithms, the promising
experimental results and interesting observations shed light on building an
unsupervised learning algorithm for medical anomaly identification using
user-defined knowledge.",2021-12-16,2021,2021-12,medical
Towards a Shapley Value Graph Framework for Medical peer-influence,"eXplainable Artificial Intelligence (XAI) is a sub-field of Artificial
Intelligence (AI) that is at the forefront of AI research. In XAI, feature
attribution methods produce explanations in the form of feature importance.
People often use feature importance as guidance for intervention. However, a
limitation of existing feature attribution methods is that there is a lack of
explanation towards the consequence of intervention. In other words, although
contribution towards a certain prediction is highlighted by feature attribution
methods, the relation between features and the consequence of intervention is
not studied. The aim of this paper is to introduce a new framework, called a
peer influence framework to look deeper into explanations using graph
representation for feature-to-feature interactions to improve the
interpretability of black-box Machine Learning models and inform intervention.",2021-12-29,2021,2021-12,medical
"Machine Learning: Algorithms, Models, and Applications","Recent times are witnessing rapid development in machine learning algorithm
systems, especially in reinforcement learning, natural language processing,
computer and robot vision, image processing, speech, and emotional processing
and understanding. In tune with the increasing importance and relevance of
machine learning models, algorithms, and their applications, and with the
emergence of more innovative uses cases of deep learning and artificial
intelligence, the current volume presents a few innovative research works and
their applications in real world, such as stock trading, medical and healthcare
systems, and software automation. The chapters in the book illustrate how
machine learning and deep learning algorithms and models are designed,
optimized, and deployed. The volume will be useful for advanced graduate and
doctoral students, researchers, faculty members of universities, practicing
data scientists and data engineers, professionals, and consultants working on
the broad areas of machine learning, deep learning, and artificial
intelligence.",2022-01-06,2022,2022-01,medical
"Get your Foes Fooled: Proximal Gradient Split Learning for Defense
  against Model Inversion Attacks on IoMT data","The past decade has seen a rapid adoption of Artificial Intelligence (AI),
specifically the deep learning networks, in Internet of Medical Things (IoMT)
ecosystem. However, it has been shown recently that the deep learning networks
can be exploited by adversarial attacks that not only make IoMT vulnerable to
the data theft but also to the manipulation of medical diagnosis. The existing
studies consider adding noise to the raw IoMT data or model parameters which
not only reduces the overall performance concerning medical inferences but also
is ineffective to the likes of deep leakage from gradients method. In this
work, we propose proximal gradient split learning (PSGL) method for defense
against the model inversion attacks. The proposed method intentionally attacks
the IoMT data when undergoing the deep neural network training process at
client side. We propose the use of proximal gradient method to recover gradient
maps and a decision-level fusion strategy to improve the recognition
performance. Extensive analysis show that the PGSL not only provides effective
defense mechanism against the model inversion attacks but also helps in
improving the recognition performance on publicly available datasets. We report
14.0$\%$, 17.9$\%$, and 36.9$\%$ gains in accuracy over reconstructed and
adversarial attacked images, respectively.",2022-01-12,2022,2022-01,medical
"Artificial Intelligence in Software Testing : Impact, Problems,
  Challenges and Prospect","Artificial Intelligence (AI) is making a significant impact in multiple areas
like medical, military, industrial, domestic, law, arts as AI is capable to
perform several roles such as managing smart factories, driving autonomous
vehicles, creating accurate weather forecasts, detecting cancer and personal
assistants, etc. Software testing is the process of putting the software to
test for some abnormal behaviour of the software. Software testing is a
tedious, laborious and most time-consuming process. Automation tools have been
developed that help to automate some activities of the testing process to
enhance quality and timely delivery. Over time with the inclusion of continuous
integration and continuous delivery (CI/CD) pipeline, automation tools are
becoming less effective. The testing community is turning to AI to fill the gap
as AI is able to check the code for bugs and errors without any human
intervention and in a much faster way than humans. In this study, we aim to
recognize the impact of AI technologies on various software testing activities
or facets in the STLC. Further, the study aims to recognize and explain some of
the biggest challenges software testers face while applying AI to testing. The
paper also proposes some key contributions of AI in the future to the domain of
software testing.",2022-01-14,2022,2022-01,medical
RuMedBench: A Russian Medical Language Understanding Benchmark,"The paper describes the open Russian medical language understanding benchmark
covering several task types (classification, question answering, natural
language inference, named entity recognition) on a number of novel text sets.
Given the sensitive nature of the data in healthcare, such a benchmark
partially closes the problem of Russian medical dataset absence. We prepare the
unified format labeling, data split, and evaluation metrics for new tasks. The
remaining tasks are from existing datasets with a few modifications. A
single-number metric expresses a model's ability to cope with the benchmark.
Moreover, we implement several baseline models, from simple ones to neural
networks with transformer architecture, and release the code. Expectedly, the
more advanced models yield better performance, but even a simple model is
enough for a decent result in some tasks. Furthermore, for all tasks, we
provide a human evaluation. Interestingly the models outperform humans in the
large-scale classification tasks. However, the advantage of natural
intelligence remains in the tasks requiring more knowledge and reasoning.",2022-01-17,2022,2022-01,medical
"Label-dependent and event-guided interpretable disease risk prediction
  using EHRs","Electronic health records (EHRs) contain patients' heterogeneous data that
are collected from medical providers involved in the patient's care, including
medical notes, clinical events, laboratory test results, symptoms, and
diagnoses. In the field of modern healthcare, predicting whether patients would
experience any risks based on their EHRs has emerged as a promising research
area, in which artificial intelligence (AI) plays a key role. To make AI models
practically applicable, it is required that the prediction results should be
both accurate and interpretable. To achieve this goal, this paper proposed a
label-dependent and event-guided risk prediction model (LERP) to predict the
presence of multiple disease risks by mainly extracting information from
unstructured medical notes. Our model is featured in the following aspects.
First, we adopt a label-dependent mechanism that gives greater attention to
words from medical notes that are semantically similar to the names of risk
labels. Secondly, as the clinical events (e.g., treatments and drugs) can also
indicate the health status of patients, our model utilizes the information from
events and uses them to generate an event-guided representation of medical
notes. Thirdly, both label-dependent and event-guided representations are
integrated to make a robust prediction, in which the interpretability is
enabled by the attention weights over words from medical notes. To demonstrate
the applicability of the proposed method, we apply it to the MIMIC-III dataset,
which contains real-world EHRs collected from hospitals. Our method is
evaluated in both quantitative and qualitative ways.",2022-01-18,2022,2022-01,medical
"Benchmark datasets driving artificial intelligence development fail to
  capture the needs of medical professionals","Publicly accessible benchmarks that allow for assessing and comparing model
performances are important drivers of progress in artificial intelligence (AI).
While recent advances in AI capabilities hold the potential to transform
medical practice by assisting and augmenting the cognitive processes of
healthcare professionals, the coverage of clinically relevant tasks by AI
benchmarks is largely unclear. Furthermore, there is a lack of systematized
meta-information that allows clinical AI researchers to quickly determine
accessibility, scope, content and other characteristics of datasets and
benchmark datasets relevant to the clinical domain.
  To address these issues, we curated and released a comprehensive catalogue of
datasets and benchmarks pertaining to the broad domain of clinical and
biomedical natural language processing (NLP), based on a systematic review of
literature and online resources. A total of 450 NLP datasets were manually
systematized and annotated with rich metadata, such as targeted tasks, clinical
applicability, data types, performance metrics, accessibility and licensing
information, and availability of data splits. We then compared tasks covered by
AI benchmark datasets with relevant tasks that medical practitioners reported
as highly desirable targets for automation in a previous empirical study.
  Our analysis indicates that AI benchmarks of direct clinical relevance are
scarce and fail to cover most work activities that clinicians want to see
addressed. In particular, tasks associated with routine documentation and
patient data administration workflows are not represented despite significant
associated workloads. Thus, currently available AI benchmarks are improperly
aligned with desired targets for AI automation in clinical settings, and novel
benchmarks should be created to fill these gaps.",2022-01-18,2022,2022-01,medical
"Label Dependent Attention Model for Disease Risk Prediction Using
  Multimodal Electronic Health Records","Disease risk prediction has attracted increasing attention in the field of
modern healthcare, especially with the latest advances in artificial
intelligence (AI). Electronic health records (EHRs), which contain
heterogeneous patient information, are widely used in disease risk prediction
tasks. One challenge of applying AI models for risk prediction lies in
generating interpretable evidence to support the prediction results while
retaining the prediction ability. In order to address this problem, we propose
the method of jointly embedding words and labels whereby attention modules
learn the weights of words from medical notes according to their relevance to
the names of risk prediction labels. This approach boosts interpretability by
employing an attention mechanism and including the names of prediction tasks in
the model. However, its application is only limited to the handling of textual
inputs such as medical notes. In this paper, we propose a label dependent
attention model LDAM to 1) improve the interpretability by exploiting
Clinical-BERT (a biomedical language model pre-trained on a large clinical
corpus) to encode biomedically meaningful features and labels jointly; 2)
extend the idea of joint embedding to the processing of time-series data, and
develop a multi-modal learning framework for integrating heterogeneous
information from medical notes and time-series health status indicators. To
demonstrate our method, we apply LDAM to the MIMIC-III dataset to predict
different disease risks. We evaluate our method both quantitatively and
qualitatively. Specifically, the predictive power of LDAM will be shown, and
case studies will be carried out to illustrate its interpretability.",2022-01-18,2022,2022-01,medical
"A Cognitive Explainer for Fetal ultrasound images classifier Based on
  Medical Concepts","Fetal standard scan plane detection during 2-D mid-pregnancy examinations is
a highly complex task, which requires extensive medical knowledge and years of
training. Although deep neural networks (DNN) can assist inexperienced
operators in these tasks, their lack of transparency and interpretability limit
their application. Despite some researchers have been committed to visualizing
the decision process of DNN, most of them only focus on the pixel-level
features and do not take into account the medical prior knowledge. In this
work, we propose an interpretable framework based on key medical concepts,
which provides explanations from the perspective of clinicians' cognition.
Moreover, we utilize a concept-based graph convolutional neural(GCN) network to
construct the relationships between key medical concepts. Extensive
experimental analysis on a private dataset has shown that the proposed method
provides easy-to-understand insights about reasoning results for clinicians.",2022-01-19,2022,2022-01,medical
MISeval: a Metric Library for Medical Image Segmentation Evaluation,"Correct performance assessment is crucial for evaluating modern artificial
intelligence algorithms in medicine like deep-learning based medical image
segmentation models. However, there is no universal metric library in Python
for standardized and reproducible evaluation. Thus, we propose our open-source
publicly available Python package MISeval: a metric library for Medical Image
Segmentation Evaluation. The implemented metrics can be intuitively used and
easily integrated into any performance assessment pipeline. The package
utilizes modern CI/CD strategies to ensure functionality and stability. MISeval
is available from PyPI (miseval) and GitHub:
https://github.com/frankkramer-lab/miseval.",2022-01-23,2022,2022-01,medical
"Distantly supervised end-to-end medical entity extraction from
  electronic health records with human-level quality","Medical entity extraction (EE) is a standard procedure used as a first stage
in medical texts processing. Usually Medical EE is a two-step process: named
entity recognition (NER) and named entity normalization (NEN). We propose a
novel method of doing medical EE from electronic health records (EHR) as a
single-step multi-label classification task by fine-tuning a transformer model
pretrained on a large EHR dataset. Our model is trained end-to-end in an
distantly supervised manner using targets automatically extracted from medical
knowledge base. We show that our model learns to generalize for entities that
are present frequently enough, achieving human-level classification quality for
most frequent entities. Our work demonstrates that medical entity extraction
can be done end-to-end without human supervision and with human quality given
the availability of a large enough amount of unlabeled EHR and a medical
knowledge base.",2022-01-25,2022,2022-01,medical
"An Analysis on Ensemble Learning optimized Medical Image Classification
  with Deep Convolutional Neural Networks","Novel and high-performance medical image classification pipelines are heavily
utilizing ensemble learning strategies. The idea of ensemble learning is to
assemble diverse models or multiple predictions and, thus, boost prediction
performance. However, it is still an open question to what extent as well as
which ensemble learning strategies are beneficial in deep learning based
medical image classification pipelines. In this work, we proposed a
reproducible medical image classification pipeline for analyzing the
performance impact of the following ensemble learning techniques: Augmenting,
Stacking, and Bagging. The pipeline consists of state-of-the-art preprocessing
and image augmentation methods as well as 9 deep convolution neural network
architectures. It was applied on four popular medical imaging datasets with
varying complexity. Furthermore, 12 pooling functions for combining multiple
predictions were analyzed, ranging from simple statistical functions like
unweighted averaging up to more complex learning-based functions like support
vector machines. Our results revealed that Stacking achieved the largest
performance gain of up to 13% F1-score increase. Augmenting showed consistent
improvement capabilities by up to 4% and is also applicable to single model
based pipelines. Cross-validation based Bagging demonstrated significant
performance gain close to Stacking, which resulted in an F1-score increase up
to +11%. Furthermore, we demonstrated that simple statistical pooling functions
are equal or often even better than more complex pooling functions. We
concluded that the integration of ensemble learning techniques is a powerful
method for any medical image classification pipeline to improve robustness and
boost performance.",2022-01-27,2022,2022-01,medical
"A Knowledge-Based Decision Support System for In Vitro Fertilization
  Treatment","In Vitro Fertilization (IVF) is the most widely used Assisted Reproductive
Technology (ART). IVF usually involves controlled ovarian stimulation, oocyte
retrieval, fertilization in the laboratory with subsequent embryo transfer. The
first two steps correspond with follicular phase of females and ovulation in
their menstrual cycle. Therefore, we refer to it as the treatment cycle in our
paper. The treatment cycle is crucial because the stimulation medications in
IVF treatment are applied directly on patients. In order to optimize the
stimulation effects and lower the side effects of the stimulation medications,
prompt treatment adjustments are in need. In addition, the quality and quantity
of the retrieved oocytes have a significant effect on the outcome of the
following procedures. To improve the IVF success rate, we propose a
knowledge-based decision support system that can provide medical advice on the
treatment protocol and medication adjustment for each patient visit during IVF
treatment cycle. Our system is efficient in data processing and light-weighted
which can be easily embedded into electronic medical record systems. Moreover,
an oocyte retrieval oriented evaluation demonstrates that our system performs
well in terms of accuracy of advice for the protocols and medications.",2022-01-27,2022,2022-01,medical
Research on Question Classification Methods in the Medical Field,"Question classification is one of the important links in the research of
question and answering system. The existing question classification models are
more trained on public data sets. At present, there is a lack of question
classification data sets in specific fields, especially in the medical field.
To make up for this gap, this paper presents a data set for question
classification in the medical field. Moreover, this paper proposes a
multi-dimensional extraction of the characteristics of the question by
combining multiple neural network models, and proposes a question
classification model based on multi-dimensional feature extraction. The
experimental results show that the proposed method can effectively improve the
performance of question classification.",2022-02-01,2022,2022-02,medical
Analyzing Medical Data with Process Mining: a COVID-19 Case Study,"The recent increase in the availability of medical data, possible through
automation and digitization of medical equipment, has enabled more accurate and
complete analysis on patients' medical data through many branches of data
science. In particular, medical records that include timestamps showing the
history of a patient have enabled the representation of medical information as
sequences of events, effectively allowing to perform process mining analyses.
In this paper, we will present some preliminary findings obtained with
established process mining techniques in regard of the medical data of patients
of the Uniklinik Aachen hospital affected by the recent epidemic of COVID-19.
We show that process mining techniques are able to reconstruct a model of the
ICU treatments for COVID patients.",2022-02-08,2022,2022-02,medical
Towards a Guideline for Evaluation Metrics in Medical Image Segmentation,"In the last decade, research on artificial intelligence has seen rapid growth
with deep learning models, especially in the field of medical image
segmentation. Various studies demonstrated that these models have powerful
prediction capabilities and achieved similar results as clinicians. However,
recent studies revealed that the evaluation in image segmentation studies lacks
reliable model performance assessment and showed statistical bias by incorrect
metric implementation or usage. Thus, this work provides an overview and
interpretation guide on the following metrics for medical image segmentation
evaluation in binary as well as multi-class problems: Dice similarity
coefficient, Jaccard, Sensitivity, Specificity, Rand index, ROC curves, Cohen's
Kappa, and Hausdorff distance. As a summary, we propose a guideline for
standardized medical image segmentation evaluation to improve evaluation
quality, reproducibility, and comparability in the research field.",2022-02-10,2022,2022-02,medical
"Guidelines and Evaluation of Clinical Explainable AI in Medical Image
  Analysis","Explainable artificial intelligence (XAI) is essential for enabling clinical
users to get informed decision support from AI and comply with evidence-based
medical practice. Applying XAI in clinical settings requires proper evaluation
criteria to ensure the explanation technique is both technically sound and
clinically useful, but specific support is lacking to achieve this goal. To
bridge the research gap, we propose the Clinical XAI Guidelines that consist of
five criteria a clinical XAI needs to be optimized for. The guidelines
recommend choosing an explanation form based on Guideline 1 (G1)
Understandability and G2 Clinical relevance. For the chosen explanation form,
its specific XAI technique should be optimized for G3 Truthfulness, G4
Informative plausibility, and G5 Computational efficiency. Following the
guidelines, we conducted a systematic evaluation on a novel problem of
multi-modal medical image explanation with two clinical tasks, and proposed new
evaluation metrics accordingly. Sixteen commonly-used heatmap XAI techniques
were evaluated and found to be insufficient for clinical use due to their
failure in G3 and G4. Our evaluation demonstrated the use of Clinical XAI
Guidelines to support the design and evaluation of clinically viable XAI.",2022-02-16,2022,2022-02,medical
"Graph Convolutional Networks for Multi-modality Medical Imaging:
  Methods, Architectures, and Clinical Applications","Image-based characterization and disease understanding involve integrative
analysis of morphological, spatial, and topological information across
biological scales. The development of graph convolutional networks (GCNs) has
created the opportunity to address this information complexity via graph-driven
architectures, since GCNs can perform feature aggregation, interaction, and
reasoning with remarkable flexibility and efficiency. These GCNs capabilities
have spawned a new wave of research in medical imaging analysis with the
overarching goal of improving quantitative disease understanding, monitoring,
and diagnosis. Yet daunting challenges remain for designing the important
image-to-graph transformation for multi-modality medical imaging and gaining
insights into model interpretation and enhanced clinical decision support. In
this review, we present recent GCNs developments in the context of medical
image analysis including imaging data from radiology and histopathology. We
discuss the fast-growing use of graph network architectures in medical image
analysis to improve disease diagnosis and patient outcomes in clinical
practice. To foster cross-disciplinary research, we present GCNs technical
advancements, emerging medical applications, identify common challenges in the
use of image-based GCNs and their extensions in model interpretation,
large-scale benchmarks that promise to transform the scope of medical image
studies and related graph-driven medical research.",2022-02-17,2022,2022-02,medical
DialMed: A Dataset for Dialogue-based Medication Recommendation,"Medication recommendation is a crucial task for intelligent healthcare
systems. Previous studies mainly recommend medications with electronic health
records (EHRs). However, some details of interactions between doctors and
patients may be ignored or omitted in EHRs, which are essential for automatic
medication recommendation. Therefore, we make the first attempt to recommend
medications with the conversations between doctors and patients. In this work,
we construct DIALMED, the first high-quality dataset for medical dialogue-based
medication recommendation task. It contains 11,996 medical dialogues related to
16 common diseases from 3 departments and 70 corresponding common medications.
Furthermore, we propose a Dialogue structure and Disease knowledge aware
Network (DDN), where a QA Dialogue Graph mechanism is designed to model the
dialogue structure and the knowledge graph is used to introduce external
disease knowledge. The extensive experimental results demonstrate that the
proposed method is a promising solution to recommend medications with medical
dialogues. The dataset and code are available at
https://github.com/f-window/DialMed.",2022-02-22,2022,2022-02,medical
Application of DatasetGAN in medical imaging: preliminary studies,"Generative adversarial networks (GANs) have been widely investigated for many
potential applications in medical imaging. DatasetGAN is a recently proposed
framework based on modern GANs that can synthesize high-quality segmented
images while requiring only a small set of annotated training images. The
synthesized annotated images could be potentially employed for many medical
imaging applications, where images with segmentation information are required.
However, to the best of our knowledge, there are no published studies focusing
on its applications to medical imaging. In this work, preliminary studies were
conducted to investigate the utility of DatasetGAN in medical imaging. Three
improvements were proposed to the original DatasetGAN framework, considering
the unique characteristics of medical images. The synthesized segmented images
by DatasetGAN were visually evaluated. The trained DatasetGAN was further
analyzed by evaluating the performance of a pre-defined image segmentation
technique, which was trained by the use of the synthesized datasets. The
effectiveness, concerns, and potential usage of DatasetGAN were discussed.",2022-02-27,2022,2022-02,medical
Hierarchical BERT for Medical Document Understanding,"Medical document understanding has gained much attention recently. One
representative task is the International Classification of Disease (ICD)
diagnosis code assignment. Existing work adopts either RNN or CNN as the
backbone network because the vanilla BERT cannot handle well long documents
(>2000 to kens). One issue shared across all these approaches is that they are
over specific to the ICD code assignment task, losing generality to give the
whole document-level and sentence-level embedding. As a result, it is not
straight-forward to direct them to other downstream NLU tasks. Motivated by
these observations, we propose Medical Document BERT (MDBERT) for long medical
document understanding tasks. MDBERT is not only effective in learning
representations at different levels of semantics but efficient in encoding long
documents by leveraging a bottom-up hierarchical architecture. Compared to
vanilla BERT solutions: 1, MDBERT boosts the performance up to relatively 20%
on the MIMIC-III dataset, making it comparable to current SOTA solutions; 2, it
cuts the computational complexity on self-attention modules to less than 1/100.
Other than the ICD code assignment, we conduct a variety of other NLU tasks on
a large commercial dataset named as TrialTrove, to showcase MDBERT's strength
in delivering different levels of semantics.",2022-03-11,2022,2022-03,medical
"Evaluating Explainable AI on a Multi-Modal Medical Imaging Task: Can
  Existing Algorithms Fulfill Clinical Requirements?","Being able to explain the prediction to clinical end-users is a necessity to
leverage the power of artificial intelligence (AI) models for clinical decision
support. For medical images, a feature attribution map, or heatmap, is the most
common form of explanation that highlights important features for AI models'
prediction. However, it is unknown how well heatmaps perform on explaining
decisions on multi-modal medical images, where each image modality or channel
visualizes distinct clinical information of the same underlying biomedical
phenomenon. Understanding such modality-dependent features is essential for
clinical users' interpretation of AI decisions. To tackle this clinically
important but technically ignored problem, we propose the modality-specific
feature importance (MSFI) metric. It encodes clinical image and explanation
interpretation patterns of modality prioritization and modality-specific
feature localization. We conduct a clinical requirement-grounded, systematic
evaluation using computational methods and a clinician user study. Results show
that the examined 16 heatmap algorithms failed to fulfill clinical requirements
to correctly indicate AI model decision process or decision quality. The
evaluation and MSFI metric can guide the design and selection of XAI algorithms
to meet clinical requirements on multi-modal explanation.",2022-03-12,2022,2022-03,medical
"Review of Disentanglement Approaches for Medical Applications -- Towards
  Solving the Gordian Knot of Generative Models in Healthcare","Deep neural networks are commonly used for medical purposes such as image
generation, segmentation, or classification. Besides this, they are often
criticized as black boxes as their decision process is often not human
interpretable. Encouraging the latent representation of a generative model to
be disentangled offers new perspectives of control and interpretability.
Understanding the data generation process could help to create artificial
medical data sets without violating patient privacy, synthesizing different
data modalities, or discovering data generating characteristics. These
characteristics might unravel novel relationships that can be related to
genetic traits or patient outcomes. In this paper, we give a comprehensive
overview of popular generative models, like Generative Adversarial Networks
(GANs), Variational Autoencoders (VAEs), and Flow-based Models. Furthermore, we
summarize the different notions of disentanglement, review approaches to
disentangle latent space representations and metrics to evaluate the degree of
disentanglement. After introducing the theoretical frameworks, we give an
overview of recent medical applications and discuss the impact and importance
of disentanglement approaches for medical applications.",2022-03-21,2022,2022-03,medical
"Visual explanations for polyp detection: How medical doctors assess
  intrinsic versus extrinsic explanations","Deep learning has in recent years achieved immense success in all areas of
computer vision and has the potential of assisting medical doctors in analyzing
visual content for disease and other abnormalities. However, the current state
of deep learning is very much a black box, making medical professionals highly
skeptical about integrating these methods into clinical practice. Several
methods have been proposed in order to shine some light onto these black boxes,
but there is no consensus on the opinion of the medical doctors that will
consume these explanations. This paper presents a study asking medical doctors
about their opinion of current state-of-the-art explainable artificial
intelligence methods when applied to a gastrointestinal disease detection use
case. We compare two different categories of explanation methods, intrinsic and
extrinsic, and gauge their opinion of the current value of these explanations.
The results indicate that intrinsic explanations are preferred and that
explanation.",2022-03-23,2022,2022-03,medical
"MedMCQA : A Large-scale Multi-Subject Multi-Choice Dataset for Medical
  domain Question Answering","This paper introduces MedMCQA, a new large-scale, Multiple-Choice Question
Answering (MCQA) dataset designed to address real-world medical entrance exam
questions. More than 194k high-quality AIIMS \& NEET PG entrance exam MCQs
covering 2.4k healthcare topics and 21 medical subjects are collected with an
average token length of 12.77 and high topical diversity. Each sample contains
a question, correct answer(s), and other options which requires a deeper
language understanding as it tests the 10+ reasoning abilities of a model
across a wide range of medical subjects \& topics. A detailed explanation of
the solution, along with the above information, is provided in this study.",2022-03-27,2022,2022-03,medical
"Access to care: analysis of the geographical distribution of healthcare
  using Linked Open Data","Background: Access to medical care is strongly dependent on resource
allocation, such as the geographical distribution of medical facilities.
Nevertheless, this data is usually restricted to country official
documentation, not available to the public. While some medical facilities' data
is accessible as semantic resources on the Web, it is not consistent in its
modeling and has yet to be integrated into a complete, open, and specialized
repository. This work focuses on generating a comprehensive semantic dataset of
medical facilities worldwide containing extensive information about such
facilities' geo-location.
  Results: For this purpose, we collect, align, and link various open-source
databases where medical facilities' information may be present. This work
allows us to evaluate each data source along various dimensions, such as
completeness, correctness, and interlinking with other sources, all critical
aspects of current knowledge representation technologies.
  Conclusions: Our contributions directly benefit stakeholders in the
biomedical and health domain (patients, healthcare professionals, companies,
regulatory authorities, and researchers), who will now have a better overview
of the access to and distribution of medical facilities.",2022-04-11,2022,2022-04,medical
"Optimally Designing Cybersecurity Insurance Contracts to Encourage the
  Sharing of Medical Data","Though the sharing of medical data has the potential to lead to breakthroughs
in health care, the sharing process itself exposes patients and health care
providers to various risks. Patients face risks due to the possible loss in
privacy or livelihood that can occur when medical data is stolen or used in
non-permitted ways, whereas health care providers face risks due to the
associated liability. For medical data, these risks persist even after
anonymizing/deidentifying, according to the standards defined in existing
legislation, the data sets prior to sharing, because shared medical data can
often be deanonymized/reidentified using advanced artificial intelligence and
machine learning methodologies. As a result, health care providers are hesitant
to share medical data. One possible solution to encourage health care providers
to responsibly share data is through the use of cybersecurity insurance
contracts. This paper studies the problem of designing optimal cybersecurity
insurance contracts, with the goal of encouraging the sharing of the medical
data. We use a principal-agent model with moral hazard to model various
scenarios, derive the optimal contract, discuss its implications, and perform
numerical case studies. In particular, we consider two scenarios: the first
scenario is where a health care provider is selling medical data to a
technology firm who is developing an artificial intelligence algorithm using
the shared data. The second scenario is where a group of health care providers
share health data amongst themselves for the purpose of furthering medical
research using the aggregated medical data.",2022-04-13,2022,2022-04,medical
"IOP-FL: Inside-Outside Personalization for Federated Medical Image
  Segmentation","Federated learning (FL) allows multiple medical institutions to
collaboratively learn a global model without centralizing client data. It is
difficult, if possible at all, for such a global model to commonly achieve
optimal performance for each individual client, due to the heterogeneity of
medical images from various scanners and patient demographics. This problem
becomes even more significant when deploying the global model to unseen clients
outside the FL with unseen distributions not presented during federated
training. To optimize the prediction accuracy of each individual client for
medical imaging tasks, we propose a novel unified framework for both
\textit{Inside and Outside model Personalization in FL} (IOP-FL). Our inside
personalization uses a lightweight gradient-based approach that exploits the
local adapted model for each client, by accumulating both the global gradients
for common knowledge and the local gradients for client-specific optimization.
Moreover, and importantly, the obtained local personalized models and the
global model can form a diverse and informative routing space to personalize an
adapted model for outside FL clients. Hence, we design a new test-time routing
scheme using the consistency loss with a shape constraint to dynamically
incorporate the models, given the distribution information conveyed by the test
data. Our extensive experimental results on two medical image segmentation
tasks present significant improvements over SOTA methods on both inside and
outside personalization, demonstrating the potential of our IOP-FL scheme for
clinical practice.",2022-04-16,2022,2022-04,medical
U-Net and its variants for Medical Image Segmentation : A short review,"The paper is a short review of medical image segmentation using U-Net and its
variants. As we understand going through a medical images is not an easy job
for any clinician either radiologist or pathologist. Analysing medical images
is the only way to perform non-invasive diagnosis. Segmenting out the regions
of interest has significant importance in medical images and is key for
diagnosis. This paper also gives a bird eye view of how medical image
segmentation has evolved. Also discusses challenge's and success of the deep
neural architectures. Following how different hybrid architectures have built
upon strong techniques from visual recognition tasks. In the end we will see
current challenges and future directions for medical image segmentation(MIS).",2022-04-17,2022,2022-04,medical
"Factors that influence the adoption of human-AI collaboration in
  clinical decision-making","Recent developments in Artificial Intelligence (AI) have fueled the emergence
of human-AI collaboration, a setting where AI is a coequal partner. Especially
in clinical decision-making, it has the potential to improve treatment quality
by assisting overworked medical professionals. Even though research has started
to investigate the utilization of AI for clinical decision-making, its
potential benefits do not imply its adoption by medical professionals. While
several studies have started to analyze adoption criteria from a technical
perspective, research providing a human-centered perspective with a focus on
AI's potential for becoming a coequal team member in the decision-making
process remains limited. Therefore, in this work, we identify factors for the
adoption of human-AI collaboration by conducting a series of semi-structured
interviews with experts in the healthcare domain. We identify six relevant
adoption factors and highlight existing tensions between them and effective
human-AI collaboration.",2022-04-19,2022,2022-04,medical
"LingYi: Medical Conversational Question Answering System based on
  Multi-modal Knowledge Graphs","The medical conversational system can relieve the burden of doctors and
improve the efficiency of healthcare, especially during the pandemic. This
paper presents a medical conversational question answering (CQA) system based
on the multi-modal knowledge graph, namely ""LingYi"", which is designed as a
pipeline framework to maintain high flexibility. Our system utilizes automated
medical procedures including medical triage, consultation, image-text drug
recommendation and record. To conduct knowledge-grounded dialogues with
patients, we first construct a Chinese Medical Multi-Modal Knowledge Graph
(CM3KG) and collect a large-scale Chinese Medical CQA (CMCQA) dataset. Compared
with the other existing medical question-answering systems, our system adopts
several state-of-the-art technologies including medical entity disambiguation
and medical dialogue generation, which is more friendly to provide medical
services to patients. In addition, we have open-sourced our codes which contain
back-end models and front-end web pages at https://github.com/WENGSYX/LingYi.
The datasets including CM3KG at https://github.com/WENGSYX/CM3KG and CMCQA at
https://github.com/WENGSYX/CMCQA are also released to further promote future
research.",2022-04-20,2022,2022-04,medical
"MedFACT: Modeling Medical Feature Correlations in Patient Health
  Representation Learning via Feature Clustering","In healthcare prediction tasks, it is essential to exploit the correlations
between medical features and learn better patient health representations.
Existing methods try to estimate feature correlations only from data, or
increase the quality of estimation by introducing task-specific medical
knowledge. However, such methods either are difficult to estimate the feature
correlations due to insufficient training samples, or cannot be generalized to
other tasks due to reliance on specific knowledge. There are medical research
revealing that not all the medical features are strongly correlated. Thus, to
address the issues, we expect to group up strongly correlated features and
learn feature correlations in a group-wise manner to reduce the learning
complexity without losing generality. In this paper, we propose a general
patient health representation learning framework MedFACT. We estimate
correlations via measuring similarity between temporal patterns of medical
features with kernel methods, and cluster features with strong correlations
into groups. The feature group is further formulated as a correlation graph,
and we employ graph convolutional networks to conduct group-wise feature
interactions for better representation learning. Experiments on two real-world
datasets demonstrate the superiority of MedFACT. The discovered medical
findings are also confirmed by literature, providing valuable medical insights
and explanations.",2022-04-21,2022,2022-04,medical
"KnowAugNet: Multi-Source Medical Knowledge Augmented Medication
  Prediction Network with Multi-Level Graph Contrastive Learning","Predicting medications is a crucial task in many intelligent healthcare
systems. It can assist doctors in making informed medication decisions for
patients according to electronic medical records (EMRs). However, medication
prediction is a challenging data mining task due to the complex relations
between medical codes. Most existing studies focus on utilizing inherent
relations between homogeneous codes of medical ontology graph to enhance their
representations using supervised methods, and few studies pay attention to the
valuable relations between heterogeneous or homogeneous medical codes from
history EMRs, which further limits the prediction performance and application
scenarios. Therefore, to address these limitations, this paper proposes
KnowAugNet, a multi-sourced medical knowledge augmented medication prediction
network which can fully capture the diverse relations between medical codes via
multi-level graph contrastive learning framework. Specifically, KnowAugNet
first leverages the graph contrastive learning using graph attention network as
the encoder to capture the implicit relations between homogeneous medical codes
from the medical ontology graph and obtains the knowledge augmented medical
codes embedding vectors. Then, it utilizes the graph contrastive learning using
a weighted graph convolutional network as the encoder to capture the
correlative relations between homogeneous or heterogeneous medical codes from
the constructed medical prior relation graph and obtains the relation augmented
medical codes embedding vectors. Finally, the augmented medical codes embedding
vectors and the supervised medical codes embedding vectors are retrieved and
input to the sequential learning network to capture the temporal relations of
medical codes and predict medications for patients.",2022-04-25,2022,2022-04,medical
Masked Image Modeling Advances 3D Medical Image Analysis,"Recently, masked image modeling (MIM) has gained considerable attention due
to its capacity to learn from vast amounts of unlabeled data and has been
demonstrated to be effective on a wide variety of vision tasks involving
natural images. Meanwhile, the potential of self-supervised learning in
modeling 3D medical images is anticipated to be immense due to the high
quantities of unlabeled images, and the expense and difficulty of quality
labels. However, MIM's applicability to medical images remains uncertain. In
this paper, we demonstrate that masked image modeling approaches can also
advance 3D medical images analysis in addition to natural images. We study how
masked image modeling strategies leverage performance from the viewpoints of 3D
medical image segmentation as a representative downstream task: i) when
compared to naive contrastive learning, masked image modeling approaches
accelerate the convergence of supervised training even faster (1.40$\times$)
and ultimately produce a higher dice score; ii) predicting raw voxel values
with a high masking ratio and a relatively smaller patch size is non-trivial
self-supervised pretext-task for medical images modeling; iii) a lightweight
decoder or projection head design for reconstruction is powerful for masked
image modeling on 3D medical images which speeds up training and reduce cost;
iv) finally, we also investigate the effectiveness of MIM methods under
different practical scenarios where different image resolutions and labeled
data ratios are applied.",2022-04-25,2022,2022-04,medical
"A survey on attention mechanisms for medical applications: are we moving
  towards better algorithms?","The increasing popularity of attention mechanisms in deep learning algorithms
for computer vision and natural language processing made these models
attractive to other research domains. In healthcare, there is a strong need for
tools that may improve the routines of the clinicians and the patients.
Naturally, the use of attention-based algorithms for medical applications
occurred smoothly. However, being healthcare a domain that depends on
high-stake decisions, the scientific community must ponder if these
high-performing algorithms fit the needs of medical applications. With this
motto, this paper extensively reviews the use of attention mechanisms in
machine learning (including Transformers) for several medical applications.
This work distinguishes itself from its predecessors by proposing a critical
analysis of the claims and potentialities of attention mechanisms presented in
the literature through an experimental case study on medical image
classification with three different use cases. These experiments focus on the
integrating process of attention mechanisms into established deep learning
architectures, the analysis of their predictive power, and a visual assessment
of their saliency maps generated by post-hoc explanation methods. This paper
concludes with a critical analysis of the claims and potentialities presented
in the literature about attention mechanisms and proposes future research lines
in medical applications that may benefit from these frameworks.",2022-04-26,2022,2022-04,medical
"CATNet: Cross-event Attention-based Time-aware Network for Medical Event
  Prediction","Medical event prediction (MEP) is a fundamental task in the medical domain,
which needs to predict medical events, including medications, diagnosis codes,
laboratory tests, procedures, outcomes, and so on, according to historical
medical records. The task is challenging as medical data is a type of complex
time series data with heterogeneous and temporal irregular characteristics.
Many machine learning methods that consider the two characteristics have been
proposed for medical event prediction. However, most of them consider the two
characteristics separately and ignore the correlations among different types of
medical events, especially relations between historical medical events and
target medical events. In this paper, we propose a novel neural network based
on attention mechanism, called cross-event attention-based time-aware network
(CATNet), for medical event prediction. It is a time-aware, event-aware and
task-adaptive method with the following advantages: 1) modeling heterogeneous
information and temporal information in a unified way and considering temporal
irregular characteristics locally and globally respectively, 2) taking full
advantage of correlations among different types of events via cross-event
attention. Experiments on two public datasets (MIMIC-III and eICU) show CATNet
can be adaptive with different MEP tasks and outperforms other state-of-the-art
methods on various MEP tasks. The source code of CATNet will be released after
this manuscript is accepted.",2022-04-29,2022,2022-04,medical
"Understanding Transfer Learning for Chest Radiograph Clinical Report
  Generation with Modified Transformer Architectures","The image captioning task is increasingly prevalent in artificial
intelligence applications for medicine. One important application is clinical
report generation from chest radiographs. The clinical writing of unstructured
reports is time consuming and error-prone. An automated system would improve
standardization, error reduction, time consumption, and medical accessibility.
In this paper we demonstrate the importance of domain specific pre-training and
propose a modified transformer architecture for the medical image captioning
task. To accomplish this, we train a series of modified transformers to
generate clinical reports from chest radiograph image input. These modified
transformers include: a meshed-memory augmented transformer architecture with
visual extractor using ImageNet pre-trained weights, a meshed-memory augmented
transformer architecture with visual extractor using CheXpert pre-trained
weights, and a meshed-memory augmented transformer whose encoder is passed the
concatenated embeddings using both ImageNet pre-trained weights and CheXpert
pre-trained weights. We use BLEU(1-4), ROUGE-L, CIDEr, and the clinical
CheXbert F1 scores to validate our models and demonstrate competitive scores
with state of the art models. We provide evidence that ImageNet pre-training is
ill-suited for the medical image captioning task, especially for less frequent
conditions (eg: enlarged cardiomediastinum, lung lesion, pneumothorax).
Furthermore, we demonstrate that the double feature model improves performance
for specific medical conditions (edema, consolidation, pneumothorax, support
devices) and overall CheXbert F1 score, and should be further developed in
future work. Such a double feature model, including both ImageNet pre-training
as well as domain specific pre-training, could be used in a wide range of image
captioning models in medicine.",2022-05-05,2022,2022-05,medical
"Deep Supervised Information Bottleneck Hashing for Cross-modal Retrieval
  based Computer-aided Diagnosis","Mapping X-ray images, radiology reports, and other medical data as binary
codes in the common space, which can assist clinicians to retrieve
pathology-related data from heterogeneous modalities (i.e., hashing-based
cross-modal medical data retrieval), provides a new view to promot
computeraided diagnosis. Nevertheless, there remains a barrier to boost medical
retrieval accuracy: how to reveal the ambiguous semantics of medical data
without the distraction of superfluous information. To circumvent this
drawback, we propose Deep Supervised Information Bottleneck Hashing (DSIBH),
which effectively strengthens the discriminability of hash codes. Specifically,
the Deep Deterministic Information Bottleneck (Yu, Yu, and Principe 2021) for
single modality is extended to the cross-modal scenario. Benefiting from this,
the superfluous information is reduced, which facilitates the discriminability
of hash codes. Experimental results demonstrate the superior accuracy of the
proposed DSIBH compared with state-of-the-arts in cross-modal medical data
retrieval tasks.",2022-05-06,2022,2022-05,medical
"Skin disease diagnosis using image analysis and natural language
  processing","In Zambia, there is a serious shortage of medical staff where each
practitioner attends to about 17000 patients in a given district while still,
other patients travel over 10 km to access the basic medical services. In this
research, we implement a deep learning model that can perform the clinical
diagnosis process. The study will prove whether image analysis is capable of
performing clinical diagnosis. It will also enable us to understand if we can
use image analysis to lessen the workload on medical practitioners by
delegating some tasks to an AI. The success of this study has the potential to
increase the accessibility of medical services to Zambians, which is one of the
national goals of Vision 2030.",2022-05-09,2022,2022-05,medical
"Explainable Deep Learning Methods in Medical Image Classification: A
  Survey","The remarkable success of deep learning has prompted interest in its
application to medical imaging diagnosis. Even though state-of-the-art deep
learning models have achieved human-level accuracy on the classification of
different types of medical data, these models are hardly adopted in clinical
workflows, mainly due to their lack of interpretability. The black-box-ness of
deep learning models has raised the need for devising strategies to explain the
decision process of these models, leading to the creation of the topic of
eXplainable Artificial Intelligence (XAI). In this context, we provide a
thorough survey of XAI applied to medical imaging diagnosis, including visual,
textual, example-based and concept-based explanation methods. Moreover, this
work reviews the existing medical imaging datasets and the existing metrics for
evaluating the quality of the explanations. In addition, we include a
performance comparison among a set of report generation-based methods. Finally,
the major challenges in applying XAI to medical imaging and the future research
directions on the topic are also discussed.",2022-05-10,2022,2022-05,medical
"Using artificial intelligence to detect chest X-rays with no significant
  findings in a primary health care setting in Oulu, Finland","Objectives: To assess the use of artificial intelligence-based software in
ruling out chest X-ray cases, with no significant findings in a primary health
care setting.
  Methods: In this retrospective study, a commercially available artificial
intelligence (AI) software was used to analyse 10 000 chest X-rays of Finnish
primary health care patients. In studies with a mismatch between an AI normal
report and the original radiologist report, a consensus read by two
board-certified radiologists was conducted to make the final diagnosis.
  Results: After the exclusion of cases not meeting the study criteria, 9579
cases were analysed by AI. Of these cases, 4451 were considered normal in the
original radiologist report and 4644 after the consensus reading. The number of
cases correctly found nonsignificant by AI was 1692 (17.7% of all studies and
36.4% of studies with no significant findings). After the consensus read, there
were nine confirmed false-negative studies. These studies included four cases
of slightly enlarged heart size, four cases of slightly increased pulmonary
opacification and one case with a small unilateral pleural effusion. This gives
the AI a sensitivity of 99.8% (95% CI= 99.65-99.92) and specificity of 36.4 %
(95% CI= 35.05-37.84) for recognising significant pathology on a chest X-ray.
  Conclusions: AI was able to correctly rule out 36.4% of chest X-rays with no
significant findings of primary health care patients, with a minimal number of
false negatives that would lead to effectively no compromise on patient safety.
No critical findings were missed by the software.",2022-05-17,2022,2022-05,medical
Robust and Efficient Medical Imaging with Self-Supervision,"Recent progress in Medical Artificial Intelligence (AI) has delivered systems
that can reach clinical expert level performance. However, such systems tend to
demonstrate sub-optimal ""out-of-distribution"" performance when evaluated in
clinical settings different from the training environment. A common mitigation
strategy is to develop separate systems for each clinical setting using
site-specific data [1]. However, this quickly becomes impractical as medical
data is time-consuming to acquire and expensive to annotate [2]. Thus, the
problem of ""data-efficient generalization"" presents an ongoing difficulty for
Medical AI development. Although progress in representation learning shows
promise, their benefits have not been rigorously studied, specifically for
out-of-distribution settings. To meet these challenges, we present REMEDIS, a
unified representation learning strategy to improve robustness and
data-efficiency of medical imaging AI. REMEDIS uses a generic combination of
large-scale supervised transfer learning with self-supervised learning and
requires little task-specific customization. We study a diverse range of
medical imaging tasks and simulate three realistic application scenarios using
retrospective data. REMEDIS exhibits significantly improved in-distribution
performance with up to 11.5% relative improvement in diagnostic accuracy over a
strong supervised baseline. More importantly, our strategy leads to strong
data-efficient generalization of medical imaging AI, matching strong supervised
baselines using between 1% to 33% of retraining data across tasks. These
results suggest that REMEDIS can significantly accelerate the life-cycle of
medical imaging AI development thereby presenting an important step forward for
medical imaging AI to deliver broad impact.",2022-05-19,2022,2022-05,medical
"Preparing data for pathological artificial intelligence with
  clinical-grade performance","[Purpose] The pathology is decisive for disease diagnosis, but relies heavily
on the experienced pathologists. Recently, pathological artificial intelligence
(PAI) is thought to improve diagnostic accuracy and efficiency. However, the
high performance of PAI based on deep learning in the laboratory generally
cannot be reproduced in the clinic. [Methods] Because the data preparation is
important for PAI, the paper has reviewed PAI-related studies in the PubMed
database published from January 2017 to February 2022, and 118 studies were
included. The in-depth analysis of methods for preparing data is performed,
including obtaining slides of pathological tissue, cleaning, screening, and
then digitizing. Expert review, image annotation, dataset division for model
training and validation are also discussed. We further discuss the reasons why
the high performance of PAI is not reproducible in the clinical practices and
show some effective ways to improve clinical performances of PAI. [Results] The
robustness of PAI depend on randomized collection of representative disease
slides, including rigorous quality control and screening, correction of digital
discrepancies, reasonable annotation, and the amount of data. The digital
pathology is fundamental of clinical-grade PAI, and the techniques of data
standardization and weakly supervised learning methods based on whole slide
image (WSI) are effective ways to overcome obstacles of performance
reproduction. [Conclusion] The representative data, the amount of labeling and
consistency from multi-centers is the key to performance reproduction. The
digital pathology for clinical diagnosis, data standardization and technique of
WSI-based weakly supervised learning hopefully build clinical-grade PAI.
Keywords: pathological artificial intelligence; data preparation;
clinical-grade; deep learning",2022-05-22,2022,2022-05,medical
"Automatic Quantification of Volumes and Biventricular Function in
  Cardiac Resonance. Validation of a New Artificial Intelligence Approach","Background: Artificial intelligence techniques have shown great potential in
cardiology, especially in quantifying cardiac biventricular function, volume,
mass, and ejection fraction (EF). However, its use in clinical practice is not
straightforward due to its poor reproducibility with cases from daily practice,
among other reasons. Objectives: To validate a new artificial intelligence tool
in order to quantify the cardiac biventricular function (volume, mass, and EF).
To analyze its robustness in the clinical area, and the computational times
compared with conventional methods. Methods: A total of 189 patients were
analyzed: 89 from a regional center and 100 from a public center. The method
proposes two convolutional networks that include anatomical information of the
heart to reduce classification errors. Results: A high concordance (Pearson
coefficient) was observed between manual quantification and the proposed
quantification of cardiac function (0.98, 0.92, 0.96 and 0.8 for volumes and
biventricular EF) in about 5 seconds per study. Conclusions: This method
quantifies biventricular function and volumes in seconds with an accuracy
equivalent to that of a specialist.",2022-06-03,2022,2022-06,medical
Future Artificial Intelligence tools and perspectives in medicine,"Purpose of review: Artificial intelligence (AI) has become popular in medical
applications, specifically as a clinical support tool for computer-aided
diagnosis. These tools are typically employed on medical data (i.e., image,
molecular data, clinical variables, etc.) and used the statistical and machine
learning methods to measure the model performance. In this review, we
summarized and discussed the most recent radiomic pipeline used for clinical
analysis. Recent findings:Currently, limited management of cancers benefits
from artificial intelligence, mostly related to a computer-aided diagnosis that
avoids a biopsy analysis that presents additional risks and costs. Most AI
tools are based on imaging features, known as radiomic analysis that can be
refined into predictive models in non-invasively acquired imaging data. This
review explores the progress of AI-based radiomic tools for clinical
applications with a brief description of necessary technical steps. Explaining
new radiomic approaches based on deep learning techniques will explain how the
new radiomic models (deep radiomic analysis) can benefit from deep
convolutional neural networks and be applied on limited data sets. Summary: To
consider the radiomic algorithms, further investigations are recommended to
involve deep learning in radiomic models with additional validation steps on
various cancer types.",2022-06-04,2022,2022-06,medical
"Bootstrapping Semi-supervised Medical Image Segmentation with
  Anatomical-aware Contrastive Distillation","Contrastive learning has shown great promise over annotation scarcity
problems in the context of medical image segmentation. Existing approaches
typically assume a balanced class distribution for both labeled and unlabeled
medical images. However, medical image data in reality is commonly imbalanced
(i.e., multi-class label imbalance), which naturally yields blurry contours and
usually incorrectly labels rare objects. Moreover, it remains unclear whether
all negative samples are equally negative. In this work, we present ACTION, an
Anatomical-aware ConTrastive dIstillatiON framework, for semi-supervised
medical image segmentation. Specifically, we first develop an iterative
contrastive distillation algorithm by softly labeling the negatives rather than
binary supervision between positive and negative pairs. We also capture more
semantically similar features from the randomly chosen negative set compared to
the positives to enforce the diversity of the sampled data. Second, we raise a
more important question: Can we really handle imbalanced samples to yield
better performance? Hence, the key innovation in ACTION is to learn global
semantic relationship across the entire dataset and local anatomical features
among the neighbouring pixels with minimal additional memory footprint. During
the training, we introduce anatomical contrast by actively sampling a sparse
set of hard negative pixels, which can generate smoother segmentation
boundaries and more accurate predictions. Extensive experiments across two
benchmark datasets and different unlabeled settings show that ACTION
significantly outperforms the current state-of-the-art semi-supervised methods.",2022-06-06,2022,2022-06,medical
"Implementation of a Modified U-Net for Medical Image Segmentation on
  Edge Devices","Deep learning techniques, particularly convolutional neural networks, have
shown great potential in computer vision and medical imaging applications.
However, deep learning models are computationally demanding as they require
enormous computational power and specialized processing hardware for model
training. To make these models portable and compatible for prototyping, their
implementation on low-power devices is imperative. In this work, we present the
implementation of Modified U-Net on Intel Movidius Neural Compute Stick 2
(NCS-2) for the segmentation of medical images. We selected U-Net because, in
medical image segmentation, U-Net is a prominent model that provides improved
performance for medical image segmentation even if the dataset size is small.
The modified U-Net model is evaluated for performance in terms of dice score.
Experiments are reported for segmentation task on three medical imaging
datasets: BraTs dataset of brain MRI, heart MRI dataset, and Ziehl-Neelsen
sputum smear microscopy image (ZNSDB) dataset. For the proposed model, we
reduced the number of parameters from 30 million in the U-Net model to 0.49
million in the proposed architecture. Experimental results show that the
modified U-Net provides comparable performance while requiring significantly
lower resources and provides inference on the NCS-2. The maximum dice scores
recorded are 0.96 for the BraTs dataset, 0.94 for the heart MRI dataset, and
0.74 for the ZNSDB dataset.",2022-06-06,2022,2022-06,medical
"Improving Medical Systems in the United States using Knowledge-Based
  Systems","America has one of the best medical systems in the world. The medical
treatment care options offered by the medical system make it sophisticated.
However, many American patients are not receiving health care on a regular
basis, and at the same time, they cannot afford it. Also, the current medical
system has many flaws such as high medical treatment costs and lack of doctors
to accommodate many patients. This paper presents the principles of medical
artificial intelligence called the knowledge based system. Doctors can remotely
check and monitor their patients health data, medical history, how and what
medical tests were done, and the lab results. The patients have access to
detailed health information online and do not need to make an appointment with
doctors to check their health on a daily basis. One doctor can check many
patients simultaneously online (when medical centers are understaffed) and do
not need to spend a lot of time with patients. Thus, doctors save more money
for patients, because patients will no longer be transporting to medical
centers to receive routine health check-ups. Patients do not need to overpay
for their insurance because they will have access to the knowledge-based
system, and the system will save the patients money to have their health
checked and reduce the number of unnecessary medical exams. This paper
undertakes a brief overview of research work done in a knowledge based system
rule based expert systems in the field of medical practices.",2022-06-07,2022,2022-06,medical
A Review of Causality for Learning Algorithms in Medical Image Analysis,"Medical image analysis is a vibrant research area that offers doctors and
medical practitioners invaluable insight and the ability to accurately diagnose
and monitor disease. Machine learning provides an additional boost for this
area. However, machine learning for medical image analysis is particularly
vulnerable to natural biases like domain shifts that affect algorithmic
performance and robustness. In this paper we analyze machine learning for
medical image analysis within the framework of Technology Readiness Levels and
review how causal analysis methods can fill a gap when creating robust and
adaptable medical image analysis algorithms. We review methods using causality
in medical imaging AI/ML and find that causal analysis has the potential to
mitigate critical problems for clinical translation but that uptake and
clinical downstream research has been limited so far.",2022-06-11,2022,2022-06,medical
Medical Dialogue Response Generation with Pivotal Information Recalling,"Medical dialogue generation is an important yet challenging task. Most
previous works rely on the attention mechanism and large-scale pretrained
language models. However, these methods often fail to acquire pivotal
information from the long dialogue history to yield an accurate and informative
response, due to the fact that the medical entities usually scatters throughout
multiple utterances along with the complex relationships between them. To
mitigate this problem, we propose a medical response generation model with
Pivotal Information Recalling (MedPIR), which is built on two components, i.e.,
knowledge-aware dialogue graph encoder and recall-enhanced generator. The
knowledge-aware dialogue graph encoder constructs a dialogue graph by
exploiting the knowledge relationships between entities in the utterances, and
encodes it with a graph attention network. Then, the recall-enhanced generator
strengthens the usage of these pivotal information by generating a summary of
the dialogue before producing the actual response. Experimental results on two
large-scale medical dialogue datasets show that MedPIR outperforms the strong
baselines in BLEU scores and medical entities F1 measure.",2022-06-17,2022,2022-06,medical
Autoencoder-based Attribute Noise Handling Method for Medical Data,"Medical datasets are particularly subject to attribute noise, that is,
missing and erroneous values. Attribute noise is known to be largely
detrimental to learning performances. To maximize future learning performances
it is primordial to deal with attribute noise before any inference. We propose
a simple autoencoder-based preprocessing method that can correct mixed-type
tabular data corrupted by attribute noise. No other method currently exists to
handle attribute noise in tabular data. We experimentally demonstrate that our
method outperforms both state-of-the-art imputation methods and noise
correction methods on several real-world medical datasets.",2022-06-20,2022,2022-06,medical
"Automated Systems For Diagnosis of Dysgraphia in Children: A Survey and
  Novel Framework","Learning disabilities, which primarily interfere with the basic learning
skills such as reading, writing and math, are known to affect around 10% of
children in the world. The poor motor skills and motor coordination as part of
the neurodevelopmental disorder can become a causative factor for the
difficulty in learning to write (dysgraphia), hindering the academic track of
an individual. The signs and symptoms of dysgraphia include but are not limited
to irregular handwriting, improper handling of writing medium, slow or labored
writing, unusual hand position, etc. The widely accepted assessment criterion
for all the types of learning disabilities is the examination performed by
medical experts. The few available artificial intelligence-powered screening
systems for dysgraphia relies on the distinctive features of handwriting from
the corresponding images.This work presents a review of the existing automated
dysgraphia diagnosis systems for children in the literature. The main focus of
the work is to review artificial intelligence-based systems for dysgraphia
diagnosis in children. This work discusses the data collection method,
important handwriting features, machine learning algorithms employed in the
literature for the diagnosis of dysgraphia. Apart from that, this article
discusses some of the non-artificial intelligence-based automated systems also.
Furthermore, this article discusses the drawbacks of existing systems and
proposes a novel framework for dysgraphia diagnosis.",2022-06-27,2022,2022-06,medical
GERNERMED++: Transfer Learning in German Medical NLP,"We present a statistical model for German medical natural language processing
trained for named entity recognition (NER) as an open, publicly available
model. The work serves as a refined successor to our first GERNERMED model
which is substantially outperformed by our work. We demonstrate the
effectiveness of combining multiple techniques in order to achieve strong
results in entity recognition performance by the means of transfer-learning on
pretrained deep language models (LM), word-alignment and neural machine
translation. Due to the sparse situation on open, public medical entity
recognition models for German texts, this work offers benefits to the German
research community on medical NLP as a baseline model. Since our model is based
on public English data, its weights are provided without legal restrictions on
usage and distribution. The sample code and the statistical model is available
at: https://github.com/frankkramer-lab/GERNERMED-pp",2022-06-29,2022,2022-06,medical
"Backdoor Attack is a Devil in Federated GAN-based Medical Image
  Synthesis","Deep Learning-based image synthesis techniques have been applied in
healthcare research for generating medical images to support open research.
Training generative adversarial neural networks (GAN) usually requires large
amounts of training data. Federated learning (FL) provides a way of training a
central model using distributed data from different medical institutions while
keeping raw data locally. However, FL is vulnerable to backdoor attack, an
adversarial by poisoning training data, given the central server cannot access
the original data directly. Most backdoor attack strategies focus on
classification models and centralized domains. In this study, we propose a way
of attacking federated GAN (FedGAN) by treating the discriminator with a
commonly used data poisoning strategy in backdoor attack classification models.
We demonstrate that adding a small trigger with size less than 0.5 percent of
the original image size can corrupt the FL-GAN model. Based on the proposed
attack, we provide two effective defense strategies: global malicious detection
and local training regularization. We show that combining the two defense
strategies yields a robust medical image generation.",2022-07-02,2022,2022-07,medical
"Complementary artificial intelligence designed to augment human
  discovery","Neither artificial intelligence designed to play Turing's imitation game, nor
augmented intelligence built to maximize the human manipulation of information
are tuned to accelerate innovation and improve humanity's collective advance
against its greatest challenges. We reconceptualize and pilot beneficial AI to
radically augment human understanding by complementing rather than competing
with human cognitive capacity. Our approach to complementary intelligence
builds on insights underlying the wisdom of crowds, which hinges on the
independence and diversity of crowd members' information and approach. By
programmatically incorporating information on the evolving distribution of
scientific expertise from research papers, our approach follows the
distribution of content in the literature while avoiding the scientific crowd
and the hypotheses cognitively available to it. We use this approach to
generate valuable predictions for what materials possess valuable
energy-related properties (e.g., thermoelectricity), and what compounds possess
valuable medical properties (e.g., asthma) that complement the human scientific
crowd. We demonstrate that our complementary predictions, if identified by
human scientists and inventors at all, are only discovered years further into
the future. When we evaluate the promise of our predictions with
first-principles equations, we demonstrate that increased complementarity of
our predictions does not decrease and in some cases increases the probability
that the predictions possess the targeted properties. In summary, by tuning AI
to avoid the crowd, we can generate hypotheses unlikely to be imagined or
pursued until the distant future and promise to punctuate scientific advance.
By identifying and correcting for collective human bias, these models also
suggest opportunities to improve human prediction by reformulating science
education for discovery.",2022-07-02,2022,2022-07,medical
"Efficient Lung Cancer Image Classification and Segmentation Algorithm
  Based on Improved Swin Transformer","With the development of computer technology, various models have emerged in
artificial intelligence. The transformer model has been applied to the field of
computer vision (CV) after its success in natural language processing (NLP).
Radiologists continue to face multiple challenges in today's rapidly evolving
medical field, such as increased workload and increased diagnostic demands.
Although there are some conventional methods for lung cancer detection before,
their accuracy still needs to be improved, especially in realistic diagnostic
scenarios. This paper creatively proposes a segmentation method based on
efficient transformer and applies it to medical image analysis. The algorithm
completes the task of lung cancer classification and segmentation by analyzing
lung cancer data, and aims to provide efficient technical support for medical
staff. In addition, we evaluated and compared the results in various aspects.
For the classification mission, the max accuracy of Swin-T by regular training
and Swin-B in two resolutions by pre-training can be up to 82.3%. For the
segmentation mission, we use pre-training to help the model improve the
accuracy of our experiments. The accuracy of the three models reaches over 95%.
The experiments demonstrate that the algorithm can be well applied to lung
cancer classification and segmentation missions.",2022-07-04,2022,2022-07,medical
"Towards the Use of Saliency Maps for Explaining Low-Quality
  Electrocardiograms to End Users","When using medical images for diagnosis, either by clinicians or artificial
intelligence (AI) systems, it is important that the images are of high quality.
When an image is of low quality, the medical exam that produced the image often
needs to be redone. In telemedicine, a common problem is that the quality issue
is only flagged once the patient has left the clinic, meaning they must return
in order to have the exam redone. This can be especially difficult for people
living in remote regions, who make up a substantial portion of the patients at
Portal Telemedicina, a digital healthcare organization based in Brazil. In this
paper, we report on ongoing work regarding (i) the development of an AI system
for flagging and explaining low-quality medical images in real-time, (ii) an
interview study to understand the explanation needs of stakeholders using the
AI system at OurCompany, and, (iii) a longitudinal user study design to examine
the effect of including explanations on the workflow of the technicians in our
clinics. To the best of our knowledge, this would be the first longitudinal
study on evaluating the effects of XAI methods on end-users -- stakeholders
that use AI systems but do not have AI-specific expertise. We welcome feedback
and suggestions on our experimental setup.",2022-07-06,2022,2022-07,medical
"High-Resolution Swin Transformer for Automatic Medical Image
  Segmentation","The Resolution of feature maps is critical for medical image segmentation.
Most of the existing Transformer-based networks for medical image segmentation
are U-Net-like architecture that contains an encoder that utilizes a sequence
of Transformer blocks to convert the input medical image from high-resolution
representation into low-resolution feature maps and a decoder that gradually
recovers the high-resolution representation from low-resolution feature maps.
Unlike previous studies, in this paper, we utilize the network design style
from the High-Resolution Network (HRNet), replace the convolutional layers with
Transformer blocks, and continuously exchange information from the different
resolution feature maps that are generated by Transformer blocks. The newly
Transformer-based network presented in this paper is denoted as High-Resolution
Swin Transformer Network (HRSTNet). Extensive experiments illustrate that
HRSTNet can achieve comparable performance with the state-of-the-art
Transformer-based U-Net-like architecture on Brain Tumor Segmentation(BraTS)
2021 and the liver dataset from Medical Segmentation Decathlon. The code of
HRSTNet will be publicly available at https://github.com/auroua/HRSTNet.",2022-07-23,2022,2022-07,medical
AI Approaches in Processing and Using Data in Personalized Medicine,"In modern dynamic constantly developing society, more and more people suffer
from chronic and serious diseases and doctors and patients need special and
sophisticated medical and health support. Accordingly, prominent health
stakeholders have recognized the importance of development of such services to
make patients life easier. Such support requires the collection of huge amount
of patients complex data like clinical, environmental, nutritional, daily
activities, variety of data from smart wearable devices, data from clothing
equipped with sensors etc. Holistic patients data must be properly aggregated,
processed, analyzed, and presented to the doctors and caregivers to recommend
adequate treatment and actions to improve patients health related parameters
and general wellbeing. Advanced artificial intelligence techniques offer the
opportunity to analyze such big data, consume them, and derive new knowledge to
support personalized medical decisions. New approaches like those based on
advanced machine learning, federated learning, transfer learning, explainable
artificial intelligence open new paths for more quality use of health and
medical data in future. In this paper, we will present some crucial aspects and
characteristic examples in the area of application of a range of artificial
intelligence approaches in personalized medical decisions.",2022-07-26,2022,2022-07,medical
"Remote Medication Status Prediction for Individuals with Parkinson's
  Disease using Time-series Data from Smartphones","Medication for neurological diseases such as the Parkinson's disease usually
happens remotely away from hospitals. Such out-of-lab environments pose
challenges in collecting timely and accurate health status data. Individual
differences in behavioral signals collected from wearable sensors also lead to
difficulties in adopting current general machine learning analysis pipelines.
To address these challenges, we present a method for predicting the medication
status of Parkinson's disease patients using the public mPower dataset, which
contains 62,182 remote multi-modal test records collected on smartphones from
487 patients. The proposed method shows promising results in predicting three
medication statuses objectively: Before Medication (AUC=0.95), After Medication
(AUC=0.958), and Another Time (AUC=0.976) by examining patient-wise historical
records with the attention weights learned through a Transformer model. Our
method provides an innovative way for personalized remote health sensing in a
timely and objective fashion which could benefit a broad range of similar
applications.",2022-07-26,2022,2022-07,medical
"Decentralized Machine Learning for Intelligent Health Care Systems on
  the Computing Continuum","The introduction of electronic personal health records (EHR) enables
nationwide information exchange and curation among different health care
systems. However, the current EHR systems do not provide transparent means for
diagnosis support, medical research or can utilize the omnipresent data
produced by the personal medical devices. Besides, the EHR systems are
centrally orchestrated, which could potentially lead to a single point of
failure. Therefore, in this article, we explore novel approaches for
decentralizing machine learning over distributed ledgers to create intelligent
EHR systems that can utilize information from personal medical devices for
improved knowledge extraction. Consequently, we proposed and evaluated a
conceptual EHR to enable anonymous predictive analysis across multiple medical
institutions. The evaluation results indicate that the decentralized EHR can be
deployed over the computing continuum with reduced machine learning time of up
to 60% and consensus latency of below 8 seconds.",2022-07-29,2022,2022-07,medical
"Diagnosis of Paratuberculosis in Histopathological Images Based on
  Explainable Artificial Intelligence and Deep Learning","Artificial intelligence holds great promise in medical imaging, especially
histopathological imaging. However, artificial intelligence algorithms cannot
fully explain the thought processes during decision-making. This situation has
brought the problem of explainability, i.e., the black box problem, of
artificial intelligence applications to the agenda: an algorithm simply
responds without stating the reasons for the given images. To overcome the
problem and improve the explainability, explainable artificial intelligence
(XAI) has come to the fore, and piqued the interest of many researchers.
Against this backdrop, this study examines a new and original dataset using the
deep learning algorithm, and visualizes the output with gradient-weighted class
activation mapping (Grad-CAM), one of the XAI applications. Afterwards, a
detailed questionnaire survey was conducted with the pathologists on these
images. Both the decision-making processes and the explanations were verified,
and the accuracy of the output was tested. The research results greatly help
pathologists in the diagnosis of paratuberculosis.",2022-08-02,2022,2022-08,medical
"Advances of Artificial Intelligence in Classical and Novel
  Spectroscopy-Based Approaches for Cancer Diagnostics. A Review","Cancer is one of the leading causes of death worldwide. Fast and safe
early-stage, pre- and intra-operative diagnostics can significantly contribute
to successful cancer identification and treatment. Artificial intelligence has
played an increasing role in the enhancement of cancer diagnostics techniques
in the last 15 years. This review covers the advances of artificial
intelligence applications in well-established techniques such as MRI and CT.
Also, it shows its high potential in combination with optical
spectroscopy-based approaches that are under development for mobile,
ultra-fast, and low-invasive diagnostics. I will show how spectroscopy-based
approaches can reduce the time of tissue preparation for pathological analysis
by making thin-slicing or haematoxylin-and-eosin staining obsolete. I will
present examples of spectroscopic tools for fast and low-invasive ex- and
in-vivo tissue classification for the determination of a tumour and its
boundaries. Also, I will discuss that, contrary to MRI and CT, spectroscopic
measurements do not require the administration of chemical agents to enhance
the quality of cancer imaging which contributes to the development of more
secure diagnostic methods. Overall, we will see that the combination of
spectroscopy and artificial intelligence constitutes a highly promising and
fast-developing field of medical technology that will soon augment available
cancer diagnostic methods.",2022-08-08,2022,2022-08,medical
"Self-supervised Multi-modal Training from Uncurated Image and Reports
  Enables Zero-shot Oversight Artificial Intelligence in Radiology","Oversight AI is an emerging concept in radiology where the AI forms a
symbiosis with radiologists by continuously supporting radiologists in their
decision-making. Recent advances in vision-language models sheds a light on the
long-standing problems of the oversight AI by the understanding both visual and
textual concepts and their semantic correspondences. However, there have been
limited successes in the application of vision-language models in the medical
domain, as the current vision-language models and learning strategies for
photographic images and captions call for the web-scale data corpus of image
and text pairs which was not often feasible in the medical domain. To address
this, here we present a model dubbed Medical Cross-attention Vision-Language
model (Medical X-VL), leveraging the key components to be tailored for the
medical domain. Our medical X-VL model is based on the following components:
self-supervised uni-modal models in medical domain and fusion encoder to bridge
them, momentum distillation, sentence-wise contrastive learning for medical
reports, and the sentence similarity-adjusted hard negative mining. We
experimentally demonstrated that our model enables various zero-shot tasks for
oversight AI, ranging from the zero-shot classification to zero-shot error
correction. Our model outperformed the current state-of-the-art models in two
different medical image database, suggesting the novel clinical usage of our
oversight AI model for monitoring human errors. Our method was especially
successful in the data-limited setting, which is frequently encountered in the
clinics, suggesting the potential widespread applicability in medical domain.",2022-08-10,2022,2022-08,medical
"OpenMedIA: Open-Source Medical Image Analysis Toolbox and Benchmark
  under Heterogeneous AI Computing Platforms","In this paper, we present OpenMedIA, an open-source toolbox library
containing a rich set of deep learning methods for medical image analysis under
heterogeneous Artificial Intelligence (AI) computing platforms. Various medical
image analysis methods, including 2D/3D medical image classification,
segmentation, localisation, and detection, have been included in the toolbox
with PyTorch and/or MindSpore implementations under heterogeneous NVIDIA and
Huawei Ascend computing systems. To our best knowledge, OpenMedIA is the first
open-source algorithm library providing compared PyTorch and MindSpore
implementations and results on several benchmark datasets. The source codes and
models are available at https://git.openi.org.cn/OpenMedIA.",2022-08-11,2022,2022-08,medical
"An Empirical Comparison of Explainable Artificial Intelligence Methods
  for Clinical Data: A Case Study on Traumatic Brain Injury","A longstanding challenge surrounding deep learning algorithms is unpacking
and understanding how they make their decisions. Explainable Artificial
Intelligence (XAI) offers methods to provide explanations of internal functions
of algorithms and reasons behind their decisions in ways that are interpretable
and understandable to human users. . Numerous XAI approaches have been
developed thus far, and a comparative analysis of these strategies seems
necessary to discern their relevance to clinical prediction models. To this
end, we first implemented two prediction models for short- and long-term
outcomes of traumatic brain injury (TBI) utilizing structured tabular as well
as time-series physiologic data, respectively. Six different interpretation
techniques were used to describe both prediction models at the local and global
levels. We then performed a critical analysis of merits and drawbacks of each
strategy, highlighting the implications for researchers who are interested in
applying these methodologies. The implemented methods were compared to one
another in terms of several XAI characteristics such as understandability,
fidelity, and stability. Our findings show that SHAP is the most stable with
the highest fidelity but falls short of understandability. Anchors, on the
other hand, is the most understandable approach, but it is only applicable to
tabular data and not time series data.",2022-08-13,2022,2022-08,medical
"Learn2Trust: A video and streamlit-based educational programme for
  AI-based medical image analysis targeted towards medical students","In order to be able to use artificial intelligence (AI) in medicine without
scepticism and to recognise and assess its growing potential, a basic
understanding of this topic is necessary among current and future medical
staff. Under the premise of ""trust through understanding"", we developed an
innovative online course as a learning opportunity within the framework of the
German KI Campus (AI campus) project, which is a self-guided course that
teaches the basics of AI for the analysis of medical image data. The main goal
is to provide a learning environment for a sufficient understanding of AI in
medical image analysis so that further interest in this topic is stimulated and
inhibitions towards its use can be overcome by means of positive application
experience. The focus was on medical applications and the fundamentals of
machine learning. The online course was divided into consecutive lessons, which
include theory in the form of explanatory videos, practical exercises in the
form of Streamlit and practical exercises and/or quizzes to check learning
progress. A survey among the participating medical students in the first run of
the course was used to analyse our research hypotheses quantitatively.",2022-08-15,2022,2022-08,medical
"End-to-end Clinical Event Extraction from Chinese Electronic Health
  Record","Event extraction is an important work of medical text processing. According
to the complex characteristics of medical text annotation, we use the
end-to-end event extraction model to enhance the output formatting information
of events. Through pre training and fine-tuning, we can extract the attributes
of the four dimensions of medical text: anatomical position, subject word,
description word and occurrence state. On the test set, the accuracy rate was
0.4511, the recall rate was 0.3928, and the F1 value was 0.42. The method of
this model is simple, and it has won the second place in the task of mining
clinical discovery events (task2) in the Chinese electronic medical record of
the seventh China health information processing Conference (chip2021).",2022-08-19,2022,2022-08,medical
"Advancing the cybersecurity of the healthcare system with
  self-optimising and self-adaptative artificial intelligence (part 2)","This article advances the knowledge on teaching and training new artificial
intelligence algorithms, for securing, preparing, and adapting the healthcare
system to cope with future pandemics. The core objective is to develop a
concept healthcare system supported by autonomous artificial intelligence that
can use edge health devices with real-time data. The article constructs two
case scenarios for applying cybersecurity with autonomous artificial
intelligence for (1) self-optimising predictive cyber risk analytics of
failures in healthcare systems during a Disease X event (i.e., undefined future
pandemic), and (2) self-adaptive forecasting of medical production and supply
chain bottlenecks during future pandemics. To construct the two testing
scenarios, the article uses the case of Covid-19 to synthesise data for the
algorithms i.e., for optimising and securing digital healthcare systems in
anticipation of disease X. The testing scenarios are built to tackle the
logistical challenges and disruption of complex production and supply chains
for vaccine distribution with optimisation algorithms.",2022-08-30,2022,2022-08,medical
An Artificial Intelligence Outlook for Colorectal Cancer Screening,"Colorectal cancer is the third most common tumor in men and the second in
women, accounting for 10% of all tumors worldwide. It ranks second in
cancer-related deaths with 9.4%, following lung cancer. The decrease in
mortality rate documented over the last 20 years has shown signs of slowing
down since 2017, necessitating concentrated actions on specific measures that
have exhibited considerable potential. As such, the technical foundation and
research evidence for blood-derived protein markers have been set, pending
comparative validation, clinical implementation and integration into an
artificial intelligence enabled decision support framework that also considers
knowledge on risk factors. The current paper aspires to constitute the driving
force for creating change in colorectal cancer screening by reviewing existing
medical practices through accessible and non-invasive risk estimation,
employing a straightforward artificial intelligence outlook.",2022-09-05,2022,2022-09,medical
"A hybrid Bayesian network for medical device risk assessment and
  management","ISO 14971 is the primary standard used for medical device risk management.
While it specifies the requirements for medical device risk management, it does
not specify a particular method for performing risk management. Hence, medical
device manufacturers are free to develop or use any appropriate methods for
managing the risk of medical devices. The most commonly used methods, such as
Fault Tree Analysis (FTA), are unable to provide a reasonable basis for
computing risk estimates when there are limited or no historical data available
or where there is second-order uncertainty about the data. In this paper, we
present a novel method for medical device risk management using hybrid Bayesian
networks (BNs) that resolves the limitations of classical methods such as FTA
and incorporates relevant factors affecting the risk of medical devices. The
proposed BN method is generic but can be instantiated on a system-by-system
basis, and we apply it to a Defibrillator device to demonstrate the process
involved for medical device risk management during production and
post-production. The example is validated against real-world data.",2022-09-07,2022,2022-09,medical
"Continuous Design Control for Machine Learning in Certified Medical
  Systems","Continuous software engineering has become commonplace in numerous fields.
However, in regulating intensive sectors, where additional concerns needs to be
taken into account, it is often considered difficult to apply continuous
development approaches, such as devops. In this paper, we present an approach
for using pull requests as design controls, and apply this approach to machine
learning in certified medical systems leveraging model cards, a novel technique
developed to add explainability to machine learning systems, as a regulatory
audit trail. The approach is demonstrated with an industrial system that we
have used previously to show how medical systems can be developed in a
continuous fashion.",2022-09-13,2022,2022-09,medical
"Declarative Guideline Conformance Checking of Clinical Treatments: A
  Case Study","Conformance checking is a process mining technique that allows verifying the
conformance of process instances to a given model. Thus, this technique is
predestined to be used in the medical context for the comparison of treatment
cases with clinical guidelines. However, medical processes are highly variable,
highly dynamic, and complex. This makes the use of imperative conformance
checking approaches in the medical domain difficult. Studies show that
declarative approaches can better address these characteristics. However, none
of the approaches has yet gained practical acceptance. Another challenge are
alignments, which usually do not add any value from a medical point of view.
For this reason, we investigate in a case study the usability of the HL7
standard Arden Syntax for declarative, rule-based conformance checking and the
use of manually modeled alignments. Using the approach, it was possible to
check the conformance of treatment cases and create medically meaningful
alignments for large parts of a medical guideline.",2022-09-20,2022,2022-09,medical
"Artificial Intelligence-Based Image Reconstruction in Cardiac Magnetic
  Resonance","Artificial intelligence (AI) and Machine Learning (ML) have shown great
potential in improving the medical imaging workflow, from image acquisition and
reconstruction to disease diagnosis and treatment. Particularly, in recent
years, there has been a significant growth in the use of AI and ML algorithms,
especially Deep Learning (DL) based methods, for medical image reconstruction.
DL techniques have shown to be competitive and often superior over conventional
reconstruction methods in terms of both reconstruction quality and
computational efficiency. The use of DL-based image reconstruction also
provides promising opportunities to transform the way cardiac images are
acquired and reconstructed. In this chapter, we will review recent advances in
DL-based reconstruction techniques for cardiac imaging, with emphasis on
cardiac magnetic resonance (CMR) image reconstruction. We mainly focus on
supervised DL methods for the application, including image post-processing
techniques, model-driven approaches and k-space based methods. Current
limitations, challenges and future opportunities of DL for cardiac image
reconstruction are also discussed.",2022-09-21,2022,2022-09,medical
"DR.BENCH: Diagnostic Reasoning Benchmark for Clinical Natural Language
  Processing","The meaningful use of electronic health records (EHR) continues to progress
in the digital era with clinical decision support systems augmented by
artificial intelligence. A priority in improving provider experience is to
overcome information overload and reduce the cognitive burden so fewer medical
errors and cognitive biases are introduced during patient care. One major type
of medical error is diagnostic error due to systematic or predictable errors in
judgment that rely on heuristics. The potential for clinical natural language
processing (cNLP) to model diagnostic reasoning in humans with forward
reasoning from data to diagnosis and potentially reduce the cognitive burden
and medical error has not been investigated. Existing tasks to advance the
science in cNLP have largely focused on information extraction and named entity
recognition through classification tasks. We introduce a novel suite of tasks
coined as Diagnostic Reasoning Benchmarks, DR.BENCH, as a new benchmark for
developing and evaluating cNLP models with clinical diagnostic reasoning
ability. The suite includes six tasks from ten publicly available datasets
addressing clinical text understanding, medical knowledge reasoning, and
diagnosis generation. DR.BENCH is the first clinical suite of tasks designed to
be a natural language generation framework to evaluate pre-trained language
models. Experiments with state-of-the-art pre-trained generative language
models using large general domain models and models that were continually
trained on a medical corpus demonstrate opportunities for improvement when
evaluated in DR. BENCH. We share DR. BENCH as a publicly available GitLab
repository with a systematic approach to load and evaluate models for the cNLP
community.",2022-09-29,2022,2022-09,medical
"Compressed Gastric Image Generation Based on Soft-Label Dataset
  Distillation for Medical Data Sharing","Background and objective: Sharing of medical data is required to enable the
cross-agency flow of healthcare information and construct high-accuracy
computer-aided diagnosis systems. However, the large sizes of medical datasets,
the massive amount of memory of saved deep convolutional neural network (DCNN)
models, and patients' privacy protection are problems that can lead to
inefficient medical data sharing. Therefore, this study proposes a novel
soft-label dataset distillation method for medical data sharing.
  Methods: The proposed method distills valid information of medical image data
and generates several compressed images with different data distributions for
anonymous medical data sharing. Furthermore, our method can extract essential
weights of DCNN models to reduce the memory required to save trained models for
efficient medical data sharing.
  Results: The proposed method can compress tens of thousands of images into
several soft-label images and reduce the size of a trained model to a few
hundredths of its original size. The compressed images obtained after
distillation have been visually anonymized; therefore, they do not contain the
private information of the patients. Furthermore, we can realize high-detection
performance with a small number of compressed images.
  Conclusions: The experimental results show that the proposed method can
improve the efficiency and security of medical data sharing.",2022-09-29,2022,2022-09,medical
"Medical Image Retrieval via Nearest Neighbor Search on Pre-trained Image
  Features","Nearest neighbor search (NNS) aims to locate the points in high-dimensional
space that is closest to the query point. The brute-force approach for finding
the nearest neighbor becomes computationally infeasible when the number of
points is large. The NNS has multiple applications in medicine, such as
searching large medical imaging databases, disease classification, diagnosis,
etc. With a focus on medical imaging, this paper proposes DenseLinkSearch an
effective and efficient algorithm that searches and retrieves the relevant
images from heterogeneous sources of medical images. Towards this, given a
medical database, the proposed algorithm builds the index that consists of
pre-computed links of each point in the database. The search algorithm utilizes
the index to efficiently traverse the database in search of the nearest
neighbor. We extensively tested the proposed NNS approach and compared the
performance with state-of-the-art NNS approaches on benchmark datasets and our
created medical image datasets. The proposed approach outperformed the existing
approach in terms of retrieving accurate neighbors and retrieval speed. We also
explore the role of medical image feature representation in content-based
medical image retrieval tasks. We propose a Transformer-based feature
representation technique that outperformed the existing pre-trained Transformer
approach on CLEF 2011 medical image retrieval task. The source code of our
experiments are available at https://github.com/deepaknlp/DLS.",2022-10-05,2022,2022-10,medical
Token Classification for Disambiguating Medical Abbreviations,"Abbreviations are unavoidable yet critical parts of the medical text. Using
abbreviations, especially in clinical patient notes, can save time and space,
protect sensitive information, and help avoid repetitions. However, most
abbreviations might have multiple senses, and the lack of a standardized
mapping system makes disambiguating abbreviations a difficult and
time-consuming task. The main objective of this study is to examine the
feasibility of token classification methods for medical abbreviation
disambiguation. Specifically, we explore the capability of token classification
methods to deal with multiple unique abbreviations in a single text. We use two
public datasets to compare and contrast the performance of several transformer
models pre-trained on different scientific and medical corpora. Our proposed
token classification approach outperforms the more commonly used text
classification models for the abbreviation disambiguation task. In particular,
the SciBERT model shows a strong performance for both token and text
classification tasks over the two considered datasets. Furthermore, we find
that abbreviation disambiguation performance for the text classification models
becomes comparable to that of token classification only when postprocessing is
applied to their predictions, which involves filtering possible labels for an
abbreviation based on the training data.",2022-10-05,2022,2022-10,medical
"KG-MTT-BERT: Knowledge Graph Enhanced BERT for Multi-Type Medical Text
  Classification","Medical text learning has recently emerged as a promising area to improve
healthcare due to the wide adoption of electronic health record (EHR) systems.
The complexity of the medical text such as diverse length, mixed text types,
and full of medical jargon, poses a great challenge for developing effective
deep learning models. BERT has presented state-of-the-art results in many NLP
tasks, such as text classification and question answering. However, the
standalone BERT model cannot deal with the complexity of the medical text,
especially the lengthy clinical notes. Herein, we develop a new model called
KG-MTT-BERT (Knowledge Graph Enhanced Multi-Type Text BERT) by extending the
BERT model for long and multi-type text with the integration of the medical
knowledge graph. Our model can outperform all baselines and other
state-of-the-art models in diagnosis-related group (DRG) classification, which
requires comprehensive medical text for accurate classification. We also
demonstrated that our model can effectively handle multi-type text and the
integration of medical knowledge graph can significantly improve the
performance.",2022-10-08,2022,2022-10,medical
"Adapting Pretrained Vision-Language Foundational Models to Medical
  Imaging Domains","Multi-modal foundation models are typically trained on millions of pairs of
natural images and text captions, frequently obtained through web-crawling
approaches. Although such models depict excellent generative capabilities, they
do not typically generalize well to specific domains such as medical images
that have fundamentally shifted distributions compared to natural images.
Building generative models for medical images that faithfully depict clinical
context may help alleviate the paucity of healthcare datasets. Thus, in this
study, we seek to research and expand the representational capabilities of
large pretrained foundation models to medical concepts, specifically for
leveraging the Stable Diffusion model to generate domain specific images found
in medical imaging. We explore the sub-components of the Stable Diffusion
pipeline (the variational autoencoder, the U-Net and the text-encoder) to
fine-tune the model to generate medical images. We benchmark the efficacy of
these efforts using quantitative image quality metrics and qualitative
radiologist-driven evaluations that accurately represent the clinical content
of conditional text prompts. Our best-performing model improves upon the stable
diffusion baseline and can be conditioned to insert a realistic-looking
abnormality on a synthetic radiology image, while maintaining a 95% accuracy on
a classifier trained to detect the abnormality.",2022-10-09,2022,2022-10,medical
Domain-guided data augmentation for deep learning on medical imaging,"While domain-specific data augmentation can be useful in training neural
networks for medical imaging tasks, such techniques have not been widely used
to date. Here, we test whether domain-specific data augmentation is useful for
medical imaging using a well-benchmarked task: view classification on fetal
ultrasound FETAL-125 and OB-125 datasets. We found that using a
context-preserving cut-paste strategy, we could create valid training data as
measured by performance of the resulting trained model on the benchmark test
dataset. When used in an online fashion, models trained on this data performed
similarly to those trained using traditional data augmentation (FETAL-125
F-score 85.33+/-0.24 vs 86.89+/-0.60, p-value 0.0139; OB-125 F-score
74.60+/-0.11 vs 72.43+/-0.62, p-value 0.0039). Furthermore, the ability to
perform augmentations during training time, as well as the ability to apply
chosen augmentations equally across data classes, are important considerations
in designing a bespoke data augmentation. Finally, we provide open-source code
to facilitate running bespoke data augmentations in an online fashion. Taken
together, this work expands the ability to design and apply domain-guided data
augmentations for medical imaging tasks.",2022-10-10,2022,2022-10,medical
The evolution of AI approaches for motor imagery EEG-based BCIs,"The Motor Imagery (MI) electroencephalography (EEG) based Brain Computer
Interfaces (BCIs) allow the direct communication between humans and machines by
exploiting the neural pathways connected to motor imagination. Therefore, these
systems open the possibility of developing applications that could span from
the medical field to the entertainment industry. In this context, Artificial
Intelligence (AI) approaches become of fundamental importance especially when
wanting to provide a correct and coherent feedback to BCI users. Moreover,
publicly available datasets in the field of MI EEG-based BCIs have been widely
exploited to test new techniques from the AI domain. In this work, AI
approaches applied to datasets collected in different years and with different
devices but with coherent experimental paradigms are investigated with the aim
of providing a concise yet sufficiently comprehensive survey on the evolution
and influence of AI techniques on MI EEG-based BCI data.",2022-10-11,2022,2022-10,medical
"Multi-Granularity Cross-modal Alignment for Generalized Medical Visual
  Representation Learning","Learning medical visual representations directly from paired radiology
reports has become an emerging topic in representation learning. However,
existing medical image-text joint learning methods are limited by instance or
local supervision analysis, ignoring disease-level semantic correspondences. In
this paper, we present a novel Multi-Granularity Cross-modal Alignment (MGCA)
framework for generalized medical visual representation learning by harnessing
the naturally exhibited semantic correspondences between medical image and
radiology reports at three different levels, i.e., pathological region-level,
instance-level, and disease-level. Specifically, we first incorporate the
instance-wise alignment module by maximizing the agreement between image-report
pairs. Further, for token-wise alignment, we introduce a bidirectional
cross-attention strategy to explicitly learn the matching between fine-grained
visual tokens and text tokens, followed by contrastive learning to align them.
More important, to leverage the high-level inter-subject relationship semantic
(e.g., disease) correspondences, we design a novel cross-modal disease-level
alignment paradigm to enforce the cross-modal cluster assignment consistency.
Extensive experimental results on seven downstream medical image datasets
covering image classification, object detection, and semantic segmentation
tasks demonstrate the stable and superior performance of our framework.",2022-10-12,2022,2022-10,medical
"Artificial Intelligence-Based Methods for Fusion of Electronic Health
  Records and Imaging Data","Healthcare data are inherently multimodal, including electronic health
records (EHR), medical images, and multi-omics data. Combining these multimodal
data sources contributes to a better understanding of human health and provides
optimal personalized healthcare. Advances in artificial intelligence (AI)
technologies, particularly machine learning (ML), enable the fusion of these
different data modalities to provide multimodal insights. To this end, in this
scoping review, we focus on synthesizing and analyzing the literature that uses
AI techniques to fuse multimodal medical data for different clinical
applications. More specifically, we focus on studies that only fused EHR with
medical imaging data to develop various AI methods for clinical applications.
We present a comprehensive analysis of the various fusion strategies, the
diseases and clinical outcomes for which multimodal fusion was used, the ML
algorithms used to perform multimodal fusion for each clinical application, and
the available multimodal medical datasets. We followed the PRISMA-ScR
guidelines. We searched Embase, PubMed, Scopus, and Google Scholar to retrieve
relevant studies. We extracted data from 34 studies that fulfilled the
inclusion criteria. In our analysis, a typical workflow was observed: feeding
raw data, fusing different data modalities by applying conventional machine
learning (ML) or deep learning (DL) algorithms, and finally, evaluating the
multimodal fusion through clinical outcome predictions. Specifically, early
fusion was the most used technique in most applications for multimodal learning
(22 out of 34 studies). We found that multimodality fusion models outperformed
traditional single-modality models for the same task. Disease diagnosis and
prediction were the most common clinical outcomes (reported in 20 and 10
studies, respectively) from a clinical outcome perspective.",2022-10-23,2022,2022-10,medical
AI Ethics in Smart Healthcare,"This article reviews the landscape of ethical challenges of integrating
artificial intelligence (AI) into smart healthcare products, including medical
electronic devices. Differences between traditional ethics in the medical
domain and emerging ethical challenges with AI-driven healthcare are presented,
particularly as they relate to transparency, bias, privacy, safety,
responsibility, justice, and autonomy. Open challenges and recommendations are
outlined to enable the integration of ethical principles into the design,
validation, clinical trials, deployment, monitoring, repair, and retirement of
AI-based smart healthcare products.",2022-11-02,2022,2022-11,medical
"Spot the fake lungs: Generating Synthetic Medical Images using Neural
  Diffusion Models","Generative models are becoming popular for the synthesis of medical images.
Recently, neural diffusion models have demonstrated the potential to generate
photo-realistic images of objects. However, their potential to generate medical
images is not explored yet. In this work, we explore the possibilities of
synthesis of medical images using neural diffusion models. First, we use a
pre-trained DALLE2 model to generate lungs X-Ray and CT images from an input
text prompt. Second, we train a stable diffusion model with 3165 X-Ray images
and generate synthetic images. We evaluate the synthetic image data through a
qualitative analysis where two independent radiologists label randomly chosen
samples from the generated data as real, fake, or unsure. Results demonstrate
that images generated with the diffusion model can translate characteristics
that are otherwise very specific to certain medical conditions in chest X-Ray
or CT images. Careful tuning of the model can be very promising. To the best of
our knowledge, this is the first attempt to generate lungs X-Ray and CT images
using neural diffusion models. This work aims to introduce a new dimension in
artificial intelligence for medical imaging. Given that this is a new topic,
the paper will serve as an introduction and motivation for the research
community to explore the potential of diffusion models for medical image
synthesis. We have released the synthetic images on
https://www.kaggle.com/datasets/hazrat/awesomelungs.",2022-11-02,2022,2022-11,medical
"Explainable AI over the Internet of Things (IoT): Overview,
  State-of-the-Art and Future Directions","Explainable Artificial Intelligence (XAI) is transforming the field of
Artificial Intelligence (AI) by enhancing the trust of end-users in machines.
As the number of connected devices keeps on growing, the Internet of Things
(IoT) market needs to be trustworthy for the end-users. However, existing
literature still lacks a systematic and comprehensive survey work on the use of
XAI for IoT. To bridge this lacking, in this paper, we address the XAI
frameworks with a focus on their characteristics and support for IoT. We
illustrate the widely-used XAI services for IoT applications, such as security
enhancement, Internet of Medical Things (IoMT), Industrial IoT (IIoT), and
Internet of City Things (IoCT). We also suggest the implementation choice of
XAI models over IoT systems in these applications with appropriate examples and
summarize the key inferences for future works. Moreover, we present the
cutting-edge development in edge XAI structures and the support of
sixth-generation (6G) communication services for IoT applications, along with
key inferences. In a nutshell, this paper constitutes the first holistic
compilation on the development of XAI-based frameworks tailored for the demands
of future IoT use cases.",2022-11-02,2022,2022-11,medical
"Issues and Challenges in Applications of Artificial Intelligence to
  Nuclear Medicine -- The Bethesda Report (AI Summit 2022)","The SNMMI Artificial Intelligence (SNMMI-AI) Summit, organized by the SNMMI
AI Task Force, took place in Bethesda, MD on March 21-22, 2022. It brought
together various community members and stakeholders from academia, healthcare,
industry, patient representatives, and government (NIH, FDA), and considered
various key themes to envision and facilitate a bright future for routine,
trustworthy use of AI in nuclear medicine. In what follows, essential issues,
challenges, controversies and findings emphasized in the meeting are
summarized.",2022-11-07,2022,2022-11,medical
"Nested Named Entity Recognition from Medical Texts: An Adaptive Shared
  Network Architecture with Attentive CRF","Recognizing useful named entities plays a vital role in medical information
processing, which helps drive the development of medical area research. Deep
learning methods have achieved good results in medical named entity recognition
(NER). However, we find that existing methods face great challenges when
dealing with the nested named entities. In this work, we propose a novel
method, referred to as ASAC, to solve the dilemma caused by the nested
phenomenon, in which the core idea is to model the dependency between different
categories of entity recognition. The proposed method contains two key modules:
the adaptive shared (AS) part and the attentive conditional random field (ACRF)
module. The former part automatically assigns adaptive weights across each task
to achieve optimal recognition accuracy in the multi-layer network. The latter
module employs the attention operation to model the dependency between
different entities. In this way, our model could learn better entity
representations by capturing the implicit distinctions and relationships
between different categories of entities. Extensive experiments on public
datasets verify the effectiveness of our method. Besides, we also perform
ablation analyses to deeply understand our methods.",2022-11-09,2022,2022-11,medical
"MF2-MVQA: A Multi-stage Feature Fusion method for Medical Visual
  Question Answering","There is a key problem in the medical visual question answering task that how
to effectively realize the feature fusion of language and medical images with
limited datasets. In order to better utilize multi-scale information of medical
images, previous methods directly embed the multi-stage visual feature maps as
tokens of same size respectively and fuse them with text representation.
However, this will cause the confusion of visual features at different stages.
To this end, we propose a simple but powerful multi-stage feature fusion
method, MF2-MVQA, which stage-wise fuses multi-level visual features with
textual semantics. MF2-MVQA achieves the State-Of-The-Art performance on
VQA-Med 2019 and VQA-RAD dataset. The results of visualization also verify that
our model outperforms previous work.",2022-11-11,2022,2022-11,medical
"Secure and Privacy-Preserving Automated Machine Learning Operations into
  End-to-End Integrated IoT-Edge-Artificial Intelligence-Blockchain Monitoring
  System for Diabetes Mellitus Prediction","Diabetes Mellitus, one of the leading causes of death worldwide, has no cure
to date and can lead to severe health complications, such as retinopathy, limb
amputation, cardiovascular diseases, and neuronal disease, if left untreated.
Consequently, it becomes crucial to take precautionary measures to
avoid/predict the occurrence of diabetes. Machine learning approaches have been
proposed and evaluated in the literature for diabetes prediction. This paper
proposes an IoT-edge-Artificial Intelligence (AI)-blockchain system for
diabetes prediction based on risk factors. The proposed system is underpinned
by the blockchain to obtain a cohesive view of the risk factors data from
patients across different hospitals and to ensure security and privacy of the
user's data. Furthermore, we provide a comparative analysis of different
medical sensors, devices, and methods to measure and collect the risk factors
values in the system. Numerical experiments and comparative analysis were
carried out between our proposed system, using the most accurate random forest
(RF) model, and the two most used state-of-the-art machine learning approaches,
Logistic Regression (LR) and Support Vector Machine (SVM), using three
real-life diabetes datasets. The results show that the proposed system using RF
predicts diabetes with 4.57% more accuracy on average compared to LR and SVM,
with 2.87 times more execution time. Data balancing without feature selection
does not show significant improvement. The performance is improved by 1.14% and
0.02% after feature selection for PIMA Indian and Sylhet datasets respectively,
while it reduces by 0.89% for MIMIC III.",2022-11-13,2022,2022-11,medical
"Robust Alzheimer's Progression Modeling using Cross-Domain
  Self-Supervised Deep Learning","Developing successful artificial intelligence systems in practice depends on
both robust deep learning models and large, high-quality data. However,
acquiring and labeling data can be prohibitively expensive and time-consuming
in many real-world applications, such as clinical disease models.
Self-supervised learning has demonstrated great potential in increasing model
accuracy and robustness in small data regimes. In addition, many clinical
imaging and disease modeling applications rely heavily on regression of
continuous quantities. However, the applicability of self-supervised learning
for these medical-imaging regression tasks has not been extensively studied. In
this study, we develop a cross-domain self-supervised learning approach for
disease prognostic modeling as a regression problem using medical images as
input. We demonstrate that self-supervised pretraining can improve the
prediction of Alzheimer's Disease progression from brain MRI. We also show that
pretraining on extended (but not labeled) brain MRI data outperforms
pretraining on natural images. We further observe that the highest performance
is achieved when both natural images and extended brain-MRI data are used for
pretraining.",2022-11-15,2022,2022-11,medical
"Generalization of Artificial Intelligence Models in Medical Imaging: A
  Case-Based Review","The discussions around Artificial Intelligence (AI) and medical imaging are
centered around the success of deep learning algorithms. As new algorithms
enter the market, it is important for practicing radiologists to understand the
pitfalls of various AI algorithms. This entails having a basic understanding of
how algorithms are developed, the kind of data they are trained on, and the
settings in which they will be deployed. As with all new technologies, use of
AI should be preceded by a fundamental understanding of the risks and benefits
to those it is intended to help. This case-based review is intended to point
out specific factors practicing radiologists who intend to use AI should
consider.",2022-11-15,2022,2022-11,medical
"CDialog: A Multi-turn Covid-19 Conversation Dataset for Entity-Aware
  Dialog Generation","The development of conversational agents to interact with patients and
deliver clinical advice has attracted the interest of many researchers,
particularly in light of the COVID-19 pandemic. The training of an end-to-end
neural based dialog system, on the other hand, is hampered by a lack of
multi-turn medical dialog corpus. We make the very first attempt to release a
high-quality multi-turn Medical Dialog dataset relating to Covid-19 disease
named CDialog, with over 1K conversations collected from the online medical
counselling websites. We annotate each utterance of the conversation with seven
different categories of medical entities, including diseases, symptoms, medical
tests, medical history, remedies, medications and other aspects as additional
labels. Finally, we propose a novel neural medical dialog system based on the
CDialog dataset to advance future research on developing automated medical
dialog systems. We use pre-trained language models for dialogue generation,
incorporating annotated medical entities, to generate a virtual doctor's
response that addresses the patient's query. Experimental results show that the
proposed dialog models perform comparably better when supplemented with entity
information and hence can improve the response quality.",2022-11-16,2022,2022-11,medical
Vision Transformers in Medical Imaging: A Review,"Transformer, a model comprising attention-based encoder-decoder architecture,
have gained prevalence in the field of natural language processing (NLP) and
recently influenced the computer vision (CV) space. The similarities between
computer vision and medical imaging, reviewed the question among researchers if
the impact of transformers on computer vision be translated to medical imaging?
In this paper, we attempt to provide a comprehensive and recent review on the
application of transformers in medical imaging by; describing the transformer
model comparing it with a diversity of convolutional neural networks (CNNs),
detailing the transformer based approaches for medical image classification,
segmentation, registration and reconstruction with a focus on the image
modality, comparing the performance of state-of-the-art transformer
architectures to best performing CNNs on standard medical datasets.",2022-11-18,2022,2022-11,medical
"Social media mining for toxicovigilance of prescription medications:
  End-to-end pipeline, challenges and future work","Substance use, substance use disorder, and overdoses related to substance use
are major public health problems globally and in the United States. A key
aspect of addressing these problems from a public health standpoint is improved
surveillance. Traditional surveillance systems are laggy, and social media are
potentially useful sources of timely data. However, mining knowledge from
social media is challenging, and requires the development of advanced
artificial intelligence, specifically natural language processing (NLP) and
machine learning methods. We developed a sophisticated end-to-end pipeline for
mining information about nonmedical prescription medication use from social
media, namely Twitter and Reddit. Our pipeline employs supervised machine
learning and NLP for filtering out noise and characterizing the chatter. In
this paper, we describe our end-to-end pipeline developed over four years. In
addition to describing our data mining infrastructure, we discuss existing
challenges in social media mining for toxicovigilance, and possible future
research directions.",2022-11-18,2022,2022-11,medical
"Self-supervised vision-language pretraining for Medical visual question
  answering","Medical image visual question answering (VQA) is a task to answer clinical
questions, given a radiographic image, which is a challenging problem that
requires a model to integrate both vision and language information. To solve
medical VQA problems with a limited number of training data, pretrain-finetune
paradigm is widely used to improve the model generalization. In this paper, we
propose a self-supervised method that applies Masked image modeling, Masked
language modeling, Image text matching and Image text alignment via contrastive
learning (M2I2) for pretraining on medical image caption dataset, and finetunes
to downstream medical VQA tasks. The proposed method achieves state-of-the-art
performance on all the three public medical VQA datasets. Our codes and models
are available at https://github.com/pengfeiliHEU/M2I2.",2022-11-24,2022,2022-11,medical
Heterogeneous Graph Learning for Multi-modal Medical Data Analysis,"Routine clinical visits of a patient produce not only image data, but also
non-image data containing clinical information regarding the patient, i.e.,
medical data is multi-modal in nature. Such heterogeneous modalities offer
different and complementary perspectives on the same patient, resulting in more
accurate clinical decisions when they are properly combined. However, despite
its significance, how to effectively fuse the multi-modal medical data into a
unified framework has received relatively little attention. In this paper, we
propose an effective graph-based framework called HetMed (Heterogeneous Graph
Learning for Multi-modal Medical Data Analysis) for fusing the multi-modal
medical data. Specifically, we construct a multiplex network that incorporates
multiple types of non-image features of patients to capture the complex
relationship between patients in a systematic way, which leads to more accurate
clinical decisions. Extensive experiments on various real-world datasets
demonstrate the superiority and practicality of HetMed. The source code for
HetMed is available at https://github.com/Sein-Kim/Multimodal-Medical.",2022-11-28,2022,2022-11,medical
MED-SE: Medical Entity Definition-based Sentence Embedding,"We propose Medical Entity Definition-based Sentence Embedding (MED-SE), a
novel unsupervised contrastive learning framework designed for clinical texts,
which exploits the definitions of medical entities. To this end, we conduct an
extensive analysis of multiple sentence embedding techniques in clinical
semantic textual similarity (STS) settings. In the entity-centric setting that
we have designed, MED-SE achieves significantly better performance, while the
existing unsupervised methods including SimCSE show degraded performance. Our
experiments elucidate the inherent discrepancies between the general- and
clinical-domain texts, and suggest that entity-centric contrastive approaches
may help bridge this gap and lead to a better representation of clinical
sentences.",2022-12-09,2022,2022-12,medical
"Analysis of Explainable Artificial Intelligence Methods on Medical Image
  Classification","The use of deep learning in computer vision tasks such as image
classification has led to a rapid increase in the performance of such systems.
Due to this substantial increment in the utility of these systems, the use of
artificial intelligence in many critical tasks has exploded. In the medical
domain, medical image classification systems are being adopted due to their
high accuracy and near parity with human physicians in many tasks. However,
these artificial intelligence systems are extremely complex and are considered
black boxes by scientists, due to the difficulty in interpreting what exactly
led to the predictions made by these models. When these systems are being used
to assist high-stakes decision-making, it is extremely important to be able to
understand, verify and justify the conclusions reached by the model. The
research techniques being used to gain insight into the black-box models are in
the field of explainable artificial intelligence (XAI). In this paper, we
evaluated three different XAI methods across two convolutional neural network
models trained to classify lung cancer from histopathological images. We
visualized the outputs and analyzed the performance of these methods, in order
to better understand how to apply explainable artificial intelligence in the
medical domain.",2022-12-10,2022,2022-12,medical
Influence of AI in human lives,"Artificial Intelligence is one of the most significant and prominent
technological innovations which has reshaped all aspects of human life on the
lines of ease from magnitudes like shopping, data collection, driving, everyday
life, medical approach and many more. On the contrary, although recent
developments in both subjects that are backed by technology, progress on AI
alongside CE must have mostly been undertaken in isolation, providing little
understanding into how the two areas intersect. Artificial intelligence is now
widely used in services, from back-office tasks to front-line interactions with
customers. This trend has accelerated in recent years. Artificial intelligence
(AI)-based virtual assistants are changing successful engagement away from
being dominated by humans and toward being dominated by technologies. As a
result, people are expected to solve their own problems before calling customer
care representatives, eventually emerging as a crucial component of providing
services as value co-creators. AI-powered chats may potentially go awry, which
could enrage, perplex, and anger customers. Considering all these, the main
objectives of this study will engage the following
  1. To identify the alterations in the scope of human searches for information
offered by the application of AI?
  2. To analyse how AI helps in the way someone drives the car
  3. To evaluate how AI has changed the way customer interact with the
customers",2022-12-15,2022,2022-12,medical
"SADM: Sequence-Aware Diffusion Model for Longitudinal Medical Image
  Generation","Human organs constantly undergo anatomical changes due to a complex mix of
short-term (e.g., heartbeat) and long-term (e.g., aging) factors. Evidently,
prior knowledge of these factors will be beneficial when modeling their future
state, i.e., via image generation. However, most of the medical image
generation tasks only rely on the input from a single image, thus ignoring the
sequential dependency even when longitudinal data is available. Sequence-aware
deep generative models, where model input is a sequence of ordered and
timestamped images, are still underexplored in the medical imaging domain that
is featured by several unique challenges: 1) Sequences with various lengths; 2)
Missing data or frame, and 3) High dimensionality. To this end, we propose a
sequence-aware diffusion model (SADM) for the generation of longitudinal
medical images. Recently, diffusion models have shown promising results in
high-fidelity image generation. Our method extends this new technique by
introducing a sequence-aware transformer as the conditional module in a
diffusion model. The novel design enables learning longitudinal dependency even
with missing data during training and allows autoregressive generation of a
sequence of images during inference. Our extensive experiments on 3D
longitudinal medical images demonstrate the effectiveness of SADM compared with
baselines and alternative methods. The code is available at
https://github.com/ubc-tea/SADM-Longitudinal-Medical-Image-Generation.",2022-12-16,2022,2022-12,medical
"Annotation by Clicks: A Point-Supervised Contrastive Variance Method for
  Medical Semantic Segmentation","Medical image segmentation methods typically rely on numerous dense annotated
images for model training, which are notoriously expensive and time-consuming
to collect. To alleviate this burden, weakly supervised techniques have been
exploited to train segmentation models with less expensive annotations. In this
paper, we propose a novel point-supervised contrastive variance method (PSCV)
for medical image semantic segmentation, which only requires one pixel-point
from each organ category to be annotated. The proposed method trains the base
segmentation network by using a novel contrastive variance (CV) loss to exploit
the unlabeled pixels and a partial cross-entropy loss on the labeled pixels.
The CV loss function is designed to exploit the statistical spatial
distribution properties of organs in medical images and their variance
distribution map representations to enforce discriminative predictions over the
unlabeled pixels. Experimental results on two standard medical image datasets
demonstrate that the proposed method outperforms the state-of-the-art weakly
supervised methods on point-supervised medical image semantic segmentation
tasks.",2022-12-17,2022,2022-12,medical
"Local Differential Privacy Image Generation Using Flow-based Deep
  Generative Models","Diagnostic radiologists need artificial intelligence (AI) for medical
imaging, but access to medical images required for training in AI has become
increasingly restrictive. To release and use medical images, we need an
algorithm that can simultaneously protect privacy and preserve pathologies in
medical images. To develop such an algorithm, here, we propose DP-GLOW, a
hybrid of a local differential privacy (LDP) algorithm and one of the
flow-based deep generative models (GLOW). By applying a GLOW model, we
disentangle the pixelwise correlation of images, which makes it difficult to
protect privacy with straightforward LDP algorithms for images. Specifically,
we map images onto the latent vector of the GLOW model, each element of which
follows an independent normal distribution, and we apply the Laplace mechanism
to the latent vector. Moreover, we applied DP-GLOW to chest X-ray images to
generate LDP images while preserving pathologies.",2022-12-20,2022,2022-12,medical
"UnICLAM:Contrastive Representation Learning with Adversarial Masking for
  Unified and Interpretable Medical Vision Question Answering","Medical Visual Question Answering (Medical-VQA) aims to to answer clinical
questions regarding radiology images, assisting doctors with decision-making
options. Nevertheless, current Medical-VQA models learn cross-modal
representations through residing vision and texture encoders in dual separate
spaces, which lead to indirect semantic alignment. In this paper, we propose
UnICLAM, a Unified and Interpretable Medical-VQA model through Contrastive
Representation Learning with Adversarial Masking. Specifically, to learn an
aligned image-text representation, we first establish a unified dual-stream
pre-training structure with the gradually soft-parameter sharing strategy.
Technically, the proposed strategy learns a constraint for the vision and
texture encoders to be close in a same space, which is gradually loosened as
the higher number of layers. Moreover, for grasping the unified semantic
representation, we extend the adversarial masking data augmentation to the
contrastive representation learning of vision and text in a unified manner.
Concretely, while the encoder training minimizes the distance between original
and masking samples, the adversarial masking module keeps adversarial learning
to conversely maximize the distance. Furthermore, we also intuitively take a
further exploration to the unified adversarial masking augmentation model,
which improves the potential ante-hoc interpretability with remarkable
performance and efficiency. Experimental results on VQA-RAD and SLAKE public
benchmarks demonstrate that UnICLAM outperforms existing 11 state-of-the-art
Medical-VQA models. More importantly, we make an additional discussion about
the performance of UnICLAM in diagnosing heart failure, verifying that UnICLAM
exhibits superior few-shot adaption performance in practical disease diagnosis.",2022-12-21,2022,2022-12,medical
"A New Perspective to Boost Vision Transformer for Medical Image
  Classification","Transformer has achieved impressive successes for various computer vision
tasks. However, most of existing studies require to pretrain the Transformer
backbone on a large-scale labeled dataset (e.g., ImageNet) for achieving
satisfactory performance, which is usually unavailable for medical images.
Additionally, due to the gap between medical and natural images, the
improvement generated by the ImageNet pretrained weights significantly degrades
while transferring the weights to medical image processing tasks. In this
paper, we propose Bootstrap Own Latent of Transformer (BOLT), a self-supervised
learning approach specifically for medical image classification with the
Transformer backbone. Our BOLT consists of two networks, namely online and
target branches, for self-supervised representation learning. Concretely, the
online network is trained to predict the target network representation of the
same patch embedding tokens with a different perturbation. To maximally
excavate the impact of Transformer from limited medical data, we propose an
auxiliary difficulty ranking task. The Transformer is enforced to identify
which branch (i.e., online/target) is processing the more difficult perturbed
tokens. Overall, the Transformer endeavours itself to distill the
transformation-invariant features from the perturbed tokens to simultaneously
achieve difficulty measurement and maintain the consistency of self-supervised
representations. The proposed BOLT is evaluated on three medical image
processing tasks, i.e., skin lesion classification, knee fatigue fracture
grading and diabetic retinopathy grading. The experimental results validate the
superiority of our BOLT for medical image classification, compared to ImageNet
pretrained weights and state-of-the-art self-supervised learning approaches.",2023-01-03,2023,2023-01,medical
"Artificial Intelligence Model for Tumoral Clinical Decision Support
  Systems","Comparative diagnostic in brain tumor evaluation makes possible to use the
available information of a medical center to compare similar cases when a new
patient is evaluated. By leveraging Artificial Intelligence models, the
proposed system is able of retrieving the most similar cases of brain tumors
for a given query. The primary objective is to enhance the diagnostic process
by generating more accurate representations of medical images, with a
particular focus on patient-specific normal features and pathologies. The
proposed model uses Artificial Intelligence to detect patient features to
recommend the most similar cases from a database. The system not only suggests
similar cases but also balances the representation of healthy and abnormal
features in its design. This not only encourages the generalization of its use
but also aids clinicians in their decision-making processes. We conducted a
comparative analysis of our approach in relation to similar studies. The
proposed architecture obtains a Dice coefficient of 0.474 in both tumoral and
healthy regions of the patients, which outperforms previous literature. Our
proposed model excels at extracting and combining anatomical and pathological
features from brain \glspl{mr}, achieving state-of-the-art results while
relying on less expensive label information. This substantially reduces the
overall cost of the training process. This paper provides substantial grounds
for further exploration of the broader applicability and optimization of the
proposed architecture to enhance clinical decision-making. The novel approach
presented in this work marks a significant advancement in the field of medical
diagnosis, particularly in the context of Artificial Intelligence-assisted
image retrieval, and promises to reduce costs and improve the quality of
patient care using Artificial Intelligence as a support tool instead of a black
box system.",2023-01-09,2023,2023-01,medical
"Contrast with Major Classifier Vectors for Federated Medical Relation
  Extraction with Heterogeneous Label Distribution","Federated medical relation extraction enables multiple clients to train a
deep network collaboratively without sharing their raw medical data. In order
to handle the heterogeneous label distribution across clients, most of the
existing works only involve enforcing regularization between local and global
models during optimization. In this paper, we fully utilize the models of all
clients and propose a novel concept of \textit{major classifier vectors}, where
a group of class vectors is obtained in an ensemble rather than the weighted
average method on the server. The major classifier vectors are then distributed
to all clients and the local training of each client is Contrasted with Major
Classifier vectors (FedCMC), so the local model is not prone to overfitting to
the local label distribution. FedCMC requires only a small amount of additional
transfer of classifier parameters without any leakage of raw data, extracted
representations, and label distributions. Our extensive experiments show that
FedCMC outperforms the other state-of-the-art FL algorithms on three medical
relation extraction datasets.",2023-01-13,2023,2023-01,medical
"An Artificial Intelligence-based model for cell killing prediction:
  development, validation and explainability analysis of the ANAKIN model","The present work develops ANAKIN: an Artificial iNtelligence bAsed model for
(radiation induced) cell KIlliNg prediction. ANAKIN is trained and tested over
513 cell survival experiments with different types of radiation contained in
the publicly available PIDE database. We show how ANAKIN accurately predicts
several relevant biological endpoints over a wide broad range on ions beams and
for a high number of cell--lines. We compare the prediction of ANAKIN to the
only two radiobiological model for RBE prediction used in clinics, that is the
Microdosimetric Kinetic Model (MKM) and the Local Effect Model (LEM version
III), showing how ANAKIN has higher accuracy over the all considered biological
endpoints. At last, via modern techniques of Explainable Artificial
Intelligence (XAI), we show how ANAKIN predictions can be understood and
explained, highlighting how ANAKIN is in fact able to reproduce relevant
well-known biological patterns, such as the overkilling effect.",2023-01-19,2023,2023-01,medical
"Redesigning Electronic Health Record Systems to Support Developing
  Countries","Electronic Health Record (EHR) has become an essential tool in the healthcare
ecosystem, providing authorized clinicians with patients' health-related
information for better treatment. While most developed countries are taking
advantage of EHRs to improve their healthcare system, it remains challenging in
developing countries to support clinical decision-making and public health
using a computerized patient healthcare information system. This paper proposes
a novel EHR architecture suitable for developing countries--an architecture
that fosters inclusion and provides solutions tailored to all social classes
and socioeconomic statuses. Our architecture foresees an internet-free
(offline) solution to allow medical transactions between healthcare
organizations, and the storage of EHRs in geographically underserved and rural
areas. Moreover, we discuss how artificial intelligence can leverage anonymous
health-related information to enable better public health policy and
surveillance.",2023-01-31,2023,2023-01,medical
Leveraging Summary Guidance on Medical Report Summarization,"This study presents three deidentified large medical text datasets, named
DISCHARGE, ECHO and RADIOLOGY, which contain 50K, 16K and 378K pairs of report
and summary that are derived from MIMIC-III, respectively. We implement
convincing baselines of automated abstractive summarization on the proposed
datasets with pre-trained encoder-decoder language models, including BERT2BERT,
T5-large and BART. Further, based on the BART model, we leverage the sampled
summaries from the train set as prior knowledge guidance, for encoding
additional contextual representations of the guidance with the encoder and
enhancing the decoding representations in the decoder. The experimental results
confirm the improvement of ROUGE scores and BERTScore made by the proposed
method, outperforming the larger model T5-large.",2023-02-08,2023,2023-02,medical
Multi-Modal Evaluation Approach for Medical Image Segmentation,"Manual segmentation of medical images (e.g., segmenting tumors in CT scans)
is a high-effort task that can be accelerated with machine learning techniques.
However, selecting the right segmentation approach depends on the evaluation
function, particularly in medical image segmentation where we must deal with
dependency between voxels. For instance, in contrast to classical systems where
the predictions are either correct or incorrect, predictions in medical image
segmentation may be partially correct and incorrect simultaneously. In this
paper, we explore this expressiveness to extract the useful properties of these
systems and formally define a novel multi-modal evaluation (MME) approach to
measure the effectiveness of different segmentation methods. This approach
improves the segmentation evaluation by introducing new relevant and
interpretable characteristics, including detection property, boundary
alignment, uniformity, total volume, and relative volume. Our proposed approach
is open-source and publicly available for use. We have conducted several
reproducible experiments, including the segmentation of pancreas, liver tumors,
and multi-organs datasets, to show the applicability of the proposed approach.",2023-02-08,2023,2023-02,medical
"Informing clinical assessment by contextualizing post-hoc explanations
  of risk prediction models in type-2 diabetes","Medical experts may use Artificial Intelligence (AI) systems with greater
trust if these are supported by contextual explanations that let the
practitioner connect system inferences to their context of use. However, their
importance in improving model usage and understanding has not been extensively
studied. Hence, we consider a comorbidity risk prediction scenario and focus on
contexts regarding the patients clinical state, AI predictions about their risk
of complications, and algorithmic explanations supporting the predictions. We
explore how relevant information for such dimensions can be extracted from
Medical guidelines to answer typical questions from clinical practitioners. We
identify this as a question answering (QA) task and employ several
state-of-the-art LLMs to present contexts around risk prediction model
inferences and evaluate their acceptability. Finally, we study the benefits of
contextual explanations by building an end-to-end AI pipeline including data
cohorting, AI risk modeling, post-hoc model explanations, and prototyped a
visual dashboard to present the combined insights from different context
dimensions and data sources, while predicting and identifying the drivers of
risk of Chronic Kidney Disease - a common type-2 diabetes comorbidity. All of
these steps were performed in engagement with medical experts, including a
final evaluation of the dashboard results by an expert medical panel. We show
that LLMs, in particular BERT and SciBERT, can be readily deployed to extract
some relevant explanations to support clinical usage. To understand the
value-add of the contextual explanations, the expert panel evaluated these
regarding actionable insights in the relevant clinical setting. Overall, our
paper is one of the first end-to-end analyses identifying the feasibility and
benefits of contextual explanations in a real-world clinical use case.",2023-02-11,2023,2023-02,medical
Integrating Artificial Intelligence and Humanities in Healthcare,"Artificial Intelligence (AI) and Medical Humanities have become two of the
most crucial and rapidly growing fields in the current world. AI has made
substantial advancements in recent years, enabling the development of
algorithms and systems that can perform tasks traditionally done by humans.
Medical Humanities, on the other hand, is the intersection of medical sciences,
humanities, and the social sciences, and deals with the cultural, historical,
philosophical, ethical, and social aspects of health, illness, and medicine.
The integration of AI and Medical Humanities can offer innovative solutions to
some of the pressing issues in the medical field.",2023-02-13,2023,2023-02,medical
"RFC-Net: Learning High Resolution Global Features for Medical Image
  Segmentation on a Computational Budget","Learning High-Resolution representations is essential for semantic
segmentation. Convolutional neural network (CNN)architectures with downstream
and upstream propagation flow are popular for segmentation in medical
diagnosis. However, due to performing spatial downsampling and upsampling in
multiple stages, information loss is inexorable. On the contrary, connecting
layers densely on high spatial resolution is computationally expensive. In this
work, we devise a Loose Dense Connection Strategy to connect neurons in
subsequent layers with reduced parameters. On top of that, using a m-way Tree
structure for feature propagation we propose Receptive Field Chain Network
(RFC-Net) that learns high resolution global features on a compressed
computational space. Our experiments demonstrates that RFC-Net achieves
state-of-the-art performance on Kvasir and CVC-ClinicDB benchmarks for Polyp
segmentation.",2023-02-13,2023,2023-02,medical
"Validation of artificial intelligence containing products across the
  regulated healthcare industries","Purpose: The introduction of artificial intelligence / machine learning
(AI/ML) products to the regulated fields of pharmaceutical research and
development (R&D) and drug manufacture, and medical devices (MD) and in-vitro
diagnostics (IVD), poses new regulatory problems: a lack of a common
terminology and understanding leads to confusion, delays and product failures.
Validation as a key step in product development, common to each of these
sectors including computerized systems and AI/ML development, offers an
opportune point of comparison for aligning people and processes for
cross-sectoral product development.
  Methods: A comparative approach, built upon workshops and a subsequent
written sequence of exchanges, summarized in a look-up table suitable for
mixed-teams work.
  Results: 1. A bottom-up, definitions led, approach which leads to a
distinction between broad vs narrow validation, and their relationship to
regulatory regimes. 2. Common basis introduction to the primary methodologies
for AI-containing software validation. 3. Pharmaceutical drug development and
MD/IVD specific perspectives on compliant AI software development, as a basis
for collaboration.
  Conclusions: Alignment of the terms and methodologies used in validation of
software products containing artificial intelligence / machine learning (AI/ML)
components across the regulated industries of human health is a vital first
step in streamlining processes and improving workflows.",2023-02-13,2023,2023-02,medical
Tailoring Requirements Engineering for Responsible AI,"Requirements Engineering (RE) is the discipline for identifying, analyzing,
as well as ensuring the implementation and delivery of user, technical, and
societal requirements. Recently reported issues concerning the acceptance of
Artificial Intelligence (AI) solutions after deployment, e.g. in the medical,
automotive, or scientific domains, stress the importance of RE for designing
and delivering Responsible AI systems. In this paper, we argue that RE should
not only be carefully conducted but also tailored for Responsible AI. We
outline related challenges for research and practice.",2023-02-21,2023,2023-02,medical
Medical visual question answering using joint self-supervised learning,"Visual Question Answering (VQA) becomes one of the most active research
problems in the medical imaging domain. A well-known VQA challenge is the
intrinsic diversity between the image and text modalities, and in the medical
VQA task, there is another critical problem relying on the limited size of
labelled image-question-answer data. In this study we propose an
encoder-decoder framework that leverages the image-text joint representation
learned from large-scaled medical image-caption data and adapted to the
small-sized medical VQA task. The encoder embeds across the image-text dual
modalities with self-attention mechanism and is independently pre-trained on
the large-scaled medical image-caption dataset by multiple self-supervised
learning tasks. Then the decoder is connected to the top of the encoder and
fine-tuned using the small-sized medical VQA dataset. The experiment results
present that our proposed method achieves better performance comparing with the
baseline and SOTA methods.",2023-02-25,2023,2023-02,medical
"Improving Medical Speech-to-Text Accuracy with Vision-Language
  Pre-training Model","Automatic Speech Recognition (ASR) is a technology that converts spoken words
into text, facilitating interaction between humans and machines. One of the
most common applications of ASR is Speech-To-Text (STT) technology, which
simplifies user workflows by transcribing spoken words into text. In the
medical field, STT has the potential to significantly reduce the workload of
clinicians who rely on typists to transcribe their voice recordings. However,
developing an STT model for the medical domain is challenging due to the lack
of sufficient speech and text datasets. To address this issue, we propose a
medical-domain text correction method that modifies the output text of a
general STT system using the Vision Language Pre-training (VLP) method. VLP
combines textual and visual information to correct text based on image
knowledge. Our extensive experiments demonstrate that the proposed method
offers quantitatively and clinically significant improvements in STT
performance in the medical field. We further show that multi-modal
understanding of image and text information outperforms single-modal
understanding using only text information.",2023-02-27,2023,2023-02,medical
"Practical Statistical Considerations for the Clinical Validation of
  AI/ML-enabled Medical Diagnostic Devices","Artificial Intelligence (AI) and Machine-Learning (ML) models have been
increasingly used in medical products, such as medical device software. General
considerations on the statistical aspects for the evaluation of AI/ML-enabled
medical diagnostic devices are discussed in this paper. We also provide
relevant academic references and note good practices in addressing various
statistical challenges in the clinical validation of AI/ML-enabled medical
devices in the context of their intended use.",2023-03-02,2023,2023-03,medical
"Decision Support System for Chronic Diseases Based on Drug-Drug
  Interactions","Many patients with chronic diseases resort to multiple medications to relieve
various symptoms, which raises concerns about the safety of multiple medication
use, as severe drug-drug antagonism can lead to serious adverse effects or even
death. This paper presents a Decision Support System, called DSSDDI, based on
drug-drug interactions to support doctors prescribing decisions. DSSDDI
contains three modules, Drug-Drug Interaction (DDI) module, Medical Decision
(MD) module and Medical Support (MS) module. The DDI module learns safer and
more effective drug representations from the drug-drug interactions. To capture
the potential causal relationship between DDI and medication use, the MD module
considers the representations of patients and drugs as context, DDI and
patients' similarity as treatment, and medication use as outcome to construct
counterfactual links for the representation learning. Furthermore, the MS
module provides drug candidates to doctors with explanations. Experiments on
the chronic data collected from the Hong Kong Chronic Disease Study Project and
a public diagnostic data MIMIC-III demonstrate that DSSDDI can be a reliable
reference for doctors in terms of safety and efficiency of clinical diagnosis,
with significant improvements compared to baseline methods.",2023-03-04,2023,2023-03,medical
A Comparison of Methods for Neural Network Aggregation,"Deep learning has been successful in the theoretical aspect. For deep
learning to succeed in industry, we need to have algorithms capable of handling
many inconsistencies appearing in real data. These inconsistencies can have
large effects on the implementation of a deep learning algorithm. Artificial
Intelligence is currently changing the medical industry. However, receiving
authorization to use medical data for training machine learning algorithms is a
huge hurdle. A possible solution is sharing the data without sharing the
patient information. We propose a multi-party computation protocol for the deep
learning algorithm. The protocol enables to conserve both the privacy and the
security of the training data. Three approaches of neural networks assembly are
analyzed: transfer learning, average ensemble learning, and series network
learning. The results are compared to approaches based on data-sharing in
different experiments. We analyze the security issues of the proposed protocol.
Although the analysis is based on medical data, the results of multi-party
computation of machine learning training are theoretical and can be implemented
in multiple research areas.",2023-03-06,2023,2023-03,medical
"Cybersecurity of AI medical devices: risks, legislation, and challenges","Medical devices and artificial intelligence systems rapidly transform
healthcare provisions. At the same time, due to their nature, AI in or as
medical devices might get exposed to cyberattacks, leading to patient safety
and security risks. This book chapter is divided into three parts. The first
part starts by setting the scene where we explain the role of cybersecurity in
healthcare. Then, we briefly define what we refer to when we talk about AI that
is considered a medical device by itself or supports one. To illustrate the
risks such medical devices pose, we provide three examples: the poisoning of
datasets, social engineering, and data or source code extraction. In the second
part, the paper provides an overview of the European Union's regulatory
framework relevant for ensuring the cybersecurity of AI as or in medical
devices (MDR, NIS Directive, Cybersecurity Act, GDPR, the AI Act proposal and
the NIS 2 Directive proposal). Finally, the third part of the paper examines
possible challenges stemming from the EU regulatory framework. In particular,
we look toward the challenges deriving from the two legislative proposals and
their interaction with the existing legislation concerning AI medical devices'
cybersecurity. They are structured as answers to the following questions: (1)
how will the AI Act interact with the MDR regarding the cybersecurity and
safety requirements?; (2) how should we interpret incident notification
requirements from the NIS 2 Directive proposal and MDR?; and (3) what are the
consequences of the evolving term of critical infrastructures?
  [This is a draft chapter. The final version will be available in Research
Handbook on Health, AI and the Law edited by Barry Solaiman & I. Glenn Cohen,
forthcoming 2023, Edward Elgar Publishing Ltd]",2023-03-06,2023,2023-03,medical
Emerging AI Technologies Inspiring the Next Generation of E-textiles,"The smart textile and wearables sector is looking towards advancing
technologies to meet both industry, consumer and new emerging innovative
textile application demands, within a fast paced textile industry. In parallel
inspiration based on the biological neural workings of the human brain is
driving the next generation of artificial intelligence. Artificial intelligence
inspired hardware (neuromorphic computing) and software modules mimicking the
processing capabilities and properties of neural networks and the human nervous
system are taking shape. The textile sector needs to actively look at such
emerging and new technologies taking inspiration from their workings and
processing methods in order to stimulate new and innovative embedded
intelligence advancements in the etextile world. This emerging next generation
of Artificial intelligence(AI) is rapidly gaining interest across varying
industries (textile, medical, automotive, aerospace, military). How such
properties can inspire and drive advancements within the etextiles sector needs
to be considered. This paper will provide an insight into current
nanotechnology and artificial intelligence advancements in the etextiles domain
before focusing specifically on the future vision and direction around the
potential application of neuromorphic computing and spiking neural network
inspired AI technologies within the textile sector. We investigate the core
architectural elements of artificial neural networks, neuromorphic computing
and how such neuroscience inspired technologies could impact and inspire change
and new research developments within the e-textile sector.",2023-03-06,2023,2023-03,medical
Towards Trust of Explainable AI in Thyroid Nodule Diagnosis,"The ability to explain the prediction of deep learning models to end-users is
an important feature to leverage the power of artificial intelligence (AI) for
the medical decision-making process, which is usually considered
non-transparent and challenging to comprehend. In this paper, we apply
state-of-the-art eXplainable artificial intelligence (XAI) methods to explain
the prediction of the black-box AI models in the thyroid nodule diagnosis
application. We propose new statistic-based XAI methods, namely Kernel Density
Estimation and Density map, to explain the case of no nodule detected. XAI
methods' performances are considered under a qualitative and quantitative
comparison as feedback to improve the data quality and the model performance.
Finally, we survey to assess doctors' and patients' trust in XAI explanations
of the model's decisions on thyroid nodule images.",2023-03-08,2023,2023-03,medical
"Contextualized Medication Information Extraction Using Transformer-based
  Deep Learning Architectures","Objective: To develop a natural language processing (NLP) system to extract
medications and contextual information that help understand drug changes. This
project is part of the 2022 n2c2 challenge.
  Materials and methods: We developed NLP systems for medication mention
extraction, event classification (indicating medication changes discussed or
not), and context classification to classify medication changes context into 5
orthogonal dimensions related to drug changes. We explored 6 state-of-the-art
pretrained transformer models for the three subtasks, including GatorTron, a
large language model pretrained using >90 billion words of text (including >80
billion words from >290 million clinical notes identified at the University of
Florida Health). We evaluated our NLP systems using annotated data and
evaluation scripts provided by the 2022 n2c2 organizers.
  Results:Our GatorTron models achieved the best F1-scores of 0.9828 for
medication extraction (ranked 3rd), 0.9379 for event classification (ranked
2nd), and the best micro-average accuracy of 0.9126 for context classification.
GatorTron outperformed existing transformer models pretrained using smaller
general English text and clinical text corpora, indicating the advantage of
large language models.
  Conclusion: This study demonstrated the advantage of using large transformer
models for contextual medication information extraction from clinical
narratives.",2023-03-14,2023,2023-03,medical
"Hybrid Classic-Quantum Computing for Staging of Invasive Ductal
  Carcinoma of Breast","Despite the great current relevance of Artificial Intelligence, and the
extraordinary innovations that this discipline has brought to many fields
-among which, without a doubt, medicine is found-, experts in medical
applications of Artificial Intelligence are looking for new alternatives to
solve problems for which current Artificial Intelligence programs do not
provide with optimal solutions. For this, one promising option could be the use
of the concepts and ideas of Quantum Mechanics, for the construction of
quantum-based Artificial Intelligence systems. From a hybrid classical-quantum
perspective, this article deals with the application of quantum computing
techniques for the staging of Invasive Ductal Carcinoma of the breast. It
includes: (1) a general explanation of a classical, and well-established,
approach for medical reasoning, (2) a description of the clinical problem, (3)
a conceptual model for staging invasive ductal carcinoma, (4) some basic
notions about Quantum Rule-Based Systems, (5) a step-by-step explanation of the
proposed approach for quantum staging of the invasive ductal carcinoma, and (6)
the results obtained after running the quantum system on a significant number
of use cases. A detailed discussion is also provided at the end of this paper.",2023-03-17,2023,2023-03,medical
Multimodal Information Fusion For The Diagnosis Of Diabetic Retinopathy,"Diabetes is a chronic disease characterized by excess sugar in the blood and
affects 422 million people worldwide, including 3.3 million in France. One of
the frequent complications of diabetes is diabetic retinopathy (DR): it is the
leading cause of blindness in the working population of developed countries. As
a result, ophthalmology is on the verge of a revolution in screening,
diagnosing, and managing of pathologies. This upheaval is led by the arrival of
technologies based on artificial intelligence. The ""Evaluation intelligente de
la r\'etinopathie diab\'etique"" (EviRed) project uses artificial intelligence
to answer a medical need: replacing the current classification of diabetic
retinopathy which is mainly based on outdated fundus photography and providing
an insufficient prediction precision. EviRed exploits modern fundus imaging
devices and artificial intelligence to properly integrate the vast amount of
data they provide with other available medical data of the patient. The goal is
to improve diagnosis and prediction and help ophthalmologists to make better
decisions during diabetic retinopathy follow-up. In this study, we investigate
the fusion of different modalities acquired simultaneously with a PLEXElite
9000 (Carl Zeiss Meditec Inc. Dublin, California, USA), namely 3-D structural
optical coherence tomography (OCT), 3-D OCT angiography (OCTA) and 2-D Line
Scanning Ophthalmoscope (LSO), for the automatic detection of proliferative DR.",2023-03-20,2023,2023-03,medical
"How can Deep Learning Retrieve the Write-Missing Additional Diagnosis
  from Chinese Electronic Medical Record For DRG","The purpose of write-missing diagnosis detection is to find diseases that
have been clearly diagnosed from medical records but are missed in the
discharge diagnosis. Unlike the definition of missed diagnosis, the
write-missing diagnosis is clearly manifested in the medical record without
further reasoning. The write-missing diagnosis is a common problem, often
caused by physician negligence. The write-missing diagnosis will result in an
incomplete diagnosis of medical records. While under DRG grouping, the
write-missing diagnoses will miss important additional diagnoses (CC, MCC),
thus affecting the correct rate of DRG enrollment.
  Under the circumstance that countries generally start to adopt DRG enrollment
and payment, the problem of write-missing diagnosis is a common and serious
problem. The current manual-based method is expensive due to the complex
content of the full medical record. We think this problem is suitable to be
solved as natural language processing. But to the best of our knowledge, no
researchers have conducted research on this problem based on natural language
processing methods.
  We propose a framework for solving the problem of write-missing diagnosis,
which mainly includes three modules: disease recall module, disease context
logic judgment module, and disease relationship comparison module. Through this
framework, we verify that the problem of write-missing diagnosis can be solved
well, and the results are interpretable. At the same time, we propose advanced
solutions for the disease context logic judgment module and disease
relationship comparison module, which have obvious advantages compared with the
mainstream methods of the same type of problems. Finally, we verified the value
of our proposed framework under DRG medical insurance payment in a tertiary
hospital.",2023-03-28,2023,2023-03,medical
"A New Deep Learning and XAI-Based Algorithm for Features Selection in
  Genomics","In the field of functional genomics, the analysis of gene expression profiles
through Machine and Deep Learning is increasingly providing meaningful insight
into a number of diseases. The paper proposes a novel algorithm to perform
Feature Selection on genomic-scale data, which exploits the reconstruction
capabilities of autoencoders and an ad-hoc defined Explainable Artificial
Intelligence-based score in order to select the most informative genes for
diagnosis, prognosis, and precision medicine. Results of the application on a
Chronic Lymphocytic Leukemia dataset evidence the effectiveness of the
algorithm, by identifying and suggesting a set of meaningful genes for further
medical investigation.",2023-03-29,2023,2023-03,medical
"Demo Alleviate: Demonstrating Artificial Intelligence Enabled Virtual
  Assistance for Telehealth: The Mental Health Case","After the pandemic, artificial intelligence (AI) powered support for mental
health care has become increasingly important. The breadth and complexity of
significant challenges required to provide adequate care involve: (a)
Personalized patient understanding, (b) Safety-constrained and medically
validated chatbot patient interactions, and (c) Support for continued
feedback-based refinements in design using chatbot-patient interactions. We
propose Alleviate, a chatbot designed to assist patients suffering from mental
health challenges with personalized care and assist clinicians with
understanding their patients better. Alleviate draws from an array of publicly
available clinically valid mental-health texts and databases, allowing
Alleviate to make medically sound and informed decisions. In addition,
Alleviate's modular design and explainable decision-making lends itself to
robust and continued feedback-based refinements to its design. In this paper,
we explain the different modules of Alleviate and submit a short video
demonstrating Alleviate's capabilities to help patients and clinicians
understand each other better to facilitate optimal care strategies.",2023-03-31,2023,2023-03,medical
Medical Pathologies Prediction : Systematic Review and Proposed Approach,"The healthcare sector is an important pillar of every community, numerous
research studies have been carried out in this context to optimize medical
processes and improve care quality and facilitate patient management. In this
article we have analyzed and examined different works concerning the
exploitation of the most recent technologies such as big data, artificial
intelligence, machine learning, and deep learning for the improvement of health
care, which enabled us to propose our general approach concentrating on the
collection, preprocessing and clustering of medical data to facilitate access,
after analysis, to the patients and health professionals to predict the most
frequent pathologies with better precision within a notable timeframe.
  keywords: Healthcare, big data, artificial intelligence, automatic language
processing, data mining, predictive models.",2023-04-01,2023,2023-04,medical
Q2ATransformer: Improving Medical VQA via an Answer Querying Decoder,"Medical Visual Question Answering (VQA) systems play a supporting role to
understand clinic-relevant information carried by medical images. The questions
to a medical image include two categories: close-end (such as Yes/No question)
and open-end. To obtain answers, the majority of the existing medical VQA
methods relies on classification approaches, while a few works attempt to use
generation approaches or a mixture of the two. The classification approaches
are relatively simple but perform poorly on long open-end questions. To bridge
this gap, in this paper, we propose a new Transformer based framework for
medical VQA (named as Q2ATransformer), which integrates the advantages of both
the classification and the generation approaches and provides a unified
treatment for the close-end and open-end questions. Specifically, we introduce
an additional Transformer decoder with a set of learnable candidate answer
embeddings to query the existence of each answer class to a given
image-question pair. Through the Transformer attention, the candidate answer
embeddings interact with the fused features of the image-question pair to make
the decision. In this way, despite being a classification-based approach, our
method provides a mechanism to interact with the answer information for
prediction like the generation-based approaches. On the other hand, by
classification, we mitigate the task difficulty by reducing the search space of
answers. Our method achieves new state-of-the-art performance on two medical
VQA benchmarks. Especially, for the open-end questions, we achieve 79.19% on
VQA-RAD and 54.85% on PathVQA, with 16.09% and 41.45% absolute improvements,
respectively.",2023-04-04,2023,2023-04,medical
"ACTION++: Improving Semi-supervised Medical Image Segmentation with
  Adaptive Anatomical Contrast","Medical data often exhibits long-tail distributions with heavy class
imbalance, which naturally leads to difficulty in classifying the minority
classes (i.e., boundary regions or rare objects). Recent work has significantly
improved semi-supervised medical image segmentation in long-tailed scenarios by
equipping them with unsupervised contrastive criteria. However, it remains
unclear how well they will perform in the labeled portion of data where class
distribution is also highly imbalanced. In this work, we present ACTION++, an
improved contrastive learning framework with adaptive anatomical contrast for
semi-supervised medical segmentation. Specifically, we propose an adaptive
supervised contrastive loss, where we first compute the optimal locations of
class centers uniformly distributed on the embedding space (i.e., off-line),
and then perform online contrastive matching training by encouraging different
class features to adaptively match these distinct and uniformly distributed
class centers. Moreover, we argue that blindly adopting a constant temperature
$\tau$ in the contrastive loss on long-tailed medical data is not optimal, and
propose to use a dynamic $\tau$ via a simple cosine schedule to yield better
separation between majority and minority classes. Empirically, we evaluate
ACTION++ on ACDC and LA benchmarks and show that it achieves state-of-the-art
across two semi-supervised settings. Theoretically, we analyze the performance
of adaptive anatomical contrast and confirm its superiority in label
efficiency.",2023-04-05,2023,2023-04,medical
"Implicit Anatomical Rendering for Medical Image Segmentation with
  Stochastic Experts","Integrating high-level semantically correlated contents and low-level
anatomical features is of central importance in medical image segmentation.
Towards this end, recent deep learning-based medical segmentation methods have
shown great promise in better modeling such information. However, convolution
operators for medical segmentation typically operate on regular grids, which
inherently blur the high-frequency regions, i.e., boundary regions. In this
work, we propose MORSE, a generic implicit neural rendering framework designed
at an anatomical level to assist learning in medical image segmentation. Our
method is motivated by the fact that implicit neural representation has been
shown to be more effective in fitting complex signals and solving computer
graphics problems than discrete grid-based representation. The core of our
approach is to formulate medical image segmentation as a rendering problem in
an end-to-end manner. Specifically, we continuously align the coarse
segmentation prediction with the ambiguous coordinate-based point
representations and aggregate these features to adaptively refine the boundary
region. To parallelly optimize multi-scale pixel-level features, we leverage
the idea from Mixture-of-Expert (MoE) to design and train our MORSE with a
stochastic gating mechanism. Our experiments demonstrate that MORSE can work
well with different medical segmentation backbones, consistently achieving
competitive performance improvements in both 2D and 3D supervised medical
segmentation methods. We also theoretically analyze the superiority of MORSE.",2023-04-06,2023,2023-04,medical
Transformer Utilization in Medical Image Segmentation Networks,"Owing to success in the data-rich domain of natural images, Transformers have
recently become popular in medical image segmentation. However, the pairing of
Transformers with convolutional blocks in varying architectural permutations
leaves their relative effectiveness to open interpretation. We introduce
Transformer Ablations that replace the Transformer blocks with plain linear
operators to quantify this effectiveness. With experiments on 8 models on 2
medical image segmentation tasks, we explore -- 1) the replaceable nature of
Transformer-learnt representations, 2) Transformer capacity alone cannot
prevent representational replaceability and works in tandem with effective
design, 3) The mere existence of explicit feature hierarchies in transformer
blocks is more beneficial than accompanying self-attention modules, 4) Major
spatial downsampling before Transformer modules should be used with caution.",2023-04-09,2023,2023-04,medical
"FrenchMedMCQA: A French Multiple-Choice Question Answering Dataset for
  Medical domain","This paper introduces FrenchMedMCQA, the first publicly available
Multiple-Choice Question Answering (MCQA) dataset in French for medical domain.
It is composed of 3,105 questions taken from real exams of the French medical
specialization diploma in pharmacy, mixing single and multiple answers. Each
instance of the dataset contains an identifier, a question, five possible
answers and their manual correction(s). We also propose first baseline models
to automatically process this MCQA task in order to report on the current
performances and to highlight the difficulty of the task. A detailed analysis
of the results showed that it is necessary to have representations adapted to
the medical domain or to the MCQA task: in our case, English specialized models
yielded better results than generic French ones, even though FrenchMedMCQA is
in French. Corpus, models and tools are available online.",2023-04-09,2023,2023-04,medical
"BerDiff: Conditional Bernoulli Diffusion Model for Medical Image
  Segmentation","Medical image segmentation is a challenging task with inherent ambiguity and
high uncertainty, attributed to factors such as unclear tumor boundaries and
multiple plausible annotations. The accuracy and diversity of segmentation
masks are both crucial for providing valuable references to radiologists in
clinical practice. While existing diffusion models have shown strong capacities
in various visual generation tasks, it is still challenging to deal with
discrete masks in segmentation. To achieve accurate and diverse medical image
segmentation masks, we propose a novel conditional Bernoulli Diffusion model
for medical image segmentation (BerDiff). Instead of using the Gaussian noise,
we first propose to use the Bernoulli noise as the diffusion kernel to enhance
the capacity of the diffusion model for binary segmentation tasks, resulting in
more accurate segmentation masks. Second, by leveraging the stochastic nature
of the diffusion model, our BerDiff randomly samples the initial Bernoulli
noise and intermediate latent variables multiple times to produce a range of
diverse segmentation masks, which can highlight salient regions of interest
that can serve as valuable references for radiologists. In addition, our
BerDiff can efficiently sample sub-sequences from the overall trajectory of the
reverse diffusion, thereby speeding up the segmentation process. Extensive
experimental results on two medical image segmentation datasets with different
modalities demonstrate that our BerDiff outperforms other recently published
state-of-the-art methods. Our results suggest diffusion models could serve as a
strong backbone for medical image segmentation.",2023-04-10,2023,2023-04,medical
"MedAlpaca -- An Open-Source Collection of Medical Conversational AI
  Models and Training Data","As large language models (LLMs) like OpenAI's GPT series continue to make
strides, we witness the emergence of artificial intelligence applications in an
ever-expanding range of fields. In medicine, these LLMs hold considerable
promise for improving medical workflows, diagnostics, patient care, and
education. Yet, there is an urgent need for open-source models that can be
deployed on-premises to safeguard patient privacy. In our work, we present an
innovative dataset consisting of over 160,000 entries, specifically crafted to
fine-tune LLMs for effective medical applications. We investigate the impact of
fine-tuning these datasets on publicly accessible pre-trained LLMs, and
subsequently, we juxtapose the performance of pre-trained-only models against
the fine-tuned models concerning the examinations that future medical doctors
must pass to achieve certification.",2023-04-14,2023,2023-04,medical
Medical Question Summarization with Entity-driven Contrastive Learning,"By summarizing longer consumer health questions into shorter and essential
ones, medical question answering (MQA) systems can more accurately understand
consumer intentions and retrieve suitable answers. However, medical question
summarization is very challenging due to obvious distinctions in health trouble
descriptions from patients and doctors. Although existing works have attempted
to utilize Seq2Seq, reinforcement learning, or contrastive learning to solve
the problem, two challenges remain: how to correctly capture question focus to
model its semantic intention, and how to obtain reliable datasets to fairly
evaluate performance. To address these challenges, this paper proposes a novel
medical question summarization framework using entity-driven contrastive
learning (ECL). ECL employs medical entities in frequently asked questions
(FAQs) as focuses and devises an effective mechanism to generate hard negative
samples. This approach forces models to pay attention to the crucial focus
information and generate more ideal question summarization. Additionally, we
find that some MQA datasets suffer from serious data leakage problems, such as
the iCliniq dataset's 33% duplicate rate. To evaluate the related methods
fairly, this paper carefully checks leaked samples to reorganize more
reasonable datasets. Extensive experiments demonstrate that our ECL method
outperforms state-of-the-art methods by accurately capturing question focus and
generating medical question summaries. The code and datasets are available at
https://github.com/yrbobo/MQS-ECL.",2023-04-15,2023,2023-04,medical
Segment Anything Model for Medical Image Analysis: an Experimental Study,"Training segmentation models for medical images continues to be challenging
due to the limited availability of data annotations. Segment Anything Model
(SAM) is a foundation model that is intended to segment user-defined objects of
interest in an interactive manner. While the performance on natural images is
impressive, medical image domains pose their own set of challenges. Here, we
perform an extensive evaluation of SAM's ability to segment medical images on a
collection of 19 medical imaging datasets from various modalities and
anatomies. We report the following findings: (1) SAM's performance based on
single prompts highly varies depending on the dataset and the task, from
IoU=0.1135 for spine MRI to IoU=0.8650 for hip X-ray. (2) Segmentation
performance appears to be better for well-circumscribed objects with prompts
with less ambiguity and poorer in various other scenarios such as the
segmentation of brain tumors. (3) SAM performs notably better with box prompts
than with point prompts. (4) SAM outperforms similar methods RITM, SimpleClick,
and FocalClick in almost all single-point prompt settings. (5) When
multiple-point prompts are provided iteratively, SAM's performance generally
improves only slightly while other methods' performance improves to the level
that surpasses SAM's point-based performance. We also provide several
illustrations for SAM's performance on all tested datasets, iterative
segmentation, and SAM's behavior given prompt ambiguity. We conclude that SAM
shows impressive zero-shot segmentation performance for certain medical imaging
datasets, but moderate to poor performance for others. SAM has the potential to
make a significant impact in automated medical image segmentation in medical
imaging, but appropriate care needs to be applied when using it.",2023-04-20,2023,2023-04,medical
"Input Augmentation with SAM: Boosting Medical Image Segmentation with
  Segmentation Foundation Model","The Segment Anything Model (SAM) is a recently developed large model for
general-purpose segmentation for computer vision tasks. SAM was trained using
11 million images with over 1 billion masks and can produce segmentation
results for a wide range of objects in natural scene images. SAM can be viewed
as a general perception model for segmentation (partitioning images into
semantically meaningful regions). Thus, how to utilize such a large foundation
model for medical image segmentation is an emerging research target. This paper
shows that although SAM does not immediately give high-quality segmentation for
medical image data, its generated masks, features, and stability scores are
useful for building and training better medical image segmentation models. In
particular, we demonstrate how to use SAM to augment image input for
commonly-used medical image segmentation models (e.g., U-Net). Experiments on
three segmentation tasks show the effectiveness of our proposed SAMAug method.
The code is available at \url{https://github.com/yizhezhang2000/SAMAug}.",2023-04-22,2023,2023-04,medical
Differentiate ChatGPT-generated and Human-written Medical Texts,"Background: Large language models such as ChatGPT are capable of generating
grammatically perfect and human-like text content, and a large number of
ChatGPT-generated texts have appeared on the Internet. However, medical texts
such as clinical notes and diagnoses require rigorous validation, and erroneous
medical content generated by ChatGPT could potentially lead to disinformation
that poses significant harm to healthcare and the general public.
  Objective: This research is among the first studies on responsible and
ethical AIGC (Artificial Intelligence Generated Content) in medicine. We focus
on analyzing the differences between medical texts written by human experts and
generated by ChatGPT, and designing machine learning workflows to effectively
detect and differentiate medical texts generated by ChatGPT.
  Methods: We first construct a suite of datasets containing medical texts
written by human experts and generated by ChatGPT. In the next step, we analyze
the linguistic features of these two types of content and uncover differences
in vocabulary, part-of-speech, dependency, sentiment, perplexity, etc. Finally,
we design and implement machine learning methods to detect medical text
generated by ChatGPT.
  Results: Medical texts written by humans are more concrete, more diverse, and
typically contain more useful information, while medical texts generated by
ChatGPT pay more attention to fluency and logic, and usually express general
terminologies rather than effective information specific to the context of the
problem. A BERT-based model can effectively detect medical texts generated by
ChatGPT, and the F1 exceeds 95%.",2023-04-23,2023,2023-04,medical
"A optimization framework for herbal prescription planning based on deep
  reinforcement learning","Treatment planning for chronic diseases is a critical task in medical
artificial intelligence, particularly in traditional Chinese medicine (TCM).
However, generating optimized sequential treatment strategies for patients with
chronic diseases in different clinical encounters remains a challenging issue
that requires further exploration. In this study, we proposed a TCM herbal
prescription planning framework based on deep reinforcement learning for
chronic disease treatment (PrescDRL). PrescDRL is a sequential herbal
prescription optimization model that focuses on long-term effectiveness rather
than achieving maximum reward at every step, thereby ensuring better patient
outcomes. We constructed a high-quality benchmark dataset for sequential
diagnosis and treatment of diabetes and evaluated PrescDRL against this
benchmark. Our results showed that PrescDRL achieved a higher curative effect,
with the single-step reward improving by 117% and 153% compared to doctors.
Furthermore, PrescDRL outperformed the benchmark in prescription prediction,
with precision improving by 40.5% and recall improving by 63%. Overall, our
study demonstrates the potential of using artificial intelligence to improve
clinical intelligent diagnosis and treatment in TCM.",2023-04-25,2023,2023-04,medical
"Towards Medical Artificial General Intelligence via Knowledge-Enhanced
  Multimodal Pretraining","Medical artificial general intelligence (MAGI) enables one foundation model
to solve different medical tasks, which is very practical in the medical
domain. It can significantly reduce the requirement of large amounts of
task-specific data by sufficiently sharing medical knowledge among different
tasks. However, due to the challenges of designing strongly generalizable
models with limited and complex medical data, most existing approaches tend to
develop task-specific models. To take a step towards MAGI, we propose a new
paradigm called Medical-knOwledge-enhanced mulTimOdal pretRaining (MOTOR). In
MOTOR, we combine two kinds of basic medical knowledge, i.e., general and
specific knowledge, in a complementary manner to boost the general pretraining
process. As a result, the foundation model with comprehensive basic knowledge
can learn compact representations from pretraining radiographic data for better
cross-modal alignment. MOTOR unifies the understanding and generation, which
are two kinds of core intelligence of an AI system, into a single medical
foundation model, to flexibly handle more diverse medical tasks. To enable a
comprehensive evaluation and facilitate further research, we construct a
medical multimodal benchmark including a wide range of downstream tasks, such
as chest x-ray report generation and medical visual question answering.
Extensive experiments on our benchmark show that MOTOR obtains promising
results through simple task-oriented adaptation. The visualization shows that
the injected knowledge successfully highlights key information in the medical
data, demonstrating the excellent interpretability of MOTOR. Our MOTOR
successfully mimics the human practice of fulfilling a ""medical student"" to
accelerate the process of becoming a ""specialist"". We believe that our work
makes a significant stride in realizing MAGI.",2023-04-26,2023,2023-04,medical
"Zero-shot performance of the Segment Anything Model (SAM) in 2D medical
  imaging: A comprehensive evaluation and practical guidelines","Segmentation in medical imaging is a critical component for the diagnosis,
monitoring, and treatment of various diseases and medical conditions.
Presently, the medical segmentation landscape is dominated by numerous
specialized deep learning models, each fine-tuned for specific segmentation
tasks and image modalities. The recently-introduced Segment Anything Model
(SAM) employs the ViT neural architecture and harnesses a massive training
dataset to segment nearly any object; however, its suitability to the medical
domain has not yet been investigated. In this study, we explore the zero-shot
performance of SAM in medical imaging by implementing eight distinct prompt
strategies across six datasets from four imaging modalities, including X-ray,
ultrasound, dermatoscopy, and colonoscopy. Our findings reveal that SAM's
zero-shot performance is not only comparable to, but in certain cases,
surpasses the current state-of-the-art. Based on these results, we propose
practical guidelines that require minimal interaction while consistently
yielding robust outcomes across all assessed contexts. The source code, along
with a demonstration of the recommended guidelines, can be accessed at
https://github.com/Malta-Lab/SAM-zero-shot-in-Medical-Imaging.",2023-04-28,2023,2023-04,medical
"DIAMANT: Dual Image-Attention Map Encoders For Medical Image
  Segmentation","Although purely transformer-based architectures showed promising performance
in many computer vision tasks, many hybrid models consisting of CNN and
transformer blocks are introduced to fit more specialized tasks. Nevertheless,
despite the performance gain of both pure and hybrid transformer-based
architectures compared to CNNs in medical imaging segmentation, their high
training cost and complexity make it challenging to use them in real scenarios.
In this work, we propose simple architectures based on purely convolutional
layers, and show that by just taking advantage of the attention map
visualizations obtained from a self-supervised pretrained vision transformer
network (e.g., DINO) one can outperform complex transformer-based networks with
much less computation costs. The proposed architecture is composed of two
encoder branches with the original image as input in one branch and the
attention map visualizations of the same image from multiple self-attention
heads from a pre-trained DINO model (as multiple channels) in the other branch.
The results of our experiments on two publicly available medical imaging
datasets show that the proposed pipeline outperforms U-Net and the
state-of-the-art medical image segmentation models.",2023-04-28,2023,2023-04,medical
SCOPE: Structural Continuity Preservation for Medical Image Segmentation,"Although the preservation of shape continuity and physiological anatomy is a
natural assumption in the segmentation of medical images, it is often neglected
by deep learning methods that mostly aim for the statistical modeling of input
data as pixels rather than interconnected structures. In biological structures,
however, organs are not separate entities; for example, in reality, a severed
vessel is an indication of an underlying problem, but traditional segmentation
models are not designed to strictly enforce the continuity of anatomy,
potentially leading to inaccurate medical diagnoses. To address this issue, we
propose a graph-based approach that enforces the continuity and connectivity of
anatomical topology in medical images. Our method encodes the continuity of
shapes as a graph constraint, ensuring that the network's predictions maintain
this continuity. We evaluate our method on two public benchmarks on retinal
vessel segmentation, showing significant improvements in connectivity metrics
compared to traditional methods while getting better or on-par performance on
segmentation metrics.",2023-04-28,2023,2023-04,medical
SAM on Medical Images: A Comprehensive Study on Three Prompt Modes,"The Segment Anything Model (SAM) made an eye-catching debut recently and
inspired many researchers to explore its potential and limitation in terms of
zero-shot generalization capability. As the first promptable foundation model
for segmentation tasks, it was trained on a large dataset with an unprecedented
number of images and annotations. This large-scale dataset and its promptable
nature endow the model with strong zero-shot generalization. Although the SAM
has shown competitive performance on several datasets, we still want to
investigate its zero-shot generalization on medical images. As we know, the
acquisition of medical image annotation usually requires a lot of effort from
professional practitioners. Therefore, if there exists a foundation model that
can give high-quality mask prediction simply based on a few point prompts, this
model will undoubtedly become the game changer for medical image analysis. To
evaluate whether SAM has the potential to become the foundation model for
medical image segmentation tasks, we collected more than 12 public medical
image datasets that cover various organs and modalities. We also explore what
kind of prompt can lead to the best zero-shot performance with different
modalities. Furthermore, we find that a pattern shows that the perturbation of
the box size will significantly change the prediction accuracy. Finally,
Extensive experiments show that the predicted mask quality varied a lot among
different datasets. And providing proper prompts, such as bounding boxes, to
the SAM will significantly increase its performance.",2023-04-28,2023,2023-04,medical
"Generating medically-accurate summaries of patient-provider dialogue: A
  multi-stage approach using large language models","A medical provider's summary of a patient visit serves several critical
purposes, including clinical decision-making, facilitating hand-offs between
providers, and as a reference for the patient. An effective summary is required
to be coherent and accurately capture all the medically relevant information in
the dialogue, despite the complexity of patient-generated language. Even minor
inaccuracies in visit summaries (for example, summarizing ""patient does not
have a fever"" when a fever is present) can be detrimental to the outcome of
care for the patient.
  This paper tackles the problem of medical conversation summarization by
discretizing the task into several smaller dialogue-understanding tasks that
are sequentially built upon. First, we identify medical entities and their
affirmations within the conversation to serve as building blocks. We study
dynamically constructing few-shot prompts for tasks by conditioning on relevant
patient information and use GPT-3 as the backbone for our experiments. We also
develop GPT-derived summarization metrics to measure performance against
reference summaries quantitatively. Both our human evaluation study and metrics
for medical correctness show that summaries generated using this approach are
clinically accurate and outperform the baseline approach of summarizing the
dialog in a zero-shot, single-prompt setting.",2023-05-10,2023,2023-05,medical
"MedGPTEval: A Dataset and Benchmark to Evaluate Responses of Large
  Language Models in Medicine","METHODS: First, a set of evaluation criteria is designed based on a
comprehensive literature review. Second, existing candidate criteria are
optimized for using a Delphi method by five experts in medicine and
engineering. Third, three clinical experts design a set of medical datasets to
interact with LLMs. Finally, benchmarking experiments are conducted on the
datasets. The responses generated by chatbots based on LLMs are recorded for
blind evaluations by five licensed medical experts. RESULTS: The obtained
evaluation criteria cover medical professional capabilities, social
comprehensive capabilities, contextual capabilities, and computational
robustness, with sixteen detailed indicators. The medical datasets include
twenty-seven medical dialogues and seven case reports in Chinese. Three
chatbots are evaluated, ChatGPT by OpenAI, ERNIE Bot by Baidu Inc., and Doctor
PuJiang (Dr. PJ) by Shanghai Artificial Intelligence Laboratory. Experimental
results show that Dr. PJ outperforms ChatGPT and ERNIE Bot in both
multiple-turn medical dialogue and case report scenarios.",2023-05-12,2023,2023-05,medical
eXplainable Artificial Intelligence on Medical Images: A Survey,"Over the last few years, the number of works about deep learning applied to
the medical field has increased enormously. The necessity of a rigorous
assessment of these models is required to explain these results to all people
involved in medical exams. A recent field in the machine learning area is
explainable artificial intelligence, also known as XAI, which targets to
explain the results of such black box models to permit the desired assessment.
This survey analyses several recent studies in the XAI field applied to medical
diagnosis research, allowing some explainability of the machine learning
results in several different diseases, such as cancers and COVID-19.",2023-05-12,2023,2023-05,medical
"Towards Expert-Level Medical Question Answering with Large Language
  Models","Recent artificial intelligence (AI) systems have reached milestones in ""grand
challenges"" ranging from Go to protein-folding. The capability to retrieve
medical knowledge, reason over it, and answer medical questions comparably to
physicians has long been viewed as one such grand challenge.
  Large language models (LLMs) have catalyzed significant progress in medical
question answering; Med-PaLM was the first model to exceed a ""passing"" score in
US Medical Licensing Examination (USMLE) style questions with a score of 67.2%
on the MedQA dataset. However, this and other prior work suggested significant
room for improvement, especially when models' answers were compared to
clinicians' answers. Here we present Med-PaLM 2, which bridges these gaps by
leveraging a combination of base LLM improvements (PaLM 2), medical domain
finetuning, and prompting strategies including a novel ensemble refinement
approach.
  Med-PaLM 2 scored up to 86.5% on the MedQA dataset, improving upon Med-PaLM
by over 19% and setting a new state-of-the-art. We also observed performance
approaching or exceeding state-of-the-art across MedMCQA, PubMedQA, and MMLU
clinical topics datasets.
  We performed detailed human evaluations on long-form questions along multiple
axes relevant to clinical applications. In pairwise comparative ranking of 1066
consumer medical questions, physicians preferred Med-PaLM 2 answers to those
produced by physicians on eight of nine axes pertaining to clinical utility (p
< 0.001). We also observed significant improvements compared to Med-PaLM on
every evaluation axis (p < 0.001) on newly introduced datasets of 240 long-form
""adversarial"" questions to probe LLM limitations.
  While further studies are necessary to validate the efficacy of these models
in real-world settings, these results highlight rapid progress towards
physician-level performance in medical question answering.",2023-05-16,2023,2023-05,medical
"Trustworthy Privacy-preserving Hierarchical Ensemble and Federated
  Learning in Healthcare 4.0 with Blockchain","The advancement of Internet and Communication Technologies (ICTs) has led to
the era of Industry 4.0. This shift is followed by healthcare industries
creating the term Healthcare 4.0. In Healthcare 4.0, the use of IoT-enabled
medical imaging devices for early disease detection has enabled medical
practitioners to increase healthcare institutions' quality of service. However,
Healthcare 4.0 is still lagging in Artificial Intelligence and big data
compared to other Industry 4.0 due to data privacy concerns. In addition,
institutions' diverse storage and computing capabilities restrict institutions
from incorporating the same training model structure. This paper presents a
secure multi-party computation-based ensemble federated learning with
blockchain that enables heterogeneous models to collaboratively learn from
healthcare institutions' data without violating users' privacy. Blockchain
properties also allow the party to enjoy data integrity without trust in a
centralized server while also providing each healthcare institution with
auditability and version control capability.",2023-05-16,2023,2023-05,medical
PMC-VQA: Visual Instruction Tuning for Medical Visual Question Answering,"Medical Visual Question Answering (MedVQA) presents a significant opportunity
to enhance diagnostic accuracy and healthcare delivery by leveraging artificial
intelligence to interpret and answer questions based on medical images. In this
study, we reframe the problem of MedVQA as a generation task that naturally
follows the human-machine interaction and propose a generative-based model for
medical visual understanding by aligning visual information from a pre-trained
vision encoder with a large language model. We establish a scalable pipeline to
construct a large-scale medical visual question-answering dataset, named
PMC-VQA, which contains 227k VQA pairs of 149k images that cover various
modalities or diseases. We train the proposed model on PMC-VQA and then
fine-tune it on multiple public benchmarks, e.g., VQA-RAD, SLAKE, and
Image-Clef-2019, significantly outperforming existing MedVQA models in
generating relevant, accurate free-form answers. In addition, we propose a test
set that has undergone manual verification, which is significantly more
challenging, serving to better monitor the development of generative MedVQA
methods. To facilitate comprehensive evaluation and comparison, we have
maintained a leaderboard at
https://paperswithcode.com/paper/pmc-vqa-visual-instruction-tuning-for-medical,
offering a centralized resource for tracking progress and benchmarking
state-of-the-art approaches. The PMC-VQA dataset emerges as a vital resource
for the field of research, and the MedVInT presents a significant breakthrough
in the area of MedVQA.",2023-05-17,2023,2023-05,medical
Taxonomy of AISecOps Threat Modeling for Cloud Based Medical Chatbots,"Artificial Intelligence (AI) is playing a vital role in all aspects of
technology including cyber security. Application of Conversational AI like the
chatbots are also becoming very popular in the medical field to provide timely
and immediate medical assistance to patients in need. As medical chatbots deal
with a lot of sensitive information, the security of these chatbots is crucial.
To secure the confidentiality, integrity, and availability of cloud-hosted
assets like these, medical chatbots can be monitored using AISecOps (Artificial
Intelligence for Secure IT Operations). AISecOPs is an emerging field that
integrates three different but interrelated domains like the IT operation, AI,
and security as one domain, where the expertise from all these three domains
are used cohesively to secure the cyber assets. It considers cloud operations
and security in a holistic framework to collect the metrics required to assess
the security threats and train the AI models to take immediate actions. This
work is focused on applying the STRIDE threat modeling framework to model the
possible threats involved in each component of the chatbot to enable the
automatic threat detection using the AISecOps techniques. This threat modeling
framework is tailored to the medical chatbots that involves sensitive data
sharing but could also be applied for chatbots used in other sectors like the
financial services, public sector, and government sectors that are concerned
with security and compliance.",2023-05-18,2023,2023-05,medical
"MedLens: Improve Mortality Prediction Via Medical Signs Selecting and
  Regression","Monitoring the health status of patients and predicting mortality in advance
is vital for providing patients with timely care and treatment. Massive medical
signs in electronic health records (EHR) are fitted into advanced machine
learning models to make predictions. However, the data-quality problem of
original clinical signs is less discussed in the literature. Based on an
in-depth measurement of the missing rate and correlation score across various
medical signs and a large amount of patient hospital admission records, we
discovered the comprehensive missing rate is extremely high, and a large number
of useless signs could hurt the performance of prediction models. Then we
concluded that only improving data-quality could improve the baseline accuracy
of different prediction algorithms. We designed MEDLENS, with an automatic
vital medical signs selection approach via statistics and a flexible
interpolation approach for high missing rate time series. After augmenting the
data-quality of original medical signs, MEDLENS applies ensemble classifiers to
boost the accuracy and reduce the computation overhead at the same time. It
achieves a very high accuracy performance of 0.96 AUC-ROC and 0.81 AUC-PR,
which exceeds the previous benchmark.",2023-05-19,2023,2023-05,medical
"PlugMed: Improving Specificity in Patient-Centered Medical Dialogue
  Generation using In-Context Learning","The patient-centered medical dialogue systems strive to offer diagnostic
interpretation services to users who are less knowledgeable about medical
knowledge, through emphasizing the importance of providing responses specific
to the patients. It is difficult for the large language models (LLMs) to
guarantee the specificity of responses in spite of its promising performance
even in some tasks in medical field. Inspired by in-context learning, we
propose PlugMed, a Plug-and-Play Medical Dialogue System, for addressing this
challenge. PlugMed is equipped with two modules, the prompt generation (PG)
module and the response ranking (RR) module, to enhances LLMs' dialogue
strategies for improving the specificity of the dialogue. The PG module is
designed to stimulate the imitative ability of LLMs by providing them with real
dialogues from similar patients as prompts. The RR module incorporates
fine-tuned small model as response filter to enable the selection of
appropriate responses generated by LLMs. Furthermore, we introduce a new
evaluation method based on matching both user's intent and high-frequency
medical term to effectively assess the specificity of the responses. We conduct
experimental evaluations on three medical dialogue datasets, and the results,
including both automatic and human evaluation, demonstrate the effectiveness of
our approach.",2023-05-19,2023,2023-05,medical
"Enhancing Small Medical Learners with Privacy-preserving Contextual
  Prompting","Large language models (LLMs) demonstrate remarkable medical expertise, but
data privacy concerns impede their direct use in healthcare environments.
Although offering improved data privacy protection, domain-specific small
language models (SLMs) often underperform LLMs, emphasizing the need for
methods that reduce this performance gap while alleviating privacy concerns. In
this paper, we present a simple yet effective method that harnesses LLMs'
medical proficiency to boost SLM performance in medical tasks under
privacy-restricted scenarios. Specifically, we mitigate patient privacy issues
by extracting keywords from medical data and prompting the LLM to generate a
medical knowledge-intensive context by simulating clinicians' thought
processes. This context serves as additional input for SLMs, augmenting their
decision-making capabilities. Our method significantly enhances performance in
both few-shot and full training settings across three medical
knowledge-intensive tasks, achieving up to a 22.57% increase in absolute
accuracy compared to SLM fine-tuning without context, and sets new
state-of-the-art results in two medical tasks within privacy-restricted
scenarios. Further out-of-domain testing and experiments in two general domain
datasets showcase its generalizability and broad applicability. Our code can be
found at https://github.com/XZhang97666/PrivacyBoost-SLM.",2023-05-22,2023,2023-05,medical
Medical Dialogue Generation via Dual Flow Modeling,"Medical dialogue systems (MDS) aim to provide patients with medical services,
such as diagnosis and prescription. Since most patients cannot precisely
describe their symptoms, dialogue understanding is challenging for MDS.
Previous studies mainly addressed this by extracting the mentioned medical
entities as critical dialogue history information. In this work, we argue that
it is also essential to capture the transitions of the medical entities and the
doctor's dialogue acts in each turn, as they help the understanding of how the
dialogue flows and enhance the prediction of the entities and dialogue acts to
be adopted in the following turn. Correspondingly, we propose a Dual Flow
enhanced Medical (DFMed) dialogue generation framework. It extracts the medical
entities and dialogue acts used in the dialogue history and models their
transitions with an entity-centric graph flow and a sequential act flow,
respectively. We employ two sequential models to encode them and devise an
interweaving component to enhance their interactions. Experiments on two
datasets demonstrate that our method exceeds baselines in both automatic and
manual evaluations.",2023-05-29,2023,2023-05,medical
"Med-UniC: Unifying Cross-Lingual Medical Vision-Language Pre-Training by
  Diminishing Bias","The scarcity of data presents a critical obstacle to the efficacy of medical
visionlanguage pre-training (VLP). A potential solution lies in the combination
of datasets from various language communities. Nevertheless, the main challenge
stems from the complexity of integrating diverse syntax and semantics,
language-specific medical terminology, and culture-specific implicit knowledge.
Therefore, one crucial aspect to consider is the presence of community bias
caused by different languages. This paper presents a novel framework named
Unifying Cross-Lingual Medical Vision-Language Pre-Training (Med-UniC),
designed to integrate multimodal medical data from the two most prevalent
languages, English and Spanish. Specifically, we propose Cross-lingual Text
Alignment Regularization (CTR) to explicitly unify cross-lingual semantic
representations of medical reports originating from diverse language
communities. CTR is optimized through latent language disentanglement,
rendering our optimization objective to not depend on negative samples, thereby
significantly mitigating the bias from determining positive-negative sample
pairs within analogous medical reports. Furthermore, it ensures that the
cross-lingual representation is not biased toward any specific language
community. Med-UniC reaches superior performance across 5 medical image tasks
and 10 datasets encompassing over 30 diseases, offering a versatile framework
for unifying multi-modal medical data within diverse linguistic communities.
The experimental outcomes highlight the presence of community bias in
cross-lingual VLP. Reducing this bias enhances the performance not only in
vision-language tasks but also in uni-modal visual tasks.",2023-05-31,2023,2023-05,medical
"DKINet: Medication Recommendation via Domain Knowledge Informed Deep
  Learning","Medication recommendation is a fundamental yet crucial branch of healthcare
that presents opportunities to assist physicians in making more accurate
medication prescriptions for patients with complex health conditions. Previous
studies have primarily focused on learning patient representation from
electronic health records (EHR). While considering the clinical manifestations
of the patient is important, incorporating domain-specific prior knowledge is
equally significant in diagnosing the patient's health conditions. However,
effectively integrating domain knowledge with the patient's clinical
manifestations can be challenging, particularly when dealing with complex
clinical manifestations. Therefore, in this paper, we first identify
comprehensive domain-specific prior knowledge, namely the Unified Medical
Language System (UMLS), which is a comprehensive repository of biomedical
vocabularies and standards, for knowledge extraction. Subsequently, we propose
a knowledge injection module that addresses the effective integration of domain
knowledge with complex clinical manifestations, enabling an effective
characterization of the health conditions of the patient. Furthermore,
considering the significant impact of a patient's medication history on their
current medication, we introduce a historical medication-aware patient
representation module to capture the longitudinal influence of historical
medication information on the representation of current patients. Extensive
experiments on three publicly benchmark datasets verify the superiority of our
proposed method, which outperformed other methods by a significant margin. The
code is available at: https://github.com/sherry6247/DKINet.",2023-05-31,2023,2023-05,medical
"XAI Renaissance: Redefining Interpretability in Medical Diagnostic
  Models","As machine learning models become increasingly prevalent in medical
diagnostics, the need for interpretability and transparency becomes paramount.
The XAI Renaissance signifies a significant shift in the field, aiming to
redefine the interpretability of medical diagnostic models. This paper explores
the innovative approaches and methodologies within the realm of Explainable AI
(XAI) that are revolutionizing the interpretability of medical diagnostic
models. By shedding light on the underlying decision-making process, XAI
techniques empower healthcare professionals to understand, trust, and
effectively utilize these models for accurate and reliable medical diagnoses.
This review highlights the key advancements in XAI for medical diagnostics and
their potential to transform the healthcare landscape, ultimately improving
patient outcomes and fostering trust in AI-driven diagnostic systems.",2023-06-02,2023,2023-06,medical
"Case Studies on X-Ray Imaging, MRI and Nuclear Imaging","The field of medical imaging is an essential aspect of the medical sciences,
involving various forms of radiation to capture images of the internal tissues
and organs of the body. These images provide vital information for clinical
diagnosis, and in this chapter, we will explore the use of X-ray, MRI, and
nuclear imaging in detecting severe illnesses. However, manual evaluation and
storage of these images can be a challenging and time-consuming process. To
address this issue, artificial intelligence (AI)-based techniques, particularly
deep learning (DL), have become increasingly popular for systematic feature
extraction and classification from imaging modalities, thereby aiding doctors
in making rapid and accurate diagnoses. In this review study, we will focus on
how AI-based approaches, particularly the use of Convolutional Neural Networks
(CNN), can assist in disease detection through medical imaging technology. CNN
is a commonly used approach for image analysis due to its ability to extract
features from raw input images, and as such, will be the primary area of
discussion in this study. Therefore, we have considered CNN as our discussion
area in this study to diagnose ailments using medical imaging technology.",2023-06-03,2023,2023-06,medical
"Generative Text-Guided 3D Vision-Language Pretraining for Unified
  Medical Image Segmentation","Vision-Language Pretraining (VLP) has demonstrated remarkable capabilities in
learning visual representations from textual descriptions of images without
annotations. Yet, effective VLP demands large-scale image-text pairs, a
resource that suffers scarcity in the medical domain. Moreover, conventional
VLP is limited to 2D images while medical images encompass diverse modalities,
often in 3D, making the learning process more challenging. To address these
challenges, we present Generative Text-Guided 3D Vision-Language Pretraining
for Unified Medical Image Segmentation (GTGM), a framework that extends of VLP
to 3D medical images without relying on paired textual descriptions.
Specifically, GTGM utilizes large language models (LLM) to generate
medical-style text from 3D medical images. This synthetic text is then used to
supervise 3D visual representation learning. Furthermore, a negative-free
contrastive learning objective strategy is introduced to cultivate consistent
visual representations between augmented 3D medical image patches, which
effectively mitigates the biases associated with strict positive-negative
sample pairings. We evaluate GTGM on three imaging modalities - Computed
Tomography (CT), Magnetic Resonance Imaging (MRI), and electron microscopy (EM)
over 13 datasets. GTGM's superior performance across various medical image
segmentation tasks underscores its effectiveness and versatility, by enabling
VLP extension into 3D medical imagery while bypassing the need for paired text.",2023-06-07,2023,2023-06,medical
AutoML Systems For Medical Imaging,"The integration of machine learning in medical image analysis can greatly
enhance the quality of healthcare provided by physicians. The combination of
human expertise and computerized systems can result in improved diagnostic
accuracy. An automated machine learning approach simplifies the creation of
custom image recognition models by utilizing neural architecture search and
transfer learning techniques. Medical imaging techniques are used to
non-invasively create images of internal organs and body parts for diagnostic
and procedural purposes. This article aims to highlight the potential
applications, strategies, and techniques of AutoML in medical imaging through
theoretical and empirical evidence.",2023-06-07,2023,2023-06,medical
XInsight: Revealing Model Insights for GNNs with Flow-based Explanations,"Progress in graph neural networks has grown rapidly in recent years, with
many new developments in drug discovery, medical diagnosis, and recommender
systems. While this progress is significant, many networks are `black boxes'
with little understanding of the `what' exactly the network is learning. Many
high-stakes applications, such as drug discovery, require human-intelligible
explanations from the models so that users can recognize errors and discover
new knowledge. Therefore, the development of explainable AI algorithms is
essential for us to reap the benefits of AI.
  We propose an explainability algorithm for GNNs called eXplainable Insight
(XInsight) that generates a distribution of model explanations using GFlowNets.
Since GFlowNets generate objects with probabilities proportional to a reward,
XInsight can generate a diverse set of explanations, compared to previous
methods that only learn the maximum reward sample. We demonstrate XInsight by
generating explanations for GNNs trained on two graph classification tasks:
classifying mutagenic compounds with the MUTAG dataset and classifying acyclic
graphs with a synthetic dataset that we have open-sourced. We show the utility
of XInsight's explanations by analyzing the generated compounds using QSAR
modeling, and we find that XInsight generates compounds that cluster by
lipophilicity, a known correlate of mutagenicity. Our results show that
XInsight generates a distribution of explanations that uncovers the underlying
relationships demonstrated by the model. They also highlight the importance of
generating a diverse set of explanations, as it enables us to discover hidden
relationships in the model and provides valuable guidance for further analysis.",2023-06-07,2023,2023-06,medical
Artificial General Intelligence for Medical Imaging Analysis,"Large-scale Artificial General Intelligence (AGI) models, including Large
Language Models (LLMs) such as ChatGPT/GPT-4, have achieved unprecedented
success in a variety of general domain tasks. Yet, when applied directly to
specialized domains like medical imaging, which require in-depth expertise,
these models face notable challenges arising from the medical field's inherent
complexities and unique characteristics. In this review, we delve into the
potential applications of AGI models in medical imaging and healthcare, with a
primary focus on LLMs, Large Vision Models, and Large Multimodal Models. We
provide a thorough overview of the key features and enabling techniques of LLMs
and AGI, and further examine the roadmaps guiding the evolution and
implementation of AGI models in the medical sector, summarizing their present
applications, potentialities, and associated challenges. In addition, we
highlight potential future research directions, offering a holistic view on
upcoming ventures. This comprehensive review aims to offer insights into the
future implications of AGI in medical imaging, healthcare, and beyond.",2023-06-08,2023,2023-06,medical
"Customizing General-Purpose Foundation Models for Medical Report
  Generation","Medical caption prediction which can be regarded as a task of medical report
generation (MRG), requires the automatic generation of coherent and accurate
captions for the given medical images. However, the scarcity of labelled
medical image-report pairs presents great challenges in the development of deep
and large-scale neural networks capable of harnessing the potential artificial
general intelligence power like large language models (LLMs). In this work, we
propose customizing off-the-shelf general-purpose large-scale pre-trained
models, i.e., foundation models (FMs), in computer vision and natural language
processing with a specific focus on medical report generation. Specifically,
following BLIP-2, a state-of-the-art vision-language pre-training approach, we
introduce our encoder-decoder-based MRG model. This model utilizes a
lightweight query Transformer to connect two FMs: the giant vision Transformer
EVA-ViT-g and a bilingual LLM trained to align with human intentions (referred
to as ChatGLM-6B). Furthermore, we conduct ablative experiments on the
trainable components of the model to identify the crucial factors for effective
transfer learning. Our findings demonstrate that unfreezing EVA-ViT-g to learn
medical image representations, followed by parameter-efficient training of
ChatGLM-6B to capture the writing styles of medical reports, is essential for
achieving optimal results. Our best attempt (PCLmed Team) achieved the 4th and
the 2nd, respectively, out of 13 participating teams, based on the BERTScore
and ROUGE-1 metrics, in the ImageCLEFmedical Caption 2023 Caption Prediction
Task competition.",2023-06-09,2023,2023-06,medical
"Medical Data Augmentation via ChatGPT: A Case Study on Medication
  Identification and Medication Event Classification","The identification of key factors such as medications, diseases, and
relationships within electronic health records and clinical notes has a wide
range of applications in the clinical field. In the N2C2 2022 competitions,
various tasks were presented to promote the identification of key factors in
electronic health records (EHRs) using the Contextualized Medication Event
Dataset (CMED). Pretrained large language models (LLMs) demonstrated
exceptional performance in these tasks. This study aims to explore the
utilization of LLMs, specifically ChatGPT, for data augmentation to overcome
the limited availability of annotated data for identifying the key factors in
EHRs. Additionally, different pre-trained BERT models, initially trained on
extensive datasets like Wikipedia and MIMIC, were employed to develop models
for identifying these key variables in EHRs through fine-tuning on augmented
datasets. The experimental results of two EHR analysis tasks, namely medication
identification and medication event classification, indicate that data
augmentation based on ChatGPT proves beneficial in improving performance for
both medication identification and medication event classification.",2023-06-10,2023,2023-06,medical
"Online learning for X-ray, CT or MRI","Medical imaging plays an important role in the medical sector in identifying
diseases. X-ray, computed tomography (CT) scans, and magnetic resonance imaging
(MRI) are a few examples of medical imaging. Most of the time, these imaging
techniques are utilized to examine and diagnose diseases. Medical professionals
identify the problem after analyzing the images. However, manual identification
can be challenging because the human eye is not always able to recognize
complex patterns in an image. Because of this, it is difficult for any
professional to recognize a disease with rapidity and accuracy. In recent
years, medical professionals have started adopting Computer-Aided Diagnosis
(CAD) systems to evaluate medical images. This system can analyze the image and
detect the disease very precisely and quickly. However, this system has certain
drawbacks in that it needs to be processed before analysis. Medical research is
already entered a new era of research which is called Artificial Intelligence
(AI). AI can automatically find complex patterns from an image and identify
diseases. Methods for medical imaging that uses AI techniques will be covered
in this chapter.",2023-06-10,2023,2023-06,medical
"Multi-modal Pre-training for Medical Vision-language Understanding and
  Generation: An Empirical Study with A New Benchmark","With the availability of large-scale, comprehensive, and general-purpose
vision-language (VL) datasets such as MSCOCO, vision-language pre-training
(VLP) has become an active area of research and proven to be effective for
various VL tasks such as visual-question answering. However, studies on VLP in
the medical domain have so far been scanty. To provide a comprehensive
perspective on VLP for medical VL tasks, we conduct a thorough experimental
analysis to study key factors that may affect the performance of VLP with a
unified vision-language Transformer. To allow making sound and quick
pre-training decisions, we propose RadioGraphy Captions (RGC), a high-quality,
multi-modality radiographic dataset containing 18,434 image-caption pairs
collected from an open-access online database MedPix. RGC can be used as a
pre-training dataset or a new benchmark for medical report generation and
medical image-text retrieval. By utilizing RGC and other available datasets for
pre-training, we develop several key insights that can guide future medical VLP
research and new strong baselines for various medical VL tasks.",2023-06-10,2023,2023-06,medical
"Preserving privacy in domain transfer of medical AI models comes at no
  performance costs: The integral role of differential privacy","Developing robust and effective artificial intelligence (AI) models in
medicine requires access to large amounts of patient data. The use of AI models
solely trained on large multi-institutional datasets can help with this, yet
the imperative to ensure data privacy remains, particularly as membership
inference risks breaching patient confidentiality. As a proposed remedy, we
advocate for the integration of differential privacy (DP). We specifically
investigate the performance of models trained with DP as compared to models
trained without DP on data from institutions that the model had not seen during
its training (i.e., external validation) - the situation that is reflective of
the clinical use of AI models. By leveraging more than 590,000 chest
radiographs from five institutions, we evaluated the efficacy of DP-enhanced
domain transfer (DP-DT) in diagnosing cardiomegaly, pleural effusion,
pneumonia, atelectasis, and in identifying healthy subjects. We juxtaposed
DP-DT with non-DP-DT and examined diagnostic accuracy and demographic fairness
using the area under the receiver operating characteristic curve (AUC) as the
main metric, as well as accuracy, sensitivity, and specificity. Our results
show that DP-DT, even with exceptionally high privacy levels (epsilon around
1), performs comparably to non-DP-DT (P>0.119 across all domains). Furthermore,
DP-DT led to marginal AUC differences - less than 1% - for nearly all
subgroups, relative to non-DP-DT. Despite consistent evidence suggesting that
DP models induce significant performance degradation for on-domain
applications, we show that off-domain performance is almost not affected.
Therefore, we ardently advocate for the adoption of DP in training diagnostic
medical AI models, given its minimal impact on performance.",2023-06-10,2023,2023-06,medical
Visual Question Answering (VQA) on Images with Superimposed Text,"Superimposed text annotations have been under-investigated, yet are
ubiquitous, useful and important, especially in medical images. Medical images
also highlight the challenges posed by low resolution, noise and superimposed
textual meta-information. Therefor we probed the impact of superimposing text
onto medical images on VQA. Our results revealed that this textual
meta-information can be added without severely degrading key measures of VQA
performance. Our findings are significant because they validate the practice of
superimposing text on images, even for medical images subjected to the VQA task
using AI techniques. The work helps advance understanding of VQA in general
and, in particular, in the domain of healthcare and medicine.",2023-06-13,2023,2023-06,medical
"Temporally-Extended Prompts Optimization for SAM in Interactive Medical
  Image Segmentation","The Segmentation Anything Model (SAM) has recently emerged as a foundation
model for addressing image segmentation. Owing to the intrinsic complexity of
medical images and the high annotation cost, the medical image segmentation
(MIS) community has been encouraged to investigate SAM's zero-shot capabilities
to facilitate automatic annotation. Inspired by the extraordinary
accomplishments of interactive medical image segmentation (IMIS) paradigm, this
paper focuses on assessing the potential of SAM's zero-shot capabilities within
the IMIS paradigm to amplify its benefits in the MIS domain. Regrettably, we
observe that SAM's vulnerability to prompt forms (e.g., points, bounding boxes)
becomes notably pronounced in IMIS. This leads us to develop a framework that
adaptively offers suitable prompt forms for human experts. We refer to the
framework above as temporally-extended prompts optimization (TEPO) and model it
as a Markov decision process, solvable through reinforcement learning.
Numerical experiments on the standardized benchmark BraTS2020 demonstrate that
the learned TEPO agent can further enhance SAM's zero-shot capability in the
MIS context.",2023-06-15,2023,2023-06,medical
"Path to Medical AGI: Unify Domain-specific Medical LLMs with the Lowest
  Cost","Medical artificial general intelligence (AGI) is an emerging field that aims
to develop systems specifically designed for medical applications that possess
the ability to understand, learn, and apply knowledge across a wide range of
tasks and domains. Large language models (LLMs) represent a significant step
towards AGI. However, training cross-domain LLMs in the medical field poses
significant challenges primarily attributed to the requirement of collecting
data from diverse domains. This task becomes particularly difficult due to
privacy restrictions and the scarcity of publicly available medical datasets.
Here, we propose Medical AGI (MedAGI), a paradigm to unify domain-specific
medical LLMs with the lowest cost, and suggest a possible path to achieve
medical AGI. With an increasing number of domain-specific professional
multimodal LLMs in the medical field being developed, MedAGI is designed to
automatically select appropriate medical models by analyzing users' questions
with our novel adaptive expert selection algorithm. It offers a unified
approach to existing LLMs in the medical field, eliminating the need for
retraining regardless of the introduction of new models. This characteristic
renders it a future-proof solution in the dynamically advancing medical domain.
To showcase the resilience of MedAGI, we conducted an evaluation across three
distinct medical domains: dermatology diagnosis, X-ray diagnosis, and analysis
of pathology pictures. The results demonstrated that MedAGI exhibited
remarkable versatility and scalability, delivering exceptional performance
across diverse domains. Our code is publicly available to facilitate further
research at https://github.com/JoshuaChou2018/MedAGI.",2023-06-19,2023,2023-06,medical
"Utilizing Segment Anything Model For Assessing Localization of GRAD-CAM
  in Medical Imaging","The introduction of saliency map algorithms as an approach for assessing the
interoperability of images has allowed for a deeper understanding of current
black-box models with Artificial Intelligence. Their rise in popularity has led
to these algorithms being applied in multiple fields, including medical
imaging. With a classification task as important as those in the medical
domain, a need for rigorous testing of their capabilities arises. Current works
examine capabilities through assessing the localization of saliency maps upon
medical abnormalities within an image, through comparisons with human
annotations. We propose utilizing Segment Anything Model (SAM) to both further
the accuracy of such existing metrics, while also generalizing beyond the need
for human annotations. Our results show both high degrees of similarity to
existing metrics while also highlighting the capabilities of this methodology
to beyond human-annotation. Furthermore, we explore the applications (and
challenges) of SAM within the medical domain, including image pre-processing
before segmenting, natural language proposals to SAM in the form of CLIP-SAM,
and SAM accuracy across multiple medical imaging datasets.",2023-06-24,2023,2023-06,medical
Regular SE(3) Group Convolutions for Volumetric Medical Image Analysis,"Regular group convolutional neural networks (G-CNNs) have been shown to
increase model performance and improve equivariance to different geometrical
symmetries. This work addresses the problem of SE(3), i.e., roto-translation
equivariance, on volumetric data. Volumetric image data is prevalent in many
medical settings. Motivated by the recent work on separable group convolutions,
we devise a SE(3) group convolution kernel separated into a continuous SO(3)
(rotation) kernel and a spatial kernel. We approximate equivariance to the
continuous setting by sampling uniform SO(3) grids. Our continuous SO(3) kernel
is parameterized via RBF interpolation on similarly uniform grids. We
demonstrate the advantages of our approach in volumetric medical image
analysis. Our SE(3) equivariant models consistently outperform CNNs and regular
discrete G-CNNs on challenging medical classification tasks and show
significantly improved generalization capabilities. Our approach achieves up to
a 16.5% gain in accuracy over regular CNNs.",2023-06-24,2023,2023-06,medical
"Multi-Scale Cross Contrastive Learning for Semi-Supervised Medical Image
  Segmentation","Semi-supervised learning has demonstrated great potential in medical image
segmentation by utilizing knowledge from unlabeled data. However, most existing
approaches do not explicitly capture high-level semantic relations between
distant regions, which limits their performance. In this paper, we focus on
representation learning for semi-supervised learning, by developing a novel
Multi-Scale Cross Supervised Contrastive Learning (MCSC) framework, to segment
structures in medical images. We jointly train CNN and Transformer models,
regularising their features to be semantically consistent across different
scales. Our approach contrasts multi-scale features based on ground-truth and
cross-predicted labels, in order to extract robust feature representations that
reflect intra- and inter-slice relationships across the whole dataset. To
tackle class imbalance, we take into account the prevalence of each class to
guide contrastive learning and ensure that features adequately capture
infrequent classes. Extensive experiments on two multi-structure medical
segmentation datasets demonstrate the effectiveness of MCSC. It not only
outperforms state-of-the-art semi-supervised methods by more than 3.0% in Dice,
but also greatly reduces the performance gap with fully supervised methods.",2023-06-25,2023,2023-06,medical
"Medical Federated Model with Mixture of Personalized and Sharing
  Components","Although data-driven methods usually have noticeable performance on disease
diagnosis and treatment, they are suspected of leakage of privacy due to
collecting data for model training. Recently, federated learning provides a
secure and trustable alternative to collaboratively train model without any
exchange of medical data among multiple institutes. Therefore, it has draw much
attention due to its natural merit on privacy protection. However, when
heterogenous medical data exists between different hospitals, federated
learning usually has to face with degradation of performance. In the paper, we
propose a new personalized framework of federated learning to handle the
problem. It successfully yields personalized models based on awareness of
similarity between local data, and achieves better tradeoff between
generalization and personalization than existing methods. After that, we
further design a differentially sparse regularizer to improve communication
efficiency during procedure of model training. Additionally, we propose an
effective method to reduce the computational cost, which improves computation
efficiency significantly. Furthermore, we collect 5 real medical datasets,
including 2 public medical image datasets and 3 private multi-center clinical
diagnosis datasets, and evaluate its performance by conducting nodule
classification, tumor segmentation, and clinical risk prediction tasks.
Comparing with 13 existing related methods, the proposed method successfully
achieves the best model performance, and meanwhile up to 60% improvement of
communication efficiency. Source code is public, and can be accessed at:
https://github.com/ApplicationTechnologyOfMedicalBigData/pFedNet-code.",2023-06-26,2023,2023-06,medical
"Stone Needle: A General Multimodal Large-scale Model Framework towards
  Healthcare","In healthcare, multimodal data is prevalent and requires to be
comprehensively analyzed before diagnostic decisions, including medical images,
clinical reports, etc. However, current large-scale artificial intelligence
models predominantly focus on single-modal cognitive abilities and neglect the
integration of multiple modalities. Therefore, we propose Stone Needle, a
general multimodal large-scale model framework tailored explicitly for
healthcare applications. Stone Needle serves as a comprehensive medical
multimodal model foundation, integrating various modalities such as text,
images, videos, and audio to surpass the limitations of single-modal systems.
Through the framework components of intent analysis, medical foundation models,
prompt manager, and medical language module, our architecture can perform
multi-modal interaction in multiple rounds of dialogue. Our method is a general
multimodal large-scale model framework, integrating diverse modalities and
allowing us to tailor for specific tasks. The experimental results demonstrate
the superior performance of our method compared to single-modal systems. The
fusion of different modalities and the ability to process complex medical
information in Stone Needle benefits accurate diagnosis, treatment
recommendations, and patient care.",2023-06-28,2023,2023-06,medical
Transformers in Healthcare: A Survey,"With Artificial Intelligence (AI) increasingly permeating various aspects of
society, including healthcare, the adoption of the Transformers neural network
architecture is rapidly changing many applications. Transformer is a type of
deep learning architecture initially developed to solve general-purpose Natural
Language Processing (NLP) tasks and has subsequently been adapted in many
fields, including healthcare. In this survey paper, we provide an overview of
how this architecture has been adopted to analyze various forms of data,
including medical imaging, structured and unstructured Electronic Health
Records (EHR), social media, physiological signals, and biomolecular sequences.
Those models could help in clinical diagnosis, report generation, data
reconstruction, and drug/protein synthesis. We identified relevant studies
using the Preferred Reporting Items for Systematic Reviews and Meta-Analyses
(PRISMA) guidelines. We also discuss the benefits and limitations of using
transformers in healthcare and examine issues such as computational cost, model
interpretability, fairness, alignment with human values, ethical implications,
and environmental impact.",2023-06-30,2023,2023-06,medical
"Performance of ChatGPT on USMLE: Unlocking the Potential of Large
  Language Models for AI-Assisted Medical Education","Artificial intelligence is gaining traction in more ways than ever before.
The popularity of language models and AI-based businesses has soared since
ChatGPT was made available to the general public via OpenAI. It is becoming
increasingly common for people to use ChatGPT both professionally and
personally. Considering the widespread use of ChatGPT and the reliance people
place on it, this study determined how reliable ChatGPT can be for answering
complex medical and clinical questions. Harvard University gross anatomy along
with the United States Medical Licensing Examination (USMLE) questionnaire were
used to accomplish the objective. The paper evaluated the obtained results
using a 2-way ANOVA and posthoc analysis. Both showed systematic covariation
between format and prompt. Furthermore, the physician adjudicators
independently rated the outcome's accuracy, concordance, and insight. As a
result of the analysis, ChatGPT-generated answers were found to be more
context-oriented and represented a better model for deductive reasoning than
regular Google search results. Furthermore, ChatGPT obtained 58.8% on logical
questions and 60% on ethical questions. This means that the ChatGPT is
approaching the passing range for logical questions and has crossed the
threshold for ethical questions. The paper believes ChatGPT and other language
learning models can be invaluable tools for e-learners; however, the study
suggests that there is still room to improve their accuracy. In order to
improve ChatGPT's performance in the future, further research is needed to
better understand how it can answer different types of questions.",2023-06-30,2023,2023-06,medical
"Beyond Known Reality: Exploiting Counterfactual Explanations for Medical
  Research","The field of explainability in artificial intelligence (AI) has witnessed a
growing number of studies and increasing scholarly interest. However, the lack
of human-friendly and individual interpretations in explaining the outcomes of
machine learning algorithms has significantly hindered the acceptance of these
methods by clinicians in their research and clinical practice. To address this
issue, our study uses counterfactual explanations to explore the applicability
of ""what if?"" scenarios in medical research. Our aim is to expand our
understanding of magnetic resonance imaging (MRI) features used for diagnosing
pediatric posterior fossa brain tumors beyond existing boundaries. In our case
study, the proposed concept provides a novel way to examine alternative
decision-making scenarios that offer personalized and context-specific
insights, enabling the validation of predictions and clarification of
variations under diverse circumstances. Additionally, we explore the potential
use of counterfactuals for data augmentation and evaluate their feasibility as
an alternative approach in our medical research case. The results demonstrate
the promising potential of using counterfactual explanations to improve
AI-driven methods in clinical research.",2023-07-05,2023,2023-07,medical
"The Role of Subgroup Separability in Group-Fair Medical Image
  Classification","We investigate performance disparities in deep classifiers. We find that the
ability of classifiers to separate individuals into subgroups varies
substantially across medical imaging modalities and protected characteristics;
crucially, we show that this property is predictive of algorithmic bias.
Through theoretical analysis and extensive empirical evaluation, we find a
relationship between subgroup separability, subgroup disparities, and
performance degradation when models are trained on data with systematic bias
such as underdiagnosis. Our findings shed new light on the question of how
models become biased, providing important insights for the development of fair
medical imaging AI.",2023-07-06,2023,2023-07,medical
"Masked Vision and Language Pre-training with Unimodal and Multimodal
  Contrastive Losses for Medical Visual Question Answering","Medical visual question answering (VQA) is a challenging task that requires
answering clinical questions of a given medical image, by taking consider of
both visual and language information. However, due to the small scale of
training data for medical VQA, pre-training fine-tuning paradigms have been a
commonly used solution to improve model generalization performance. In this
paper, we present a novel self-supervised approach that learns unimodal and
multimodal feature representations of input images and text using medical image
caption datasets, by leveraging both unimodal and multimodal contrastive
losses, along with masked language modeling and image text matching as
pretraining objectives. The pre-trained model is then transferred to downstream
medical VQA tasks. The proposed approach achieves state-of-the-art (SOTA)
performance on three publicly available medical VQA datasets with significant
accuracy improvements of 2.2%, 14.7%, and 1.7% respectively. Besides, we
conduct a comprehensive analysis to validate the effectiveness of different
components of the approach and study different pre-training settings. Our codes
and models are available at https://github.com/pengfeiliHEU/MUMC.",2023-07-11,2023,2023-07,medical
"Measuring Perceived Trust in XAI-Assisted Decision-Making by Eliciting a
  Mental Model","This empirical study proposes a novel methodology to measure users' perceived
trust in an Explainable Artificial Intelligence (XAI) model. To do so, users'
mental models are elicited using Fuzzy Cognitive Maps (FCMs). First, we exploit
an interpretable Machine Learning (ML) model to classify suspected COVID-19
patients into positive or negative cases. Then, Medical Experts' (MEs) conduct
a diagnostic decision-making task based on their knowledge and then prediction
and interpretations provided by the XAI model. In order to evaluate the impact
of interpretations on perceived trust, explanation satisfaction attributes are
rated by MEs through a survey. Then, they are considered as FCM's concepts to
determine their influences on each other and, ultimately, on the perceived
trust. Moreover, to consider MEs' mental subjectivity, fuzzy linguistic
variables are used to determine the strength of influences. After reaching the
steady state of FCMs, a quantified value is obtained to measure the perceived
trust of each ME. The results show that the quantified values can determine
whether MEs trust or distrust the XAI model. We analyze this behavior by
comparing the quantified values with MEs' performance in completing diagnostic
tasks.",2023-07-15,2023,2023-07,medical
"M-FLAG: Medical Vision-Language Pre-training with Frozen Language Models
  and Latent Space Geometry Optimization","Medical vision-language models enable co-learning and integrating features
from medical imaging and clinical text. However, these models are not easy to
train and the latent representation space can be complex. Here we propose a
novel way for pre-training and regularising medical vision-language models. The
proposed method, named Medical vision-language pre-training with Frozen
language models and Latent spAce Geometry optimization (M-FLAG), leverages a
frozen language model for training stability and efficiency and introduces a
novel orthogonality loss to harmonize the latent space geometry. We demonstrate
the potential of the pre-trained model on three downstream tasks: medical image
classification, segmentation, and object detection. Extensive experiments
across five public datasets demonstrate that M-FLAG significantly outperforms
existing medical vision-language pre-training approaches and reduces the number
of parameters by 78\%. Notably, M-FLAG achieves outstanding performance on the
segmentation task while using only 1\% of the RSNA dataset, even outperforming
ImageNet pre-trained models that have been fine-tuned using 100\% of the data.",2023-07-17,2023,2023-07,medical
"Balancing Privacy and Progress in Artificial Intelligence: Anonymization
  in Histopathology for Biomedical Research and Education","The advancement of biomedical research heavily relies on access to large
amounts of medical data. In the case of histopathology, Whole Slide Images
(WSI) and clinicopathological information are valuable for developing
Artificial Intelligence (AI) algorithms for Digital Pathology (DP).
Transferring medical data ""as open as possible"" enhances the usability of the
data for secondary purposes but poses a risk to patient privacy. At the same
time, existing regulations push towards keeping medical data ""as closed as
necessary"" to avoid re-identification risks. Generally, these legal regulations
require the removal of sensitive data but do not consider the possibility of
data linkage attacks due to modern image-matching algorithms. In addition, the
lack of standardization in DP makes it harder to establish a single solution
for all formats of WSIs. These challenges raise problems for bio-informatics
researchers in balancing privacy and progress while developing AI algorithms.
This paper explores the legal regulations and terminologies for medical
data-sharing. We review existing approaches and highlight challenges from the
histopathological perspective. We also present a data-sharing guideline for
histological data to foster multidisciplinary research and education.",2023-07-18,2023,2023-07,medical
Interpreting and Correcting Medical Image Classification with PIP-Net,"Part-prototype models are explainable-by-design image classifiers, and a
promising alternative to black box AI. This paper explores the applicability
and potential of interpretable machine learning, in particular PIP-Net, for
automated diagnosis support on real-world medical imaging data. PIP-Net learns
human-understandable prototypical image parts and we evaluate its accuracy and
interpretability for fracture detection and skin cancer diagnosis. We find that
PIP-Net's decision making process is in line with medical classification
standards, while only provided with image-level class labels. Because of
PIP-Net's unsupervised pretraining of prototypes, data quality problems such as
undesired text in an X-ray or labelling errors can be easily identified.
Additionally, we are the first to show that humans can manually correct the
reasoning of PIP-Net by directly disabling undesired prototypes. We conclude
that part-prototype models are promising for medical applications due to their
interpretability and potential for advanced model debugging.",2023-07-19,2023,2023-07,medical
Is Grad-CAM Explainable in Medical Images?,"Explainable Deep Learning has gained significant attention in the field of
artificial intelligence (AI), particularly in domains such as medical imaging,
where accurate and interpretable machine learning models are crucial for
effective diagnosis and treatment planning. Grad-CAM is a baseline that
highlights the most critical regions of an image used in a deep learning
model's decision-making process, increasing interpretability and trust in the
results. It is applied in many computer vision (CV) tasks such as
classification and explanation. This study explores the principles of
Explainable Deep Learning and its relevance to medical imaging, discusses
various explainability techniques and their limitations, and examines medical
imaging applications of Grad-CAM. The findings highlight the potential of
Explainable Deep Learning and Grad-CAM in improving the accuracy and
interpretability of deep learning models in medical imaging. The code is
available in (will be available).",2023-07-20,2023,2023-07,medical
IvyGPT: InteractiVe Chinese pathwaY language model in medical domain,"General large language models (LLMs) such as ChatGPT have shown remarkable
success. However, such LLMs have not been widely adopted for medical purposes,
due to poor accuracy and inability to provide medical advice. We propose
IvyGPT, an LLM based on LLaMA that is trained and fine-tuned with high-quality
medical question-answer (QA) instances and Reinforcement Learning from Human
Feedback (RLHF). After supervised fine-tuning, IvyGPT has good multi-turn
conversation capabilities, but it cannot perform like a doctor in other
aspects, such as comprehensive diagnosis. Through RLHF, IvyGPT can output
richer diagnosis and treatment answers that are closer to human. In the
training, we used QLoRA to train 33 billion parameters on a small number of
NVIDIA A100 (80GB) GPUs. Experimental results show that IvyGPT has outperformed
other medical GPT models.",2023-07-20,2023,2023-07,medical
"Probabilistic Modeling of Inter- and Intra-observer Variability in
  Medical Image Segmentation","Medical image segmentation is a challenging task, particularly due to inter-
and intra-observer variability, even between medical experts. In this paper, we
propose a novel model, called Probabilistic Inter-Observer and iNtra-Observer
variation NetwOrk (Pionono). It captures the labeling behavior of each rater
with a multidimensional probability distribution and integrates this
information with the feature maps of the image to produce probabilistic
segmentation predictions. The model is optimized by variational inference and
can be trained end-to-end. It outperforms state-of-the-art models such as
STAPLE, Probabilistic U-Net, and models based on confusion matrices.
Additionally, Pionono predicts multiple coherent segmentation maps that mimic
the rater's expert opinion, which provides additional valuable information for
the diagnostic process. Experiments on real-world cancer segmentation datasets
demonstrate the high accuracy and efficiency of Pionono, making it a powerful
tool for medical image analysis.",2023-07-21,2023,2023-07,medical
"A Revolution of Personalized Healthcare: Enabling Human Digital Twin
  with Mobile AIGC","Mobile Artificial Intelligence-Generated Content (AIGC) technology refers to
the adoption of AI algorithms deployed at mobile edge networks to automate the
information creation process while fulfilling the requirements of end users.
Mobile AIGC has recently attracted phenomenal attentions and can be a key
enabling technology for an emerging application, called human digital twin
(HDT). HDT empowered by the mobile AIGC is expected to revolutionize the
personalized healthcare by generating rare disease data, modeling high-fidelity
digital twin, building versatile testbeds, and providing 24/7 customized
medical services. To promote the development of this new breed of paradigm, in
this article, we propose a system architecture of mobile AIGC-driven HDT and
highlight the corresponding design requirements and challenges. Moreover, we
illustrate two use cases, i.e., mobile AIGC-driven HDT in customized surgery
planning and personalized medication. In addition, we conduct an experimental
study to prove the effectiveness of the proposed mobile AIGC-driven HDT
solution, which shows a particular application in a virtual physical therapy
teaching platform. Finally, we conclude this article by briefly discussing
several open issues and future directions.",2023-07-22,2023,2023-07,medical
"Client-Level Differential Privacy via Adaptive Intermediary in Federated
  Medical Imaging","Despite recent progress in enhancing the privacy of federated learning (FL)
via differential privacy (DP), the trade-off of DP between privacy protection
and performance is still underexplored for real-world medical scenario. In this
paper, we propose to optimize the trade-off under the context of client-level
DP, which focuses on privacy during communications. However, FL for medical
imaging involves typically much fewer participants (hospitals) than other
domains (e.g., mobile devices), thus ensuring clients be differentially private
is much more challenging. To tackle this problem, we propose an adaptive
intermediary strategy to improve performance without harming privacy.
Specifically, we theoretically find splitting clients into sub-clients, which
serve as intermediaries between hospitals and the server, can mitigate the
noises introduced by DP without harming privacy. Our proposed approach is
empirically evaluated on both classification and segmentation tasks using two
public datasets, and its effectiveness is demonstrated with significant
performance improvements and comprehensive analytical studies. Code is
available at: https://github.com/med-air/Client-DP-FL.",2023-07-24,2023,2023-07,medical
"SL: Stable Learning in Source-Free Domain Adaption for Medical Image
  Segmentation","Deep learning techniques for medical image analysis usually suffer from the
domain shift between source and target data. Most existing works focus on
unsupervised domain adaptation (UDA). However, in practical applications,
privacy issues are much more severe. For example, the data of different
hospitals have domain shifts due to equipment problems, and data of the two
domains cannot be available simultaneously because of privacy. In this
challenge defined as Source-Free UDA, the previous UDA medical methods are
limited. Although a variety of medical source-free unsupervised domain adaption
(MSFUDA) methods have been proposed, we found they fall into an over-fitting
dilemma called ""longer training, worse performance."" Therefore, we propose the
Stable Learning (SL) strategy to address the dilemma. SL is a scalable method
and can be integrated with other research, which consists of Weight
Consolidation and Entropy Increase. First, we apply Weight Consolidation to
retain domain-invariant knowledge and then we design Entropy Increase to avoid
over-learning. Comparative experiments prove the effectiveness of SL. We also
have done extensive ablation experiments. Besides, We will release codes
including a variety of MSFUDA methods.",2023-07-24,2023,2023-07,medical
Is attention all you need in medical image analysis? A review,"Medical imaging is a key component in clinical diagnosis, treatment planning
and clinical trial design, accounting for almost 90% of all healthcare data.
CNNs achieved performance gains in medical image analysis (MIA) over the last
years. CNNs can efficiently model local pixel interactions and be trained on
small-scale MI data. The main disadvantage of typical CNN models is that they
ignore global pixel relationships within images, which limits their
generalisation ability to understand out-of-distribution data with different
'global' information. The recent progress of Artificial Intelligence gave rise
to Transformers, which can learn global relationships from data. However, full
Transformer models need to be trained on large-scale data and involve
tremendous computational complexity. Attention and Transformer compartments
(Transf/Attention) which can well maintain properties for modelling global
relationships, have been proposed as lighter alternatives of full Transformers.
Recently, there is an increasing trend to co-pollinate complementary
local-global properties from CNN and Transf/Attention architectures, which led
to a new era of hybrid models. The past years have witnessed substantial growth
in hybrid CNN-Transf/Attention models across diverse MIA problems. In this
systematic review, we survey existing hybrid CNN-Transf/Attention models,
review and unravel key architectural designs, analyse breakthroughs, and
evaluate current and future opportunities as well as challenges. We also
introduced a comprehensive analysis framework on generalisation opportunities
of scientific and clinical impact, based on which new data-driven domain
generalisation and adaptation methods can be stimulated.",2023-07-24,2023,2023-07,medical
Med-Flamingo: a Multimodal Medical Few-shot Learner,"Medicine, by its nature, is a multifaceted domain that requires the synthesis
of information across various modalities. Medical generative vision-language
models (VLMs) make a first step in this direction and promise many exciting
clinical applications. However, existing models typically have to be fine-tuned
on sizeable down-stream datasets, which poses a significant limitation as in
many medical applications data is scarce, necessitating models that are capable
of learning from few examples in real-time. Here we propose Med-Flamingo, a
multimodal few-shot learner adapted to the medical domain. Based on
OpenFlamingo-9B, we continue pre-training on paired and interleaved medical
image-text data from publications and textbooks. Med-Flamingo unlocks few-shot
generative medical visual question answering (VQA) abilities, which we evaluate
on several datasets including a novel challenging open-ended VQA dataset of
visual USMLE-style problems. Furthermore, we conduct the first human evaluation
for generative medical VQA where physicians review the problems and blinded
generations in an interactive app. Med-Flamingo improves performance in
generative medical VQA by up to 20\% in clinician's rating and firstly enables
multimodal medical few-shot adaptations, such as rationale generation. We
release our model, code, and evaluation app under
https://github.com/snap-stanford/med-flamingo.",2023-07-27,2023,2023-07,medical
Med-HALT: Medical Domain Hallucination Test for Large Language Models,"This research paper focuses on the challenges posed by hallucinations in
large language models (LLMs), particularly in the context of the medical
domain. Hallucination, wherein these models generate plausible yet unverified
or incorrect information, can have serious consequences in healthcare
applications. We propose a new benchmark and dataset, Med-HALT (Medical Domain
Hallucination Test), designed specifically to evaluate and reduce
hallucinations. Med-HALT provides a diverse multinational dataset derived from
medical examinations across various countries and includes multiple innovative
testing modalities. Med-HALT includes two categories of tests reasoning and
memory-based hallucination tests, designed to assess LLMs's problem-solving and
information retrieval abilities.
  Our study evaluated leading LLMs, including Text Davinci, GPT-3.5, LlaMa-2,
MPT, and Falcon, revealing significant differences in their performance. The
paper provides detailed insights into the dataset, promoting transparency and
reproducibility. Through this work, we aim to contribute to the development of
safer and more reliable language models in healthcare. Our benchmark can be
found at medhalt.github.io",2023-07-28,2023,2023-07,medical
"Recent advancement in Disease Diagnostic using machine learning:
  Systematic survey of decades, comparisons, and challenges","Computer-aided diagnosis (CAD), a vibrant medical imaging research field, is
expanding quickly. Because errors in medical diagnostic systems might lead to
seriously misleading medical treatments, major efforts have been made in recent
years to improve computer-aided diagnostics applications. The use of machine
learning in computer-aided diagnosis is crucial. A simple equation may result
in a false indication of items like organs. Therefore, learning from examples
is a vital component of pattern recognition. Pattern recognition and machine
learning in the biomedical area promise to increase the precision of disease
detection and diagnosis. They also support the decision-making process's
objectivity. Machine learning provides a practical method for creating elegant
and autonomous algorithms to analyze high-dimensional and multimodal
bio-medical data. This review article examines machine-learning algorithms for
detecting diseases, including hepatitis, diabetes, liver disease, dengue fever,
and heart disease. It draws attention to the collection of machine learning
techniques and algorithms employed in studying conditions and the ensuing
decision-making process.",2023-07-31,2023,2023-07,medical
"Retrieval Augmented Generation and Representative Vector Summarization
  for large unstructured textual data in Medical Education","Large Language Models are increasingly being used for various tasks including
content generation and as chatbots. Despite their impressive performances in
general tasks, LLMs need to be aligned when applying for domain specific tasks
to mitigate the problems of hallucination and producing harmful answers.
Retrieval Augmented Generation (RAG) allows to easily attach and manipulate a
non-parametric knowledgebases to LLMs. Applications of RAG in the field of
medical education are discussed in this paper. A combined extractive and
abstractive summarization method for large unstructured textual data using
representative vectors is proposed.",2023-08-01,2023,2023-08,medical
"Data-Centric Diet: Effective Multi-center Dataset Pruning for Medical
  Image Segmentation","This paper seeks to address the dense labeling problems where a significant
fraction of the dataset can be pruned without sacrificing much accuracy. We
observe that, on standard medical image segmentation benchmarks, the loss
gradient norm-based metrics of individual training examples applied in image
classification fail to identify the important samples. To address this issue,
we propose a data pruning method by taking into consideration the training
dynamics on target regions using Dynamic Average Dice (DAD) score. To the best
of our knowledge, we are among the first to address the data importance in
dense labeling tasks in the field of medical image analysis, making the
following contributions: (1) investigating the underlying causes with rigorous
empirical analysis, and (2) determining effective data pruning approach in
dense labeling problems. Our solution can be used as a strong yet simple
baseline to select important examples for medical image segmentation with
combined data sources.",2023-08-02,2023,2023-08,medical
"From Military to Healthcare: Adopting and Expanding Ethical Principles
  for Generative Artificial Intelligence","In 2020, the U.S. Department of Defense officially disclosed a set of ethical
principles to guide the use of Artificial Intelligence (AI) technologies on
future battlefields. Despite stark differences, there are core similarities
between the military and medical service. Warriors on battlefields often face
life-altering circumstances that require quick decision-making. Medical
providers experience similar challenges in a rapidly changing healthcare
environment, such as in the emergency department or during surgery treating a
life-threatening condition. Generative AI, an emerging technology designed to
efficiently generate valuable information, holds great promise. As computing
power becomes more accessible and the abundance of health data, such as
electronic health records, electrocardiograms, and medical images, increases,
it is inevitable that healthcare will be revolutionized by this technology.
Recently, generative AI has captivated the research community, leading to
debates about its application in healthcare, mainly due to concerns about
transparency and related issues. Meanwhile, concerns about the potential
exacerbation of health disparities due to modeling biases have raised notable
ethical concerns regarding the use of this technology in healthcare. However,
the ethical principles for generative AI in healthcare have been understudied,
and decision-makers often fail to consider the significance of generative AI.
In this paper, we propose GREAT PLEA ethical principles, encompassing
governance, reliability, equity, accountability, traceability, privacy,
lawfulness, empathy, and autonomy, for generative AI in healthcare. We aim to
proactively address the ethical dilemmas and challenges posed by the
integration of generative AI in healthcare.",2023-08-04,2023,2023-08,medical
"Coupling Symbolic Reasoning with Language Modeling for Efficient
  Longitudinal Understanding of Unstructured Electronic Medical Records","The application of Artificial Intelligence (AI) in healthcare has been
revolutionary, especially with the recent advancements in transformer-based
Large Language Models (LLMs). However, the task of understanding unstructured
electronic medical records remains a challenge given the nature of the records
(e.g., disorganization, inconsistency, and redundancy) and the inability of
LLMs to derive reasoning paradigms that allow for comprehensive understanding
of medical variables. In this work, we examine the power of coupling symbolic
reasoning with language modeling toward improved understanding of unstructured
clinical texts. We show that such a combination improves the extraction of
several medical variables from unstructured records. In addition, we show that
the state-of-the-art commercially-free LLMs enjoy retrieval capabilities
comparable to those provided by their commercial counterparts. Finally, we
elaborate on the need for LLM steering through the application of symbolic
reasoning as the exclusive use of LLMs results in the lowest performance.",2023-08-07,2023,2023-08,medical
"Rapid Training Data Creation by Synthesizing Medical Images for
  Classification and Localization","While the use of artificial intelligence (AI) for medical image analysis is
gaining wide acceptance, the expertise, time and cost required to generate
annotated data in the medical field are significantly high, due to limited
availability of both data and expert annotation. Strongly supervised object
localization models require data that is exhaustively annotated, meaning all
objects of interest in an image are identified. This is difficult to achieve
and verify for medical images. We present a method for the transformation of
real data to train any Deep Neural Network to solve the above problems. We show
the efficacy of this approach on both a weakly supervised localization model
and a strongly supervised localization model. For the weakly supervised model,
we show that the localization accuracy increases significantly using the
generated data. For the strongly supervised model, this approach overcomes the
need for exhaustive annotation on real images. In the latter model, we show
that the accuracy, when trained with generated images, closely parallels the
accuracy when trained with exhaustively annotated real images. The results are
demonstrated on images of human urine samples obtained using microscopy.",2023-08-09,2023,2023-08,medical
Explainable AI applications in the Medical Domain: a systematic review,"Artificial Intelligence in Medicine has made significant progress with
emerging applications in medical imaging, patient care, and other areas. While
these applications have proven successful in retrospective studies, very few of
them were applied in practice.The field of Medical AI faces various challenges,
in terms of building user trust, complying with regulations, using data
ethically.Explainable AI (XAI) aims to enable humans understand AI and trust
its results. This paper presents a literature review on the recent developments
of XAI solutions for medical decision support, based on a representative sample
of 198 articles published in recent years. The systematic synthesis of the
relevant articles resulted in several findings. (1) model-agnostic XAI
techniques were mostly employed in these solutions, (2) deep learning models
are utilized more than other types of machine learning models, (3)
explainability was applied to promote trust, but very few works reported the
physicians participation in the loop, (4) visual and interactive user interface
is more useful in understanding the explanation and the recommendation of the
system. More research is needed in collaboration between medical and AI
experts, that could guide the development of suitable frameworks for the
design, implementation, and evaluation of XAI solutions in medicine.",2023-08-10,2023,2023-08,medical
"Ground Truth Or Dare: Factors Affecting The Creation Of Medical Datasets
  For Training AI","One of the core goals of responsible AI development is ensuring high-quality
training datasets. Many researchers have pointed to the importance of the
annotation step in the creation of high-quality data, but less attention has
been paid to the work that enables data annotation. We define this work as the
design of ground truth schema and explore the challenges involved in the
creation of datasets in the medical domain even before any annotations are
made. Based on extensive work in three health-tech organisations, we describe
five external and internal factors that condition medical dataset creation
processes. Three external factors include regulatory constraints, the context
of creation and use, and commercial and operational pressures. These factors
condition medical data collection and shape the ground truth schema design. Two
internal factors include epistemic differences and limits of labelling. These
directly shape the design of the ground truth schema. Discussions of what
constitutes high-quality data need to pay attention to the factors that shape
and constrain what is possible to be created, to ensure responsible AI design.",2023-08-12,2023,2023-08,medical
"The Performance of Transferability Metrics does not Translate to Medical
  Tasks","Transfer learning boosts the performance of medical image analysis by
enabling deep learning (DL) on small datasets through the knowledge acquired
from large ones. As the number of DL architectures explodes, exhaustively
attempting all candidates becomes unfeasible, motivating cheaper alternatives
for choosing them. Transferability scoring methods emerge as an enticing
solution, allowing to efficiently calculate a score that correlates with the
architecture accuracy on any target dataset. However, since transferability
scores have not been evaluated on medical datasets, their use in this context
remains uncertain, preventing them from benefiting practitioners. We fill that
gap in this work, thoroughly evaluating seven transferability scores in three
medical applications, including out-of-distribution scenarios. Despite
promising results in general-purpose datasets, our results show that no
transferability score can reliably and consistently estimate target performance
in medical contexts, inviting further work in that direction.",2023-08-14,2023,2023-08,medical
"Exploring Transfer Learning in Medical Image Segmentation using
  Vision-Language Models","Medical image segmentation allows quantifying target structure size and
shape, aiding in disease diagnosis, prognosis, surgery planning, and
comprehension.Building upon recent advancements in foundation Vision-Language
Models (VLMs) from natural image-text pairs, several studies have proposed
adapting them to Vision-Language Segmentation Models (VLSMs) that allow using
language text as an additional input to segmentation models. Introducing
auxiliary information via text with human-in-the-loop prompting during
inference opens up unique opportunities, such as open vocabulary segmentation
and potentially more robust segmentation models against out-of-distribution
data. Although transfer learning from natural to medical images has been
explored for image-only segmentation models, the joint representation of
vision-language in segmentation problems remains underexplored. This study
introduces the first systematic study on transferring VLSMs to 2D medical
images, using carefully curated $11$ datasets encompassing diverse modalities
and insightful language prompts and experiments. Our findings demonstrate that
although VLSMs show competitive performance compared to image-only models for
segmentation after finetuning in limited medical image datasets, not all VLSMs
utilize the additional information from language prompts, with image features
playing a dominant role. While VLSMs exhibit enhanced performance in handling
pooled datasets with diverse modalities and show potential robustness to domain
shifts compared to conventional segmentation models, our results suggest that
novel approaches are required to enable VLSMs to leverage the various auxiliary
information available through language prompts. The code and datasets are
available at https://github.com/naamiinepal/medvlsm.",2023-08-15,2023,2023-08,medical
CMB: A Comprehensive Medical Benchmark in Chinese,"Large Language Models (LLMs) provide a possibility to make a great
breakthrough in medicine. The establishment of a standardized medical benchmark
becomes a fundamental cornerstone to measure progression. However, medical
environments in different regions have their local characteristics, e.g., the
ubiquity and significance of traditional Chinese medicine within China.
Therefore, merely translating English-based medical evaluation may result in
\textit{contextual incongruities} to a local region. To solve the issue, we
propose a localized medical benchmark called CMB, a Comprehensive Medical
Benchmark in Chinese, designed and rooted entirely within the native Chinese
linguistic and cultural framework. While traditional Chinese medicine is
integral to this evaluation, it does not constitute its entirety. Using this
benchmark, we have evaluated several prominent large-scale LLMs, including
ChatGPT, GPT-4, dedicated Chinese LLMs, and LLMs specialized in the medical
domain. We hope this benchmark provide first-hand experience in existing LLMs
for medicine and also facilitate the widespread adoption and enhancement of
medical LLMs within China. Our data and code are publicly available at
https://github.com/FreedomIntelligence/CMB.",2023-08-17,2023,2023-08,medical
"Deciphering knee osteoarthritis diagnostic features with explainable
  artificial intelligence: A systematic review","Existing artificial intelligence (AI) models for diagnosing knee
osteoarthritis (OA) have faced criticism for their lack of transparency and
interpretability, despite achieving medical-expert-like performance. This
opacity makes them challenging to trust in clinical practice. Recently,
explainable artificial intelligence (XAI) has emerged as a specialized
technique that can provide confidence in the model's prediction by revealing
how the prediction is derived, thus promoting the use of AI systems in
healthcare. This paper presents the first survey of XAI techniques used for
knee OA diagnosis. The XAI techniques are discussed from two perspectives: data
interpretability and model interpretability. The aim of this paper is to
provide valuable insights into XAI's potential towards a more reliable knee OA
diagnosis approach and encourage its adoption in clinical practice.",2023-08-18,2023,2023-08,medical
False Negative/Positive Control for SAM on Noisy Medical Images,"The Segment Anything Model (SAM) is a recently developed all-range foundation
model for image segmentation. It can use sparse manual prompts such as bounding
boxes to generate pixel-level segmentation in natural images but struggles in
medical images such as low-contrast, noisy ultrasound images. We propose a
refined test-phase prompt augmentation technique designed to improve SAM's
performance in medical image segmentation. The method couples multi-box prompt
augmentation and an aleatoric uncertainty-based false-negative (FN) and
false-positive (FP) correction (FNPC) strategy. We evaluate the method on two
ultrasound datasets and show improvement in SAM's performance and robustness to
inaccurate prompts, without the necessity for further training or tuning.
Moreover, we present the Single-Slice-to-Volume (SS2V) method, enabling 3D
pixel-level segmentation using only the bounding box annotation from a single
2D slice. Our results allow efficient use of SAM in even noisy, low-contrast
medical images. The source code will be released soon.",2023-08-20,2023,2023-08,medical
"Enhancing Medical Image Segmentation: Optimizing Cross-Entropy Weights
  and Post-Processing with Autoencoders","The task of medical image segmentation presents unique challenges,
necessitating both localized and holistic semantic understanding to accurately
delineate areas of interest, such as critical tissues or aberrant features.
This complexity is heightened in medical image segmentation due to the high
degree of inter-class similarities, intra-class variations, and possible image
obfuscation. The segmentation task further diversifies when considering the
study of histopathology slides for autoimmune diseases like dermatomyositis.
The analysis of cell inflammation and interaction in these cases has been less
studied due to constraints in data acquisition pipelines. Despite the
progressive strides in medical science, we lack a comprehensive collection of
autoimmune diseases. As autoimmune diseases globally escalate in prevalence and
exhibit associations with COVID-19, their study becomes increasingly essential.
While there is existing research that integrates artificial intelligence in the
analysis of various autoimmune diseases, the exploration of dermatomyositis
remains relatively underrepresented. In this paper, we present a deep-learning
approach tailored for Medical image segmentation. Our proposed method
outperforms the current state-of-the-art techniques by an average of 12.26% for
U-Net and 12.04% for U-Net++ across the ResNet family of encoders on the
dermatomyositis dataset. Furthermore, we probe the importance of optimizing
loss function weights and benchmark our methodology on three challenging
medical image segmentation tasks",2023-08-21,2023,2023-08,medical
"Exploration of the Rashomon Set Assists Trustworthy Explanations for
  Medical Data","The machine learning modeling process conventionally culminates in selecting
a single model that maximizes a selected performance metric. However, this
approach leads to abandoning a more profound analysis of slightly inferior
models. Particularly in medical and healthcare studies, where the objective
extends beyond predictions to valuable insight generation, relying solely on a
single model can result in misleading or incomplete conclusions. This problem
is particularly pertinent when dealing with a set of models known as
$\textit{Rashomon set}$, with performance close to maximum one. Such a set can
be numerous and may contain models describing the data in a different way,
which calls for comprehensive analysis. This paper introduces a novel process
to explore models in the Rashomon set, extending the conventional modeling
approach. We propose the $\texttt{Rashomon_DETECT}$ algorithm to detect models
with different behavior. It is based on recent developments in the eXplainable
Artificial Intelligence (XAI) field. To quantify differences in variable
effects among models, we introduce the Profile Disparity Index (PDI) based on
measures from functional data analysis. To illustrate the effectiveness of our
approach, we showcase its application in predicting survival among
hemophagocytic lymphohistiocytosis (HLH) patients - a foundational case study.
Additionally, we benchmark our approach on other medical data sets,
demonstrating its versatility and utility in various contexts. If differently
behaving models are detected in the Rashomon set, their combined analysis leads
to more trustworthy conclusions, which is of vital importance for high-stakes
applications such as medical applications.",2023-08-22,2023,2023-08,medical
"A Generative Approach for Image Registration of Visible-Thermal (VT)
  Cancer Faces","Since thermal imagery offers a unique modality to investigate pain, the U.S.
National Institutes of Health (NIH) has collected a large and diverse set of
cancer patient facial thermograms for AI-based pain research. However,
differing angles from camera capture between thermal and visible sensors has
led to misalignment between Visible-Thermal (VT) images. We modernize the
classic computer vision task of image registration by applying and modifying a
generative alignment algorithm to register VT cancer faces, without the need
for a reference or alignment parameters. By registering VT faces, we
demonstrate that the quality of thermal images produced in the generative AI
downstream task of Visible-to-Thermal (V2T) image translation significantly
improves up to 52.5\%, than without registration. Images in this paper have
been approved by the NIH NCI for public dissemination.",2023-08-23,2023,2023-08,medical
"DISC-MedLLM: Bridging General Large Language Models and Real-World
  Medical Consultation","We propose DISC-MedLLM, a comprehensive solution that leverages Large
Language Models (LLMs) to provide accurate and truthful medical response in
end-to-end conversational healthcare services. To construct high-quality
Supervised Fine-Tuning (SFT) datasets, we employ three strategies: utilizing
medical knowledge-graphs, reconstructing real-world dialogues, and
incorporating human-guided preference rephrasing. These datasets are
instrumental in training DISC-MedLLM, surpassing existing medical LLMs in both
single-turn and multi-turn consultation scenarios. Extensive experimental
results demonstrate the effectiveness of the proposed model in bridging the gap
between general language models and real-world medical consultation.
Additionally, we release the constructed dataset and model weights to further
contribute to research and development. Further details and resources can be
found at https://github.com/FudanDISC/DISC-MedLLM",2023-08-28,2023,2023-08,medical
"Patient-specific, mechanistic models of tumor growth incorporating
  artificial intelligence and big data","Despite the remarkable advances in cancer diagnosis, treatment, and
management that have occurred over the past decade, malignant tumors remain a
major public health problem. Further progress in combating cancer may be
enabled by personalizing the delivery of therapies according to the predicted
response for each individual patient. The design of personalized therapies
requires patient-specific information integrated into an appropriate
mathematical model of tumor response. A fundamental barrier to realizing this
paradigm is the current lack of a rigorous, yet practical, mathematical theory
of tumor initiation, development, invasion, and response to therapy. In this
review, we begin by providing an overview of different approaches to modeling
tumor growth and treatment, including mechanistic as well as data-driven models
based on ``big data"" and artificial intelligence. Next, we present illustrative
examples of mathematical models manifesting their utility and discussing the
limitations of stand-alone mechanistic and data-driven models. We further
discuss the potential of mechanistic models for not only predicting, but also
optimizing response to therapy on a patient-specific basis. We then discuss
current efforts and future possibilities to integrate mechanistic and
data-driven models. We conclude by proposing five fundamental challenges that
must be addressed to fully realize personalized care for cancer patients driven
by computational models.",2023-08-28,2023,2023-08,medical
AutoProSAM: Automated Prompting SAM for 3D Multi-Organ Segmentation,"Segment Anything Model (SAM) is one of the pioneering prompt-based foundation
models for image segmentation and has been rapidly adopted for various medical
imaging applications. However, in clinical settings, creating effective prompts
is notably challenging and time-consuming, requiring the expertise of domain
specialists such as physicians. This requirement significantly diminishes SAM's
primary advantage, its interactive capability with end users, in medical
applications. Moreover, recent studies have indicated that SAM, originally
designed for 2D natural images, performs suboptimally on 3D medical image
segmentation tasks. This subpar performance is attributed to the domain gaps
between natural and medical images and the disparities in spatial arrangements
between 2D and 3D images, particularly in multi-organ segmentation
applications. To overcome these challenges, we present a novel technique termed
AutoProSAM. This method automates 3D multi-organ CT-based segmentation by
leveraging SAM's foundational model capabilities without relying on domain
experts for prompts. The approach utilizes parameter-efficient adaptation
techniques to adapt SAM for 3D medical imagery and incorporates an effective
automatic prompt learning paradigm specific to this domain. By eliminating the
need for manual prompts, it enhances SAM's capabilities for 3D medical image
segmentation and achieves state-of-the-art (SOTA) performance in CT-based
multi-organ segmentation tasks. The code is in this
{\href{https://github.com/ChengyinLee/AutoProSAM_2024}{link}}.",2023-08-28,2023,2023-08,medical
"StratMed: Relevance Stratification between Biomedical Entities for
  Sparsity on Medication Recommendation","With the growing imbalance between limited medical resources and escalating
demands, AI-based clinical tasks have become paramount. As a sub-domain,
medication recommendation aims to amalgamate longitudinal patient history with
medical knowledge, assisting physicians in prescribing safer and more accurate
medication combinations. Existing works ignore the inherent long-tailed
distribution of medical data, have uneven learning strengths for hot and sparse
data, and fail to balance safety and accuracy. To address the above
limitations, we propose StratMed, which introduces a stratification strategy
that overcomes the long-tailed problem and achieves fuller learning of sparse
data. It also utilizes a dual-property network to address the issue of mutual
constraints on the safety and accuracy of medication combinations,
synergistically enhancing these two properties. Specifically, we construct a
pre-training method using deep learning networks to obtain medication and
disease representations. After that, we design a pyramid-like stratification
method based on relevance to strengthen the expressiveness of sparse data.
Based on this relevance, we design two graph structures to express medication
safety and precision at the same level to obtain patient representations.
Finally, the patient's historical clinical information is fitted to generate
medication combinations for the current health condition. We employed the
MIMIC-III dataset to evaluate our model against state-of-the-art methods in
three aspects comprehensively. Compared to the sub-optimal baseline model, our
model reduces safety risk by 15.08\%, improves accuracy by 0.36\%, and reduces
training time consumption by 81.66\%.",2023-08-31,2023,2023-08,medical
"Interpretable Medical Imagery Diagnosis with Self-Attentive
  Transformers: A Review of Explainable AI for Health Care","Recent advancements in artificial intelligence (AI) have facilitated its
widespread adoption in primary medical services, addressing the demand-supply
imbalance in healthcare. Vision Transformers (ViT) have emerged as
state-of-the-art computer vision models, benefiting from self-attention
modules. However, compared to traditional machine-learning approaches,
deep-learning models are complex and are often treated as a ""black box"" that
can cause uncertainty regarding how they operate. Explainable Artificial
Intelligence (XAI) refers to methods that explain and interpret machine
learning models' inner workings and how they come to decisions, which is
especially important in the medical domain to guide the healthcare
decision-making process. This review summarises recent ViT advancements and
interpretative approaches to understanding the decision-making process of ViT,
enabling transparency in medical diagnosis applications.",2023-09-01,2023,2023-09,medical
MedChatZH: a Better Medical Adviser Learns from Better Instructions,"Generative large language models (LLMs) have shown great success in various
applications, including question-answering (QA) and dialogue systems. However,
in specialized domains like traditional Chinese medical QA, these models may
perform unsatisfactorily without fine-tuning on domain-specific datasets. To
address this, we introduce MedChatZH, a dialogue model designed specifically
for traditional Chinese medical QA. Our model is pre-trained on Chinese
traditional medical books and fine-tuned with a carefully curated medical
instruction dataset. It outperforms several solid baselines on a real-world
medical dialogue dataset. We release our model, code, and dataset on
https://github.com/tyang816/MedChatZH to facilitate further research in the
domain of traditional Chinese medicine and LLMs.",2023-09-03,2023,2023-09,medical
"Augmenting Black-box LLMs with Medical Textbooks for Biomedical Question
  Answering","Large-scale language models (LLMs) like ChatGPT have demonstrated impressive
abilities in generating responses based on human instructions. However, their
use in the medical field can be challenging due to their lack of specific,
in-depth knowledge. In this study, we present a system called LLMs Augmented
with Medical Textbooks (LLM-AMT) designed to enhance the proficiency of LLMs in
specialized domains. LLM-AMT integrates authoritative medical textbooks into
the LLMs' framework using plug-and-play modules. These modules include a Query
Augmenter, a Hybrid Textbook Retriever, and a Knowledge Self-Refiner. Together,
they incorporate authoritative medical knowledge. Additionally, an LLM Reader
aids in contextual understanding. Our experimental results on three medical QA
tasks demonstrate that LLMAMT significantly improves response quality, with
accuracy gains ranging from 11.6% to 16.6%. Notably, with GPT-4-Turbo as the
base model, LLM-AMT outperforms the specialized Med-PaLM 2 model pre-trained on
a massive amount of medical corpus by 2-3%. We found that despite being 100x
smaller in size, medical textbooks as a retrieval corpus is proven to be a more
effective knowledge database than Wikipedia in the medical domain, boosting
performance by 7.8%-13.7%.",2023-09-05,2023,2023-09,medical
"Knowledge-tuning Large Language Models with Structured Medical Knowledge
  Bases for Reliable Response Generation in Chinese","Large Language Models (LLMs) have demonstrated remarkable success in diverse
natural language processing (NLP) tasks in general domains. However, LLMs
sometimes generate responses with the hallucination about medical facts due to
limited domain knowledge. Such shortcomings pose potential risks in the
utilization of LLMs within medical contexts. To address this challenge, we
propose knowledge-tuning, which leverages structured medical knowledge bases
for the LLMs to grasp domain knowledge efficiently and facilitate reliable
response generation. We also release cMedKnowQA, a Chinese medical knowledge
question-answering dataset constructed from medical knowledge bases to assess
the medical knowledge proficiency of LLMs. Experimental results show that the
LLMs which are knowledge-tuned with cMedKnowQA, can exhibit higher levels of
accuracy in response generation compared with vanilla instruction-tuning and
offer a new reliable way for the domain adaptation of LLMs.",2023-09-08,2023,2023-09,medical
"Systematic Review of Techniques in Brain Image Synthesis using Deep
  Learning","This review paper delves into the present state of medical imaging, with a
specific focus on the use of deep learning techniques for brain image
synthesis. The need for medical image synthesis to improve diagnostic accuracy
and decrease invasiveness in medical procedures is emphasized, along with the
role of deep learning in enabling these advancements. The paper examines
various methods and techniques for brain image synthesis, including 2D to 3D
constructions, MRI synthesis, and the use of transformers. It also addresses
limitations and challenges faced in these methods, such as obtaining
well-curated training data and addressing brain ultrasound issues. The review
concludes by exploring the future potential of this field and the opportunities
for further advancements in medical imaging using deep learning techniques. The
significance of transformers and their potential to revolutionize the medical
imaging field is highlighted. Additionally, the paper discusses the potential
solutions to the shortcomings and limitations faced in this field. The review
provides researchers with an updated reference on the present state of the
field and aims to inspire further research and bridge the gap between the
present state of medical imaging and the future possibilities offered by deep
learning techniques.",2023-09-08,2023,2023-09,medical
"SHAPE: A Sample-adaptive Hierarchical Prediction Network for Medication
  Recommendation","Effectively medication recommendation with complex multimorbidity conditions
is a critical task in healthcare. Most existing works predicted medications
based on longitudinal records, which assumed the information transmitted
patterns of learning longitudinal sequence data are stable and intra-visit
medical events are serialized. However, the following conditions may have been
ignored: 1) A more compact encoder for intra-relationship in the intra-visit
medical event is urgent; 2) Strategies for learning accurate representations of
the variable longitudinal sequences of patients are different. In this paper,
we proposed a novel Sample-adaptive Hierarchical medicAtion Prediction nEtwork,
termed SHAPE, to tackle the above challenges in the medication recommendation
task. Specifically, we design a compact intra-visit set encoder to encode the
relationship in the medical event for obtaining visit-level representation and
then develop an inter-visit longitudinal encoder to learn the patient-level
longitudinal representation efficiently. To endow the model with the capability
of modeling the variable visit length, we introduce a soft curriculum learning
method to assign the difficulty of each sample automatically by the visit
length. Extensive experiments on a benchmark dataset verify the superiority of
our model compared with several state-of-the-art baselines.",2023-09-09,2023,2023-09,medical
"Functional requirements to mitigate the Risk of Harm to Patients from
  Artificial Intelligence in Healthcare","The Directorate General for Parliamentary Research Services of the European
Parliament has prepared a report to the Members of the European Parliament
where they enumerate seven main risks of Artificial Intelligence (AI) in
medicine and healthcare: patient harm due to AI errors, misuse of medical AI
tools, bias in AI and the perpetuation of existing inequities, lack of
transparency, privacy and security issues, gaps in accountability, and
obstacles in implementation.
  In this study, we propose fourteen functional requirements that AI systems
may implement to reduce the risks associated with their medical purpose: AI
passport, User management, Regulation check, Academic use only disclaimer, data
quality assessment, Clinicians double check, Continuous performance evaluation,
Audit trail, Continuous usability test, Review of retrospective/simulated
cases, Bias check, eXplainable AI, Encryption and use of field-tested
libraries, and Semantic interoperability.
  Our intention here is to provide specific high-level specifications of
technical solutions to ensure continuous good performance and use of AI systems
to benefit patients in compliance with the future EU regulatory framework.",2023-09-19,2023,2023-09,medical
"When to Trust AI: Advances and Challenges for Certification of Neural
  Networks","Artificial intelligence (AI) has been advancing at a fast pace and it is now
poised for deployment in a wide range of applications, such as autonomous
systems, medical diagnosis and natural language processing. Early adoption of
AI technology for real-world applications has not been without problems,
particularly for neural networks, which may be unstable and susceptible to
adversarial examples. In the longer term, appropriate safety assurance
techniques need to be developed to reduce potential harm due to avoidable
system failures and ensure trustworthiness. Focusing on certification and
explainability, this paper provides an overview of techniques that have been
developed to ensure safety of AI decisions and discusses future challenges.",2023-09-20,2023,2023-09,medical
A Systematic Review of Few-Shot Learning in Medical Imaging,"The lack of annotated medical images limits the performance of deep learning
models, which usually need large-scale labelled datasets. Few-shot learning
techniques can reduce data scarcity issues and enhance medical image analysis,
especially with meta-learning. This systematic review gives a comprehensive
overview of few-shot learning in medical imaging. We searched the literature
systematically and selected 80 relevant articles published from 2018 to 2023.
We clustered the articles based on medical outcomes, such as tumour
segmentation, disease classification, and image registration; anatomical
structure investigated (i.e. heart, lung, etc.); and the meta-learning method
used. For each cluster, we examined the papers' distributions and the results
provided by the state-of-the-art. In addition, we identified a generic pipeline
shared among all the studies. The review shows that few-shot learning can
overcome data scarcity in most outcomes and that meta-learning is a popular
choice to perform few-shot learning because it can adapt to new tasks with few
labelled samples. In addition, following meta-learning, supervised learning and
semi-supervised learning stand out as the predominant techniques employed to
tackle few-shot learning challenges in medical imaging and also best
performing. Lastly, we observed that the primary application areas
predominantly encompass cardiac, pulmonary, and abdominal domains. This
systematic review aims to inspire further research to improve medical image
analysis and patient care.",2023-09-20,2023,2023-09,medical
"Towards using Cough for Respiratory Disease Diagnosis by leveraging
  Artificial Intelligence: A Survey","Cough acoustics contain multitudes of vital information about
pathomorphological alterations in the respiratory system. Reliable and accurate
detection of cough events by investigating the underlying cough latent features
and disease diagnosis can play an indispensable role in revitalizing the
healthcare practices. The recent application of Artificial Intelligence (AI)
and advances of ubiquitous computing for respiratory disease prediction has
created an auspicious trend and myriad of future possibilities in the medical
domain. In particular, there is an expeditiously emerging trend of Machine
learning (ML) and Deep Learning (DL)-based diagnostic algorithms exploiting
cough signatures. The enormous body of literature on cough-based AI algorithms
demonstrate that these models can play a significant role for detecting the
onset of a specific respiratory disease. However, it is pertinent to collect
the information from all relevant studies in an exhaustive manner for the
medical experts and AI scientists to analyze the decisive role of AI/ML. This
survey offers a comprehensive overview of the cough data-driven ML/DL detection
and preliminary diagnosis frameworks, along with a detailed list of significant
features. We investigate the mechanism that causes cough and the latent cough
features of the respiratory modalities. We also analyze the customized cough
monitoring application, and their AI-powered recognition algorithms. Challenges
and prospective future research directions to develop practical, robust, and
ubiquitous solutions are also discussed in detail.",2023-09-24,2023,2023-09,medical
"Can-SAVE: Mass Cancer Risk Prediction via Survival Analysis Variables
  and EHR","Specific medical cancer screening methods are often costly, time-consuming,
and weakly applicable on a large scale. Advanced Artificial Intelligence (AI)
methods greatly help cancer detection but require specific or deep medical
data. These aspects prevent the mass implementation of cancer screening
methods. For this reason, it is a disruptive change for healthcare to apply AI
methods for mass personalized assessment of the cancer risk among patients
based on the existing Electronic Health Records (EHR) volume. This paper
presents a novel Can-SAVE cancer risk assessment method combining a survival
analysis approach with a gradient-boosting algorithm. It is highly accessible
and resource-efficient, utilizing only a sequence of high-level medical events.
We tested the proposed method in a long-term retrospective experiment covering
more than 1.1 million people and four regions of Russia. The Can-SAVE method
significantly exceeds the baselines by the Average Precision metric of
22.8%$\pm$2.7% vs 15.1%$\pm$2.6%. The extensive ablation study also confirmed
the proposed method's dominant performance. The experiment supervised by
oncologists shows a reliable cancer patient detection rate of up to 84 out of
1000 selected. Such results surpass the medical screening strategies estimates;
the typical age-specific Number Needed to Screen is only 9 out of 1000 (for
colorectal cancer). Overall, our experiments show a 4.7-6.4 times improvement
in cancer detection rate (TOP@1k) compared to the traditional healthcare risk
estimation approach.",2023-09-26,2023,2023-09,medical
"Experience and Evidence are the eyes of an excellent summarizer! Towards
  Knowledge Infused Multi-modal Clinical Conversation Summarization","With the advancement of telemedicine, both researchers and medical
practitioners are working hand-in-hand to develop various techniques to
automate various medical operations, such as diagnosis report generation. In
this paper, we first present a multi-modal clinical conversation summary
generation task that takes a clinician-patient interaction (both textual and
visual information) and generates a succinct synopsis of the conversation. We
propose a knowledge-infused, multi-modal, multi-tasking medical domain
identification and clinical conversation summary generation
(MM-CliConSummation) framework. It leverages an adapter to infuse knowledge and
visual features and unify the fused feature vector using a gated mechanism.
Furthermore, we developed a multi-modal, multi-intent clinical conversation
summarization corpus annotated with intent, symptom, and summary. The extensive
set of experiments, both quantitatively and qualitatively, led to the following
findings: (a) critical significance of visuals, (b) more precise and medical
entity preserving summary with additional knowledge infusion, and (c) a
correlation between medical department identification and clinical synopsis
generation. Furthermore, the dataset and source code are available at
https://github.com/NLP-RL/MM-CliConSummation.",2023-09-27,2023,2023-09,medical
"MKRAG: Medical Knowledge Retrieval Augmented Generation for Medical
  Question Answering","Large Language Models (LLMs), although powerful in general domains, often
perform poorly on domain-specific tasks such as medical question answering
(QA). In addition, LLMs tend to function as ""black-boxes"", making it
challenging to modify their behavior. To address the problem, our work employs
a transparent process of retrieval augmented generation (RAG), aiming to
improve LLM responses without the need for fine-tuning or retraining.
Specifically, we propose a comprehensive retrieval strategy to extract medical
facts from an external knowledge base, and then inject them into the LLM's
query prompt. Focusing on medical QA, we evaluate the impact of different
retrieval models and the number of facts on LLM performance using the
MedQA-SMILE dataset. Notably, our retrieval-augmented Vicuna-7B model exhibited
an accuracy improvement from 44.46% to 48.54%. This work underscores the
potential of RAG to enhance LLM performance, offering a practical approach to
mitigate the challenges posed by black-box LLMs.",2023-09-27,2023,2023-09,medical
"Medical Foundation Models are Susceptible to Targeted Misinformation
  Attacks","Large language models (LLMs) have broad medical knowledge and can reason
about medical information across many domains, holding promising potential for
diverse medical applications in the near future. In this study, we demonstrate
a concerning vulnerability of LLMs in medicine. Through targeted manipulation
of just 1.1% of the model's weights, we can deliberately inject an incorrect
biomedical fact. The erroneous information is then propagated in the model's
output, whilst its performance on other biomedical tasks remains intact. We
validate our findings in a set of 1,038 incorrect biomedical facts. This
peculiar susceptibility raises serious security and trustworthiness concerns
for the application of LLMs in healthcare settings. It accentuates the need for
robust protective measures, thorough verification mechanisms, and stringent
management of access to these models, ensuring their reliable and safe use in
medical practice.",2023-09-29,2023,2023-09,medical
"A Foundation Model for General Moving Object Segmentation in Medical
  Images","Medical image segmentation aims to delineate the anatomical or pathological
structures of interest, playing a crucial role in clinical diagnosis. A
substantial amount of high-quality annotated data is crucial for constructing
high-precision deep segmentation models. However, medical annotation is highly
cumbersome and time-consuming, especially for medical videos or 3D volumes, due
to the huge labeling space and poor inter-frame consistency. Recently, a
fundamental task named Moving Object Segmentation (MOS) has made significant
advancements in natural images. Its objective is to delineate moving objects
from the background within image sequences, requiring only minimal annotations.
In this paper, we propose the first foundation model, named iMOS, for MOS in
medical images. Extensive experiments on a large multi-modal medical dataset
validate the effectiveness of the proposed iMOS. Specifically, with the
annotation of only a small number of images in the sequence, iMOS can achieve
satisfactory tracking and segmentation performance of moving objects throughout
the entire sequence in bi-directions. We hope that the proposed iMOS can help
accelerate the annotation speed of experts, and boost the development of
medical foundation models.",2023-09-29,2023,2023-09,medical
A Comprehensive Review of Generative AI in Healthcare,"The advancement of Artificial Intelligence (AI) has catalyzed revolutionary
changes across various sectors, notably in healthcare. Among the significant
developments in this field are the applications of generative AI models,
specifically transformers and diffusion models. These models have played a
crucial role in analyzing diverse forms of data, including medical imaging
(encompassing image reconstruction, image-to-image translation, image
generation, and image classification), protein structure prediction, clinical
documentation, diagnostic assistance, radiology interpretation, clinical
decision support, medical coding, and billing, as well as drug design and
molecular representation. Such applications have enhanced clinical diagnosis,
data reconstruction, and drug synthesis. This review paper aims to offer a
thorough overview of the generative AI applications in healthcare, focusing on
transformers and diffusion models. Additionally, we propose potential
directions for future research to tackle the existing limitations and meet the
evolving demands of the healthcare sector. Intended to serve as a comprehensive
guide for researchers and practitioners interested in the healthcare
applications of generative AI, this review provides valuable insights into the
current state of the art, challenges faced, and prospective future directions.",2023-10-01,2023,2023-10,medical
"Generating Explanations in Medical Question-Answering by Expectation
  Maximization Inference over Evidence","Medical Question Answering~(medical QA) systems play an essential role in
assisting healthcare workers in finding answers to their questions. However, it
is not sufficient to merely provide answers by medical QA systems because users
might want explanations, that is, more analytic statements in natural language
that describe the elements and context that support the answer. To do so, we
propose a novel approach for generating natural language explanations for
answers predicted by medical QA systems. As high-quality medical explanations
require additional medical knowledge, so that our system extract knowledge from
medical textbooks to enhance the quality of explanations during the explanation
generation process. Concretely, we designed an expectation-maximization
approach that makes inferences about the evidence found in these texts,
offering an efficient way to focus attention on lengthy evidence passages.
Experimental results, conducted on two datasets MQAE-diag and MQAE, demonstrate
the effectiveness of our framework for reasoning with textual evidence. Our
approach outperforms state-of-the-art models, achieving a significant
improvement of \textbf{6.86} and \textbf{9.43} percentage points on the Rouge-1
score; \textbf{8.23} and \textbf{7.82} percentage points on the Bleu-4 score on
the respective datasets.",2023-10-02,2023,2023-10,medical
"Extraction of Medication and Temporal Relation from Clinical Text using
  Neural Language Models","Clinical texts, represented in electronic medical records (EMRs), contain
rich medical information and are essential for disease prediction, personalised
information recommendation, clinical decision support, and medication pattern
mining and measurement. Relation extractions between medication mentions and
temporal information can further help clinicians better understand the
patients' treatment history. To evaluate the performances of deep learning (DL)
and large language models (LLMs) in medication extraction and temporal
relations classification, we carry out an empirical investigation of
\textbf{MedTem} project using several advanced learning structures including
BiLSTM-CRF and CNN-BiLSTM for a clinical domain named entity recognition (NER),
and BERT-CNN for temporal relation extraction (RE), in addition to the
exploration of different word embedding techniques. Furthermore, we also
designed a set of post-processing roles to generate structured output on
medications and the temporal relation. Our experiments show that CNN-BiLSTM
slightly wins the BiLSTM-CRF model on the i2b2-2009 clinical NER task yielding
75.67, 77.83, and 78.17 for precision, recall, and F1 scores using Macro
Average. BERT-CNN model also produced reasonable evaluation scores 64.48,
67.17, and 65.03 for P/R/F1 using Macro Avg on the temporal relation extraction
test set from i2b2-2012 challenges. Code and Tools from MedTem will be hosted
at \url{https://github.com/HECTA-UoM/MedTem}",2023-10-03,2023,2023-10,medical
A ModelOps-based Framework for Intelligent Medical Knowledge Extraction,"Extracting medical knowledge from healthcare texts enhances downstream tasks
like medical knowledge graph construction and clinical decision-making.
However, the construction and application of knowledge extraction models lack
automation, reusability and unified management, leading to inefficiencies for
researchers and high barriers for non-AI experts such as doctors, to utilize
knowledge extraction. To address these issues, we propose a ModelOps-based
intelligent medical knowledge extraction framework that offers a low-code
system for model selection, training, evaluation and optimization.
Specifically, the framework includes a dataset abstraction mechanism based on
multi-layer callback functions, a reusable model training, monitoring and
management mechanism. We also propose a model recommendation method based on
dataset similarity, which helps users quickly find potentially suitable models
for a given dataset. Our framework provides convenience for researchers to
develop models and simplifies model access for non-AI experts such as doctors.",2023-10-04,2023,2023-10,medical
"Integrating UMLS Knowledge into Large Language Models for Medical
  Question Answering","Large language models (LLMs) have demonstrated powerful text generation
capabilities, bringing unprecedented innovation to the healthcare field. While
LLMs hold immense promise for applications in healthcare, applying them to real
clinical scenarios presents significant challenges, as these models may
generate content that deviates from established medical facts and even exhibit
potential biases. In our research, we develop an augmented LLM framework based
on the Unified Medical Language System (UMLS), aiming to better serve the
healthcare community. We employ LLaMa2-13b-chat and ChatGPT-3.5 as our
benchmark models, and conduct automatic evaluations using the ROUGE Score and
BERTScore on 104 questions from the LiveQA test set. Additionally, we establish
criteria for physician-evaluation based on four dimensions: Factuality,
Completeness, Readability and Relevancy. ChatGPT-3.5 is used for physician
evaluation with 20 questions on the LiveQA test set. Multiple resident
physicians conducted blind reviews to evaluate the generated content, and the
results indicate that this framework effectively enhances the factuality,
completeness, and relevance of generated content. Our research demonstrates the
effectiveness of using UMLS-augmented LLMs and highlights the potential
application value of LLMs in in medical question-answering.",2023-10-04,2023,2023-10,medical
"Comprehensive Multimodal Segmentation in Medical Imaging: Combining
  YOLOv8 with SAM and HQ-SAM Models","This paper introduces a comprehensive approach for segmenting regions of
interest (ROI) in diverse medical imaging datasets, encompassing ultrasound, CT
scans, and X-ray images. The proposed method harnesses the capabilities of the
YOLOv8 model for approximate boundary box detection across modalities,
alongside the Segment Anything Model (SAM) and High Quality (HQ) SAM for fully
automatic and precise segmentation. To generate boundary boxes, the YOLOv8
model was trained using a limited set of 100 images and masks from each
modality. The results obtained from our approach are extensively computed and
analyzed, demonstrating its effectiveness and potential in medical image
analysis. Various evaluation metrics, including precision, recall, F1 score,
and Dice Score, were employed to quantify the accuracy of the segmentation
results. A comparative analysis was conducted to assess the individual and
combined performance of the YOLOv8, YOLOv8+SAM, and YOLOv8+HQ-SAM models. The
results indicate that the SAM model performs better than the other two models,
exhibiting higher segmentation accuracy and overall performance. While HQ-SAM
offers potential advantages, its incremental gains over the standard SAM model
may not justify the additional computational cost. The YOLOv8+SAM model shows
promise for enhancing medical image segmentation and its clinical implications.",2023-10-04,2023,2023-10,medical
"DKEC: Domain Knowledge Enhanced Multi-Label Classification for Diagnosis
  Prediction","Multi-label text classification (MLTC) tasks in the medical domain often face
the long-tail label distribution problem. Prior works have explored
hierarchical label structures to find relevant information for few-shot
classes, but mostly neglected to incorporate external knowledge from medical
guidelines. This paper presents DKEC, Domain Knowledge Enhanced Classification
for diagnosis prediction with two innovations: (1) automated construction of
heterogeneous knowledge graphs from external sources to capture semantic
relations among diverse medical entities, (2) incorporating the heterogeneous
knowledge graphs in few-shot classification using a label-wise attention
mechanism. We construct DKEC using three online medical knowledge sources and
evaluate it on a real-world Emergency Medical Services (EMS) dataset and a
public electronic health record (EHR) dataset. Results show that DKEC
outperforms the state-of-the-art label-wise attention networks and transformer
models of different sizes, particularly for the few-shot classes. More
importantly, it helps the smaller language models achieve comparable
performance to large language models.",2023-10-10,2023,2023-10,medical
Histogram- and Diffusion-Based Medical Out-of-Distribution Detection,"Out-of-distribution (OOD) detection is crucial for the safety and reliability
of artificial intelligence algorithms, especially in the medical domain. In the
context of the Medical OOD (MOOD) detection challenge 2023, we propose a
pipeline that combines a histogram-based method and a diffusion-based method.
The histogram-based method is designed to accurately detect homogeneous
anomalies in the toy examples of the challenge, such as blobs with constant
intensity values. The diffusion-based method is based on one of the latest
methods for unsupervised anomaly detection, called DDPM-OOD. We explore this
method and propose extensive post-processing steps for pixel-level and
sample-level anomaly detection on brain MRI and abdominal CT data provided by
the challenge. Our results show that the proposed DDPM method is sensitive to
blur and bias field samples, but faces challenges with anatomical deformation,
black slice, and swapped patches. These findings suggest that further research
is needed to improve the performance of DDPM for OOD detection in medical
images.",2023-10-12,2023,2023-10,medical
"Medical Text Simplification: Optimizing for Readability with
  Unlikelihood Training and Reranked Beam Search Decoding","Text simplification has emerged as an increasingly useful application of AI
for bridging the communication gap in specialized fields such as medicine,
where the lexicon is often dominated by technical jargon and complex
constructs. Despite notable progress, methods in medical simplification
sometimes result in the generated text having lower quality and diversity. In
this work, we explore ways to further improve the readability of text
simplification in the medical domain. We propose (1) a new unlikelihood loss
that encourages generation of simpler terms and (2) a reranked beam search
decoding method that optimizes for simplicity, which achieve better performance
on readability metrics on three datasets. This study's findings offer promising
avenues for improving text simplification in the medical field.",2023-10-17,2023,2023-10,medical
"Cloud-Magnetic Resonance Imaging System: In the Era of 6G and Artificial
  Intelligence","Magnetic Resonance Imaging (MRI) plays an important role in medical
diagnosis, generating petabytes of image data annually in large hospitals. This
voluminous data stream requires a significant amount of network bandwidth and
extensive storage infrastructure. Additionally, local data processing demands
substantial manpower and hardware investments. Data isolation across different
healthcare institutions hinders cross-institutional collaboration in clinics
and research. In this work, we anticipate an innovative MRI system and its four
generations that integrate emerging distributed cloud computing, 6G bandwidth,
edge computing, federated learning, and blockchain technology. This system is
called Cloud-MRI, aiming at solving the problems of MRI data storage security,
transmission speed, AI algorithm maintenance, hardware upgrading, and
collaborative work. The workflow commences with the transformation of k-space
raw data into the standardized Imaging Society for Magnetic Resonance in
Medicine Raw Data (ISMRMRD) format. Then, the data are uploaded to the cloud or
edge nodes for fast image reconstruction, neural network training, and
automatic analysis. Then, the outcomes are seamlessly transmitted to clinics or
research institutes for diagnosis and other services. The Cloud-MRI system will
save the raw imaging data, reduce the risk of data loss, facilitate
inter-institutional medical collaboration, and finally improve diagnostic
accuracy and work efficiency.",2023-10-18,2023,2023-10,medical
"Quantifying Self-diagnostic Atomic Knowledge in Chinese Medical
  Foundation Model: A Computational Analysis","Foundation Models (FMs) have the potential to revolutionize the way users
self-diagnose through search engines by offering direct and efficient
suggestions. Recent studies primarily focused on the quality of FMs evaluated
by GPT-4 or their ability to pass medical exams, no studies have quantified the
extent of self-diagnostic atomic knowledge stored in FMs' memory, which is the
basis of foundation models to provide factual and reliable suggestions. In this
paper, we first constructed a benchmark of Self-diagnostic Atomic Knowledge
(SdAK), including the most common types of atomic knowledge involved in
self-diagnostic queries, with 17 atomic types and a total of 14, 048 pieces of
atomic knowledge. Then, we evaluated both generic and open-source Chinese
medical FMs on the benchmark. The experimental results showcase that generic
FMs perform better than medical FMs in terms of self-diagnostic atomic
knowledge. Error analysis revealed that both generic and medical FMs are
sycophantic, e.g., always catering to users' claims when it comes to unknown
knowledge. We further explored different types of data commonly adopted for
fine-tuning medical FMs, i.e., real-world, semi-distilled, and distilled data,
and found that distilled data can benefit FMs most. The code and data are
available at https://github.com/FreedomIntelligence/SDAK.",2023-10-18,2023,2023-10,medical
"MTS-LOF: Medical Time-Series Representation Learning via
  Occlusion-Invariant Features","Medical time series data are indispensable in healthcare, providing critical
insights for disease diagnosis, treatment planning, and patient management. The
exponential growth in data complexity, driven by advanced sensor technologies,
has presented challenges related to data labeling. Self-supervised learning
(SSL) has emerged as a transformative approach to address these challenges,
eliminating the need for extensive human annotation. In this study, we
introduce a novel framework for Medical Time Series Representation Learning,
known as MTS-LOF. MTS-LOF leverages the strengths of contrastive learning and
Masked Autoencoder (MAE) methods, offering a unique approach to representation
learning for medical time series data. By combining these techniques, MTS-LOF
enhances the potential of healthcare applications by providing more
sophisticated, context-rich representations. Additionally, MTS-LOF employs a
multi-masking strategy to facilitate occlusion-invariant feature learning. This
approach allows the model to create multiple views of the data by masking
portions of it. By minimizing the discrepancy between the representations of
these masked patches and the fully visible patches, MTS-LOF learns to capture
rich contextual information within medical time series datasets. The results of
experiments conducted on diverse medical time series datasets demonstrate the
superiority of MTS-LOF over other methods. These findings hold promise for
significantly enhancing healthcare applications by improving representation
learning. Furthermore, our work delves into the integration of joint-embedding
SSL and MAE techniques, shedding light on the intricate interplay between
temporal and structural dependencies in healthcare data. This understanding is
crucial, as it allows us to grasp the complexities of healthcare data analysis.",2023-10-19,2023,2023-10,medical
The Hidden Adversarial Vulnerabilities of Medical Federated Learning,"In this paper, we delve into the susceptibility of federated medical image
analysis systems to adversarial attacks. Our analysis uncovers a novel
exploitation avenue: using gradient information from prior global model
updates, adversaries can enhance the efficiency and transferability of their
attacks. Specifically, we demonstrate that single-step attacks (e.g. FGSM),
when aptly initialized, can outperform the efficiency of their iterative
counterparts but with reduced computational demand. Our findings underscore the
need to revisit our understanding of AI security in federated healthcare
settings.",2023-10-21,2023,2023-10,medical
PromptCBLUE: A Chinese Prompt Tuning Benchmark for the Medical Domain,"Biomedical language understanding benchmarks are the driving forces for
artificial intelligence applications with large language model (LLM) back-ends.
However, most current benchmarks: (a) are limited to English which makes it
challenging to replicate many of the successes in English for other languages,
or (b) focus on knowledge probing of LLMs and neglect to evaluate how LLMs
apply these knowledge to perform on a wide range of bio-medical tasks, or (c)
have become a publicly available corpus and are leaked to LLMs during
pre-training. To facilitate the research in medical LLMs, we re-build the
Chinese Biomedical Language Understanding Evaluation (CBLUE) benchmark into a
large scale prompt-tuning benchmark, PromptCBLUE. Our benchmark is a suitable
test-bed and an online platform for evaluating Chinese LLMs' multi-task
capabilities on a wide range bio-medical tasks including medical entity
recognition, medical text classification, medical natural language inference,
medical dialogue understanding and medical content/dialogue generation. To
establish evaluation on these tasks, we have experimented and report the
results with the current 9 Chinese LLMs fine-tuned with differtent fine-tuning
techniques.",2023-10-22,2023,2023-10,medical
AlpaCare:Instruction-tuned Large Language Models for Medical Application,"Instruction-finetuning (IFT) has become crucial in aligning Large Language
Models (LLMs) with diverse human needs and has shown great potential in medical
applications. However, previous studies mainly fine-tune LLMs on biomedical
datasets with limited diversity, which often rely on benchmarks or narrow task
scopes, and hence significantly limit the effectiveness on their medical
instruction-following ability and generalizability. To bridge this gap, we
propose creating a diverse, machine-generated medical IFT dataset,
MedInstruct-52k, using GPT-4 and ChatGPT with a high-quality expert-curated
seed set. We then fine-tune LLaMA-series models on the dataset to develop
AlpaCare. Despite using a smaller domain-specific dataset than previous medical
LLMs, AlpaCare not only demonstrates superior performance on medical
applications, with up to 38.1% absolute gain over best baselines in medical
free-form instruction evaluations, but also achieves 6.7% absolute gains
averaged over multiple general domain benchmarks. Human evaluation further
shows that AlpaCare consistently outperforms best baselines in terms of both
correctness and helpfulness. We offer public access to our data, model, and
codebase in https://github.com/XZhang97666/AlpaCare.",2023-10-23,2023,2023-10,medical
"Three-dimensional Bone Image Synthesis with Generative Adversarial
  Networks","Medical image processing has been highlighted as an area where deep
learning-based models have the greatest potential. However, in the medical
field in particular, problems of data availability and privacy are hampering
research progress and thus rapid implementation in clinical routine. The
generation of synthetic data not only ensures privacy, but also allows to
\textit{draw} new patients with specific characteristics, enabling the
development of data-driven models on a much larger scale. This work
demonstrates that three-dimensional generative adversarial networks (GANs) can
be efficiently trained to generate high-resolution medical volumes with finely
detailed voxel-based architectures. In addition, GAN inversion is successfully
implemented for the three-dimensional setting and used for extensive research
on model interpretability and applications such as image morphing, attribute
editing and style mixing. The results are comprehensively validated on a
database of three-dimensional HR-pQCT instances representing the bone
micro-architecture of the distal radius.",2023-10-26,2023,2023-10,medical
Generating Medical Prescriptions with Conditional Transformer,"Access to real-world medication prescriptions is essential for medical
research and healthcare quality improvement. However, access to real medication
prescriptions is often limited due to the sensitive nature of the information
expressed. Additionally, manually labelling these instructions for training and
fine-tuning Natural Language Processing (NLP) models can be tedious and
expensive. We introduce a novel task-specific model architecture,
Label-To-Text-Transformer (\textbf{LT3}), tailored to generate synthetic
medication prescriptions based on provided labels, such as a vocabulary list of
medications and their attributes. LT3 is trained on a set of around 2K lines of
medication prescriptions extracted from the MIMIC-III database, allowing the
model to produce valuable synthetic medication prescriptions. We evaluate LT3's
performance by contrasting it with a state-of-the-art Pre-trained Language
Model (PLM), T5, analysing the quality and diversity of generated texts. We
deploy the generated synthetic data to train the SpacyNER model for the Named
Entity Recognition (NER) task over the n2c2-2018 dataset. The experiments show
that the model trained on synthetic data can achieve a 96-98\% F1 score at
Label Recognition on Drug, Frequency, Route, Strength, and Form. LT3 codes and
data will be shared at
\url{https://github.com/HECTA-UoM/Label-To-Text-Transformer}",2023-10-30,2023,2023-10,medical
Medical Image Denosing via Explainable AI Feature Preserving Loss,"Denoising algorithms play a crucial role in medical image processing and
analysis. However, classical denoising algorithms often ignore explanatory and
critical medical features preservation, which may lead to misdiagnosis and
legal liabilities. In this work, we propose a new denoising method for medical
images that not only efficiently removes various types of noise, but also
preserves key medical features throughout the process. To achieve this goal, we
utilize a gradient-based eXplainable Artificial Intelligence (XAI) approach to
design a feature preserving loss function. Our feature preserving loss function
is motivated by the characteristic that gradient-based XAI is sensitive to
noise. Through backpropagation, medical image features before and after
denoising can be kept consistent. We conducted extensive experiments on three
available medical image datasets, including synthesized 13 different types of
noise and artifacts. The experimental results demonstrate the superiority of
our method in terms of denoising performance, model explainability, and
generalization.",2023-10-31,2023,2023-10,medical
"A Systematic Evaluation of GPT-4V's Multimodal Capability for Medical
  Image Analysis","This work conducts an evaluation of GPT-4V's multimodal capability for
medical image analysis, with a focus on three representative tasks of radiology
report generation, medical visual question answering, and medical visual
grounding. For the evaluation, a set of prompts is designed for each task to
induce the corresponding capability of GPT-4V to produce sufficiently good
outputs. Three evaluation ways including quantitative analysis, human
evaluation, and case study are employed to achieve an in-depth and extensive
evaluation. Our evaluation shows that GPT-4V excels in understanding medical
images and is able to generate high-quality radiology reports and effectively
answer questions about medical images. Meanwhile, it is found that its
performance for medical visual grounding needs to be substantially improved. In
addition, we observe the discrepancy between the evaluation outcome from
quantitative analysis and that from human evaluation. This discrepancy suggests
the limitations of conventional metrics in assessing the performance of large
language models like GPT-4V and the necessity of developing new metrics for
automatic quantitative analysis.",2023-10-31,2023,2023-10,medical
"healthAIChain: Improving security and safety using Blockchain Technology
  applications in AI-based healthcare systems","Blockchain as a digital ledger for keeping records of digital transactions
and other information, it is secure and decentralized technology. The globally
growing number of digital population every day possesses a significant threat
to online data including the medical and patients data. After bitcoin,
blockchain technology has emerged into a general-purpose technology with
applications in medical industries and healthcare. Blockchain can promote
highly configurable openness while retaining the highest security standards for
critical data of medical patients. Referred to as distributed record keeping
for healthcare systems which makes digital assets unalterable and transparent
via a cryptographic hash and decentralized network. The study delves into the
security and safety improvement associated with implementing blockchain in
AI-based healthcare systems. Blockchain-enabled AI tackles the existing issues
related to security, performance efficiencies, and safety in healthcare
systems. We have also examined the Artificial Intelligence in healthcare and
medical industry, potential areas, open questions concerning the blockchain in
healthcare systems. Finally, the article proposed an AI-based healthcare
blockchain model (healthAIChain) to improve patients data and security.",2023-11-01,2023,2023-11,medical
"Continuous Training and Fine-tuning for Domain-Specific Language Models
  in Medical Question Answering","Large language models exhibit promising general capabilities but often lack
specialized knowledge for domain-specific tasks. Developing domain experts from
a base model enables a range of applications without prohibitive training
costs. This work demonstrates a method using continuous training and
instruction fine-tuning to rapidly adapt Llama 2 base models to the Chinese
medical domain. We first conduct continuous training on 1B tokens from Chinese
medical references to teach relevant vocabulary and knowledge. The models are
then fine-tuned on 54K examples sourced from the Chinese National Medical
Licensing Examination. Experiments on Chinese medical data confirm the
effectiveness of this approach, producing a model comparable to GPT-3.5-turbo
while using way less computational resource. The resulting domain-specific
model could be useful for various Chinese medical applications. More broadly,
this provides a template for domain-specific training of large language models
in areas where pre-trained models lack the required expertise, such as law,
science, and engineering.",2023-11-01,2023,2023-11,medical
"Sam-Guided Enhanced Fine-Grained Encoding with Mixed Semantic Learning
  for Medical Image Captioning","With the development of multimodality and large language models, the deep
learning-based technique for medical image captioning holds the potential to
offer valuable diagnostic recommendations. However, current generic text and
image pre-trained models do not yield satisfactory results when it comes to
describing intricate details within medical images. In this paper, we present a
novel medical image captioning method guided by the segment anything model
(SAM) to enable enhanced encoding with both general and detailed feature
extraction. In addition, our approach employs a distinctive pre-training
strategy with mixed semantic learning to simultaneously capture both the
overall information and finer details within medical images. We demonstrate the
effectiveness of this approach, as it outperforms the pre-trained BLIP2 model
on various evaluation metrics for generating descriptions of medical images.",2023-11-02,2023,2023-11,medical
"Towards objective and systematic evaluation of bias in artificial
  intelligence for medical imaging","Artificial intelligence (AI) models trained using medical images for clinical
tasks often exhibit bias in the form of disparities in performance between
subgroups. Since not all sources of biases in real-world medical imaging data
are easily identifiable, it is challenging to comprehensively assess how those
biases are encoded in models, and how capable bias mitigation methods are at
ameliorating performance disparities. In this article, we introduce a novel
analysis framework for systematically and objectively investigating the impact
of biases in medical images on AI models. We developed and tested this
framework for conducting controlled in silico trials to assess bias in medical
imaging AI using a tool for generating synthetic magnetic resonance images with
known disease effects and sources of bias. The feasibility is showcased by
using three counterfactual bias scenarios to measure the impact of simulated
bias effects on a convolutional neural network (CNN) classifier and the
efficacy of three bias mitigation strategies. The analysis revealed that the
simulated biases resulted in expected subgroup performance disparities when the
CNN was trained on the synthetic datasets. Moreover, reweighing was identified
as the most successful bias mitigation strategy for this setup, and we
demonstrated how explainable AI methods can aid in investigating the
manifestation of bias in the model using this framework. Developing fair AI
models is a considerable challenge given that many and often unknown sources of
biases can be present in medical imaging datasets. In this work, we present a
novel methodology to objectively study the impact of biases and mitigation
strategies on deep learning pipelines, which can support the development of
clinical AI that is robust and responsible.",2023-11-03,2023,2023-11,medical
"FaMeSumm: Investigating and Improving Faithfulness of Medical
  Summarization","Summaries of medical text shall be faithful by being consistent and factual
with source inputs, which is an important but understudied topic for safety and
efficiency in healthcare. In this paper, we investigate and improve
faithfulness in summarization on a broad range of medical summarization tasks.
Our investigation reveals that current summarization models often produce
unfaithful outputs for medical input text. We then introduce FaMeSumm, a
framework to improve faithfulness by fine-tuning pre-trained language models
based on medical knowledge. FaMeSumm performs contrastive learning on designed
sets of faithful and unfaithful summaries, and it incorporates medical terms
and their contexts to encourage faithful generation of medical terms. We
conduct comprehensive experiments on three datasets in two languages: health
question and radiology report summarization datasets in English, and a
patient-doctor dialogue dataset in Chinese. Results demonstrate that FaMeSumm
is flexible and effective by delivering consistent improvements over mainstream
language models such as BART, T5, mT5, and PEGASUS, yielding state-of-the-art
performances on metrics for faithfulness and general quality. Human evaluation
by doctors also shows that FaMeSumm generates more faithful outputs. Our code
is available at https://github.com/psunlpgroup/FaMeSumm .",2023-11-03,2023,2023-11,medical
"Large Language Models Illuminate a Progressive Pathway to Artificial
  Healthcare Assistant: A Review","With the rapid development of artificial intelligence, large language models
(LLMs) have shown promising capabilities in mimicking human-level language
comprehension and reasoning. This has sparked significant interest in applying
LLMs to enhance various aspects of healthcare, ranging from medical education
to clinical decision support. However, medicine involves multifaceted data
modalities and nuanced reasoning skills, presenting challenges for integrating
LLMs. This paper provides a comprehensive review on the applications and
implications of LLMs in medicine. It begins by examining the fundamental
applications of general-purpose and specialized LLMs, demonstrating their
utilities in knowledge retrieval, research support, clinical workflow
automation, and diagnostic assistance. Recognizing the inherent multimodality
of medicine, the review then focuses on multimodal LLMs, investigating their
ability to process diverse data types like medical imaging and EHRs to augment
diagnostic accuracy. To address LLMs' limitations regarding personalization and
complex clinical reasoning, the paper explores the emerging development of
LLM-powered autonomous agents for healthcare. Furthermore, it summarizes the
evaluation methodologies for assessing LLMs' reliability and safety in medical
contexts. Overall, this review offers an extensive analysis on the
transformative potential of LLMs in modern medicine. It also highlights the
pivotal need for continuous optimizations and ethical oversight before these
models can be effectively integrated into clinical practice. Visit
https://github.com/mingze-yuan/Awesome-LLM-Healthcare for an accompanying
GitHub repository containing latest papers.",2023-11-03,2023,2023-11,medical
"Class-Incremental Continual Learning for General Purpose Healthcare
  Models","Healthcare clinics regularly encounter dynamic data that changes due to
variations in patient populations, treatment policies, medical devices, and
emerging disease patterns. Deep learning models can suffer from catastrophic
forgetting when fine-tuned in such scenarios, causing poor performance on
previously learned tasks. Continual learning allows learning on new tasks
without performance drop on previous tasks. In this work, we investigate the
performance of continual learning models on four different medical imaging
scenarios involving ten classification datasets from diverse modalities,
clinical specialties, and hospitals. We implement various continual learning
approaches and evaluate their performance in these scenarios. Our results
demonstrate that a single model can sequentially learn new tasks from different
specialties and achieve comparable performance to naive methods. These findings
indicate the feasibility of recycling or sharing models across the same or
different medical specialties, offering another step towards the development of
general-purpose medical imaging AI that can be shared across institutions.",2023-11-07,2023,2023-11,medical
Evaluating Large Language Models in Ophthalmology,"Purpose: The performance of three different large language models (LLMS)
(GPT-3.5, GPT-4, and PaLM2) in answering ophthalmology professional questions
was evaluated and compared with that of three different professional
populations (medical undergraduates, medical masters, and attending
physicians). Methods: A 100-item ophthalmology single-choice test was
administered to three different LLMs (GPT-3.5, GPT-4, and PaLM2) and three
different professional levels (medical undergraduates, medical masters, and
attending physicians), respectively. The performance of LLM was comprehensively
evaluated and compared with the human group in terms of average score,
stability, and confidence. Results: Each LLM outperformed undergraduates in
general, with GPT-3.5 and PaLM2 being slightly below the master's level, while
GPT-4 showed a level comparable to that of attending physicians. In addition,
GPT-4 showed significantly higher answer stability and confidence than GPT-3.5
and PaLM2. Conclusion: Our study shows that LLM represented by GPT-4 performs
better in the field of ophthalmology. With further improvements, LLM will bring
unexpected benefits in medical education and clinical decision making in the
near future.",2023-11-07,2023,2023-11,medical
"Generalization in medical AI: a perspective on developing scalable
  models","The scientific community is increasingly recognizing the importance of
generalization in medical AI for translating research into practical clinical
applications. A three-level scale is introduced to characterize
out-of-distribution generalization performance of medical AI models. This scale
addresses the diversity of real-world medical scenarios as well as whether
target domain data and labels are available for model recalibration. It serves
as a tool to help researchers characterize their development settings and
determine the best approach to tackling the challenge of out-of-distribution
generalization.",2023-11-09,2023,2023-11,medical
"Multimodal Foundation Models Exploit Text to Make Medical Image
  Predictions","Multimodal foundation models have shown compelling but conflicting
performance in medical image interpretation. However, the mechanisms by which
these models integrate and prioritize different data modalities, including
images and text, remain poorly understood. Here, using a diverse collection of
1014 multimodal medical cases, we evaluate the unimodal and multimodal image
interpretation abilities of proprietary (GPT-4, Gemini Pro 1.0) and open-source
(Llama-3.2-90B, LLaVA-Med-v1.5) multimodal foundational models with and without
the use of text descriptions. Across all models, image predictions were largely
driven by exploiting text, with accuracy increasing monotonically with the
amount of informative text. By contrast, human performance on medical image
interpretation did not improve with informative text. Exploitation of text is a
double-edged sword; we show that even mild suggestions of an incorrect
diagnosis in text diminishes image-based classification, reducing performance
dramatically in cases the model could previously answer with images alone.
Finally, we conducted a physician evaluation of model performance on long-form
medical cases, finding that the provision of images either reduced or had no
effect on model performance when text is already highly informative. Our
results suggest that multimodal AI models may be useful in medical diagnostic
reasoning but that their accuracy is largely driven, for better and worse, by
their exploitation of text.",2023-11-09,2023,2023-11,medical
"A Diagnosis and Treatment of Liver Diseases: Integrating Batch
  Processing, Rule-Based Event Detection and Explainable Artificial
  Intelligence","Liver diseases pose a significant global health burden, impacting many
individuals and having substantial economic and social consequences. Rising
liver problems are considered a fatal disease in many countries, such as Egypt
and Moldova. This study aims to develop a diagnosis and treatment model for
liver disease using Basic Formal Ontology (BFO), Patient Clinical Data (PCD)
ontology, and detection rules derived from a decision tree algorithm. For the
development of the ontology, the National Viral Hepatitis Control Program
(NVHCP) guidelines were used, which made the ontology more accurate and
reliable. The Apache Jena framework uses batch processing to detect events
based on these rules. Based on the event detected, queries can be directly
processed using SPARQL. We convert these Decision Tree (DT) and medical
guidelines-based rules into Semantic Web Rule Language (SWRL) to operationalize
the ontology. Using this SWRL in the ontology to predict different types of
liver disease with the help of the Pellet and Drools inference engines in
Protege Tools, a total of 615 records were taken from different liver diseases.
After inferring the rules, the result can be generated for the patient
according to the rules, and other patient-related details, along with different
precautionary suggestions, can be obtained based on these results. These rules
can make suggestions more accurate with the help of Explainable Artificial
Intelligence (XAI) with open API-based suggestions. When the patient has
prescribed a medical test, the model accommodates this result using optical
character recognition (OCR), and the same process applies when the patient has
prescribed a further medical suggestion according to the test report. These
models combine to form a comprehensive Decision Support System (DSS) for the
diagnosis of liver disease.",2023-11-10,2023,2023-11,medical
PEFT-MedAware: Large Language Model for Medical Awareness,"Chat models are capable of answering a wide range of questions, however, the
accuracy of their responses is highly uncertain. In this research, we propose a
specialized PEFT-MedAware model where we utilize parameter-efficient
fine-tuning (PEFT) to enhance the Falcon-1b large language model on specialized
MedQuAD data consisting of 16,407 medical QA pairs, leveraging only 0.44% of
its trainable parameters to enhance computational efficiency. The paper adopts
data preprocessing and PEFT to optimize model performance, complemented by a
BitsAndBytesConfig for efficient transformer training. The resulting model was
capable of outperforming other LLMs in medical question-answering tasks in
specific domains with greater accuracy utilizing limited computational
resources making it suitable for deployment in resource-constrained
environments. We propose further improvements through expanded datasets, larger
models, and feedback mechanisms for sustained medical relevancy. Our work
highlights the efficiency gains and specialized capabilities of PEFT in medical
AI, outpacing standard models in precision without extensive resource demands.
The proposed model and data are released for research purposes only.",2023-11-17,2023,2023-11,medical
"INSPECT: A Multimodal Dataset for Pulmonary Embolism Diagnosis and
  Prognosis","Synthesizing information from multiple data sources plays a crucial role in
the practice of modern medicine. Current applications of artificial
intelligence in medicine often focus on single-modality data due to a lack of
publicly available, multimodal medical datasets. To address this limitation, we
introduce INSPECT, which contains de-identified longitudinal records from a
large cohort of patients at risk for pulmonary embolism (PE), along with ground
truth labels for multiple outcomes. INSPECT contains data from 19,402 patients,
including CT images, radiology report impression sections, and structured
electronic health record (EHR) data (i.e. demographics, diagnoses, procedures,
vitals, and medications). Using INSPECT, we develop and release a benchmark for
evaluating several baseline modeling approaches on a variety of important PE
related tasks. We evaluate image-only, EHR-only, and multimodal fusion models.
Trained models and the de-identified dataset are made available for
non-commercial use under a data use agreement. To the best of our knowledge,
INSPECT is the largest multimodal dataset integrating 3D medical imaging and
EHR for reproducible methods evaluation and research.",2023-11-17,2023,2023-11,medical
"SA-Med2D-20M Dataset: Segment Anything in 2D Medical Imaging with 20
  Million masks","Segment Anything Model (SAM) has achieved impressive results for natural
image segmentation with input prompts such as points and bounding boxes. Its
success largely owes to massive labeled training data. However, directly
applying SAM to medical image segmentation cannot perform well because SAM
lacks medical knowledge -- it does not use medical images for training. To
incorporate medical knowledge into SAM, we introduce SA-Med2D-20M, a
large-scale segmentation dataset of 2D medical images built upon numerous
public and private datasets. It consists of 4.6 million 2D medical images and
19.7 million corresponding masks, covering almost the whole body and showing
significant diversity. This paper describes all the datasets collected in
SA-Med2D-20M and details how to process these datasets. Furthermore,
comprehensive statistics of SA-Med2D-20M are presented to facilitate the better
use of our dataset, which can help the researchers build medical vision
foundation models or apply their models to downstream medical applications. We
hope that the large scale and diversity of SA-Med2D-20M can be leveraged to
develop medical artificial intelligence for enhancing diagnosis, medical image
analysis, knowledge sharing, and education. The data with the redistribution
license is publicly available at https://github.com/OpenGVLab/SAM-Med2D.",2023-11-20,2023,2023-11,medical
"Energy efficiency in Edge TPU vs. embedded GPU for computer-aided
  medical imaging segmentation and classification","In this work, we evaluate the energy usage of fully embedded medical
diagnosis aids based on both segmentation and classification of medical images
implemented on Edge TPU and embedded GPU processors. We use glaucoma diagnosis
based on color fundus images as an example to show the possibility of
performing segmentation and classification in real time on embedded boards and
to highlight the different energy requirements of the studied implementations.
  Several other works develop the use of segmentation and feature extraction
techniques to detect glaucoma, among many other pathologies, with deep neural
networks. Memory limitations and low processing capabilities of embedded
accelerated systems (EAS) limit their use for deep network-based system
training. However, including specific acceleration hardware, such as NVIDIA's
Maxwell GPU or Google's Edge TPU, enables them to perform inferences using
complex pre-trained networks in very reasonable times.
  In this study, we evaluate the timing and energy performance of two EAS
equipped with Machine Learning (ML) accelerators executing an example
diagnostic tool developed in a previous work. For optic disc (OD) and cup (OC)
segmentation, the obtained prediction times per image are under 29 and 43 ms
using Edge TPUs and Maxwell GPUs, respectively. Prediction times for the
classification subsystem are lower than 10 and 14 ms for Edge TPUs and Maxwell
GPUs, respectively. Regarding energy usage, in approximate terms, for OD
segmentation Edge TPUs and Maxwell GPUs use 38 and 190 mJ per image,
respectively. For fundus classification, Edge TPUs and Maxwell GPUs use 45 and
70 mJ, respectively.",2023-11-20,2023,2023-11,medical
Medical Image Retrieval Using Pretrained Embeddings,"A wide range of imaging techniques and data formats available for medical
images make accurate retrieval from image databases challenging.
  Efficient retrieval systems are crucial in advancing medical research,
enabling large-scale studies and innovative diagnostic tools. Thus, addressing
the challenges of medical image retrieval is essential for the continued
enhancement of healthcare and research.
  In this study, we evaluated the feasibility of employing four
state-of-the-art pretrained models for medical image retrieval at modality,
body region, and organ levels and compared the results of two similarity
indexing approaches. Since the employed networks take 2D images, we analyzed
the impacts of weighting and sampling strategies to incorporate 3D information
during retrieval of 3D volumes. We showed that medical image retrieval is
feasible using pretrained networks without any additional training or
fine-tuning steps. Using pretrained embeddings, we achieved a recall of 1 for
various tasks at modality, body region, and organ level.",2023-11-22,2023,2023-11,medical
"Comparative Experimentation of Accuracy Metrics in Automated Medical
  Reporting: The Case of Otitis Consultations","Generative Artificial Intelligence (AI) can be used to automatically generate
medical reports based on transcripts of medical consultations. The aim is to
reduce the administrative burden that healthcare professionals face. The
accuracy of the generated reports needs to be established to ensure their
correctness and usefulness. There are several metrics for measuring the
accuracy of AI generated reports, but little work has been done towards the
application of these metrics in medical reporting. A comparative
experimentation of 10 accuracy metrics has been performed on AI generated
medical reports against their corresponding General Practitioner's (GP) medical
reports concerning Otitis consultations. The number of missing, incorrect, and
additional statements of the generated reports have been correlated with the
metric scores. In addition, we introduce and define a Composite Accuracy Score
which produces a single score for comparing the metrics within the field of
automated medical reporting. Findings show that based on the correlation study
and the Composite Accuracy Score, the ROUGE-L and Word Mover's Distance metrics
are the preferred metrics, which is not in line with previous work. These
findings help determine the accuracy of an AI generated medical report, which
aids the development of systems that generate medical reports for GPs to reduce
the administrative burden.",2023-11-22,2023,2023-11,medical
Machine Learning For An Explainable Cost Prediction of Medical Insurance,"Predictive modeling in healthcare continues to be an active actuarial
research topic as more insurance companies aim to maximize the potential of
Machine Learning approaches to increase their productivity and efficiency. In
this paper, the authors deployed three regression-based ensemble ML models that
combine variations of decision trees through Extreme Gradient Boosting,
Gradient-boosting Machine, and Random Forest) methods in predicting medical
insurance costs. Explainable Artificial Intelligence methods SHapley Additive
exPlanations and Individual Conditional Expectation plots were deployed to
discover and explain the key determinant factors that influence medical
insurance premium prices in the dataset. The dataset used comprised 986 records
and is publicly available in the KAGGLE repository. The models were evaluated
using four performance evaluation metrics, including R-squared, Mean Absolute
Error, Root Mean Squared Error, and Mean Absolute Percentage Error. The results
show that all models produced impressive outcomes; however, the XGBoost model
achieved a better overall performance although it also expanded more
computational resources, while the RF model recorded a lesser prediction error
and consumed far fewer computing resources than the XGBoost model. Furthermore,
we compared the outcome of both XAi methods in identifying the key determinant
features that influenced the PremiumPrices for each model and whereas both XAi
methods produced similar outcomes, we found that the ICE plots showed in more
detail the interactions between each variable than the SHAP analysis which
seemed to be more high-level. It is the aim of the authors that the
contributions of this study will help policymakers, insurers, and potential
medical insurance buyers in their decision-making process for selecting the
right policies that meet their specific needs.",2023-11-23,2023,2023-11,medical
"CMed-GPT: Prompt Tuning for Entity-Aware Chinese Medical Dialogue
  Generation","Medical dialogue generation relies on natural language generation techniques
to enable online medical consultations. Recently, the widespread adoption of
large-scale models in the field of natural language processing has facilitated
rapid advancements in this technology. Existing medical dialogue models are
mostly based on BERT and pre-trained on English corpora, but there is a lack of
high-performing models on the task of Chinese medical dialogue generation. To
solve the above problem, this paper proposes CMed-GPT, which is the GPT
pre-training language model based on Chinese medical domain text. The model is
available in two versions, namely, base and large, with corresponding
perplexity values of 8.64 and 8.01. Additionally, we incorporate lexical and
entity embeddings into the dialogue text in a uniform manner to meet the
requirements of downstream dialogue generation tasks. By applying both
fine-tuning and p-tuning to CMed-GPT, we lowered the PPL from 8.44 to 7.35.
This study not only confirms the exceptional performance of the CMed-GPT model
in generating Chinese biomedical text but also highlights the advantages of
p-tuning over traditional fine-tuning with prefix prompts. Furthermore, we
validate the significance of incorporating external information in medical
dialogue generation, which enhances the quality of dialogue generation.",2023-11-24,2023,2023-11,medical
"MRxaI: Black-Box Explainability for Image Classifiers in a Medical
  Setting","Existing tools for explaining the output of image classifiers can be divided
into white-box, which rely on access to the model internals, and black-box,
agnostic to the model. As the usage of AI in the medical domain grows, so too
does the usage of explainability tools. Existing work on medical image
explanations focuses on white-box tools, such as gradcam. However, there are
clear advantages to switching to a black-box tool, including the ability to use
it with any classifier and the wide selection of black-box tools available. On
standard images, black-box tools are as precise as white-box. In this paper we
compare the performance of several black-box methods against gradcam on a brain
cancer MRI dataset. We demonstrate that most black-box tools are not suitable
for explaining medical image classifications and present a detailed analysis of
the reasons for their shortcomings. We also show that one black-box tool, a
causal explainability-based rex, performs as well as \gradcam.",2023-11-24,2023,2023-11,medical
MEDITRON-70B: Scaling Medical Pretraining for Large Language Models,"Large language models (LLMs) can potentially democratize access to medical
knowledge. While many efforts have been made to harness and improve LLMs'
medical knowledge and reasoning capacities, the resulting models are either
closed-source (e.g., PaLM, GPT-4) or limited in scale (<= 13B parameters),
which restricts their abilities. In this work, we improve access to large-scale
medical LLMs by releasing MEDITRON: a suite of open-source LLMs with 7B and 70B
parameters adapted to the medical domain. MEDITRON builds on Llama-2 (through
our adaptation of Nvidia's Megatron-LM distributed trainer), and extends
pretraining on a comprehensively curated medical corpus, including selected
PubMed articles, abstracts, and internationally-recognized medical guidelines.
Evaluations using four major medical benchmarks show significant performance
gains over several state-of-the-art baselines before and after task-specific
finetuning. Overall, MEDITRON achieves a 6% absolute performance gain over the
best public baseline in its parameter class and 3% over the strongest baseline
we finetuned from Llama-2. Compared to closed-source LLMs, MEDITRON-70B
outperforms GPT-3.5 and Med-PaLM and is within 5% of GPT-4 and 10% of
Med-PaLM-2. We release our code for curating the medical pretraining corpus and
the MEDITRON model weights to drive open-source development of more capable
medical LLMs.",2023-11-27,2023,2023-11,medical
"De-identification of clinical free text using natural language
  processing: A systematic review of current approaches","Background: Electronic health records (EHRs) are a valuable resource for
data-driven medical research. However, the presence of protected health
information (PHI) makes EHRs unsuitable to be shared for research purposes.
De-identification, i.e. the process of removing PHI is a critical step in
making EHR data accessible. Natural language processing has repeatedly
demonstrated its feasibility in automating the de-identification process.
Objectives: Our study aims to provide systematic evidence on how the
de-identification of clinical free text has evolved in the last thirteen years,
and to report on the performances and limitations of the current
state-of-the-art systems. In addition, we aim to identify challenges and
potential research opportunities in this field. Methods: A systematic search in
PubMed, Web of Science and the DBLP was conducted for studies published between
January 2010 and February 2023. Titles and abstracts were examined to identify
the relevant studies. Selected studies were then analysed in-depth, and
information was collected on de-identification methodologies, data sources, and
measured performance. Results: A total of 2125 publications were identified for
the title and abstract screening. 69 studies were found to be relevant. Machine
learning (37 studies) and hybrid (26 studies) approaches are predominant, while
six studies relied only on rules. Majority of the approaches were trained and
evaluated on public corpora. The 2014 i2b2/UTHealth corpus is the most
frequently used (36 studies), followed by the 2006 i2b2 (18 studies) and 2016
CEGS N-GRID (10 studies) corpora.",2023-11-28,2023,2023-11,medical
"Explanatory Argument Extraction of Correct Answers in Resident Medical
  Exams","Developing the required technology to assist medical experts in their
everyday activities is currently a hot topic in the Artificial Intelligence
research field. Thus, a number of large language models (LLMs) and automated
benchmarks have recently been proposed with the aim of facilitating information
extraction in Evidence-Based Medicine (EBM) using natural language as a tool
for mediating in human-AI interaction. The most representative benchmarks are
limited to either multiple-choice or long-form answers and are available only
in English. In order to address these shortcomings, in this paper we present a
new dataset which, unlike previous work: (i) includes not only explanatory
arguments for the correct answer, but also arguments to reason why the
incorrect answers are not correct; (ii) the explanations are written originally
by medical doctors to answer questions from the Spanish Residency Medical
Exams. Furthermore, this new benchmark allows us to setup a novel extractive
task which consists of identifying the explanation of the correct answer
written by medical doctors. An additional benefit of our setting is that we can
leverage the extractive QA paradigm to automatically evaluate performance of
LLMs without resorting to costly manual evaluation by medical experts.
Comprehensive experimentation with language models for Spanish shows that
sometimes multilingual models fare better than monolingual ones, even
outperforming models which have been adapted to the medical domain.
Furthermore, results across the monolingual models are mixed, with supposedly
smaller and inferior models performing competitively. In any case, the obtained
results show that our novel dataset and approach can be an effective technique
to help medical practitioners in identifying relevant evidence-based
explanations for medical questions.",2023-12-01,2023,2023-12,medical
From Beginner to Expert: Modeling Medical Knowledge into General LLMs,"Recently, large language model (LLM) based artificial intelligence (AI)
systems have demonstrated remarkable capabilities in natural language
understanding and generation. However, these models face a significant
challenge when it comes to sensitive applications, such as reasoning over
medical knowledge and answering medical questions in a physician-like manner.
Prior studies attempted to overcome this challenge by increasing the model size
(>100B) to learn more general medical knowledge, while there is still room for
improvement in LLMs with smaller-scale model sizes (<100B). In this work, we
start from a pre-trained general LLM model (AntGLM-10B) and fine-tune it from a
medical beginner towards a medical expert (called AntGLM-Med-10B), which
leverages a 3-stage optimization procedure, i.e., general medical knowledge
injection, medical domain instruction tuning, and specific medical task
adaptation. Our contributions are threefold: (1) We specifically investigate
how to adapt a pre-trained general LLM in medical domain, especially for a
specific medical task. (2) We collect and construct large-scale medical
datasets for each stage of the optimization process. These datasets encompass
various data types and tasks, such as question-answering, medical reasoning,
multi-choice questions, and medical conversations. (3) Specifically for
multi-choice questions in the medical domain, we propose a novel
Verification-of-Choice approach for prompting engineering, which significantly
enhances the reasoning ability of LLMs. Remarkably, by combining the above
approaches, our AntGLM-Med-10B model can outperform the most of LLMs on
PubMedQA, including both general and medical LLMs, even when these LLMs have
larger model size.",2023-12-02,2023,2023-12,medical
"MKA: A Scalable Medical Knowledge Assisted Mechanism for Generative
  Models on Medical Conversation Tasks","Using natural language processing (NLP) technologies to develop medical
chatbots makes the diagnosis of the patient more convenient and efficient,
which is a typical application in healthcare AI. Because of its importance,
lots of research have been come out. Recently, the neural generative models
have shown their impressive ability as the core of chatbot, while it cannot
scale well when directly applied to medical conversation due to the lack of
medical-specific knowledge. To address the limitation, a scalable Medical
Knowledge Assisted mechanism, MKA, is proposed in this paper. The mechanism
aims to assist general neural generative models to achieve better performance
on the medical conversation task. The medical-specific knowledge graph is
designed within the mechanism, which contains 6 types of medical-related
information, including department, drug, check, symptom, disease, food.
Besides, the specific token concatenation policy is defined to effectively
inject medical information into the input data. Evaluation of our method is
carried out on two typical medical datasets, MedDG and MedDialog-CN. The
evaluation results demonstrate that models combined with our mechanism
outperform original methods in multiple automatic evaluation metrics. Besides,
MKA-Bert-GPT achieves state-of-the-art performance. The open-sourced codes are
public:
https://github.com/LIANGKE23/Knowledge_Assisted_Medical_Dialogue_Generation_Mechanism",2023-12-05,2023,2023-12,medical
Detecting algorithmic bias in medical-AI models using trees,"With the growing prevalence of machine learning and artificial
intelligence-based medical decision support systems, it is equally important to
ensure that these systems provide patient outcomes in a fair and equitable
fashion. This paper presents an innovative framework for detecting areas of
algorithmic bias in medical-AI decision support systems. Our approach
efficiently identifies potential biases in medical-AI models, specifically in
the context of sepsis prediction, by employing the Classification and
Regression Trees (CART) algorithm with conformity scores. We verify our
methodology by conducting a series of synthetic data experiments, showcasing
its ability to estimate areas of bias in controlled settings precisely. The
effectiveness of the concept is further validated by experiments using
electronic medical records from Grady Memorial Hospital in Atlanta, Georgia.
These tests demonstrate the practical implementation of our strategy in a
clinical environment, where it can function as a vital instrument for
guaranteeing fairness and equity in AI-based medical decisions.",2023-12-05,2023,2023-12,medical
"Improving Medical Report Generation with Adapter Tuning and Knowledge
  Enhancement in Vision-Language Foundation Models","Medical report generation demands automatic creation of coherent and precise
descriptions for medical images. However, the scarcity of labelled medical
image-report pairs poses formidable challenges in developing large-scale neural
networks capable of harnessing the potential of artificial intelligence,
exemplified by large language models. This study builds upon the
state-of-the-art vision-language pre-training and fine-tuning approach, BLIP-2,
to customize general large-scale foundation models. Integrating adapter tuning
and a medical knowledge enhancement loss, our model significantly improves
accuracy and coherence. Validation on the dataset of ImageCLEFmedical 2023
demonstrates our model's prowess, achieving the best-averaged results against
several state-of-the-art methods. Significant improvements in ROUGE and CIDEr
underscore our method's efficacy, highlighting promising outcomes for the rapid
medical-domain adaptation of the vision-language foundation models in
addressing challenges posed by data scarcity.",2023-12-07,2023,2023-12,medical
"Enhancing Medical Task Performance in GPT-4V: A Comprehensive Study on
  Prompt Engineering Strategies","OpenAI's latest large vision-language model (LVLM), GPT-4V(ision), has piqued
considerable interest for its potential in medical applications. Despite its
promise, recent studies and internal reviews highlight its underperformance in
specialized medical tasks. This paper explores the boundary of GPT-4V's
capabilities in medicine, particularly in processing complex imaging data from
endoscopies, CT scans, and MRIs etc. Leveraging open-source datasets, we
assessed its foundational competencies, identifying substantial areas for
enhancement. Our research emphasizes prompt engineering, an often-underutilized
strategy for improving AI responsiveness. Through iterative testing, we refined
the model's prompts, significantly improving its interpretative accuracy and
relevance in medical imaging. From our comprehensive evaluations, we distilled
10 effective prompt engineering techniques, each fortifying GPT-4V's medical
acumen. These methodical enhancements facilitate more reliable, precise, and
clinically valuable insights from GPT-4V, advancing its operability in critical
healthcare environments. Our findings are pivotal for those employing AI in
medicine, providing clear, actionable guidance on harnessing GPT-4V's full
diagnostic potential.",2023-12-07,2023,2023-12,medical
"ALGNet: Attention Light Graph Memory Network for Medical Recommendation
  System","Medication recommendation is a vital task for improving patient care and
reducing adverse events. However, existing methods often fail to capture the
complex and dynamic relationships among patient medical records, drug efficacy
and safety, and drug-drug interactions (DDI). In this paper, we propose ALGNet,
a novel model that leverages light graph convolutional networks (LGCN) and
augmentation memory networks (AMN) to enhance medication recommendation. LGCN
can efficiently encode the patient records and the DDI graph into
low-dimensional embeddings, while AMN can augment the patient representation
with external knowledge from a memory module. We evaluate our model on the
MIMIC-III dataset and show that it outperforms several baselines in terms of
recommendation accuracy and DDI avoidance. We also conduct an ablation study to
analyze the effects of different components of our model. Our results
demonstrate that ALGNet can achieve superior performance with less computation
and more interpretability. The implementation of this paper can be found at:
https://github.com/huyquoctrinh/ALGNet.",2023-12-09,2023,2023-12,medical
The Limits of Fair Medical Imaging AI In The Wild,"As artificial intelligence (AI) rapidly approaches human-level performance in
medical imaging, it is crucial that it does not exacerbate or propagate
healthcare disparities. Prior research has established AI's capacity to infer
demographic data from chest X-rays, leading to a key concern: do models using
demographic shortcuts have unfair predictions across subpopulations? In this
study, we conduct a thorough investigation into the extent to which medical AI
utilizes demographic encodings, focusing on potential fairness discrepancies
within both in-distribution training sets and external test sets. Our analysis
covers three key medical imaging disciplines: radiology, dermatology, and
ophthalmology, and incorporates data from six global chest X-ray datasets. We
confirm that medical imaging AI leverages demographic shortcuts in disease
classification. While correcting shortcuts algorithmically effectively
addresses fairness gaps to create ""locally optimal"" models within the original
data distribution, this optimality is not true in new test settings.
Surprisingly, we find that models with less encoding of demographic attributes
are often most ""globally optimal"", exhibiting better fairness during model
evaluation in new test environments. Our work establishes best practices for
medical imaging models which maintain their performance and fairness in
deployments beyond their initial training contexts, underscoring critical
considerations for AI clinical deployments across populations and sites.",2023-12-11,2023,2023-12,medical
SM70: A Large Language Model for Medical Devices,"We are introducing SM70, a 70 billion-parameter Large Language Model that is
specifically designed for SpassMed's medical devices under the brand name
'JEE1' (pronounced as G1 and means 'Life'). This large language model provides
more accurate and safe responses to medical-domain questions. To fine-tune
SM70, we used around 800K data entries from the publicly available dataset
MedAlpaca. The Llama2 70B open-sourced model served as the foundation for SM70,
and we employed the QLoRA technique for fine-tuning. The evaluation is
conducted across three benchmark datasets - MEDQA - USMLE, PUBMEDQA, and USMLE
- each representing a unique aspect of medical knowledge and reasoning. The
performance of SM70 is contrasted with other notable LLMs, including Llama2
70B, Clinical Camel 70 (CC70), GPT 3.5, GPT 4, and Med-Palm, to provide a
comparative understanding of its capabilities within the medical domain. Our
results indicate that SM70 outperforms several established models in these
datasets, showcasing its proficiency in handling a range of medical queries,
from fact-based questions derived from PubMed abstracts to complex clinical
decision-making scenarios. The robust performance of SM70, particularly in the
USMLE and PUBMEDQA datasets, suggests its potential as an effective tool in
clinical decision support and medical information retrieval. Despite its
promising results, the paper also acknowledges the areas where SM70 lags behind
the most advanced model, GPT 4, thereby highlighting the need for further
development, especially in tasks demanding extensive medical knowledge and
intricate reasoning.",2023-12-12,2023,2023-12,medical
"A Distributed Privacy Preserving Model for the Detection of Alzheimer's
  Disease","In the era of rapidly advancing medical technologies, the segmentation of
medical data has become inevitable, necessitating the development of privacy
preserving machine learning algorithms that can train on distributed data.
Consolidating sensitive medical data is not always an option particularly due
to the stringent privacy regulations imposed by the Health Insurance
Portability and Accountability Act (HIPAA). In this paper, I introduce a HIPAA
compliant framework that can train from distributed data. I then propose a
multimodal vertical federated model for Alzheimer's Disease (AD) detection, a
serious neurodegenerative condition that can cause dementia, severely impairing
brain function and hindering simple tasks, especially without preventative
care. This vertical federated learning (VFL) model offers a distributed
architecture that enables collaborative learning across diverse sources of
medical data while respecting privacy constraints imposed by HIPAA. The VFL
architecture proposed herein offers a novel distributed architecture, enabling
collaborative learning across diverse sources of medical data while respecting
statutory privacy constraints. By leveraging multiple modalities of data, the
robustness and accuracy of AD detection can be enhanced. This model not only
contributes to the advancement of federated learning techniques but also holds
promise for overcoming the hurdles posed by data segmentation in medical
research.",2023-12-15,2023,2023-12,medical
"CLIPSyntel: CLIP and LLM Synergy for Multimodal Question Summarization
  in Healthcare","In the era of modern healthcare, swiftly generating medical question
summaries is crucial for informed and timely patient care. Despite the
increasing complexity and volume of medical data, existing studies have focused
solely on text-based summarization, neglecting the integration of visual
information. Recognizing the untapped potential of combining textual queries
with visual representations of medical conditions, we introduce the Multimodal
Medical Question Summarization (MMQS) Dataset. This dataset, a major
contribution to our work, pairs medical queries with visual aids, facilitating
a richer and more nuanced understanding of patient needs. We also propose a
framework, utilizing the power of Contrastive Language Image Pretraining(CLIP)
and Large Language Models(LLMs), consisting of four modules that identify
medical disorders, generate relevant context, filter medical concepts, and
craft visually aware summaries. Our comprehensive framework harnesses the power
of CLIP, a multimodal foundation model, and various general-purpose LLMs,
comprising four main modules: the medical disorder identification module, the
relevant context generation module, the context filtration module for
distilling relevant medical concepts and knowledge, and finally, a
general-purpose LLM to generate visually aware medical question summaries.
Leveraging our MMQS dataset, we showcase how visual cues from images enhance
the generation of medically nuanced summaries. This multimodal approach not
only enhances the decision-making process in healthcare but also fosters a more
nuanced understanding of patient queries, laying the groundwork for future
research in personalized and responsive medical care",2023-12-16,2023,2023-12,medical
An Interpretable Deep Learning Approach for Skin Cancer Categorization,"Skin cancer is a serious worldwide health issue, precise and early detection
is essential for better patient outcomes and effective treatment. In this
research, we use modern deep learning methods and explainable artificial
intelligence (XAI) approaches to address the problem of skin cancer detection.
To categorize skin lesions, we employ four cutting-edge pre-trained models:
XceptionNet, EfficientNetV2S, InceptionResNetV2, and EfficientNetV2M. Image
augmentation approaches are used to reduce class imbalance and improve the
generalization capabilities of our models. Our models decision-making process
can be clarified because of the implementation of explainable artificial
intelligence (XAI). In the medical field, interpretability is essential to
establish credibility and make it easier to implement AI driven diagnostic
technologies into clinical workflows. We determined the XceptionNet
architecture to be the best performing model, achieving an accuracy of 88.72%.
Our study shows how deep learning and explainable artificial intelligence (XAI)
can improve skin cancer diagnosis, laying the groundwork for future
developments in medical image analysis. These technologies ability to allow for
early and accurate detection could enhance patient care, lower healthcare
costs, and raise the survival rates for those with skin cancer. Source Code:
https://github.com/Faysal-MD/An-Interpretable-Deep-Learning?Approach-for-Skin-Cancer-Categorization-IEEE2023",2023-12-17,2023,2023-12,medical
"UniDCP: Unifying Multiple Medical Vision-language Tasks via Dynamic
  Cross-modal Learnable Prompts","Medical vision-language pre-training (Med-VLP) models have recently
accelerated the fast-growing medical diagnostics application. However, most
Med-VLP models learn task-specific representations independently from scratch,
thereby leading to great inflexibility when they work across multiple
fine-tuning tasks. In this work, we propose UniDCP, a Unified medical
vision-language model with Dynamic Cross-modal learnable Prompts, which can be
plastically applied to multiple medical vision-language tasks. Specifically, we
explicitly construct a unified framework to harmonize diverse inputs from
multiple pretraining tasks by leveraging cross-modal prompts for unification,
which accordingly can accommodate heterogeneous medical fine-tuning tasks.
Furthermore, we conceive a dynamic cross-modal prompt optimizing strategy that
optimizes the prompts within the shareable space for implicitly processing the
shareable clinic knowledge. UniDCP is the first Med-VLP model capable of
performing all 8 medical uni-modal and cross-modal tasks over 14 corresponding
datasets, consistently yielding superior results over diverse state-of-the-art
methods.",2023-12-18,2023,2023-12,medical
"VITA: 'Carefully Chosen and Weighted Less' Is Better in Medication
  Recommendation","We address the medication recommendation problem, which aims to recommend
effective medications for a patient's current visit by utilizing information
(e.g., diagnoses and procedures) given at the patient's current and past
visits. While there exist a number of recommender systems designed for this
problem, we point out that they are challenged in accurately capturing the
relation (spec., the degree of relevance) between the current and each of the
past visits for the patient when obtaining her current health status, which is
the basis for recommending medications. To address this limitation, we propose
a novel medication recommendation framework, named VITA, based on the following
two novel ideas: (1) relevant-Visit selectIon; (2) Target-aware Attention.
Through extensive experiments using real-world datasets, we demonstrate the
superiority of VITA (spec., up to 5.56% higher accuracy, in terms of Jaccard,
than the best competitor) and the effectiveness of its two core ideas. The code
is available at https://github.com/jhheo0123/VITA.",2023-12-19,2023,2023-12,medical
"MedBench: A Large-Scale Chinese Benchmark for Evaluating Medical Large
  Language Models","The emergence of various medical large language models (LLMs) in the medical
domain has highlighted the need for unified evaluation standards, as manual
evaluation of LLMs proves to be time-consuming and labor-intensive. To address
this issue, we introduce MedBench, a comprehensive benchmark for the Chinese
medical domain, comprising 40,041 questions sourced from authentic examination
exercises and medical reports of diverse branches of medicine. In particular,
this benchmark is composed of four key components: the Chinese Medical
Licensing Examination, the Resident Standardization Training Examination, the
Doctor In-Charge Qualification Examination, and real-world clinic cases
encompassing examinations, diagnoses, and treatments. MedBench replicates the
educational progression and clinical practice experiences of doctors in
Mainland China, thereby establishing itself as a credible benchmark for
assessing the mastery of knowledge and reasoning abilities in medical language
learning models. We perform extensive experiments and conduct an in-depth
analysis from diverse perspectives, which culminate in the following findings:
(1) Chinese medical LLMs underperform on this benchmark, highlighting the need
for significant advances in clinical knowledge and diagnostic precision. (2)
Several general-domain LLMs surprisingly possess considerable medical
knowledge. These findings elucidate both the capabilities and limitations of
LLMs within the context of MedBench, with the ultimate goal of aiding the
medical research community.",2023-12-20,2023,2023-12,medical
Responsible Deep Learning for Software as a Medical Device,"Tools, models and statistical methods for signal processing and medical image
analysis and training deep learning models to create research prototypes for
eventual clinical applications are of special interest to the biomedical
imaging community. But material and optical properties of biological tissues
are complex and not easily captured by imaging devices. Added complexity can be
introduced by datasets with underrepresentation of medical images from races
and ethnicities for deep learning, and limited knowledge about the regulatory
framework needed for commercialization and safety of emerging Artificial
Intelligence (AI) and Machine Learning (ML) technologies for medical image
analysis. This extended version of the workshop paper presented at the special
session of the 2022 IEEE 19th International Symposium on Biomedical Imaging,
describes strategy and opportunities by University of California professors
engaged in machine learning (section I) and clinical research (section II), the
Office of Science and Engineering Laboratories (OSEL) section III, and
officials at the US FDA in Center for Devices & Radiological Health (CDRH)
section IV. Performance evaluations of AI/ML models of skin (RGB), tissue
biopsy (digital pathology), and lungs and kidneys (Magnetic Resonance, X-ray,
Computed Tomography) medical images for regulatory evaluations and real-world
deployment are discussed.",2023-12-20,2023,2023-12,medical
Towards Detecting Cascades of Biased Medical Claims on Twitter,"Social media may disseminate medical claims that highlight misleading
correlations between social identifiers and diseases due to not accounting for
structural determinants of health. Our research aims to identify biased medical
claims on Twitter and measure their spread. We propose a machine learning
framework that uses two models in tandem: RoBERTa to detect medical claims and
DistilBERT to classify bias. After identifying original biased medical claims,
we conducted a retweet cascade analysis, computing their individual reach and
rate of spread. Tweets containing biased claims were found to circulate faster
and further than unbiased claims.",2023-12-22,2023,2023-12,medical
"Medical Report Generation based on Segment-Enhanced Contrastive
  Representation Learning","Automated radiology report generation has the potential to improve radiology
reporting and alleviate the workload of radiologists. However, the medical
report generation task poses unique challenges due to the limited availability
of medical data and the presence of data bias. To maximize the utility of
available data and reduce data bias, we propose MSCL (Medical image
Segmentation with Contrastive Learning), a framework that utilizes the Segment
Anything Model (SAM) to segment organs, abnormalities, bones, etc., and can pay
more attention to the meaningful ROIs in the image to get better visual
representations. Then we introduce a supervised contrastive loss that assigns
more weight to reports that are semantically similar to the target while
training. The design of this loss function aims to mitigate the impact of data
bias and encourage the model to capture the essential features of a medical
image and generate high-quality reports. Experimental results demonstrate the
effectiveness of our proposed model, where we achieve state-of-the-art
performance on the IU X-Ray public dataset.",2023-12-26,2023,2023-12,medical
"Deploying ADVISER: Impact and Lessons from Using Artificial Intelligence
  for Child Vaccination Uptake in Nigeria","More than 5 million children under five years die from largely preventable or
treatable medical conditions every year, with an overwhelmingly large
proportion of deaths occurring in underdeveloped countries with low vaccination
uptake. One of the United Nations' sustainable development goals (SDG 3) aims
to end preventable deaths of newborns and children under five years of age. We
focus on Nigeria, where the rate of infant mortality is appalling. In
particular, low vaccination uptake in Nigeria is a major driver of more than
2,000 daily deaths of children under the age of five years. In this paper, we
describe our collaboration with government partners in Nigeria to deploy
ADVISER: AI-Driven Vaccination Intervention Optimiser. The framework, based on
an integer linear program that seeks to maximize the cumulative probability of
successful vaccination, is the first successful deployment of an AI-enabled
toolchain for optimizing the allocation of health interventions in Nigeria. In
this paper, we provide a background of the ADVISER framework and present
results, lessons, and success stories of deploying ADVISER to more than 13,000
families in the state of Oyo, Nigeria.",2023-12-30,2023,2023-12,medical
A generic model of consciousness,"This is a model of consciousness. The hard problem of consciousness, what it
feels like, is answered. The work builds on medical research analyzing the
source and mechanisms associated with our feelings. It goes further by
describing a generic model with wide applicability. The model is fully
consistent with medical pathways in humans, but easily extends to animals and
AI. The essence of the model is the interplay between associative memory and
physiology. The model is a clear and concrete counterexample to the famous
philosophical objections to a scientific explanation.",2024-01-02,2024,2024-01,medical
"Freeze the backbones: A Parameter-Efficient Contrastive Approach to
  Robust Medical Vision-Language Pre-training","Modern healthcare often utilises radiographic images alongside textual
reports for diagnostics, encouraging the use of Vision-Language Self-Supervised
Learning (VL-SSL) with large pre-trained models to learn versatile medical
vision representations. However, most existing VL-SSL frameworks are trained
end-to-end, which is computation-heavy and can lose vital prior information
embedded in pre-trained encoders. To address both issues, we introduce the
backbone-agnostic Adaptor framework, which preserves medical knowledge in
pre-trained image and text encoders by keeping them frozen, and employs a
lightweight Adaptor module for cross-modal learning. Experiments on medical
image classification and segmentation tasks across three datasets reveal that
our framework delivers competitive performance while cutting trainable
parameters by over 90% compared to current pre-training approaches. Notably,
when fine-tuned with just 1% of data, Adaptor outperforms several
Transformer-based methods trained on full datasets in medical image
segmentation.",2024-01-02,2024,2024-01,medical
"MedSumm: A Multimodal Approach to Summarizing Code-Mixed Hindi-English
  Clinical Queries","In the healthcare domain, summarizing medical questions posed by patients is
critical for improving doctor-patient interactions and medical decision-making.
Although medical data has grown in complexity and quantity, the current body of
research in this domain has primarily concentrated on text-based methods,
overlooking the integration of visual cues. Also prior works in the area of
medical question summarisation have been limited to the English language. This
work introduces the task of multimodal medical question summarization for
codemixed input in a low-resource setting. To address this gap, we introduce
the Multimodal Medical Codemixed Question Summarization MMCQS dataset, which
combines Hindi-English codemixed medical queries with visual aids. This
integration enriches the representation of a patient's medical condition,
providing a more comprehensive perspective. We also propose a framework named
MedSumm that leverages the power of LLMs and VLMs for this task. By utilizing
our MMCQS dataset, we demonstrate the value of integrating visual information
from images to improve the creation of medically detailed summaries. This
multimodal strategy not only improves healthcare decision-making but also
promotes a deeper comprehension of patient queries, paving the way for future
exploration in personalized and responsive medical care. Our dataset, code, and
pre-trained models will be made publicly available.",2024-01-03,2024,2024-01,medical
"TRLS: A Time Series Representation Learning Framework via Spectrogram
  for Medical Signal Processing","Representation learning frameworks in unlabeled time series have been
proposed for medical signal processing. Despite the numerous excellent
progresses have been made in previous works, we observe the representation
extracted for the time series still does not generalize well. In this paper, we
present a Time series (medical signal) Representation Learning framework via
Spectrogram (TRLS) to get more informative representations. We transform the
input time-domain medical signals into spectrograms and design a time-frequency
encoder named Time Frequency RNN (TFRNN) to capture more robust multi-scale
representations from the augmented spectrograms. Our TRLS takes spectrogram as
input with two types of different data augmentations and maximizes the
similarity between positive ones, which effectively circumvents the problem of
designing negative samples. Our evaluation of four real-world medical signal
datasets focusing on medical signal classification shows that TRLS is superior
to the existing frameworks.",2024-01-06,2024,2024-01,medical
MISS: A Generative Pretraining and Finetuning Approach for Med-VQA,"Medical visual question answering (VQA) is a challenging multimodal task,
where Vision-Language Pre-training (VLP) models can effectively improve the
generalization performance. However, most methods in the medical field treat
VQA as an answer classification task which is difficult to transfer to
practical application scenarios. Additionally, due to the privacy of medical
images and the expensive annotation process, large-scale medical image-text
pairs datasets for pretraining are severely lacking. In this paper, we propose
a large-scale MultI-task Self-Supervised learning based framework (MISS) for
medical VQA tasks. Unlike existing methods, we treat medical VQA as a
generative task. We unify the text encoder and multimodal encoder and align
image-text features through multi-task learning. Furthermore, we propose a
Transfer-and-Caption method that extends the feature space of single-modal
image datasets using Large Language Models (LLMs), enabling those traditional
medical vision field task data to be applied to VLP. Experiments show that our
method achieves excellent results with fewer multimodal datasets and
demonstrates the advantages of generative VQA models.",2024-01-10,2024,2024-01,medical
"Yes, this is what I was looking for! Towards Multi-modal Medical
  Consultation Concern Summary Generation","Over the past few years, the use of the Internet for healthcare-related tasks
has grown by leaps and bounds, posing a challenge in effectively managing and
processing information to ensure its efficient utilization. During moments of
emotional turmoil and psychological challenges, we frequently turn to the
internet as our initial source of support, choosing this over discussing our
feelings with others due to the associated social stigma. In this paper, we
propose a new task of multi-modal medical concern summary (MMCS) generation,
which provides a short and precise summary of patients' major concerns brought
up during the consultation. Nonverbal cues, such as patients' gestures and
facial expressions, aid in accurately identifying patients' concerns. Doctors
also consider patients' personal information, such as age and gender, in order
to describe the medical condition appropriately. Motivated by the potential
efficacy of patients' personal context and visual gestures, we propose a
transformer-based multi-task, multi-modal intent-recognition, and medical
concern summary generation (IR-MMCSG) system. Furthermore, we propose a
multitasking framework for intent recognition and medical concern summary
generation for doctor-patient consultations. We construct the first multi-modal
medical concern summary generation (MM-MediConSummation) corpus, which includes
patient-doctor consultations annotated with medical concern summaries, intents,
patient personal information, doctor's recommendations, and keywords. Our
experiments and analysis demonstrate (a) the significant role of patients'
expressions/gestures and their personal information in intent identification
and medical concern summary generation, and (b) the strong correlation between
intent recognition and patients' medical concern summary generation
  The dataset and source code are available at https://github.com/NLP-RL/MMCSG.",2024-01-10,2024,2024-01,medical
Hallucination Benchmark in Medical Visual Question Answering,"The recent success of large language and vision models (LLVMs) on vision
question answering (VQA), particularly their applications in medicine
(Med-VQA), has shown a great potential of realizing effective visual assistants
for healthcare. However, these models are not extensively tested on the
hallucination phenomenon in clinical settings. Here, we created a hallucination
benchmark of medical images paired with question-answer sets and conducted a
comprehensive evaluation of the state-of-the-art models. The study provides an
in-depth analysis of current models' limitations and reveals the effectiveness
of various prompting strategies.",2024-01-11,2024,2024-01,medical
"Medical Dialogue Generation via Intuitive-then-Analytical Differential
  Diagnosis","Medical dialogue systems have attracted growing research attention as they
have the potential to provide rapid diagnoses, treatment plans, and health
consultations. In medical dialogues, a proper diagnosis is crucial as it
establishes the foundation for future consultations. Clinicians typically
employ both intuitive and analytic reasoning to formulate a differential
diagnosis. This reasoning process hypothesizes and verifies a variety of
possible diseases and strives to generate a comprehensive and rigorous
diagnosis. However, recent studies on medical dialogue generation have
overlooked the significance of modeling a differential diagnosis, which hinders
the practical application of these systems. To address the above issue, we
propose a medical dialogue generation framework with the
Intuitive-then-Analytic Differential Diagnosis (IADDx). Our method starts with
a differential diagnosis via retrieval-based intuitive association and
subsequently refines it through a graph-enhanced analytic procedure. The
resulting differential diagnosis is then used to retrieve medical knowledge and
guide response generation. Experimental results on two datasets validate the
efficacy of our method. Besides, we demonstrate how our framework assists both
clinicians and patients in understanding the diagnostic process, for instance,
by producing intermediate results and graph-based diagnosis paths.",2024-01-12,2024,2024-01,medical
"Empowering Medical Imaging with Artificial Intelligence: A Review of
  Machine Learning Approaches for the Detection, and Segmentation of COVID-19
  Using Radiographic and Tomographic Images","Since 2019, the global dissemination of the Coronavirus and its novel strains
has resulted in a surge of new infections. The use of X-ray and computed
tomography (CT) imaging techniques is critical in diagnosing and managing
COVID-19. Incorporating artificial intelligence (AI) into the field of medical
imaging is a powerful combination that can provide valuable support to
healthcare professionals.This paper focuses on the methodological approach of
using machine learning (ML) to enhance medical imaging for COVID-19
diagnosis.For example, deep learning can accurately distinguish lesions from
other parts of the lung without human intervention in a matter of
minutes.Moreover, ML can enhance performance efficiency by assisting
radiologists in making more precise clinical decisions, such as detecting and
distinguishing Covid-19 from different respiratory infections and segmenting
infections in CT and X-ray images, even when the lesions have varying sizes and
shapes.This article critically assesses machine learning methodologies utilized
for the segmentation, classification, and detection of Covid-19 within CT and
X-ray images, which are commonly employed tools in clinical and hospital
settings to represent the lung in various aspects and extensive detail.There is
a widespread expectation that this technology will continue to hold a central
position within the healthcare sector, driving further progress in the
management of the pandemic.",2024-01-13,2024,2024-01,medical
"Developing ChatGPT for Biology and Medicine: A Complete Review of
  Biomedical Question Answering","ChatGPT explores a strategic blueprint of question answering (QA) in
delivering medical diagnosis, treatment recommendations, and other healthcare
support. This is achieved through the increasing incorporation of medical
domain data via natural language processing (NLP) and multimodal paradigms. By
transitioning the distribution of text, images, videos, and other modalities
from the general domain to the medical domain, these techniques have expedited
the progress of medical domain question answering (MDQA). They bridge the gap
between human natural language and sophisticated medical domain knowledge or
expert manual annotations, handling large-scale, diverse, unbalanced, or even
unlabeled data analysis scenarios in medical contexts. Central to our focus is
the utilizing of language models and multimodal paradigms for medical question
answering, aiming to guide the research community in selecting appropriate
mechanisms for their specific medical research requirements. Specialized tasks
such as unimodal-related question answering, reading comprehension, reasoning,
diagnosis, relation extraction, probability modeling, and others, as well as
multimodal-related tasks like vision question answering, image caption,
cross-modal retrieval, report summarization, and generation, are discussed in
detail. Each section delves into the intricate specifics of the respective
method under consideration. This paper highlights the structures and
advancements of medical domain explorations against general domain methods,
emphasizing their applications across different tasks and datasets. It also
outlines current challenges and opportunities for future medical domain
research, paving the way for continued innovation and application in this
rapidly evolving field.",2024-01-15,2024,2024-01,medical
"MICA: Towards Explainable Skin Lesion Diagnosis via Multi-Level
  Image-Concept Alignment","Black-box deep learning approaches have showcased significant potential in
the realm of medical image analysis. However, the stringent trustworthiness
requirements intrinsic to the medical field have catalyzed research into the
utilization of Explainable Artificial Intelligence (XAI), with a particular
focus on concept-based methods. Existing concept-based methods predominantly
apply concept annotations from a single perspective (e.g., global level),
neglecting the nuanced semantic relationships between sub-regions and concepts
embedded within medical images. This leads to underutilization of the valuable
medical information and may cause models to fall short in harmoniously
balancing interpretability and performance when employing inherently
interpretable architectures such as Concept Bottlenecks. To mitigate these
shortcomings, we propose a multi-modal explainable disease diagnosis framework
that meticulously aligns medical images and clinical-related concepts
semantically at multiple strata, encompassing the image level, token level, and
concept level. Moreover, our method allows for model intervention and offers
both textual and visual explanations in terms of human-interpretable concepts.
Experimental results on three skin image datasets demonstrate that our method,
while preserving model interpretability, attains high performance and label
efficiency for concept detection and disease diagnosis.",2024-01-16,2024,2024-01,medical
"Artificial Intelligence-based algorithms in medical image scan
  seg-mentation and intelligent visual-content generation -- a concise overview","Recently, Artificial Intelligence (AI)-based algorithms have revolutionized
the medical image segmentation processes. Thus, the precise segmentation of
organs and their lesions may contribute to an efficient diagnostics process and
a more effective selection of targeted therapies as well as increasing the
effectiveness of the training process. In this context, AI may contribute to
the automatization of the image scan segmentation process and increase the
quality of the resulting 3D objects, which may lead to the generation of more
realistic virtual objects. In this paper, we focus on the AI-based solutions
applied in the medical image scan segmentation, and intelligent visual-content
generation, i.e. computer-generated three-dimensional (3D) images in the
context of Extended Reality (XR). We consider different types of neural
networks used with a special emphasis on the learning rules applied, taking
into account algorithm accuracy and performance, as well as open data
availability. This paper attempts to summarize the current development of
AI-based segmentation methods in medical imaging and intelligent visual content
generation that are applied in XR. It concludes also with possible developments
and open challenges in AI application in Extended Reality-based solutions.
Finally, the future lines of research and development directions of Artificial
Intelligence applications both in medical image segmentation and Extended
Reality-based medical solutions are discussed",2024-01-18,2024,2024-01,medical
Aprendizado de m√°quina aplicado na eletroqu√≠mica,"This systematic review focuses on analyzing the use of machine learning
techniques for identifying and quantifying analytes in various electrochemical
applications, presenting the available applications in the literature. Machine
learning is a tool that can facilitate the analysis and enhance the
understanding of processes involving various analytes. In electrochemical
biosensors, it increases the precision of medical diagnostics, improving the
identification of biomarkers and pathogens with high reliability. It can be
effectively used for the classification of complex chemical products; in
environmental monitoring, using low-cost sensors; in portable devices and
wearable systems; among others. Currently, the analysis of some analytes is
still performed manually, requiring the expertise of a specialist in the field
and thus hindering the generalization of results. In light of the advancements
in artificial intelligence today, this work proposes to carry out a systematic
review of the literature on the applications of artificial intelligence
techniques. A set of articles has been identified that address electrochemical
problems using machine learning techniques, more specifically, supervised
learning.",2024-01-20,2024,2024-01,medical
MedLM: Exploring Language Models for Medical Question Answering Systems,"In the face of rapidly expanding online medical literature, automated systems
for aggregating and summarizing information are becoming increasingly crucial
for healthcare professionals and patients. Large Language Models (LLMs), with
their advanced generative capabilities, have shown promise in various NLP
tasks, and their potential in the healthcare domain, particularly for
Closed-Book Generative QnA, is significant. However, the performance of these
models in domain-specific tasks such as medical Q&A remains largely unexplored.
This study aims to fill this gap by comparing the performance of general and
medical-specific distilled LMs for medical Q&A. We aim to evaluate the
effectiveness of fine-tuning domain-specific LMs and compare the performance of
different families of Language Models. The study will address critical
questions about these models' reliability, comparative performance, and
effectiveness in the context of medical Q&A. The findings will provide valuable
insights into the suitability of different LMs for specific applications in the
medical domain.",2024-01-21,2024,2024-01,medical
"Next Visit Diagnosis Prediction via Medical Code-Centric Multimodal
  Contrastive EHR Modelling with Hierarchical Regularisation","Predicting next visit diagnosis using Electronic Health Records (EHR) is an
essential task in healthcare, critical for devising proactive future plans for
both healthcare providers and patients. Nonetheless, many preceding studies
have not sufficiently addressed the heterogeneous and hierarchical
characteristics inherent in EHR data, inevitably leading to sub-optimal
performance. To this end, we propose NECHO, a novel medical code-centric
multimodal contrastive EHR learning framework with hierarchical regularisation.
First, we integrate multifaceted information encompassing medical codes,
demographics, and clinical notes using a tailored network design and a pair of
bimodal contrastive losses, all of which pivot around a medical codes
representation. We also regularise modality-specific encoders using a parental
level information in medical ontology to learn hierarchical structure of EHR
data. A series of experiments on MIMIC-III data demonstrates effectiveness of
our approach.",2024-01-22,2024,2024-01,medical
Free Form Medical Visual Question Answering in Radiology,"Visual Question Answering (VQA) in the medical domain presents a unique,
interdisciplinary challenge, combining fields such as Computer Vision, Natural
Language Processing, and Knowledge Representation. Despite its importance,
research in medical VQA has been scant, only gaining momentum since 2018.
Addressing this gap, our research delves into the effective representation of
radiology images and the joint learning of multimodal representations,
surpassing existing methods. We innovatively augment the SLAKE dataset,
enabling our model to respond to a more diverse array of questions, not limited
to the immediate content of radiology or pathology images. Our model achieves a
top-1 accuracy of 79.55\% with a less complex architecture, demonstrating
comparable performance to current state-of-the-art models. This research not
only advances medical VQA but also opens avenues for practical applications in
diagnostic settings.",2024-01-23,2024,2024-01,medical
"Exploiting Liver CT scans in Colorectal Carcinoma genomics mutation
  classification","The liver is the most involved organ by distant metastasis in colon-rectal
cancer (CRC) patients and it comes necessary to be aware of the mutational
status of the lesions to correctly design the best individual treatment. So
far, efforts have been made in order to develop non-invasive and real-time
methods that permit the analysis of the whole tumor, using new artificial
intelligence tools to analyze the tumor's image obtained by Computed Tomography
(CT) scan. In order to address the current medical workflow, that is biopsy
analysis-based, we propose the first DeepLearning-based exploration, to our
knowledge, of such classification approach from the patient medical imaging. We
propose i) a solid pipeline for managing undersized datasets of available CT
scans and ii) a baseline study for genomics mutation diagnosis support for
preemptive patient follow-up. Our method is able to identify CRC RAS mutation
family from CT images with 0.73 F1 score.",2024-01-25,2024,2024-01,medical
"Application analysis of ai technology combined with spiral CT scanning
  in early lung cancer screening","At present, the incidence and fatality rate of lung cancer in China rank
first among all malignant tumors. Despite the continuous development and
improvement of China's medical level, the overall 5-year survival rate of lung
cancer patients is still lower than 20% and is staged. A number of studies have
confirmed that early diagnosis and treatment of early stage lung cancer is of
great significance to improve the prognosis of patients. In recent years,
artificial intelligence technology has gradually begun to be applied in
oncology. ai is used in cancer screening, clinical diagnosis, radiation therapy
(image acquisition, at-risk organ segmentation, image calibration and delivery)
and other aspects of rapid development. However, whether medical ai can be
socialized depends on the public's attitude and acceptance to a certain extent.
However, at present, there are few studies on the diagnosis of early lung
cancer by AI technology combined with SCT scanning. In view of this, this study
applied the combined method in early lung cancer screening, aiming to find a
safe and efficient screening mode and provide a reference for clinical
diagnosis and treatment.",2024-01-26,2024,2024-01,medical
"Evaluating LLM -- Generated Multimodal Diagnosis from Medical Images and
  Symptom Analysis","Large language models (LLMs) constitute a breakthrough state-of-the-art
Artificial Intelligence technology which is rapidly evolving and promises to
aid in medical diagnosis. However, the correctness and the accuracy of their
returns has not yet been properly evaluated. In this work, we propose an LLM
evaluation paradigm that incorporates two independent steps of a novel
methodology, namely (1) multimodal LLM evaluation via structured interactions
and (2) follow-up, domain-specific analysis based on data extracted via the
previous interactions. Using this paradigm, (1) we evaluate the correctness and
accuracy of LLM-generated medical diagnosis with publicly available multimodal
multiple-choice questions(MCQs) in the domain of Pathology and (2) proceed to a
systemic and comprehensive analysis of extracted results. We used
GPT-4-Vision-Preview as the LLM to respond to complex, medical questions
consisting of both images and text, and we explored a wide range of diseases,
conditions, chemical compounds, and related entity types that are included in
the vast knowledge domain of Pathology. GPT-4-Vision-Preview performed quite
well, scoring approximately 84\% of correct diagnoses. Next, we further
analyzed the findings of our work, following an analytical approach which
included Image Metadata Analysis, Named Entity Recognition and Knowledge
Graphs. Weaknesses of GPT-4-Vision-Preview were revealed on specific knowledge
paths, leading to a further understanding of its shortcomings in specific
areas. Our methodology and findings are not limited to the use of
GPT-4-Vision-Preview, but a similar approach can be followed to evaluate the
usefulness and accuracy of other LLMs and, thus, improve their use with further
optimization.",2024-01-28,2024,2024-01,medical
"A Medical Data-Effective Learning Benchmark for Highly Efficient
  Pre-training of Foundation Models","Foundation models, pre-trained on massive datasets, have achieved
unprecedented generalizability. However, is it truly necessary to involve such
vast amounts of data in pre-training, consuming extensive computational
resources? This paper introduces data-effective learning, aiming to use data in
the most impactful way to pre-train foundation models. This involves strategies
that focus on data quality rather than quantity, ensuring the data used for
training has high informational value. Data-effective learning plays a profound
role in accelerating foundation model training, reducing computational costs,
and saving data storage, which is very important as the volume of medical data
in recent years has grown beyond many people's expectations. However, due to
the lack of standards and comprehensive benchmarks, research on medical
data-effective learning is poorly studied. To address this gap, our paper
introduces a comprehensive benchmark specifically for evaluating data-effective
learning in the medical field. This benchmark includes a dataset with millions
of data samples from 31 medical centers (DataDEL), a baseline method for
comparison (MedDEL), and a new evaluation metric (NormDEL) to objectively
measure data-effective learning performance. Our extensive experimental results
show the baseline MedDEL can achieve performance comparable to the original
large dataset with only 5% of the data. Establishing such an open
data-effective learning benchmark is crucial for the medical foundation model
research community because it facilitates efficient data use, promotes
collaborative breakthroughs, and fosters the development of cost-effective,
scalable, and impactful healthcare solutions.",2024-01-31,2024,2024-01,medical
"SA-MDKIF: A Scalable and Adaptable Medical Domain Knowledge Injection
  Framework for Large Language Models","Recent advances in large language models (LLMs) have demonstrated exceptional
performance in various natural language processing (NLP) tasks. However, their
effective application in the medical domain is hampered by a lack of medical
domain knowledge. In this study, we present SA-MDKIF, a scalable and adaptable
framework that aims to inject medical knowledge into general-purpose LLMs
through instruction tuning, thereby enabling adaptability for various
downstream tasks. SA-MDKIF consists of two stages: skill training and skill
adaptation. In the first stage, we define 12 basic medical skills and use
AdaLoRA to train these skills based on uniformly formatted instructional
datasets that we have constructed. In the next stage, we train the skill router
using task-specific downstream data and use this router to integrate the
acquired skills with LLMs during inference. Experimental results on 9 different
medical tasks show that SA-MDKIF improves performance by 10-20% compared to the
original LLMs. Notably, this improvement is particularly pronounced for unseen
medical tasks, showing an improvement of up to 30%.",2024-02-01,2024,2024-02,medical
"How well do LLMs cite relevant medical references? An evaluation
  framework and analyses","Large language models (LLMs) are currently being used to answer medical
questions across a variety of clinical domains. Recent top-performing
commercial LLMs, in particular, are also capable of citing sources to support
their responses. In this paper, we ask: do the sources that LLMs generate
actually support the claims that they make? To answer this, we propose three
contributions. First, as expert medical annotations are an expensive and
time-consuming bottleneck for scalable evaluation, we demonstrate that GPT-4 is
highly accurate in validating source relevance, agreeing 88% of the time with a
panel of medical doctors. Second, we develop an end-to-end, automated pipeline
called \textit{SourceCheckup} and use it to evaluate five top-performing LLMs
on a dataset of 1200 generated questions, totaling over 40K pairs of statements
and sources. Interestingly, we find that between ~50% to 90% of LLM responses
are not fully supported by the sources they provide. We also evaluate GPT-4
with retrieval augmented generation (RAG) and find that, even still, around
30\% of individual statements are unsupported, while nearly half of its
responses are not fully supported. Third, we open-source our curated dataset of
medical questions and expert annotations for future evaluations. Given the
rapid pace of LLM development and the potential harms of incorrect or outdated
medical information, it is crucial to also understand and quantify their
capability to produce relevant, trustworthy medical references.",2024-02-03,2024,2024-02,medical
"Exploring Intrinsic Properties of Medical Images for Self-Supervised
  Binary Semantic Segmentation","Recent advancements in self-supervised learning have unlocked the potential
to harness unlabeled data for auxiliary tasks, facilitating the learning of
beneficial priors. This has been particularly advantageous in fields like
medical image analysis, where labeled data are scarce. Although effective for
classification tasks, this methodology has shown limitations in more complex
applications, such as medical image segmentation. In this paper, we introduce
Medical imaging Enhanced with Dynamic Self-Adaptive Semantic Segmentation
(MedSASS), a dedicated self-supervised framework tailored for medical image
segmentation. We evaluate MedSASS against existing state-of-the-art methods
across four diverse medical datasets, showcasing its superiority. MedSASS
outperforms existing CNN-based self-supervised methods by 3.83% and matches the
performance of ViT-based methods. Furthermore, when MedSASS is trained
end-to-end, covering both encoder and decoder, it demonstrates significant
improvements of 14.4% for CNNs and 6% for ViT-based architectures compared to
existing state-of-the-art self-supervised strategies.",2024-02-04,2024,2024-02,medical
"COMPRER: A Multimodal Multi-Objective Pretraining Framework for Enhanced
  Medical Image Representation","Substantial advances in multi-modal Artificial Intelligence (AI) facilitate
the combination of diverse medical modalities to achieve holistic health
assessments. We present COMPRER , a novel multi-modal, multi-objective
pretraining framework which enhances medical-image representation, diagnostic
inferences, and prognosis of diseases. COMPRER employs a multi-objective
training framework, where each objective introduces distinct knowledge to the
model. This includes a multimodal loss that consolidates information across
different imaging modalities; A temporal loss that imparts the ability to
discern patterns over time; Medical-measure prediction adds appropriate medical
insights; Lastly, reconstruction loss ensures the integrity of image structure
within the latent space. Despite the concern that multiple objectives could
weaken task performance, our findings show that this combination actually
boosts outcomes on certain tasks. Here, we apply this framework to both fundus
images and carotid ultrasound, and validate our downstream tasks capabilities
by predicting both current and future cardiovascular conditions. COMPRER
achieved higher Area Under the Curve (AUC) scores in evaluating medical
conditions compared to existing models on held-out data. On the
Out-of-distribution (OOD) UK-Biobank dataset COMPRER maintains favorable
performance over well-established models with more parameters, even though
these models were trained on $75\times$ more data than COMPRER. In addition, to
better assess our model's performance in contrastive learning, we introduce a
novel evaluation metric, providing deeper understanding of the effectiveness of
the latent space pairing.",2024-02-04,2024,2024-02,medical
AI-Enhanced Virtual Reality in Medicine: A Comprehensive Survey,"With the rapid advance of computer graphics and artificial intelligence
technologies, the ways we interact with the world have undergone a
transformative shift. Virtual Reality (VR) technology, aided by artificial
intelligence (AI), has emerged as a dominant interaction media in multiple
application areas, thanks to its advantage of providing users with immersive
experiences. Among those applications, medicine is considered one of the most
promising areas. In this paper, we present a comprehensive examination of the
burgeoning field of AI-enhanced VR applications in medical care and services.
By introducing a systematic taxonomy, we meticulously classify the pertinent
techniques and applications into three well-defined categories based on
different phases of medical diagnosis and treatment: Visualization Enhancement,
VR-related Medical Data Processing, and VR-assisted Intervention. This
categorization enables a structured exploration of the diverse roles that
AI-powered VR plays in the medical domain, providing a framework for a more
comprehensive understanding and evaluation of these technologies. To our best
knowledge, this is the first systematic survey of AI-powered VR systems in
medical settings, laying a foundation for future research in this
interdisciplinary domain.",2024-02-05,2024,2024-02,medical
Large Language Model Distilling Medication Recommendation Model,"The recommendation of medication is a vital aspect of intelligent healthcare
systems, as it involves prescribing the most suitable drugs based on a
patient's specific health needs. Unfortunately, many sophisticated models
currently in use tend to overlook the nuanced semantics of medical data, while
only relying heavily on identities. Furthermore, these models face significant
challenges in handling cases involving patients who are visiting the hospital
for the first time, as they lack prior prescription histories to draw upon. To
tackle these issues, we harness the powerful semantic comprehension and
input-agnostic characteristics of Large Language Models (LLMs). Our research
aims to transform existing medication recommendation methodologies using LLMs.
In this paper, we introduce a novel approach called Large Language Model
Distilling Medication Recommendation (LEADER). We begin by creating appropriate
prompt templates that enable LLMs to suggest medications effectively. However,
the straightforward integration of LLMs into recommender systems leads to an
out-of-corpus issue specific to drugs. We handle it by adapting the LLMs with a
novel output layer and a refined tuning loss function. Although LLM-based
models exhibit remarkable capabilities, they are plagued by high computational
costs during inference, which is impractical for the healthcare sector. To
mitigate this, we have developed a feature-level knowledge distillation
technique, which transfers the LLM's proficiency to a more compact model.
Extensive experiments conducted on two real-world datasets, MIMIC-III and
MIMIC-IV, demonstrate that our proposed model not only delivers effective
results but also is efficient. To ease the reproducibility of our experiments,
we release the implementation code online.",2024-02-05,2024,2024-02,medical
"Neural machine translation of clinical procedure codes for medical
  diagnosis and uncertainty quantification","A Clinical Decision Support System (CDSS) is designed to enhance clinician
decision-making by combining system-generated recommendations with medical
expertise. Given the high costs, intensive labor, and time-sensitive nature of
medical treatments, there is a pressing need for efficient decision support,
especially in complex emergency scenarios. In these scenarios, where
information can be limited, an advanced CDSS framework that leverages AI
(artificial intelligence) models to effectively reduce diagnostic uncertainty
has utility. Such an AI-enabled CDSS framework with quantified uncertainty
promises to be practical and beneficial in the demanding context of real-world
medical care. In this study, we introduce the concept of Medical Entropy,
quantifying uncertainties in patient outcomes predicted by neural machine
translation based on the ICD-9 code of procedures. Our experimental results not
only show strong correlations between procedure and diagnosis sequences based
on the simple ICD-9 code but also demonstrate the promising capacity to model
trends of uncertainties during hospitalizations through a data-driven approach.",2024-02-07,2024,2024-02,medical
Using text embedding models as text classifiers with medical data,"The advent of Large Language Models (LLMs) is promising and LLMs have been
applied to numerous fields. However, it is not trivial to implement LLMs in the
medical field, due to the high standards for precision and accuracy. Currently,
the diagnosis of medical ailments must be done by hand, as it is costly to
build a sufficiently broad LLM that can diagnose a wide range of diseases.
Here, we explore the use of vector databases and embedding models as a means of
encoding and classifying text with medical text data without the need to train
a new model altogether. We used various LLMs to generate the medical data, then
encoded the data with a text embedding model and stored it in a vector
database. We hypothesized that higher embedding dimensions coupled with
descriptive data in the vector database would lead to better classifications
and designed a robustness test to test our hypothesis. By using vector
databases and text embedding models to classify a clinician's notes on a
patient presenting with a certain ailment, we showed that these tools can be
successful at classifying medical text data. We found that a higher embedding
dimension did indeed yield better results, however, querying with simple data
in the database was optimal for performance. We have shown in this study the
applicability of text embedding models and vector databases on a small scale,
and our work lays the groundwork for applying these tools on a larger scale.",2024-02-07,2024,2024-02,medical
"Benchmarking Large Language Models on Communicative Medical Coaching: a
  Novel System and Dataset","Traditional applications of natural language processing (NLP) in healthcare
have predominantly focused on patient-centered services, enhancing patient
interactions and care delivery, such as through medical dialogue systems.
However, the potential of NLP to benefit inexperienced doctors, particularly in
areas such as communicative medical coaching, remains largely unexplored. We
introduce ""ChatCoach"", a human-AI cooperative framework designed to assist
medical learners in practicing their communication skills during patient
consultations. ChatCoach (Our data and code are available online:
https://github.com/zerowst/Chatcoach)differentiates itself from conventional
dialogue systems by offering a simulated environment where medical learners can
practice dialogues with a patient agent, while a coach agent provides
immediate, structured feedback. This is facilitated by our proposed Generalized
Chain-of-Thought (GCoT) approach, which fosters the generation of structured
feedback and enhances the utilization of external knowledge sources.
Additionally, we have developed a dataset specifically for evaluating Large
Language Models (LLMs) within the ChatCoach framework on communicative medical
coaching tasks. Our empirical results validate the effectiveness of ChatCoach.",2024-02-08,2024,2024-02,medical
"Gemini Goes to Med School: Exploring the Capabilities of Multimodal
  Large Language Models on Medical Challenge Problems & Hallucinations","Large language models have the potential to be valuable in the healthcare
industry, but it's crucial to verify their safety and effectiveness through
rigorous evaluation. For this purpose, we comprehensively evaluated both
open-source LLMs and Google's new multimodal LLM called Gemini across Medical
reasoning, hallucination detection, and Medical Visual Question Answering
tasks. While Gemini showed competence, it lagged behind state-of-the-art models
like MedPaLM 2 and GPT-4 in diagnostic accuracy. Additionally, Gemini achieved
an accuracy of 61.45\% on the medical VQA dataset, significantly lower than
GPT-4V's score of 88\%. Our analysis revealed that Gemini is highly susceptible
to hallucinations, overconfidence, and knowledge gaps, which indicate risks if
deployed uncritically. We also performed a detailed analysis by medical subject
and test type, providing actionable feedback for developers and clinicians. To
mitigate risks, we applied prompting strategies that improved performance.
Additionally, we facilitated future research and development by releasing a
Python module for medical LLM evaluation and establishing a dedicated
leaderboard on Hugging Face for medical domain LLMs. Python module can be found
at https://github.com/promptslab/RosettaEval",2024-02-10,2024,2024-02,medical
"FESS Loss: Feature-Enhanced Spatial Segmentation Loss for Optimizing
  Medical Image Analysis","Medical image segmentation is a critical process in the field of medical
imaging, playing a pivotal role in diagnosis, treatment, and research. It
involves partitioning of an image into multiple regions, representing distinct
anatomical or pathological structures. Conventional methods often grapple with
the challenge of balancing spatial precision and comprehensive feature
representation due to their reliance on traditional loss functions. To overcome
this, we propose Feature-Enhanced Spatial Segmentation Loss (FESS Loss), that
integrates the benefits of contrastive learning (which extracts intricate
features, particularly in the nuanced domain of medical imaging) with the
spatial accuracy inherent in the Dice loss. The objective is to augment both
spatial precision and feature-based representation in the segmentation of
medical images. FESS Loss signifies a notable advancement, offering a more
accurate and refined segmentation process, ultimately contributing to
heightened precision in the analysis of medical images. Further, FESS loss
demonstrates superior performance in limited annotated data availability
scenarios often present in the medical domain.",2024-02-13,2024,2024-02,medical
"BioMistral: A Collection of Open-Source Pretrained Large Language Models
  for Medical Domains","Large Language Models (LLMs) have demonstrated remarkable versatility in
recent years, offering potential applications across specialized domains such
as healthcare and medicine. Despite the availability of various open-source
LLMs tailored for health contexts, adapting general-purpose LLMs to the medical
domain presents significant challenges. In this paper, we introduce BioMistral,
an open-source LLM tailored for the biomedical domain, utilizing Mistral as its
foundation model and further pre-trained on PubMed Central. We conduct a
comprehensive evaluation of BioMistral on a benchmark comprising 10 established
medical question-answering (QA) tasks in English. We also explore lightweight
models obtained through quantization and model merging approaches. Our results
demonstrate BioMistral's superior performance compared to existing open-source
medical models and its competitive edge against proprietary counterparts.
Finally, to address the limited availability of data beyond English and to
assess the multilingual generalization of medical LLMs, we automatically
translated and evaluated this benchmark into 7 other languages. This marks the
first large-scale multilingual evaluation of LLMs in the medical domain.
Datasets, multilingual evaluation benchmarks, scripts, and all the models
obtained during our experiments are freely released.",2024-02-15,2024,2024-02,medical
"LLMs in the Heart of Differential Testing: A Case Study on a Medical
  Rule Engine","The Cancer Registry of Norway (CRN) uses an automated cancer registration
support system (CaReSS) to support core cancer registry activities, i.e, data
capture, data curation, and producing data products and statistics for various
stakeholders. GURI is a core component of CaReSS, which is responsible for
validating incoming data with medical rules. Such medical rules are manually
implemented by medical experts based on medical standards, regulations, and
research. Since large language models (LLMs) have been trained on a large
amount of public information, including these documents, they can be employed
to generate tests for GURI. Thus, we propose an LLM-based test generation and
differential testing approach (LLMeDiff) to test GURI. We experimented with
four different LLMs, two medical rule engine implementations, and 58 real
medical rules to investigate the hallucination, success, time efficiency, and
robustness of the LLMs to generate tests, and these tests' ability to find
potential issues in GURI. Our results showed that GPT-3.5 hallucinates the
least, is the most successful, and is generally the most robust; however, it
has the worst time efficiency. Our differential testing revealed 22 medical
rules where implementation inconsistencies were discovered (e.g., regarding
handling rule versions). Finally, we provide insights for practitioners and
researchers based on the results.",2024-02-16,2024,2024-02,medical
Benchmarking Retrieval-Augmented Generation for Medicine,"While large language models (LLMs) have achieved state-of-the-art performance
on a wide range of medical question answering (QA) tasks, they still face
challenges with hallucinations and outdated knowledge. Retrieval-augmented
generation (RAG) is a promising solution and has been widely adopted. However,
a RAG system can involve multiple flexible components, and there is a lack of
best practices regarding the optimal RAG setting for various medical purposes.
To systematically evaluate such systems, we propose the Medical Information
Retrieval-Augmented Generation Evaluation (MIRAGE), a first-of-its-kind
benchmark including 7,663 questions from five medical QA datasets. Using
MIRAGE, we conducted large-scale experiments with over 1.8 trillion prompt
tokens on 41 combinations of different corpora, retrievers, and backbone LLMs
through the MedRAG toolkit introduced in this work. Overall, MedRAG improves
the accuracy of six different LLMs by up to 18% over chain-of-thought
prompting, elevating the performance of GPT-3.5 and Mixtral to GPT-4-level. Our
results show that the combination of various medical corpora and retrievers
achieves the best performance. In addition, we discovered a log-linear scaling
property and the ""lost-in-the-middle"" effects in medical RAG. We believe our
comprehensive evaluations can serve as practical guidelines for implementing
RAG systems for medicine.",2024-02-20,2024,2024-02,medical
"From Cloud to Edge: Rethinking Generative AI for Low-Resource Design
  Challenges","Generative Artificial Intelligence (AI) has shown tremendous prospects in all
aspects of technology, including design. However, due to its heavy demand on
resources, it is usually trained on large computing infrastructure and often
made available as a cloud-based service. In this position paper, we consider
the potential, challenges, and promising approaches for generative AI for
design on the edge, i.e., in resource-constrained settings where memory,
compute, energy (battery) and network connectivity may be limited. Adapting
generative AI for such settings involves overcoming significant hurdles,
primarily in how to streamline complex models to function efficiently in
low-resource environments. This necessitates innovative approaches in model
compression, efficient algorithmic design, and perhaps even leveraging edge
computing. The objective is to harness the power of generative AI in creating
bespoke solutions for design problems, such as medical interventions, farm
equipment maintenance, and educational material design, tailored to the unique
constraints and needs of remote areas. These efforts could democratize access
to advanced technology and foster sustainable development, ensuring universal
accessibility and environmental consideration of AI-driven design benefits.",2024-02-20,2024,2024-02,medical
"Word-Sequence Entropy: Towards Uncertainty Estimation in Free-Form
  Medical Question Answering Applications and Beyond","Uncertainty estimation is crucial for the reliability of safety-critical
human and artificial intelligence (AI) interaction systems, particularly in the
domain of healthcare engineering. However, a robust and general uncertainty
measure for free-form answers has not been well-established in open-ended
medical question-answering (QA) tasks, where generative inequality introduces a
large number of irrelevant words and sequences within the generated set for
uncertainty quantification (UQ), which can lead to biases. This paper
introduces Word-Sequence Entropy (WSE), a method that calibrates uncertainty at
both the word and sequence levels, considering semantic relevance. WSE
quantifies uncertainty in a way that is more closely aligned with the
reliability of LLMs during uncertainty quantification (UQ). We compare WSE with
six baseline methods on five free-form medical QA datasets, utilizing seven
popular large language models (LLMs). Experimental results demonstrate that WSE
exhibits superior performance in UQ under two standard criteria for correctness
evaluation. Additionally, in terms of real-world medical QA applications, the
performance of LLMs is significantly enhanced (e.g., a 6.36% improvement in
model accuracy on the COVID-QA dataset) by employing responses with lower
uncertainty that are identified by WSE as final answers, without any additional
task-specific fine-tuning or architectural modifications.",2024-02-22,2024,2024-02,medical
"Demographic Bias of Expert-Level Vision-Language Foundation Models in
  Medical Imaging","Advances in artificial intelligence (AI) have achieved expert-level
performance in medical imaging applications. Notably, self-supervised
vision-language foundation models can detect a broad spectrum of pathologies
without relying on explicit training annotations. However, it is crucial to
ensure that these AI models do not mirror or amplify human biases, thereby
disadvantaging historically marginalized groups such as females or Black
patients. The manifestation of such biases could systematically delay essential
medical care for certain patient subgroups. In this study, we investigate the
algorithmic fairness of state-of-the-art vision-language foundation models in
chest X-ray diagnosis across five globally-sourced datasets. Our findings
reveal that compared to board-certified radiologists, these foundation models
consistently underdiagnose marginalized groups, with even higher rates seen in
intersectional subgroups, such as Black female patients. Such demographic
biases present over a wide range of pathologies and demographic attributes.
Further analysis of the model embedding uncovers its significant encoding of
demographic information. Deploying AI systems with these biases in medical
imaging can intensify pre-existing care disparities, posing potential
challenges to equitable healthcare access and raising ethical questions about
their clinical application.",2024-02-22,2024,2024-02,medical
"Adversarial-Robust Transfer Learning for Medical Imaging via Domain
  Assimilation","In the field of Medical Imaging, extensive research has been dedicated to
leveraging its potential in uncovering critical diagnostic features in
patients. Artificial Intelligence (AI)-driven medical diagnosis relies on
sophisticated machine learning and deep learning models to analyze, detect, and
identify diseases from medical images. Despite the remarkable performance of
these models, characterized by high accuracy, they grapple with trustworthiness
issues. The introduction of a subtle perturbation to the original image
empowers adversaries to manipulate the prediction output, redirecting it to
other targeted or untargeted classes. Furthermore, the scarcity of publicly
available medical images, constituting a bottleneck for reliable training, has
led contemporary algorithms to depend on pretrained models grounded on a large
set of natural images -- a practice referred to as transfer learning. However,
a significant {\em domain discrepancy} exists between natural and medical
images, which causes AI models resulting from transfer learning to exhibit
heightened {\em vulnerability} to adversarial attacks. This paper proposes a
{\em domain assimilation} approach that introduces texture and color adaptation
into transfer learning, followed by a texture preservation component to
suppress undesired distortion. We systematically analyze the performance of
transfer learning in the face of various adversarial attacks under different
data modalities, with the overarching goal of fortifying the model's robustness
and security in medical imaging tasks. The results demonstrate high
effectiveness in reducing attack efficacy, contributing toward more trustworthy
transfer learning in biomedical applications.",2024-02-25,2024,2024-02,medical
GigaPevt: Multimodal Medical Assistant,"Building an intelligent and efficient medical assistant is still a
challenging AI problem. The major limitation comes from the data modality
scarceness, which reduces comprehensive patient perception. This demo paper
presents the GigaPevt, the first multimodal medical assistant that combines the
dialog capabilities of large language models with specialized medical models.
Such an approach shows immediate advantages in dialog quality and metric
performance, with a 1.18% accuracy improvement in the question-answering task.",2024-02-26,2024,2024-02,medical
An Overview of the Development of Stereotactic Body Radiation Therapy,"Stereotactic body radiation therapy (SBRT) refers to focusing high-energy
rays in three-dimensional space on the tumor lesion area, reducing the dose
received by surrounding normal tissues, which can effectively improve the local
control rate of the tumor and reduce the probability of complications. With the
comprehensive development of medical imaging, radiation biology and other
disciplines, this less-fractional, high-dose radiotherapy method has been
increasingly developed and applied in clinical practice. The background,
radio-biological basis, key technologies and main equipment of SBRT are
discussed, and its future development direction is prospected.",2024-02-26,2024,2024-02,medical
ICE-SEARCH: A Language Model-Driven Feature Selection Approach,"This study unveils the In-Context Evolutionary Search (ICE-SEARCH) method,
which is among the first works that melds large language models (LLMs) with
evolutionary algorithms for feature selection (FS) tasks and demonstrates its
effectiveness in Medical Predictive Analytics (MPA) applications. ICE-SEARCH
harnesses the crossover and mutation capabilities inherent in LLMs within an
evolutionary framework, significantly improving FS through the model's
comprehensive world knowledge and its adaptability to a variety of roles. Our
evaluation of this methodology spans three crucial MPA tasks: stroke,
cardiovascular disease, and diabetes, where ICE-SEARCH outperforms traditional
FS methods in pinpointing essential features for medical applications.
ICE-SEARCH achieves State-of-the-Art (SOTA) performance in stroke prediction
and diabetes prediction; the Decision-Randomized ICE-SEARCH ranks as SOTA in
cardiovascular disease prediction. The study emphasizes the critical role of
incorporating domain-specific insights, illustrating ICE-SEARCH's robustness,
generalizability, and convergence. This opens avenues for further research into
comprehensive and intricate FS landscapes, marking a significant stride in the
application of artificial intelligence in medical predictive analytics.",2024-02-28,2024,2024-02,medical
"MedAide: Leveraging Large Language Models for On-Premise Medical
  Assistance on Edge Devices","Large language models (LLMs) are revolutionizing various domains with their
remarkable natural language processing (NLP) abilities. However, deploying LLMs
in resource-constrained edge computing and embedded systems presents
significant challenges. Another challenge lies in delivering medical assistance
in remote areas with limited healthcare facilities and infrastructure. To
address this, we introduce MedAide, an on-premise healthcare chatbot. It
leverages tiny-LLMs integrated with LangChain, providing efficient edge-based
preliminary medical diagnostics and support. MedAide employs model
optimizations for minimal memory footprint and latency on embedded edge devices
without server infrastructure. The training process is optimized using low-rank
adaptation (LoRA). Additionally, the model is trained on diverse medical
datasets, employing reinforcement learning from human feedback (RLHF) to
enhance its domain-specific capabilities. The system is implemented on various
consumer GPUs and Nvidia Jetson development board. MedAide achieves 77\%
accuracy in medical consultations and scores 56 in USMLE benchmark, enabling an
energy-efficient healthcare assistance platform that alleviates privacy
concerns due to edge-based deployment, thereby empowering the community.",2024-02-28,2024,2024-02,medical
"OpenMedLM: Prompt engineering can out-perform fine-tuning in medical
  question-answering with open-source large language models","LLMs have become increasingly capable at accomplishing a range of
specialized-tasks and can be utilized to expand equitable access to medical
knowledge. Most medical LLMs have involved extensive fine-tuning, leveraging
specialized medical data and significant, thus costly, amounts of computational
power. Many of the top performing LLMs are proprietary and their access is
limited to very few research groups. However, open-source (OS) models represent
a key area of growth for medical LLMs due to significant improvements in
performance and an inherent ability to provide the transparency and compliance
required in healthcare. We present OpenMedLM, a prompting platform which
delivers state-of-the-art (SOTA) performance for OS LLMs on medical benchmarks.
We evaluated a range of OS foundation LLMs (7B-70B) on four medical benchmarks
(MedQA, MedMCQA, PubMedQA, MMLU medical-subset). We employed a series of
prompting strategies, including zero-shot, few-shot, chain-of-thought (random
selection and kNN selection), and ensemble/self-consistency voting. We found
that OpenMedLM delivers OS SOTA results on three common medical LLM benchmarks,
surpassing the previous best performing OS models that leveraged
computationally costly extensive fine-tuning. The model delivers a 72.6%
accuracy on the MedQA benchmark, outperforming the previous SOTA by 2.4%, and
achieves 81.7% accuracy on the MMLU medical-subset, establishing itself as the
first OS LLM to surpass 80% accuracy on this benchmark. Our results highlight
medical-specific emergent properties in OS LLMs which have not yet been
documented to date elsewhere, and showcase the benefits of further leveraging
prompt engineering to improve the performance of accessible LLMs for medical
applications.",2024-02-29,2024,2024-02,medical
EyeGPT: Ophthalmic Assistant with Large Language Models,"Artificial intelligence (AI) has gained significant attention in healthcare
consultation due to its potential to improve clinical workflow and enhance
medical communication. However, owing to the complex nature of medical
information, large language models (LLM) trained with general world knowledge
might not possess the capability to tackle medical-related tasks at an expert
level. Here, we introduce EyeGPT, a specialized LLM designed specifically for
ophthalmology, using three optimization strategies including role-playing,
finetuning, and retrieval-augmented generation. In particular, we proposed a
comprehensive evaluation framework that encompasses a diverse dataset, covering
various subspecialties of ophthalmology, different users, and diverse inquiry
intents. Moreover, we considered multiple evaluation metrics, including
accuracy, understandability, trustworthiness, empathy, and the proportion of
hallucinations. By assessing the performance of different EyeGPT variants, we
identify the most effective one, which exhibits comparable levels of
understandability, trustworthiness, and empathy to human ophthalmologists (all
Ps>0.05). Overall, ur study provides valuable insights for future research,
facilitating comprehensive comparisons and evaluations of different strategies
for developing specialized LLMs in ophthalmology. The potential benefits
include enhancing the patient experience in eye care and optimizing
ophthalmologists' services.",2024-02-29,2024,2024-02,medical
"CIDGMed: Causal Inference-Driven Medication Recommendation with Enhanced
  Dual-Granularity Learning","Medication recommendation aims to integrate patients' long-term health
records to provide accurate and safe medication combinations for specific
health states. Existing methods often fail to deeply explore the true causal
relationships between diseases/procedures and medications, resulting in biased
recommendations. Additionally, in medication representation learning, the
relationships between information at different granularities of medications,
coarse-grained (medication itself) and fine-grained (molecular level), are not
effectively integrated, leading to biases in representation learning. To
address these limitations, we propose the Causal Inference-driven
Dual-Granularity Medication Recommendation method (CIDGMed). Our approach
leverages causal inference to uncover the relationships between
diseases/procedures and medications, thereby enhancing the rationality and
interpretability of recommendations. By integrating coarse-grained medication
effects with fine-grained molecular structure information, CIDGMed provides a
comprehensive representation of medications. Additionally, we employ a bias
correction model during the prediction phase to further refine recommendations,
ensuring both accuracy and safety. Through extensive experiments, CIDGMed
significantly outperforms current state-of-the-art models across multiple
metrics, achieving a 2.54% increase in accuracy, a 3.65% reduction in side
effects, and a 39.42% improvement in time efficiency. Additionally, we
demonstrate the rationale of CIDGMed through a case study.",2024-03-01,2024,2024-03,medical
"AutoRD: An Automatic and End-to-End System for Rare Disease Knowledge
  Graph Construction Based on Ontologies-enhanced Large Language Models","Rare diseases affect millions worldwide but often face limited research focus
due to their low prevalence. This results in prolonged diagnoses and a lack of
approved therapies. Recent advancements in Large Language Models (LLMs) have
shown promise in automating the extraction of medical information, offering
potential to improve medical diagnosis and management. However, most LLMs lack
professional medical knowledge, especially concerning rare diseases, and
struggle to handle the latest rare disease information. They also cannot
effectively manage rare disease data and are not directly suitable for
diagnosis and management tasks. Our objective is to create an end-to-end system
called AutoRD, which automates the extraction of information from medical texts
about rare diseases, focusing on entities and their relations. AutoRD
integrates up-to-date structured knowledge and demonstrates superior
performance in rare disease extraction tasks. We conduct various experiments to
evaluate AutoRD's performance, aiming to surpass common LLMs and traditional
methods.",2024-03-01,2024,2024-03,medical
"MedSafetyBench: Evaluating and Improving the Medical Safety of Large
  Language Models","As large language models (LLMs) develop increasingly sophisticated
capabilities and find applications in medical settings, it becomes important to
assess their medical safety due to their far-reaching implications for personal
and public health, patient safety, and human rights. However, there is little
to no understanding of the notion of medical safety in the context of LLMs, let
alone how to evaluate and improve it. To address this gap, we first define the
notion of medical safety in LLMs based on the Principles of Medical Ethics set
forth by the American Medical Association. We then leverage this understanding
to introduce MedSafetyBench, the first benchmark dataset designed to measure
the medical safety of LLMs. We demonstrate the utility of MedSafetyBench by
using it to evaluate and improve the medical safety of LLMs. Our results show
that publicly-available medical LLMs do not meet standards of medical safety
and that fine-tuning them using MedSafetyBench improves their medical safety
while preserving their medical performance. By introducing this new benchmark
dataset, our work enables a systematic study of the state of medical safety in
LLMs and motivates future work in this area, paving the way to mitigate the
safety risks of LLMs in medicine. The benchmark dataset and code are available
at https://github.com/AI4LIFE-GROUP/med-safety-bench.",2024-03-06,2024,2024-03,medical
"Apollo: A Lightweight Multilingual Medical LLM towards Democratizing
  Medical AI to 6B People","Despite the vast repository of global medical knowledge predominantly being
in English, local languages are crucial for delivering tailored healthcare
services, particularly in areas with limited medical resources. To extend the
reach of medical AI advancements to a broader population, we aim to develop
medical LLMs across the six most widely spoken languages, encompassing a global
population of 6.1 billion. This effort culminates in the creation of the
ApolloCorpora multilingual medical dataset and the XMedBench benchmark. In the
multilingual medical benchmark, the released Apollo models, at various
relatively-small sizes (i.e., 0.5B, 1.8B, 2B, 6B, and 7B), achieve the best
performance among models of equivalent size. Especially, Apollo-7B is the
state-of-the-art multilingual medical LLMs up to 70B. Additionally, these lite
models could be used to improve the multi-lingual medical capabilities of
larger models without fine-tuning in a proxy-tuning fashion. We will
open-source training corpora, code, model weights and evaluation benchmark.",2024-03-06,2024,2024-03,medical
"An Explainable AI Framework for Artificial Intelligence of Medical
  Things","The healthcare industry has been revolutionized by the convergence of
Artificial Intelligence of Medical Things (AIoMT), allowing advanced
data-driven solutions to improve healthcare systems. With the increasing
complexity of Artificial Intelligence (AI) models, the need for Explainable
Artificial Intelligence (XAI) techniques become paramount, particularly in the
medical domain, where transparent and interpretable decision-making becomes
crucial. Therefore, in this work, we leverage a custom XAI framework,
incorporating techniques such as Local Interpretable Model-Agnostic
Explanations (LIME), SHapley Additive exPlanations (SHAP), and
Gradient-weighted Class Activation Mapping (Grad-Cam), explicitly designed for
the domain of AIoMT. The proposed framework enhances the effectiveness of
strategic healthcare methods and aims to instill trust and promote
understanding in AI-driven medical applications. Moreover, we utilize a
majority voting technique that aggregates predictions from multiple
convolutional neural networks (CNNs) and leverages their collective
intelligence to make robust and accurate decisions in the healthcare system.
Building upon this decision-making process, we apply the XAI framework to brain
tumor detection as a use case demonstrating accurate and transparent diagnosis.
Evaluation results underscore the exceptional performance of the XAI framework,
achieving high precision, recall, and F1 scores with a training accuracy of 99%
and a validation accuracy of 98%. Combining advanced XAI techniques with
ensemble-based deep-learning (DL) methodologies allows for precise and reliable
brain tumor diagnoses as an application of AIoMT.",2024-03-07,2024,2024-03,medical
Medical Speech Symptoms Classification via Disentangled Representation,"Intent is defined for understanding spoken language in existing works. Both
textual features and acoustic features involved in medical speech contain
intent, which is important for symptomatic diagnosis. In this paper, we propose
a medical speech classification model named DRSC that automatically learns to
disentangle intent and content representations from textual-acoustic data for
classification. The intent representations of the text domain and the
Mel-spectrogram domain are extracted via intent encoders, and then the
reconstructed text feature and the Mel-spectrogram feature are obtained through
two exchanges. After combining the intent from two domains into a joint
representation, the integrated intent representation is fed into a decision
layer for classification. Experimental results show that our model obtains an
average accuracy rate of 95% in detecting 25 different medical symptoms.",2024-03-08,2024,2024-03,medical
"All-in-one platform for AI R&D in medical imaging, encompassing data
  collection, selection, annotation, and pre-processing","Deep Learning is advancing medical imaging Research and Development (R&D),
leading to the frequent clinical use of Artificial Intelligence/Machine
Learning (AI/ML)-based medical devices. However, to advance AI R&D, two
challenges arise: 1) significant data imbalance, with most data from
Europe/America and under 10% from Asia, despite its 60% global population
share; and 2) hefty time and investment needed to curate proprietary datasets
for commercial use. In response, we established the first commercial medical
imaging platform, encompassing steps like: 1) data collection, 2) data
selection, 3) annotation, and 4) pre-processing. Moreover, we focus on
harnessing under-represented data from Japan and broader Asia, including
Computed Tomography, Magnetic Resonance Imaging, and Whole Slide Imaging scans.
Using the collected data, we are preparing/providing ready-to-use datasets for
medical AI R&D by 1) offering these datasets to AI firms, biopharma, and
medical device makers and 2) using them as training/test data to develop
tailored AI solutions for such entities. We also aim to merge Blockchain for
data security and plan to synthesize rare disease data via generative AI.
DataHub Website: https://medical-datahub.ai/",2024-03-10,2024,2024-03,medical
"MedKP: Medical Dialogue with Knowledge Enhancement and Clinical Pathway
  Encoding","With appropriate data selection and training techniques, Large Language
Models (LLMs) have demonstrated exceptional success in various medical
examinations and multiple-choice questions. However, the application of LLMs in
medical dialogue generation-a task more closely aligned with actual medical
practice-has been less explored. This gap is attributed to the insufficient
medical knowledge of LLMs, which leads to inaccuracies and hallucinated
information in the generated medical responses. In this work, we introduce the
Medical dialogue with Knowledge enhancement and clinical Pathway encoding
(MedKP) framework, which integrates an external knowledge enhancement module
through a medical knowledge graph and an internal clinical pathway encoding via
medical entities and physician actions. Evaluated with comprehensive metrics,
our experiments on two large-scale, real-world online medical consultation
datasets (MedDG and KaMed) demonstrate that MedKP surpasses multiple baselines
and mitigates the incidence of hallucinations, achieving a new
state-of-the-art. Extensive ablation studies further reveal the effectiveness
of each component of MedKP. This enhancement advances the development of
reliable, automated medical consultation responses using LLMs, thereby
broadening the potential accessibility of precise and real-time medical
assistance.",2024-03-11,2024,2024-03,medical
"Medical Image Synthesis via Fine-Grained Image-Text Alignment and
  Anatomy-Pathology Prompting","Data scarcity and privacy concerns limit the availability of high-quality
medical images for public use, which can be mitigated through medical image
synthesis. However, current medical image synthesis methods often struggle to
accurately capture the complexity of detailed anatomical structures and
pathological conditions. To address these challenges, we propose a novel
medical image synthesis model that leverages fine-grained image-text alignment
and anatomy-pathology prompts to generate highly detailed and accurate
synthetic medical images. Our method integrates advanced natural language
processing techniques with image generative modeling, enabling precise
alignment between descriptive text prompts and the synthesized images'
anatomical and pathological details. The proposed approach consists of two key
components: an anatomy-pathology prompting module and a fine-grained
alignment-based synthesis module. The anatomy-pathology prompting module
automatically generates descriptive prompts for high-quality medical images. To
further synthesize high-quality medical images from the generated prompts, the
fine-grained alignment-based synthesis module pre-defines a visual codebook for
the radiology dataset and performs fine-grained alignment between the codebook
and generated prompts to obtain key patches as visual clues, facilitating
accurate image synthesis. We validate the superiority of our method through
experiments on public chest X-ray datasets and demonstrate that our synthetic
images preserve accurate semantic information, making them valuable for various
medical applications.",2024-03-11,2024,2024-03,medical
"When Eye-Tracking Meets Machine Learning: A Systematic Review on
  Applications in Medical Image Analysis","Eye-gaze tracking research offers significant promise in enhancing various
healthcare-related tasks, above all in medical image analysis and
interpretation. Eye tracking, a technology that monitors and records the
movement of the eyes, provides valuable insights into human visual attention
patterns. This technology can transform how healthcare professionals and
medical specialists engage with and analyze diagnostic images, offering a more
insightful and efficient approach to medical diagnostics. Hence, extracting
meaningful features and insights from medical images by leveraging eye-gaze
data improves our understanding of how radiologists and other medical experts
monitor, interpret, and understand images for diagnostic purposes. Eye-tracking
data, with intricate human visual attention patterns embedded, provides a
bridge to integrating artificial intelligence (AI) development and human
cognition. This integration allows novel methods to incorporate domain
knowledge into machine learning (ML) and deep learning (DL) approaches to
enhance their alignment with human-like perception and decision-making.
Moreover, extensive collections of eye-tracking data have also enabled novel
ML/DL methods to analyze human visual patterns, paving the way to a better
understanding of human vision, attention, and cognition. This systematic review
investigates eye-gaze tracking applications and methodologies for enhancing
ML/DL algorithms for medical image analysis in depth.",2024-03-12,2024,2024-03,medical
"Explainable Machine Learning-Based Security and Privacy Protection
  Framework for Internet of Medical Things Systems","The Internet of Medical Things (IoMT) transcends traditional medical
boundaries, enabling a transition from reactive treatment to proactive
prevention. This innovative method revolutionizes healthcare by facilitating
early disease detection and tailored care, particularly in chronic disease
management, where IoMT automates treatments based on real-time health data
collection. Nonetheless, its benefits are countered by significant security
challenges that endanger the lives of its users due to the sensitivity and
value of the processed data, thereby attracting malicious interests. Moreover,
the utilization of wireless communication for data transmission exposes medical
data to interception and tampering by cybercriminals. Additionally, anomalies
may arise due to human error, network interference, or hardware malfunctions.
In this context, anomaly detection based on Machine Learning (ML) is an
interesting solution, but it comes up against obstacles in terms of
explicability and privacy protection. To address these challenges, a new
framework for Intrusion Detection Systems is introduced, leveraging Artificial
Neural Networks for intrusion detection while utilizing Federated Learning (FL)
for privacy preservation. Additionally, eXplainable Artificial Intelligence
methods are incorporated to enhance model explanation and interpretation. The
efficacy of the proposed framework is evaluated and compared with centralized
approaches using multiple datasets containing network and medical data,
simulating various attack types impacting the confidentiality, integrity, and
availability of medical and physiological data. The results obtained offer
compelling evidence that the FL method performs comparably to the centralized
method, demonstrating high performance. Additionally, it affords the dual
advantage of safeguarding privacy and providing model explanation while
adhering to ethical principles.",2024-03-14,2024,2024-03,medical
"A Continued Pretrained LLM Approach for Automatic Medical Note
  Generation","LLMs are revolutionizing NLP tasks. However, the use of the most advanced
LLMs, such as GPT-4, is often prohibitively expensive for most specialized
fields. We introduce HEAL, the first continuously trained 13B LLaMA2-based LLM
that is purpose-built for medical conversations and measured on automated
scribing. Our results demonstrate that HEAL outperforms GPT-4 and PMC-LLaMA in
PubMedQA, with an accuracy of 78.4\%. It also achieves parity with GPT-4 in
generating medical notes. Remarkably, HEAL surpasses GPT-4 and Med-PaLM 2 in
identifying more correct medical concepts and exceeds the performance of human
scribes and other comparable models in correctness and completeness.",2024-03-14,2024,2024-03,medical
"Emotional Intelligence Through Artificial Intelligence : NLP and Deep
  Learning in the Analysis of Healthcare Texts","This manuscript presents a methodical examination of the utilization of
Artificial Intelligence in the assessment of emotions in texts related to
healthcare, with a particular focus on the incorporation of Natural Language
Processing and deep learning technologies. We scrutinize numerous research
studies that employ AI to augment sentiment analysis, categorize emotions, and
forecast patient outcomes based on textual information derived from clinical
narratives, patient feedback on medications, and online health discussions. The
review demonstrates noteworthy progress in the precision of algorithms used for
sentiment classification, the prognostic capabilities of AI models for
neurodegenerative diseases, and the creation of AI-powered systems that offer
support in clinical decision-making. Remarkably, the utilization of AI
applications has exhibited an enhancement in personalized therapy plans by
integrating patient sentiment and contributing to the early identification of
mental health disorders. There persist challenges, which encompass ensuring the
ethical application of AI, safeguarding patient confidentiality, and addressing
potential biases in algorithmic procedures. Nevertheless, the potential of AI
to revolutionize healthcare practices is unmistakable, offering a future where
healthcare is not only more knowledgeable and efficient but also more
empathetic and centered around the needs of patients. This investigation
underscores the transformative influence of AI on healthcare, delivering a
comprehensive comprehension of its role in examining emotional content in
healthcare texts and highlighting the trajectory towards a more compassionate
approach to patient care. The findings advocate for a harmonious synergy
between AI's analytical capabilities and the human aspects of healthcare.",2024-03-14,2024,2024-03,medical
"VisionCLIP: An Med-AIGC based Ethical Language-Image Foundation Model
  for Generalizable Retina Image Analysis","Generalist foundation model has ushered in newfound capabilities in medical
domain. However, the contradiction between the growing demand for high-quality
annotated data with patient privacy continues to intensify. The utilization of
medical artificial intelligence generated content (Med-AIGC) as an
inexhaustible resource repository arises as a potential solution to address the
aforementioned challenge. Here we harness 1 million open-source synthetic
fundus images paired with natural language descriptions, to curate an ethical
language-image foundation model for retina image analysis named VisionCLIP.
VisionCLIP achieves competitive performance on three external datasets compared
with the existing method pre-trained on real-world data in a zero-shot fashion.
The employment of artificially synthetic images alongside corresponding textual
data for training enables the medical foundation model to successfully
assimilate knowledge of disease symptomatology, thereby circumventing potential
breaches of patient confidentiality.",2024-03-16,2024,2024-03,medical
"Machine Learning and Transformers for Thyroid Carcinoma Diagnosis: A
  Review","The growing interest in developing smart diagnostic systems to help medical
experts process extensive data for treating incurable diseases has been
notable. In particular, the challenge of identifying thyroid cancer (TC) has
seen progress with the use of machine learning (ML) and big data analysis,
incorporating Transformers to evaluate TC prognosis and determine the risk of
malignancy in individuals. This review article presents a summary of various
studies on AI-based approaches, especially those employing Transformers, for
diagnosing TC. It introduces a new categorization system for these methods
based on artificial intelligence (AI) algorithms, the goals of the framework,
and the computing environments used. Additionally, it scrutinizes and contrasts
the available TC datasets by their features. The paper highlights the
importance of AI instruments in aiding the diagnosis and treatment of TC
through supervised, unsupervised, or mixed approaches, with a special focus on
the ongoing importance of Transformers and large language models (LLMs) in
medical diagnostics and disease management. It further discusses the progress
made and the continuing obstacles in this area. Lastly, it explores future
directions and focuses within this research field.",2024-03-17,2024,2024-03,medical
"Deep learning with noisy labels in medical prediction problems: a
  scoping review","Objectives: Medical research faces substantial challenges from noisy labels
attributed to factors like inter-expert variability and machine-extracted
labels. Despite this, the adoption of label noise management remains limited,
and label noise is largely ignored. To this end, there is a critical need to
conduct a scoping review focusing on the problem space. This scoping review
aims to comprehensively review label noise management in deep learning-based
medical prediction problems, which includes label noise detection, label noise
handling, and evaluation. Research involving label uncertainty is also
included.
  Methods: Our scoping review follows the Preferred Reporting Items for
Systematic Reviews and Meta-Analyses (PRISMA) guidelines. We searched 4
databases, including PubMed, IEEE Xplore, Google Scholar, and Semantic Scholar.
Our search terms include ""noisy label AND medical / healthcare / clinical"",
""un-certainty AND medical / healthcare / clinical"", and ""noise AND medical /
healthcare / clinical"".
  Results: A total of 60 papers met inclusion criteria between 2016 and 2023. A
series of practical questions in medical research are investigated. These
include the sources of label noise, the impact of label noise, the detection of
label noise, label noise handling techniques, and their evaluation.
Categorization of both label noise detection methods and handling techniques
are provided.
  Discussion: From a methodological perspective, we observe that the medical
community has been up to date with the broader deep-learning community, given
that most techniques have been evaluated on medical data. We recommend
considering label noise as a standard element in medical research, even if it
is not dedicated to handling noisy labels. Initial experiments can start with
easy-to-implement methods, such as noise-robust loss functions, weighting, and
curriculum learning.",2024-03-19,2024,2024-03,medical
"Large Language Models for Multi-Choice Question Classification of
  Medical Subjects","The aim of this paper is to evaluate whether large language models trained on
multi-choice question data can be used to discriminate between medical
subjects. This is an important and challenging task for automatic question
answering. To achieve this goal, we train deep neural networks for multi-class
classification of questions into the inferred medical subjects. Using our
Multi-Question (MQ) Sequence-BERT method, we outperform the state-of-the-art
results on the MedMCQA dataset with an accuracy of 0.68 and 0.60 on their
development and test sets, respectively. In this sense, we show the capability
of AI and LLMs in particular for multi-classification tasks in the Healthcare
domain.",2024-03-21,2024,2024-03,medical
"Dermacen Analytica: A Novel Methodology Integrating Multi-Modal Large
  Language Models with Machine Learning in tele-dermatology","The rise of Artificial Intelligence creates great promise in the field of
medical discovery, diagnostics and patient management. However, the vast
complexity of all medical domains require a more complex approach that combines
machine learning algorithms, classifiers, segmentation algorithms and, lately,
large language models. In this paper, we describe, implement and assess an
Artificial Intelligence-empowered system and methodology aimed at assisting the
diagnosis process of skin lesions and other skin conditions within the field of
dermatology that aims to holistically address the diagnostic process in this
domain. The workflow integrates large language, transformer-based vision models
and sophisticated machine learning tools. This holistic approach achieves a
nuanced interpretation of dermatological conditions that simulates and
facilitates a dermatologist's workflow. We assess our proposed methodology
through a thorough cross-model validation technique embedded in an evaluation
pipeline that utilizes publicly available medical case studies of skin
conditions and relevant images. To quantitatively score the system performance,
advanced machine learning and natural language processing tools are employed
which focus on similarity comparison and natural language inference.
Additionally, we incorporate a human expert evaluation process based on a
structured checklist to further validate our results. We implemented the
proposed methodology in a system which achieved approximate (weighted) scores
of 0.87 for both contextual understanding and diagnostic accuracy,
demonstrating the efficacy of our approach in enhancing dermatological
analysis. The proposed methodology is expected to prove useful in the
development of next-generation tele-dermatology applications, enhancing remote
consultation capabilities and access to care, especially in underserved areas.",2024-03-21,2024,2024-03,medical
"Practical Applications of Advanced Cloud Services and Generative AI
  Systems in Medical Image Analysis","The medical field is one of the important fields in the application of
artificial intelligence technology. With the explosive growth and
diversification of medical data, as well as the continuous improvement of
medical needs and challenges, artificial intelligence technology is playing an
increasingly important role in the medical field. Artificial intelligence
technologies represented by computer vision, natural language processing, and
machine learning have been widely penetrated into diverse scenarios such as
medical imaging, health management, medical information, and drug research and
development, and have become an important driving force for improving the level
and quality of medical services.The article explores the transformative
potential of generative AI in medical imaging, emphasizing its ability to
generate syntheticACM-2 data, enhance images, aid in anomaly detection, and
facilitate image-to-image translation. Despite challenges like model
complexity, the applications of generative models in healthcare, including
Med-PaLM 2 technology, show promising results. By addressing limitations in
dataset size and diversity, these models contribute to more accurate diagnoses
and improved patient outcomes. However, ethical considerations and
collaboration among stakeholders are essential for responsible implementation.
Through experiments leveraging GANs to augment brain tumor MRI datasets, the
study demonstrates how generative AI can enhance image quality and diversity,
ultimately advancing medical diagnostics and patient care.",2024-03-26,2024,2024-03,medical
"Medical Visual Prompting (MVP): A Unified Framework for Versatile and
  High-Quality Medical Image Segmentation","Accurate segmentation of lesion regions is crucial for clinical diagnosis and
treatment across various diseases. While deep convolutional networks have
achieved satisfactory results in medical image segmentation, they face
challenges such as loss of lesion shape information due to continuous
convolution and downsampling, as well as the high cost of manually labeling
lesions with varying shapes and sizes. To address these issues, we propose a
novel medical visual prompting (MVP) framework that leverages pre-training and
prompting concepts from natural language processing (NLP). The framework
utilizes three key components: Super-Pixel Guided Prompting (SPGP) for
superpixelating the input image, Image Embedding Guided Prompting (IEGP) for
freezing patch embedding and merging with superpixels to provide visual
prompts, and Adaptive Attention Mechanism Guided Prompting (AAGP) for
pinpointing prompt content and efficiently adapting all layers. By integrating
SPGP, IEGP, and AAGP, the MVP enables the segmentation network to better learn
shape prompting information and facilitates mutual learning across different
tasks. Extensive experiments conducted on five datasets demonstrate superior
performance of this method in various challenging medical image tasks, while
simplifying single-task medical segmentation models. This novel framework
offers improved performance with fewer parameters and holds significant
potential for accurate segmentation of lesion regions in various medical tasks,
making it clinically valuable.",2024-04-01,2024,2024-04,medical
"Data-Efficient Unsupervised Interpolation Without Any Intermediate Frame
  for 4D Medical Images","4D medical images, which represent 3D images with temporal information, are
crucial in clinical practice for capturing dynamic changes and monitoring
long-term disease progression. However, acquiring 4D medical images poses
challenges due to factors such as radiation exposure and imaging duration,
necessitating a balance between achieving high temporal resolution and
minimizing adverse effects. Given these circumstances, not only is data
acquisition challenging, but increasing the frame rate for each dataset also
proves difficult. To address this challenge, this paper proposes a simple yet
effective Unsupervised Volumetric Interpolation framework, UVI-Net. This
framework facilitates temporal interpolation without the need for any
intermediate frames, distinguishing it from the majority of other existing
unsupervised methods. Experiments on benchmark datasets demonstrate significant
improvements across diverse evaluation metrics compared to unsupervised and
supervised baselines. Remarkably, our approach achieves this superior
performance even when trained with a dataset as small as one, highlighting its
exceptional robustness and efficiency in scenarios with sparse supervision.
This positions UVI-Net as a compelling alternative for 4D medical imaging,
particularly in settings where data availability is limited. The source code is
available at https://github.com/jungeun122333/UVI-Net.",2024-04-01,2024,2024-04,medical
"Non-negative Subspace Feature Representation for Few-shot Learning in
  Medical Imaging","Unlike typical visual scene recognition domains, in which massive datasets
are accessible to deep neural networks, medical image interpretations are often
obstructed by the paucity of data. In this paper, we investigate the
effectiveness of data-based few-shot learning in medical imaging by exploring
different data attribute representations in a low-dimensional space. We
introduce different types of non-negative matrix factorization (NMF) in
few-shot learning, addressing the data scarcity issue in medical image
classification. Extensive empirical studies are conducted in terms of
validating the effectiveness of NMF, especially its supervised variants (e.g.,
discriminative NMF, and supervised and constrained NMF with sparseness), and
the comparison with principal component analysis (PCA), i.e., the collaborative
representation-based dimensionality reduction technique derived from
eigenvectors. With 14 different datasets covering 11 distinct illness
categories, thorough experimental results and comparison with related
techniques demonstrate that NMF is a competitive alternative to PCA for
few-shot learning in medical imaging, and the supervised NMF algorithms are
more discriminative in the subspace with greater effectiveness. Furthermore, we
show that the part-based representation of NMF, especially its supervised
variants, is dramatically impactful in detecting lesion areas in medical
imaging with limited samples.",2024-04-03,2024,2024-04,medical
"Investigation of Energy-efficient AI Model Architectures and Compression
  Techniques for ""Green"" Fetal Brain Segmentation","Artificial intelligence have contributed to advancements across various
industries. However, the rapid growth of artificial intelligence technologies
also raises concerns about their environmental impact, due to associated carbon
footprints to train computational models. Fetal brain segmentation in medical
imaging is challenging due to the small size of the fetal brain and the limited
image quality of fast 2D sequences. Deep neural networks are a promising method
to overcome this challenge. In this context, the construction of larger models
requires extensive data and computing power, leading to high energy
consumption. Our study aims to explore model architectures and compression
techniques that promote energy efficiency by optimizing the trade-off between
accuracy and energy consumption through various strategies such as lightweight
network design, architecture search, and optimized distributed training tools.
We have identified several effective strategies including optimization of data
loading, modern optimizers, distributed training strategy implementation, and
reduced floating point operations precision usage with light model
architectures while tuning parameters according to available computer
resources. Our findings demonstrate that these methods lead to satisfactory
model performance with low energy consumption during deep neural network
training for medical image segmentation.",2024-04-03,2024,2024-04,medical
"Conversational Disease Diagnosis via External Planner-Controlled Large
  Language Models","The development of large language models (LLMs) has brought unprecedented
possibilities for artificial intelligence (AI) based medical diagnosis.
However, the application perspective of LLMs in real diagnostic scenarios is
still unclear because they are not adept at collecting patient data
proactively. This study presents a LLM-based diagnostic system that enhances
planning capabilities by emulating doctors. Our system involves two external
planners to handle planning tasks. The first planner employs a reinforcement
learning approach to formulate disease screening questions and conduct initial
diagnoses. The second planner uses LLMs to parse medical guidelines and conduct
differential diagnoses. By utilizing real patient electronic medical record
data, we constructed simulated dialogues between virtual patients and doctors
and evaluated the diagnostic abilities of our system. We demonstrated that our
system obtained impressive performance in both disease screening and
differential diagnoses tasks. This research represents a step towards more
seamlessly integrating AI into clinical settings, potentially enhancing the
accuracy and accessibility of medical diagnostics.",2024-04-04,2024,2024-04,medical
Does Biomedical Training Lead to Better Medical Performance?,"Large Language Models (LLMs) are expected to significantly contribute to
patient care, diagnostics, and administrative processes. Emerging biomedical
LLMs aim to address healthcare-specific challenges, including privacy demands
and computational constraints. Assessing the models' suitability for this
sensitive application area is of the utmost importance. However, biomedical
training has not been systematically evaluated on medical tasks. This study
investigates the effect of biomedical training in the context of six practical
medical tasks evaluating $25$ models. In contrast to previous evaluations, our
results reveal a performance decline in nine out of twelve biomedical models
after fine-tuning, particularly on tasks involving hallucinations, ICD10
coding, and instruction adherence. General-domain models like
Meta-Llama-3.1-70B-Instruct outperformed their biomedical counterparts,
indicating a trade-off between domain-specific fine-tuning and general medical
task performance. We open-source all evaluation scripts and datasets at
https://github.com/TIO-IKIM/CLUE to support further research in this critical
area.",2024-04-05,2024,2024-04,medical
"Autonomous Artificial Intelligence Agents for Clinical Decision Making
  in Oncology","Multimodal artificial intelligence (AI) systems have the potential to enhance
clinical decision-making by interpreting various types of medical data.
However, the effectiveness of these models across all medical fields is
uncertain. Each discipline presents unique challenges that need to be addressed
for optimal performance. This complexity is further increased when attempting
to integrate different fields into a single model. Here, we introduce an
alternative approach to multimodal medical AI that utilizes the generalist
capabilities of a large language model (LLM) as a central reasoning engine.
This engine autonomously coordinates and deploys a set of specialized medical
AI tools. These tools include text, radiology and histopathology image
interpretation, genomic data processing, web searches, and document retrieval
from medical guidelines. We validate our system across a series of clinical
oncology scenarios that closely resemble typical patient care workflows. We
show that the system has a high capability in employing appropriate tools
(97%), drawing correct conclusions (93.6%), and providing complete (94%), and
helpful (89.2%) recommendations for individual patient cases while consistently
referencing relevant literature (82.5%) upon instruction. This work provides
evidence that LLMs can effectively plan and execute domain-specific models to
retrieve or synthesize new information when used as autonomous agents. This
enables them to function as specialist, patient-tailored clinical assistants.
It also simplifies regulatory compliance by allowing each component tool to be
individually validated and approved. We believe, that our work can serve as a
proof-of-concept for more advanced LLM-agents in the medical domain.",2024-04-06,2024,2024-04,medical
"ProtoAL: Interpretable Deep Active Learning with prototypes for medical
  imaging","The adoption of Deep Learning algorithms in the medical imaging field is a
prominent area of research, with high potential for advancing AI-based
Computer-aided diagnosis (AI-CAD) solutions. However, current solutions face
challenges due to a lack of interpretability features and high data demands,
prompting recent efforts to address these issues. In this study, we propose the
ProtoAL method, where we integrate an interpretable DL model into the Deep
Active Learning (DAL) framework. This approach aims to address both challenges
by focusing on the medical imaging context and utilizing an inherently
interpretable model based on prototypes. We evaluated ProtoAL on the Messidor
dataset, achieving an area under the precision-recall curve of 0.79 while
utilizing only 76.54\% of the available labeled data. These capabilities can
enhances the practical usability of a DL model in the medical field, providing
a means of trust calibration in domain experts and a suitable solution for
learning in the data scarcity context often found.",2024-04-06,2024,2024-04,medical
"MedExpQA: Multilingual Benchmarking of Large Language Models for Medical
  Question Answering","Large Language Models (LLMs) have the potential of facilitating the
development of Artificial Intelligence technology to assist medical experts for
interactive decision support, which has been demonstrated by their competitive
performances in Medical QA. However, while impressive, the required quality bar
for medical applications remains far from being achieved. Currently, LLMs
remain challenged by outdated knowledge and by their tendency to generate
hallucinated content. Furthermore, most benchmarks to assess medical knowledge
lack reference gold explanations which means that it is not possible to
evaluate the reasoning of LLMs predictions. Finally, the situation is
particularly grim if we consider benchmarking LLMs for languages other than
English which remains, as far as we know, a totally neglected topic. In order
to address these shortcomings, in this paper we present MedExpQA, the first
multilingual benchmark based on medical exams to evaluate LLMs in Medical
Question Answering. To the best of our knowledge, MedExpQA includes for the
first time reference gold explanations written by medical doctors which can be
leveraged to establish various gold-based upper-bounds for comparison with LLMs
performance. Comprehensive multilingual experimentation using both the gold
reference explanations and Retrieval Augmented Generation (RAG) approaches show
that performance of LLMs still has large room for improvement, especially for
languages other than English. Furthermore, and despite using state-of-the-art
RAG methods, our results also demonstrate the difficulty of obtaining and
integrating readily available medical knowledge that may positively impact
results on downstream evaluations for Medical Question Answering. So far the
benchmark is available in four languages, but we hope that this work may
encourage further development to other languages.",2024-04-08,2024,2024-04,medical
"VietMed: A Dataset and Benchmark for Automatic Speech Recognition of
  Vietnamese in the Medical Domain","Due to privacy restrictions, there's a shortage of publicly available speech
recognition datasets in the medical domain. In this work, we present VietMed -
a Vietnamese speech recognition dataset in the medical domain comprising 16h of
labeled medical speech, 1000h of unlabeled medical speech and 1200h of
unlabeled general-domain speech. To our best knowledge, VietMed is by far the
world's largest public medical speech recognition dataset in 7 aspects: total
duration, number of speakers, diseases, recording conditions, speaker roles,
unique medical terms and accents. VietMed is also by far the largest public
Vietnamese speech dataset in terms of total duration. Additionally, we are the
first to present a medical ASR dataset covering all ICD-10 disease groups and
all accents within a country. Moreover, we release the first public large-scale
pre-trained models for Vietnamese ASR, w2v2-Viet and XLSR-53-Viet, along with
the first public large-scale fine-tuned models for medical ASR. Even without
any medical data in unsupervised pre-training, our best pre-trained model
XLSR-53-Viet generalizes very well to the medical domain by outperforming
state-of-the-art XLSR-53, from 51.8% to 29.6% WER on test set (a relative
reduction of more than 40%). All code, data and models are made publicly
available: https://github.com/leduckhai/MultiMed/tree/master/VietMed.",2024-04-08,2024,2024-04,medical
"Iterative Refinement Strategy for Automated Data Labeling: Facial
  Landmark Diagnosis in Medical Imaging","Automated data labeling techniques are crucial for accelerating the
development of deep learning models, particularly in complex medical imaging
applications. However, ensuring accuracy and efficiency remains challenging.
This paper presents iterative refinement strategies for automated data labeling
in facial landmark diagnosis to enhance accuracy and efficiency for deep
learning models in medical applications, including dermatology, plastic
surgery, and ophthalmology. Leveraging feedback mechanisms and advanced
algorithms, our approach iteratively refines initial labels, reducing reliance
on manual intervention while improving label quality. Through empirical
evaluation and case studies, we demonstrate the effectiveness of our proposed
strategies in deep learning tasks across medical imaging domains. Our results
highlight the importance of iterative refinement in automated data labeling to
enhance the capabilities of deep learning systems in medical imaging
applications.",2024-04-08,2024,2024-04,medical
"Medical mT5: An Open-Source Multilingual Text-to-Text LLM for The
  Medical Domain","Research on language technology for the development of medical applications
is currently a hot topic in Natural Language Understanding and Generation.
Thus, a number of large language models (LLMs) have recently been adapted to
the medical domain, so that they can be used as a tool for mediating in
human-AI interaction. While these LLMs display competitive performance on
automated medical texts benchmarks, they have been pre-trained and evaluated
with a focus on a single language (English mostly). This is particularly true
of text-to-text models, which typically require large amounts of
domain-specific pre-training data, often not easily accessible for many
languages. In this paper, we address these shortcomings by compiling, to the
best of our knowledge, the largest multilingual corpus for the medical domain
in four languages, namely English, French, Italian and Spanish. This new corpus
has been used to train Medical mT5, the first open-source text-to-text
multilingual model for the medical domain. Additionally, we present two new
evaluation benchmarks for all four languages with the aim of facilitating
multilingual research in this domain. A comprehensive evaluation shows that
Medical mT5 outperforms both encoders and similarly sized text-to-text models
for the Spanish, French, and Italian benchmarks, while being competitive with
current state-of-the-art LLMs in English.",2024-04-11,2024,2024-04,medical
"Introducing L2M3, A Multilingual Medical Large Language Model to Advance
  Health Equity in Low-Resource Regions","Addressing the imminent shortfall of 10 million health workers by 2030,
predominantly in Low- and Middle-Income Countries (LMICs), this paper
introduces an innovative approach that harnesses the power of Large Language
Models (LLMs) integrated with machine translation models. This solution is
engineered to meet the unique needs of Community Health Workers (CHWs),
overcoming language barriers, cultural sensitivities, and the limited
availability of medical dialog datasets. I have crafted a model that not only
boasts superior translation capabilities but also undergoes rigorous
fine-tuning on open-source datasets to ensure medical accuracy and is equipped
with comprehensive safety features to counteract the risks of misinformation.
  Featuring a modular design, this approach is specifically structured for
swift adaptation across various linguistic and cultural contexts, utilizing
open-source components to significantly reduce healthcare operational costs.
This strategic innovation markedly improves the accessibility and quality of
healthcare services by providing CHWs with contextually appropriate medical
knowledge and diagnostic tools. This paper highlights the transformative impact
of this context-aware LLM, underscoring its crucial role in addressing the
global healthcare workforce deficit and propelling forward healthcare outcomes
in LMICs.",2024-04-11,2024,2024-04,medical
"Leveraging Large Language Model as Simulated Patients for Clinical
  Education","Simulated Patients (SPs) play a crucial role in clinical medical education by
providing realistic scenarios for student practice. However, the high cost of
training and hiring qualified SPs, along with the heavy workload and potential
risks they face in consistently portraying actual patients, limit students'
access to this type of clinical training. Consequently, the integration of
computer program-based simulated patients has emerged as a valuable educational
tool in recent years. With the rapid development of Large Language Models
(LLMs), their exceptional capabilities in conversational artificial
intelligence and role-playing have been demonstrated, making them a feasible
option for implementing Virtual Simulated Patient (VSP). In this paper, we
present an integrated model-agnostic framework called CureFun that harnesses
the potential of LLMs in clinical medical education. This framework facilitates
natural conversations between students and simulated patients, evaluates their
dialogue, and provides suggestions to enhance students' clinical inquiry
skills. Through comprehensive evaluations, our approach demonstrates more
authentic and professional SP-scenario dialogue flows compared to other
LLM-based chatbots, thus proving its proficiency in simulating patients.
Additionally, leveraging CureFun's evaluation ability, we assess several
medical LLMs and discuss the possibilities and limitations of using LLMs as
virtual doctors from the perspective of their diagnostic abilities.",2024-04-13,2024,2024-04,medical
Ethical Framework for Responsible Foundational Models in Medical Imaging,"Foundational models (FMs) have tremendous potential to revolutionize medical
imaging. However, their deployment in real-world clinical settings demands
extensive ethical considerations. This paper aims to highlight the ethical
concerns related to FMs and propose a framework to guide their responsible
development and implementation within medicine. We meticulously examine ethical
issues such as privacy of patient data, bias mitigation, algorithmic
transparency, explainability and accountability. The proposed framework is
designed to prioritize patient welfare, mitigate potential risks, and foster
trust in AI-assisted healthcare.",2024-04-14,2024,2024-04,medical
A Sentiment Analysis of Medical Text Based on Deep Learning,"The field of natural language processing (NLP) has made significant progress
with the rapid development of deep learning technologies. One of the research
directions in text sentiment analysis is sentiment analysis of medical texts,
which holds great potential for application in clinical diagnosis. However, the
medical field currently lacks sufficient text datasets, and the effectiveness
of sentiment analysis is greatly impacted by different model design approaches,
which presents challenges. Therefore, this paper focuses on the medical domain,
using bidirectional encoder representations from transformers (BERT) as the
basic pre-trained model and experimenting with modules such as convolutional
neural network (CNN), fully connected network (FCN), and graph convolutional
networks (GCN) at the output layer. Experiments and analyses were conducted on
the METS-CoV dataset to explore the training performance after integrating
different deep learning networks. The results indicate that CNN models
outperform other networks when trained on smaller medical text datasets in
combination with pre-trained models like BERT. This study highlights the
significance of model selection in achieving effective sentiment analysis in
the medical domain and provides a reference for future research to develop more
efficient model architectures.",2024-04-16,2024,2024-04,medical
"Integration of Self-Supervised BYOL in Semi-Supervised Medical Image
  Recognition","Image recognition techniques heavily rely on abundant labeled data,
particularly in medical contexts. Addressing the challenges associated with
obtaining labeled data has led to the prominence of self-supervised learning
and semi-supervised learning, especially in scenarios with limited annotated
data. In this paper, we proposed an innovative approach by integrating
self-supervised learning into semi-supervised models to enhance medical image
recognition. Our methodology commences with pre-training on unlabeled data
utilizing the BYOL method. Subsequently, we merge pseudo-labeled and labeled
datasets to construct a neural network classifier, refining it through
iterative fine-tuning. Experimental results on three different datasets
demonstrate that our approach optimally leverages unlabeled data, outperforming
existing methods in terms of accuracy for medical image recognition.",2024-04-16,2024,2024-04,medical
"CausalMed: Causality-Based Personalized Medication Recommendation
  Centered on Patient health state","Medication recommendation systems are developed to recommend suitable
medications tailored to specific patient. Previous researches primarily focus
on learning medication representations, which have yielded notable advances.
However, these methods are limited to capturing personalized patient
representations due to the following primary limitations: (i) unable to capture
the differences in the impact of diseases/procedures on patients across various
patient health states; (ii) fail to model the direct causal relationships
between medications and specific health state of patients, resulting in an
inability to determine which specific disease each medication is treating. To
address these limitations, we propose CausalMed, a patient health state-centric
model capable of enhancing the personalization of patient representations.
Specifically, CausalMed first captures the causal relationship between
diseases/procedures and medications through causal discovery and evaluates
their causal effects. Building upon this, CausalMed focuses on analyzing the
health state of patients, capturing the dynamic differences of
diseases/procedures in different health states of patients, and transforming
diseases/procedures into medications on direct causal relationships.
Ultimately, CausalMed integrates information from longitudinal visits to
recommend medication combinations. Extensive experiments on real-world datasets
show that our method learns more personalized patient representation and
outperforms state-of-the-art models in accuracy and safety.",2024-04-18,2024,2024-04,medical
A Large-scale Medical Visual Task Adaptation Benchmark,"Visual task adaptation has been demonstrated to be effective in adapting
pre-trained Vision Transformers (ViTs) to general downstream visual tasks using
specialized learnable layers or tokens. However, there is yet a large-scale
benchmark to fully explore the effect of visual task adaptation on the
realistic and important medical domain, particularly across diverse medical
visual modalities, such as color images, X-ray, and CT. To close this gap, we
present Med-VTAB, a large-scale Medical Visual Task Adaptation Benchmark
consisting of 1.68 million medical images for diverse organs, modalities, and
adaptation approaches. Based on Med-VTAB, we explore the scaling law of medical
prompt tuning concerning tunable parameters and the generalizability of medical
visual adaptation using non-medical/medical pre-train weights. Besides, we
study the impact of patient ID out-of-distribution on medical visual
adaptation, which is a real and challenging scenario. Furthermore, results from
Med-VTAB indicate that a single pre-trained model falls short in medical task
adaptation. Therefore, we introduce GMoE-Adapter, a novel method that combines
medical and general pre-training weights through a gated mixture-of-experts
adapter, achieving state-of-the-art results in medical visual task adaptation.",2024-04-19,2024,2024-04,medical
"COIN: Counterfactual inpainting for weakly supervised semantic
  segmentation for medical images","Deep learning is dramatically transforming the field of medical imaging and
radiology, enabling the identification of pathologies in medical images,
including computed tomography (CT) and X-ray scans. However, the performance of
deep learning models, particularly in segmentation tasks, is often limited by
the need for extensive annotated datasets. To address this challenge, the
capabilities of weakly supervised semantic segmentation are explored through
the lens of Explainable AI and the generation of counterfactual explanations.
The scope of this research is development of a novel counterfactual inpainting
approach (COIN) that flips the predicted classification label from abnormal to
normal by using a generative model. For instance, if the classifier deems an
input medical image X as abnormal, indicating the presence of a pathology, the
generative model aims to inpaint the abnormal region, thus reversing the
classifier's original prediction label. The approach enables us to produce
precise segmentations for pathologies without depending on pre-existing
segmentation masks. Crucially, image-level labels are utilized, which are
substantially easier to acquire than creating detailed segmentation masks. The
effectiveness of the method is demonstrated by segmenting synthetic targets and
actual kidney tumors from CT images acquired from Tartu University Hospital in
Estonia. The findings indicate that COIN greatly surpasses established
attribution methods, such as RISE, ScoreCAM, and LayerCAM, as well as an
alternative counterfactual explanation method introduced by Singla et al. This
evidence suggests that COIN is a promising approach for semantic segmentation
of tumors in CT images, and presents a step forward in making deep learning
applications more accessible and effective in healthcare, where annotated data
is scarce.",2024-04-19,2024,2024-04,medical
"Accelerating Medical Knowledge Discovery through Automated Knowledge
  Graph Generation and Enrichment","Knowledge graphs (KGs) serve as powerful tools for organizing and
representing structured knowledge. While their utility is widely recognized,
challenges persist in their automation and completeness. Despite efforts in
automation and the utilization of expert-created ontologies, gaps in
connectivity remain prevalent within KGs. In response to these challenges, we
propose an innovative approach termed ``Medical Knowledge Graph Automation
(M-KGA)"". M-KGA leverages user-provided medical concepts and enriches them
semantically using BioPortal ontologies, thereby enhancing the completeness of
knowledge graphs through the integration of pre-trained embeddings. Our
approach introduces two distinct methodologies for uncovering hidden
connections within the knowledge graph: a cluster-based approach and a
node-based approach. Through rigorous testing involving 100 frequently
occurring medical concepts in Electronic Health Records (EHRs), our M-KGA
framework demonstrates promising results, indicating its potential to address
the limitations of existing knowledge graph automation techniques.",2024-04-21,2024,2024-04,medical
MDAgents: An Adaptive Collaboration of LLMs for Medical Decision-Making,"Foundation models are becoming valuable tools in medicine. Yet despite their
promise, the best way to leverage Large Language Models (LLMs) in complex
medical tasks remains an open question. We introduce a novel multi-agent
framework, named Medical Decision-making Agents (MDAgents) that helps address
this gap by automatically assigning a collaboration structure to a team of
LLMs. The assigned solo or group collaboration structure is tailored to the
medical task at hand, emulating real-world medical decision-making processes
adapted to tasks of varying complexities. We evaluate our framework and
baseline methods using state-of-the-art LLMs across a suite of real-world
medical knowledge and medical diagnosis benchmarks, including a comparison of
LLMs' medical complexity classification against human physicians. MDAgents
achieved the best performance in seven out of ten benchmarks on tasks requiring
an understanding of medical knowledge and multi-modal reasoning, showing a
significant improvement of up to 4.2% (p < 0.05) compared to previous methods'
best performances. Ablation studies reveal that MDAgents effectively determines
medical complexity to optimize for efficiency and accuracy across diverse
medical tasks. Notably, the combination of moderator review and external
medical knowledge in group collaboration resulted in an average accuracy
improvement of 11.8%. Our code can be found at
https://github.com/mitmedialab/MDAgents.",2024-04-22,2024,2024-04,medical
"Grounded Knowledge-Enhanced Medical Vision-Language Pre-training for
  Chest X-Ray","Medical foundation models have the potential to revolutionize healthcare by
providing robust and generalized representations of medical data. Medical
vision-language pre-training has emerged as a promising approach for learning
domain-general representations of medical image and text. Current algorithms
that exploit global and local alignment between medical image and text could
however be marred by redundant information in medical data. To address this
issue, we propose a grounded knowledge-enhanced medical vision-language
pre-training (GK-MVLP) framework for chest X-ray. In this framework, medical
knowledge was grounded to the appropriate anatomical regions by using a
transformer-based grounded knowledge-enhanced module for fine-grained alignment
between textural features of medical knowledge and the corresponding anatomical
region-level visual features. The performance of GK-MVLP was competitive with
or exceeded the state of the art on downstream image understanding tasks (chest
X-ray disease classification, disease localization), generative task (report
generation), and vision-language understanding task (medical visual
question-answering). Our results demonstrate the advantage of incorporating
grounding mechanism to remove biases and improve the alignment between chest
X-ray image and radiology report.",2024-04-23,2024,2024-04,medical
"Gallbladder Cancer Detection in Ultrasound Images based on YOLO and
  Faster R-CNN","Medical image analysis is a significant application of artificial
intelligence for disease diagnosis. A crucial step in this process is the
identification of regions of interest within the images. This task can be
automated using object detection algorithms. YOLO and Faster R-CNN are renowned
for such algorithms, each with its own strengths and weaknesses. This study
aims to explore the advantages of both techniques to select more accurate
bounding boxes for gallbladder detection from ultrasound images, thereby
enhancing gallbladder cancer classification. A fusion method that leverages the
benefits of both techniques is presented in this study. The proposed method
demonstrated superior classification performance, with an accuracy of 92.62%,
compared to the individual use of Faster R-CNN and YOLOv8, which yielded
accuracies of 90.16% and 82.79%, respectively.",2024-04-23,2024,2024-04,medical
"Report on Candidate Computational Indicators for Conscious Valenced
  Experience","This report enlists 13 functional conditions cashed out in computational
terms that have been argued to be constituent of conscious valenced experience.
These are extracted from existing empirical and theoretical literature on,
among others, animal sentience, medical disorders, anaesthetics, philosophy,
evolution, neuroscience, and artificial intelligence.",2024-04-25,2024,2024-04,medical
"Hippocrates: An Open-Source Framework for Advancing Large Language
  Models in Healthcare","The integration of Large Language Models (LLMs) into healthcare promises to
transform medical diagnostics, research, and patient care. Yet, the progression
of medical LLMs faces obstacles such as complex training requirements, rigorous
evaluation demands, and the dominance of proprietary models that restrict
academic exploration. Transparent, comprehensive access to LLM resources is
essential for advancing the field, fostering reproducibility, and encouraging
innovation in healthcare AI. We present Hippocrates, an open-source LLM
framework specifically developed for the medical domain. In stark contrast to
previous efforts, it offers unrestricted access to its training datasets,
codebase, checkpoints, and evaluation protocols. This open approach is designed
to stimulate collaborative research, allowing the community to build upon,
refine, and rigorously evaluate medical LLMs within a transparent ecosystem.
Also, we introduce Hippo, a family of 7B models tailored for the medical
domain, fine-tuned from Mistral and LLaMA2 through continual pre-training,
instruction tuning, and reinforcement learning from human and AI feedback. Our
models outperform existing open medical LLMs models by a large-margin, even
surpassing models with 70B parameters. Through Hippocrates, we aspire to unlock
the full potential of LLMs not just to advance medical knowledge and patient
care but also to democratize the benefits of AI research in healthcare, making
them available across the globe.",2024-04-25,2024,2024-04,medical
"Processing HSV Colored Medical Images and Adapting Color Thresholds for
  Computational Image Analysis: a Practical Introduction to an open-source tool","Background: Using artificial intelligence (AI) techniques for computational
medical image analysis has shown promising results. However, colored images are
often not readily available for AI analysis because of different coloring
thresholds used across centers and physicians as well as the removal of
clinical annotations. We aimed to develop an open-source tool that can adapt
different color thresholds of HSV-colored medical images and remove annotations
with a simple click.
  Materials and Methods: We built a function using MATLAB and used multi-center
international shear wave elastography data (NCT 02638935) to test the function.
We provide step-by-step instructions with accompanying code lines.
  Results: We demonstrate that the newly developed pre-processing function
successfully removed letters and adapted different color thresholds of
HSV-colored medical images.
  Conclusion: We developed an open-source tool for removing letters and
adapting different color thresholds in HSV-colored medical images. We hope this
contributes to advancing medical image processing for developing robust
computational imaging algorithms using diverse multi-center big data. The
open-source Matlab tool is available at
https://github.com/cailiemed/image-threshold-adapting.",2024-04-27,2024,2024-04,medical
"Advancing Healthcare Automation: Multi-Agent System for Medical
  Necessity Justification","Prior Authorization delivers safe, appropriate, and cost-effective care that
is medically justified with evidence-based guidelines. However, the process
often requires labor-intensive manual comparisons between patient medical
records and clinical guidelines, that is both repetitive and time-consuming.
Recent developments in Large Language Models (LLMs) have shown potential in
addressing complex medical NLP tasks with minimal supervision. This paper
explores the application of Multi-Agent System (MAS) that utilize specialized
LLM agents to automate Prior Authorization task by breaking them down into
simpler and manageable sub-tasks. Our study systematically investigates the
effects of various prompting strategies on these agents and benchmarks the
performance of different LLMs. We demonstrate that GPT-4 achieves an accuracy
of 86.2% in predicting checklist item-level judgments with evidence, and 95.6%
in determining overall checklist judgment. Additionally, we explore how these
agents can contribute to explainability of steps taken in the process, thereby
enhancing trust and transparency in the system.",2024-04-27,2024,2024-04,medical
"MediFact at MEDIQA-M3G 2024: Medical Question Answering in Dermatology
  with Multimodal Learning","The MEDIQA-M3G 2024 challenge necessitates novel solutions for Multilingual &
Multimodal Medical Answer Generation in dermatology (wai Yim et al., 2024a).
This paper addresses the limitations of traditional methods by proposing a
weakly supervised learning approach for open-ended medical question-answering
(QA). Our system leverages readily available MEDIQA-M3G images via a
VGG16-CNN-SVM model, enabling multilingual (English, Chinese, Spanish) learning
of informative skin condition representations. Using pre-trained QA models, we
further bridge the gap between visual and textual information through
multimodal fusion. This approach tackles complex, open-ended questions even
without predefined answer choices. We empower the generation of comprehensive
answers by feeding the ViT-CLIP model with multiple responses alongside images.
This work advances medical QA research, paving the way for clinical decision
support systems and ultimately improving healthcare delivery.",2024-04-27,2024,2024-04,medical
"ConPro: Learning Severity Representation for Medical Images using
  Contrastive Learning and Preference Optimization","Understanding the severity of conditions shown in images in medical diagnosis
is crucial, serving as a key guide for clinical assessment, treatment, as well
as evaluating longitudinal progression. This paper proposes Con- PrO: a novel
representation learning method for severity assessment in medical images using
Contrastive learningintegrated Preference Optimization. Different from
conventional contrastive learning methods that maximize the distance between
classes, ConPrO injects into the latent vector the distance preference
knowledge between various severity classes and the normal class. We
systematically examine the key components of our framework to illuminate how
contrastive prediction tasks acquire valuable representations. We show that our
representation learning framework offers valuable severity ordering in the
feature space while outperforming previous state-of-the-art methods on
classification tasks. We achieve a 6% and 20% relative improvement compared to
a supervised and a self-supervised baseline, respectively. In addition, we
derived discussions on severity indicators and related applications of
preference comparison in the medical domain.",2024-04-29,2024,2024-04,medical
"Artificial Intelligence in Bone Metastasis Analysis: Current
  Advancements, Opportunities and Challenges","In recent years, Artificial Intelligence (AI) has been widely used in
medicine, particularly in the analysis of medical imaging, which has been
driven by advances in computer vision and deep learning methods. This is
particularly important in overcoming the challenges posed by diseases such as
Bone Metastases (BM), a common and complex malignancy of the bones. Indeed,
there have been an increasing interest in developing Machine Learning (ML)
techniques into oncologic imaging for BM analysis. In order to provide a
comprehensive overview of the current state-of-the-art and advancements for BM
analysis using artificial intelligence, this review is conducted with the
accordance with PRISMA guidelines. Firstly, this review highlights the clinical
and oncologic perspectives of BM and the used medical imaging modalities, with
discussing their advantages and limitations. Then the review focuses on modern
approaches with considering the main BM analysis tasks, which includes:
classification, detection and segmentation. The results analysis show that ML
technologies can achieve promising performance for BM analysis and have
significant potential to improve clinician efficiency and cope with time and
cost limitations. Furthermore, there are requirements for further research to
validate the clinical performance of ML tools and facilitate their integration
into routine clinical practice.",2024-04-30,2024,2024-04,medical
Agent Hospital: A Simulacrum of Hospital with Evolvable Medical Agents,"The recent rapid development of large language models (LLMs) has sparked a
new wave of technological revolution in medical artificial intelligence (AI).
While LLMs are designed to understand and generate text like a human,
autonomous agents that utilize LLMs as their ""brain"" have exhibited
capabilities beyond text processing such as planning, reflection, and using
tools by enabling their ""bodies"" to interact with the environment. We introduce
a simulacrum of hospital called Agent Hospital that simulates the entire
process of treating illness, in which all patients, nurses, and doctors are
LLM-powered autonomous agents. Within the simulacrum, doctor agents are able to
evolve by treating a large number of patient agents without the need to label
training data manually. After treating tens of thousands of patient agents in
the simulacrum (human doctors may take several years in the real world), the
evolved doctor agents outperform state-of-the-art medical agent methods on the
MedQA benchmark comprising US Medical Licensing Examination (USMLE) test
questions. Our methods of simulacrum construction and agent evolution have the
potential in benefiting a broad range of applications beyond medical AI.",2024-05-05,2024,2024-05,medical
"Automated Computation of Therapies Using Failure Mode and Effects
  Analysis in the Medical Domain","Failure mode and effects analysis (FMEA) is a systematic approach to identify
and analyse potential failures and their effects in a system or process. The
FMEA approach, however, requires domain experts to manually analyse the FMEA
model to derive risk-reducing actions that should be applied. In this paper, we
provide a formal framework to allow for automatic planning and acting in FMEA
models. More specifically, we cast the FMEA model into a Markov decision
process which can then be solved by existing solvers. We show that the FMEA
approach can not only be used to support medical experts during the modelling
process but also to automatically derive optimal therapies for the treatment of
patients.",2024-05-06,2024,2024-05,medical
"MEDVOC: Vocabulary Adaptation for Fine-tuning Pre-trained Language
  Models on Medical Text Summarization","This work presents a dynamic vocabulary adaptation strategy, MEDVOC, for
fine-tuning pre-trained language models (PLMs) like BertSumAbs, BART, and
PEGASUS for improved medical text summarization. In contrast to existing domain
adaptation approaches in summarization, MEDVOC treats vocabulary as an
optimizable parameter and optimizes the PLM vocabulary based on fragment score
conditioned only on the downstream task's reference summaries. Unlike previous
works on vocabulary adaptation (limited only to classification tasks),
optimizing vocabulary based on summarization tasks requires an extremely costly
intermediate fine-tuning step on large summarization datasets. To that end, our
novel fragment score-based hyperparameter search very significantly reduces
this fine-tuning time -- from 450 days to less than 2 days on average.
Furthermore, while previous works on vocabulary adaptation are often primarily
tied to single PLMs, MEDVOC is designed to be deployable across multiple PLMs
(with varying model vocabulary sizes, pre-training objectives, and model sizes)
-- bridging the limited vocabulary overlap between the biomedical literature
domain and PLMs. MEDVOC outperforms baselines by 15.74% in terms of Rouge-L in
zero-shot setting and shows gains of 17.29% in high Out-Of-Vocabulary (OOV)
concentrations. Our human evaluation shows MEDVOC generates more faithful
medical summaries (88% compared to 59% in baselines). We make the codebase
publicly available at https://github.com/gb-kgp/MEDVOC.",2024-05-07,2024,2024-05,medical
Summarizing Radiology Reports Findings into Impressions,"Patient hand-off and triage are two fundamental problems in health care.
Often doctors must painstakingly summarize complex findings to efficiently
communicate with specialists and quickly make decisions on which patients have
the most urgent cases. In pursuit of these challenges, we present (1) a model
with state-of-art radiology report summarization performance using (2) a novel
method for augmenting medical data, and (3) an analysis of the model
limitations and radiology knowledge gain. We also provide a data processing
pipeline for future models developed on the the MIMIC CXR dataset. Our best
performing model was a fine-tuned BERT-to-BERT encoder-decoder with 58.75/100
ROUGE-L F1, which outperformed specialized checkpoints with more sophisticated
attention mechanisms. We investigate these aspects in this work.",2024-05-10,2024,2024-05,medical
A Generalist Learner for Multifaceted Medical Image Interpretation,"Current medical artificial intelligence systems are often limited to narrow
applications, hindering their widespread adoption in clinical practice. To
address this limitation, we propose MedVersa, a generalist learner that enables
flexible learning and tasking for medical image interpretation. By leveraging a
large language model as a learnable orchestrator, MedVersa can learn from both
visual and linguistic supervision, support multimodal inputs, and perform
real-time task specification. This versatility allows MedVersa to adapt to
various clinical scenarios and perform multifaceted medical image analysis. We
introduce MedInterp, the largest multimodal dataset to date for medical image
interpretation, consisting of over 13 million annotated instances spanning 11
tasks across 3 modalities, to support the development of MedVersa. Our
experiments demonstrate that MedVersa achieves state-of-the-art performance in
9 tasks, sometimes outperforming specialist counterparts by over 10%. MedVersa
is the first to showcase the viability of multimodal generative medical AI in
implementing multimodal outputs, inputs, and dynamic task specification,
highlighting its potential as a multifunctional system for comprehensive
medical image analysis. This generalist approach to medical image
interpretation paves the way for more adaptable and efficient AI-assisted
clinical decision-making.",2024-05-13,2024,2024-05,medical
"Evaluating the Explainable AI Method Grad-CAM for Breath Classification
  on Newborn Time Series Data","With the digitalization of health care systems, artificial intelligence
becomes more present in medicine. Especially machine learning shows great
potential for complex tasks such as time series classification, usually at the
cost of transparency and comprehensibility. This leads to a lack of trust by
humans and thus hinders its active usage. Explainable artificial intelligence
tries to close this gap by providing insight into the decision-making process,
the actual usefulness of its different methods is however unclear. This paper
proposes a user study based evaluation of the explanation method Grad-CAM with
application to a neural network for the classification of breaths in time
series neonatal ventilation data. We present the perceived usefulness of the
explainability method by different stakeholders, exposing the difficulty to
achieve actual transparency and the wish for more in-depth explanations by many
of the participants.",2024-05-13,2024,2024-05,medical
Evaluating large language models in medical applications: a survey,"Large language models (LLMs) have emerged as powerful tools with
transformative potential across numerous domains, including healthcare and
medicine. In the medical domain, LLMs hold promise for tasks ranging from
clinical decision support to patient education. However, evaluating the
performance of LLMs in medical contexts presents unique challenges due to the
complex and critical nature of medical information. This paper provides a
comprehensive overview of the landscape of medical LLM evaluation, synthesizing
insights from existing studies and highlighting evaluation data sources, task
scenarios, and evaluation methods. Additionally, it identifies key challenges
and opportunities in medical LLM evaluation, emphasizing the need for continued
research and innovation to ensure the responsible integration of LLMs into
clinical practice.",2024-05-13,2024,2024-05,medical
"MoVL:Exploring Fusion Strategies for the Domain-Adaptive Application of
  Pretrained Models in Medical Imaging Tasks","Medical images are often more difficult to acquire than natural images due to
the specialism of the equipment and technology, which leads to less medical
image datasets. So it is hard to train a strong pretrained medical vision
model. How to make the best of natural pretrained vision model and adapt in
medical domain still pends. For image classification, a popular method is
linear probe (LP). However, LP only considers the output after feature
extraction. Yet, there exists a gap between input medical images and natural
pretrained vision model. We introduce visual prompting (VP) to fill in the gap,
and analyze the strategies of coupling between LP and VP. We design a joint
learning loss function containing categorisation loss and discrepancy loss,
which describe the variance of prompted and plain images, naming this joint
training strategy MoVL (Mixture of Visual Prompting and Linear Probe). We
experiment on 4 medical image classification datasets, with two mainstream
architectures, ResNet and CLIP. Results shows that without changing the
parameters and architecture of backbone model and with less parameters, there
is potential for MoVL to achieve full finetune (FF) accuracy (on four medical
datasets, average 90.91% for MoVL and 91.13% for FF). On out of distribution
medical dataset, our method(90.33%) can outperform FF (85.15%) with absolute
5.18 % lead.",2024-05-13,2024,2024-05,medical
CTS: A Consistency-Based Medical Image Segmentation Model,"In medical image segmentation tasks, diffusion models have shown significant
potential. However, mainstream diffusion models suffer from drawbacks such as
multiple sampling times and slow prediction results. Recently, consistency
models, as a standalone generative network, have resolved this issue. Compared
to diffusion models, consistency models can reduce the sampling times to once,
not only achieving similar generative effects but also significantly speeding
up training and prediction. However, they are not suitable for image
segmentation tasks, and their application in the medical imaging field has not
yet been explored. Therefore, this paper applies the consistency model to
medical image segmentation tasks, designing multi-scale feature signal
supervision modes and loss function guidance to achieve model convergence.
Experiments have verified that the CTS model can obtain better medical image
segmentation results with a single sampling during the test phase.",2024-05-15,2024,2024-05,medical
"Content-Based Image Retrieval for Multi-Class Volumetric Radiology
  Images: A Benchmark Study","While content-based image retrieval (CBIR) has been extensively studied in
natural image retrieval, its application to medical images presents ongoing
challenges, primarily due to the 3D nature of medical images. Recent studies
have shown the potential use of pre-trained vision embeddings for CBIR in the
context of radiology image retrieval. However, a benchmark for the retrieval of
3D volumetric medical images is still lacking, hindering the ability to
objectively evaluate and compare the efficiency of proposed CBIR approaches in
medical imaging. In this study, we extend previous work and establish a
benchmark for region-based and localized multi-organ retrieval using the
TotalSegmentator dataset (TS) with detailed multi-organ annotations. We
benchmark embeddings derived from pre-trained supervised models on medical
images against embeddings derived from pre-trained unsupervised models on
non-medical images for 29 coarse and 104 detailed anatomical structures in
volume and region levels. For volumetric image retrieval, we adopt a late
interaction re-ranking method inspired by text matching. We compare it against
the original method proposed for volume and region retrieval and achieve a
retrieval recall of 1.0 for diverse anatomical regions with a wide size range.
The findings and methodologies presented in this paper provide insights and
benchmarks for further development and evaluation of CBIR approaches in the
context of medical imaging.",2024-05-15,2024,2024-05,medical
"COGNET-MD, an evaluation framework and dataset for Large Language Model
  benchmarks in the medical domain","Large Language Models (LLMs) constitute a breakthrough state-of-the-art
Artificial Intelligence (AI) technology which is rapidly evolving and promises
to aid in medical diagnosis either by assisting doctors or by simulating a
doctor's workflow in more advanced and complex implementations. In this
technical paper, we outline Cognitive Network Evaluation Toolkit for Medical
Domains (COGNET-MD), which constitutes a novel benchmark for LLM evaluation in
the medical domain. Specifically, we propose a scoring-framework with increased
difficulty to assess the ability of LLMs in interpreting medical text. The
proposed framework is accompanied with a database of Multiple Choice Quizzes
(MCQs). To ensure alignment with current medical trends and enhance safety,
usefulness, and applicability, these MCQs have been constructed in
collaboration with several associated medical experts in various medical
domains and are characterized by varying degrees of difficulty. The current
(first) version of the database includes the medical domains of Psychiatry,
Dentistry, Pulmonology, Dermatology and Endocrinology, but it will be
continuously extended and expanded to include additional medical domains.",2024-05-17,2024,2024-05,medical
"Medical Dialogue: A Survey of Categories, Methods, Evaluation and
  Challenges","This paper surveys and organizes research works on medical dialog systems,
which is an important yet challenging task. Although these systems have been
surveyed in the medical community from an application perspective, a systematic
review from a rigorous technical perspective has to date remained noticeably
absent. As a result, an overview of the categories, methods, and evaluation of
medical dialogue systems remain limited and underspecified, hindering the
further improvement of this area. To fill this gap, we investigate an initial
pool of 325 papers from well-known computer science, and natural language
processing conferences and journals, and make an overview. Recently, large
language models have shown strong model capacity on downstream tasks, which
also reshaped medical dialog systems' foundation. Despite the alluring
practical application value, current medical dialogue systems still suffer from
problems. To this end, this paper lists the grand challenges of medical dialog
systems, especially of large language models.",2024-05-17,2024,2024-05,medical
"Application of Artificial Intelligence in Schizophrenia Rehabilitation
  Management: A Systematic Scoping Review","This systematic review assessed the current state and future prospects of
artificial intelligence (AI) in schizophrenia rehabilitation management. We
reviewed 61 studies on AI-related data types, feature engineering methods,
algorithmic models, and evaluation metrics published from 2012-2024. The review
categorizes AI applications into the following key application areas: symptom
monitoring, medication management, risk management, functional training, and
psychosocial support. Findings indicate that supervised machine learning
techniques, particularly for symptom monitoring and relapse risk management,
remain the predominant approaches, effectively leveraging structured data while
incorporating interpretable algorithms. This study underscores the potential of
AI in transforming long-term management strategies for schizophrenia, offering
valuable insights into improving the quality of life of patients. Future
research should focus on expanding data sources through multimodal data
integration, exploring deep learning models, and integrating AI-driven
interventions into training tasks to fully capitalize on AI's potential in
schizophrenia rehabilitation.",2024-05-17,2024,2024-05,medical
"Overcoming Medical Overuse with AI Assistance: An Experimental
  Investigation","This study evaluates the effectiveness of Artificial Intelligence (AI) in
mitigating medical overtreatment, a significant issue characterized by
unnecessary interventions that inflate healthcare costs and pose risks to
patients. We conducted a lab-in-the-field experiment at a medical school,
utilizing a novel medical prescription task, manipulating monetary incentives
and the availability of AI assistance among medical students using a
three-by-two factorial design. We tested three incentive schemes: Flat
(constant pay regardless of treatment quantity), Progressive (pay increases
with the number of treatments), and Regressive (penalties for overtreatment) to
assess their influence on the adoption and effectiveness of AI assistance. Our
findings demonstrate that AI significantly reduced overtreatment rates by up to
62% in the Regressive incentive conditions where (prospective) physician and
patient interests were most aligned. Diagnostic accuracy improved by 17% to
37%, depending on the incentive scheme. Adoption of AI advice was high, with
approximately half of the participants modifying their decisions based on AI
input across all settings. For policy implications, we quantified the monetary
(57%) and non-monetary (43%) incentives of overtreatment and highlighted AI's
potential to mitigate non-monetary incentives and enhance social welfare. Our
results provide valuable insights for healthcare administrators considering AI
integration into healthcare systems.",2024-05-17,2024,2024-05,medical
Generative Artificial Intelligence: A Systematic Review and Applications,"In recent years, the study of artificial intelligence (AI) has undergone a
paradigm shift. This has been propelled by the groundbreaking capabilities of
generative models both in supervised and unsupervised learning scenarios.
Generative AI has shown state-of-the-art performance in solving perplexing
real-world conundrums in fields such as image translation, medical diagnostics,
textual imagery fusion, natural language processing, and beyond. This paper
documents the systematic review and analysis of recent advancements and
techniques in Generative AI with a detailed discussion of their applications
including application-specific models. Indeed, the major impact that generative
AI has made to date, has been in language generation with the development of
large language models, in the field of image translation and several other
interdisciplinary applications of generative AI. Moreover, the primary
contribution of this paper lies in its coherent synthesis of the latest
advancements in these areas, seamlessly weaving together contemporary
breakthroughs in the field. Particularly, how it shares an exploration of the
future trajectory for generative AI. In conclusion, the paper ends with a
discussion of Responsible AI principles, and the necessary ethical
considerations for the sustainability and growth of these generative models.",2024-05-17,2024,2024-05,medical
"Inquire, Interact, and Integrate: A Proactive Agent Collaborative
  Framework for Zero-Shot Multimodal Medical Reasoning","The adoption of large language models (LLMs) in healthcare has attracted
significant research interest. However, their performance in healthcare remains
under-investigated and potentially limited, due to i) they lack rich
domain-specific knowledge and medical reasoning skills; and ii) most
state-of-the-art LLMs are unimodal, text-only models that cannot directly
process multimodal inputs. To this end, we propose a multimodal medical
collaborative reasoning framework \textbf{MultiMedRes}, which incorporates a
learner agent to proactively gain essential information from domain-specific
expert models, to solve medical multimodal reasoning problems. Our method
includes three steps: i) \textbf{Inquire}: The learner agent first decomposes
given complex medical reasoning problems into multiple domain-specific
sub-problems; ii) \textbf{Interact}: The agent then interacts with
domain-specific expert models by repeating the ``ask-answer'' process to
progressively obtain different domain-specific knowledge; iii)
\textbf{Integrate}: The agent finally integrates all the acquired
domain-specific knowledge to accurately address the medical reasoning problem.
We validate the effectiveness of our method on the task of difference visual
question answering for X-ray images. The experiments demonstrate that our
zero-shot prediction achieves state-of-the-art performance, and even
outperforms the fully supervised methods. Besides, our approach can be
incorporated into various LLMs and multimodal LLMs to significantly boost their
performance.",2024-05-19,2024,2024-05,medical
Large Language Models for Medicine: A Survey,"To address challenges in the digital economy's landscape of digital
intelligence, large language models (LLMs) have been developed. Improvements in
computational power and available resources have significantly advanced LLMs,
allowing their integration into diverse domains for human life. Medical LLMs
are essential application tools with potential across various medical
scenarios. In this paper, we review LLM developments, focusing on the
requirements and applications of medical LLMs. We provide a concise overview of
existing models, aiming to explore advanced research directions and benefit
researchers for future medical applications. We emphasize the advantages of
medical LLMs in applications, as well as the challenges encountered during
their development. Finally, we suggest directions for technical integration to
mitigate challenges and potential research directions for the future of medical
LLMs, aiming to meet the demands of the medical field better.",2024-05-20,2024,2024-05,medical
"A Survey of Artificial Intelligence in Gait-Based Neurodegenerative
  Disease Diagnosis","Recent years have witnessed an increasing global population affected by
neurodegenerative diseases (NDs), which traditionally require extensive
healthcare resources and human effort for medical diagnosis and monitoring. As
a crucial disease-related motor symptom, human gait can be exploited to
characterize different NDs. The current advances in artificial intelligence
(AI) models enable automatic gait analysis for NDs identification and
classification, opening a new avenue to facilitate faster and more
cost-effective diagnosis of NDs. In this paper, we provide a comprehensive
survey on recent progress of machine learning and deep learning based AI
techniques applied to diagnosis of five typical NDs through gait. We provide an
overview of the process of AI-assisted NDs diagnosis, and present a systematic
taxonomy of existing gait data and AI models. Meanwhile, a novel quality
evaluation criterion is proposed to quantitatively assess the quality of
existing studies. Through an extensive review and analysis of 169 studies, we
present recent technical advancements, discuss existing challenges, potential
solutions, and future directions in this field. Finally, we envision the
prospective utilization of 3D skeleton data for human gait representation and
the development of more efficient AI models for NDs diagnosis.",2024-05-21,2024,2024-05,medical
"Reducing Biases towards Minoritized Populations in Medical Curricular
  Content via Artificial Intelligence for Fairer Health Outcomes","Biased information (recently termed bisinformation) continues to be taught in
medical curricula, often long after having been debunked. In this paper, we
introduce BRICC, a firstin-class initiative that seeks to mitigate medical
bisinformation using machine learning to systematically identify and flag text
with potential biases, for subsequent review in an expert-in-the-loop fashion,
thus greatly accelerating an otherwise labor-intensive process. A gold-standard
BRICC dataset was developed throughout several years, and contains over 12K
pages of instructional materials. Medical experts meticulously annotated these
documents for bias according to comprehensive coding guidelines, emphasizing
gender, sex, age, geography, ethnicity, and race. Using this labeled dataset,
we trained, validated, and tested medical bias classifiers. We test three
classifier approaches: a binary type-specific classifier, a general bias
classifier; an ensemble combining bias type-specific classifiers
independently-trained; and a multitask learning (MTL) model tasked with
predicting both general and type-specific biases. While MTL led to some
improvement on race bias detection in terms of F1-score, it did not outperform
binary classifiers trained specifically on each task. On general bias
detection, the binary classifier achieves up to 0.923 of AUC, a 27.8%
improvement over the baseline. This work lays the foundations for debiasing
medical curricula by exploring a novel dataset and evaluating different
training model strategies. Hence, it offers new pathways for more nuanced and
effective mitigation of bisinformation.",2024-05-21,2024,2024-05,medical
"Efficient Medical Question Answering with Knowledge-Augmented Question
  Generation","In the expanding field of language model applications, medical knowledge
representation remains a significant challenge due to the specialized nature of
the domain. Large language models, such as GPT-4, obtain reasonable scores on
medical question answering tasks, but smaller models are far behind. In this
work, we introduce a method to improve the proficiency of a small language
model in the medical domain by employing a two-fold approach. We first
fine-tune the model on a corpus of medical textbooks. Then, we use GPT-4 to
generate questions similar to the downstream task, prompted with textbook
knowledge, and use them to fine-tune the model. Additionally, we introduce
ECN-QA, a novel medical question answering dataset containing ``progressive
questions'' composed of related sequential questions. We show the benefits of
our training strategy on this dataset. The study's findings highlight the
potential of small language models in the medical domain when appropriately
fine-tuned. The code and weights are available at
https://github.com/raidium-med/MQG.",2024-05-23,2024,2024-05,medical
"Investigation of Customized Medical Decision Algorithms Utilizing Graph
  Neural Networks","Aiming at the limitations of traditional medical decision system in
processing large-scale heterogeneous medical data and realizing highly
personalized recommendation, this paper introduces a personalized medical
decision algorithm utilizing graph neural network (GNN). This research
innovatively integrates graph neural network technology into the medical and
health field, aiming to build a high-precision representation model of patient
health status by mining the complex association between patients' clinical
characteristics, genetic information, living habits. In this study, medical
data is preprocessed to transform it into a graph structure, where nodes
represent different data entities (such as patients, diseases, genes, etc.) and
edges represent interactions or relationships between entities. The core of the
algorithm is to design a novel multi-scale fusion mechanism, combining the
historical medical records, physiological indicators and genetic
characteristics of patients, to dynamically adjust the attention allocation
strategy of the graph neural network, so as to achieve highly customized
analysis of individual cases. In the experimental part, this study selected
several publicly available medical data sets for validation, and the results
showed that compared with traditional machine learning methods and a single
graph neural network model, the proposed personalized medical decision
algorithm showed significantly superior performance in terms of disease
prediction accuracy, treatment effect evaluation and patient risk
stratification.",2024-05-23,2024,2024-05,medical
"Integrating Medical Imaging and Clinical Reports Using Multimodal Deep
  Learning for Advanced Disease Analysis","In this paper, an innovative multi-modal deep learning model is proposed to
deeply integrate heterogeneous information from medical images and clinical
reports. First, for medical images, convolutional neural networks were used to
extract high-dimensional features and capture key visual information such as
focal details, texture and spatial distribution. Secondly, for clinical report
text, a two-way long and short-term memory network combined with an attention
mechanism is used for deep semantic understanding, and key statements related
to the disease are accurately captured. The two features interact and integrate
effectively through the designed multi-modal fusion layer to realize the joint
representation learning of image and text. In the empirical study, we selected
a large medical image database covering a variety of diseases, combined with
corresponding clinical reports for model training and validation. The proposed
multimodal deep learning model demonstrated substantial superiority in the
realms of disease classification, lesion localization, and clinical description
generation, as evidenced by the experimental results.",2024-05-23,2024,2024-05,medical
"PriCE: Privacy-Preserving and Cost-Effective Scheduling for
  Parallelizing the Large Medical Image Processing Workflow over Hybrid Clouds","Running deep neural networks for large medical images is a resource-hungry
and time-consuming task with centralized computing. Outsourcing such medical
image processing tasks to hybrid clouds has benefits, such as a significant
reduction of execution time and monetary cost. However, due to privacy
concerns, it is still challenging to process sensitive medical images over
clouds, which would hinder their deployment in many real-world applications. To
overcome this, we first formulate the overall optimization objectives of the
privacy-preserving distributed system model, i.e., minimizing the amount of
information about the private data learned by the adversaries throughout the
process, reducing the maximum execution time and cost under the user budget
constraint. We propose a novel privacy-preserving and cost-effective method
called PriCE to solve this multi-objective optimization problem. We performed
extensive simulation experiments for artifact detection tasks on medical images
using an ensemble of five deep convolutional neural network inferences as the
workflow task. Experimental results show that PriCE successfully splits a wide
range of input gigapixel medical images with graph-coloring-based strategies,
yielding desired output utility and lowering the privacy risk, makespan, and
monetary cost under user's budget.",2024-05-24,2024,2024-05,medical
Transductive Confidence Machine and its application to Medical Data Sets,"The Transductive Confidence Machine Nearest Neighbours (TCMNN) algorithm and
a supporting, simple user interface was developed. Different settings of the
TCMNN algorithms' parameters were tested on medical data sets, in addition to
the use of different Minkowski metrics and polynomial kernels. The effect of
increasing the number of nearest neighbours and marking results with
significance was also investigated. SVM implementation of the Transductive
Confidence Machine was compared with Nearest Neighbours implementation. The
application of neural networks was investigated as a useful comparison to the
transductive algorithms.",2024-05-25,2024,2024-05,medical
"Medical MLLM is Vulnerable: Cross-Modality Jailbreak and Mismatched
  Attacks on Medical Multimodal Large Language Models","Security concerns related to Large Language Models (LLMs) have been
extensively explored, yet the safety implications for Multimodal Large Language
Models (MLLMs), particularly in medical contexts (MedMLLMs), remain
insufficiently studied. This paper delves into the underexplored security
vulnerabilities of MedMLLMs, especially when deployed in clinical environments
where the accuracy and relevance of question-and-answer interactions are
critically tested against complex medical challenges. By combining existing
clinical medical data with atypical natural phenomena, we define the mismatched
malicious attack (2M-attack) and introduce its optimized version, known as the
optimized mismatched malicious attack (O2M-attack or 2M-optimization). Using
the voluminous 3MAD dataset that we construct, which covers a wide range of
medical image modalities and harmful medical scenarios, we conduct a
comprehensive analysis and propose the MCM optimization method, which
significantly enhances the attack success rate on MedMLLMs. Evaluations with
this dataset and attack methods, including white-box attacks on LLaVA-Med and
transfer attacks (black-box) on four other SOTA models, indicate that even
MedMLLMs designed with enhanced security features remain vulnerable to security
breaches. Our work underscores the urgent need for a concerted effort to
implement robust security measures and enhance the safety and efficacy of
open-source MedMLLMs, particularly given the potential severity of jailbreak
attacks and other malicious or clinically significant exploits in medical
settings. Our code is available at https://github.com/dirtycomputer/O2M_attack.",2024-05-26,2024,2024-05,medical
"""It depends"": Configuring AI to Improve Clinical Usefulness Across
  Contexts","Artificial Intelligence (AI) repeatedly match or outperform radiologists in
lab experiments. However, real-world implementations of radiological AI-based
systems are found to provide little to no clinical value. This paper explores
how to design AI for clinical usefulness in different contexts. We conducted 19
design sessions and design interventions with 13 radiologists from 7 clinical
sites in Denmark and Kenya, based on three iterations of a functional AI-based
prototype. Ten sociotechnical dependencies were identified as crucial for the
design of AI in radiology. We conceptualised four technical dimensions that
must be configured to the intended clinical context of use: AI functionality,
AI medical focus, AI decision threshold, and AI Explainability. We present four
design recommendations on how to address dependencies pertaining to the medical
knowledge, clinic type, user expertise level, patient context, and user
situation that condition the configuration of these technical dimensions.",2024-05-27,2024,2024-05,medical
"SkinCAP: A Multi-modal Dermatology Dataset Annotated with Rich Medical
  Captions","With the widespread application of artificial intelligence (AI), particularly
deep learning (DL) and vision-based large language models (VLLMs), in skin
disease diagnosis, the need for interpretability becomes crucial. However,
existing dermatology datasets are limited in their inclusion of concept-level
meta-labels, and none offer rich medical descriptions in natural language. This
deficiency impedes the advancement of LLM-based methods in dermatological
diagnosis. To address this gap and provide a meticulously annotated dermatology
dataset with comprehensive natural language descriptions, we introduce SkinCAP:
a multi-modal dermatology dataset annotated with rich medical captions. SkinCAP
comprises 4,000 images sourced from the Fitzpatrick 17k skin disease dataset
and the Diverse Dermatology Images dataset, annotated by board-certified
dermatologists to provide extensive medical descriptions and captions. Notably,
SkinCAP represents the world's first such dataset and is publicly available at
https://huggingface.co/datasets/joshuachou/SkinCAP.",2024-05-28,2024,2024-05,medical
"Worse than Random? An Embarrassingly Simple Probing Evaluation of Large
  Multimodal Models in Medical VQA","Large Multimodal Models (LMMs) have shown remarkable progress in medical
Visual Question Answering (Med-VQA), achieving high accuracy on existing
benchmarks. However, their reliability under robust evaluation is questionable.
This study reveals that when subjected to simple probing evaluation,
state-of-the-art models perform worse than random guessing on medical diagnosis
questions. To address this critical evaluation problem, we introduce the
Probing Evaluation for Medical Diagnosis (ProbMed) dataset to rigorously assess
LMM performance in medical imaging through probing evaluation and procedural
diagnosis. Particularly, probing evaluation features pairing original questions
with negation questions with hallucinated attributes, while procedural
diagnosis requires reasoning across various diagnostic dimensions for each
image, including modality recognition, organ identification, clinical findings,
abnormalities, and positional grounding. Our evaluation reveals that
top-performing models like GPT-4o, GPT-4V, and Gemini Pro perform worse than
random guessing on specialized diagnostic questions, indicating significant
limitations in handling fine-grained medical inquiries. Besides, models like
LLaVA-Med struggle even with more general questions, and results from CheXagent
demonstrate the transferability of expertise across different modalities of the
same organ, showing that specialized domain knowledge is still crucial for
improving performance. This study underscores the urgent need for more robust
evaluation to ensure the reliability of LMMs in critical fields like medical
diagnosis, and current LMMs are still far from applicable to those fields.",2024-05-30,2024,2024-05,medical
The Explanation Necessity for Healthcare AI,"Explainability is a critical factor in enhancing the trustworthiness and
acceptance of artificial intelligence (AI) in healthcare, where decisions
directly impact patient outcomes. Despite advancements in AI interpretability,
clear guidelines on when and to what extent explanations are required in
medical applications remain lacking. We propose a novel categorization system
comprising four classes of explanation necessity (self-explainable,
semi-explainable, non-explainable, and new-patterns discovery), guiding the
required level of explanation; whether local (patient or sample level), global
(cohort or dataset level), or both. To support this system, we introduce a
mathematical formulation that incorporates three key factors: (i) robustness of
the evaluation protocol, (ii) variability of expert observations, and (iii)
representation dimensionality of the application. This framework provides a
practical tool for researchers to determine the appropriate depth of
explainability needed, addressing the critical question: When does an AI
medical application need to be explained, and at what level of detail?",2024-05-31,2024,2024-05,medical
"GAMedX: Generative AI-based Medical Entity Data Extractor Using Large
  Language Models","In the rapidly evolving field of healthcare and beyond, the integration of
generative AI in Electronic Health Records (EHRs) represents a pivotal
advancement, addressing a critical gap in current information extraction
techniques. This paper introduces GAMedX, a Named Entity Recognition (NER)
approach utilizing Large Language Models (LLMs) to efficiently extract entities
from medical narratives and unstructured text generated throughout various
phases of the patient hospital visit. By addressing the significant challenge
of processing unstructured medical text, GAMedX leverages the capabilities of
generative AI and LLMs for improved data extraction. Employing a unified
approach, the methodology integrates open-source LLMs for NER, utilizing
chained prompts and Pydantic schemas for structured output to navigate the
complexities of specialized medical jargon. The findings reveal significant
ROUGE F1 score on one of the evaluation datasets with an accuracy of 98\%. This
innovation enhances entity extraction, offering a scalable, cost-effective
solution for automated forms filling from unstructured data. As a result,
GAMedX streamlines the processing of unstructured narratives, and sets a new
standard in NER applications, contributing significantly to theoretical and
practical advancements beyond the medical technology sphere.",2024-05-31,2024,2024-05,medical
"Breast Cancer Diagnosis: A Comprehensive Exploration of Explainable
  Artificial Intelligence (XAI) Techniques","Breast cancer (BC) stands as one of the most common malignancies affecting
women worldwide, necessitating advancements in diagnostic methodologies for
better clinical outcomes. This article provides a comprehensive exploration of
the application of Explainable Artificial Intelligence (XAI) techniques in the
detection and diagnosis of breast cancer. As Artificial Intelligence (AI)
technologies continue to permeate the healthcare sector, particularly in
oncology, the need for transparent and interpretable models becomes imperative
to enhance clinical decision-making and patient care. This review discusses the
integration of various XAI approaches, such as SHAP, LIME, Grad-CAM, and
others, with machine learning and deep learning models utilized in breast
cancer detection and classification. By investigating the modalities of breast
cancer datasets, including mammograms, ultrasounds and their processing with
AI, the paper highlights how XAI can lead to more accurate diagnoses and
personalized treatment plans. It also examines the challenges in implementing
these techniques and the importance of developing standardized metrics for
evaluating XAI's effectiveness in clinical settings. Through detailed analysis
and discussion, this article aims to highlight the potential of XAI in bridging
the gap between complex AI models and practical healthcare applications,
thereby fostering trust and understanding among medical professionals and
improving patient outcomes.",2024-06-01,2024,2024-06,medical
Lightening Anything in Medical Images,"The development of medical imaging techniques has made a significant
contribution to clinical decision-making. However, the existence of suboptimal
imaging quality, as indicated by irregular illumination or imbalanced
intensity, presents significant obstacles in automating disease screening,
analysis, and diagnosis. Existing approaches for natural image enhancement are
mostly trained with numerous paired images, presenting challenges in data
collection and training costs, all while lacking the ability to generalize
effectively. Here, we introduce a pioneering training-free Diffusion Model for
Universal Medical Image Enhancement, named UniMIE. UniMIE demonstrates its
unsupervised enhancement capabilities across various medical image modalities
without the need for any fine-tuning. It accomplishes this by relying solely on
a single pre-trained model from ImageNet. We conduct a comprehensive evaluation
on 13 imaging modalities and over 15 medical types, demonstrating better
qualities, robustness, and accuracy than other modality-specific and
data-inefficient models. By delivering high-quality enhancement and
corresponding accuracy downstream tasks across a wide range of tasks, UniMIE
exhibits considerable potential to accelerate the advancement of diagnostic
tools and customized treatment plans.",2024-06-01,2024,2024-06,medical
"An Early Investigation into the Utility of Multimodal Large Language
  Models in Medical Imaging","Recent developments in multimodal large language models (MLLMs) have spurred
significant interest in their potential applications across various medical
imaging domains. On the one hand, there is a temptation to use these generative
models to synthesize realistic-looking medical image data, while on the other
hand, the ability to identify synthetic image data in a pool of data is also
significantly important. In this study, we explore the potential of the Gemini
(\textit{gemini-1.0-pro-vision-latest}) and GPT-4V (gpt-4-vision-preview)
models for medical image analysis using two modalities of medical image data.
Utilizing synthetic and real imaging data, both Gemini AI and GPT-4V are first
used to classify real versus synthetic images, followed by an interpretation
and analysis of the input images. Experimental results demonstrate that both
Gemini and GPT-4 could perform some interpretation of the input images. In this
specific experiment, Gemini was able to perform slightly better than the GPT-4V
on the classification task. In contrast, responses associated with GPT-4V were
mostly generic in nature. Our early investigation presented in this work
provides insights into the potential of MLLMs to assist with the classification
and interpretation of retinal fundoscopy and lung X-ray images. We also
identify key limitations associated with the early investigation study on MLLMs
for specialized tasks in medical image analysis.",2024-06-02,2024,2024-06,medical
"Nuclear Medicine Artificial Intelligence in Action: The Bethesda Report
  (AI Summit 2024)","The 2nd SNMMI Artificial Intelligence (AI) Summit, organized by the SNMMI AI
Task Force, took place in Bethesda, MD, on February 29 - March 1, 2024.
Bringing together various community members and stakeholders, and following up
on a prior successful 2022 AI Summit, the summit theme was: AI in Action. Six
key topics included (i) an overview of prior and ongoing efforts by the AI task
force, (ii) emerging needs and tools for computational nuclear oncology, (iii)
new frontiers in large language and generative models, (iv) defining the value
proposition for the use of AI in nuclear medicine, (v) open science including
efforts for data and model repositories, and (vi) issues of reimbursement and
funding. The primary efforts, findings, challenges, and next steps are
summarized in this manuscript.",2024-06-03,2024,2024-06,medical
"Multiple Choice Questions and Large Languages Models: A Case Study with
  Fictional Medical Data","Large Language Models (LLMs) like ChatGPT demonstrate significant potential
in the medical field, often evaluated using multiple-choice questions (MCQs)
similar to those found on the USMLE. Despite their prevalence in medical
education, MCQs have limitations that might be exacerbated when assessing LLMs.
To evaluate the effectiveness of MCQs in assessing the performance of LLMs, we
developed a fictional medical benchmark focused on a non-existent gland, the
Glianorex. This approach allowed us to isolate the knowledge of the LLM from
its test-taking abilities. We used GPT-4 to generate a comprehensive textbook
on the Glianorex in both English and French and developed corresponding
multiple-choice questions in both languages. We evaluated various open-source,
proprietary, and domain-specific LLMs using these questions in a zero-shot
setting. The models achieved average scores around 67%, with minor performance
differences between larger and smaller models. Performance was slightly higher
in English than in French. Fine-tuned medical models showed some improvement
over their base versions in English but not in French. The uniformly high
performance across models suggests that traditional MCQ-based benchmarks may
not accurately measure LLMs' clinical knowledge and reasoning abilities,
instead highlighting their pattern recognition skills. This study underscores
the need for more robust evaluation methods to better assess the true
capabilities of LLMs in medical contexts.",2024-06-04,2024,2024-06,medical
"A Survey on Medical Large Language Models: Technology, Application,
  Trustworthiness, and Future Directions","With the advent of Large Language Models (LLMs), medical artificial
intelligence (AI) has experienced substantial technological progress and
paradigm shifts, highlighting the potential of LLMs to streamline healthcare
delivery and improve patient outcomes. Considering this rapid technical
progress, in this survey, we trace the recent advances of Medical Large
Language Models (Med-LLMs), including the background, key findings, and
mainstream techniques, especially for the evolution from general-purpose models
to medical-specialized applications. Firstly, we delve into the foundational
technology of Med-LLMs, indicating how general models can be progressively
adapted and refined for the complicated medical tasks. Secondly, the
wide-ranging applications of Med-LLMs are investigated across various
healthcare domains, as well as an up-to-date review of existing Med-LLMs. The
transformative impact of these models on daily medical practice is evident
through their ability to assist clinicians, educators, and patients.
Recognizing the importance of responsible innovation, we discuss the challenges
associated with ensuring fairness, accountability, privacy, and robustness.
Ethical considerations, rigorous evaluation methodologies, and the
establishment of regulatory frameworks are crucial for building trustworthiness
in the real-world system. We emphasize the need for ongoing scrutiny and
development to maintain high standards of safety and reliability. Finally, we
anticipate possible future trajectories for Med-LLMs, identifying key avenues
for prudent expansion. By consolidating these insights, our review aims to
provide professionals and researchers with a thorough understanding of the
strengths and limitations of Med-LLMs, fostering a balanced and ethical
approach to their integration into the healthcare ecosystem.",2024-06-06,2024,2024-06,medical
"Transforming Dental Diagnostics with Artificial Intelligence: Advanced
  Integration of ChatGPT and Large Language Models for Patient Care","Artificial intelligence has dramatically reshaped our interaction with
digital technologies, ushering in an era where advancements in AI algorithms
and Large Language Models (LLMs) have natural language processing (NLP) systems
like ChatGPT. This study delves into the impact of cutting-edge LLMs, notably
OpenAI's ChatGPT, on medical diagnostics, with a keen focus on the dental
sector. Leveraging publicly accessible datasets, these models augment the
diagnostic capabilities of medical professionals, streamline communication
between patients and healthcare providers, and enhance the efficiency of
clinical procedures. The advent of ChatGPT-4 is poised to make substantial
inroads into dental practices, especially in the realm of oral surgery. This
paper sheds light on the current landscape and explores potential future
research directions in the burgeoning field of LLMs, offering valuable insights
for both practitioners and developers. Furthermore, it critically assesses the
broad implications and challenges within various sectors, including academia
and healthcare, thus mapping out an overview of AI's role in transforming
dental diagnostics for enhanced patient care.",2024-06-07,2024,2024-06,medical
"Development and Validation of a Deep-Learning Model for Differential
  Treatment Benefit Prediction for Adults with Major Depressive Disorder
  Deployed in the Artificial Intelligence in Depression Medication Enhancement
  (AIDME) Study","INTRODUCTION: The pharmacological treatment of Major Depressive Disorder
(MDD) relies on a trial-and-error approach. We introduce an artificial
intelligence (AI) model aiming to personalize treatment and improve outcomes,
which was deployed in the Artificial Intelligence in Depression Medication
Enhancement (AIDME) Study. OBJECTIVES: 1) Develop a model capable of predicting
probabilities of remission across multiple pharmacological treatments for
adults with at least moderate major depression. 2) Validate model predictions
and examine them for amplification of harmful biases. METHODS: Data from
previous clinical trials of antidepressant medications were standardized into a
common framework and included 9,042 adults with moderate to severe major
depression. Feature selection retained 25 clinical and demographic variables.
Using Bayesian optimization, a deep learning model was trained on the training
set, refined using the validation set, and tested once on the held-out test
set. RESULTS: In the evaluation on the held-out test set, the model
demonstrated achieved an AUC of 0.65. The model outperformed a null model on
the test set (p = 0.01). The model demonstrated clinical utility, achieving an
absolute improvement in population remission rate in hypothetical and actual
improvement testing. While the model did identify one drug (escitalopram) as
generally outperforming the other drugs (consistent with the input data), there
was otherwise significant variation in drug rankings. On bias testing, the
model did not amplify potentially harmful biases. CONCLUSIONS: We demonstrate
the first model capable of predicting outcomes for 10 different treatment
options for patients with MDD, intended to be used at or near the start of
treatment to personalize treatment. The model was put into clinical practice
during the AIDME randomized controlled trial whose results are reported
separately.",2024-06-07,2024,2024-06,medical
Rapid Review of Generative AI in Smart Medical Applications,"With the continuous advancement of technology, artificial intelligence has
significantly impacted various fields, particularly healthcare. Generative
models, a key AI technology, have revolutionized medical image generation, data
analysis, and diagnosis. This article explores their application in intelligent
medical devices. Generative models enhance diagnostic speed and accuracy,
improving medical service quality and efficiency while reducing equipment
costs. These models show great promise in medical image generation, data
analysis, and diagnosis. Additionally, integrating generative models with IoT
technology facilitates real-time data analysis and predictions, offering
smarter healthcare services and aiding in telemedicine. Challenges include
computational demands, ethical concerns, and scenario-specific limitations.",2024-06-08,2024,2024-06,medical
"DeviceBERT: Applied Transfer Learning With Targeted Annotations and
  Vocabulary Enrichment to Identify Medical Device and Component Terminology in
  FDA Recall Summaries","FDA Medical Device recalls are critical and time-sensitive events, requiring
swift identification of impacted devices to inform the public of a recall event
and ensure patient safety. The OpenFDA device recall dataset contains valuable
information about ongoing device recall actions, but manually extracting
relevant device information from the recall action summaries is a
time-consuming task. Named Entity Recognition (NER) is a task in Natural
Language Processing (NLP) that involves identifying and categorizing named
entities in unstructured text. Existing NER models, including domain-specific
models like BioBERT, struggle to correctly identify medical device trade names,
part numbers and component terms within these summaries. To address this, we
propose DeviceBERT, a medical device annotation, pre-processing and enrichment
pipeline, which builds on BioBERT to identify and label medical device
terminology in the device recall summaries with improved accuracy. Furthermore,
we demonstrate that our approach can be applied effectively for performing
entity recognition tasks where training data is limited or sparse.",2024-06-08,2024,2024-06,medical
MedExQA: Medical Question Answering Benchmark with Multiple Explanations,"This paper introduces MedExQA, a novel benchmark in medical
question-answering, to evaluate large language models' (LLMs) understanding of
medical knowledge through explanations. By constructing datasets across five
distinct medical specialties that are underrepresented in current datasets and
further incorporating multiple explanations for each question-answer pair, we
address a major gap in current medical QA benchmarks which is the absence of
comprehensive assessments of LLMs' ability to generate nuanced medical
explanations. Our work highlights the importance of explainability in medical
LLMs, proposes an effective methodology for evaluating models beyond
classification accuracy, and sheds light on one specific domain, speech
language pathology, where current LLMs including GPT4 lack good understanding.
Our results show generation evaluation with multiple explanations aligns better
with human assessment, highlighting an opportunity for a more robust automated
comprehension assessment for LLMs. To diversify open-source medical LLMs
(currently mostly based on Llama2), this work also proposes a new medical
model, MedPhi-2, based on Phi-2 (2.7B). The model outperformed medical LLMs
based on Llama2-70B in generating explanations, showing its effectiveness in
the resource-constrained medical domain. We will share our benchmark datasets
and the trained model.",2024-06-10,2024,2024-06,medical
"Overcoming Limitations in Artificial Intelligence-based Prostate Cancer
  Detection through Better Datasets and a Bayesian Approach to Aggregate Panel
  Predictions","Despite considerable progress in developing artificial intelligence (AI)
algorithms for prostate cancer detection from whole slide images, the clinical
applicability of these models remains limited due to variability in
pathological annotations and existing dataset limitations. This article
proposes a novel approach to overcome these challenges by leveraging a Bayesian
framework to seamlessly integrate new data, and present results as a panel of
annotations. The framework is demonstrated by integrating a Bayesian prior with
one trained AI model to generate a distribution of Gleason patterns for each
pixel of an image. It is shown that using this distribution of Gleason patterns
rather than a ground-truth label can improve model applicability, mitigate
errors, and highlight areas of interest for pathologists. Additionally, we
present a high-quality, hand-curated dataset of prostate histopathological
images annotated at the gland level by trained pre-medical students and
verified by an expert pathologist. We highlight the potential of this adaptive
and uncertainty-aware framework for developing clinically deployable AI tools
that can support pathologists in accurate prostate cancer grading, improve
diagnostic accuracy, and create positive patient outcomes.",2024-06-10,2024,2024-06,medical
"Global AI Governance in Healthcare: A Cross-Jurisdictional Regulatory
  Analysis","Artificial Intelligence (AI) is being adopted across the world and promises a
new revolution in healthcare. While AI-enabled medical devices in North America
dominate 42.3% of the global market, the use of AI-enabled medical devices in
other countries is still a story waiting to be unfolded. We aim to delve deeper
into global regulatory approaches towards AI use in healthcare, with a focus on
how common themes are emerging globally. We compare these themes to the World
Health Organization's (WHO) regulatory considerations and principles on ethical
use of AI for healthcare applications. Our work seeks to take a global
perspective on AI policy by analyzing 14 legal jurisdictions including
countries representative of various regions in the world (North America, South
America, South East Asia, Middle East, Africa, Australia, and the
Asia-Pacific). Our eventual goal is to foster a global conversation on the
ethical use of AI in healthcare and the regulations that will guide it. We
propose solutions to promote international harmonization of AI regulations and
examine the requirements for regulating generative AI, using China and
Singapore as examples of countries with well-developed policies in this area.",2024-06-12,2024,2024-06,medical
"A Survey on Large Language Models from General Purpose to Medical
  Applications: Datasets, Methodologies, and Evaluations","Large Language Models (LLMs) have demonstrated surprising performance across
various natural language processing tasks. Recently, medical LLMs enhanced with
domain-specific knowledge have exhibited excellent capabilities in medical
consultation and diagnosis. These models can smoothly simulate doctor-patient
dialogues and provide professional medical advice. Most medical LLMs are
developed through continued training of open-source general LLMs, which require
significantly fewer computational resources than training LLMs from scratch.
Additionally, this approach offers better patient privacy protection than
API-based solutions. Given the above advantages, this survey systematically
summarizes how to train medical LLMs based on open-source general LLMs from a
more fine-grained perspective. It covers (a) how to acquire training corpus and
construct customized medical training sets, (b) how to choose an appropriate
training paradigm, (c) how to choose a suitable evaluation benchmark, and (d)
existing challenges and promising research directions are discussed. This
survey can provide guidance for the development of LLMs focused on various
medical applications, such as medical education, diagnostic planning, and
clinical assistants. Related resources and supplemental information can be
found on the GitHub repository.",2024-06-14,2024,2024-06,medical
"CliBench: A Multifaceted and Multigranular Evaluation of Large Language
  Models for Clinical Decision Making","The integration of Artificial Intelligence (AI), especially Large Language
Models (LLMs), into the clinical diagnosis process offers significant potential
to improve the efficiency and accessibility of medical care. While LLMs have
shown some promise in the medical domain, their application in clinical
diagnosis remains underexplored, especially in real-world clinical practice,
where highly sophisticated, patient-specific decisions need to be made. Current
evaluations of LLMs in this field are often narrow in scope, focusing on
specific diseases or specialties and employing simplified diagnostic tasks. To
bridge this gap, we introduce CliBench, a novel benchmark developed from the
MIMIC IV dataset, offering a comprehensive and realistic assessment of LLMs'
capabilities in clinical diagnosis. This benchmark not only covers diagnoses
from a diverse range of medical cases across various specialties but also
incorporates tasks of clinical significance: treatment procedure
identification, lab test ordering and medication prescriptions. Supported by
structured output ontologies, CliBench enables a precise and multi-granular
evaluation, offering an in-depth understanding of LLM's capability on diverse
clinical tasks of desired granularity. We conduct a zero-shot evaluation of
leading LLMs to assess their proficiency in clinical decision-making. Our
preliminary results shed light on the potential and limitations of current LLMs
in clinical settings, providing valuable insights for future advancements in
LLM-powered healthcare.",2024-06-14,2024,2024-06,medical
Boosting Medical Image Classification with Segmentation Foundation Model,"The Segment Anything Model (SAM) exhibits impressive capabilities in
zero-shot segmentation for natural images. Recently, SAM has gained a great
deal of attention for its applications in medical image segmentation. However,
to our best knowledge, no studies have shown how to harness the power of SAM
for medical image classification. To fill this gap and make SAM a true
``foundation model'' for medical image analysis, it is highly desirable to
customize SAM specifically for medical image classification. In this paper, we
introduce SAMAug-C, an innovative augmentation method based on SAM for
augmenting classification datasets by generating variants of the original
images. The augmented datasets can be used to train a deep learning
classification model, thereby boosting the classification performance.
Furthermore, we propose a novel framework that simultaneously processes raw and
SAMAug-C augmented image input, capitalizing on the complementary information
that is offered by both. Experiments on three public datasets validate the
effectiveness of our new approach.",2024-06-16,2024,2024-06,medical
"Retrieval-Augmented Generation for Generative Artificial Intelligence in
  Medicine","Generative artificial intelligence (AI) has brought revolutionary innovations
in various fields, including medicine. However, it also exhibits limitations.
In response, retrieval-augmented generation (RAG) provides a potential
solution, enabling models to generate more accurate contents by leveraging the
retrieval of external knowledge. With the rapid advancement of generative AI,
RAG can pave the way for connecting this transformative technology with medical
applications and is expected to bring innovations in equity, reliability, and
personalization to health care.",2024-06-18,2024,2024-06,medical
"Privacy Preserving Federated Learning in Medical Imaging with
  Uncertainty Estimation","Machine learning (ML) and Artificial Intelligence (AI) have fueled remarkable
advancements, particularly in healthcare. Within medical imaging, ML models
hold the promise of improving disease diagnoses, treatment planning, and
post-treatment monitoring. Various computer vision tasks like image
classification, object detection, and image segmentation are poised to become
routine in clinical analysis. However, privacy concerns surrounding patient
data hinder the assembly of large training datasets needed for developing and
training accurate, robust, and generalizable models. Federated Learning (FL)
emerges as a compelling solution, enabling organizations to collaborate on ML
model training by sharing model training information (gradients) rather than
data (e.g., medical images). FL's distributed learning framework facilitates
inter-institutional collaboration while preserving patient privacy. However,
FL, while robust in privacy preservation, faces several challenges. Sensitive
information can still be gleaned from shared gradients that are passed on
between organizations during model training. Additionally, in medical imaging,
quantifying model confidence\uncertainty accurately is crucial due to the noise
and artifacts present in the data. Uncertainty estimation in FL encounters
unique hurdles due to data heterogeneity across organizations. This paper
offers a comprehensive review of FL, privacy preservation, and uncertainty
estimation, with a focus on medical imaging. Alongside a survey of current
research, we identify gaps in the field and suggest future directions for FL
research to enhance privacy and address noisy medical imaging data challenges.",2024-06-18,2024,2024-06,medical
"Aqulia-Med LLM: Pioneering Full-Process Open-Source Medical Language
  Models","Recently, both closed-source LLMs and open-source communities have made
significant strides, outperforming humans in various general domains. However,
their performance in specific professional fields such as medicine, especially
within the open-source community, remains suboptimal due to the complexity of
medical knowledge. We propose Aquila-Med, a bilingual medical LLM based on
Aquila, addressing these challenges through continue pre-training, supervised
fine-tuning (SFT), and reinforcement learning from human feedback (RLHF). We
construct a large-scale Chinese and English medical dataset for continue
pre-training and a high-quality SFT dataset, covering extensive medical
specialties. Additionally, we develop a high-quality Direct Preference
Optimization (DPO) dataset for further alignment. Aquila-Med achieves notable
results across single-turn, multi-turn dialogues, and medical multiple-choice
questions, demonstrating the effectiveness of our approach. We open-source the
datasets and the entire training process, contributing valuable resources to
the research community. Our models and datasets will released at
https://huggingface.co/BAAI/AquilaMed-RL.",2024-06-18,2024,2024-06,medical
Adversarial Attacks on Large Language Models in Medicine,"The integration of Large Language Models (LLMs) into healthcare applications
offers promising advancements in medical diagnostics, treatment
recommendations, and patient care. However, the susceptibility of LLMs to
adversarial attacks poses a significant threat, potentially leading to harmful
outcomes in delicate medical contexts. This study investigates the
vulnerability of LLMs to two types of adversarial attacks in three medical
tasks. Utilizing real-world patient data, we demonstrate that both open-source
and proprietary LLMs are susceptible to manipulation across multiple tasks.
This research further reveals that domain-specific tasks demand more
adversarial data in model fine-tuning than general domain tasks for effective
attack execution, especially for more capable models. We discover that while
integrating adversarial data does not markedly degrade overall model
performance on medical benchmarks, it does lead to noticeable shifts in
fine-tuned model weights, suggesting a potential pathway for detecting and
countering model attacks. This research highlights the urgent need for robust
security measures and the development of defensive mechanisms to safeguard LLMs
in medical applications, to ensure their safe and effective deployment in
healthcare settings.",2024-06-18,2024,2024-06,medical
"Reasoning Like a Doctor: Improving Medical Dialogue Systems via
  Diagnostic Reasoning Process Alignment","Medical dialogue systems have attracted significant attention for their
potential to act as medical assistants. Enabling these medical systems to
emulate clinicians' diagnostic reasoning process has been the long-standing
research focus. Previous studies rudimentarily realized the simulation of
clinicians' diagnostic process by fine-tuning language models on high-quality
dialogue datasets. Nonetheless, they overly focus on the outcomes of the
clinician's reasoning process while ignoring their internal thought processes
and alignment with clinician preferences. Our work aims to build a medical
dialogue system that aligns with clinicians' diagnostic reasoning processes. We
propose a novel framework, Emulation, designed to generate an appropriate
response that relies on abductive and deductive diagnostic reasoning analyses
and aligns with clinician preferences through thought process modeling.
Experimental results on two datasets confirm the efficacy of Emulation.
Crucially, our framework furnishes clear explanations for the generated
responses, enhancing its transparency in medical consultations.",2024-06-20,2024,2024-06,medical
A Data-Driven Guided Decoding Mechanism for Diagnostic Captioning,"Diagnostic Captioning (DC) automatically generates a diagnostic text from one
or more medical images (e.g., X-rays, MRIs) of a patient. Treated as a draft,
the generated text may assist clinicians, by providing an initial estimation of
the patient's condition, speeding up and helping safeguard the diagnostic
process. The accuracy of a diagnostic text, however, strongly depends on how
well the key medical conditions depicted in the images are expressed. We
propose a new data-driven guided decoding method that incorporates medical
information, in the form of existing tags capturing key conditions of the
image(s), into the beam search of the diagnostic text generation process. We
evaluate the proposed method on two medical datasets using four DC systems that
range from generic image-to-text systems with CNN encoders and RNN decoders to
pre-trained Large Language Models. The latter can also be used in few- and
zero-shot learning scenarios. In most cases, the proposed mechanism improves
performance with respect to all evaluation measures. We provide an open-source
implementation of the proposed method at https://github.com/nlpaueb/dmmcs.",2024-06-20,2024,2024-06,medical
Human-AI collectives produce the most accurate differential diagnoses,"Artificial intelligence systems, particularly large language models (LLMs),
are increasingly being employed in high-stakes decisions that impact both
individuals and society at large, often without adequate safeguards to ensure
safety, quality, and equity. Yet LLMs hallucinate, lack common sense, and are
biased - shortcomings that may reflect LLMs' inherent limitations and thus may
not be remedied by more sophisticated architectures, more data, or more human
feedback. Relying solely on LLMs for complex, high-stakes decisions is
therefore problematic. Here we present a hybrid collective intelligence system
that mitigates these risks by leveraging the complementary strengths of human
experience and the vast information processed by LLMs. We apply our method to
open-ended medical diagnostics, combining 40,762 differential diagnoses made by
physicians with the diagnoses of five state-of-the art LLMs across 2,133
medical cases. We show that hybrid collectives of physicians and LLMs
outperform both single physicians and physician collectives, as well as single
LLMs and LLM ensembles. This result holds across a range of medical specialties
and professional experience, and can be attributed to humans' and LLMs'
complementary contributions that lead to different kinds of errors. Our
approach highlights the potential for collective human and machine intelligence
to improve accuracy in complex, open-ended domains like medical diagnostics.",2024-06-21,2024,2024-06,medical
Real-time Speech Summarization for Medical Conversations,"In doctor-patient conversations, identifying medically relevant information
is crucial, posing the need for conversation summarization. In this work, we
propose the first deployable real-time speech summarization system for
real-world applications in industry, which generates a local summary after
every N speech utterances within a conversation and a global summary after the
end of a conversation. Our system could enhance user experience from a business
standpoint, while also reducing computational costs from a technical
perspective. Secondly, we present VietMed-Sum which, to our knowledge, is the
first speech summarization dataset for medical conversations. Thirdly, we are
the first to utilize LLM and human annotators collaboratively to create gold
standard and synthetic summaries for medical conversation summarization.
Finally, we present baseline results of state-of-the-art models on VietMed-Sum.
All code, data (English-translated and Vietnamese) and models are available
online: https://github.com/leduckhai/MultiMed/tree/master/VietMed-Sum",2024-06-22,2024,2024-06,medical
"The Potential and Perils of Generative Artificial Intelligence for
  Quality Improvement and Patient Safety","Generative artificial intelligence (GenAI) has the potential to improve
healthcare through automation that enhances the quality and safety of patient
care. Powered by foundation models that have been pretrained and can generate
complex content, GenAI represents a paradigm shift away from the more
traditional focus on task-specific classifiers that have dominated the AI
landscape thus far. We posit that the imminent application of GenAI in
healthcare will be through well-defined, low risk, high value, and narrow
applications that automate healthcare workflows at the point of care using
smaller foundation models. These models will be finetuned for different
capabilities and application specific scenarios and will have the ability to
provide medical explanations, reference evidence within a retrieval augmented
framework and utilizing external tools. We contrast this with a general,
all-purpose AI model for end-to-end clinical decision making that improves
clinician performance, including safety-critical diagnostic tasks, which will
require greater research prior to implementation. We consider areas where
'human in the loop' Generative AI can improve healthcare quality and safety by
automating mundane tasks. Using the principles of implementation science will
be critical for integrating 'end to end' GenAI systems that will be accepted by
healthcare teams.",2024-06-23,2024,2024-06,medical
"Scalable Artificial Intelligence for Science: Perspectives, Methods and
  Exemplars","In a post-ChatGPT world, this paper explores the potential of leveraging
scalable artificial intelligence for scientific discovery. We propose that
scaling up artificial intelligence on high-performance computing platforms is
essential to address such complex problems. This perspective focuses on
scientific use cases like cognitive simulations, large language models for
scientific inquiry, medical image analysis, and physics-informed approaches.
The study outlines the methodologies needed to address such challenges at scale
on supercomputers or the cloud and provides exemplars of such approaches
applied to solve a variety of scientific problems.",2024-06-24,2024,2024-06,medical
"Assessing the role of clinical summarization and patient chart review
  within communications, medical management, and diagnostics","Effective summarization of unstructured patient data in electronic health
records (EHRs) is crucial for accurate diagnosis and efficient patient care,
yet clinicians often struggle with information overload and time constraints.
This review dives into recent literature and case studies on both the
significant impacts and outstanding issues of patient chart review on
communications, diagnostics, and management. It also discusses recent efforts
to integrate artificial intelligence (AI) into clinical summarization tasks,
and its transformative impact on the clinician's potential, including but not
limited to reductions of administrative burden and improved patient-centered
care.",2024-06-24,2024,2024-06,medical
"Guardrails for avoiding harmful medical product recommendations and
  off-label promotion in generative AI models","Generative AI (GenAI) models have demonstrated remarkable capabilities in a
wide variety of medical tasks. However, as these models are trained using
generalist datasets with very limited human oversight, they can learn uses of
medical products that have not been adequately evaluated for safety and
efficacy, nor approved by regulatory agencies. Given the scale at which GenAI
may reach users, unvetted recommendations pose a public health risk. In this
work, we propose an approach to identify potentially harmful product
recommendations, and demonstrate it using a recent multimodal large language
model.",2024-06-24,2024,2024-06,medical
"MedBench: A Comprehensive, Standardized, and Reliable Benchmarking
  System for Evaluating Chinese Medical Large Language Models","Ensuring the general efficacy and goodness for human beings from medical
large language models (LLM) before real-world deployment is crucial. However, a
widely accepted and accessible evaluation process for medical LLM, especially
in the Chinese context, remains to be established. In this work, we introduce
""MedBench"", a comprehensive, standardized, and reliable benchmarking system for
Chinese medical LLM. First, MedBench assembles the currently largest evaluation
dataset (300,901 questions) to cover 43 clinical specialties and performs
multi-facet evaluation on medical LLM. Second, MedBench provides a standardized
and fully automatic cloud-based evaluation infrastructure, with physical
separations for question and ground truth. Third, MedBench implements dynamic
evaluation mechanisms to prevent shortcut learning and answer remembering.
Applying MedBench to popular general and medical LLMs, we observe unbiased,
reproducible evaluation results largely aligning with medical professionals'
perspectives. This study establishes a significant foundation for preparing the
practical applications of Chinese medical LLMs. MedBench is publicly accessible
at https://medbench.opencompass.org.cn.",2024-06-24,2024,2024-06,medical
"Evaluation of Language Models in the Medical Context Under
  Resource-Constrained Settings","Since the Transformer architecture emerged, language model development has
grown, driven by their promising potential. Releasing these models into
production requires properly understanding their behavior, particularly in
sensitive domains like medicine. Despite this need, the medical literature
still lacks practical assessment of pre-trained language models, which are
especially valuable in settings where only consumer-grade computational
resources are available. To address this gap, we have conducted a comprehensive
survey of language models in the medical field and evaluated a subset of these
for medical text classification and conditional text generation. The subset
includes 53 models with 110 million to 13 billion parameters, spanning the
Transformer-based model families and knowledge domains. Different approaches
are employed for text classification, including zero-shot learning, enabling
tuning without the need to train the model. These approaches are helpful in our
target settings, where many users of language models find themselves. The
results reveal remarkable performance across the tasks and datasets evaluated,
underscoring the potential of certain models to contain medical knowledge, even
without domain specialization. This study thus advocates for further
exploration of model applications in medical contexts, particularly in
computational resource-constrained settings, to benefit a wide range of users.
The code is available on https://github.com/anpoc/Language-models-in-medicine.",2024-06-24,2024,2024-06,medical
"HuatuoGPT-Vision, Towards Injecting Medical Visual Knowledge into
  Multimodal LLMs at Scale","The rapid development of multimodal large language models (MLLMs), such as
GPT-4V, has led to significant advancements. However, these models still face
challenges in medical multimodal capabilities due to limitations in the
quantity and quality of medical vision-text data, stemming from data privacy
concerns and high annotation costs. While pioneering approaches utilize
PubMed's large-scale, de-identified medical image-text pairs to address these
limitations, they still fall short due to inherent data noise. To tackle this,
we refined medical image-text pairs from PubMed and employed MLLMs (GPT-4V) in
an 'unblinded' capacity to denoise and reformat the data, resulting in the
creation of the PubMedVision dataset with 1.3 million medical VQA samples. Our
validation demonstrates that: (1) PubMedVision can significantly enhance the
medical multimodal capabilities of current MLLMs, showing significant
improvement in benchmarks including the MMMU Health & Medicine track; (2)
manual checks by medical experts and empirical results validate the superior
data quality of our dataset compared to other data construction methods. Using
PubMedVision, we train a 34B medical MLLM HuatuoGPT-Vision, which shows
superior performance in medical multimodal scenarios among open-source MLLMs.",2024-06-27,2024,2024-06,medical
"Generative AI for Synthetic Data Across Multiple Medical Modalities: A
  Systematic Review of Recent Developments and Challenges","This paper presents a comprehensive systematic review of generative models
(GANs, VAEs, DMs, and LLMs) used to synthesize various medical data types,
including imaging (dermoscopic, mammographic, ultrasound, CT, MRI, and X-ray),
text, time-series, and tabular data (EHR). Unlike previous narrowly focused
reviews, our study encompasses a broad array of medical data modalities and
explores various generative models. Our search strategy queries databases such
as Scopus, PubMed, and ArXiv, focusing on recent works from January 2021 to
November 2023, excluding reviews and perspectives. This period emphasizes
recent advancements beyond GANs, which have been extensively covered
previously.
  The survey reveals insights from three key aspects: (1) Synthesis
applications and purpose of synthesis, (2) generation techniques, and (3)
evaluation methods. It highlights clinically valid synthesis applications,
demonstrating the potential of synthetic data to tackle diverse clinical
requirements. While conditional models incorporating class labels, segmentation
masks and image translations are prevalent, there is a gap in utilizing prior
clinical knowledge and patient-specific context, suggesting a need for more
personalized synthesis approaches and emphasizing the importance of tailoring
generative approaches to the unique characteristics of medical data.
Additionally, there is a significant gap in using synthetic data beyond
augmentation, such as for validation and evaluation of downstream medical AI
models. The survey uncovers that the lack of standardized evaluation
methodologies tailored to medical images is a barrier to clinical application,
underscoring the need for in-depth evaluation approaches, benchmarking, and
comparative studies to promote openness and collaboration.",2024-06-27,2024,2024-06,medical
"MH-pFLGB: Model Heterogeneous personalized Federated Learning via Global
  Bypass for Medical Image Analysis","In the evolving application of medical artificial intelligence, federated
learning is notable for its ability to protect training data privacy. Federated
learning facilitates collaborative model development without the need to share
local data from healthcare institutions. Yet, the statistical and system
heterogeneity among these institutions poses substantial challenges, which
affects the effectiveness of federated learning and hampers the exchange of
information between clients. To address these issues, we introduce a novel
approach, MH-pFLGB, which employs a global bypass strategy to mitigate the
reliance on public datasets and navigate the complexities of non-IID data
distributions. Our method enhances traditional federated learning by
integrating a global bypass model, which would share the information among the
clients, but also serves as part of the network to enhance the performance on
each client. Additionally, MH-pFLGB provides a feature fusion module to better
combine the local and global features. We validate \model{}'s effectiveness and
adaptability through extensive testing on different medical tasks,
demonstrating superior performance compared to existing state-of-the-art
methods.",2024-06-29,2024,2024-06,medical
"TrialBench: Multi-Modal Artificial Intelligence-Ready Clinical Trial
  Datasets","Clinical trials are pivotal for developing new medical treatments, yet they
typically pose some risks such as patient mortality, adverse events, and
enrollment failure that waste immense efforts spanning over a decade. Applying
artificial intelligence (AI) to forecast or simulate key events in clinical
trials holds great potential for providing insights to guide trial designs.
However, complex data collection and question definition requiring medical
expertise and a deep understanding of trial designs have hindered the
involvement of AI thus far. This paper tackles these challenges by presenting a
comprehensive suite of meticulously curated AIready datasets covering
multi-modal data (e.g., drug molecule, disease code, text,
categorical/numerical features) and 8 crucial prediction challenges in clinical
trial design, encompassing prediction of trial duration, patient dropout rate,
serious adverse event, mortality rate, trial approval outcome, trial failure
reason, drug dose finding, design of eligibility criteria. Furthermore, we
provide basic validation methods for each task to ensure the datasets'
usability and reliability. We anticipate that the availability of such
open-access datasets will catalyze the development of advanced AI approaches
for clinical trial design, ultimately advancing clinical trial research and
accelerating medical solution development. The curated dataset, metrics, and
basic models are publicly available at
https://github.com/ML2Health/ML2ClinicalTrials/tree/main/AI4Trial.",2024-06-30,2024,2024-06,medical
"Evaluation of Bias Towards Medical Professionals in Large Language
  Models","This study evaluates whether large language models (LLMs) exhibit biases
towards medical professionals. Fictitious candidate resumes were created to
control for identity factors while maintaining consistent qualifications. Three
LLMs (GPT-4, Claude-3-haiku, and Mistral-Large) were tested using a
standardized prompt to evaluate resumes for specific residency programs.
Explicit bias was tested by changing gender and race information, while
implicit bias was tested by changing names while hiding race and gender.
Physician data from the Association of American Medical Colleges was used to
compare with real-world demographics. 900,000 resumes were evaluated. All LLMs
exhibited significant gender and racial biases across medical specialties.
Gender preferences varied, favoring male candidates in surgery and orthopedics,
while preferring females in dermatology, family medicine, obstetrics and
gynecology, pediatrics, and psychiatry. Claude-3 and Mistral-Large generally
favored Asian candidates, while GPT-4 preferred Black and Hispanic candidates
in several specialties. Tests revealed strong preferences towards Hispanic
females and Asian males in various specialties. Compared to real-world data,
LLMs consistently chose higher proportions of female and underrepresented
racial candidates than their actual representation in the medical workforce.
GPT-4, Claude-3, and Mistral-Large showed significant gender and racial biases
when evaluating medical professionals for residency selection. These findings
highlight the potential for LLMs to perpetuate biases and compromise healthcare
workforce diversity if used without proper bias mitigation strategies.",2024-06-30,2024,2024-06,medical
"First Place Solution of 2023 Global Artificial Intelligence Technology
  Innovation Competition Track 1","In this paper, we present our champion solution to the Global Artificial
Intelligence Technology Innovation Competition Track 1: Medical Imaging
Diagnosis Report Generation. We select CPT-BASE as our base model for the text
generation task. During the pre-training stage, we delete the mask language
modeling task of CPT-BASE and instead reconstruct the vocabulary, adopting a
span mask strategy and gradually increasing the number of masking ratios to
perform the denoising auto-encoder pre-training task. In the fine-tuning stage,
we design iterative retrieval augmentation and noise-aware similarity bucket
prompt strategies. The retrieval augmentation constructs a mini-knowledge base,
enriching the input information of the model, while the similarity bucket
further perceives the noise information within the mini-knowledge base, guiding
the model to generate higher-quality diagnostic reports based on the similarity
prompts. Surprisingly, our single model has achieved a score of 2.321 on
leaderboard A, and the multiple model fusion scores are 2.362 and 2.320 on the
A and B leaderboards respectively, securing first place in the rankings.",2024-07-01,2024,2024-07,medical
"Hybrid RAG-empowered Multi-modal LLM for Secure Data Management in
  Internet of Medical Things: A Diffusion-based Contract Approach","Secure data management and effective data sharing have become paramount in
the rapidly evolving healthcare landscape, especially with the growing
integration of the Internet of Medical Things (IoMT). The rise of generative
artificial intelligence has further elevated Multi-modal Large Language Models
(MLLMs) as essential tools for managing and optimizing healthcare data in IoMT.
MLLMs can support multi-modal inputs and generate diverse types of content by
leveraging large-scale training on vast amounts of multi-modal data. However,
critical challenges persist in developing medical MLLMs, including security and
freshness issues of healthcare data, affecting the output quality of MLLMs. To
this end, in this paper, we propose a hybrid Retrieval-Augmented Generation
(RAG)-empowered medical MLLM framework for healthcare data management. This
framework leverages a hierarchical cross-chain architecture to facilitate
secure data training. Moreover, it enhances the output quality of MLLMs through
hybrid RAG, which employs multi-modal metrics to filter various unimodal RAG
results and incorporates these retrieval results as additional inputs to MLLMs.
Additionally, we employ age of information to indirectly evaluate the data
freshness impact of MLLMs and utilize contract theory to incentivize healthcare
data holders to share their fresh data, mitigating information asymmetry during
data sharing. Finally, we utilize a generative diffusion model-based deep
reinforcement learning algorithm to identify the optimal contract for efficient
data sharing. Numerical results demonstrate the effectiveness of the proposed
schemes, which achieve secure and efficient healthcare data management.",2024-07-01,2024,2024-07,medical
MMedAgent: Learning to Use Medical Tools with Multi-modal Agent,"Multi-Modal Large Language Models (MLLMs), despite being successful, exhibit
limited generality and often fall short when compared to specialized models.
Recently, LLM-based agents have been developed to address these challenges by
selecting appropriate specialized models as tools based on user inputs.
However, such advancements have not been extensively explored within the
medical domain. To bridge this gap, this paper introduces the first agent
explicitly designed for the medical field, named \textbf{M}ulti-modal
\textbf{Med}ical \textbf{Agent} (MMedAgent). We curate an instruction-tuning
dataset comprising six medical tools solving seven tasks across five
modalities, enabling the agent to choose the most suitable tools for a given
task. Comprehensive experiments demonstrate that MMedAgent achieves superior
performance across a variety of medical tasks compared to state-of-the-art
open-source methods and even the closed-source model, GPT-4o. Furthermore,
MMedAgent exhibits efficiency in updating and integrating new medical tools.
Codes and models are all available.",2024-07-02,2024,2024-07,medical
"FedIA: Federated Medical Image Segmentation with Heterogeneous
  Annotation Completeness","Federated learning has emerged as a compelling paradigm for medical image
segmentation, particularly in light of increasing privacy concerns. However,
most of the existing research relies on relatively stringent assumptions
regarding the uniformity and completeness of annotations across clients.
Contrary to this, this paper highlights a prevalent challenge in medical
practice: incomplete annotations. Such annotations can introduce incorrectly
labeled pixels, potentially undermining the performance of neural networks in
supervised learning. To tackle this issue, we introduce a novel solution, named
FedIA. Our insight is to conceptualize incomplete annotations as noisy data
(i.e., low-quality data), with a focus on mitigating their adverse effects. We
begin by evaluating the completeness of annotations at the client level using a
designed indicator. Subsequently, we enhance the influence of clients with more
comprehensive annotations and implement corrections for incomplete ones,
thereby ensuring that models are trained on accurate data. Our method's
effectiveness is validated through its superior performance on two extensively
used medical image segmentation datasets, outperforming existing solutions. The
code is available at https://github.com/HUSTxyy/FedIA.",2024-07-02,2024,2024-07,medical
"MedVH: Towards Systematic Evaluation of Hallucination for Large Vision
  Language Models in the Medical Context","Large Vision Language Models (LVLMs) have recently achieved superior
performance in various tasks on natural image and text data, which inspires a
large amount of studies for LVLMs fine-tuning and training. Despite their
advancements, there has been scant research on the robustness of these models
against hallucination when fine-tuned on smaller datasets. In this study, we
introduce a new benchmark dataset, the Medical Visual Hallucination Test
(MedVH), to evaluate the hallucination of domain-specific LVLMs. MedVH
comprises five tasks to evaluate hallucinations in LVLMs within the medical
context, which includes tasks for comprehensive understanding of textual and
visual input, as well as long textual response generation. Our extensive
experiments with both general and medical LVLMs reveal that, although medical
LVLMs demonstrate promising performance on standard medical tasks, they are
particularly susceptible to hallucinations, often more so than the general
models, raising significant concerns about the reliability of these
domain-specific models. For medical LVLMs to be truly valuable in real-world
applications, they must not only accurately integrate medical knowledge but
also maintain robust reasoning abilities to prevent hallucination. Our work
paves the way for future evaluations of these studies.",2024-07-03,2024,2024-07,medical
"A Survey on Trustworthiness in Foundation Models for Medical Image
  Analysis","The rapid advancement of foundation models in medical imaging represents a
significant leap toward enhancing diagnostic accuracy and personalized
treatment. However, the deployment of foundation models in healthcare
necessitates a rigorous examination of their trustworthiness, encompassing
privacy, robustness, reliability, explainability, and fairness. The current
body of survey literature on foundation models in medical imaging reveals
considerable gaps, particularly in the area of trustworthiness. Additionally,
existing surveys on the trustworthiness of foundation models do not adequately
address their specific variations and applications within the medical imaging
domain. This survey aims to fill that gap by presenting a novel taxonomy of
foundation models used in medical imaging and analyzing the key motivations for
ensuring their trustworthiness. We review current research on foundation models
in major medical imaging applications, focusing on segmentation, medical report
generation, medical question and answering (Q\&A), and disease diagnosis. These
areas are highlighted because they have seen a relatively mature and
substantial number of foundation models compared to other applications. We
focus on literature that discusses trustworthiness in medical image analysis
manuscripts. We explore the complex challenges of building trustworthy
foundation models for each application, summarizing current concerns and
strategies for enhancing trustworthiness. Furthermore, we examine the potential
of these models to revolutionize patient care. Our analysis underscores the
imperative for advancing towards trustworthy AI in medical image analysis,
advocating for a balanced approach that fosters innovation while ensuring
ethical and equitable healthcare delivery.",2024-07-03,2024,2024-07,medical
"MedPix 2.0: A Comprehensive Multimodal Biomedical Data set for Advanced
  AI Applications","The increasing interest in developing Artificial Intelligence applications in
the medical domain, suffers from the lack of high-quality data set, mainly due
to privacy-related issues. Moreover, the recent rising of Large Multimodal
Models (LMM) leads to a need for multimodal medical data sets, where clinical
reports and findings are attached to the corresponding CT or MR scans. This
paper illustrates the entire workflow for building the data set MedPix 2.0.
Starting from the well-known multimodal data set MedPix, mainly used by
physicians, nurses and healthcare students for Continuing Medical Education
purposes, a semi-automatic pipeline was developed to extract visual and textual
data followed by a manual curing procedure where noisy samples were removed,
thus creating a MongoDB database. Along with the data set, we developed a GUI
aimed at navigating efficiently the MongoDB instance, and obtaining the raw
data that can be easily used for training and/or fine-tuning LMMs. To enforce
this point, we also propose a CLIP-based model trained on MedPix 2.0 for
scanning modality and location classification tasks. MedPix 2.0 is available on
GitHub",2024-07-03,2024,2024-07,medical
"MiniGPT-Med: Large Language Model as a General Interface for Radiology
  Diagnosis","Recent advancements in artificial intelligence (AI) have precipitated
significant breakthroughs in healthcare, particularly in refining diagnostic
procedures. However, previous studies have often been constrained to limited
functionalities. This study introduces MiniGPT-Med, a vision-language model
derived from large-scale language models and tailored for medical applications.
MiniGPT-Med demonstrates remarkable versatility across various imaging
modalities, including X-rays, CT scans, and MRIs, enhancing its utility. The
model is capable of performing tasks such as medical report generation, visual
question answering (VQA), and disease identification within medical imagery.
Its integrated processing of both image and textual clinical data markedly
improves diagnostic accuracy. Our empirical assessments confirm MiniGPT-Med's
superior performance in disease grounding, medical report generation, and VQA
benchmarks, representing a significant step towards reducing the gap in
assisting radiology practice. Furthermore, it achieves state-of-the-art
performance on medical report generation, higher than the previous best model
by 19\% accuracy. MiniGPT-Med promises to become a general interface for
radiology diagnoses, enhancing diagnostic efficiency across a wide range of
medical imaging applications.",2024-07-04,2024,2024-07,medical
"PubTrend: General Overview of Artificial Intelligence for Colorectal
  cancer diagnosis from 2010-2022","Colorectal cancer (CRC) is among the most prevalent cancers in the world. Due
to numerous scholarly papers and broad enquiries about specific use cases for
artificial intelligence (AI) in colorectal cancer, researchers find it
challenging to explore relevant papers on the current knowledge, comprehensive
knowledge, and past methodologies in the literature review. This review
extracts recent AI technology advances for diagnosing colorectal cancer from
January 2010 to March 2022. PubTrends was used to identify and automate the
intellectual structure and comparable papers on the use of AI in colorectal
cancer diagnosis using the most cited papers, keywords, and similar papers.
Papers with quantitative results were represented with a tabular summary, and
other paper contributions were in a sentence summary. Twenty-four (24) out of
the forty-nine (49) top-cited papers were quantitative results, with one (1)
outlier about lung cancer comprehensive screening. The most frequently used
words were: ""polyps,"" ""detected"", ""image,"" and ""colonoscopy."" In addition, 83
per cent of the terms frequently used shortly before 2022 were image, polyps,
detected, colonoscopy, and learning. In addition, 16 per cent are preparation,
variant, classification, sample, and surgery. The review showcases 49 of the 50
most cited papers, their notable contributions, objectives, specific AI
methods, results, conclusions, and further recommendations. These papers
highlight the limitations of colonoscopy for therapeutic use. The review
concluded that despite the enormous benefits of using artificial intelligence,
from improving diagnosis, the medical AI programmer still needs to be actively
involved in the diagnosis team for effective results in CRC diagnosis.",2024-07-06,2024,2024-07,medical
"Integrating AI in College Education: Positive yet Mixed Experiences with
  ChatGPT","The integration of artificial intelligence (AI) chatbots into higher
education marks a shift towards a new generation of pedagogical tools,
mirroring the arrival of milestones like the internet. With the launch of
ChatGPT-4 Turbo in November 2023, we developed a ChatGPT-based teaching
application (https://chat.openai.com/g/g-1imx1py4K-chatge-medical-imaging) and
integrated it into our undergraduate medical imaging course in the Spring 2024
semester. This study investigates the use of ChatGPT throughout a semester-long
trial, providing insights into students' engagement, perception, and the
overall educational effectiveness of the technology. We systematically
collected and analyzed data concerning students' interaction with ChatGPT,
focusing on their attitudes, concerns, and usage patterns. The findings
indicate that ChatGPT offers significant advantages such as improved
information access and increased interactivity, but its adoption is accompanied
by concerns about the accuracy of the information provided and the necessity
for well-defined guidelines to optimize its use.",2024-07-08,2024,2024-07,medical
"Potential of Multimodal Large Language Models for Data Mining of Medical
  Images and Free-text Reports","Medical images and radiology reports are crucial for diagnosing medical
conditions, highlighting the importance of quantitative analysis for clinical
decision-making. However, the diversity and cross-source heterogeneity of these
data challenge the generalizability of current data-mining methods. Multimodal
large language models (MLLMs) have recently transformed many domains,
significantly affecting the medical field. Notably, Gemini-Vision-series
(Gemini) and GPT-4-series (GPT-4) models have epitomized a paradigm shift in
Artificial General Intelligence (AGI) for computer vision, showcasing their
potential in the biomedical domain. In this study, we evaluated the performance
of the Gemini, GPT-4, and 4 popular large models for an exhaustive evaluation
across 14 medical imaging datasets, including 5 medical imaging categories
(dermatology, radiology, dentistry, ophthalmology, and endoscopy), and 3
radiology report datasets. The investigated tasks encompass disease
classification, lesion segmentation, anatomical localization, disease
diagnosis, report generation, and lesion detection. Our experimental results
demonstrated that Gemini-series models excelled in report generation and lesion
detection but faces challenges in disease classification and anatomical
localization. Conversely, GPT-series models exhibited proficiency in lesion
segmentation and anatomical localization but encountered difficulties in
disease diagnosis and lesion detection. Additionally, both the Gemini series
and GPT series contain models that have demonstrated commendable generation
efficiency. While both models hold promise in reducing physician workload,
alleviating pressure on limited healthcare resources, and fostering
collaboration between clinical practitioners and artificial intelligence
technologies, substantial enhancements and comprehensive validations remain
imperative before clinical deployment.",2024-07-08,2024,2024-07,medical
"Promoting AI Competencies for Medical Students: A Scoping Review on
  Frameworks, Programs, and Tools","As more clinical workflows continue to be augmented by artificial
intelligence (AI), AI literacy among physicians will become a critical
requirement for ensuring safe and ethical AI-enabled patient care. Despite the
evolving importance of AI in healthcare, the extent to which it has been
adopted into traditional and often-overloaded medical curricula is currently
unknown. In a scoping review of 1,699 articles published between January 2016
and June 2024, we identified 18 studies which propose guiding frameworks, and
11 studies documenting real-world instruction, centered around the integration
of AI into medical education. We found that comprehensive guidelines will
require greater clinical relevance and personalization to suit medical student
interests and career trajectories. Current efforts highlight discrepancies in
the teaching guidelines, emphasizing AI evaluation and ethics over technical
topics such as data science and coding. Additionally, we identified several
challenges associated with integrating AI training into the medical education
program, including a lack of guidelines to define medical students AI literacy,
a perceived lack of proven clinical value, and a scarcity of qualified
instructors. With this knowledge, we propose an AI literacy framework to define
competencies for medical students. To prioritize relevant and personalized AI
education, we categorize literacy into four dimensions: Foundational,
Practical, Experimental, and Ethical, with tailored learning objectives to the
pre-clinical, clinical, and clinical research stages of medical education. This
review provides a road map for developing practical and relevant education
strategies for building an AI-competent healthcare workforce.",2024-07-10,2024,2024-07,medical
Weakly-supervised Medical Image Segmentation with Gaze Annotations,"Eye gaze that reveals human observational patterns has increasingly been
incorporated into solutions for vision tasks. Despite recent explorations on
leveraging gaze to aid deep networks, few studies exploit gaze as an efficient
annotation approach for medical image segmentation which typically entails
heavy annotating costs. In this paper, we propose to collect dense weak
supervision for medical image segmentation with a gaze annotation scheme. To
train with gaze, we propose a multi-level framework that trains multiple
networks from discriminative human attention, simulated with a set of
pseudo-masks derived by applying hierarchical thresholds on gaze heatmaps.
Furthermore, to mitigate gaze noise, a cross-level consistency is exploited to
regularize overfitting noisy labels, steering models toward clean patterns
learned by peer networks. The proposed method is validated on two public
medical datasets of polyp and prostate segmentation tasks. We contribute a
high-quality gaze dataset entitled GazeMedSeg as an extension to the popular
medical segmentation datasets. To the best of our knowledge, this is the first
gaze dataset for medical image segmentation. Our experiments demonstrate that
gaze annotation outperforms previous label-efficient annotation schemes in
terms of both performance and annotation time. Our collected gaze data and code
are available at: https://github.com/med-air/GazeMedSeg.",2024-07-10,2024,2024-07,medical
"FedMedICL: Towards Holistic Evaluation of Distribution Shifts in
  Federated Medical Imaging","For medical imaging AI models to be clinically impactful, they must
generalize. However, this goal is hindered by (i) diverse types of distribution
shifts, such as temporal, demographic, and label shifts, and (ii) limited
diversity in datasets that are siloed within single medical institutions. While
these limitations have spurred interest in federated learning, current
evaluation benchmarks fail to evaluate different shifts simultaneously.
However, in real healthcare settings, multiple types of shifts co-exist, yet
their impact on medical imaging performance remains unstudied. In response, we
introduce FedMedICL, a unified framework and benchmark to holistically evaluate
federated medical imaging challenges, simultaneously capturing label,
demographic, and temporal distribution shifts. We comprehensively evaluate
several popular methods on six diverse medical imaging datasets (totaling 550
GPU hours). Furthermore, we use FedMedICL to simulate COVID-19 propagation
across hospitals and evaluate whether methods can adapt to pandemic changes in
disease prevalence. We find that a simple batch balancing technique surpasses
advanced methods in average performance across FedMedICL experiments. This
finding questions the applicability of results from previous, narrow benchmarks
in real-world medical settings.",2024-07-11,2024,2024-07,medical
"Explainable artificial intelligence in breast cancer detection and risk
  prediction: A systematic scoping review","With the advances in artificial intelligence (AI), data-driven algorithms are
becoming increasingly popular in the medical domain. However, due to the
nonlinear and complex behavior of many of these algorithms, decision-making by
such algorithms is not trustworthy for clinicians and is considered a black-box
process. Hence, the scientific community has introduced explainable artificial
intelligence (XAI) to remedy the problem. This systematic scoping review
investigates the application of XAI in breast cancer detection and risk
prediction. We conducted a comprehensive search on Scopus, IEEE Explore,
PubMed, and Google Scholar (first 50 citations) using a systematic search
strategy. The search spanned from January 2017 to July 2023, focusing on
peer-reviewed studies implementing XAI methods in breast cancer datasets.
Thirty studies met our inclusion criteria and were included in the analysis.
The results revealed that SHapley Additive exPlanations (SHAP) is the top
model-agnostic XAI technique in breast cancer research in terms of usage,
explaining the model prediction results, diagnosis and classification of
biomarkers, and prognosis and survival analysis. Additionally, the SHAP model
primarily explained tree-based ensemble machine learning models. The most
common reason is that SHAP is model agnostic, which makes it both popular and
useful for explaining any model prediction. Additionally, it is relatively easy
to implement effectively and completely suits performant models, such as
tree-based models. Explainable AI improves the transparency, interpretability,
fairness, and trustworthiness of AI-enabled health systems and medical devices
and, ultimately, the quality of care and outcomes.",2024-07-12,2024,2024-07,medical
"Fine-Tuning Medical Language Models for Enhanced Long-Contextual
  Understanding and Domain Expertise","Large Language Models (LLMs) have been widely applied in various professional
fields. By fine-tuning the models using domain specific question and answer
datasets, the professional domain knowledge and Q\&A abilities of these models
have significantly improved, for example, medical professional LLMs that use
fine-tuning of doctor-patient Q\&A data exhibit extraordinary disease
diagnostic abilities. However, we observed that despite improvements in
specific domain knowledge, the performance of medical LLM in long-context
understanding has significantly declined, especially compared to general
language models with similar parameters. The purpose of this study is to
investigate the phenomenon of reduced performance in understanding long-context
in medical LLM. We designed a series of experiments to conduct open-book
professional knowledge exams on all models to evaluate their ability to read
long-context. By adjusting the proportion and quantity of general data and
medical data in the process of fine-tuning, we can determine the best data
composition to optimize the professional model and achieve a balance between
long-context performance and specific domain knowledge.",2024-07-16,2024,2024-07,medical
"LLMs-in-the-loop Part-1: Expert Small AI Models for Bio-Medical Text
  Translation","Machine translation is indispensable in healthcare for enabling the global
dissemination of medical knowledge across languages. However, complex medical
terminology poses unique challenges to achieving adequate translation quality
and accuracy. This study introduces a novel ""LLMs-in-the-loop"" approach to
develop supervised neural machine translation models optimized specifically for
medical texts. While large language models (LLMs) have demonstrated powerful
capabilities, this research shows that small, specialized models trained on
high-quality in-domain (mostly synthetic) data can outperform even vastly
larger LLMs.
  Custom parallel corpora in six languages were compiled from scientific
articles, synthetically generated clinical documents, and medical texts. Our
LLMs-in-the-loop methodology employs synthetic data generation, rigorous
evaluation, and agent orchestration to enhance performance. We developed small
medical translation models using the MarianMT base model. We introduce a new
medical translation test dataset to standardize evaluation in this domain.
Assessed using BLEU, METEOR, ROUGE, and BERT scores on this test set, our
MarianMT-based models outperform Google Translate, DeepL, and GPT-4-Turbo.
  Results demonstrate that our LLMs-in-the-loop approach, combined with
fine-tuning high-quality, domain-specific data, enables specialized models to
outperform general-purpose and some larger systems. This research, part of a
broader series on expert small models, paves the way for future
healthcare-related AI developments, including deidentification and bio-medical
entity extraction models. Our study underscores the potential of tailored
neural translation models and the LLMs-in-the-loop methodology to advance the
field through improved data generation, evaluation, agent, and modeling
techniques.",2024-07-16,2024,2024-07,medical
"Applying Conditional Generative Adversarial Networks for Imaging
  Diagnosis","This study introduces an innovative application of Conditional Generative
Adversarial Networks (C-GAN) integrated with Stacked Hourglass Networks (SHGN)
aimed at enhancing image segmentation, particularly in the challenging
environment of medical imaging. We address the problem of overfitting, common
in deep learning models applied to complex imaging datasets, by augmenting data
through rotation and scaling. A hybrid loss function combining L1 and L2
reconstruction losses, enriched with adversarial training, is introduced to
refine segmentation processes in intravascular ultrasound (IVUS) imaging. Our
approach is unique in its capacity to accurately delineate distinct regions
within medical images, such as tissue boundaries and vascular structures,
without extensive reliance on domain-specific knowledge. The algorithm was
evaluated using a standard medical image library, showing superior performance
metrics compared to existing methods, thereby demonstrating its potential in
enhancing automated medical diagnostics through deep learning",2024-07-17,2024,2024-07,medical
"Addressing Imbalance for Class Incremental Learning in Medical Image
  Classification","Deep convolutional neural networks have made significant breakthroughs in
medical image classification, under the assumption that training samples from
all classes are simultaneously available. However, in real-world medical
scenarios, there's a common need to continuously learn about new diseases,
leading to the emerging field of class incremental learning (CIL) in the
medical domain. Typically, CIL suffers from catastrophic forgetting when
trained on new classes. This phenomenon is mainly caused by the imbalance
between old and new classes, and it becomes even more challenging with
imbalanced medical datasets. In this work, we introduce two simple yet
effective plug-in methods to mitigate the adverse effects of the imbalance.
First, we propose a CIL-balanced classification loss to mitigate the classifier
bias toward majority classes via logit adjustment. Second, we propose a
distribution margin loss that not only alleviates the inter-class overlap in
embedding space but also enforces the intra-class compactness. We evaluate the
effectiveness of our method with extensive experiments on three benchmark
datasets (CCH5000, HAM10000, and EyePACS). The results demonstrate that our
approach outperforms state-of-the-art methods.",2024-07-18,2024,2024-07,medical
"MedSAGa: Few-shot Memory Efficient Medical Image Segmentation using
  Gradient Low-Rank Projection in SAM","The application of large-scale models in medical image segmentation demands
substantial quantities of meticulously annotated data curated by experts along
with high computational resources, both of which are challenges in
resource-poor settings. In this study, we present the Medical Segment Anything
Model with Galore MedSAGa where we adopt the Segment Anything Model (SAM) to
achieve memory-efficient, few-shot medical image segmentation by applying
Gradient Low-Rank Projection GaLore to the parameters of the image encoder of
SAM. Meanwhile, the weights of the prompt encoder and mask decoder undergo full
parameter fine-tuning using standard optimizers. We further assess MedSAGa's
few-shot learning capabilities, reporting on its memory efficiency and
segmentation performance across multiple standard medical image segmentation
datasets. We compare it with several baseline models, including LoRA fine-tuned
SAM (SAMed) and DAE-Former. Experiments across multiple datasets and these
baseline models with different number of images for fine tuning demonstrated
that the GPU memory consumption of MedSAGa is significantly less than that of
the baseline models, achieving an average memory efficiency of 66% more than
current state-of-the-art (SOTA) models for medical image segmentation. The
combination of substantially lower memory requirements and comparable to SOTA
results in few-shot learning for medical image segmentation positions MedSAGa
as an optimal solution for deployment in resource-constrained settings.",2024-07-21,2024,2024-07,medical
"MiranDa: Mimicking the Learning Processes of Human Doctors to Achieve
  Causal Inference for Medication Recommendation","To enhance therapeutic outcomes from a pharmacological perspective, we
propose MiranDa, designed for medication recommendation, which is the first
actionable model capable of providing the estimated length of stay in hospitals
(ELOS) as counterfactual outcomes that guide clinical practice and model
training. In detail, MiranDa emulates the educational trajectory of doctors
through two gradient-scaling phases shifted by ELOS: an Evidence-based Training
Phase that utilizes supervised learning and a Therapeutic Optimization Phase
grounds in reinforcement learning within the gradient space, explores optimal
medications by perturbations from ELOS. Evaluation of the Medical Information
Mart for Intensive Care III dataset and IV dataset, showcased the superior
results of our model across five metrics, particularly in reducing the ELOS.
Surprisingly, our model provides structural attributes of medication
combinations proved in hyperbolic space and advocated ""procedure-specific""
medication combinations. These findings posit that MiranDa enhanced medication
efficacy. Notably, our paradigm can be applied to nearly all medical tasks and
those with information to evaluate predicted outcomes. The source code of the
MiranDa model is available at https://github.com/azusakou/MiranDa.",2024-07-23,2024,2024-07,medical
Prompt Injection Attacks on Large Language Models in Oncology,"Vision-language artificial intelligence models (VLMs) possess medical
knowledge and can be employed in healthcare in numerous ways, including as
image interpreters, virtual scribes, and general decision support systems.
However, here, we demonstrate that current VLMs applied to medical tasks
exhibit a fundamental security flaw: they can be attacked by prompt injection
attacks, which can be used to output harmful information just by interacting
with the VLM, without any access to its parameters. We performed a quantitative
study to evaluate the vulnerabilities to these attacks in four state of the art
VLMs which have been proposed to be of utility in healthcare: Claude 3 Opus,
Claude 3.5 Sonnet, Reka Core, and GPT-4o. Using a set of N=297 attacks, we show
that all of these models are susceptible. Specifically, we show that embedding
sub-visual prompts in medical imaging data can cause the model to provide
harmful output, and that these prompts are non-obvious to human observers.
Thus, our study demonstrates a key vulnerability in medical VLMs which should
be mitigated before widespread clinical adoption.",2024-07-23,2024,2024-07,medical
"An Active Inference Strategy for Prompting Reliable Responses from Large
  Language Models in Medical Practice","Continuing advances in Large Language Models (LLMs) in artificial
intelligence offer important capacities in intuitively accessing and using
medical knowledge in many contexts, including education and training as well as
assessment and treatment. Most of the initial literature on LLMs in medicine
has emphasized that LLMs are unsuitable for medical use because they are
non-deterministic, may provide incorrect or harmful responses, and cannot be
regulated to assure quality control. If these issues could be corrected,
optimizing LLM technology could benefit patients and physicians by providing
affordable, point-of-care medical knowledge. Our proposed framework refines LLM
responses by restricting their primary knowledge base to domain-specific
datasets containing validated medical information. Additionally, we introduce
an actor-critic LLM prompting protocol based on active inference principles of
human cognition, where a Therapist agent initially responds to patient queries,
and a Supervisor agent evaluates and adjusts responses to ensure accuracy and
reliability. We conducted a validation study where expert cognitive behaviour
therapy for insomnia (CBT-I) therapists evaluated responses from the LLM in a
blind format. Experienced human CBT-I therapists assessed responses to 100
patient queries, comparing LLM-generated responses with appropriate and
inappropriate responses crafted by experienced CBT-I therapists. Results showed
that LLM responses received high ratings from the CBT-I therapists, often
exceeding those of therapist-generated appropriate responses. This structured
approach aims to integrate advanced LLM technology into medical applications,
meeting regulatory requirements for establishing the safe and effective use of
special purpose validated LLMs in medicine.",2024-07-23,2024,2024-07,medical
"Open Challenges on Fairness of Artificial Intelligence in Medical
  Imaging Applications","Recently, the research community of computerized medical imaging has started
to discuss and address potential fairness issues that may emerge when
developing and deploying AI systems for medical image analysis. This chapter
covers some of the pressing challenges encountered when doing research in this
area, and it is intended to raise questions and provide food for thought for
those aiming to enter this research field. The chapter first discusses various
sources of bias, including data collection, model training, and clinical
deployment, and their impact on the fairness of machine learning algorithms in
medical image computing. We then turn to discussing open challenges that we
believe require attention from researchers and practitioners, as well as
potential pitfalls of naive application of common methods in the field. We
cover a variety of topics including the impact of biased metrics when auditing
for fairness, the leveling down effect, task difficulty variations among
subgroups, discovering biases in unseen populations, and explaining biases
beyond standard demographic attributes.",2024-07-24,2024,2024-07,medical
Yucca: A Deep Learning Framework For Medical Image Analysis,"Medical image analysis using deep learning frameworks has advanced healthcare
by automating complex tasks, but many existing frameworks lack flexibility,
modularity, and user-friendliness. To address these challenges, we introduce
Yucca, an open-source AI framework available at
https://github.com/Sllambias/yucca, designed specifically for medical imaging
applications and built on PyTorch and PyTorch Lightning. Yucca features a
three-tiered architecture: Functional, Modules, and Pipeline, providing a
comprehensive and customizable solution. Evaluated across diverse tasks such as
cerebral microbleeds detection, white matter hyperintensity segmentation, and
hippocampus segmentation, Yucca achieves state-of-the-art results,
demonstrating its robustness and versatility. Yucca offers a powerful,
flexible, and user-friendly platform for medical image analysis, inviting
community contributions to advance its capabilities and impact.",2024-07-29,2024,2024-07,medical
Robust Conformal Volume Estimation in 3D Medical Images,"Volumetry is one of the principal downstream applications of 3D medical image
segmentation, for example, to detect abnormal tissue growth or for surgery
planning. Conformal Prediction is a promising framework for uncertainty
quantification, providing calibrated predictive intervals associated with
automatic volume measurements. However, this methodology is based on the
hypothesis that calibration and test samples are exchangeable, an assumption
that is in practice often violated in medical image applications. A weighted
formulation of Conformal Prediction can be framed to mitigate this issue, but
its empirical investigation in the medical domain is still lacking. A potential
reason is that it relies on the estimation of the density ratio between the
calibration and test distributions, which is likely to be intractable in
scenarios involving high-dimensional data. To circumvent this, we propose an
efficient approach for density ratio estimation relying on the compressed
latent representations generated by the segmentation model. Our experiments
demonstrate the efficiency of our approach to reduce the coverage error in the
presence of covariate shifts, in both synthetic and real-world settings. Our
implementation is available at https://github.com/benolmbrt/wcp_miccai",2024-07-29,2024,2024-07,medical
"S-SYNTH: Knowledge-Based, Synthetic Generation of Skin Images","Development of artificial intelligence (AI) techniques in medical imaging
requires access to large-scale and diverse datasets for training and
evaluation. In dermatology, obtaining such datasets remains challenging due to
significant variations in patient populations, illumination conditions, and
acquisition system characteristics. In this work, we propose S-SYNTH, the first
knowledge-based, adaptable open-source skin simulation framework to rapidly
generate synthetic skin, 3D models and digitally rendered images, using an
anatomically inspired multi-layer, multi-component skin and growing lesion
model. The skin model allows for controlled variation in skin appearance, such
as skin color, presence of hair, lesion shape, and blood fraction among other
parameters. We use this framework to study the effect of possible variations on
the development and evaluation of AI models for skin lesion segmentation, and
show that results obtained using synthetic data follow similar comparative
trends as real dermatologic images, while mitigating biases and limitations
from existing datasets including small dataset size, lack of diversity, and
underrepresentation.",2024-07-31,2024,2024-07,medical
"Enhanced Uncertainty Estimation in Ultrasound Image Segmentation with
  MSU-Net","Efficient intravascular access in trauma and critical care significantly
impacts patient outcomes. However, the availability of skilled medical
personnel in austere environments is often limited. Autonomous robotic
ultrasound systems can aid in needle insertion for medication delivery and
support non-experts in such tasks. Despite advances in autonomous needle
insertion, inaccuracies in vessel segmentation predictions pose risks.
Understanding the uncertainty of predictive models in ultrasound imaging is
crucial for assessing their reliability. We introduce MSU-Net, a novel
multistage approach for training an ensemble of U-Nets to yield accurate
ultrasound image segmentation maps. We demonstrate substantial improvements,
18.1% over a single Monte Carlo U-Net, enhancing uncertainty evaluations, model
transparency, and trustworthiness. By highlighting areas of model certainty,
MSU-Net can guide safe needle insertions, empowering non-experts to accomplish
such tasks.",2024-07-31,2024,2024-07,medical
"MIST: A Simple and Scalable End-To-End 3D Medical Imaging Segmentation
  Framework","Medical imaging segmentation is a highly active area of research, with deep
learning-based methods achieving state-of-the-art results in several
benchmarks. However, the lack of standardized tools for training, testing, and
evaluating new methods makes the comparison of methods difficult. To address
this, we introduce the Medical Imaging Segmentation Toolkit (MIST), a simple,
modular, and end-to-end medical imaging segmentation framework designed to
facilitate consistent training, testing, and evaluation of deep learning-based
medical imaging segmentation methods. MIST standardizes data analysis,
preprocessing, and evaluation pipelines, accommodating multiple architectures
and loss functions. This standardization ensures reproducible and fair
comparisons across different methods. We detail MIST's data format
requirements, pipelines, and auxiliary features and demonstrate its efficacy
using the BraTS Adult Glioma Post-Treatment Challenge dataset. Our results
highlight MIST's ability to produce accurate segmentation masks and its
scalability across multiple GPUs, showcasing its potential as a powerful tool
for future medical imaging research and development.",2024-07-31,2024,2024-07,medical
"Advancing Medical Image Segmentation: Morphology-Driven Learning with
  Diffusion Transformer","Understanding the morphological structure of medical images and precisely
segmenting the region of interest or abnormality is an important task that can
assist in diagnosis. However, the unique properties of medical imaging make
clear segmentation difficult,and the high cost and time-consuming task of
labeling leads to a coarse-grained representation of ground truth. Facing with
these problems, we propose a novel Diffusion Transformer Segmentation (DTS)
model for robust segmentation in the presence of noise. We propose an
alternative to the dominant Denoising U-Net encoder through experiments
applying a transformer architecture, which captures global dependency through
self-attention. Additionally, we propose k-neighbor label smoothing, reverse
boundary attention, and self-supervised learning with morphology-driven
learning to improve the ability to identify complex structures. Our model,
which analyzes the morphological representation of images, shows better results
than the previous models in various medical imaging modalities, including CT,
MRI, and lesion images.",2024-08-01,2024,2024-08,medical
"Securing the Diagnosis of Medical Imaging: An In-depth Analysis of
  AI-Resistant Attacks","Machine learning (ML) is a rapidly developing area of medicine that uses
significant resources to apply computer science and statistics to medical
issues. ML's proponents laud its capacity to handle vast, complicated, and
erratic medical data. It's common knowledge that attackers might cause
misclassification by deliberately creating inputs for machine learning
classifiers. Research on adversarial examples has been extensively conducted in
the field of computer vision applications. Healthcare systems are thought to be
highly difficult because of the security and life-or-death considerations they
include, and performance accuracy is very important. Recent arguments have
suggested that adversarial attacks could be made against medical image analysis
(MedIA) technologies because of the accompanying technology infrastructure and
powerful financial incentives. Since the diagnosis will be the basis for
important decisions, it is essential to assess how strong medical DNN tasks are
against adversarial attacks. Simple adversarial attacks have been taken into
account in several earlier studies. However, DNNs are susceptible to more risky
and realistic attacks. The present paper covers recent proposed adversarial
attack strategies against DNNs for medical imaging as well as countermeasures.
In this study, we review current techniques for adversarial imaging attacks,
detections. It also encompasses various facets of these techniques and offers
suggestions for the robustness of neural networks to be improved in the future.",2024-08-01,2024,2024-08,medical
"More Than Positive and Negative: Communicating Fine Granularity in
  Medical Diagnosis","With the advance of deep learning, much progress has been made in building
powerful artificial intelligence (AI) systems for automatic Chest X-ray (CXR)
analysis. Most existing AI models are trained to be a binary classifier with
the aim of distinguishing positive and negative cases. However, a large gap
exists between the simple binary setting and complicated real-world medical
scenarios. In this work, we reinvestigate the problem of automatic radiology
diagnosis. We first observe that there is considerable diversity among cases
within the positive class, which means simply classifying them as positive
loses many important details. This motivates us to build AI models that can
communicate fine-grained knowledge from medical images like human experts. To
this end, we first propose a new benchmark on fine granularity learning from
medical images. Specifically, we devise a division rule based on medical
knowledge to divide positive cases into two subcategories, namely atypical
positive and typical positive. Then, we propose a new metric termed
AUC$^\text{FG}$ on the two subcategories for evaluation of the ability to
separate them apart. With the proposed benchmark, we encourage the community to
develop AI diagnosis systems that could better learn fine granularity from
medical images. Last, we propose a simple risk modulation approach to this
problem by only using coarse labels in training. Empirical results show that
despite its simplicity, the proposed method achieves superior performance and
thus serves as a strong baseline.",2024-08-05,2024,2024-08,medical
"Enhancing Healthcare through Large Language Models: A Study on Medical
  Question Answering","In recent years, the application of Large Language Models (LLMs) in
healthcare has shown significant promise in improving the accessibility and
dissemination of medical knowledge. This paper presents a detailed study of
various LLMs trained on the MedQuAD medical question-answering dataset, with a
focus on identifying the most effective model for providing accurate medical
information. Among the models tested, the Sentence-t5 combined with Mistral 7B
demonstrated superior performance, achieving a precision score of 0.762. This
model's enhanced capabilities are attributed to its advanced pretraining
techniques, robust architecture, and effective prompt construction
methodologies. By leveraging these strengths, the Sentence-t5 + Mistral 7B
model excels in understanding and generating precise medical answers. Our
findings highlight the potential of integrating sophisticated LLMs in medical
contexts to facilitate efficient and accurate medical knowledge retrieval, thus
significantly enhancing patient education and support.",2024-08-08,2024,2024-08,medical
"People over trust AI-generated medical responses and view them to be as
  valid as doctors, despite low accuracy","This paper presents a comprehensive analysis of how AI-generated medical
responses are perceived and evaluated by non-experts. A total of 300
participants gave evaluations for medical responses that were either written by
a medical doctor on an online healthcare platform, or generated by a large
language model and labeled by physicians as having high or low accuracy.
Results showed that participants could not effectively distinguish between
AI-generated and Doctors' responses and demonstrated a preference for
AI-generated responses, rating High Accuracy AI-generated responses as
significantly more valid, trustworthy, and complete/satisfactory. Low Accuracy
AI-generated responses on average performed very similar to Doctors' responses,
if not more. Participants not only found these low-accuracy AI-generated
responses to be valid, trustworthy, and complete/satisfactory but also
indicated a high tendency to follow the potentially harmful medical advice and
incorrectly seek unnecessary medical attention as a result of the response
provided. This problematic reaction was comparable if not more to the reaction
they displayed towards doctors' responses. This increased trust placed on
inaccurate or inappropriate AI-generated medical advice can lead to
misdiagnosis and harmful consequences for individuals seeking help. Further,
participants were more trusting of High Accuracy AI-generated responses when
told they were given by a doctor and experts rated AI-generated responses
significantly higher when the source of the response was unknown. Both experts
and non-experts exhibited bias, finding AI-generated responses to be more
thorough and accurate than Doctors' responses but still valuing the involvement
of a Doctor in the delivery of their medical advice. Ensuring AI systems are
implemented with medical professionals should be the future of using AI for the
delivery of medical advice.",2024-08-11,2024,2024-08,medical
"Automated Retinal Image Analysis and Medical Report Generation through
  Deep Learning","The increasing prevalence of retinal diseases poses a significant challenge
to the healthcare system, as the demand for ophthalmologists surpasses the
available workforce. This imbalance creates a bottleneck in diagnosis and
treatment, potentially delaying critical care. Traditional methods of
generating medical reports from retinal images rely on manual interpretation,
which is time-consuming and prone to errors, further straining
ophthalmologists' limited resources. This thesis investigates the potential of
Artificial Intelligence (AI) to automate medical report generation for retinal
images. AI can quickly analyze large volumes of image data, identifying subtle
patterns essential for accurate diagnosis. By automating this process, AI
systems can greatly enhance the efficiency of retinal disease diagnosis,
reducing doctors' workloads and enabling them to focus on more complex cases.
The proposed AI-based methods address key challenges in automated report
generation: (1) Improved methods for medical keyword representation enhance the
system's ability to capture nuances in medical terminology; (2) A multi-modal
deep learning approach captures interactions between textual keywords and
retinal images, resulting in more comprehensive medical reports; (3) Techniques
to enhance the interpretability of the AI-based report generation system,
fostering trust and acceptance in clinical practice. These methods are
rigorously evaluated using various metrics and achieve state-of-the-art
performance. This thesis demonstrates AI's potential to revolutionize retinal
disease diagnosis by automating medical report generation, ultimately improving
clinical efficiency, diagnostic accuracy, and patient care.
[https://github.com/Jhhuangkay/DeepOpht-Medical-Report-Generation-for-Retinal-Images-via-Deep-Models-and-Visual-Explanation]",2024-08-14,2024,2024-08,medical
"Navigating Data Scarcity using Foundation Models: A Benchmark of
  Few-Shot and Zero-Shot Learning Approaches in Medical Imaging","Data scarcity is a major limiting factor for applying modern machine learning
techniques to clinical tasks. Although sufficient data exists for some
well-studied medical tasks, there remains a long tail of clinically relevant
tasks with poor data availability. Recently, numerous foundation models have
demonstrated high suitability for few-shot learning (FSL) and zero-shot
learning (ZSL), potentially making them more accessible to practitioners.
However, it remains unclear which foundation model performs best on FSL medical
image analysis tasks and what the optimal methods are for learning from limited
data. We conducted a comprehensive benchmark study of ZSL and FSL using 16
pretrained foundation models on 19 diverse medical imaging datasets. Our
results indicate that BiomedCLIP, a model pretrained exclusively on medical
data, performs best on average for very small training set sizes, while very
large CLIP models pretrained on LAION-2B perform best with slightly more
training samples. However, simply fine-tuning a ResNet-18 pretrained on
ImageNet performs similarly with more than five training examples per class.
Our findings also highlight the need for further research on foundation models
specifically tailored for medical applications and the collection of more
datasets to train these models.",2024-08-15,2024,2024-08,medical
"A Disease-Specific Foundation Model Using Over 100K Fundus Images:
  Release and Validation for Abnormality and Multi-Disease Classification on
  Downstream Tasks","Artificial intelligence applied to retinal images offers significant
potential for recognizing signs and symptoms of retinal conditions and
expediting the diagnosis of eye diseases and systemic disorders. However,
developing generalized artificial intelligence models for medical data often
requires a large number of labeled images representing various disease signs,
and most models are typically task-specific, focusing on major retinal
diseases. In this study, we developed a Fundus-Specific Pretrained Model
(Image+Fundus), a supervised artificial intelligence model trained to detect
abnormalities in fundus images. A total of 57,803 images were used to develop
this pretrained model, which achieved superior performance across various
downstream tasks, indicating that our proposed model outperforms other general
methods. Our Image+Fundus model offers a generalized approach to improve model
performance while reducing the number of labeled datasets required.
Additionally, it provides more disease-specific insights into fundus images,
with visualizations generated by our model. These disease-specific foundation
models are invaluable in enhancing the performance and efficiency of deep
learning models in the field of fundus imaging.",2024-08-16,2024,2024-08,medical
"FEDKIM: Adaptive Federated Knowledge Injection into Medical Foundation
  Models","Foundation models have demonstrated remarkable capabilities in handling
diverse modalities and tasks, outperforming conventional artificial
intelligence (AI) approaches that are highly task-specific and
modality-reliant. In the medical domain, however, the development of
comprehensive foundation models is constrained by limited access to diverse
modalities and stringent privacy regulations. To address these constraints,
this study introduces a novel knowledge injection approach, FedKIM, designed to
scale the medical foundation model within a federated learning framework.
FedKIM leverages lightweight local models to extract healthcare knowledge from
private data and integrates this knowledge into a centralized foundation model
using a designed adaptive Multitask Multimodal Mixture Of Experts (M3OE)
module. This method not only preserves privacy but also enhances the model's
ability to handle complex medical tasks involving multiple modalities. Our
extensive experiments across twelve tasks in seven modalities demonstrate the
effectiveness of FedKIM in various settings, highlighting its potential to
scale medical foundation models without direct access to sensitive data.",2024-08-17,2024,2024-08,medical
"FEDMEKI: A Benchmark for Scaling Medical Foundation Models via Federated
  Knowledge Injection","This study introduces the Federated Medical Knowledge Injection (FEDMEKI)
platform, a new benchmark designed to address the unique challenges of
integrating medical knowledge into foundation models under privacy constraints.
By leveraging a cross-silo federated learning approach, FEDMEKI circumvents the
issues associated with centralized data collection, which is often prohibited
under health regulations like the Health Insurance Portability and
Accountability Act (HIPAA) in the USA. The platform is meticulously designed to
handle multi-site, multi-modal, and multi-task medical data, which includes 7
medical modalities, including images, signals, texts, laboratory test results,
vital signs, input variables, and output variables. The curated dataset to
validate FEDMEKI covers 8 medical tasks, including 6 classification tasks (lung
opacity detection, COVID-19 detection, electrocardiogram (ECG) abnormal
detection, mortality prediction, sepsis prediction, and enlarged
cardiomediastinum detection) and 2 generation tasks (medical visual question
answering (MedVQA) and ECG noise clarification). This comprehensive dataset is
partitioned across several clients to facilitate the decentralized training
process under 16 benchmark approaches. FEDMEKI not only preserves data privacy
but also enhances the capability of medical foundation models by allowing them
to learn from a broader spectrum of medical knowledge without direct data
exposure, thereby setting a new benchmark in the application of foundation
models within the healthcare sector.",2024-08-17,2024,2024-08,medical
"Tipta uzmanlik sinavinda (tus) buyuk dil modelleri insanlardan daha mi
  basarili?","The potential of artificial intelligence in medical education and assessment
has been made evident by recent developments in natural language processing and
artificial intelligence. Medical questions can now be successfully answered by
artificial intelligence algorithms. It can help medical practitioners. This
study evaluates the performance of three different artificial intelligence
models in answering Turkish medical questions in the 2021 1st Term Medical
Specialization Examination (MSE). MSE consists of a total of 240 questions
across clinical (CMST) and basic (BMST) medical sciences. According to the
results in CMST, it was concluded that Gemini correctly answered 82 questions,
ChatGPT-4 answered 105 questions and ChatGPT-4o answered 117 questions. In
BMST, Gemini and ChatGPT-4 answered 93 questions and ChatGPT-4o answered 107
questions correctly according to the answer key. ChatGPT-4o outperformed the
candidate with the highest scores of 113 and 106 according to CMST and BMST
respectively. This study highlights the importance of the potential of
artificial intelligence in medical education and assessment. It demonstrates
that advanced models can achieve high accuracy and contextual understanding,
demonstrating their potential role in medical education and evaluation.",2024-08-22,2024,2024-08,medical
MultiMed: Massively Multimodal and Multitask Medical Understanding,"Biomedical data is inherently multimodal, consisting of electronic health
records, medical imaging, digital pathology, genome sequencing, wearable
sensors, and more. The application of artificial intelligence tools to these
multifaceted sensing technologies has the potential to revolutionize the
prognosis, diagnosis, and management of human health and disease. However,
current approaches to biomedical AI typically only train and evaluate with one
or a small set of medical modalities and tasks. This limitation hampers the
development of comprehensive tools that can leverage the rich interconnected
information across many heterogeneous biomedical sensors. To address this
challenge, we present MultiMed, a benchmark designed to evaluate and enable
large-scale learning across a wide spectrum of medical modalities and tasks.
MultiMed consists of 2.56 million samples across ten medical modalities such as
medical reports, pathology, genomics, and protein data, and is structured into
eleven challenging tasks, including disease prognosis, protein structure
prediction, and medical question answering. Using MultiMed, we conduct
comprehensive experiments benchmarking state-of-the-art unimodal, multimodal,
and multitask models. Our analysis highlights the advantages of training
large-scale medical models across many related modalities and tasks. Moreover,
MultiMed enables studies of generalization across related medical concepts,
robustness to real-world noisy data and distribution shifts, and novel modality
combinations to improve prediction performance. MultiMed will be publicly
available and regularly updated and welcomes inputs from the community.",2024-08-22,2024,2024-08,medical
"MedDiT: A Knowledge-Controlled Diffusion Transformer Framework for
  Dynamic Medical Image Generation in Virtual Simulated Patient","Medical education relies heavily on Simulated Patients (SPs) to provide a
safe environment for students to practice clinical skills, including medical
image analysis. However, the high cost of recruiting qualified SPs and the lack
of diverse medical imaging datasets have presented significant challenges. To
address these issues, this paper introduces MedDiT, a novel
knowledge-controlled conversational framework that can dynamically generate
plausible medical images aligned with simulated patient symptoms, enabling
diverse diagnostic skill training. Specifically, MedDiT integrates various
patient Knowledge Graphs (KGs), which describe the attributes and symptoms of
patients, to dynamically prompt Large Language Models' (LLMs) behavior and
control the patient characteristics, mitigating hallucination during medical
conversation. Additionally, a well-tuned Diffusion Transformer (DiT) model is
incorporated to generate medical images according to the specified patient
attributes in the KG. In this paper, we present the capabilities of MedDiT
through a practical demonstration, showcasing its ability to act in diverse
simulated patient cases and generate the corresponding medical images. This can
provide an abundant and interactive learning experience for students, advancing
medical education by offering an immersive simulation platform for future
healthcare professionals. The work sheds light on the feasibility of
incorporating advanced technologies like LLM, KG, and DiT in education
applications, highlighting their potential to address the challenges faced in
simulated patient-based medical education.",2024-08-22,2024,2024-08,medical
MEDCO: Medical Education Copilots Based on A Multi-Agent Framework,"Large language models (LLMs) have had a significant impact on diverse
research domains, including medicine and healthcare. However, the potential of
LLMs as copilots in medical education remains underexplored. Current
AI-assisted educational tools are limited by their solitary learning approach
and inability to simulate the multi-disciplinary and interactive nature of
actual medical training. To address these limitations, we propose MEDCO
(Medical EDucation COpilots), a novel multi-agent-based copilot system
specially developed to emulate real-world medical training environments. MEDCO
incorporates three primary agents: an agentic patient, an expert doctor, and a
radiologist, facilitating a multi-modal and interactive learning environment.
Our framework emphasizes the learning of proficient question-asking skills,
multi-disciplinary collaboration, and peer discussions between students. Our
experiments show that simulated virtual students who underwent training with
MEDCO not only achieved substantial performance enhancements comparable to
those of advanced models, but also demonstrated human-like learning behaviors
and improvements, coupled with an increase in the number of learning samples.
This work contributes to medical education by introducing a copilot that
implements an interactive and collaborative learning approach. It also provides
valuable insights into the effectiveness of AI-integrated training paradigms.",2024-08-22,2024,2024-08,medical
Automatic Medical Report Generation: Methods and Applications,"The increasing demand for medical imaging has surpassed the capacity of
available radiologists, leading to diagnostic delays and potential
misdiagnoses. Artificial intelligence (AI) techniques, particularly in
automatic medical report generation (AMRG), offer a promising solution to this
dilemma. This review comprehensively examines AMRG methods from 2021 to 2024.
It (i) presents solutions to primary challenges in this field, (ii) explores
AMRG applications across various imaging modalities, (iii) introduces publicly
available datasets, (iv) outlines evaluation metrics, (v) identifies techniques
that significantly enhance model performance, and (vi) discusses unresolved
issues and potential future research directions. This paper aims to provide a
comprehensive understanding of the existing literature and inspire valuable
future research.",2024-08-26,2024,2024-08,medical
"MEDSAGE: Enhancing Robustness of Medical Dialogue Summarization to ASR
  Errors with LLM-generated Synthetic Dialogues","Automatic Speech Recognition (ASR) systems are pivotal in transcribing speech
into text, yet the errors they introduce can significantly degrade the
performance of downstream tasks like summarization. This issue is particularly
pronounced in clinical dialogue summarization, a low-resource domain where
supervised data for fine-tuning is scarce, necessitating the use of ASR models
as black-box solutions. Employing conventional data augmentation for enhancing
the noise robustness of summarization models is not feasible either due to the
unavailability of sufficient medical dialogue audio recordings and
corresponding ASR transcripts. To address this challenge, we propose MEDSAGE,
an approach for generating synthetic samples for data augmentation using Large
Language Models (LLMs). Specifically, we leverage the in-context learning
capabilities of LLMs and instruct them to generate ASR-like errors based on a
few available medical dialogue examples with audio recordings. Experimental
results show that LLMs can effectively model ASR noise, and incorporating this
noisy data into the training process significantly improves the robustness and
accuracy of medical dialogue summarization systems. This approach addresses the
challenges of noisy ASR outputs in critical applications, offering a robust
solution to enhance the reliability of clinical dialogue summarization.",2024-08-26,2024,2024-08,medical
"Aligning XAI with EU Regulations for Smart Biomedical Devices: A
  Methodology for Compliance Analysis","Significant investment and development have gone into integrating Artificial
Intelligence (AI) in medical and healthcare applications, leading to advanced
control systems in medical technology. However, the opacity of AI systems
raises concerns about essential characteristics needed in such sensitive
applications, like transparency and trustworthiness. Our study addresses these
concerns by investigating a process for selecting the most adequate Explainable
AI (XAI) methods to comply with the explanation requirements of key EU
regulations in the context of smart bioelectronics for medical devices. The
adopted methodology starts with categorising smart devices by their control
mechanisms (open-loop, closed-loop, and semi-closed-loop systems) and delving
into their technology. Then, we analyse these regulations to define their
explainability requirements for the various devices and related goals.
Simultaneously, we classify XAI methods by their explanatory objectives. This
allows for matching legal explainability requirements with XAI explanatory
goals and determining the suitable XAI algorithms for achieving them. Our
findings provide a nuanced understanding of which XAI algorithms align better
with EU regulations for different types of medical devices. We demonstrate this
through practical case studies on different neural implants, from chronic
disease management to advanced prosthetics. This study fills a crucial gap in
aligning XAI applications in bioelectronics with stringent provisions of EU
regulations. It provides a practical framework for developers and researchers,
ensuring their AI innovations advance healthcare technology and adhere to legal
and ethical standards.",2024-08-27,2024,2024-08,medical
"Disease Classification and Impact of Pretrained Deep Convolution Neural
  Networks on Diverse Medical Imaging Datasets across Imaging Modalities","Imaging techniques such as Chest X-rays, whole slide images, and optical
coherence tomography serve as the initial screening and detection for a wide
variety of medical pulmonary and ophthalmic conditions respectively. This paper
investigates the intricacies of using pretrained deep convolutional neural
networks with transfer learning across diverse medical imaging datasets with
varying modalities for binary and multiclass classification. We conducted a
comprehensive performance analysis with ten network architectures and model
families each with pretraining and random initialization. Our finding showed
that the use of pretrained models as fixed feature extractors yields poor
performance irrespective of the datasets. Contrary, histopathology microscopy
whole slide images have better performance. It is also found that deeper and
more complex architectures did not necessarily result in the best performance.
This observation implies that the improvements in ImageNet are not parallel to
the medical imaging tasks. Within a medical domain, the performance of the
network architectures varies within model families with shifts in datasets.
This indicates that the performance of models within a specific modality may
not be conclusive for another modality within the same domain. This study
provides a deeper understanding of the applications of deep learning techniques
in medical imaging and highlights the impact of pretrained networks across
different medical imaging datasets under five different experimental settings.",2024-08-30,2024,2024-08,medical
Medical Report Generation Is A Multi-label Classification Problem,"Medical report generation is a critical task in healthcare that involves the
automatic creation of detailed and accurate descriptions from medical images.
Traditionally, this task has been approached as a sequence generation problem,
relying on vision-and-language techniques to generate coherent and contextually
relevant reports. However, in this paper, we propose a novel perspective:
rethinking medical report generation as a multi-label classification problem.
By framing the task this way, we leverage the radiology nodes from the commonly
used knowledge graph, which can be better captured through classification
techniques. To verify our argument, we introduce a novel report generation
framework based on BLIP integrated with classified key nodes, which allows for
effective report generation with accurate classification of multiple key
aspects within the medical images. This approach not only simplifies the report
generation process but also significantly enhances performance metrics. Our
extensive experiments demonstrate that leveraging key nodes can achieve
state-of-the-art (SOTA) performance, surpassing existing approaches across two
benchmark datasets. The results underscore the potential of re-envisioning
traditional tasks with innovative methodologies, paving the way for more
efficient and accurate medical report generation.",2024-08-30,2024,2024-08,medical
Curriculum Prompting Foundation Models for Medical Image Segmentation,"Adapting large pre-trained foundation models, e.g., SAM, for medical image
segmentation remains a significant challenge. A crucial step involves the
formulation of a series of specialized prompts that incorporate specific
clinical instructions. Past works have been heavily reliant on a singular type
of prompt for each instance, necessitating manual input of an ideally correct
prompt, which is less efficient. To tackle this issue, we propose to utilize
prompts of different granularity, which are sourced from original images to
provide a broader scope of clinical insights. However, combining prompts of
varying types can pose a challenge due to potential conflicts. In response, we
have designed a coarse-to-fine mechanism, referred to as curriculum prompting,
that progressively integrates prompts of different types. Through extensive
experiments on three public medical datasets across various modalities, we
demonstrate the effectiveness of our proposed approach, which not only
automates the prompt generation process but also yields superior performance
compared to other SAM-based medical image segmentation methods. Code is
available at: https://github.com/AnnaZzz-zxq/Curriculum-Prompting.",2024-09-01,2024,2024-09,medical
"SeCo-INR: Semantically Conditioned Implicit Neural Representations for
  Improved Medical Image Super-Resolution","Implicit Neural Representations (INRs) have recently advanced the field of
deep learning due to their ability to learn continuous representations of
signals without the need for large training datasets. Although INR methods have
been studied for medical image super-resolution, their adaptability to
localized priors in medical images has not been extensively explored. Medical
images contain rich anatomical divisions that could provide valuable local
prior information to enhance the accuracy and robustness of INRs. In this work,
we propose a novel framework, referred to as the Semantically Conditioned INR
(SeCo-INR), that conditions an INR using local priors from a medical image,
enabling accurate model fitting and interpolation capabilities to achieve
super-resolution. Our framework learns a continuous representation of the
semantic segmentation features of a medical image and utilizes it to derive the
optimal INR for each semantic region of the image. We tested our framework
using several medical imaging modalities and achieved higher quantitative
scores and more realistic super-resolution outputs compared to state-of-the-art
methods.",2024-09-02,2024,2024-09,medical
"The Era of Foundation Models in Medical Imaging is Approaching : A
  Scoping Review of the Clinical Value of Large-Scale Generative AI
  Applications in Radiology","Social problems stemming from the shortage of radiologists are intensifying,
and artificial intelligence is being highlighted as a potential solution.
Recently emerging large-scale generative AI has expanded from large language
models (LLMs) to multi-modal models, showing potential to revolutionize the
entire process of medical imaging. However, comprehensive reviews on their
development status and future challenges are currently lacking. This scoping
review systematically organizes existing literature on the clinical value of
large-scale generative AI applications by following PCC guidelines. A
systematic search was conducted across four databases: PubMed, EMbase,
IEEE-Xplore, and Google Scholar, and 15 studies meeting the inclusion/exclusion
criteria set by the researchers were reviewed. Most of these studies focused on
improving the efficiency of report generation in specific parts of the
interpretation process or on translating reports to aid patient understanding,
with the latest studies extending to AI applications performing direct
interpretations. All studies were quantitatively evaluated by clinicians, with
most utilizing LLMs and only three employing multi-modal models. Both LLMs and
multi-modal models showed excellent results in specific areas, but none yet
outperformed radiologists in diagnostic performance. Most studies utilized GPT,
with few using models specialized for the medical imaging domain. This study
provides insights into the current state and limitations of large-scale
generative AI-based applications in the medical imaging field, offering
foundational data and suggesting that the era of medical imaging foundation
models is on the horizon, which may fundamentally transform clinical practice
in the near future.",2024-09-03,2024,2024-09,medical
"Coupling AI and Citizen Science in Creation of Enhanced Training Dataset
  for Medical Image Segmentation","Recent advancements in medical imaging and artificial intelligence (AI) have
greatly enhanced diagnostic capabilities, but the development of effective deep
learning (DL) models is still constrained by the lack of high-quality annotated
datasets. The traditional manual annotation process by medical experts is time-
and resource-intensive, limiting the scalability of these datasets. In this
work, we introduce a robust and versatile framework that combines AI and
crowdsourcing to improve both the quality and quantity of medical image
datasets across different modalities. Our approach utilises a user-friendly
online platform that enables a diverse group of crowd annotators to label
medical images efficiently. By integrating the MedSAM segmentation AI with this
platform, we accelerate the annotation process while maintaining expert-level
quality through an algorithm that merges crowd-labelled images. Additionally,
we employ pix2pixGAN, a generative AI model, to expand the training dataset
with synthetic images that capture realistic morphological features. These
methods are combined into a cohesive framework designed to produce an enhanced
dataset, which can serve as a universal pre-processing pipeline to boost the
training of any medical deep learning segmentation model. Our results
demonstrate that this framework significantly improves model performance,
especially when training data is limited.",2024-09-04,2024,2024-09,medical
"MEDIC: Towards a Comprehensive Framework for Evaluating LLMs in Clinical
  Applications","The rapid development of Large Language Models (LLMs) for healthcare
applications has spurred calls for holistic evaluation beyond frequently-cited
benchmarks like USMLE, to better reflect real-world performance. While
real-world assessments are valuable indicators of utility, they often lag
behind the pace of LLM evolution, likely rendering findings obsolete upon
deployment. This temporal disconnect necessitates a comprehensive upfront
evaluation that can guide model selection for specific clinical applications.
We introduce MEDIC, a framework assessing LLMs across five critical dimensions
of clinical competence: medical reasoning, ethics and bias, data and language
understanding, in-context learning, and clinical safety. MEDIC features a novel
cross-examination framework quantifying LLM performance across areas like
coverage and hallucination detection, without requiring reference outputs. We
apply MEDIC to evaluate LLMs on medical question-answering, safety,
summarization, note generation, and other tasks. Our results show performance
disparities across model sizes, baseline vs medically finetuned models, and
have implications on model selection for applications requiring specific model
strengths, such as low hallucination or lower cost of inference. MEDIC's
multifaceted evaluation reveals these performance trade-offs, bridging the gap
between theoretical capabilities and practical implementation in healthcare
settings, ensuring that the most promising models are identified and adapted
for diverse healthcare applications.",2024-09-11,2024,2024-09,medical
Safety challenges of AI in medicine in the era of large language models,"Recent advancements in artificial intelligence (AI), particularly in large
language models (LLMs), have unlocked significant potential to enhance the
quality and efficiency of medical care. By introducing a novel way to interact
with AI and data through natural language, LLMs offer new opportunities for
medical practitioners, patients, and researchers. However, as AI and LLMs
become more powerful and especially achieve superhuman performance in some
medical tasks, public concerns over their safety have intensified. These
concerns about AI safety have emerged as the most significant obstacles to the
adoption of AI in medicine. In response, this review examines emerging risks in
AI utilization during the LLM era. First, we explore LLM-specific safety
challenges from functional and communication perspectives, addressing issues
across data collection, model training, and real-world application. We then
consider inherent safety problems shared by all AI systems, along with
additional complications introduced by LLMs. Last, we discussed how safety
issues of using AI in clinical practice and healthcare system operation would
undermine trust among patient, clinicians and the public, and how to build
confidence in these systems. By emphasizing the development of safe AI, we
believe these technologies can be more rapidly and reliably integrated into
everyday medical practice to benefit both patients and clinicians.",2024-09-11,2024,2024-09,medical
"Privacy-Preserving SAM Quantization for Efficient Edge Intelligence in
  Healthcare","The disparity in healthcare personnel expertise and medical resources across
different regions of the world is a pressing social issue. Artificial
intelligence technology offers new opportunities to alleviate this issue.
Segment Anything Model (SAM), which excels in intelligent image segmentation,
has demonstrated exceptional performance in medical monitoring and assisted
diagnosis. Unfortunately, the huge computational and storage overhead of SAM
poses significant challenges for deployment on resource-limited edge devices.
Quantization is an effective solution for model compression; however,
traditional methods rely heavily on original data for calibration, which raises
widespread concerns about medical data privacy and security. In this paper, we
propose a data-free quantization framework for SAM, called DFQ-SAM, which
learns and calibrates quantization parameters without any original data, thus
effectively preserving data privacy during model compression. Specifically, we
propose pseudo-positive label evolution for segmentation, combined with patch
similarity, to fully leverage the semantic and distribution priors in
pre-trained models, which facilitates high-quality data synthesis as a
substitute for real data. Furthermore, we introduce scale reparameterization to
ensure the accuracy of low-bit quantization. We perform extensive segmentation
experiments on various datasets, and DFQ-SAM consistently provides significant
performance on low-bit quantization. DFQ-SAM eliminates the need for data
transfer in cloud-edge collaboration, thereby protecting sensitive data from
potential attacks. It enables secure, fast, and personalized healthcare
services at the edge, which enhances system efficiency and optimizes resource
allocation, and thus facilitating the pervasive application of artificial
intelligence in worldwide healthcare.",2024-09-14,2024,2024-09,medical
"Protecting Copyright of Medical Pre-trained Language Models:
  Training-Free Backdoor Model Watermarking","With the advancement of intelligent healthcare, medical pre-trained language
models (Med-PLMs) have emerged and demonstrated significant effectiveness in
downstream medical tasks. While these models are valuable assets, they are
vulnerable to misuse and theft, requiring copyright protection. However,
existing watermarking methods for pre-trained language models (PLMs) cannot be
directly applied to Med-PLMs due to domain-task mismatch and inefficient
watermark embedding. To fill this gap, we propose the first training-free
backdoor model watermarking for Med-PLMs. Our method employs low-frequency
words as triggers, embedding the watermark by replacing their embeddings in the
model's word embedding layer with those of specific medical terms. The
watermarked Med-PLMs produce the same output for triggers as for the
corresponding specified medical terms. We leverage this unique mapping to
design tailored watermark extraction schemes for different downstream tasks,
thereby addressing the challenge of domain-task mismatch in previous methods.
Experiments demonstrate superior effectiveness of our watermarking method
across medical downstream tasks. Moreover, the method exhibits robustness
against model extraction, pruning, fusion-based backdoor removal attacks, while
maintaining high efficiency with 10-second watermark embedding.",2024-09-14,2024,2024-09,medical
"Efficient Fine-Tuning of Large Language Models for Automated Medical
  Documentation","Scientific research indicates that for every hour spent in direct patient
care, physicians spend nearly two additional hours on administrative tasks,
particularly on electronic health records (EHRs) and desk work. This excessive
administrative burden not only reduces the time available for patient care but
also contributes to physician burnout and inefficiencies in healthcare
delivery. To address these challenges, this study introduces MediGen, a
fine-tuned large language model (LLM) designed to automate the generation of
medical reports from medical dialogues. By leveraging state-of-the-art
methodologies for fine-tuning open-source pretrained models, including
LLaMA3-8B, MediGen achieves high accuracy in transcribing and summarizing
clinical interactions. The fine-tuned LLaMA3-8B model demonstrated promising
results, achieving a ROUGE score of 58% and a BERTScore-F1 of 72%, indicating
its effectiveness in generating accurate and clinically relevant medical
reports. These findings suggest that MediGen has the potential to significantly
reduce the administrative workload on physicians, improving both healthcare
efficiency and physician well-being.",2024-09-14,2024,2024-09,medical
MedCodER: A Generative AI Assistant for Medical Coding,"Medical coding is essential for standardizing clinical data and communication
but is often time-consuming and prone to errors. Traditional Natural Language
Processing (NLP) methods struggle with automating coding due to the large label
space, lengthy text inputs, and the absence of supporting evidence annotations
that justify code selection. Recent advancements in Generative Artificial
Intelligence (AI) offer promising solutions to these challenges. In this work,
we introduce MedCodER, a Generative AI framework for automatic medical coding
that leverages extraction, retrieval, and re-ranking techniques as core
components. MedCodER achieves a micro-F1 score of 0.60 on International
Classification of Diseases (ICD) code prediction, significantly outperforming
state-of-the-art methods. Additionally, we present a new dataset containing
medical records annotated with disease diagnoses, ICD codes, and supporting
evidence texts (https://doi.org/10.5281/zenodo.13308316). Ablation tests
confirm that MedCodER's performance depends on the integration of each of its
aforementioned components, as performance declines when these components are
evaluated in isolation.",2024-09-18,2024,2024-09,medical
Reliable and diverse evaluation of LLM medical knowledge mastery,"Mastering medical knowledge is crucial for medical-specific LLMs. However,
despite the existence of medical benchmarks like MedQA, a unified framework
that fully leverages existing knowledge bases to evaluate LLMs' mastery of
medical knowledge is still lacking. In the study, we propose a novel framework
PretexEval that dynamically generates reliable and diverse test samples to
evaluate LLMs for any given medical knowledge base. We notice that test samples
produced directly from knowledge bases by templates or LLMs may introduce
factual errors and also lack diversity. To address these issues, we introduce a
novel schema into our proposed evaluation framework that employs predicate
equivalence transformations to produce a series of variants for any given
medical knowledge point. Finally, these produced predicate variants are
converted into textual language, resulting in a series of reliable and diverse
test samples to evaluate whether LLMs fully master the given medical factual
knowledge point. Here, we use our proposed framework to systematically
investigate the mastery of medical factual knowledge of 12 well-known LLMs,
based on two knowledge bases that are crucial for clinical diagnosis and
treatment. The evaluation results illustrate that current LLMs still exhibit
significant deficiencies in fully mastering medical knowledge, despite
achieving considerable success on some famous public benchmarks. These new
findings provide valuable insights for developing medical-specific LLMs,
highlighting that current LLMs urgently need to strengthen their comprehensive
and in-depth mastery of medical knowledge before being applied to real-world
medical scenarios.",2024-09-22,2024,2024-09,medical
Pareto-Optimized Open-Source LLMs for Healthcare via Context Retrieval,"This study leverages optimized context retrieval to enhance open-source Large
Language Models (LLMs) for cost-effective, high performance healthcare AI. We
demonstrate that this approach achieves state-of-the-art accuracy on medical
question answering at a fraction of the cost of proprietary models,
significantly improving the cost-accuracy Pareto frontier on the MedQA
benchmark. Key contributions include: (1) OpenMedQA, a novel benchmark
revealing a performance gap in open-ended medical QA compared to
multiple-choice formats; (2) a practical, reproducible pipeline for context
retrieval optimization; and (3) open-source resources (Prompt Engine,
CoT/ToT/Thinking databases) to empower healthcare AI development. By advancing
retrieval techniques and QA evaluation, we enable more affordable and reliable
LLM solutions for healthcare.",2024-09-23,2024,2024-09,medical
"Future-Proofing Medical Imaging with Privacy-Preserving Federated
  Learning and Uncertainty Quantification: A Review","Artificial Intelligence (AI) has demonstrated significant potential in
automating various medical imaging tasks, which could soon become routine in
clinical practice for disease diagnosis, prognosis, treatment planning, and
post-treatment surveillance. However, the privacy concerns surrounding patient
data present a major barrier to the widespread adoption of AI in medical
imaging, as large, diverse training datasets are essential for developing
accurate, generalizable, and robust Artificial intelligence models. Federated
Learning (FL) offers a solution that enables organizations to train AI models
collaboratively without sharing sensitive data. federated learning exchanges
model training information, such as gradients, between the participating sites.
Despite its promise, federated learning is still in its developmental stages
and faces several challenges. Notably, sensitive information can still be
inferred from the gradients shared during model training. Quantifying AI
models' uncertainty is vital due to potential data distribution shifts
post-deployment, which can affect model performance. Uncertainty quantification
(UQ) in FL is particularly challenging due to data heterogeneity across
participating sites. This review provides a comprehensive examination of FL,
privacy-preserving FL (PPFL), and UQ in FL. We identify key gaps in current FL
methodologies and propose future research directions to enhance data privacy
and trustworthiness in medical imaging applications.",2024-09-24,2024,2024-09,medical
"Development and Validation of Heparin Dosing Policies Using an Offline
  Reinforcement Learning Algorithm","Appropriate medication dosages in the intensive care unit (ICU) are critical
for patient survival. Heparin, used to treat thrombosis and inhibit blood
clotting in the ICU, requires careful administration due to its complexity and
sensitivity to various factors, including patient clinical characteristics,
underlying medical conditions, and potential drug interactions. Incorrect
dosing can lead to severe complications such as strokes or excessive bleeding.
To address these challenges, this study proposes a reinforcement learning
(RL)-based personalized optimal heparin dosing policy that guides dosing
decisions reliably within the therapeutic range based on individual patient
conditions. A batch-constrained policy was implemented to minimize
out-of-distribution errors in an offline RL environment and effectively
integrate RL with existing clinician policies. The policy's effectiveness was
evaluated using weighted importance sampling, an off-policy evaluation method,
and the relationship between state representations and Q-values was explored
using t-SNE. Both quantitative and qualitative analyses were conducted using
the Medical Information Mart for Intensive Care III (MIMIC-III) database,
demonstrating the efficacy of the proposed RL-based medication policy.
Leveraging advanced machine learning techniques and extensive clinical data,
this research enhances heparin administration practices and establishes a
precedent for the development of sophisticated decision-support tools in
medicine.",2024-09-24,2024,2024-09,medical
The Role of Language Models in Modern Healthcare: A Comprehensive Review,"The application of large language models (LLMs) in healthcare has gained
significant attention due to their ability to process complex medical data and
provide insights for clinical decision-making. These models have demonstrated
substantial capabilities in understanding and generating natural language,
which is crucial for medical documentation, diagnostics, and patient
interaction. This review examines the trajectory of language models from their
early stages to the current state-of-the-art LLMs, highlighting their strengths
in healthcare applications and discussing challenges such as data privacy,
bias, and ethical considerations. The potential of LLMs to enhance healthcare
delivery is explored, alongside the necessary steps to ensure their ethical and
effective integration into medical practice.",2024-09-25,2024,2024-09,medical
"CBIDR: A novel method for information retrieval combining image and data
  by means of TOPSIS applied to medical diagnosis","Content-Based Image Retrieval (CBIR) have shown promising results in the
field of medical diagnosis, which aims to provide support to medical
professionals (doctor or pathologist). However, the ultimate decision regarding
the diagnosis is made by the medical professional, drawing upon their
accumulated experience. In this context, we believe that artificial
intelligence can play a pivotal role in addressing the challenges in medical
diagnosis not by making the final decision but by assisting in the diagnosis
process with the most relevant information. The CBIR methods use similarity
metrics to compare feature vectors generated from images using Convolutional
Neural Networks (CNNs). In addition to the information contained in medical
images, clinical data about the patient is often available and is also relevant
in the final decision-making process by medical professionals. In this paper,
we propose a novel method named CBIDR, which leverage both medical images and
clinical data of patient, combining them through the ranking algorithm TOPSIS.
The goal is to aid medical professionals in their final diagnosis by retrieving
images and clinical data of patient that are most similar to query data from
the database. As a case study, we illustrate our CBIDR for diagnostic of oral
cancer including histopathological images and clinical data of patient.
Experimental results in terms of accuracy achieved 97.44% in Top-1 and 100% in
Top-5 showing the effectiveness of the proposed approach.",2024-09-26,2024,2024-09,medical
"Evaluation of Large Language Models for Summarization Tasks in the
  Medical Domain: A Narrative Review","Large Language Models have advanced clinical Natural Language Generation,
creating opportunities to manage the volume of medical text. However, the
high-stakes nature of medicine requires reliable evaluation, which remains a
challenge. In this narrative review, we assess the current evaluation state for
clinical summarization tasks and propose future directions to address the
resource constraints of expert human evaluation.",2024-09-26,2024,2024-09,medical
Global-Local Medical SAM Adaptor Based on Full Adaption,"Emerging of visual language models, such as the segment anything model (SAM),
have made great breakthroughs in the field of universal semantic segmentation
and significantly aid the improvements of medical image segmentation, in
particular with the help of Medical SAM adaptor (Med-SA). However, Med-SA still
can be improved, as it fine-tunes SAM in a partial adaption manner. To resolve
this problem, we present a novel global medical SAM adaptor (GMed-SA) with full
adaption, which can adapt SAM globally. We further combine GMed-SA and Med-SA
to propose a global-local medical SAM adaptor (GLMed-SA) to adapt SAM both
globally and locally. Extensive experiments have been performed on the
challenging public 2D melanoma segmentation dataset. The results show that
GLMed-SA outperforms several state-of-the-art semantic segmentation methods on
various evaluation metrics, demonstrating the superiority of our methods.",2024-09-26,2024,2024-09,medical
"Zero- and Few-shot Named Entity Recognition and Text Expansion in
  Medication Prescriptions using ChatGPT","Introduction: Medication prescriptions are often in free text and include a
mix of two languages, local brand names, and a wide range of idiosyncratic
formats and abbreviations. Large language models (LLMs) have shown promising
ability to generate text in response to input prompts. We use ChatGPT 3.5 to
automatically structure and expand medication statements in discharge summaries
and thus make them easier to interpret for people and machines. Methods:
Named-entity Recognition (NER) and Text Expansion (EX) are used in a zero- and
few-shot setting with different prompt strategies. 100 medication statements
were manually annotated and curated. NER performance was measured by using
strict and partial matching. For the task EX, two experts interpreted the
results by assessing semantic equivalence between original and expanded
statements. The model performance was measured by precision, recall, and F1
score. Results: For NER, the best-performing prompt reached an average F1 score
of 0.94 in the test set. For EX, the few-shot prompt showed superior
performance among other prompts, with an average F1 score of 0.87. Conclusion:
Our study demonstrates good performance for NER and EX tasks in free-text
medication statements using ChatGPT. Compared to a zero-shot baseline, a
few-shot approach prevented the system from hallucinating, which would be
unacceptable when processing safety-relevant medication data.",2024-09-26,2024,2024-09,medical
"Building a Chinese Medical Dialogue System: Integrating Large-scale
  Corpora and Novel Models","The global COVID-19 pandemic underscored major deficiencies in traditional
healthcare systems, hastening the advancement of online medical services,
especially in medical triage and consultation. However, existing studies face
two main challenges. First, the scarcity of large-scale, publicly available,
domain-specific medical datasets due to privacy concerns, with current datasets
being small and limited to a few diseases, limiting the effectiveness of triage
methods based on Pre-trained Language Models (PLMs). Second, existing methods
lack medical knowledge and struggle to accurately understand professional terms
and expressions in patient-doctor consultations. To overcome these obstacles,
we construct the Large-scale Chinese Medical Dialogue Corpora (LCMDC), thereby
addressing the data shortage in this field. Moreover, we further propose a
novel triage system that combines BERT-based supervised learning with prompt
learning, as well as a GPT-based medical consultation model. To enhance domain
knowledge acquisition, we pre-trained PLMs using our self-constructed
background corpus. Experimental results on the LCMDC demonstrate the efficacy
of our proposed systems.",2024-09-27,2024,2024-09,medical
A GEN AI Framework for Medical Note Generation,"The increasing administrative burden of medical documentation, particularly
through Electronic Health Records (EHR), significantly reduces the time
available for direct patient care and contributes to physician burnout. To
address this issue, we propose MediNotes, an advanced generative AI framework
designed to automate the creation of SOAP (Subjective, Objective, Assessment,
Plan) notes from medical conversations. MediNotes integrates Large Language
Models (LLMs), Retrieval-Augmented Generation (RAG), and Automatic Speech
Recognition (ASR) to capture and process both text and voice inputs in real
time or from recorded audio, generating structured and contextually accurate
medical notes. The framework also incorporates advanced techniques like
Quantized Low-Rank Adaptation (QLoRA) and Parameter-Efficient Fine-Tuning
(PEFT) for efficient model fine-tuning in resource-constrained environments.
Additionally, MediNotes offers a query-based retrieval system, allowing
healthcare providers and patients to access relevant medical information
quickly and accurately. Evaluations using the ACI-BENCH dataset demonstrate
that MediNotes significantly improves the accuracy, efficiency, and usability
of automated medical documentation, offering a robust solution to reduce the
administrative burden on healthcare professionals while improving the quality
of clinical workflows.",2024-09-27,2024,2024-09,medical
"INSIGHTBUDDY-AI: Medication Extraction and Entity Linking using Large
  Language Models and Ensemble Learning","Medication Extraction and Mining play an important role in healthcare NLP
research due to its practical applications in hospital settings, such as their
mapping into standard clinical knowledge bases (SNOMED-CT, BNF, etc.). In this
work, we investigate state-of-the-art LLMs in text mining tasks on medications
and their related attributes such as dosage, route, strength, and adverse
effects. In addition, we explore different ensemble learning methods
(\textsc{Stack-Ensemble} and \textsc{Voting-Ensemble}) to augment the model
performances from individual LLMs. Our ensemble learning result demonstrated
better performances than individually fine-tuned base models BERT, RoBERTa,
RoBERTa-L, BioBERT, BioClinicalBERT, BioMedRoBERTa, ClinicalBERT, and
PubMedBERT across general and specific domains. Finally, we build up an entity
linking function to map extracted medical terminologies into the SNOMED-CT
codes and the British National Formulary (BNF) codes, which are further mapped
to the Dictionary of Medicines and Devices (dm+d), and ICD. Our model's toolkit
and desktop applications are publicly available (at
\url{https://github.com/HECTA-UoM/ensemble-NER}).",2024-09-28,2024,2024-09,medical
"Adapting LLMs for the Medical Domain in Portuguese: A Study on
  Fine-Tuning and Model Evaluation","This study evaluates the performance of large language models (LLMs) as
medical agents in Portuguese, aiming to develop a reliable and relevant virtual
assistant for healthcare professionals. The HealthCareMagic-100k-en and MedQuAD
datasets, translated from English using GPT-3.5, were used to fine-tune the
ChatBode-7B model using the PEFT-QLoRA method. The InternLM2 model, with
initial training on medical data, presented the best overall performance, with
high precision and adequacy in metrics such as accuracy, completeness and
safety. However, DrBode models, derived from ChatBode, exhibited a phenomenon
of catastrophic forgetting of acquired medical knowledge. Despite this, these
models performed frequently or even better in aspects such as grammaticality
and coherence. A significant challenge was low inter-rater agreement,
highlighting the need for more robust assessment protocols. This work paves the
way for future research, such as evaluating multilingual models specific to the
medical field, improving the quality of training data, and developing more
consistent evaluation methodologies for the medical field.",2024-09-30,2024,2024-09,medical
"MedQA-CS: Benchmarking Large Language Models Clinical Skills Using an
  AI-SCE Framework","Artificial intelligence (AI) and large language models (LLMs) in healthcare
require advanced clinical skills (CS), yet current benchmarks fail to evaluate
these comprehensively. We introduce MedQA-CS, an AI-SCE framework inspired by
medical education's Objective Structured Clinical Examinations (OSCEs), to
address this gap. MedQA-CS evaluates LLMs through two instruction-following
tasks, LLM-as-medical-student and LLM-as-CS-examiner, designed to reflect real
clinical scenarios. Our contributions include developing MedQA-CS, a
comprehensive evaluation framework with publicly available data and expert
annotations, and providing the quantitative and qualitative assessment of LLMs
as reliable judges in CS evaluation. Our experiments show that MedQA-CS is a
more challenging benchmark for evaluating clinical skills than traditional
multiple-choice QA benchmarks (e.g., MedQA). Combined with existing benchmarks,
MedQA-CS enables a more comprehensive evaluation of LLMs' clinical capabilities
for both open- and closed-source LLMs.",2024-10-02,2024,2024-10,medical
"Taming the Tail: Leveraging Asymmetric Loss and Pade Approximation to
  Overcome Medical Image Long-Tailed Class Imbalance","Long-tailed problems in healthcare emerge from data imbalance due to
variability in the prevalence and representation of different medical
conditions, warranting the requirement of precise and dependable classification
methods. Traditional loss functions such as cross-entropy and binary
cross-entropy are often inadequate due to their inability to address the
imbalances between the classes with high representation and the classes with
low representation found in medical image datasets. We introduce a novel
polynomial loss function based on Pade approximation, designed specifically to
overcome the challenges associated with long-tailed classification. This
approach incorporates asymmetric sampling techniques to better classify
under-represented classes. We conducted extensive evaluations on three publicly
available medical datasets and a proprietary medical dataset. Our
implementation of the proposed loss function is open-sourced in the public
repository:https://github.com/ipankhi/ALPA.",2024-10-05,2024,2024-10,medical
"CasiMedicos-Arg: A Medical Question Answering Dataset Annotated with
  Explanatory Argumentative Structures","Explaining Artificial Intelligence (AI) decisions is a major challenge
nowadays in AI, in particular when applied to sensitive scenarios like medicine
and law. However, the need to explain the rationale behind decisions is a main
issue also for human-based deliberation as it is important to justify
\textit{why} a certain decision has been taken. Resident medical doctors for
instance are required not only to provide a (possibly correct) diagnosis, but
also to explain how they reached a certain conclusion. Developing new tools to
aid residents to train their explanation skills is therefore a central
objective of AI in education. In this paper, we follow this direction, and we
present, to the best of our knowledge, the first multilingual dataset for
Medical Question Answering where correct and incorrect diagnoses for a clinical
case are enriched with a natural language explanation written by doctors. These
explanations have been manually annotated with argument components (i.e.,
premise, claim) and argument relations (i.e., attack, support), resulting in
the Multilingual CasiMedicos-Arg dataset which consists of 558 clinical cases
in four languages (English, Spanish, French, Italian) with explanations, where
we annotated 5021 claims, 2313 premises, 2431 support relations, and 1106
attack relations. We conclude by showing how competitive baselines perform over
this challenging dataset for the argument mining task.",2024-10-07,2024,2024-10,medical
KGARevion: An AI Agent for Knowledge-Intensive Biomedical QA,"Biomedical reasoning integrates structured, codified knowledge with tacit,
experience-driven insights. Depending on the context, quantity, and nature of
available evidence, researchers and clinicians use diverse strategies,
including rule-based, prototype-based, and case-based reasoning. Effective
medical AI models must handle this complexity while ensuring reliability and
adaptability. We introduce KGARevion, a knowledge graph-based agent that
answers knowledge-intensive questions. Upon receiving a query, KGARevion
generates relevant triplets by leveraging the latent knowledge embedded in a
large language model. It then verifies these triplets against a grounded
knowledge graph, filtering out errors and retaining only accurate, contextually
relevant information for the final answer. This multi-step process strengthens
reasoning, adapts to different models of medical inference, and outperforms
retrieval-augmented generation-based approaches that lack effective
verification mechanisms. Evaluations on medical QA benchmarks show that
KGARevion improves accuracy by over 5.2% over 15 models in handling complex
medical queries. To further assess its effectiveness, we curated three new
medical QA datasets with varying levels of semantic complexity, where KGARevion
improved accuracy by 10.4%. The agent integrates with different LLMs and
biomedical knowledge graphs for broad applicability across knowledge-intensive
tasks. We evaluated KGARevion on AfriMed-QA, a newly introduced dataset focused
on African healthcare, demonstrating its strong zero-shot generalization to
underrepresented medical contexts.",2024-10-07,2024,2024-10,medical
"Large Language Models for Medical OSCE Assessment: A Novel Approach to
  Transcript Analysis","Grading Objective Structured Clinical Examinations (OSCEs) is a
time-consuming and expensive process, traditionally requiring extensive manual
effort from human experts. In this study, we explore the potential of Large
Language Models (LLMs) to assess skills related to medical student
communication. We analyzed 2,027 video-recorded OSCE examinations from the
University of Texas Southwestern Medical Center (UTSW), spanning four years
(2019-2022), and several different medical cases or ""stations."" Specifically,
our focus was on evaluating students' ability to summarize patients' medical
history: we targeted the rubric item 'did the student summarize the patients'
medical history?' from the communication skills rubric. After transcribing
speech audio captured by OSCE videos using Whisper-v3, we studied the
performance of various LLM-based approaches for grading students on this
summarization task based on their examination transcripts. Using various
frontier-level open-source and proprietary LLMs, we evaluated different
techniques such as zero-shot chain-of-thought prompting, retrieval augmented
generation, and multi-model ensemble methods. Our results show that frontier
LLM models like GPT-4 achieved remarkable alignment with human graders,
demonstrating a Cohen's kappa agreement of 0.88 and indicating strong potential
for LLM-based OSCE grading to augment the current grading process. Open-source
models also showed promising results, suggesting potential for widespread,
cost-effective deployment. Further, we present a failure analysis identifying
conditions where LLM grading may be less reliable in this context and recommend
best practices for deploying LLMs in medical education settings.",2024-10-11,2024,2024-10,medical
"MIRAGE: Multimodal Identification and Recognition of Annotations in
  Indian General Prescriptions","Hospitals in India still rely on handwritten medical records despite the
availability of Electronic Medical Records (EMR), complicating statistical
analysis and record retrieval. Handwritten records pose a unique challenge,
requiring specialized data for training models to recognize medications and
their recommendation patterns. While traditional handwriting recognition
approaches employ 2-D LSTMs, recent studies have explored using Multimodal
Large Language Models (MLLMs) for OCR tasks. Building on this approach, we
focus on extracting medication names and dosages from simulated medical
records. Our methodology MIRAGE (Multimodal Identification and Recognition of
Annotations in indian GEneral prescriptions) involves fine-tuning the QWEN VL,
LLaVA 1.6 and Idefics2 models on 743,118 high resolution simulated medical
record images-fully annotated from 1,133 doctors across India. Our approach
achieves 82% accuracy in extracting medication names and dosages.",2024-10-13,2024,2024-10,medical
IMAS: A Comprehensive Agentic Approach to Rural Healthcare Delivery,"Since the onset of COVID-19, rural communities worldwide have faced
significant challenges in accessing healthcare due to the migration of
experienced medical professionals to urban centers. Semi-trained caregivers,
such as Community Health Workers (CHWs) and Registered Medical Practitioners
(RMPs), have stepped in to fill this gap, but often lack formal training. This
paper proposes an advanced agentic medical assistant system designed to improve
healthcare delivery in rural areas by utilizing Large Language Models (LLMs)
and agentic approaches. The system is composed of five crucial components:
translation, medical complexity assessment, expert network integration, final
medical advice generation, and response simplification. Our innovative
framework ensures context-sensitive, adaptive, and reliable medical assistance,
capable of clinical triaging, diagnostics, and identifying cases requiring
specialist intervention. The system is designed to handle cultural nuances and
varying literacy levels, providing clear and actionable medical advice in local
languages. Evaluation results using the MedQA, PubMedQA, and JAMA datasets
demonstrate that this integrated approach significantly enhances the
effectiveness of rural healthcare workers, making healthcare more accessible
and understandable for underserved populations. All code and supplemental
materials associated with the paper and IMAS are available at
https://github.com/uheal/imas.",2024-10-13,2024,2024-10,medical
Adaptive Reasoning and Acting in Medical Language Agents,"This paper presents an innovative large language model (LLM) agent framework
for enhancing diagnostic accuracy in simulated clinical environments using the
AgentClinic benchmark. The proposed automatic correction enables doctor agents
to iteratively refine their reasoning and actions following incorrect
diagnoses, fostering improved decision-making over time. Experiments show that
the implementation of the adaptive LLM-based doctor agents achieve correct
diagnoses through dynamic interactions with simulated patients. The evaluations
highlight the capacity of autonomous agents to adapt and improve in complex
medical scenarios. Future enhancements will focus on refining the algorithm and
expanding its applicability across a wider range of tasks and different large
language models.",2024-10-13,2024,2024-10,medical
Large-Scale 3D Medical Image Pre-training with Geometric Context Priors,"The scarcity of annotations poses a significant challenge in medical image
analysis. Large-scale pre-training has emerged as a promising label-efficient
solution, owing to the utilization of large-scale data, large models, and
advanced pre-training techniques. However, its development in medical images
remains underexplored. The primary challenge lies in harnessing large-scale
unlabeled data and learning high-level semantics without annotations. We
observe that 3D medical images exhibit consistent geometric context, i.e.,
consistent geometric relations between different organs, which leads to a
promising way for learning consistent representations. Motivated by this, we
introduce a simple-yet-effective Volume Contrast (VoCo) framework to leverage
geometric context priors for self-supervision. Given an input volume, we
extract base crops from different regions to construct positive and negative
pairs for contrastive learning. Then we predict the contextual position of a
random crop by contrasting its similarity to the base crops. In this way, VoCo
encodes the inherent geometric context into model representations, facilitating
high-level semantic learning without annotations. Specifically, we (1)
introduce the largest medical pre-training dataset PreCT-160K; (2) investigate
scaling laws and propose guidelines for tailoring different model sizes to
various medical tasks; (3) build a benchmark encompassing 48 medical tasks.
Extensive experiments highlight the superiority of VoCo. Codes at
https://github.com/Luffy03/Large-Scale-Medical.",2024-10-13,2024,2024-10,medical
Study on the Helpfulness of Explainable Artificial Intelligence,"Explainable Artificial Intelligence (XAI) is essential for building advanced
machine learning-powered applications, especially in critical domains such as
medical diagnostics or autonomous driving. Legal, business, and ethical
requirements motivate using effective XAI, but the increasing number of
different methods makes it challenging to pick the right ones. Further, as
explanations are highly context-dependent, measuring the effectiveness of XAI
methods without users can only reveal a limited amount of information,
excluding human factors such as the ability to understand it. We propose to
evaluate XAI methods via the user's ability to successfully perform a proxy
task, designed such that a good performance is an indicator for the explanation
to provide helpful information. In other words, we address the helpfulness of
XAI for human decision-making. Further, a user study on state-of-the-art
methods was conducted, showing differences in their ability to generate trust
and skepticism and the ability to judge the rightfulness of an AI decision
correctly. Based on the results, we highly recommend using and extending this
approach for more objective-based human-centered user studies to measure XAI
performance in an end-to-end fashion.",2024-10-14,2024,2024-10,medical
"HR-Agent: A Task-Oriented Dialogue (TOD) LLM Agent Tailored for HR
  Applications","Recent LLM (Large Language Models) advancements benefit many fields such as
education and finance, but HR has hundreds of repetitive processes, such as
access requests, medical claim filing and time-off submissions, which are
unaddressed. We relate these tasks to the LLM agent, which has addressed tasks
such as writing assisting and customer support. We present HR-Agent, an
efficient, confidential, and HR-specific LLM-based task-oriented dialogue
system tailored for automating repetitive HR processes such as medical claims
and access requests. Since conversation data is not sent to an LLM during
inference, it preserves confidentiality required in HR-related tasks.",2024-10-15,2024,2024-10,medical
"Advancing Healthcare: Innovative ML Approaches for Improved Medical
  Imaging in Data-Constrained Environments","Healthcare industries face challenges when experiencing rare diseases due to
limited samples. Artificial Intelligence (AI) communities overcome this
situation to create synthetic data which is an ethical and privacy issue in the
medical domain. This research introduces the CAT-U-Net framework as a new
approach to overcome these limitations, which enhances feature extraction from
medical images without the need for large datasets. The proposed framework adds
an extra concatenation layer with downsampling parts, thereby improving its
ability to learn from limited data while maintaining patient privacy. To
validate, the proposed framework's robustness, different medical conditioning
datasets were utilized including COVID-19, brain tumors, and wrist fractures.
The framework achieved nearly 98% reconstruction accuracy, with a Dice
coefficient close to 0.946. The proposed CAT-U-Net has the potential to make a
big difference in medical image diagnostics in settings with limited data.",2024-10-16,2024,2024-10,medical
"Toward a Unified Graph-Based Representation of Medical Data for
  Precision Oncology Medicine","We present a new unified graph-based representation of medical data,
combining genetic information and medical records of patients with medical
knowledge via a unique knowledge graph. This approach allows us to infer
meaningful information and explanations that would be unavailable by looking at
each data set separately. The systematic use of different databases, managed
throughout the built knowledge graph, gives new insights toward a better
understanding of oncology medicine. Indeed, we reduce some useful medical tasks
to well-known problems in theoretical computer science for which efficient
algorithms exist.",2024-10-17,2024,2024-10,medical
Representation Learning of Structured Data for Medical Foundation Models,"Large Language Models (LLMs) have demonstrated remarkable performance across
various domains, including healthcare. However, their ability to effectively
represent structured non-textual data, such as the alphanumeric medical codes
used in records like ICD-10 or SNOMED-CT, is limited and has been particularly
exposed in recent research. This paper examines the challenges LLMs face in
processing medical codes due to the shortcomings of current tokenization
methods. As a result, we introduce the UniStruct architecture to design a
multimodal medical foundation model of unstructured text and structured data,
which addresses these challenges by adapting subword tokenization techniques
specifically for the structured medical codes. Our approach is validated
through model pre-training on both an extensive internal medical database and a
public repository of structured medical records. Trained on over 1 billion
tokens on the internal medical database, the proposed model achieves up to a
23% improvement in evaluation metrics, with around 2% gain attributed to our
proposed tokenization. Additionally, when evaluated on the EHRSHOT public
benchmark with a 1/1000 fraction of the pre-training data, the UniStruct model
improves performance on over 42% of the downstream tasks. Our approach not only
enhances the representation and generalization capabilities of patient-centric
models but also bridges a critical gap in representation learning models'
ability to handle complex structured medical data, alongside unstructured text.",2024-10-17,2024,2024-10,medical
"MeNTi: Bridging Medical Calculator and LLM Agent with Nested Tool
  Calling","Integrating tools into Large Language Models (LLMs) has facilitated the
widespread application. Despite this, in specialized downstream task contexts,
reliance solely on tools is insufficient to fully address the complexities of
the real world. This particularly restricts the effective deployment of LLMs in
fields such as medicine. In this paper, we focus on the downstream tasks of
medical calculators, which use standardized tests to assess an individual's
health status. We introduce MeNTi, a universal agent architecture for LLMs.
MeNTi integrates a specialized medical toolkit and employs meta-tool and nested
calling mechanisms to enhance LLM tool utilization. Specifically, it achieves
flexible tool selection and nested tool calling to address practical issues
faced in intricate medical scenarios, including calculator selection, slot
filling, and unit conversion. To assess the capabilities of LLMs for
quantitative assessment throughout the clinical process of calculator
scenarios, we introduce CalcQA. This benchmark requires LLMs to use medical
calculators to perform calculations and assess patient health status. CalcQA is
constructed by professional physicians and includes 100 case-calculator pairs,
complemented by a toolkit of 281 medical tools. The experimental results
demonstrate significant performance improvements with our framework. This
research paves new directions for applying LLMs in demanding scenarios of
medicine.",2024-10-17,2024,2024-10,medical
"Deep Learning Applications in Medical Image Analysis: Advancements,
  Challenges, and Future Directions","Medical image analysis has emerged as an essential element of contemporary
healthcare, facilitating physicians in achieving expedited and precise
diagnosis. Recent breakthroughs in deep learning, a subset of artificial
intelligence, have markedly revolutionized the analysis of medical pictures,
improving the accuracy and efficiency of clinical procedures. Deep learning
algorithms, especially convolutional neural networks (CNNs), have demonstrated
remarkable proficiency in autonomously learning features from multidimensional
medical pictures, including MRI, CT, and X-ray scans, without the necessity for
manual feature extraction. These models have been utilized across multiple
medical disciplines, including pathology, radiology, ophthalmology, and
cardiology, where they aid in illness detection, classification, and
segmentation tasks......",2024-10-18,2024,2024-10,medical
Enabling Scalable Evaluation of Bias Patterns in Medical LLMs,"Large language models (LLMs) have shown impressive potential in helping with
numerous medical challenges. Deploying LLMs in high-stakes applications such as
medicine, however, brings in many concerns. One major area of concern relates
to biased behaviors of LLMs in medical applications, leading to unfair
treatment of individuals. To pave the way for the responsible and impactful
deployment of Med LLMs, rigorous evaluation is a key prerequisite. Due to the
huge complexity and variability of different medical scenarios, existing work
in this domain has primarily relied on using manually crafted datasets for bias
evaluation. In this study, we present a new method to scale up such bias
evaluations by automatically generating test cases based on rigorous medical
evidence. We specifically target the challenges of a) domain-specificity of
bias characterization, b) hallucinating while generating the test cases, and c)
various dependencies between the health outcomes and sensitive attributes. To
that end, we offer new methods to address these challenges integrated with our
generative pipeline, using medical knowledge graphs, medical ontologies, and
customized general LLM evaluation frameworks in our method. Through a series of
extensive experiments, we show that the test cases generated by our proposed
method can effectively reveal bias patterns in Med LLMs at larger and more
flexible scales than human-crafted datasets. We publish a large bias evaluation
dataset using our pipeline, which is dedicated to a few medical case studies. A
live demo of our application for vignette generation is available at
https://vignette.streamlit.app. Our code is also available at
https://github.com/healthylaife/autofair.",2024-10-18,2024,2024-10,medical
LLaVA-Ultra: Large Chinese Language and Vision Assistant for Ultrasound,"Multimodal Large Language Model (MLLM) has recently garnered attention as a
prominent research focus. By harnessing powerful LLM, it facilitates a
transition of conversational generative AI from unimodal text to performing
multimodal tasks. This boom begins to significantly impact medical field.
However, general visual language model (VLM) lacks sophisticated comprehension
for medical visual question answering (Med-VQA). Even models specifically
tailored for medical domain tend to produce vague answers with weak visual
relevance. In this paper, we propose a fine-grained adaptive VLM architecture
for Chinese medical visual conversations through parameter-efficient tuning.
Specifically, we devise a fusion module with fine-grained vision encoders to
achieve enhancement for subtle medical visual semantics. Then we note data
redundancy common to medical scenes is ignored in most prior works. In cases of
a single text paired with multiple figures, we utilize weighted scoring with
knowledge distillation to adaptively screen valid images mirroring text
descriptions. For execution, we leverage a large-scale multimodal Chinese
ultrasound dataset obtained from the hospital. We create instruction-following
data based on text from professional doctors, which ensures effective tuning.
With enhanced model and quality data, our Large Chinese Language and Vision
Assistant for Ultrasound (LLaVA-Ultra) shows strong capability and robustness
to medical scenarios. On three Med-VQA datasets, LLaVA-Ultra surpasses previous
state-of-the-art models on various metrics.",2024-10-19,2024,2024-10,medical
"MMDS: A Multimodal Medical Diagnosis System Integrating Image Analysis
  and Knowledge-based Departmental Consultation","We present MMDS, a system capable of recognizing medical images and patient
facial details, and providing professional medical diagnoses. The system
consists of two core components:The first component is the analysis of medical
images and videos. We trained a specialized multimodal medical model capable of
interpreting medical images and accurately analyzing patients' facial emotions
and facial paralysis conditions. The model achieved an accuracy of 72.59% on
the FER2013 facial emotion recognition dataset, with a 91.1% accuracy in
recognizing the ""happy"" emotion. In facial paralysis recognition, the model
reached an accuracy of 92%, which is 30% higher than that of GPT-4o. Based on
this model, we developed a parser for analyzing facial movement videos of
patients with facial paralysis, achieving precise grading of the paralysis
severity. In tests on 30 videos of facial paralysis patients, the system
demonstrated a grading accuracy of 83.3%.The second component is the generation
of professional medical responses. We employed a large language model,
integrated with a medical knowledge base, to generate professional diagnoses
based on the analysis of medical images or videos. The core innovation lies in
our development of a department-specific knowledge base routing management
mechanism, in which the large language model categorizes data by medical
departments and, during the retrieval process, determines the appropriate
knowledge base to query. This significantly improves retrieval accuracy in the
RAG (retrieval-augmented generation) process.",2024-10-20,2024,2024-10,medical
"Concept Complement Bottleneck Model for Interpretable Medical Image
  Diagnosis","Models based on human-understandable concepts have received extensive
attention to improve model interpretability for trustworthy artificial
intelligence in the field of medical image analysis. These methods can provide
convincing explanations for model decisions but heavily rely on the detailed
annotation of pre-defined concepts. Consequently, they may not be effective in
cases where concepts or annotations are incomplete or low-quality. Although
some methods automatically discover effective and new visual concepts rather
than using pre-defined concepts or could find some human-understandable
concepts via large Language models, they are prone to veering away from medical
diagnostic evidence and are challenging to understand. In this paper, we
propose a concept complement bottleneck model for interpretable medical image
diagnosis with the aim of complementing the existing concept set and finding
new concepts bridging the gap between explainable models. Specifically, we
propose to use concept adapters for specific concepts to mine the concept
differences and score concepts in their own attention channels to support
almost fairly concept learning. Then, we devise a concept complement strategy
to learn new concepts while jointly using known concepts to improve model
performance. Comprehensive experiments on medical datasets demonstrate that our
model outperforms the state-of-the-art competitors in concept detection and
disease diagnosis tasks while providing diverse explanations to ensure model
interpretability effectively.",2024-10-20,2024,2024-10,medical
"On Creating an English-Thai Code-switched Machine Translation in Medical
  Domain","Machine translation (MT) in the medical domain plays a pivotal role in
enhancing healthcare quality and disseminating medical knowledge. Despite
advancements in English-Thai MT technology, common MT approaches often
underperform in the medical field due to their inability to precisely translate
medical terminologies. Our research prioritizes not merely improving
translation accuracy but also maintaining medical terminology in English within
the translated text through code-switched (CS) translation. We developed a
method to produce CS medical translation data, fine-tuned a CS translation
model with this data, and evaluated its performance against strong baselines,
such as Google Neural Machine Translation (NMT) and GPT-3.5/GPT-4. Our model
demonstrated competitive performance in automatic metrics and was highly
favored in human preference evaluations. Our evaluation result also shows that
medical professionals significantly prefer CS translations that maintain
critical English terms accurately, even if it slightly compromises fluency. Our
code and test set are publicly available
https://github.com/preceptorai-org/NLLB_CS_EM_NLP2024.",2024-10-21,2024,2024-10,medical
GenAI Assisting Medical Training,"Medical procedures such as venipuncture and cannulation are essential for
nurses and require precise skills. Learning this skill, in turn, is a challenge
for educators due to the number of teachers per class and the complexity of the
task. The study aims to help students with skill acquisition and alleviate the
educator's workload by integrating generative AI methods to provide real-time
feedback on medical procedures such as venipuncture and cannulation.",2024-10-21,2024,2024-10,medical
Resource-Efficient Medical Report Generation using Large Language Models,"Medical report generation is the task of automatically writing radiology
reports for chest X-ray images. Manually composing these reports is a
time-consuming process that is also prone to human errors. Generating medical
reports can therefore help reduce the burden on radiologists. In other words,
we can promote greater clinical automation in the medical domain. In this work,
we propose a new framework leveraging vision-enabled Large Language Models
(LLM) for the task of medical report generation. We introduce a lightweight
solution that achieves better or comparative performance as compared to
previous solutions on the task of medical report generation. We conduct
extensive experiments exploring different model sizes and enhancement
approaches, such as prefix tuning to improve the text generation abilities of
the LLMs. We evaluate our approach on a prominent large-scale radiology report
dataset - MIMIC-CXR. Our results demonstrate the capability of our
resource-efficient framework to generate patient-specific reports with strong
medical contextual understanding and high precision.",2024-10-21,2024,2024-10,medical
MAC Revivo: Artificial Intelligence Paves the Way,"The vast adoption of Wi-Fi and/or Bluetooth capabilities in Internet of
Things (IoT) devices, along with the rapid growth of deployed smart devices,
has caused significant interference and congestion in the industrial,
scientific, and medical (ISM) bands. Traditional Wi-Fi Medium Access Control
(MAC) design faces significant challenges in managing increasingly complex
wireless environments while ensuring network Quality of Service (QoS)
performance. This paper explores the potential integration of advanced
Artificial Intelligence (AI) methods into the design of Wi-Fi MAC protocols. We
propose AI-MAC, an innovative approach that employs machine learning algorithms
to dynamically adapt to changing network conditions, optimize channel access,
mitigate interference, and ensure deterministic latency. By intelligently
predicting and managing interference, AI-MAC aims to provide a robust solution
for next generation of Wi-Fi networks, enabling seamless connectivity and
enhanced QoS. Our experimental results demonstrate that AI-MAC significantly
reduces both interference and latency, paving the way for more reliable and
efficient wireless communications in the increasingly crowded ISM band.",2024-10-21,2024,2024-10,medical
Random Token Fusion for Multi-View Medical Diagnosis,"In multi-view medical diagnosis, deep learning-based models often fuse
information from different imaging perspectives to improve diagnostic
performance. However, existing approaches are prone to overfitting and rely
heavily on view-specific features, which can lead to trivial solutions. In this
work, we introduce Random Token Fusion (RTF), a novel technique designed to
enhance multi-view medical image analysis using vision transformers. By
integrating randomness into the feature fusion process during training, RTF
addresses the issue of overfitting and enhances the robustness and accuracy of
diagnostic models without incurring any additional cost at inference. We
validate our approach on standard mammography and chest X-ray benchmark
datasets. Through extensive experiments, we demonstrate that RTF consistently
improves the performance of existing fusion methods, paving the way for a new
generation of multi-view medical foundation models.",2024-10-21,2024,2024-10,medical
Fine-Tuning LLMs for Reliable Medical Question-Answering Services,"We present an advanced approach to medical question-answering (QA) services,
using fine-tuned Large Language Models (LLMs) to improve the accuracy and
reliability of healthcare information. Our study focuses on optimizing models
like LLaMA-2 and Mistral, which have shown great promise in delivering precise,
reliable medical answers. By leveraging comprehensive datasets, we applied
fine-tuning techniques such as rsDoRA+ and ReRAG. rsDoRA+ enhances model
performance through a combination of decomposed model weights, varied learning
rates for low-rank matrices, and rank stabilization, leading to improved
efficiency. ReRAG, which integrates retrieval on demand and question rewriting,
further refines the accuracy of the responses. This approach enables healthcare
providers to access fast, dependable information, aiding in more efficient
decision-making and fostering greater patient trust. Our work highlights the
potential of fine-tuned LLMs to significantly improve the quality and
accessibility of medical information services, ultimately contributing to
better healthcare outcomes for all.",2024-10-21,2024,2024-10,medical
"Development of CNN Architectures using Transfer Learning Methods for
  Medical Image Classification","The application of deep learning-based architecture has seen a tremendous
rise in recent years. For example, medical image classification using deep
learning achieved breakthrough results. Convolutional Neural Networks (CNNs)
are implemented predominantly in medical image classification and segmentation.
On the other hand, transfer learning has emerged as a prominent supporting tool
for enhancing the efficiency and accuracy of deep learning models. This paper
investigates the development of CNN architectures using transfer learning
techniques in the field of medical image classification using a timeline
mapping model for key image classification challenges. Our findings help make
an informed decision while selecting the optimum and state-of-the-art CNN
architectures.",2024-10-22,2024,2024-10,medical
"Explaining Bayesian Networks in Natural Language using Factor Arguments.
  Evaluation in the medical domain","In this paper, we propose a model for building natural language explanations
for Bayesian Network Reasoning in terms of factor arguments, which are
argumentation graphs of flowing evidence, relating the observed evidence to a
target variable we want to learn about. We introduce the notion of factor
argument independence to address the outstanding question of defining when
arguments should be presented jointly or separately and present an algorithm
that, starting from the evidence nodes and a target node, produces a list of
all independent factor arguments ordered by their strength. Finally, we
implemented a scheme to build natural language explanations of Bayesian
Reasoning using this approach. Our proposal has been validated in the medical
domain through a human-driven evaluation study where we compare the Bayesian
Network Reasoning explanations obtained using factor arguments with an
alternative explanation method. Evaluation results indicate that our proposed
explanation approach is deemed by users as significantly more useful for
understanding Bayesian Network Reasoning than another existing explanation
method it is compared to.",2024-10-23,2024,2024-10,medical
"Which Client is Reliable?: A Reliable and Personalized Prompt-based
  Federated Learning for Medical Image Question Answering","Conventional medical artificial intelligence (AI) models face barriers in
clinical application and ethical issues owing to their inability to handle the
privacy-sensitive characteristics of medical data. We present a novel
personalized federated learning (pFL) method for medical visual question
answering (VQA) models, addressing privacy reliability challenges in the
medical domain. Our method introduces learnable prompts into a Transformer
architecture to efficiently train it on diverse medical datasets without
massive computational costs. Then we introduce a reliable client VQA model that
incorporates Dempster-Shafer evidence theory to quantify uncertainty in
predictions, enhancing the model's reliability. Furthermore, we propose a novel
inter-client communication mechanism that uses maximum likelihood estimation to
balance accuracy and uncertainty, fostering efficient integration of insights
across clients.",2024-10-23,2024,2024-10,medical
AI Readiness in Healthcare through Storytelling XAI,"Artificial Intelligence is rapidly advancing and radically impacting everyday
life, driven by the increasing availability of computing power. Despite this
trend, the adoption of AI in real-world healthcare is still limited. One of the
main reasons is the trustworthiness of AI models and the potential hesitation
of domain experts with model predictions. Explainable Artificial Intelligence
(XAI) techniques aim to address these issues. However, explainability can mean
different things to people with different backgrounds, expertise, and goals. To
address the target audience with diverse needs, we develop storytelling XAI. In
this research, we have developed an approach that combines multi-task
distillation with interpretability techniques to enable audience-centric
explainability. Using multi-task distillation allows the model to exploit the
relationships between tasks, potentially improving interpretability as each
task supports the other leading to an enhanced interpretability from the
perspective of a domain expert. The distillation process allows us to extend
this research to large deep models that are highly complex. We focus on both
model-agnostic and model-specific methods of interpretability, supported by
textual justification of the results in healthcare through our use case. Our
methods increase the trust of both the domain experts and the machine learning
experts to enable a responsible AI.",2024-10-24,2024,2024-10,medical
"AutoMIR: Effective Zero-Shot Medical Information Retrieval without
  Relevance Labels","Medical information retrieval (MIR) is essential for retrieving relevant
medical knowledge from diverse sources, including electronic health records,
scientific literature, and medical databases. However, achieving effective
zero-shot dense retrieval in the medical domain poses substantial challenges
due to the lack of relevance-labeled data. In this paper, we introduce a novel
approach called Self-Learning Hypothetical Document Embeddings (SL-HyDE) to
tackle this issue. SL-HyDE leverages large language models (LLMs) as generators
to generate hypothetical documents based on a given query. These generated
documents encapsulate key medical context, guiding a dense retriever in
identifying the most relevant documents. The self-learning framework
progressively refines both pseudo-document generation and retrieval, utilizing
unlabeled medical corpora without requiring any relevance-labeled data.
Additionally, we present the Chinese Medical Information Retrieval Benchmark
(CMIRB), a comprehensive evaluation framework grounded in real-world medical
scenarios, encompassing five tasks and ten datasets. By benchmarking ten models
on CMIRB, we establish a rigorous standard for evaluating medical information
retrieval systems. Experimental results demonstrate that SL-HyDE significantly
surpasses existing methods in retrieval accuracy while showcasing strong
generalization and scalability across various LLM and retriever configurations.
CMIRB data and evaluation code are publicly available at:
https://github.com/CMIRB-benchmark/CMIRB.",2024-10-26,2024,2024-10,medical
MedGo: A Chinese Medical Large Language Model,"Large models are a hot research topic in the field of artificial
intelligence. Leveraging their generative capabilities has the potential to
enhance the level and quality of medical services. In response to the
limitations of current large language models, which often struggle with
accuracy and have narrow capabilities in medical applications, this paper
presents a Chinese medical large language model, MedGo. MedGo was trained using
a combination of high quality unsupervised medical data, supervised data, and
preference alignment data, aimed at enhancing both its versatility and
precision in medical tasks. The model was evaluated through the public CBLUE
benchmark and a manually constructed dataset ClinicalQA. The results
demonstrate that MedGo achieved promising performance across various Chinese
medical information processing tasks, achieved the first place in the CBLUE
evaluation. Additionally, on our constructed dataset ClinicalQA, MedGo
outperformed its base model Qwen2, highlighting its potential to improve both
automated medical question answering and clinical decision support. These
experimental results demonstrate that MedGo possesses strong information
processing capabilities in the medical field. At present, we have successfully
deployed MedGo at Shanghai East Hospital.",2024-10-27,2024,2024-10,medical
"R-LLaVA: Improving Med-VQA Understanding through Visual Region of
  Interest","Artificial intelligence has made significant strides in medical visual
question answering (Med-VQA), yet prevalent studies often interpret images
holistically, overlooking the visual regions of interest that may contain
crucial information, potentially aligning with a doctor's prior knowledge that
can be incorporated with minimal annotations (e.g., bounding boxes). To address
this gap, this paper introduces R-LLaVA, designed to enhance biomedical VQA
understanding by integrating simple medical annotations as prior knowledge
directly into the image space through CLIP. These annotated visual regions of
interest are then fed into the LLaVA model during training, aiming to enrich
the model's understanding of biomedical queries. Experimental evaluation on
four standard Med-VQA datasets demonstrates R-LLaVA's superiority over existing
state-of-the-art (SoTA) methods. Additionally, to verify the model's capability
in visual comprehension, a novel multiple-choice medical visual understanding
dataset is introduced, confirming the positive impact of focusing on visual
regions of interest in advancing biomedical VQA understanding.",2024-10-27,2024,2024-10,medical
Large Language Model Benchmarks in Medical Tasks,"With the increasing application of large language models (LLMs) in the
medical domain, evaluating these models' performance using benchmark datasets
has become crucial. This paper presents a comprehensive survey of various
benchmark datasets employed in medical LLM tasks. These datasets span multiple
modalities including text, image, and multimodal benchmarks, focusing on
different aspects of medical knowledge such as electronic health records
(EHRs), doctor-patient dialogues, medical question-answering, and medical image
captioning. The survey categorizes the datasets by modality, discussing their
significance, data structure, and impact on the development of LLMs for
clinical tasks such as diagnosis, report generation, and predictive decision
support. Key benchmarks include MIMIC-III, MIMIC-IV, BioASQ, PubMedQA, and
CheXpert, which have facilitated advancements in tasks like medical report
generation, clinical summarization, and synthetic data generation. The paper
summarizes the challenges and opportunities in leveraging these benchmarks for
advancing multimodal medical intelligence, emphasizing the need for datasets
with a greater degree of language diversity, structured omics data, and
innovative approaches to synthesis. This work also provides a foundation for
future research in the application of LLMs in medicine, contributing to the
evolving field of medical artificial intelligence.",2024-10-28,2024,2024-10,medical
"A Perspective for Adapting Generalist AI to Specialized Medical AI
  Applications and Their Challenges","The integration of Large Language Models (LLMs) into medical applications has
sparked widespread interest across the healthcare industry, from drug discovery
and development to clinical decision support, assisting telemedicine, medical
devices, and healthcare insurance applications. This perspective paper aims to
discuss the inner workings of building LLM-powered medical AI applications and
introduces a comprehensive framework for their development. We review existing
literature and outline the unique challenges of applying LLMs in specialized
medical contexts. Additionally, we introduce a three-step framework to organize
medical LLM research activities: 1) Modeling: breaking down complex medical
workflows into manageable steps for developing medical-specific models; 2)
Optimization: optimizing the model performance with crafted prompts and
integrating external knowledge and tools, and 3) System engineering:
decomposing complex tasks into subtasks and leveraging human expertise for
building medical AI applications. Furthermore, we offer a detailed use case
playbook that describes various LLM-powered medical AI applications, such as
optimizing clinical trial design, enhancing clinical decision support, and
advancing medical imaging analysis. Finally, we discuss various challenges and
considerations for building medical AI applications with LLMs, such as handling
hallucination issues, data ownership and compliance, privacy, intellectual
property considerations, compute cost, sustainability issues, and responsible
AI requirements.",2024-10-28,2024,2024-10,medical
"Efficient Bilinear Attention-based Fusion for Medical Visual Question
  Answering","Medical Visual Question Answering (MedVQA) has attracted growing interest at
the intersection of computer vision and natural language processing. By
interpreting medical images and providing precise answers to relevant clinical
inquiries, MedVQA has the potential to support diagnostic decision-making and
reduce workload across various domains, particularly radiology. While recent
approaches rely heavily on unified large pre-trained Visual-Language Models,
research on more efficient fusion mechanisms remains relatively limited in this
domain. In this paper, we introduce a novel fusion model, OMniBAN, that
integrates Orthogonality loss, Multi-head attention, and a Bilinear Attention
Network to achieve high computational efficiency alongside solid performance.
We conduct comprehensive experiments and provide insights into how bilinear
attention fusion can approximate the performance of larger fusion models like
cross-modal Transformer. Our results demonstrate that OMniBAN outperforms
traditional approaches on key MedVQA benchmarks while maintaining a lower
computational cost. This balance between efficiency and accuracy suggests that
OMniBAN could be a viable option for real-world medical image question
answering, where computational resources are often constrained.",2024-10-28,2024,2024-10,medical
"MAPUNetR: A Hybrid Vision Transformer and U-Net Architecture for
  Efficient and Interpretable Medical Image Segmentation","Medical image segmentation is pivotal in healthcare, enhancing diagnostic
accuracy, informing treatment strategies, and tracking disease progression.
This process allows clinicians to extract critical information from visual
data, enabling personalized patient care. However, developing neural networks
for segmentation remains challenging, especially when preserving image
resolution, which is essential in detecting subtle details that influence
diagnoses. Moreover, the lack of transparency in these deep learning models has
slowed their adoption in clinical practice. Efforts in model interpretability
are increasingly focused on making these models' decision-making processes more
transparent. In this paper, we introduce MAPUNetR, a novel architecture that
synergizes the strengths of transformer models with the proven U-Net framework
for medical image segmentation. Our model addresses the resolution preservation
challenge and incorporates attention maps highlighting segmented regions,
increasing accuracy and interpretability. Evaluated on the BraTS 2020 dataset,
MAPUNetR achieved a dice score of 0.88 and a dice coefficient of 0.92 on the
ISIC 2018 dataset. Our experiments show that the model maintains stable
performance and potential as a powerful tool for medical image segmentation in
clinical practice.",2024-10-29,2024,2024-10,medical
"Parameter-Efficient Fine-Tuning Medical Multimodal Large Language Models
  for Medical Visual Grounding","Multimodal Large Language Models (MLLMs) inherit the superior text
understanding capabilities of LLMs and extend these capabilities to multimodal
scenarios. These models achieve excellent results in the general domain of
multimodal tasks. However, in the medical domain, the substantial training
costs and the requirement for extensive medical data pose challenges to the
development of medical MLLMs. Furthermore, due to the free-text form of
answers, tasks such as visual grounding that need to produce output in a
prescribed form become difficult for MLLMs. So far, there have been no medical
MLLMs works in medical visual grounding area. For the medical vision grounding
task, which involves identifying locations in medical images based on short
text descriptions, we propose Parameter-efficient Fine-tuning medical
multimodal large language models for Medcial Visual Grounding (PFMVG). To
validate the performance of the model, we evaluate it on a public benchmark
dataset for medical visual grounding, where it achieves competitive results,
and significantly outperforming GPT-4v. Our code will be open sourced after
peer review.",2024-10-31,2024,2024-10,medical
"Beyond Label Attention: Transparency in Language Models for Automated
  Medical Coding via Dictionary Learning","Medical coding, the translation of unstructured clinical text into
standardized medical codes, is a crucial but time-consuming healthcare
practice. Though large language models (LLM) could automate the coding process
and improve the efficiency of such tasks, interpretability remains paramount
for maintaining patient trust. Current efforts in interpretability of medical
coding applications rely heavily on label attention mechanisms, which often
leads to the highlighting of extraneous tokens irrelevant to the ICD code. To
facilitate accurate interpretability in medical language models, this paper
leverages dictionary learning that can efficiently extract sparsely activated
representations from dense language model embeddings in superposition. Compared
with common label attention mechanisms, our model goes beyond token-level
representations by building an interpretable dictionary which enhances the
mechanistic-based explanations for each ICD code prediction, even when the
highlighted tokens are medically irrelevant. We show that dictionary features
can steer model behavior, elucidate the hidden meanings of upwards of 90% of
medically irrelevant tokens, and are human interpretable.",2024-10-31,2024,2024-10,medical
"Medical X-Ray Image Enhancement Using Global Contrast-Limited Adaptive
  Histogram Equalization","In medical imaging, accurate diagnosis heavily relies on effective image
enhancement techniques, particularly for X-ray images. Existing methods often
suffer from various challenges such as sacrificing global image characteristics
over local image characteristics or vice versa. In this paper, we present a
novel approach, called G-CLAHE (Global-Contrast Limited Adaptive Histogram
Equalization), which perfectly suits medical imaging with a focus on X-rays.
This method adapts from Global Histogram Equalization (GHE) and Contrast
Limited Adaptive Histogram Equalization (CLAHE) to take both advantages and
avoid weakness to preserve local and global characteristics. Experimental
results show that it can significantly improve current state-of-the-art
algorithms to effectively address their limitations and enhance the contrast
and quality of X-ray images for diagnostic accuracy.",2024-11-02,2024,2024-11,medical
"Optical Flow Representation Alignment Mamba Diffusion Model for Medical
  Video Generation","Medical video generation models are expected to have a profound impact on the
healthcare industry, including but not limited to medical education and
training, surgical planning, and simulation. Current video diffusion models
typically build on image diffusion architecture by incorporating temporal
operations (such as 3D convolution and temporal attention). Although this
approach is effective, its oversimplification limits spatio-temporal
performance and consumes substantial computational resources. To counter this,
we propose Medical Simulation Video Generator (MedSora), which incorporates
three key elements: i) a video diffusion framework integrates the advantages of
attention and Mamba, balancing low computational load with high-quality video
generation, ii) an optical flow representation alignment method that implicitly
enhances attention to inter-frame pixels, and iii) a video variational
autoencoder (VAE) with frequency compensation addresses the information loss of
medical features that occurs when transforming pixel space into latent features
and then back to pixel frames. Extensive experiments and applications
demonstrate that MedSora exhibits superior visual quality in generating medical
videos, outperforming the most advanced baseline methods. Further results and
code are available at https://wongzbb.github.io/MedSora",2024-11-03,2024,2024-11,medical
Diagnosing Medical Datasets with Training Dynamics,"This study explores the potential of using training dynamics as an automated
alternative to human annotation for evaluating the quality of training data.
The framework used is Data Maps, which classifies data points into categories
such as easy-to-learn, hard-to-learn, and ambiguous (Swayamdipta et al., 2020).
Swayamdipta et al. (2020) highlight that difficult-to-learn examples often
contain errors, and ambiguous cases significantly impact model training. To
confirm the reliability of these findings, we replicated the experiments using
a challenging dataset, with a focus on medical question answering. In addition
to text comprehension, this field requires the acquisition of detailed medical
knowledge, which further complicates the task. A comprehensive evaluation was
conducted to assess the feasibility and transferability of the Data Maps
framework to the medical domain. The evaluation indicates that the framework is
unsuitable for addressing datasets' unique challenges in answering medical
questions.",2024-11-03,2024,2024-11,medical
"Simulation of Nanorobots with Artificial Intelligence and Reinforcement
  Learning for Advanced Cancer Cell Detection and Tracking","Nanorobots are a promising development in targeted drug delivery and the
treatment of neurological disorders, with potential for crossing the
blood-brain barrier (BBB). These small devices leverage advancements in
nanotechnology and bioengineering for precise navigation and targeted payload
delivery, particularly for conditions like brain tumors, Alzheimer's disease,
and Parkinson's disease. Recent progress in artificial intelligence (AI) and
machine learning (ML) has improved the navigation and effectiveness of
nanorobots, allowing them to detect and interact with cancer cells through
biomarker analysis. This study presents a new reinforcement learning (RL)
framework for optimizing nanorobot navigation in complex biological
environments, focusing on cancer cell detection by analyzing the concentration
gradients of surrounding biomarkers. We utilize a computer simulation model to
explore the behavior of nanorobots in a three-dimensional space with cancer
cells and biological barriers. The proposed method uses Q-learning to refine
movement strategies based on real-time biomarker concentration data, enabling
nanorobots to autonomously navigate to cancerous tissues for targeted drug
delivery. This research lays the groundwork for future laboratory experiments
and clinical applications, with implications for personalized medicine and less
invasive cancer treatments. The integration of intelligent nanorobots could
revolutionize therapeutic strategies, reducing side effects and enhancing
treatment effectiveness for cancer patients. Further research will investigate
the practical deployment of these technologies in medical settings, aiming to
unlock the full potential of nanorobotics in healthcare.",2024-11-04,2024,2024-11,medical
Foundation AI Model for Medical Image Segmentation,"Foundation models refer to artificial intelligence (AI) models that are
trained on massive amounts of data and demonstrate broad generalizability
across various tasks with high accuracy. These models offer versatile,
one-for-many or one-for-all solutions, eliminating the need for developing
task-specific AI models. Examples of such foundation models include the Chat
Generative Pre-trained Transformer (ChatGPT) and the Segment Anything Model
(SAM). These models have been trained on millions to billions of samples and
have shown wide-ranging and accurate applications in numerous tasks such as
text processing (using ChatGPT) and natural image segmentation (using SAM). In
medical image segmentation - finding target regions in medical images - there
is a growing need for these one-for-many or one-for-all foundation models. Such
models could obviate the need to develop thousands of task-specific AI models,
which is currently standard practice in the field. They can also be adapted to
tasks with datasets too small for effective training. We discuss two paths to
achieve foundation models for medical image segmentation and comment on
progress, challenges, and opportunities. One path is to adapt or fine-tune
existing models, originally developed for natural images, for use with medical
images. The second path entails building models from scratch, exclusively
training on medical images.",2024-11-05,2024,2024-11,medical
"Medical Adaptation of Large Language and Vision-Language Models: Are We
  Making Progress?","Several recent works seek to develop foundation models specifically for
medical applications, adapting general-purpose large language models (LLMs) and
vision-language models (VLMs) via continued pretraining on publicly available
biomedical corpora. These works typically claim that such domain-adaptive
pretraining (DAPT) improves performance on downstream medical tasks, such as
answering medical licensing exam questions. In this paper, we compare seven
public ""medical"" LLMs and two VLMs against their corresponding base models,
arriving at a different conclusion: all medical VLMs and nearly all medical
LLMs fail to consistently improve over their base models in the zero-/few-shot
prompting regime for medical question-answering (QA) tasks. For instance,
across the tasks and model pairs we consider in the 3-shot setting, medical
LLMs only outperform their base models in 12.1% of cases, reach a (statistical)
tie in 49.8% of cases, and are significantly worse than their base models in
the remaining 38.2% of cases. Our conclusions are based on (i) comparing each
medical model head-to-head, directly against the corresponding base model; (ii)
optimizing the prompts for each model separately; and (iii) accounting for
statistical uncertainty in comparisons. While these basic practices are not
consistently adopted in the literature, our ablations show that they
substantially impact conclusions. Our findings suggest that state-of-the-art
general-domain models may already exhibit strong medical knowledge and
reasoning capabilities, and offer recommendations to strengthen the conclusions
of future studies.",2024-11-06,2024,2024-11,medical
"Humans and Large Language Models in Clinical Decision Support: A Study
  with Medical Calculators","Although large language models (LLMs) have been assessed for general medical
knowledge using licensing exams, their ability to support clinical
decision-making, such as selecting medical calculators, remains uncertain. We
assessed nine LLMs, including open-source, proprietary, and domain-specific
models, with 1,009 multiple-choice question-answer pairs across 35 clinical
calculators and compared LLMs to humans on a subset of questions. While the
highest-performing LLM, OpenAI o1, provided an answer accuracy of 66.0% (CI:
56.7-75.3%) on the subset of 100 questions, two human annotators nominally
outperformed LLMs with an average answer accuracy of 79.5% (CI: 73.5-85.0%).
Ultimately, we evaluated medical trainees and LLMs in recommending medical
calculators across clinical scenarios like risk stratification and diagnosis.
With error analysis showing that the highest-performing LLMs continue to make
mistakes in comprehension (49.3% of errors) and calculator knowledge (7.1% of
errors), our findings highlight that LLMs are not superior to humans in
calculator recommendation.",2024-11-08,2024,2024-11,medical
"GuidelineGuard: An Agentic Framework for Medical Note Evaluation with
  Guideline Adherence","Although rapid advancements in Large Language Models (LLMs) are facilitating
the integration of artificial intelligence-based applications and services in
healthcare, limited research has focused on the systematic evaluation of
medical notes for guideline adherence. This paper introduces GuidelineGuard, an
agentic framework powered by LLMs that autonomously analyzes medical notes,
such as hospital discharge and office visit notes, to ensure compliance with
established healthcare guidelines. By identifying deviations from recommended
practices and providing evidence-based suggestions, GuidelineGuard helps
clinicians adhere to the latest standards from organizations like the WHO and
CDC. This framework offers a novel approach to improving documentation quality
and reducing clinical errors.",2024-11-09,2024,2024-11,medical
"Data-Driven Analysis of AI in Medical Device Software in China: Deep
  Learning and General AI Trends Based on Regulatory Data","Artificial intelligence (AI) in medical device software (MDSW) represents a
transformative clinical technology, attracting increasing attention within both
the medical community and the regulators. In this study, we leverage a
data-driven approach to automatically extract and analyze AI-enabled medical
devices (AIMD) from the National Medical Products Administration (NMPA)
regulatory database. The continued increase in publicly available regulatory
data requires scalable methods for analysis. Automation of regulatory
information screening is essential to create reproducible insights that can be
quickly updated in an ever changing medical device landscape. More than 4
million entries were assessed, identifying 2,174 MDSW registrations, including
531 standalone applications and 1,643 integrated within medical devices, of
which 43 were AI-enabled. It was shown that the leading medical specialties
utilizing AIMD include respiratory (20.5%), ophthalmology/endocrinology
(12.8%), and orthopedics (10.3%). This approach greatly improves the speed of
data extracting providing a greater ability to compare and contrast. This study
provides the first extensive, data-driven exploration of AIMD in China,
showcasing the potential of automated regulatory data analysis in understanding
and advancing the landscape of AI in medical technology.",2024-11-11,2024,2024-11,medical
"The Limited Impact of Medical Adaptation of Large Language and
  Vision-Language Models","Several recent works seek to adapt general-purpose large language models
(LLMs) and vision-language models (VLMs) for medical applications through
continued pretraining on publicly available biomedical corpora. These works
typically claim that such domain-adaptive pretraining improves performance on
various downstream medical tasks, such as answering medical exam questions. In
this paper, we compare ten ""medical"" LLMs and two VLMs against their
corresponding base models, arriving at a different conclusion: all medical VLMs
and nearly all medical LLMs fail to consistently improve over their base models
in the zero-/few-shot prompting and supervised fine-tuning regimes for medical
question answering (QA). For instance, on clinical-note-based QA tasks in the
3-shot setting, medical LLMs outperform their base models in only 26.7% of
cases, reach a (statistical) tie in 16.7% of cases, and perform significantly
worse in the remaining 56.7% of cases. Our conclusions are based on (i)
comparing each medical model directly against its base model; (ii) optimizing
the prompts for each model separately in zero-/few-shot prompting; and (iii)
accounting for statistical uncertainty in comparisons. Our findings suggest
that state-of-the-art general-domain models may already exhibit strong medical
knowledge and reasoning capabilities, and offer recommendations to strengthen
the conclusions of future studies.",2024-11-13,2024,2024-11,medical
"Comprehensive and Practical Evaluation of Retrieval-Augmented Generation
  Systems for Medical Question Answering","Retrieval-augmented generation (RAG) has emerged as a promising approach to
enhance the performance of large language models (LLMs) in knowledge-intensive
tasks such as those from medical domain. However, the sensitive nature of the
medical domain necessitates a completely accurate and trustworthy system. While
existing RAG benchmarks primarily focus on the standard retrieve-answer
setting, they overlook many practical scenarios that measure crucial aspects of
a reliable medical system. This paper addresses this gap by providing a
comprehensive evaluation framework for medical question-answering (QA) systems
in a RAG setting for these situations, including sufficiency, integration, and
robustness. We introduce Medical Retrieval-Augmented Generation Benchmark
(MedRGB) that provides various supplementary elements to four medical QA
datasets for testing LLMs' ability to handle these specific scenarios.
Utilizing MedRGB, we conduct extensive evaluations of both state-of-the-art
commercial LLMs and open-source models across multiple retrieval conditions.
Our experimental results reveals current models' limited ability to handle
noise and misinformation in the retrieved documents. We further analyze the
LLMs' reasoning processes to provides valuable insights and future directions
for developing RAG systems in this critical medical domain.",2024-11-14,2024,2024-11,medical
A Benchmark for Long-Form Medical Question Answering,"There is a lack of benchmarks for evaluating large language models (LLMs) in
long-form medical question answering (QA). Most existing medical QA evaluation
benchmarks focus on automatic metrics and multiple-choice questions. While
valuable, these benchmarks fail to fully capture or assess the complexities of
real-world clinical applications where LLMs are being deployed. Furthermore,
existing studies on evaluating long-form answer generation in medical QA are
primarily closed-source, lacking access to human medical expert annotations,
which makes it difficult to reproduce results and enhance existing baselines.
In this work, we introduce a new publicly available benchmark featuring
real-world consumer medical questions with long-form answer evaluations
annotated by medical doctors. We performed pairwise comparisons of responses
from various open and closed-source medical and general-purpose LLMs based on
criteria such as correctness, helpfulness, harmfulness, and bias. Additionally,
we performed a comprehensive LLM-as-a-judge analysis to study the alignment
between human judgments and LLMs. Our preliminary results highlight the strong
potential of open LLMs in medical QA compared to leading closed models. Code &
Data: https://github.com/lavita-ai/medical-eval-sphere",2024-11-14,2024,2024-11,medical
"Artificial Intelligence for Infectious Disease Prediction and
  Prevention: A Comprehensive Review","Artificial Intelligence (AI) and infectious diseases prediction have recently
experienced a common development and advancement. Machine learning (ML)
apparition, along with deep learning (DL) emergence, extended many approaches
against diseases apparition and their spread. And despite their outstanding
results in predicting infectious diseases, conflicts appeared regarding the
types of data used and how they can be studied, analyzed, and exploited using
various emerging methods. This has led to some ongoing discussions in the
field. This research aims not only to provide an overview of what has been
accomplished, but also to highlight the difficulties related to the types of
data used, and the learning methods applied for each research objective. It
categorizes these contributions into three areas: predictions using Public
Health Data to prevent the spread of a transmissible disease within a region;
predictions using Patients' Medical Data to detect whether a person is infected
by a transmissible disease; and predictions using both Public and patient
medical data to estimate the extent of disease spread in a population. The
paper also critically assesses the potential of AI and outlines its limitations
in infectious disease management.",2024-11-14,2024,2024-11,medical
"Exploring Zero-Shot Anomaly Detection with CLIP in Medical Imaging: Are
  We There Yet?","Zero-shot anomaly detection (ZSAD) offers potential for identifying anomalies
in medical imaging without task-specific training. In this paper, we evaluate
CLIP-based models, originally developed for industrial tasks, on brain tumor
detection using the BraTS-MET dataset. Our analysis examines their ability to
detect medical-specific anomalies with no or minimal supervision, addressing
the challenges posed by limited data annotation. While these models show
promise in transferring general knowledge to medical tasks, their performance
falls short of the precision required for clinical use. Our findings highlight
the need for further adaptation before CLIP-based models can be reliably
applied to medical anomaly detection.",2024-11-14,2024,2024-11,medical
"Med-Bot: An AI-Powered Assistant to Provide Accurate and Reliable
  Medical Information","This paper introduces Med-Bot, an AI-powered chatbot designed to provide
users with accurate and reliable medical information. Utilizing advanced
libraries and frameworks such as PyTorch, Chromadb, Langchain and Autogptq,
Med-Bot is built to handle the complexities of natural language understanding
in a healthcare context. The integration of llamaassisted data processing and
AutoGPT-Q provides enhanced performance in processing and responding to queries
based on PDFs of medical literature, ensuring that users receive precise and
trustworthy information. This research details the methodologies employed in
developing Med-Bot and evaluates its effectiveness in disseminating healthcare
information.",2024-11-14,2024,2024-11,medical
Explainable Artificial Intelligence for Medical Applications: A Review,"The continuous development of artificial intelligence (AI) theory has
propelled this field to unprecedented heights, owing to the relentless efforts
of scholars and researchers. In the medical realm, AI takes a pivotal role,
leveraging robust machine learning (ML) algorithms. AI technology in medical
imaging aids physicians in X-ray, computed tomography (CT) scans, and magnetic
resonance imaging (MRI) diagnoses, conducts pattern recognition and disease
prediction based on acoustic data, delivers prognoses on disease types and
developmental trends for patients, and employs intelligent health management
wearable devices with human-computer interaction technology to name but a few.
While these well-established applications have significantly assisted in
medical field diagnoses, clinical decision-making, and management,
collaboration between the medical and AI sectors faces an urgent challenge: How
to substantiate the reliability of decision-making? The underlying issue stems
from the conflict between the demand for accountability and result transparency
in medical scenarios and the black-box model traits of AI. This article reviews
recent research grounded in explainable artificial intelligence (XAI), with an
emphasis on medical practices within the visual, audio, and multimodal
perspectives. We endeavour to categorise and synthesise these practices, aiming
to provide support and guidance for future researchers and healthcare
professionals.",2024-11-15,2024,2024-11,medical
"Towards Next-Generation Medical Agent: How o1 is Reshaping
  Decision-Making in Medical Scenarios","Artificial Intelligence (AI) has become essential in modern healthcare, with
large language models (LLMs) offering promising advances in clinical
decision-making. Traditional model-based approaches, including those leveraging
in-context demonstrations and those with specialized medical fine-tuning, have
demonstrated strong performance in medical language processing but struggle
with real-time adaptability, multi-step reasoning, and handling complex medical
tasks. Agent-based AI systems address these limitations by incorporating
reasoning traces, tool selection based on context, knowledge retrieval, and
both short- and long-term memory. These additional features enable the medical
AI agent to handle complex medical scenarios where decision-making should be
built on real-time interaction with the environment. Therefore, unlike
conventional model-based approaches that treat medical queries as isolated
questions, medical AI agents approach them as complex tasks and behave more
like human doctors. In this paper, we study the choice of the backbone LLM for
medical AI agents, which is the foundation for the agent's overall reasoning
and action generation. In particular, we consider the emergent o1 model and
examine its impact on agents' reasoning, tool-use adaptability, and real-time
information retrieval across diverse clinical scenarios, including high-stakes
settings such as intensive care units (ICUs). Our findings demonstrate o1's
ability to enhance diagnostic accuracy and consistency, paving the way for
smarter, more responsive AI tools that support better patient outcomes and
decision-making efficacy in clinical practice.",2024-11-16,2024,2024-11,medical
BianCang: A Traditional Chinese Medicine Large Language Model,"The rise of large language models (LLMs) has driven significant progress in
medical applications, including traditional Chinese medicine (TCM). However,
current medical LLMs struggle with TCM diagnosis and syndrome differentiation
due to substantial differences between TCM and modern medical theory, and the
scarcity of specialized, high-quality corpora. This paper addresses these
challenges by proposing BianCang, a TCM-specific LLM, using a two-stage
training process that first injects domain-specific knowledge and then aligns
it through targeted stimulation. To enhance diagnostic and differentiation
capabilities, we constructed pre-training corpora, instruction-aligned datasets
based on real hospital records, and the ChP-TCM dataset derived from the
Pharmacopoeia of the People's Republic of China. We compiled extensive TCM and
medical corpora for continuous pre-training and supervised fine-tuning,
building a comprehensive dataset to refine the model's understanding of TCM.
Evaluations across 11 test sets involving 29 models and 4 tasks demonstrate the
effectiveness of BianCang, offering valuable insights for future research.
Code, datasets, and models are available at
https://github.com/QLU-NLP/BianCang.",2024-11-17,2024,2024-11,medical
TP-UNet: Temporal Prompt Guided UNet for Medical Image Segmentation,"The advancement of medical image segmentation techniques has been propelled
by the adoption of deep learning techniques, particularly UNet-based
approaches, which exploit semantic information to improve the accuracy of
segmentations. However, the order of organs in scanned images has been
disregarded by current medical image segmentation approaches based on UNet.
Furthermore, the inherent network structure of UNet does not provide direct
capabilities for integrating temporal information. To efficiently integrate
temporal information, we propose TP-UNet that utilizes temporal prompts,
encompassing organ-construction relationships, to guide the segmentation UNet
model. Specifically, our framework is featured with cross-attention and
semantic alignment based on unsupervised contrastive learning to combine
temporal prompts and image features effectively. Extensive evaluations on two
medical image segmentation datasets demonstrate the state-of-the-art
performance of TP-UNet. Our implementation will be open-sourced after
acceptance.",2024-11-18,2024,2024-11,medical
"Ethical Challenges and Evolving Strategies in the Integration of
  Artificial Intelligence into Clinical Practice","Artificial intelligence (AI) has rapidly transformed various sectors,
including healthcare, where it holds the potential to revolutionize clinical
practice and improve patient outcomes. However, its integration into medical
settings brings significant ethical challenges that need careful consideration.
This paper examines the current state of AI in healthcare, focusing on five
critical ethical concerns: justice and fairness, transparency, patient consent
and confidentiality, accountability, and patient-centered and equitable care.
These concerns are particularly pressing as AI systems can perpetuate or even
exacerbate existing biases, often resulting from non-representative datasets
and opaque model development processes. The paper explores how bias, lack of
transparency, and challenges in maintaining patient trust can undermine the
effectiveness and fairness of AI applications in healthcare. In addition, we
review existing frameworks for the regulation and deployment of AI, identifying
gaps that limit the widespread adoption of these systems in a just and
equitable manner. Our analysis provides recommendations to address these
ethical challenges, emphasizing the need for fairness in algorithm design,
transparency in model decision-making, and patient-centered approaches to
consent and data privacy. By highlighting the importance of continuous ethical
scrutiny and collaboration between AI developers, clinicians, and ethicists, we
outline pathways for achieving more responsible and inclusive AI implementation
in healthcare. These strategies, if adopted, could enhance both the clinical
value of AI and the trustworthiness of AI systems among patients and healthcare
professionals, ensuring that these technologies serve all populations
equitably.",2024-11-18,2024,2024-11,medical
Medical Video Generation for Disease Progression Simulation,"Modeling disease progression is crucial for improving the quality and
efficacy of clinical diagnosis and prognosis, but it is often hindered by a
lack of longitudinal medical image monitoring for individual patients. To
address this challenge, we propose the first Medical Video Generation (MVG)
framework that enables controlled manipulation of disease-related image and
video features, allowing precise, realistic, and personalized simulations of
disease progression. Our approach begins by leveraging large language models
(LLMs) to recaption prompt for disease trajectory. Next, a controllable
multi-round diffusion model simulates the disease progression state for each
patient, creating realistic intermediate disease state sequence. Finally, a
diffusion-based video transition generation model interpolates disease
progression between these states. We validate our framework across three
medical imaging domains: chest X-ray, fundus photography, and skin image. Our
results demonstrate that MVG significantly outperforms baseline models in
generating coherent and clinically plausible disease trajectories. Two user
studies by veteran physicians, provide further validation and insights into the
clinical utility of the generated sequences. MVG has the potential to assist
healthcare providers in modeling disease trajectories, interpolating missing
medical image data, and enhancing medical education through realistic, dynamic
visualizations of disease progression.",2024-11-18,2024,2024-11,medical
Conversational Medical AI: Ready for Practice,"The shortage of doctors is creating a critical squeeze in access to medical
expertise. While conversational Artificial Intelligence (AI) holds promise in
addressing this problem, its safe deployment in patient-facing roles remains
largely unexplored in real-world medical settings. We present the first
large-scale evaluation of a physician-supervised LLM-based conversational agent
in a real-world medical setting.
  Our agent, Mo, was integrated into an existing medical advice chat service.
Over a three-week period, we conducted a randomized controlled experiment with
926 cases to evaluate patient experience and satisfaction. Among these, Mo
handled 298 complete patient interactions, for which we report
physician-assessed measures of safety and medical accuracy.
  Patients reported higher clarity of information (3.73 vs 3.62 out of 4, p <
0.05) and overall satisfaction (4.58 vs 4.42 out of 5, p < 0.05) with
AI-assisted conversations compared to standard care, while showing equivalent
levels of trust and perceived empathy. The high opt-in rate (81% among
respondents) exceeded previous benchmarks for AI acceptance in healthcare.
Physician oversight ensured safety, with 95% of conversations rated as ""good""
or ""excellent"" by general practitioners experienced in operating a medical
advice chat service.
  Our findings demonstrate that carefully implemented AI medical assistants can
enhance patient experience while maintaining safety standards through physician
supervision. This work provides empirical evidence for the feasibility of AI
deployment in healthcare communication and insights into the requirements for
successful integration into existing healthcare services.",2024-11-19,2024,2024-11,medical
"Enhancing Multi-Class Disease Classification: Neoplasms, Cardiovascular,
  Nervous System, and Digestive Disorders Using Advanced LLMs","In this research, we explored the improvement in terms of multi-class disease
classification via pre-trained language models over Medical-Abstracts-TC-Corpus
that spans five medical conditions. We excluded non-cancer conditions and
examined four specific diseases. We assessed four LLMs, BioBERT, XLNet, and
BERT, as well as a novel base model (Last-BERT). BioBERT, which was pre-trained
on medical data, demonstrated superior performance in medical text
classification (97% accuracy). Surprisingly, XLNet followed closely (96%
accuracy), demonstrating its generalizability across domains even though it was
not pre-trained on medical data. LastBERT, a custom model based on the lighter
version of BERT, also proved competitive with 87.10% accuracy (just under
BERT's 89.33%). Our findings confirm the importance of specialized models such
as BioBERT and also support impressions around more general solutions like
XLNet and well-tuned transformer architectures with fewer parameters (in this
case, LastBERT) in medical domain tasks.",2024-11-19,2024,2024-11,medical
"GraphCL: Graph-based Clustering for Semi-Supervised Medical Image
  Segmentation","Semi-supervised learning (SSL) has made notable advancements in medical image
segmentation (MIS), particularly in scenarios with limited labeled data and
significantly enhancing data utilization efficiency. Previous methods primarily
focus on complex training strategies to utilize unlabeled data but neglect the
importance of graph structural information. Different from existing methods, we
propose a graph-based clustering for semi-supervised medical image segmentation
(GraphCL) by jointly modeling graph data structure in a unified deep model. The
proposed GraphCL model enjoys several advantages. Firstly, to the best of our
knowledge, this is the first work to model the data structure information for
semi-supervised medical image segmentation (SSMIS). Secondly, to get the
clustered features across different graphs, we integrate both pairwise
affinities between local image features and raw features as inputs. Extensive
experimental results on three standard benchmarks show that the proposed
GraphCL algorithm outperforms state-of-the-art semi-supervised medical image
segmentation methods.",2024-11-20,2024,2024-11,medical
"Uni-Mlip: Unified Self-supervision for Medical Vision Language
  Pre-training","Recent advancements in vision-language pre-training via contrastive learning
have significantly improved performance across computer vision tasks. However,
in the medical domain, obtaining multimodal data is often costly and
challenging due to privacy, sensitivity, and annotation complexity. To mitigate
data scarcity while boosting model performance, we introduce \textbf{Uni-Mlip},
a unified self-supervision framework specifically designed to enhance medical
vision-language pre-training. Uni-Mlip seamlessly integrates cross-modality,
uni-modality, and fused-modality self-supervision techniques at the data-level
and the feature-level. Additionally, Uni-Mlip tailors uni-modal image
self-supervision to accommodate the unique characteristics of medical images.
Our experiments across datasets of varying scales demonstrate that Uni-Mlip
significantly surpasses current state-of-the-art methods in three key
downstream tasks: image-text retrieval, image classification, and visual
question answering (VQA).",2024-11-20,2024,2024-11,medical
Uterine Ultrasound Image Captioning Using Deep Learning Techniques,"Medical imaging has significantly revolutionized medical diagnostics and
treatment planning, progressing from early X-ray usage to sophisticated methods
like MRIs, CT scans, and ultrasounds. This paper investigates the use of deep
learning for medical image captioning, with a particular focus on uterine
ultrasound images. These images are vital in obstetrics and gynecology for
diagnosing and monitoring various conditions across different age groups.
However, their interpretation is often challenging due to their complexity and
variability. To address this, a deep learning-based medical image captioning
system was developed, integrating Convolutional Neural Networks with a
Bidirectional Gated Recurrent Unit network. This hybrid model processes both
image and text features to generate descriptive captions for uterine ultrasound
images. Our experimental results demonstrate the effectiveness of this approach
over baseline methods, with the proposed model achieving superior performance
in generating accurate and informative captions, as indicated by higher BLEU
and ROUGE scores. By enhancing the interpretation of uterine ultrasound images,
our research aims to assist medical professionals in making timely and accurate
diagnoses, ultimately contributing to improved patient care.",2024-11-21,2024,2024-11,medical
"Med-PerSAM: One-Shot Visual Prompt Tuning for Personalized Segment
  Anything Model in Medical Domain","Leveraging pre-trained models with tailored prompts for in-context learning
has proven highly effective in NLP tasks. Building on this success, recent
studies have applied a similar approach to the Segment Anything Model (SAM)
within a ``one-shot"" framework, where only a single reference image and its
label are employed. However, these methods face limitations in the medical
domain, primarily due to SAM's essential requirement for visual prompts and the
over-reliance on pixel similarity for generating them. This dependency may lead
to (1) inaccurate prompt generation and (2) clustering of point prompts,
resulting in suboptimal outcomes. To address these challenges, we introduce
\textbf{Med-PerSAM}, a novel and straightforward one-shot framework designed
for the medical domain. Med-PerSAM uses only visual prompt engineering and
eliminates the need for additional training of the pretrained SAM or human
intervention, owing to our novel automated prompt generation process. By
integrating our lightweight warping-based prompt tuning model with SAM, we
enable the extraction and iterative refinement of visual prompts, enhancing the
performance of the pre-trained SAM. This advancement is particularly meaningful
in the medical domain, where creating visual prompts poses notable challenges
for individuals lacking medical expertise. Our model outperforms various
foundational models and previous SAM-based approaches across diverse 2D medical
imaging datasets.",2024-11-25,2024,2024-11,medical
HOPPR Medical-Grade Platform for Medical Imaging AI,"Technological advances in artificial intelligence (AI) have enabled the
development of large vision language models (LVLMs) that are trained on
millions of paired image and text samples. Subsequent research efforts have
demonstrated great potential of LVLMs to achieve high performance in medical
imaging use cases (e.g., radiology report generation), but there remain
barriers that hinder the ability to deploy these solutions broadly. These
include the cost of extensive computational requirements for developing large
scale models, expertise in the development of sophisticated AI models, and the
difficulty in accessing substantially large, high-quality datasets that
adequately represent the population in which the LVLM solution is to be
deployed. The HOPPR Medical-Grade Platform addresses these barriers by
providing powerful computational infrastructure, a suite of foundation models
on top of which developers can fine-tune for their specific use cases, and a
robust quality management system that sets a standard for evaluating fine-tuned
models for deployment in clinical settings. The HOPPR Platform has access to
millions of imaging studies and text reports sourced from hundreds of imaging
centers from diverse populations to pretrain foundation models and enable use
case-specific cohorts for fine-tuning. All data are deidentified and securely
stored for HIPAA compliance. Additionally, developers can securely host models
on the HOPPR platform and access them via an API to make inferences using these
models within established clinical workflows. With the Medical-Grade Platform,
HOPPR's mission is to expedite the deployment of LVLM solutions for medical
imaging and ultimately optimize radiologist's workflows and meet the growing
demands of the field.",2024-11-26,2024,2024-11,medical
"Mapping Public Perception of Artificial Intelligence: Expectations,
  Risk-Benefit Tradeoffs, and Value As Determinants for Societal Acceptance","Understanding public perception of artificial intelligence (AI) and the
tradeoffs between potential risks and benefits is crucial, as these perceptions
might shape policy decisions, influence innovation trajectories for successful
market strategies, and determine individual and societal acceptance of AI
technologies. Using a representative sample of 1100 participants from Germany,
this study examines mental models of AI. Participants quantitatively evaluated
71 statements about AI's future capabilities (e.g., autonomous driving, medical
care, art, politics, warfare, and societal divides), assessing the expected
likelihood of occurrence, perceived risks, benefits, and overall value. We
present rankings of these projections alongside visual mappings illustrating
public risk-benefit tradeoffs. While many scenarios were deemed likely,
participants often associated them with high risks, limited benefits, and low
overall value. Across all scenarios, 96.4% ($r^2=96.4\%$) of the variance in
value assessment can be explained by perceived risks ($\beta=-.504$) and
perceived benefits ($\beta=+.710$), with no significant relation to expected
likelihood. Demographics and personality traits influenced perceptions of
risks, benefits, and overall evaluations, underscoring the importance of
increasing AI literacy and tailoring public information to diverse user needs.
These findings provide actionable insights for researchers, developers, and
policymakers by highlighting critical public concerns and individual factors
essential to align AI development with individual values.",2024-11-28,2024,2024-11,medical
"Adaptive Interactive Segmentation for Multimodal Medical Imaging via
  Selection Engine","In medical image analysis, achieving fast, efficient, and accurate
segmentation is essential for automated diagnosis and treatment. Although
recent advancements in deep learning have significantly improved segmentation
accuracy, current models often face challenges in adaptability and
generalization, particularly when processing multi-modal medical imaging data.
These limitations stem from the substantial variations between imaging
modalities and the inherent complexity of medical data. To address these
challenges, we propose the Strategy-driven Interactive Segmentation Model
(SISeg), built on SAM2, which enhances segmentation performance across various
medical imaging modalities by integrating a selection engine. To mitigate
memory bottlenecks and optimize prompt frame selection during the inference of
2D image sequences, we developed an automated system, the Adaptive Frame
Selection Engine (AFSE). This system dynamically selects the optimal prompt
frames without requiring extensive prior medical knowledge and enhances the
interpretability of the model's inference process through an interactive
feedback mechanism. We conducted extensive experiments on 10 datasets covering
7 representative medical imaging modalities, demonstrating the SISeg model's
robust adaptability and generalization in multi-modal tasks. The project page
and code will be available at: [URL].",2024-11-29,2024,2024-11,medical
"Polish Medical Exams: A new dataset for cross-lingual medical knowledge
  transfer assessment","Large Language Models (LLMs) have demonstrated significant potential in
handling specialized tasks, including medical problem-solving. However, most
studies predominantly focus on English-language contexts. This study introduces
a novel benchmark dataset based on Polish medical licensing and specialization
exams (LEK, LDEK, PES) taken by medical doctor candidates and practicing
doctors pursuing specialization. The dataset was web-scraped from publicly
available resources provided by the Medical Examination Center and the Chief
Medical Chamber. It comprises over 24,000 exam questions, including a subset of
parallel Polish-English corpora, where the English portion was professionally
translated by the examination center for foreign candidates. By creating a
structured benchmark from these existing exam questions, we systematically
evaluate state-of-the-art LLMs, including general-purpose, domain-specific, and
Polish-specific models, and compare their performance against human medical
students. Our analysis reveals that while models like GPT-4o achieve near-human
performance, significant challenges persist in cross-lingual translation and
domain-specific understanding. These findings underscore disparities in model
performance across languages and medical specialties, highlighting the
limitations and ethical considerations of deploying LLMs in clinical practice.",2024-11-30,2024,2024-11,medical
"Medchain: Bridging the Gap Between LLM Agents and Clinical Practice
  through Interactive Sequential Benchmarking","Clinical decision making (CDM) is a complex, dynamic process crucial to
healthcare delivery, yet it remains a significant challenge for artificial
intelligence systems. While Large Language Model (LLM)-based agents have been
tested on general medical knowledge using licensing exams and knowledge
question-answering tasks, their performance in the CDM in real-world scenarios
is limited due to the lack of comprehensive testing datasets that mirror actual
medical practice. To address this gap, we present MedChain, a dataset of 12,163
clinical cases that covers five key stages of clinical workflow. MedChain
distinguishes itself from existing benchmarks with three key features of
real-world clinical practice: personalization, interactivity, and
sequentiality. Further, to tackle real-world CDM challenges, we also propose
MedChain-Agent, an AI system that integrates a feedback mechanism and a
MCase-RAG module to learn from previous cases and adapt its responses.
MedChain-Agent demonstrates remarkable adaptability in gathering information
dynamically and handling sequential clinical tasks, significantly outperforming
existing approaches. The relevant dataset and code will be released upon
acceptance of this paper.",2024-12-02,2024,2024-12,medical
"U-Net in Medical Image Segmentation: A Review of Its Applications Across
  Modalities","Medical imaging is essential in healthcare to provide key insights into
patient anatomy and pathology, aiding in diagnosis and treatment. Non-invasive
techniques such as X-ray, Magnetic Resonance Imaging (MRI), Computed Tomography
(CT), and Ultrasound (US), capture detailed images of organs, tissues, and
abnormalities. Effective analysis of these images requires precise segmentation
to delineate regions of interest (ROI), such as organs or lesions. Traditional
segmentation methods, relying on manual feature-extraction, are labor-intensive
and vary across experts. Recent advancements in Artificial Intelligence (AI)
and Deep Learning (DL), particularly convolutional models such as U-Net and its
variants (U-Net++ and U-Net 3+), have transformed medical image segmentation
(MIS) by automating the process and enhancing accuracy. These models enable
efficient, precise pixel-wise classification across various imaging modalities,
overcoming the limitations of manual segmentation. This review explores various
medical imaging techniques, examines the U-Net architectures and their
adaptations, and discusses their application across different modalities. It
also identifies common challenges in MIS and proposes potential solutions.",2024-12-03,2024,2024-12,medical
"Intuitive Axial Augmentation Using Polar-Sine-Based Piecewise Distortion
  for Medical Slice-Wise Segmentation","Most data-driven models for medical image analysis rely on universal
augmentations to improve accuracy. Experimental evidence has confirmed their
effectiveness, but the unclear mechanism underlying them poses a barrier to the
widespread acceptance and trust in such methods within the medical community.
We revisit and acknowledge the unique characteristics of medical images apart
from traditional digital images, and consequently, proposed a medical-specific
augmentation algorithm that is more elastic and aligns well with radiology scan
procedure. The method performs piecewise affine with sinusoidal distorted ray
according to radius on polar coordinates, thus simulating uncertain postures of
human lying flat on the scanning table. Our method could generate human
visceral distribution without affecting the fundamental relative position on
axial plane. Two non-adaptive algorithms, namely Meta-based Scan Table Removal
and Similarity-Guided Parameter Search, are introduced to bolster robustness of
our augmentation method. In contrast to other methodologies, our method is
highlighted for its intuitive design and ease of understanding for medical
professionals, thereby enhancing its applicability in clinical scenarios.
Experiments show our method improves accuracy with two modality across multiple
famous segmentation frameworks without requiring more data samples. Our preview
code is available in: https://github.com/MGAMZ/PSBPD.",2024-12-04,2024,2024-12,medical
"Privacy-Preserving in Medical Image Analysis: A Review of Methods and
  Applications","With the rapid advancement of artificial intelligence and deep learning,
medical image analysis has become a critical tool in modern healthcare,
significantly improving diagnostic accuracy and efficiency. However, AI-based
methods also raise serious privacy concerns, as medical images often contain
highly sensitive patient information. This review offers a comprehensive
overview of privacy-preserving techniques in medical image analysis, including
encryption, differential privacy, homomorphic encryption, federated learning,
and generative adversarial networks. We explore the application of these
techniques across various medical image analysis tasks, such as diagnosis,
pathology, and telemedicine. Notably, we organizes the review based on specific
challenges and their corresponding solutions in different medical image
analysis applications, so that technical applications are directly aligned with
practical issues, addressing gaps in the current research landscape.
Additionally, we discuss emerging trends, such as zero-knowledge proofs and
secure multi-party computation, offering insights for future research. This
review serves as a valuable resource for researchers and practitioners and can
help advance privacy-preserving in medical image analysis.",2024-12-05,2024,2024-12,medical
"Electrocardiogram (ECG) Based Cardiac Arrhythmia Detection and
  Classification using Machine Learning Algorithms","The rapid advancements in Artificial Intelligence, specifically Machine
Learning (ML) and Deep Learning (DL), have opened new prospects in medical
sciences for improved diagnosis, prognosis, and treatment of severe health
conditions. This paper focuses on the development of an ML model with high
predictive accuracy to classify arrhythmic electrocardiogram (ECG) signals. The
ECG signals datasets utilized in this study were sourced from the PhysioNet and
MIT-BIH databases. The research commenced with binary classification, where an
optimized Bidirectional Long Short-Term Memory (Bi-LSTM) model yielded
excellent results in differentiating normal and atrial fibrillation signals. A
pivotal aspect of this research was a survey among medical professionals, which
not only validated the practicality of AI-based ECG classifiers but also
identified areas for improvement, including accuracy and the inclusion of more
arrhythmia types. These insights drove the development of an advanced
Convolutional Neural Network (CNN) system capable of classifying five different
types of ECG signals with better accuracy and precision. The CNN model's robust
performance was ensured through rigorous stratified 5-fold cross validation. A
web portal was also developed to demonstrate real-world utility, offering
access to the trained model for real-time classification. This study highlights
the potential applications of such models in remote health monitoring,
predictive healthcare, assistive diagnostic tools, and simulated environments
for educational training and interdisciplinary collaboration between data
scientists and medical personnel.",2024-12-07,2024,2024-12,medical
"Participatory Assessment of Large Language Model Applications in an
  Academic Medical Center","Although Large Language Models (LLMs) have shown promising performance in
healthcare-related applications, their deployment in the medical domain poses
unique challenges of ethical, regulatory, and technical nature. In this study,
we employ a systematic participatory approach to investigate the needs and
expectations regarding clinical applications of LLMs at Lausanne University
Hospital, an academic medical center in Switzerland. Having identified
potential LLM use-cases in collaboration with thirty stakeholders, including
clinical staff across 11 departments as well nursing and patient
representatives, we assess the current feasibility of these use-cases taking
into account the regulatory frameworks, data protection regulation, bias,
hallucinations, and deployment constraints. This study provides a framework for
a participatory approach to identifying institutional needs with respect to
introducing advanced technologies into healthcare practice, and a realistic
analysis of the technology readiness level of LLMs for medical applications,
highlighting the issues that would need to be overcome LLMs in healthcare to be
ethical, and regulatory compliant.",2024-12-09,2024,2024-12,medical
"Advancing Music Therapy: Integrating Eastern Five-Element Music Theory
  and Western Techniques with AI in the Novel Five-Element Harmony System","In traditional medical practices, music therapy has proven effective in
treating various psychological and physiological ailments. Particularly in
Eastern traditions, the Five Elements Music Therapy (FEMT), rooted in
traditional Chinese medicine, possesses profound cultural significance and
unique therapeutic philosophies. With the rapid advancement of Information
Technology and Artificial Intelligence, applying these modern technologies to
FEMT could enhance the personalization and cultural relevance of the therapy
and potentially improve therapeutic outcomes. In this article, we developed a
music therapy system for the first time by applying the theory of the five
elements in music therapy to practice. This innovative approach integrates
advanced Information Technology and Artificial Intelligence with Five-Element
Music Therapy (FEMT) to enhance personalized music therapy practices. As
traditional music therapy predominantly follows Western methodologies, the
unique aspects of Eastern practices, specifically the Five-Element theory from
traditional Chinese medicine, should be considered. This system aims to bridge
this gap by utilizing computational technologies to provide a more
personalized, culturally relevant, and therapeutically effective music therapy
experience.",2024-12-09,2024,2024-12,medical
"MMedPO: Aligning Medical Vision-Language Models with Clinical-Aware
  Multimodal Preference Optimization","The advancement of Large Vision-Language Models (LVLMs) has propelled their
application in the medical field. However, Medical LVLMs (Med-LVLMs) encounter
factuality challenges due to modality misalignment, where the models prioritize
textual knowledge over visual input, leading to hallucinations that contradict
information in medical images. Previous attempts to enhance modality alignment
in Med-LVLMs through preference optimization have inadequately mitigated
clinical relevance in preference data, making these samples easily
distinguishable and reducing alignment effectiveness. To address this
challenge, we propose MMedPO, a novel multimodal medical preference
optimization approach that considers the clinical relevance of preference
samples to enhance Med-LVLM alignment. MMedPO curates multimodal preference
data by introducing two types of dispreference: (1) plausible hallucinations
injected through target Med-LVLMs or GPT-4o to produce medically inaccurate
responses, and (2) lesion region neglect achieved through local lesion-noising,
disrupting visual understanding of critical areas. We then calculate clinical
relevance for each sample based on scores from multiple Med-LLMs and visual
tools, and integrate these scores into the preference optimization process as
weights, enabling effective alignment. Our experiments demonstrate that MMedPO
significantly enhances factual accuracy in Med-LVLMs, achieving substantial
improvements over existing preference optimization methods by averaging 14.2%
and 51.7% across the Med-VQA and report generation tasks. Our code are
available in https://github.com/aiming-lab/MMedPO.",2024-12-09,2024,2024-12,medical
"Performance of a large language model-Artificial Intelligence based
  chatbot for counseling patients with sexually transmitted infections and
  genital diseases","Introduction: Global burden of sexually transmitted infections (STIs) is
rising out of proportion to specialists. Current chatbots like ChatGPT are not
tailored for handling STI-related concerns out of the box. We developed Otiz,
an Artificial Intelligence-based (AI-based) chatbot platform designed
specifically for STI detection and counseling, and assessed its performance.
Methods: Otiz employs a multi-agent system architecture based on GPT4-0613,
leveraging large language model (LLM) and Deterministic Finite Automaton
principles to provide contextually relevant, medically accurate, and empathetic
responses. Its components include modules for general STI information,
emotional recognition, Acute Stress Disorder detection, and psychotherapy. A
question suggestion agent operates in parallel. Four STIs (anogenital warts,
herpes, syphilis, urethritis/cervicitis) and 2 non-STIs (candidiasis, penile
cancer) were evaluated using prompts mimicking patient language. Each prompt
was independently graded by two venereologists conversing with Otiz as patient
actors on 6 criteria using Numerical Rating Scale ranging from 0 (poor) to 5
(excellent). Results: Twenty-three venereologists did 60 evaluations of 30
prompts. Across STIs, Otiz scored highly on diagnostic accuracy (4.1-4.7),
overall accuracy (4.3-4.6), correctness of information (5.0), comprehensibility
(4.2-4.4), and empathy (4.5-4.8). However, relevance scores were lower
(2.9-3.6), suggesting some redundancy. Diagnostic scores for non-STIs were
lower (p=0.038). Inter-observer agreement was strong, with differences greater
than 1 point occurring in only 12.7% of paired evaluations. Conclusions: AI
conversational agents like Otiz can provide accurate, correct, discrete,
non-judgmental, readily accessible and easily understandable STI-related
information in an empathetic manner, and can alleviate the burden on healthcare
systems.",2024-12-11,2024,2024-12,medical
CareBot: A Pioneering Full-Process Open-Source Medical Language Model,"Recently, both closed-source LLMs and open-source communities have made
significant strides, outperforming humans in various general domains. However,
their performance in specific professional domains such as medicine, especially
within the open-source community, remains suboptimal due to the complexity of
medical knowledge. In this paper, we propose CareBot, a bilingual medical LLM,
which leverages a comprehensive approach integrating continuous pre-training
(CPT), supervised fine-tuning (SFT), and reinforcement learning with human
feedback (RLHF). Our novel two-stage CPT method, comprising Stable CPT and
Boost CPT, effectively bridges the gap between general and domain-specific
data, facilitating a smooth transition from pre-training to fine-tuning and
enhancing domain knowledge progressively. We also introduce DataRater, a model
designed to assess data quality during CPT, ensuring that the training data is
both accurate and relevant. For SFT, we develope a large and diverse bilingual
dataset, along with ConFilter, a metric to enhance multi-turn dialogue quality,
which is crucial to improving the model's ability to handle more complex
dialogues. The combination of high-quality data sources and innovative
techniques significantly improves CareBot's performance across a range of
medical applications. Our rigorous evaluations on Chinese and English
benchmarks confirm CareBot's effectiveness in medical consultation and
education. These advancements not only address current limitations in medical
LLMs but also set a new standard for developing effective and reliable
open-source models in the medical domain. We will open-source the datasets and
models later, contributing valuable resources to the research community.",2024-12-12,2024,2024-12,medical
"FAMNet: Frequency-aware Matching Network for Cross-domain Few-shot
  Medical Image Segmentation","Existing few-shot medical image segmentation (FSMIS) models fail to address a
practical issue in medical imaging: the domain shift caused by different
imaging techniques, which limits the applicability to current FSMIS tasks. To
overcome this limitation, we focus on the cross-domain few-shot medical image
segmentation (CD-FSMIS) task, aiming to develop a generalized model capable of
adapting to a broader range of medical image segmentation scenarios with
limited labeled data from the novel target domain. Inspired by the
characteristics of frequency domain similarity across different domains, we
propose a Frequency-aware Matching Network (FAMNet), which includes two key
components: a Frequency-aware Matching (FAM) module and a Multi-Spectral Fusion
(MSF) module. The FAM module tackles two problems during the meta-learning
phase: 1) intra-domain variance caused by the inherent support-query bias, due
to the different appearances of organs and lesions, and 2) inter-domain
variance caused by different medical imaging techniques. Additionally, we
design an MSF module to integrate the different frequency features decoupled by
the FAM module, and further mitigate the impact of inter-domain variance on the
model's segmentation performance. Combining these two modules, our FAMNet
surpasses existing FSMIS models and Cross-domain Few-shot Semantic Segmentation
models on three cross-domain datasets, achieving state-of-the-art performance
in the CD-FSMIS task.",2024-12-12,2024,2024-12,medical
"Embeddings are all you need! Achieving High Performance Medical Image
  Classification through Training-Free Embedding Analysis","Developing artificial intelligence (AI) and machine learning (ML) models for
medical imaging typically involves extensive training and testing on large
datasets, consuming significant computational time, energy, and resources.
There is a need for more efficient methods that can achieve comparable or
superior diagnostic performance without the associated resource burden. We
investigated the feasibility of replacing conventional training procedures with
an embedding-based approach that leverages concise and semantically meaningful
representations of medical images. Using pre-trained foundational
models-specifically, convolutional neural networks (CNN) like ResNet and
multimodal models like Contrastive Language-Image Pre-training (CLIP)-we
generated image embeddings for multi-class classification tasks. Simple linear
classifiers were then applied to these embeddings. The approach was evaluated
across diverse medical imaging modalities, including retinal images,
mammography, dermatoscopic images, and chest radiographs. Performance was
compared to benchmark models trained and tested using traditional methods. The
embedding-based models surpassed the benchmark area under the receiver
operating characteristic curve (AUC-ROC) scores by up to 87 percentage in
multi-class classification tasks across the various medical imaging modalities.
Notably, CLIP embedding models achieved the highest AUC-ROC scores,
demonstrating superior classification performance while significantly reducing
computational demands. Our study indicates that leveraging embeddings from
pre-trained foundational models can effectively replace conventional,
resource-intensive training and testing procedures in medical image analysis.
This embedding-based approach offers a more efficient alternative for image
segmentation, classification, and prediction, potentially accelerating AI
technology integration into clinical practice.",2024-12-12,2024,2024-12,medical
Medical Manifestation-Aware De-Identification,"Face de-identification (DeID) has been widely studied for common scenes, but
remains under-researched for medical scenes, mostly due to the lack of
large-scale patient face datasets. In this paper, we release MeMa, consisting
of over 40,000 photo-realistic patient faces. MeMa is re-generated from massive
real patient photos. By carefully modulating the generation and data-filtering
procedures, MeMa avoids breaching real patient privacy, while ensuring rich and
plausible medical manifestations. We recruit expert clinicians to annotate MeMa
with both coarse- and fine-grained labels, building the first medical-scene
DeID benchmark. Additionally, we propose a baseline approach for this new
medical-aware DeID task, by integrating data-driven medical semantic priors
into the DeID procedure. Despite its conciseness and simplicity, our approach
substantially outperforms previous ones. Dataset is available at
https://github.com/tianyuan168326/MeMa-Pytorch.",2024-12-14,2024,2024-12,medical
Overview of TREC 2024 Medical Video Question Answering (MedVidQA) Track,"One of the key goals of artificial intelligence (AI) is the development of a
multimodal system that facilitates communication with the visual world (image
and video) using a natural language query. Earlier works on medical question
answering primarily focused on textual and visual (image) modalities, which may
be inefficient in answering questions requiring demonstration. In recent years,
significant progress has been achieved due to the introduction of large-scale
language-vision datasets and the development of efficient deep neural
techniques that bridge the gap between language and visual understanding.
Improvements have been made in numerous vision-and-language tasks, such as
visual captioning visual question answering, and natural language video
localization. Most of the existing work on language vision focused on creating
datasets and developing solutions for open-domain applications. We believe
medical videos may provide the best possible answers to many first aid, medical
emergency, and medical education questions. With increasing interest in AI to
support clinical decision-making and improve patient engagement, there is a
need to explore such challenges and develop efficient algorithms for medical
language-video understanding and generation. Toward this, we introduced new
tasks to foster research toward designing systems that can understand medical
videos to provide visual answers to natural language questions, and are
equipped with multimodal capability to generate instruction steps from the
medical video. These tasks have the potential to support the development of
sophisticated downstream applications that can benefit the public and medical
professionals.",2024-12-15,2024,2024-12,medical
ACE-$M^3$: Automatic Capability Evaluator for Multimodal Medical Models,"As multimodal large language models (MLLMs) gain prominence in the medical
field, the need for precise evaluation methods to assess their effectiveness
has become critical. While benchmarks provide a reliable means to evaluate the
capabilities of MLLMs, traditional metrics like ROUGE and BLEU employed for
open domain evaluation only focus on token overlap and may not align with human
judgment. Although human evaluation is more reliable, it is labor-intensive,
costly, and not scalable. LLM-based evaluation methods have proven promising,
but to date, there is still an urgent need for open-source multimodal LLM-based
evaluators in the medical field. To address this issue, we introduce ACE-$M^3$,
an open-sourced \textbf{A}utomatic \textbf{C}apability \textbf{E}valuator for
\textbf{M}ultimodal \textbf{M}edical \textbf{M}odels specifically designed to
assess the question answering abilities of medical MLLMs. It first utilizes a
branch-merge architecture to provide both detailed analysis and a concise final
score based on standard medical evaluation criteria. Subsequently, a reward
token-based direct preference optimization (RTDPO) strategy is incorporated to
save training time without compromising performance of our model. Extensive
experiments have demonstrated the effectiveness of our ACE-$M^3$
model\footnote{\url{https://huggingface.co/collections/AIUSRTMP/ace-m3-67593297ff391b93e3e5d068}}
in evaluating the capabilities of medical MLLMs.",2024-12-16,2024,2024-12,medical
In-context learning for medical image segmentation,"Annotation of medical images, such as MRI and CT scans, is crucial for
evaluating treatment efficacy and planning radiotherapy. However, the extensive
workload of medical professionals limits their ability to annotate large image
datasets, posing a bottleneck for AI applications in medical imaging. To
address this, we propose In-context Cascade Segmentation (ICS), a novel method
that minimizes annotation requirements while achieving high segmentation
accuracy for sequential medical images. ICS builds on the UniverSeg framework,
which performs few-shot segmentation using support images without additional
training. By iteratively adding the inference results of each slice to the
support set, ICS propagates information forward and backward through the
sequence, ensuring inter-slice consistency. We evaluate the proposed method on
the HVSMR dataset, which includes segmentation tasks for eight cardiac regions.
Experimental results demonstrate that ICS significantly improves segmentation
performance in complex anatomical regions, particularly in maintaining boundary
consistency across slices, compared to baseline methods. The study also
highlights the impact of the number and position of initial support slices on
segmentation accuracy. ICS offers a promising solution for reducing annotation
burdens while delivering robust segmentation results, paving the way for its
broader adoption in clinical and research applications.",2024-12-17,2024,2024-12,medical
Clinical Trials Ontology Engineering with Large Language Models,"Managing clinical trial information is currently a significant challenge for
the medical industry, as traditional methods are both time-consuming and
costly. This paper proposes a simple yet effective methodology to extract and
integrate clinical trial data in a cost-effective and time-efficient manner.
Allowing the medical industry to stay up-to-date with medical developments.
Comparing time, cost, and quality of the ontologies created by humans, GPT3.5,
GPT4, and Llama3 (8b & 70b). Findings suggest that large language models (LLM)
are a viable option to automate this process both from a cost and time
perspective. This study underscores significant implications for medical
research where real-time data integration from clinical trials could become the
norm.",2024-12-18,2024,2024-12,medical
"Critique of Impure Reason: Unveiling the reasoning behaviour of medical
  Large Language Models","Background: Despite the current ubiquity of Large Language Models (LLMs)
across the medical domain, there is a surprising lack of studies which address
their reasoning behaviour. We emphasise the importance of understanding
reasoning behaviour as opposed to high-level prediction accuracies, since it is
equivalent to explainable AI (XAI) in this context. In particular, achieving
XAI in medical LLMs used in the clinical domain will have a significant impact
across the healthcare sector. Results: Therefore, we define the concept of
reasoning behaviour in the specific context of medical LLMs. We then categorise
and discuss the current state of the art of methods which evaluate reasoning
behaviour in medical LLMs. Finally, we propose theoretical frameworks which can
empower medical professionals or machine learning engineers to gain insight
into the low-level reasoning operations of these previously obscure models.
Conclusion: The subsequent increased transparency and trust in medical machine
learning models by clinicians as well as patients will accelerate the
integration, application as well as further development of medical AI for the
healthcare system as a whole",2024-12-20,2024,2024-12,medical
"From General to Specific: Tailoring Large Language Models for
  Personalized Healthcare","The rapid development of large language models (LLMs) has transformed many
industries, including healthcare. However, previous medical LLMs have largely
focused on leveraging general medical knowledge to provide responses, without
accounting for patient variability and lacking true personalization at the
individual level. To address this, we propose a novel method called
personalized medical language model (PMLM), which explores and optimizes
personalized LLMs through recommendation systems and reinforcement learning
(RL). Specifically, by utilizing self-informed and peer-informed
personalization, PMLM captures changes in behaviors and preferences to design
initial personalized prompts tailored to individual needs. We further refine
these initial personalized prompts through RL, ultimately enhancing the
precision of LLM guidance. Notably, the personalized prompt are hard prompt,
which grants PMLM high adaptability and reusability, allowing it to directly
leverage high-quality proprietary LLMs. We evaluate PMLM using real-world
obstetrics and gynecology data, and the experimental results demonstrate that
PMLM achieves personalized responses, and it provides more refined and
individualized services, offering a potential way for personalized medical
LLMs.",2024-12-20,2024,2024-12,medical
"FairREAD: Re-fusing Demographic Attributes after Disentanglement for
  Fair Medical Image Classification","Recent advancements in deep learning have shown transformative potential in
medical imaging, yet concerns about fairness persist due to performance
disparities across demographic subgroups. Existing methods aim to address these
biases by mitigating sensitive attributes in image data; however, these
attributes often carry clinically relevant information, and their removal can
compromise model performance-a highly undesirable outcome. To address this
challenge, we propose Fair Re-fusion After Disentanglement (FairREAD), a novel,
simple, and efficient framework that mitigates unfairness by re-integrating
sensitive demographic attributes into fair image representations. FairREAD
employs orthogonality constraints and adversarial training to disentangle
demographic information while using a controlled re-fusion mechanism to
preserve clinically relevant details. Additionally, subgroup-specific threshold
adjustments ensure equitable performance across demographic groups.
Comprehensive evaluations on a large-scale clinical X-ray dataset demonstrate
that FairREAD significantly reduces unfairness metrics while maintaining
diagnostic accuracy, establishing a new benchmark for fairness and performance
in medical image classification.",2024-12-20,2024,2024-12,medical
"KG4Diagnosis: A Hierarchical Multi-Agent LLM Framework with Knowledge
  Graph Enhancement for Medical Diagnosis","Integrating Large Language Models (LLMs) in healthcare diagnosis demands
systematic frameworks that can handle complex medical scenarios while
maintaining specialized expertise. We present KG4Diagnosis, a novel
hierarchical multi-agent framework that combines LLMs with automated knowledge
graph construction, encompassing 362 common diseases across medical
specialties. Our framework mirrors real-world medical systems through a
two-tier architecture: a general practitioner (GP) agent for initial assessment
and triage, coordinating with specialized agents for in-depth diagnosis in
specific domains. The core innovation lies in our end-to-end knowledge graph
generation methodology, incorporating: (1) semantic-driven entity and relation
extraction optimized for medical terminology, (2) multi-dimensional decision
relationship reconstruction from unstructured medical texts, and (3)
human-guided reasoning for knowledge expansion. KG4Diagnosis serves as an
extensible foundation for specialized medical diagnosis systems, with
capabilities to incorporate new diseases and medical knowledge. The framework's
modular design enables seamless integration of domain-specific enhancements,
making it valuable for developing targeted medical diagnosis systems. We
provide architectural guidelines and protocols to facilitate adoption across
medical contexts.",2024-12-22,2024,2024-12,medical
"Enhancing Cancer Diagnosis with Explainable & Trustworthy Deep Learning
  Models","This research presents an innovative approach to cancer diagnosis and
prediction using explainable Artificial Intelligence (XAI) and deep learning
techniques. With cancer causing nearly 10 million deaths globally in 2020,
early and accurate diagnosis is crucial. Traditional methods often face
challenges in cost, accuracy, and efficiency. Our study develops an AI model
that provides precise outcomes and clear insights into its decision-making
process, addressing the ""black box"" problem of deep learning models. By
employing XAI techniques, we enhance interpretability and transparency,
building trust among healthcare professionals and patients. Our approach
leverages neural networks to analyse extensive datasets, identifying patterns
for cancer detection. This model has the potential to revolutionise diagnosis
by improving accuracy, accessibility, and clarity in medical decision-making,
possibly leading to earlier detection and more personalised treatment
strategies. Furthermore, it could democratise access to high-quality
diagnostics, particularly in resource-limited settings, contributing to global
health equity. The model's applications extend beyond cancer diagnosis,
potentially transforming various aspects of medical decision-making and saving
millions of lives worldwide.",2024-12-23,2024,2024-12,medical
"HuatuoGPT-o1, Towards Medical Complex Reasoning with LLMs","The breakthrough of OpenAI o1 highlights the potential of enhancing reasoning
to improve LLM. Yet, most research in reasoning has focused on mathematical
tasks, leaving domains like medicine underexplored. The medical domain, though
distinct from mathematics, also demands robust reasoning to provide reliable
answers, given the high standards of healthcare. However, verifying medical
reasoning is challenging, unlike those in mathematics. To address this, we
propose verifiable medical problems with a medical verifier to check the
correctness of model outputs. This verifiable nature enables advancements in
medical reasoning through a two-stage approach: (1) using the verifier to guide
the search for a complex reasoning trajectory for fine-tuning LLMs, (2)
applying reinforcement learning (RL) with verifier-based rewards to enhance
complex reasoning further. Finally, we introduce HuatuoGPT-o1, a medical LLM
capable of complex reasoning, which outperforms general and medical-specific
baselines using only 40K verifiable problems. Experiments show complex
reasoning improves medical problem-solving and benefits more from RL. We hope
our approach inspires advancements in reasoning across medical and other
specialized domains.",2024-12-25,2024,2024-12,medical
"MedHallBench: A New Benchmark for Assessing Hallucination in Medical
  Large Language Models","Medical Large Language Models (MLLMs) have demonstrated potential in
healthcare applications, yet their propensity for hallucinations -- generating
medically implausible or inaccurate information -- presents substantial risks
to patient care. This paper introduces MedHallBench, a comprehensive benchmark
framework for evaluating and mitigating hallucinations in MLLMs. Our
methodology integrates expert-validated medical case scenarios with established
medical databases to create a robust evaluation dataset. The framework employs
a sophisticated measurement system that combines automated ACHMI (Automatic
Caption Hallucination Measurement in Medical Imaging) scoring with rigorous
clinical expert evaluations and utilizes reinforcement learning methods to
achieve automatic annotation. Through an optimized reinforcement learning from
human feedback (RLHF) training pipeline specifically designed for medical
applications, MedHallBench enables thorough evaluation of MLLMs across diverse
clinical contexts while maintaining stringent accuracy standards. We conducted
comparative experiments involving various models, utilizing the benchmark to
establish a baseline for widely adopted large language models (LLMs). Our
findings indicate that ACHMI provides a more nuanced understanding of the
effects of hallucinations compared to traditional metrics, thereby highlighting
its advantages in hallucination assessment. This research establishes a
foundational framework for enhancing MLLMs' reliability in healthcare settings
and presents actionable strategies for addressing the critical challenge of AI
hallucinations in medical applications.",2024-12-25,2024,2024-12,medical
"Evaluating Self-Supervised Learning in Medical Imaging: A Benchmark for
  Robustness, Generalizability, and Multi-Domain Impact","Self-supervised learning (SSL) has emerged as a promising paradigm in medical
imaging, addressing the chronic challenge of limited labeled data in healthcare
settings. While SSL has shown impressive results, existing studies in the
medical domain are often limited in scope, focusing on specific datasets or
modalities, or evaluating only isolated aspects of model performance. This
fragmented evaluation approach poses a significant challenge, as models
deployed in critical medical settings must not only achieve high accuracy but
also demonstrate robust performance and generalizability across diverse
datasets and varying conditions. To address this gap, we present a
comprehensive evaluation of SSL methods within the medical domain, with a
particular focus on robustness and generalizability. Using the MedMNIST dataset
collection as a standardized benchmark, we evaluate 8 major SSL methods across
11 different medical datasets. Our study provides an in-depth analysis of model
performance in both in-domain scenarios and the detection of
out-of-distribution (OOD) samples, while exploring the effect of various
initialization strategies, model architectures, and multi-domain pre-training.
We further assess the generalizability of SSL methods through cross-dataset
evaluations and the in-domain performance with varying label proportions (1%,
10%, and 100%) to simulate real-world scenarios with limited supervision. We
hope this comprehensive benchmark helps practitioners and researchers make more
informed decisions when applying SSL methods to medical applications.",2024-12-26,2024,2024-12,medical
"MEDEC: A Benchmark for Medical Error Detection and Correction in
  Clinical Notes","Several studies showed that Large Language Models (LLMs) can answer medical
questions correctly, even outperforming the average human score in some medical
exams. However, to our knowledge, no study has been conducted to assess the
ability of language models to validate existing or generated medical text for
correctness and consistency. In this paper, we introduce MEDEC
(https://github.com/abachaa/MEDEC), the first publicly available benchmark for
medical error detection and correction in clinical notes, covering five types
of errors (Diagnosis, Management, Treatment, Pharmacotherapy, and Causal
Organism). MEDEC consists of 3,848 clinical texts, including 488 clinical notes
from three US hospital systems that were not previously seen by any LLM. The
dataset has been used for the MEDIQA-CORR shared task to evaluate seventeen
participating systems [Ben Abacha et al., 2024]. In this paper, we describe the
data creation methods and we evaluate recent LLMs (e.g., o1-preview, GPT-4,
Claude 3.5 Sonnet, and Gemini 2.0 Flash) for the tasks of detecting and
correcting medical errors requiring both medical knowledge and reasoning
capabilities. We also conducted a comparative study where two medical doctors
performed the same task on the MEDEC test set. The results showed that MEDEC is
a sufficiently challenging benchmark to assess the ability of models to
validate existing or generated notes and to correct medical errors. We also
found that although recent LLMs have a good performance in error detection and
correction, they are still outperformed by medical doctors in these tasks. We
discuss the potential factors behind this gap, the insights from our
experiments, the limitations of current evaluation metrics, and share potential
pointers for future research.",2024-12-26,2024,2024-12,medical
"A Review on the Integration of Artificial Intelligence and Medical
  Imaging in IVF Ovarian Stimulation","Artificial intelligence (AI) has emerged as a powerful tool to enhance
decision-making and optimize treatment protocols in in vitro fertilization
(IVF). In particular, AI shows significant promise in supporting
decision-making during the ovarian stimulation phase of the IVF process. This
review evaluates studies focused on the applications of AI combined with
medical imaging in ovarian stimulation, examining methodologies, outcomes, and
current limitations. Our analysis of 13 studies on this topic reveals that,
reveal that while AI algorithms demonstrated notable potential in predicting
optimal hormonal dosages, trigger timing, and oocyte retrieval outcomes, the
medical imaging data utilized predominantly came from two-dimensional (2D)
ultrasound which mainly involved basic quantifications, such as follicle size
and number, with limited use of direct feature extraction or advanced image
analysis techniques. This points to an underexplored opportunity where advanced
image analysis approaches, such as deep learning, and more diverse imaging
modalities, like three-dimensional (3D) ultrasound, could unlock deeper
insights. Additionally, the lack of explainable AI (XAI) in most studies raises
concerns about the transparency and traceability of AI-driven decisions - key
factors for clinical adoption and trust. Furthermore, many studies relied on
single-center designs and small datasets, which limit the generalizability of
their findings. This review highlights the need for integrating advanced
imaging analysis techniques with explainable AI methodologies, as well as the
importance of leveraging multicenter collaborations and larger datasets.
Addressing these gaps has the potential to enhance ovarian stimulation
management, paving the way for efficient, personalized, and data-driven
treatment pathways that improve IVF outcomes.",2024-12-27,2024,2024-12,medical
"On the Compositional Generalization of Multimodal LLMs for Medical
  Imaging","Multimodal large language models (MLLMs) hold significant potential in the
medical field, but their capabilities are often limited by insufficient data in
certain medical domains, highlighting the need for understanding what kinds of
images can be used by MLLMs for generalization. Current research suggests that
multi-task training outperforms single-task as different tasks can benefit each
other, but they often overlook the internal relationships within these tasks,
providing limited guidance on selecting datasets to enhance specific tasks. To
analyze this phenomenon, we attempted to employ compositional generalization
(CG)-the ability of models to understand novel combinations by recombining
learned elements-as a guiding framework. Since medical images can be precisely
defined by Modality, Anatomical area, and Task, naturally providing an
environment for exploring CG. Therefore, we assembled 106 medical datasets to
create Med-MAT for comprehensive experiments. The experiments confirmed that
MLLMs can use CG to understand unseen medical images and identified CG as one
of the main drivers of the generalization observed in multi-task training.
Additionally, further studies demonstrated that CG effectively supports
datasets with limited data and delivers consistent performance across different
backbones, highlighting its versatility and broad applicability. Med-MAT is
publicly available at https://github.com/FreedomIntelligence/Med-MAT.",2024-12-28,2024,2024-12,medical
"LLM-MedQA: Enhancing Medical Question Answering through Case Studies in
  Large Language Models","Accurate and efficient question-answering systems are essential for
delivering high-quality patient care in the medical field. While Large Language
Models (LLMs) have made remarkable strides across various domains, they
continue to face significant challenges in medical question answering,
particularly in understanding domain-specific terminologies and performing
complex reasoning. These limitations undermine their effectiveness in critical
medical applications. To address these issues, we propose a novel approach
incorporating similar case generation within a multi-agent medical
question-answering (MedQA) system. Specifically, we leverage the Llama3.1:70B
model, a state-of-the-art LLM, in a multi-agent architecture to enhance
performance on the MedQA dataset using zero-shot learning. Our method
capitalizes on the model's inherent medical knowledge and reasoning
capabilities, eliminating the need for additional training data. Experimental
results show substantial performance gains over existing benchmark models, with
improvements of 7% in both accuracy and F1-score across various medical QA
tasks. Furthermore, we examine the model's interpretability and reliability in
addressing complex medical queries. This research not only offers a robust
solution for medical question answering but also establishes a foundation for
broader applications of LLMs in the medical domain.",2024-12-31,2024,2024-12,medical
