title,summary,published,year,month,category
"Ontology-supported processing of clinical text using medical knowledge
  integration for multi-label classification of diagnosis coding","This paper discusses the knowledge integration of clinical information
extracted from distributed medical ontology in order to ameliorate a machine
learning-based multi-label coding assignment system. The proposed approach is
implemented using a decision tree based cascade hierarchical technique on the
university hospital data for patients with Coronary Heart Disease (CHD). The
preliminary results obtained show a satisfactory finding.",2010-04-08,2010,2010-04,medical
Using Semantic Wikis for Structured Argument in Medical Domain,"This research applies ideas from argumentation theory in the context of
semantic wikis, aiming to provide support for structured-large scale
argumentation between human agents. The implemented prototype is exemplified by
modelling the MMR vaccine controversy.",2010-12-08,2010,2010-12,medical
Variational Probabilistic Inference and the QMR-DT Network,"We describe a variational approximation method for efficient inference in
large-scale probabilistic models. Variational methods are deterministic
procedures that provide approximations to marginal and conditional
probabilities of interest. They provide alternatives to approximate inference
methods based on stochastic sampling or search. We describe a variational
approach to the problem of diagnostic inference in the `Quick Medical
Reference' (QMR) network. The QMR network is a large-scale probabilistic
graphical model built on statistical and expert knowledge. Exact probabilistic
inference is infeasible in this model for all but a small set of cases. We
evaluate our variational inference algorithm on a large set of diagnostic test
cases, comparing the algorithm to a state-of-the-art stochastic sampling
method.",2011-05-27,2011,2011-05,medical
Expert-Guided Subgroup Discovery: Methodology and Application,"This paper presents an approach to expert-guided subgroup discovery. The main
step of the subgroup discovery process, the induction of subgroup descriptions,
is performed by a heuristic beam search algorithm, using a novel parametrized
definition of rule quality which is analyzed in detail. The other important
steps of the proposed subgroup discovery process are the detection of
statistically significant properties of selected subgroups and subgroup
visualization: statistically significant properties are used to enrich the
descriptions of induced subgroups, while the visualization shows subgroup
properties in the form of distributions of the numbers of examples in the
subgroups. The approach is illustrated by the results obtained for a medical
problem of early detection of patient risk groups.",2011-06-22,2011,2011-06,medical
"Modeling Multiple Annotator Expertise in the Semi-Supervised Learning
  Scenario","Learning algorithms normally assume that there is at most one annotation or
label per data point. However, in some scenarios, such as medical diagnosis and
on-line collaboration,multiple annotations may be available. In either case,
obtaining labels for data points can be expensive and time-consuming (in some
circumstances ground-truth may not exist). Semi-supervised learning approaches
have shown that utilizing the unlabeled data is often beneficial in these
cases. This paper presents a probabilistic semi-supervised model and algorithm
that allows for learning from both unlabeled and labeled data in the presence
of multiple annotators. We assume that it is known what annotator labeled which
data points. The proposed approach produces annotator models that allow us to
provide (1) estimates of the true label and (2) annotator variable expertise
for both labeled and unlabeled data. We provide numerical comparisons under
various scenarios and with respect to standard semi-supervised learning.
Experiments showed that the presented approach provides clear advantages over
multi-annotator methods that do not use the unlabeled data and over methods
that do not use multi-labeler information.",2012-03-15,2012,2012-03,medical
"Demand-Driven Clustering in Relational Domains for Predicting Adverse
  Drug Events","Learning from electronic medical records (EMR) is challenging due to their
relational nature and the uncertain dependence between a patient's past and
future health status. Statistical relational learning is a natural fit for
analyzing EMRs but is less adept at handling their inherent latent structure,
such as connections between related medications or diseases. One way to capture
the latent structure is via a relational clustering of objects. We propose a
novel approach that, instead of pre-clustering the objects, performs a
demand-driven clustering during learning. We evaluate our algorithm on three
real-world tasks where the goal is to use EMRs to predict whether a patient
will have an adverse reaction to a medication. We find that our approach is
more accurate than performing no clustering, pre-clustering, and using
expert-constructed medical heterarchies.",2012-06-27,2012,2012-06,medical
A Non-Parametric Bayesian Method for Inferring Hidden Causes,"We present a non-parametric Bayesian approach to structure learning with
hidden causes. Previous Bayesian treatments of this problem define a prior over
the number of hidden causes and use algorithms such as reversible jump Markov
chain Monte Carlo to move between solutions. In contrast, we assume that the
number of hidden causes is unbounded, but only a finite number influence
observable variables. This makes it possible to use a Gibbs sampler to
approximate the distribution over causal structures. We evaluate the
performance of both approaches in discovering hidden causes in simulated data,
and use our non-parametric approach to discover hidden causes in a real medical
dataset.",2012-06-27,2012,2012-06,medical
Rule Based Expert System for Cerebral Palsy Diagnosis,"The use of Artificial Intelligence is finding prominence not only in core
computer areas, but also in cross disciplinary areas including medical
diagnosis. In this paper, we present a rule based Expert System used in
diagnosis of Cerebral Palsy. The expert system takes user input and depending
on the symptoms of the patient, diagnoses if the patient is suffering from
Cerebral Palsy. The Expert System also classifies the Cerebral Palsy as mild,
moderate or severe based on the presented symptoms.",2012-06-30,2012,2012-06,medical
"Dynamic Decision Support System Based on Bayesian Networks Application
  to fight against the Nosocomial Infections","The improvement of medical care quality is a significant interest for the
future years. The fight against nosocomial infections (NI) in the intensive
care units (ICU) is a good example. We will focus on a set of observations
which reflect the dynamic aspect of the decision, result of the application of
a Medical Decision Support System (MDSS). This system has to make dynamic
decision on temporal data. We use dynamic Bayesian network (DBN) to model this
dynamic process. It is a temporal reasoning within a real-time environment; we
are interested in the Dynamic Decision Support Systems in healthcare domain
(MDDSS).",2012-11-09,2012,2012-11,medical
Fuzzy Soft Set Based Classification for Gene Expression Data,"Classification is one of the major issues in Data Mining Research fields. The
classification problems in medical area often classify medical dataset based on
the result of medical diagnosis or description of medical treatment by the
medical practitioner. This research work discusses the classification process
of Gene Expression data for three different cancers which are breast cancer,
lung cancer and leukemia cancer with two classes which are cancerous stage and
non cancerous stage. We have applied a fuzzy soft set similarity based
classifier to enhance the accuracy to predict the stages among cancer genes and
the informative genes are selected by using Entopy filtering.",2013-01-08,2013,2013-01,medical
"Artificial Intelligence Framework for Simulating Clinical
  Decision-Making: A Markov Decision Process Approach","In the modern healthcare system, rapidly expanding costs/complexity, the
growing myriad of treatment options, and exploding information streams that
often do not effectively reach the front lines hinder the ability to choose
optimal treatment decisions over time. The goal in this paper is to develop a
general purpose (non-disease-specific) computational/artificial intelligence
(AI) framework to address these challenges. This serves two potential
functions: 1) a simulation environment for exploring various healthcare
policies, payment methodologies, etc., and 2) the basis for clinical artificial
intelligence - an AI that can think like a doctor. This approach combines
Markov decision processes and dynamic decision networks to learn from clinical
data and develop complex plans via simulation of alternative sequential
decision paths while capturing the sometimes conflicting, sometimes synergistic
interactions of various components in the healthcare system. It can operate in
partially observable environments (in the case of missing observations or data)
by maintaining belief states about patient health status and functions as an
online agent that plans and re-plans. This framework was evaluated using real
patient data from an electronic health record. Such an AI framework easily
outperforms the current treatment-as-usual (TAU) case-rate/fee-for-service
models of healthcare (Cost per Unit Change: $189 vs. $497) while obtaining a
30-35% increase in patient outcomes. Tweaking certain model parameters further
enhances this advantage, obtaining roughly 50% more improvement for roughly
half the costs. Given careful design and problem formulation, an AI simulation
framework can approximate optimal decisions even in complex and uncertain
environments. Future work is described that outlines potential lines of
research and integration of machine learning algorithms for personalized
medicine.",2013-01-10,2013,2013-01,medical
"Similarity Measures on Preference Structures, Part II: Utility Functions","In previous work cite{Ha98:Towards} we presented a case-based approach to
eliciting and reasoning with preferences. A key issue in this approach is the
definition of similarity between user preferences. We introduced the
probabilistic distance as a measure of similarity on user preferences, and
provided an algorithm to compute the distance between two partially specified
{em value} functions. This is for the case of decision making under {em
certainty}. In this paper we address the more challenging issue of computing
the probabilistic distance in the case of decision making under{em
uncertainty}. We provide an algorithm to compute the probabilistic distance
between two partially specified {em utility} functions. We demonstrate the use
of this algorithm with a medical data set of partially specified patient
preferences,where none of the other existing distancemeasures appear definable.
Using this data set, we also demonstrate that the case-based approach to
preference elicitation isapplicable in domains with uncertainty. Finally, we
provide a comprehensive analytical comparison of the probabilistic distance
with some existing distance measures on preferences.",2013-01-10,2013,2013-01,medical
Multiplicative Factorization of Noisy-Max,"The noisy-or and its generalization noisy-max have been utilized to reduce
the complexity of knowledge acquisition. In this paper, we present a new
representation of noisy-max that allows for efficient inference in general
Bayesian networks. Empirical studies show that our method is capable of
computing queries in well-known large medical networks, QMR-DT and CPCS, for
which no previous exact inference method has been shown to perform well.",2013-01-23,2013,2013-01,medical
A Temporal Bayesian Network for Diagnosis and Prediction,"Diagnosis and prediction in some domains, like medical and industrial
diagnosis, require a representation that combines uncertainty management and
temporal reasoning. Based on the fact that in many cases there are few state
changes in the temporal range of interest, we propose a novel representation
called Temporal Nodes Bayesian Networks (TNBN). In a TNBN each node represents
an event or state change of a variable, and an arc corresponds to a
causal-temporal relationship. The temporal intervals can differ in number and
size for each temporal node, so this allows multiple granularity. Our approach
is contrasted with a dynamic Bayesian network for a simple medical example. An
empirical evaluation is presented for a more complex problem, a subsystem of a
fossil power plant, in which this approach is used for fault diagnosis and
prediction with good results.",2013-01-23,2013,2013-01,medical
Mini-Bucket Heuristics for Improved Search,"The paper is a second in a series of two papers evaluating the power of a new
scheme that generates search heuristics mechanically. The heuristics are
extracted from an approximation scheme called mini-bucket elimination that was
recently introduced. The first paper introduced the idea and evaluated it
within Branch-and-Bound search. In the current paper the idea is further
extended and evaluated within Best-First search. The resulting algorithms are
compared on coding and medical diagnosis problems, using varying strength of
the mini-bucket heuristics.
  Our results demonstrate an effective search scheme that permits controlled
tradeoff between preprocessing (for heuristic generation) and search.
Best-first search is shown to outperform Branch-and-Bound, when supplied with
good heuristics, and sufficient memory space.",2013-01-23,2013,2013-01,medical
From Likelihood to Plausibility,"Several authors have explained that the likelihood ratio measures the
strength of the evidence represented by observations in statistical problems.
This idea works fine when the goal is to evaluate the strength of the available
evidence for a simple hypothesis versus another simple hypothesis. However, the
applicability of this idea is limited to simple hypotheses because the
likelihood function is primarily defined on points (simple hypotheses) of the
parameter space. In this paper we define a general weight of evidence that is
applicable to both simple and composite hypotheses. It is based on the
Dempster-Shafer concept of plausibility and is shown to be a generalization of
the likelihood ratio. Functional models are of a fundamental importance for the
general weight of evidence proposed in this paper. The relevant concepts and
ideas are explained by means of a familiar urn problem and the general analysis
of a real-world medical problem is presented.",2013-01-30,2013,2013-01,medical
"Why Is Diagnosis Using Belief Networks Insensitive to Imprecision In
  Probabilities?","Recent research has found that diagnostic performance with Bayesian belief
networks is often surprisingly insensitive to imprecision in the numerical
probabilities. For example, the authors have recently completed an extensive
study in which they applied random noise to the numerical probabilities in a
set of belief networks for medical diagnosis, subsets of the CPCS network, a
subset of the QMR (Quick Medical Reference) focused on liver and bile diseases.
The diagnostic performance in terms of the average probabilities assigned to
the actual diseases showed small sensitivity even to large amounts of noise. In
this paper, we summarize the findings of this study and discuss possible
explanations of this low sensitivity. One reason is that the criterion for
performance is average probability of the true hypotheses, rather than average
error in probability, which is insensitive to symmetric noise distributions.
But, we show that even asymmetric, logodds-normal noise has modest effects. A
second reason is that the gold-standard posterior probabilities are often near
zero or one, and are little disturbed by noise.",2013-02-13,2013,2013-02,medical
Efficient Decision-Theoretic Planning: Techniques and Empirical Analysis,"This paper discusses techniques for performing efficient decision-theoretic
planning. We give an overview of the DRIPS decision-theoretic refinement
planning system, which uses abstraction to efficiently identify optimal plans.
We present techniques for automatically generating search control information,
which can significantly improve the planner's performance. We evaluate the
efficiency of DRIPS both with and without the search control rules on a complex
medical planning problem and compare its performance to that of a
branch-and-bound decision tree algorithm.",2013-02-20,2013,2013-02,medical
Graph-Grammar Assistance for Automated Generation of Influence Diagrams,"One of the most difficult aspects of modeling complex dilemmas in
decision-analytic terms is composing a diagram of relevance relations from a
set of domain concepts. Decision models in domains such as medicine, however,
exhibit certain prototypical patterns that can guide the modeling process.
Medical concepts can be classified according to semantic types that have
characteristic positions and typical roles in an influence-diagram model. We
have developed a graph-grammar production system that uses such inherent
interrelationships among medical terms to facilitate the modeling of medical
decisions.",2013-03-06,2013,2013-03,medical
Computing as compression: the SP theory of intelligence,"This paper provides an overview of the SP theory of intelligence and its
central idea that artificial intelligence, mainstream computing, and much of
human perception and cognition, may be understood as information compression.
  The background and origins of the SP theory are described, and the main
elements of the theory, including the key concept of multiple alignment,
borrowed from bioinformatics but with important differences. Associated with
the SP theory is the idea that redundancy in information may be understood as
repetition of patterns, that compression of information may be achieved via the
matching and unification (merging) of patterns, and that computing and
information compression are both fundamentally probabilistic. It appears that
the SP system is Turing-equivalent in the sense that anything that may be
computed with a Turing machine may, in principle, also be computed with an SP
machine.
  One of the main strengths of the SP theory and the multiple alignment concept
is in modelling concepts and phenomena in artificial intelligence. Within that
area, the SP theory provides a simple but versatile means of representing
different kinds of knowledge, it can model both the parsing and production of
natural language, with potential for the understanding and translation of
natural languages, it has strengths in pattern recognition, with potential in
computer vision, it can model several kinds of reasoning, and it has
capabilities in planning, problem solving, and unsupervised learning.
  The paper includes two examples showing how alternative parsings of an
ambiguous sentence may be modelled as multiple alignments, and another example
showing how the concept of multiple alignment may be applied in medical
diagnosis.",2013-03-08,2013,2013-03,medical
Analysis in HUGIN of Data Conflict,"After a brief introduction to causal probabilistic networks and the HUGIN
approach, the problem of conflicting data is discussed. A measure of conflict
is defined, and it is used in the medical diagnostic system MUNIN. Finally, it
is discussed how to distinguish between conflicting data and a rare case.",2013-03-27,2013,2013-03,medical
"A Heuristic Bayesian Approach to Knowledge Acquisition: Application to
  Analysis of Tissue-Type Plasminogen Activator","This paper describes a heuristic Bayesian method for computing probability
distributions from experimental data, based upon the multivariate normal form
of the influence diagram. An example illustrates its use in medical technology
assessment. This approach facilitates the integration of results from different
studies, and permits a medical expert to make proper assessments without
considerable statistical training.",2013-03-27,2013,2013-03,medical
"A Combination of Cutset Conditioning with Clique-Tree Propagation in the
  Pathfinder System","Cutset conditioning and clique-tree propagation are two popular methods for
performing exact probabilistic inference in Bayesian belief networks. Cutset
conditioning is based on decomposition of a subset of network nodes, whereas
clique-tree propagation depends on aggregation of nodes. We describe a means to
combine cutset conditioning and clique- tree propagation in an approach called
aggregation after decomposition (AD). We discuss the application of the AD
method in the Pathfinder system, a medical expert system that offers assistance
with diagnosis in hematopathology.",2013-03-27,2013,2013-03,medical
Exact Reasoning Under Uncertainty,"This paper focuses on designing expert systems to support decision making in
complex, uncertain environments. In this context, our research indicates that
strictly probabilistic representations, which enable the use of
decision-theoretic reasoning, are highly preferable to recently proposed
alternatives (e.g., fuzzy set theory and Dempster-Shafer theory). Furthermore,
we discuss the language of influence diagrams and a corresponding methodology
-decision analysis -- that allows decision theory to be used effectively and
efficiently as a decision-making aid. Finally, we use RACHEL, a system that
helps infertile couples select medical treatments, to illustrate the
methodology of decision analysis as basis for expert decision systems.",2013-03-27,2013,2013-03,medical
"Induction and Uncertainty Management Techniques Applied to Veterinary
  Medical Diagnosis","This paper discusses a project undertaken between the Departments of
Computing Science, Statistics, and the College of Veterinary Medicine to design
a medical diagnostic system. On-line medical data has been collected in the
hospital database system for several years. A number of induction methods are
being used to extract knowledge from the data in an attempt to improve upon
simple diagnostic charts used by the clinicians. They also enhance the results
of classical statistical methods - finding many more significant variables. The
second part of the paper describes an essentially Bayesian method of evidence
combination using fuzzy events at an initial step. Results are presented and
comparisons are made with other methods.",2013-03-27,2013,2013-03,medical
"Using Belief Functions for Uncertainty Management and Knowledge
  Acquisition: An Expert Application","This paper describes recent work on an ongoing project in medical diagnosis
at the University of Guelph. A domain on which experts are not very good at
pinpointing a single disease outcome is explored. On-line medical data is
available over a relatively short period of time. Belief Functions
(Dempster-Shafer theory) are first extracted from data and then modified with
expert opinions. Several methods for doing this are compared and results show
that one formulation statistically outperforms the others, including a method
suggested by Shafer. Expert opinions and statistically derived information
about dependencies among symptoms are also compared. The benefits of using
uncertainty management techniques as methods for knowledge acquisition from
data are discussed.",2013-03-27,2013,2013-03,medical
"Experiments Using Belief Functions and Weights of Evidence incorporating
  Statistical Data and Expert Opinions","This paper presents some ideas and results of using uncertainty management
methods in the presence of data in preference to other statistical and machine
learning methods. A medical domain is used as a test-bed with data available
from a large hospital database system which collects symptom and outcome
information about patients. Data is often missing, of many variable types and
sample sizes for particular outcomes is not large. Uncertainty management
methods are useful for such domains and have the added advantage of allowing
for expert modification of belief values originally obtained from data.
Methodological considerations for using belief functions on statistical data
are dealt with in some detail. Expert opinions are Incorporated at various
levels of the project development and results are reported on an application to
liver disease diagnosis. Recent results contrasting the use of weights of
evidence and logistic regression on another medical domain are also presented.",2013-03-27,2013,2013-03,medical
"An Empirical Evaluation of a Randomized Algorithm for Probabilistic
  Inference","In recent years, researchers in decision analysis and artificial intelligence
(Al) have used Bayesian belief networks to build models of expert opinion.
Using standard methods drawn from the theory of computational complexity,
workers in the field have shown that the problem of probabilistic inference in
belief networks is difficult and almost certainly intractable. K N ET, a
software environment for constructing knowledge-based systems within the
axiomatic framework of decision theory, contains a randomized approximation
scheme for probabilistic inference. The algorithm can, in many circumstances,
perform efficient approximate inference in large and richly interconnected
models of medical diagnosis. Unlike previously described stochastic algorithms
for probabilistic inference, the randomized approximation scheme computes a
priori bounds on running time by analyzing the structure and contents of the
belief network. In this article, we describe a randomized algorithm for
probabilistic inference and analyze its performance mathematically. Then, we
devote the major portion of the paper to a discussion of the algorithm's
empirical behavior. The results indicate that the generation of good trials
(that is, trials whose distribution closely matches the true distribution),
rather than the computation of numerous mediocre trials, dominates the
performance of stochastic simulation. Key words: probabilistic inference,
belief networks, stochastic simulation, computational complexity theory,
randomized algorithms.",2013-03-27,2013,2013-03,medical
A Decision-Theoretic Model for Using Scientific Data,"Many Artificial Intelligence systems depend on the agent's updating its
beliefs about the world on the basis of experience. Experiments constitute one
type of experience, so scientific methodology offers a natural environment for
examining the issues attendant to using this class of evidence. This paper
presents a framework which structures the process of using scientific data from
research reports for the purpose of making decisions, using decision analysis
as the basis for the structure and using medical research as the general
scientific domain. The structure extends the basic influence diagram for
updating belief in an object domain parameter of interest by expanding the
parameter into four parts: those of the patient, the population, the study
sample, and the effective study sample. The structure uses biases to perform
the transformation of one parameter into another, so that, for instance,
selection biases, in concert with the population parameter, yield the study
sample parameter. The influence diagram structure provides decision theoretic
justification for practices of good clinical research such as randomized
assignment and blindfolding of care providers. The model covers most research
designs used in medicine: case-control studies, cohort studies, and controlled
clinical trials, and provides an architecture to separate clearly between
statistical knowledge and domain knowledge. The proposed general model can be
the basis for clinical epidemiological advisory systems, when coupled with
heuristic pruning of irrelevant biases; of statistical workstations, when the
computational machinery for calculation of posterior distributions is added;
and of meta-analytic reviews, when multiple studies may impact on a single
population parameter.",2013-03-27,2013,2013-03,medical
A Tractable Inference Algorithm for Diagnosing Multiple Diseases,"We examine a probabilistic model for the diagnosis of multiple diseases. In
the model, diseases and findings are represented as binary variables. Also,
diseases are marginally independent, features are conditionally independent
given disease instances, and diseases interact to produce findings via a noisy
OR-gate. An algorithm for computing the posterior probability of each disease,
given a set of observed findings, called quickscore, is presented. The time
complexity of the algorithm is O(nm-2m+), where n is the number of diseases, m+
is the number of positive findings and m- is the number of negative findings.
Although the time complexity of quickscore i5 exponential in the number of
positive findings, the algorithm is useful in practice because the number of
observed positive findings is usually far less than the number of diseases
under consideration. Performance results for quickscore applied to a
probabilistic version of Quick Medical Reference (QMR) are provided.",2013-03-27,2013,2013-03,medical
"Assessment, Criticism and Improvement of Imprecise Subjective
  Probabilities for a Medical Expert System","Three paediatric cardiologists assessed nearly 1000 imprecise subjective
conditional probabilities for a simple belief network representing congenital
heart disease, and the quality of the assessments has been measured using
prospective data on 200 babies. Quality has been assessed by a Brier scoring
rule, which decomposes into terms measuring lack of discrimination and
reliability. The results are displayed for each of 27 diseases and 24
questions, and generally the assessments are reliable although there was a
tendency for the probabilities to be too extreme. The imprecision allows the
judgements to be converted to implicit samples, and by combining with the
observed data the probabilities naturally adapt with experience. This appears
to be a practical procedure even for reasonably large expert systems.",2013-03-27,2013,2013-03,medical
"NAIVE: A Method for Representing Uncertainty and Temporal Relationships
  in an Automated Reasoner","This paper describes NAIVE, a low-level knowledge representation language and
inferencing process. NAIVE has been designed for reasoning about
nondeterministic dynamic systems like those found in medicine. Knowledge is
represented in a graph structure consisting of nodes, which correspond to the
variables describing the system of interest, and arcs, which correspond to the
procedures used to infer the value of a variable from the values of other
variables. The value of a variable can be determined at an instant in time,
over a time interval or for a series of times. Information about the value of a
variable is expressed as a probability density function which quantifies the
likelihood of each possible value. The inferencing process uses these
probability density functions to propagate uncertainty. NAIVE has been used to
develop medical knowledge bases including over 100 variables.",2013-03-27,2013,2013-03,medical
Steps Towards Programs that Manage Uncertainty,"Reasoning under uncertainty in Al hats come to mean assessing the credibility
of hypotheses inferred from evidence. But techniques for assessing credibility
do not tell a problem solver what to do when it is uncertain. This is the focus
of our current research. We have developed a medical expert system called MUM,
for Managing Uncertainty in Medicine, that plans diagnostic sequences of
questions, tests, and treatments. This paper describes the kinds of problems
that MUM was designed to solve and gives a brief description of its
architecture. More recently, we have built an empty version of MUM called MU,
and used it to reimplement MUM and a small diagnostic system for plant
pathology. The latter part of the paper describes the features of MU that make
it appropriate for building expert systems that manage uncertainty.",2013-03-27,2013,2013-03,medical
"Imprecise Meanings as a Cause of Uncertainty in Medical Knowledge-Based
  Systems","There has been a considerable amount of work on uncertainty in
knowledge-based systems. This work has generally been concerned with
uncertainty arising from the strength of inferences and the weight of evidence.
In this paper we discuss another type of uncertainty: that which is due to
imprecision in the underlying primitives used to represent the knowledge of the
system. In particular, a given word may denote many similar but not identical
entities. Such words are said to be lexically imprecise. Lexical imprecision
has caused widespread problems in many areas. Unless this phenomenon is
recognized and appropriately handled, it can degrade the performance of
knowledge-based systems. In particular, it can lead to difficulties with the
user interface, and with the inferencing processes of these systems. Some
techniques are suggested for coping with this phenomenon.",2013-03-27,2013,2013-03,medical
Advantages and a Limitation of Using LEG Nets in a Real-TIme Problem,"After experimenting with a number of non-probabilistic methods for dealing
with uncertainty many researchers reaffirm a preference for probability methods
[1] [2], although this remains controversial. The importance of being able to
form decisions from incomplete data in diagnostic problems has highlighted
probabilistic methods [5] which compute posterior probabilities from prior
distributions in a way similar to Bayes Rule, and thus are called Bayesian
methods. This paper documents the use of a Bayesian method in a real time
problem which is similar to medical diagnosis in that there is a need to form
decisions and take some action without complete knowledge of conditions in the
problem domain. This particular method has a limitation which is discussed.",2013-03-28,2013,2013-03,medical
"Using a bag of Words for Automatic Medical Image Annotation with a
  Latent Semantic","We present in this paper a new approach for the automatic annotation of
medical images, using the approach of ""bag-of-words"" to represent the visual
content of the medical image combined with text descriptors based approach
tf.idf and reduced by latent semantic to extract the co-occurrence between
terms and visual terms. A medical report is composed of a text describing a
medical image. First, we are interested to index the text and extract all
relevant terms using a thesaurus containing MeSH medical concepts. In a second
phase, the medical image is indexed while recovering areas of interest which
are invariant to change in scale, light and tilt. To annotate a new medical
image, we use the approach of ""bagof-words"" to recover the feature vector.
Indeed, we use the vector space model to retrieve similar medical image from
the database training. The calculation of the relevance value of an image to
the query image is based on the cosine function. We conclude with an experiment
carried out on five types of radiological imaging to evaluate the performance
of our system of medical annotation. The results showed that our approach works
better with more images from the radiology of the skull.",2013-06-02,2013,2013-06,medical
A hybrid decision support system : application on healthcare,"Many systems based on knowledge, especially expert systems for medical
decision support have been developed. Only systems are based on production
rules, and cannot learn and evolve only by updating them. In addition, taking
into account several criteria induces an exorbitant number of rules to be
injected into the system. It becomes difficult to translate medical knowledge
or a support decision as a simple rule. Moreover, reasoning based on generic
cases became classic and can even reduce the range of possible solutions. To
remedy that, we propose an approach based on using a multi-criteria decision
guided by a case-based reasoning (CBR) approach.",2013-11-16,2013,2013-11,medical
Medical Image Fusion: A survey of the state of the art,"Medical image fusion is the process of registering and combining multiple
images from single or multiple imaging modalities to improve the imaging
quality and reduce randomness and redundancy in order to increase the clinical
applicability of medical images for diagnosis and assessment of medical
problems. Multi-modal medical image fusion algorithms and devices have shown
notable achievements in improving clinical accuracy of decisions based on
medical images. This review article provides a factual listing of methods and
summarizes the broad scientific challenges faced in the field of medical image
fusion. We characterize the medical image fusion research based on (1) the
widely used image fusion methods, (2) imaging modalities, and (3) imaging of
organs that are under study. This review concludes that even though there
exists several open ended technological and scientific challenges, the fusion
of medical images has proved to be useful for advancing the clinical
reliability of using medical imaging for medical diagnostics and analysis, and
is a scientific discipline that has the potential to significantly grow in the
coming years.",2013-12-31,2013,2013-12,medical
"Medical diagnosis as pattern recognition in a framework of information
  compression by multiple alignment, unification and search","This paper describes a novel approach to medical diagnosis based on the SP
theory of computing and cognition. The main attractions of this approach are: a
format for representing diseases that is simple and intuitive; an ability to
cope with errors and uncertainties in diagnostic information; the simplicity of
storing statistical information as frequencies of occurrence of diseases; a
method for evaluating alternative diagnostic hypotheses that yields true
probabilities; and a framework that should facilitate unsupervised learning of
medical knowledge and the integration of medical diagnosis with other AI
applications.",2014-09-29,2014,2014-09,medical
"Subsumptive reflection in SNOMED CT: a large description logic-based
  terminology for diagnosis","Description logic (DL) based biomedical terminology (SNOMED CT) is used
routinely in medical practice. However, diagnostic inference using such
terminology is precluded by its complexity. Here we propose a model that
simplifies these inferential components. We propose three concepts that
classify clinical features and examined their effect on inference using SNOMED
CT. We used PAIRS (Physician Assistant Artificial Intelligence Reference
System) database (1964 findings for 485 disorders, 18 397 disease feature
links) for our analysis. We also use a 50-million medical word corpus for
estimating the vectors of disease-feature links. Our major results are 10% of
finding-disorder links are concomitant in both assertion and negation where as
90% are either concomitant in assertion or negation. Logical implications of
PAIRS data on SNOMED CT include 70% of the links do not share any common system
while 18% share organ and 12% share both system and organ. Applications of
these principles for inference are discussed and suggestions are made for
deriving a diagnostic process using SNOMED CT. Limitations of these processes
and suggestions for improvements are also discussed.",2015-12-11,2015,2015-12,medical
"Performance Based Evaluation of Various Machine Learning Classification
  Techniques for Chronic Kidney Disease Diagnosis","Areas where Artificial Intelligence (AI) & related fields are finding their
applications are increasing day by day, moving from core areas of computer
science they are finding their applications in various other domains.In recent
times Machine Learning i.e. a sub-domain of AI has been widely used in order to
assist medical experts and doctors in the prediction, diagnosis and prognosis
of various diseases and other medical disorders. In this manuscript the authors
applied various machine learning algorithms to a problem in the domain of
medical diagnosis and analyzed their efficiency in predicting the results. The
problem selected for the study is the diagnosis of the Chronic Kidney
Disease.The dataset used for the study consists of 400 instances and 24
attributes. The authors evaluated 12 classification techniques by applying them
to the Chronic Kidney Disease data. In order to calculate efficiency, results
of the prediction by candidate methods were compared with the actual medical
results of the subject.The various metrics used for performance evaluation are
predictive accuracy, precision, sensitivity and specificity. The results
indicate that decision-tree performed best with nearly the accuracy of 98.6%,
sensitivity of 0.9720, precision of 1 and specificity of 1.",2016-06-28,2016,2016-06,medical
"Harmonization of conflicting medical opinions using argumentation
  protocols and textual entailment - a case study on Parkinson disease","Parkinson's disease is the second most common neurodegenerative disease,
affecting more than 1.2 million people in Europe. Medications are available for
the management of its symptoms, but the exact cause of the disease is unknown
and there is currently no cure on the market. To better understand the
relations between new findings and current medical knowledge, we need tools
able to analyse published medical papers based on natural language processing
and tools capable to identify various relationships of new findings with the
current medical knowledge. Our work aims to fill the above technological gap.
  To identify conflicting information in medical documents, we enact textual
entailment technology. To encapsulate existing medical knowledge, we rely on
ontologies. To connect the formal axioms in ontologies with natural text in
medical articles, we exploit ontology verbalisation techniques. To assess the
level of disagreement between human agents with respect to a medical issue, we
rely on fuzzy aggregation. To harmonize this disagreement, we design mediation
protocols within a multi-agent framework.",2016-07-27,2016,2016-07,medical
"Mining Arguments from Cancer Documents Using Natural Language Processing
  and Ontologies","In the medical domain, the continuous stream of scientific research contains
contradictory results supported by arguments and counter-arguments. As medical
expertise occurs at different levels, part of the human agents have
difficulties to face the huge amount of studies, but also to understand the
reasons and pieces of evidences claimed by the proponents and the opponents of
the debated topic. To better understand the supporting arguments for new
findings related to current state of the art in the medical domain we need
tools able to identify arguments in scientific papers. Our work here aims to
fill the above technological gap.
  Quite aware of the difficulty of this task, we embark to this road by relying
on the well-known interleaving of domain knowledge with natural language
processing. To formalise the existing medical knowledge, we rely on ontologies.
To structure the argumentation model we use also the expressivity and reasoning
capabilities of Description Logics. To perform argumentation mining we
formalise various linguistic patterns in a rule-based language. We tested our
solution against a corpus of scientific papers related to breast cancer. The
run experiments show a F-measure between 0.71 and 0.86 for identifying
conclusions of an argument and between 0.65 and 0.86 for identifying premises
of an argument.",2016-07-27,2016,2016-07,medical
Relational Models,"We provide a survey on relational models. Relational models describe complete
networked {domains by taking into account global dependencies in the data}.
Relational models can lead to more accurate predictions if compared to
non-relational machine learning approaches. Relational models typically are
based on probabilistic graphical models, e.g., Bayesian networks, Markov
networks, or latent variable models. Relational models have applications in
social networks analysis, the modeling of knowledge graphs, bioinformatics,
recommendation systems, natural language processing, medical decision support,
and linked data.",2016-09-11,2016,2016-09,medical
"GOTM: a Goal-Oriented Framework for Capturing Uncertainty of Medical
  Treatments","It has been widely recognized that uncertainty is an inevitable aspect of
diagnosis and treatment of medical disorders. Such uncertainties hence, need to
be considered in computerized medical models. The existing medical modeling
techniques however, have mainly focused on capturing uncertainty associated
with diagnosis of medical disorders while ignoring uncertainty of treatments.
To tackle this issue, we have proposed using a fuzzy-based modeling and
description technique for capturing uncertainties in treatment plans. We have
further contributed a formal framework which allows for goal-oriented modeling
and analysis of medical treatments.",2016-12-09,2016,2016-12,medical
"Neural Networks for Joint Sentence Classification in Medical Paper
  Abstracts","Existing models based on artificial neural networks (ANNs) for sentence
classification often do not incorporate the context in which sentences appear,
and classify sentences individually. However, traditional sentence
classification approaches have been shown to greatly benefit from jointly
classifying subsequent sentences, such as with conditional random fields. In
this work, we present an ANN architecture that combines the effectiveness of
typical ANN models to classify sentences in isolation, with the strength of
structured prediction. Our model achieves state-of-the-art results on two
different datasets for sequential sentence classification in medical abstracts.",2016-12-15,2016,2016-12,medical
"Learning and inference in knowledge-based probabilistic model for
  medical diagnosis","Based on a weighted knowledge graph to represent first-order knowledge and
combining it with a probabilistic model, we propose a methodology for the
creation of a medical knowledge network (MKN) in medical diagnosis. When a set
of symptoms is activated for a specific patient, we can generate a ground
medical knowledge network composed of symptom nodes and potential disease
nodes. By Incorporating a Boltzmann machine into the potential function of a
Markov network, we investigated the joint probability distribution of the MKN.
In order to deal with numerical symptoms, a multivariate inference model is
presented that uses conditional probability. In addition, the weights for the
knowledge graph were efficiently learned from manually annotated Chinese
Electronic Medical Records (CEMRs). In our experiments, we found numerically
that the optimum choice of the quality of disease node and the expression of
symptom variable can improve the effectiveness of medical diagnosis. Our
experimental results comparing a Markov logic network and the logistic
regression algorithm on an actual CEMR database indicate that our method holds
promise and that MKN can facilitate studies of intelligent diagnosis.",2017-03-28,2017,2017-03,medical
People on Drugs: Credibility of User Statements in Health Communities,"Online health communities are a valuable source of information for patients
and physicians. However, such user-generated resources are often plagued by
inaccuracies and misinformation. In this work we propose a method for
automatically establishing the credibility of user-generated medical statements
and the trustworthiness of their authors by exploiting linguistic cues and
distant supervision from expert sources. To this end we introduce a
probabilistic graphical model that jointly learns user trustworthiness,
statement credibility, and language objectivity. We apply this methodology to
the task of extracting rare or unknown side-effects of medical drugs --- this
being one of the problems where large scale non-expert data has the potential
to complement expert medical knowledge. We show that our method can reliably
extract side-effects and filter out false statements, while identifying
trustworthy users that are likely to contribute valuable medical information.",2017-05-06,2017,2017-05,medical
Brain Intelligence: Go Beyond Artificial Intelligence,"Artificial intelligence (AI) is an important technology that supports daily
social life and economic activities. It contributes greatly to the sustainable
growth of Japan's economy and solves various social problems. In recent years,
AI has attracted attention as a key for growth in developed countries such as
Europe and the United States and developing countries such as China and India.
The attention has been focused mainly on developing new artificial intelligence
information communication technology (ICT) and robot technology (RT). Although
recently developed AI technology certainly excels in extracting certain
patterns, there are many limitations. Most ICT models are overly dependent on
big data, lack a self-idea function, and are complicated. In this paper, rather
than merely developing next-generation artificial intelligence technology, we
aim to develop a new concept of general-purpose intelligence cognition
technology called Beyond AI. Specifically, we plan to develop an intelligent
learning model called Brain Intelligence (BI) that generates new ideas about
events without having experienced them by using artificial life with an imagine
function. We will also conduct demonstrations of the developed BI intelligence
learning model on automatic driving, precision medical care, and industrial
robots.",2017-06-04,2017,2017-06,medical
"Technical Report: Implementation and Validation of a Smart Health
  Application","In this article, we explain in detail the internal structures and databases
of a smart health application. Moreover, we describe how to generate a
statistically sound synthetic dataset using real-world medical data.",2017-06-13,2017,2017-06,medical
"PDD Graph: Bridging Electronic Medical Records and Biomedical Knowledge
  Graphs via Entity Linking","Electronic medical records contain multi-format electronic medical data that
consist of an abundance of medical knowledge. Facing with patient's symptoms,
experienced caregivers make right medical decisions based on their professional
knowledge that accurately grasps relationships between symptoms, diagnosis and
corresponding treatments. In this paper, we aim to capture these relationships
by constructing a large and high-quality heterogenous graph linking patients,
diseases, and drugs (PDD) in EMRs. Specifically, we propose a novel framework
to extract important medical entities from MIMIC-III (Medical Information Mart
for Intensive Care III) and automatically link them with the existing
biomedical knowledge graphs, including ICD-9 ontology and DrugBank. The PDD
graph presented in this paper is accessible on the Web via the SPARQL endpoint,
and provides a pathway for medical discovery and applications, such as
effective treatment recommendations.",2017-07-17,2017,2017-07,medical
"Explainable Artificial Intelligence: Understanding, Visualizing and
  Interpreting Deep Learning Models","With the availability of large databases and recent improvements in deep
learning methodology, the performance of AI systems is reaching or even
exceeding the human level on an increasing number of complex tasks. Impressive
examples of this development can be found in domains such as image
classification, sentiment analysis, speech understanding or strategic game
playing. However, because of their nested non-linear structure, these highly
successful machine learning and artificial intelligence models are usually
applied in a black box manner, i.e., no information is provided about what
exactly makes them arrive at their predictions. Since this lack of transparency
can be a major drawback, e.g., in medical applications, the development of
methods for visualizing, explaining and interpreting deep learning models has
recently attracted increasing attention. This paper summarizes recent
developments in this field and makes a plea for more interpretability in
artificial intelligence. Furthermore, it presents two approaches to explaining
predictions of deep learning models, one method which computes the sensitivity
of the prediction with respect to changes in the input and one approach which
meaningfully decomposes the decision in terms of the input variables. These
methods are evaluated on three classification tasks.",2017-08-28,2017,2017-08,medical
"Determining Positive Cancer Rescue Mutations in p53 Based Cancers by
  using Artificial Intelligence","A mutation in a protein-coding gene in DNA can alter the protein structure
coded by the same gene. Structurally altered proteins usually lose their
functions and sometimes gain an undesirable function instead. These types of
mutations and their effects can result in genetic diseases or antibiotic
resistant bacteria, among other health issues. Important curing methods have
been developed for detecting mutations against AIDS as well as genetic
diseases. Another example is the influenza virus. The reasons why a vaccination
developed to fight against influenza does not work the following year are (a)
the mutation of its DNA and (b) the outbreak of the virus after it has been
mutated especially if it is a virus that escaped the vaccinations target. Due
to such reasons, it is highly important to know in advance the location of a
potential mutation in a protein as well as the problems it might cause the
medical sciences. In this study we have used artificial neural networks, which
are one of the latest artificial intelligence technologies, to determine the
effects of cancer mutations. The model we developed has given more successful
results compared to other methods. We foresee that our model will bring a new
dimension to medical research and the medical industry.",2017-08-28,2017,2017-08,medical
"EMR-based medical knowledge representation and inference via Markov
  random fields and distributed representation learning","Objective: Electronic medical records (EMRs) contain an amount of medical
knowledge which can be used for clinical decision support (CDS). Our objective
is a general system that can extract and represent these knowledge contained in
EMRs to support three CDS tasks: test recommendation, initial diagnosis, and
treatment plan recommendation, with the given condition of one patient.
Methods: We extracted four kinds of medical entities from records and
constructed an EMR-based medical knowledge network (EMKN), in which nodes are
entities and edges reflect their co-occurrence in a single record. Three
bipartite subgraphs (bi-graphs) were extracted from the EMKN to support each
task. One part of the bi-graph was the given condition (e.g., symptoms), and
the other was the condition to be inferred (e.g., diseases). Each bi-graph was
regarded as a Markov random field to support the inference. Three lazy energy
functions and one parameter-based energy function were proposed, as well as two
knowledge representation learning-based energy functions, which can provide a
distributed representation of medical entities. Three measures were utilized
for performance evaluation. Results: On the initial diagnosis task, 80.11% of
the test records identified at least one correct disease from top 10
candidates. Test and treatment recommendation results were 87.88% and 92.55%,
respectively. These results altogether indicate that the proposed system
outperformed the baseline methods. The distributed representation of medical
entities does reflect similarity relationships in regards to knowledge level.
Conclusion: Combining EMKN and MRF is an effective approach for general medical
knowledge representation and inference. Different tasks, however, require
designing their energy functions individually.",2017-09-20,2017,2017-09,medical
Artificial Intelligence and Statistics,"Artificial intelligence (AI) is intrinsically data-driven. It calls for the
application of statistical concepts through human-machine collaboration during
generation of data, development of algorithms, and evaluation of results. This
paper discusses how such human-machine collaboration can be approached through
the statistical concepts of population, question of interest,
representativeness of training data, and scrutiny of results (PQRS). The PQRS
workflow provides a conceptual framework for integrating statistical ideas with
human input into AI products and research. These ideas include experimental
design principles of randomization and local control as well as the principle
of stability to gain reproducibility and interpretability of algorithms and
data results. We discuss the use of these principles in the contexts of
self-driving cars, automated medical diagnoses, and examples from the authors'
collaborative research.",2017-12-08,2017,2017-12,medical
"Towards the Augmented Pathologist: Challenges of Explainable-AI in
  Digital Pathology","Digital pathology is not only one of the most promising fields of diagnostic
medicine, but at the same time a hot topic for fundamental research. Digital
pathology is not just the transfer of histopathological slides into digital
representations. The combination of different data sources (images, patient
records, and *omics data) together with current advances in artificial
intelligence/machine learning enable to make novel information accessible and
quantifiable to a human expert, which is not yet available and not exploited in
current medical settings. The grand goal is to reach a level of usable
intelligence to understand the data in the context of an application task,
thereby making machine decisions transparent, interpretable and explainable.
The foundation of such an ""augmented pathologist"" needs an integrated approach:
While machine learning algorithms require many thousands of training examples,
a human expert is often confronted with only a few data points. Interestingly,
humans can learn from such few examples and are able to instantly interpret
complex patterns. Consequently, the grand goal is to combine the possibilities
of artificial intelligence with human intelligence and to find a well-suited
balance between them to enable what neither of them could do on their own. This
can raise the quality of education, diagnosis, prognosis and prediction of
cancer and other diseases. In this paper we describe some (incomplete) research
issues which we believe should be addressed in an integrated and concerted
effort for paving the way towards the augmented pathologist.",2017-12-18,2017,2017-12,medical
Artificial intelligence and pediatrics: A synthetic mini review,"The use of artificial intelligence intelligencein medicine can be traced back
to 1968 when Paycha published his paper Le diagnostic a l'aide d'intelligences
artificielle, presentation de la premiere machine diagnostri. Few years later
Shortliffe et al. presented an expert system named Mycin which was able to
identify bacteria causing severe blood infections and to recommend antibiotics.
Despite the fact that Mycin outperformed members of the Stanford medical school
in the reliability of diagnosis it was never used in practice due to a legal
issue who do you sue if it gives a wrong diagnosis?. However only in 2016 when
the artificial intelligence software built into the IBM Watson AI platform
correctly diagnosed and proposed an effective treatment for a 60-year-old
womans rare form of leukemia the AI use in medicine become really popular.On of
first papers presenting the use of AI in paediatrics was published in 1984. The
paper introduced a computer-assisted medical decision making system called
SHELP.",2018-02-16,2018,2018-02,medical
"Generating retinal flow maps from structural optical coherence
  tomography with artificial intelligence","Despite significant advances in artificial intelligence (AI) for computer
vision, its application in medical imaging has been limited by the burden and
limits of expert-generated labels. We used images from optical coherence
tomography angiography (OCTA), a relatively new imaging modality that measures
perfusion of the retinal vasculature, to train an AI algorithm to generate
vasculature maps from standard structural optical coherence tomography (OCT)
images of the same retinae, both exceeding the ability and bypassing the need
for expert labeling. Deep learning was able to infer perfusion of
microvasculature from structural OCT images with similar fidelity to OCTA and
significantly better than expert clinicians (P < 0.00001). OCTA suffers from
need of specialized hardware, laborious acquisition protocols, and motion
artifacts; whereas our model works directly from standard OCT which are
ubiquitous and quick to obtain, and allows unlocking of large volumes of
previously collected standard OCT data both in existing clinical trials and
clinical practice. This finding demonstrates a novel application of AI to
medical imaging, whereby subtle regularities between different modalities are
used to image the same body part and AI is used to generate detailed and
accurate inferences of tissue function from structure imaging.",2018-02-24,2018,2018-02,medical
"A Conversational Interface to Improve Medication Adherence: Towards AI
  Support in Patient's Treatment","Medication adherence is of utmost importance for many chronic conditions,
regardless of the disease type. Engaging patients in self-tracking their
medication is a big challenge. One way to potentially reduce this burden is to
use reminders to promote wellness throughout all stages of life and improve
medication adherence. Chatbots have proven effectiveness in triggering users to
engage in certain activity, such as medication adherence. In this paper, we
discuss ""Roborto"", a chatbot to create an engaging interactive and intelligent
environment for patients and assist in positive lifestyle modification. We
introduce a way for healthcare providers to track patients adherence and
intervene whenever necessary. We describe the health, technical and behavioural
approaches to the problem of medication non-adherence and propose a diagnostic
and decision support tool. The proposed study will be implemented and validated
through a pilot experiment with users to measure the efficacy of the proposed
approach.",2018-03-03,2018,2018-03,medical
"Label-aware Double Transfer Learning for Cross-Specialty Medical Named
  Entity Recognition","We study the problem of named entity recognition (NER) from electronic
medical records, which is one of the most fundamental and critical problems for
medical text mining. Medical records which are written by clinicians from
different specialties usually contain quite different terminologies and writing
styles. The difference of specialties and the cost of human annotation makes it
particularly difficult to train a universal medical NER system. In this paper,
we propose a label-aware double transfer learning framework (La-DTL) for
cross-specialty NER, so that a medical NER system designed for one specialty
could be conveniently applied to another one with minimal annotation efforts.
The transferability is guaranteed by two components: (i) we propose label-aware
MMD for feature representation transfer, and (ii) we perform parameter transfer
with a theoretical upper bound which is also label aware. We conduct extensive
experiments on 12 cross-specialty NER tasks. The experimental results
demonstrate that La-DTL provides consistent accuracy improvement over strong
baselines. Besides, the promising experimental results on non-medical NER
scenarios indicate that La-DTL is potential to be seamlessly adapted to a wide
range of NER tasks.",2018-04-24,2018,2018-04,medical
"Classifying medical relations in clinical text via convolutional neural
  networks","Deep learning research on relation classification has achieved solid
performance in the general domain. This study proposes a convolutional neural
network (CNN) architecture with a multi-pooling operation for medical relation
classification on clinical records and explores a loss function with a
category-level constraint matrix. Experiments using the 2010 i2b2/VA relation
corpus demonstrate these models, which do not depend on any external features,
outperform previous single-model methods and our best model is competitive with
the existing ensemble-based method.",2018-05-17,2018,2018-05,medical
"Producing radiologist-quality reports for interpretable artificial
  intelligence","Current approaches to explaining the decisions of deep learning systems for
medical tasks have focused on visualising the elements that have contributed to
each decision. We argue that such approaches are not enough to ""open the black
box"" of medical decision making systems because they are missing a key
component that has been used as a standard communication tool between doctors
for centuries: language. We propose a model-agnostic interpretability method
that involves training a simple recurrent neural network model to produce
descriptive sentences to clarify the decision of deep learning classifiers.
  We test our method on the task of detecting hip fractures from frontal pelvic
x-rays. This process requires minimal additional labelling despite producing
text containing elements that the original deep learning classification model
was not specifically trained to detect.
  The experimental results show that: 1) the sentences produced by our method
consistently contain the desired information, 2) the generated sentences are
preferred by doctors compared to current tools that create saliency maps, and
3) the combination of visualisations and generated text is better than either
alone.",2018-06-01,2018,2018-06,medical
Medical Concept Embedding with Time-Aware Attention,"Embeddings of medical concepts such as medication, procedure and diagnosis
codes in Electronic Medical Records (EMRs) are central to healthcare analytics.
Previous work on medical concept embedding takes medical concepts and EMRs as
words and documents respectively. Nevertheless, such models miss out the
temporal nature of EMR data. On the one hand, two consecutive medical concepts
do not indicate they are temporally close, but the correlations between them
can be revealed by the time gap. On the other hand, the temporal scopes of
medical concepts often vary greatly (e.g., \textit{common cold} and
\textit{diabetes}). In this paper, we propose to incorporate the temporal
information to embed medical codes. Based on the Continuous Bag-of-Words model,
we employ the attention mechanism to learn a ""soft"" time-aware context window
for each medical concept. Experiments on public and proprietary datasets
through clustering and nearest neighbour search tasks demonstrate the
effectiveness of our model, showing that it outperforms five state-of-the-art
baselines.",2018-06-06,2018,2018-06,medical
Behavior Trees as a Representation for Medical Procedures,"Objective: Effective collaboration between machines and clinicians requires
flexible data structures to represent medical processes and clinical practice
guidelines. Such a data structure could enable effective turn-taking between
human and automated components of a complex treatment, accurate on-line
monitoring of clinical treatments (for example to detect medical errors), or
automated treatment systems (such as future medical robots) whose overall
treatment plan is understandable and auditable by human experts.
  Materials and Methods: Behavior trees (BTs) emerged from video game
development as a graphical language for modeling intelligent agent behavior.
BTs have several properties which are attractive for modeling medical
procedures including human-readability, authoring tools, and composability.
  Results: This paper will illustrate construction of BTs for exemplary medical
procedures and clinical protocols.
  Discussion and Conclusion: Behavior Trees thus form a useful, and human
authorable/readable bridge between clinical practice guidelines and AI systems.",2018-08-27,2018,2018-08,medical
"Adaptive Structural Learning of Deep Belief Network for Medical
  Examination Data and Its Knowledge Extraction by using C4.5","Deep Learning has a hierarchical network architecture to represent the
complicated feature of input patterns. The adaptive structural learning method
of Deep Belief Network (DBN) has been developed. The method can discover an
optimal number of hidden neurons for given input data in a Restricted Boltzmann
Machine (RBM) by neuron generation-annihilation algorithm, and generate a new
hidden layer in DBN by the extension of the algorithm. In this paper, the
proposed adaptive structural learning of DBN was applied to the comprehensive
medical examination data for the cancer prediction. The prediction system shows
higher classification accuracy (99.8% for training and 95.5% for test) than the
traditional DBN. Moreover, the explicit knowledge with respect to the relation
between input and output patterns was extracted from the trained DBN network by
C4.5. Some characteristics extracted in the form of IF-THEN rules to find an
initial cancer at the early stage were reported in this paper.",2018-08-27,2018,2018-08,medical
"GAMENet: Graph Augmented MEmory Networks for Recommending Medication
  Combination","Recent progress in deep learning is revolutionizing the healthcare domain
including providing solutions to medication recommendations, especially
recommending medication combination for patients with complex health
conditions. Existing approaches either do not customize based on patient health
history, or ignore existing knowledge on drug-drug interactions (DDI) that
might lead to adverse outcomes. To fill this gap, we propose the Graph
Augmented Memory Networks (GAMENet), which integrates the drug-drug
interactions knowledge graph by a memory module implemented as a graph
convolutional networks, and models longitudinal patient records as the query.
It is trained end-to-end to provide safe and personalized recommendation of
medication combination. We demonstrate the effectiveness and safety of GAMENet
by comparing with several state-of-the-art methods on real EHR data. GAMENet
outperformed all baselines in all effectiveness measures, and also achieved
3.60% DDI rate reduction from existing EHR data.",2018-09-06,2018,2018-09,medical
Focus Group on Artificial Intelligence for Health,"Artificial Intelligence (AI) - the phenomenon of machines being able to solve
problems that require human intelligence - has in the past decade seen an
enormous rise of interest due to significant advances in effectiveness and use.
The health sector, one of the most important sectors for societies and
economies worldwide, is particularly interesting for AI applications, given the
ongoing digitalisation of all types of health information. The potential for AI
assistance in the health domain is immense, because AI can support medical
decision making at reduced costs, everywhere. However, due to the complexity of
AI algorithms, it is difficult to distinguish good from bad AI-based solutions
and to understand their strengths and weaknesses, which is crucial for
clarifying responsibilities and for building trust. For this reason, the
International Telecommunication Union (ITU) has established a new Focus Group
on ""Artificial Intelligence for Health"" (FG-AI4H) in partnership with the World
Health Organization (WHO). Health and care services are usually the
responsibility of a government - even when provided through private insurance
systems - and thus under the responsibility of WHO/ITU member states. FG-AI4H
will identify opportunities for international standardization, which will
foster the application of AI to health issues on a global scale. In particular,
it will establish a standardized assessment framework with open benchmarks for
the evaluation of AI-based methods for health, such as AI-based diagnosis,
triage or treatment decisions.",2018-09-13,2018,2018-09,medical
Finding Similar Medical Questions from Question Answering Websites,"The past few years have witnessed the flourishing of crowdsourced medical
question answering (Q&A) websites. Patients who have medical information
demands tend to post questions about their health conditions on these
crowdsourced Q&A websites and get answers from other users. However, we observe
that a large portion of new medical questions cannot be answered in time or
receive only few answers from these websites. On the other hand, we notice that
solved questions have great potential to solve this challenge. Motivated by
these, we propose an end-to-end system that can automatically find similar
questions for unsolved medical questions. By learning the vector presentation
of unsolved questions and their candidate similar questions, the proposed
system outputs similar questions according to the similarity between vector
representations. Through the vector representation, the similar questions are
found at the question level, and the diversity of medical questions expression
issue can be addressed. Further, we handle two more important issues, i.e.,
training data generation issue and efficiency issue, associated with the LSTM
training procedure and the retrieval of candidate similar questions. The
effectiveness of the proposed system is validated on a large-scale real-world
dataset collected from a crowdsourced maternal-infant Q&A website.",2018-10-14,2018,2018-10,medical
On the Generation of Medical Question-Answer Pairs,"Question answering (QA) has achieved promising progress recently. However,
answering a question in real-world scenarios like the medical domain is still
challenging, due to the requirement of external knowledge and the insufficient
quantity of high-quality training data. In the light of these challenges, we
study the task of generating medical QA pairs in this paper. With the insight
that each medical question can be considered as a sample from the latent
distribution of questions given answers, we propose an automated medical QA
pair generation framework, consisting of an unsupervised key phrase detector
that explores unstructured material for validity, and a generator that involves
a multi-pass decoder to integrate structural knowledge for diversity. A series
of experiments have been conducted on a real-world dataset collected from the
National Medical Licensing Examination of China. Both automatic evaluation and
human annotation demonstrate the effectiveness of the proposed method. Further
investigation shows that, by incorporating the generated QA pairs for training,
significant improvement in terms of accuracy can be achieved for the
examination QA system.",2018-11-01,2018,2018-11,medical
Exploiting Sentence Embedding for Medical Question Answering,"Despite the great success of word embedding, sentence embedding remains a
not-well-solved problem. In this paper, we present a supervised learning
framework to exploit sentence embedding for the medical question answering
task. The learning framework consists of two main parts: 1) a sentence
embedding producing module, and 2) a scoring module. The former is developed
with contextual self-attention and multi-scale techniques to encode a sentence
into an embedding tensor. This module is shortly called Contextual
self-Attention Multi-scale Sentence Embedding (CAMSE). The latter employs two
scoring strategies: Semantic Matching Scoring (SMS) and Semantic Association
Scoring (SAS). SMS measures similarity while SAS captures association between
sentence pairs: a medical question concatenated with a candidate choice, and a
piece of corresponding supportive evidence. The proposed framework is examined
by two Medical Question Answering(MedicalQA) datasets which are collected from
real-world applications: medical exam and clinical diagnosis based on
electronic medical records (EMR). The comparison results show that our proposed
framework achieved significant improvements compared to competitive baseline
approaches. Additionally, a series of controlled experiments are also conducted
to illustrate that the multi-scale strategy and the contextual self-attention
layer play important roles for producing effective sentence embedding, and the
two kinds of scoring strategies are highly complementary to each other for
question answering problems.",2018-11-15,2018,2018-11,medical
Multimodal Densenet,"Humans make accurate decisions by interpreting complex data from multiple
sources. Medical diagnostics, in particular, often hinge on human
interpretation of multi-modal information. In order for artificial intelligence
to make progress in automated, objective, and accurate diagnosis and prognosis,
methods to fuse information from multiple medical imaging modalities are
required. However, combining information from multiple data sources has several
challenges, as current deep learning architectures lack the ability to extract
useful representations from multimodal information, and often simple
concatenation is used to fuse such information. In this work, we propose
Multimodal DenseNet, a novel architecture for fusing multimodal data. Instead
of focusing on concatenation or early and late fusion, our proposed
architectures fuses information over several layers and gives the model
flexibility in how it combines information from multiple sources. We apply this
architecture to the challenge of polyp characterization and landmark
identification in endoscopy. Features from white light images are fused with
features from narrow band imaging or depth maps. This study demonstrates that
Multimodal DenseNet outperforms monomodal classification as well as other
multimodal fusion techniques by a significant margin on two different datasets.",2018-11-18,2018,2018-11,medical
Model-Based Reinforcement Learning for Sepsis Treatment,"Sepsis is a dangerous condition that is a leading cause of patient mortality.
Treating sepsis is highly challenging, because individual patients respond very
differently to medical interventions and there is no universally agreed-upon
treatment for sepsis. In this work, we explore the use of continuous
state-space model-based reinforcement learning (RL) to discover high-quality
treatment policies for sepsis patients. Our quantitative evaluation reveals
that by blending the treatment strategy discovered with RL with what clinicians
follow, we can obtain improved policies, potentially allowing for better
medical treatment for sepsis.",2018-11-23,2018,2018-11,medical
"XNet: A convolutional neural network (CNN) implementation for medical
  X-Ray image segmentation suitable for small datasets","X-Ray image enhancement, along with many other medical image processing
applications, requires the segmentation of images into bone, soft tissue, and
open beam regions. We apply a machine learning approach to this problem,
presenting an end-to-end solution which results in robust and efficient
inference. Since medical institutions frequently do not have the resources to
process and label the large quantity of X-Ray images usually needed for neural
network training, we design an end-to-end solution for small datasets, while
achieving state-of-the-art results. Our implementation produces an overall
accuracy of 92%, F1 score of 0.92, and an AUC of 0.98, surpassing classical
image processing techniques, such as clustering and entropy based methods,
while improving upon the output of existing neural networks used for
segmentation in non-medical contexts. The code used for this project is
available online.",2018-12-03,2018,2018-12,medical
Medical Diagnosis with a Novel SVM-CoDOA Based Hybrid Approach,"Machine Learning is an important sub-field of the Artificial Intelligence and
it has been become a very critical task to train Machine Learning techniques
via effective method or techniques. Recently, researchers try to use
alternative techniques to improve ability of Machine Learning techniques.
Moving from the explanations, objective of this study is to introduce a novel
SVM-CoDOA (Cognitive Development Optimization Algorithm trained Support Vector
Machines) system for general medical diagnosis. In detail, the system consists
of a SVM, which is trained by CoDOA, a newly developed optimization algorithm.
As it is known, use of optimization algorithms is an essential task to train
and improve Machine Learning techniques. In this sense, the study has provided
a medical diagnosis oriented problem scope in order to show effectiveness of
the SVM-CoDOA hybrid formation.",2019-02-02,2019,2019-02,medical
"Outlining the Design Space of Explainable Intelligent Systems for
  Medical Diagnosis","The adoption of intelligent systems creates opportunities as well as
challenges for medical work. On the positive side, intelligent systems have the
potential to compute complex data from patients and generate automated
diagnosis recommendations for doctors. However, medical professionals often
perceive such systems as black boxes and, therefore, feel concerned about
relying on system generated results to make decisions. In this paper, we
contribute to the ongoing discussion of explainable artificial intelligence
(XAI) by exploring the concept of explanation from a human-centered
perspective. We hypothesize that medical professionals would perceive a system
as explainable if the system was designed to think and act like doctors. We
report a preliminary interview study that collected six medical professionals'
reflection of how they interact with data for diagnosis and treatment purposes.
Our data reveals when and how doctors prioritize among various types of data as
a central part of their diagnosis process. Based on these findings, we outline
future directions regarding the design of XAI systems in the medical context.",2019-02-16,2019,2019-02,medical
"The Virtual Doctor: An Interactive Artificial Intelligence based on Deep
  Learning for Non-Invasive Prediction of Diabetes","Artificial intelligence (AI) will pave the way to a new era in medicine.
However, currently available AI systems do not interact with a patient, e.g.,
for anamnesis, and thus are only used by the physicians for predictions in
diagnosis or prognosis. However, these systems are widely used, e.g., in
diabetes or cancer prediction. In the current study, we developed an AI that is
able to interact with a patient (virtual doctor) by using a speech recognition
and speech synthesis system and thus can autonomously interact with the
patient, which is particularly important for, e.g., rural areas, where the
availability of primary medical care is strongly limited by low population
densities. As a proof-of-concept, the system is able to predict type 2 diabetes
mellitus (T2DM) based on non-invasive sensors and deep neural networks.
Moreover, the system provides an easy-to-interpret probability estimation for
T2DM for a given patient. Besides the development of the AI, we further
analyzed the acceptance of young people for AI in healthcare to estimate the
impact of such system in the future.",2019-03-09,2019,2019-03,medical
"Parallel Medical Imaging for Intelligent Medical Image Analysis:
  Concepts, Methods, and Applications","There has been much progress in data-driven artificial intelligence
technology for medical image analysis in the last decades. However, it still
remains challenging due to its distinctive complexity of acquiring and
annotating image data, extracting medical domain knowledge, and explaining the
diagnostic decision for medical image analysis. In this paper, we propose a
data-knowledge-driven framework termed as Parallel Medical Imaging (PMI) for
intelligent medical image analysis based on the methodology of interactive
ACP-based parallel intelligence. In the PMI framework, computational
experiments with predictive learning in a data-driven way are conducted to
extract medical knowledge for diagnostic decision support. Artificial imaging
systems are introduced to select and prescriptively generate medical image data
in a knowledge-driven way to utilize medical domain knowledge. Through the
closed-loop optimization based on parallel execution, our proposed PMI
framework can boost the generalization ability and alleviate the limitation of
medical interpretation for diagnostic decisions. Furthermore, we illustrate the
preliminary implementation of PMI method through the case studies of mammogram
analysis and skin lesion image analysis. Experimental results on several public
medical image datasets demonstrate the effectiveness of proposed PMI.",2019-03-12,2019,2019-03,medical
"Social Behavioral Phenotyping of Drosophila with a2D-3D Hybrid CNN
  Framework","Behavioural phenotyping of Drosophila is an important means in biological and
medical research to identify genetic, pathologic or psychologic impact on
animal behaviour.",2019-03-27,2019,2019-03,medical
Learning More with Less: GAN-based Medical Image Augmentation,"Convolutional Neural Network (CNN)-based accurate prediction typically
requires large-scale annotated training data. In Medical Imaging, however, both
obtaining medical data and annotating them by expert physicians are
challenging; to overcome this lack of data, Data Augmentation (DA) using
Generative Adversarial Networks (GANs) is essential, since they can synthesize
additional annotated training data to handle small and fragmented medical
images from various scanners--those generated images, realistic but completely
novel, can further fill the real image distribution uncovered by the original
dataset. As a tutorial, this paper introduces GAN-based Medical Image
Augmentation, along with tricks to boost classification/object
detection/segmentation performance using them, based on our experience and
related work. Moreover, we show our first GAN-based DA work using automatic
bounding box annotation, for robust CNN-based brain metastases detection on 256
x 256 MR images; GAN-based DA can boost 10% sensitivity in diagnosis with a
clinically acceptable number of additional False Positives, even with
highly-rough and inconsistent bounding boxes.",2019-03-29,2019,2019-03,medical
"MedGCN: Medication recommendation and lab test imputation via graph
  convolutional networks","Laboratory testing and medication prescription are two of the most important
routines in daily clinical practice. Developing an artificial intelligence
system that can automatically make lab test imputations and medication
recommendations can save costs on potentially redundant lab tests and inform
physicians of a more effective prescription. We present an intelligent medical
system (named MedGCN) that can automatically recommend the patients'
medications based on their incomplete lab tests, and can even accurately
estimate the lab values that have not been taken. In our system, we integrate
the complex relations between multiple types of medical entities with their
inherent features in a heterogeneous graph. Then we model the graph to learn a
distributed representation for each entity in the graph based on graph
convolutional networks (GCN). By the propagation of graph convolutional
networks, the entity representations can incorporate multiple types of medical
information that can benefit multiple medical tasks. Moreover, we introduce a
cross regularization strategy to reduce overfitting for multi-task training by
the interaction between the multiple tasks. In this study, we construct a graph
to associate 4 types of medical entities, i.e., patients, encounters, lab
tests, and medications, and applied a graph neural network to learn node
embeddings for medication recommendation and lab test imputation. we validate
our MedGCN model on two real-world datasets: NMEDW and MIMIC-III. The
experimental results on both datasets demonstrate that our model can outperform
the state-of-the-art in both tasks. We believe that our innovative system can
provide a promising and reliable way to assist physicians to make medication
prescriptions and to save costs on potentially redundant lab tests.",2019-03-31,2019,2019-03,medical
"A Strong Baseline for Domain Adaptation and Generalization in Medical
  Imaging","This work provides a strong baseline for the problem of multi-source
multi-target domain adaptation and generalization in medical imaging. Using a
diverse collection of ten chest X-ray datasets, we empirically demonstrate the
benefits of training medical imaging deep learning models on varied patient
populations for generalization to out-of-sample domains.",2019-04-02,2019,2019-04,medical
Artificial Intelligence for Pediatric Ophthalmology,"PURPOSE OF REVIEW: Despite the impressive results of recent artificial
intelligence (AI) applications to general ophthalmology, comparatively less
progress has been made toward solving problems in pediatric ophthalmology using
similar techniques. This article discusses the unique needs of pediatric
ophthalmology patients and how AI techniques can address these challenges,
surveys recent applications of AI to pediatric ophthalmology, and discusses
future directions in the field.
  RECENT FINDINGS: The most significant advances involve the automated
detection of retinopathy of prematurity (ROP), yielding results that rival
experts. Machine learning (ML) has also been successfully applied to the
classification of pediatric cataracts, prediction of post-operative
complications following cataract surgery, detection of strabismus and
refractive error, prediction of future high myopia, and diagnosis of reading
disability via eye tracking. In addition, ML techniques have been used for the
study of visual development, vessel segmentation in pediatric fundus images,
and ophthalmic image synthesis.
  SUMMARY: AI applications could significantly benefit clinical care for
pediatric ophthalmology patients by optimizing disease detection and grading,
broadening access to care, furthering scientific discovery, and improving
clinical efficiency. These methods need to match or surpass physician
performance in clinical trials before deployment with patients. Due to
widespread use of closed-access data sets and software implementations, it is
difficult to directly compare the performance of these approaches, and
reproducibility is poor. Open-access data sets and software implementations
could alleviate these issues, and encourage further AI applications to
pediatric ophthalmology.
  KEYWORDS: pediatric ophthalmology, machine learning, artificial intelligence,
deep learning",2019-04-06,2019,2019-04,medical
"A new direction to promote the implementation of artificial intelligence
  in natural clinical settings","Artificial intelligence (AI) researchers claim that they have made great
`achievements' in clinical realms. However, clinicians point out the so-called
`achievements' have no ability to implement into natural clinical settings. The
root cause for this huge gap is that many essential features of natural
clinical tasks are overlooked by AI system developers without medical
background. In this paper, we propose that the clinical benchmark suite is a
novel and promising direction to capture the essential features of the
real-world clinical tasks, hence qualifies itself for guiding the development
of AI systems, promoting the implementation of AI in real-world clinical
practice.",2019-05-08,2019,2019-05,medical
"Artificial intelligence technology in oncology: a new technological
  paradigm","Artificial Intelligence (AI) technology is based on theory and development of
computer systems able to perform tasks that normally require human
intelligence. In this context, deep learning is a family of computational
methods that allow an algorithm to program itself by learning from a large set
of examples that demonstrate the desired behavior. Application of these methods
to medical imaging can assist pathologists in the detection of cancer subtype,
gene mutations and/or metastases for applying appropriate therapies. The
purpose of this study is to show the emerging application of AI in medical
imaging to detect lung and breast cancer. Moreover, this study shows the
comparative evolutionary pathways of this emerging technology for three
critical cancers: lung, breast and thyroid. A main finding of this study is the
recognition that, since the late 1990, the sharp increase of technological
trajectories of AI technology applied in cancer imaging seems to be driven by
high rates of mortality of some types of cancer (e.g., lung and breast) in
order to find new techniques for a more accurate detection, characterization
and monitoring as well as to apply efficiently anticancer therapies that
increase the progression-free survival of patients: the so-called
mortality-driven AI technological trajectories. Results also suggest that this
new technology can generate a technological paradigm shift for diagnostic
assessment of any cancer type. However, application of these methods to medical
imaging requires further assessment and validation to assist pathologists to
increase the efficiency of their workflow in both routine tasks and critical
cases of diagnostics.",2019-05-14,2019,2019-05,medical
"Using Natural Language Processing to Develop an Automated Orthodontic
  Diagnostic System","We work on the task of automatically designing a treatment plan from the
findings included in the medical certificate written by the dentist. To develop
an artificial intelligence system that deals with free-form certificates
written by dentists, we annotate the findings and utilized the natural language
processing approach. As a result of the experiment using 990 certificates,
0.585 F1-score was achieved for the task of extracting orthodontic problems
from findings, and 0.584 correlation coefficient with the human ranking was
achieved for the treatment prioritization task.",2019-05-31,2019,2019-05,medical
"Pre-training of Graph Augmented Transformers for Medication
  Recommendation","Medication recommendation is an important healthcare application. It is
commonly formulated as a temporal prediction task. Hence, most existing works
only utilize longitudinal electronic health records (EHRs) from a small number
of patients with multiple visits ignoring a large number of patients with a
single visit (selection bias). Moreover, important hierarchical knowledge such
as diagnosis hierarchy is not leveraged in the representation learning process.
To address these challenges, we propose G-BERT, a new model to combine the
power of Graph Neural Networks (GNNs) and BERT (Bidirectional Encoder
Representations from Transformers) for medical code representation and
medication recommendation. We use GNNs to represent the internal hierarchical
structures of medical codes. Then we integrate the GNN representation into a
transformer-based visit encoder and pre-train it on EHR data from patients only
with a single visit. The pre-trained visit encoder and representation are then
fine-tuned for downstream predictive tasks on longitudinal EHRs from patients
with multiple visits. G-BERT is the first to bring the language model
pre-training schema into the healthcare domain and it achieved state-of-the-art
performance on the medication recommendation task.",2019-06-02,2019,2019-06,medical
Artificial Intelligence in Clinical Health Care Applications: Viewpoint,"The idea of Artificial Intelligence (AI) has a long history. It turned out,
however, that reaching intelligence at human levels is more complicated than
originally anticipated. Currently we are experiencing a renewed interest in AI,
fueled by an enormous increase in computing power and an even larger increase
in data, in combination with improved AI technologies like deep learning.
Healthcare is considered the next domain to be revolutionized by Artificial
Intelligence. While AI approaches are excellently suited to develop certain
algorithms, for biomedical applications there are specific challenges. We
propose recommendations to improve AI projects in the biomedical space and
especially clinical healthcare.",2019-06-05,2019,2019-06,medical
"High Accuracy Classification of White Blood Cells using TSLDA Classifier
  and Covariance Features","creating automated processes in different areas of medical science with the
application of engineering tools is a highly growing field over recent decades.
In this context, many medical image processing and analyzing researchers use
worthwhile methods in artificial intelligence, which can reduce necessary human
power while increases accuracy of results. Among various medical images, blood
microscopic images play a vital role in heart failure diagnosis, e.g., blood
cancers. The prominent component in blood cancer diagnosis is white blood cells
(WBCs) which due to its general characteristics in microscopic images sometimes
make difficulties in recognition and classification tasks such as non-uniform
colors/illuminances, different shapes, sizes, and textures. Moreover,
overlapped WBCs in bone marrow images and neighboring to red blood cells are
identified as reasons for errors in the classification task. In this paper, we
have endeavored to segment various parts in medical images via Na\""ive Bayes
clustering method and in next stage via TSLDA classifier, which is supplied by
features acquired from covariance descriptor results in the accuracy of 98.02%.
It seems that this result is delightful in WBCs recognition.",2019-06-12,2019,2019-06,medical
"Developing an App to interpret Chest X-rays to support the diagnosis of
  respiratory pathology with Artificial Intelligence","In this paper we present our work to improve access to diagnosis in remote
areas where good quality medical services may be lacking. We develop new
Machine Learning methodologies for deployment onto mobile devices to help the
early diagnosis of a number of life-threatening conditions using X-ray images.
By using the latest developments in fast and portable Artificial Intelligence
environments, we develop a smartphone app using an Artificial Neural Network to
assist physicians in their diagnostic.",2019-06-26,2019,2019-06,medical
"A Survey on Explainable Artificial Intelligence (XAI): Towards Medical
  XAI","Recently, artificial intelligence and machine learning in general have
demonstrated remarkable performances in many tasks, from image processing to
natural language processing, especially with the advent of deep learning. Along
with research progress, they have encroached upon many different fields and
disciplines. Some of them require high level of accountability and thus
transparency, for example the medical sector. Explanations for machine
decisions and predictions are thus needed to justify their reliability. This
requires greater interpretability, which often means we need to understand the
mechanism underlying the algorithms. Unfortunately, the blackbox nature of the
deep learning is still unresolved, and many machine decisions are still poorly
understood. We provide a review on interpretabilities suggested by different
research works and categorize them. The different categories show different
dimensions in interpretability research, from approaches that provide
""obviously"" interpretable information to the studies of complex patterns. By
applying the same categorization to interpretability in medical research, it is
hoped that (1) clinicians and practitioners can subsequently approach these
methods with caution, (2) insights into interpretability will be born with more
considerations for medical practices, and (3) initiatives to push forward
data-based, mathematically- and technically-grounded medical education are
encouraged.",2019-07-17,2019,2019-07,medical
"Linking Physicians to Medical Research Results via Knowledge Graph
  Embeddings and Twitter","Informing professionals about the latest research results in their field is a
particularly important task in the field of health care, since any development
in this field directly improves the health status of the patients. Meanwhile,
social media is an infrastructure that allows public instant sharing of
information, thus it has recently become popular in medical applications. In
this study, we apply Multi Distance Knowledge Graph Embeddings (MDE) to link
physicians and surgeons to the latest medical breakthroughs that are shared as
the research results on Twitter. Our study shows that using this method
physicians can be informed about the new findings in their field given that
they have an account dedicated to their profession.",2019-07-24,2019,2019-07,medical
"Clinical acceptance of software based on artificial intelligence
  technologies (radiology)","Aim: provide a methodological framework for the process of clinical tests,
clinical acceptance, and scientific assessment of algorithms and software based
on the artificial intelligence (AI) technologies. Clinical tests are considered
as a preparation stage for the software registration as a medical product. The
authors propose approaches to evaluate accuracy and efficiency of the AI
algorithms for radiology.",2019-08-01,2019,2019-08,medical
Incorporating Domain Knowledge into Medical NLI using Knowledge Graphs,"Recently, biomedical version of embeddings obtained from language models such
as BioELMo have shown state-of-the-art results for the textual inference task
in the medical domain. In this paper, we explore how to incorporate structured
domain knowledge, available in the form of a knowledge graph (UMLS), for the
Medical NLI task. Specifically, we experiment with fusing embeddings obtained
from knowledge graph with the state-of-the-art approaches for NLI task (ESIM
model). We also experiment with fusing the domain-specific sentiment
information for the task. Experiments conducted on MedNLI dataset clearly show
that this strategy improves the baseline BioELMo architecture for the Medical
NLI task.",2019-08-31,2019,2019-08,medical
"DeepHealth: Review and challenges of artificial intelligence in health
  informatics","Artificial intelligence has provided us with an exploration of a whole new
research era. As more data and better computational power become available, the
approach is being implemented in various fields. The demand for it in health
informatics is also increasing, and we can expect to see the potential benefits
of its applications in healthcare. It can help clinicians diagnose disease,
identify drug effects for each patient, understand the relationship between
genotypes and phenotypes, explore new phenotypes or treatment recommendations,
and predict infectious disease outbreaks with high accuracy. In contrast to
traditional models, recent artificial intelligence approaches do not require
domain-specific data pre-processing, and it is expected that it will ultimately
change life in the future. Despite its notable advantages, there are some key
challenges on data (high dimensionality, heterogeneity, time dependency,
sparsity, irregularity, lack of label, bias) and model (reliability,
interpretability, feasibility, security, scalability) for practical use. This
article presents a comprehensive review of research applying artificial
intelligence in health informatics, focusing on the last seven years in the
fields of medical imaging, electronic health records, genomics, sensing, and
online communication health, as well as challenges and promising directions for
future research. We highlight ongoing popular approaches' research and identify
several challenges in building models.",2019-09-01,2019,2019-09,medical
"A Method to Learn Embedding of a Probabilistic Medical Knowledge Graph:
  Algorithm Development","This paper proposes an algorithm named as PrTransH to learn embedding vectors
from real world EMR data based medical knowledge. The unique challenge in
embedding medical knowledge graph from real world EMR data is that the
uncertainty of knowledge triplets blurs the border between ""correct triplet""
and ""wrong triplet"", changing the fundamental assumption of many existing
algorithms. To address the challenge, some enhancements are made to existing
TransH algorithm, including: 1) involve probability of medical knowledge
triplet into training objective; 2) replace the margin-based ranking loss with
unified loss calculation considering both valid and corrupted triplets; 3)
augment training data set with medical background knowledge. Verifications on
real world EMR data based medical knowledge graph prove that PrTransH
outperforms TransH in link prediction task. To the best of our survey, this
paper is the first one to learn and verify knowledge embedding on probabilistic
knowledge graphs.",2019-09-02,2019,2019-09,medical
Lattice-Based Fuzzy Medical Expert System for Low Back Pain Management,"Low Back Pain (LBP) is a common medical condition that deprives many
individuals worldwide of their normal routine activities. In the absence of
external biomarkers, diagnosis of LBP is quite challenging. It requires dealing
with several clinical variables, which have no precisely quantified values.
Aiming at the development of a fuzzy medical expert system for LBP management,
this research proposes an attractive lattice-based knowledge representation
scheme for handling imprecision in knowledge, offering a suitable design
methodology for a fuzzy knowledge base and a fuzzy inference system. The fuzzy
knowledge base is constructed in modular fashion, with each module capturing
interrelated medical knowledge about the relevant clinical history, clinical
examinations and laboratory investigation results. This approach in design
ensures optimality, consistency and preciseness in the knowledge base and
scalability. The fuzzy inference system, which uses the Mamdani method, adopts
the triangular membership function for fuzzification and the Centroid of Area
technique for defuzzification. A prototype of this system has been built using
the knowledge extracted from the domain expert physicians. The inference of the
system against a few available patient records at the ESI Hospital, Sealdah has
been checked. It was found to be acceptable by the verifying medical experts.",2019-09-09,2019,2019-09,medical
"Automated Blood Cell Detection and Counting via Deep Learning for
  Microfluidic Point-of-Care Medical Devices","Automated in-vitro cell detection and counting have been a key theme for
artificial and intelligent biological analysis such as biopsy, drug analysis
and decease diagnosis. Along with the rapid development of microfluidics and
lab-on-chip technologies, in-vitro live cell analysis has been one of the
critical tasks for both research and industry communities. However, it is a
great challenge to obtain and then predict the precise information of live
cells from numerous microscopic videos and images. In this paper, we
investigated in-vitro detection of white blood cells using deep neural
networks, and discussed how state-of-the-art machine learning techniques could
fulfil the needs of medical diagnosis. The approach we used in this study was
based on Faster Region-based Convolutional Neural Networks (Faster RCNNs), and
a transfer learning process was applied to apply this technique to the
microscopic detection of blood cells. Our experimental results demonstrated
that fast and efficient analysis of blood cells via automated microscopic
imaging can achieve much better accuracy and faster speed than the
conventionally applied methods, implying a promising future of this technology
to be applied to the microfluidic point-of-care medical devices.",2019-09-11,2019,2019-09,medical
Evaluating and Boosting Uncertainty Quantification in Classification,"Emergence of artificial intelligence techniques in biomedical applications
urges the researchers to pay more attention on the uncertainty quantification
(UQ) in machine-assisted medical decision making. For classification tasks,
prior studies on UQ are difficult to compare with each other, due to the lack
of a unified quantitative evaluation metric. Considering that well-performing
UQ models ought to know when the classification models act incorrectly, we
design a new evaluation metric, area under Confidence-Classification
Characteristic curves (AUCCC), to quantitatively evaluate the performance of
the UQ models. AUCCC is threshold-free, robust to perturbation, and insensitive
to the classification performance. We evaluate several UQ methods (e.g., max
softmax output) with AUCCC to validate its effectiveness. Furthermore, a simple
scheme, named Uncertainty Distillation (UDist), is developed to boost the UQ
performance, where a confidence model is distilling the confidence estimated by
deep ensembles. The proposed method is easy to implement; it consistently
outperforms strong baselines on natural and medical image datasets in our
experiments.",2019-09-13,2019,2019-09,medical
"Distributed representation of patients and its use for medical cost
  prediction","Efficient representation of patients is very important in the healthcare
domain and can help with many tasks such as medical risk prediction. Many
existing methods, such as diagnostic Cost Groups (DCG), rely on expert
knowledge to build patient representation from medical data, which is resource
consuming and non-scalable. Unsupervised machine learning algorithms are a good
choice for automating the representation learning process. However, there is
very little research focusing on onpatient-level representation learning
directly from medical claims. In this paper, weproposed a novel patient vector
learning architecture that learns high quality,fixed-length patient
representation from claims data. We conducted several experiments to test the
quality of our learned representation, and the empirical results show that our
learned patient vectors are superior to vectors learned through other methods
including a popular commercial model. Lastly, we provide potential clinical
interpretation for using our representation on predictive tasks, as
interpretability is vital in the healthcare domain",2019-09-13,2019,2019-09,medical
"Clinical Text Generation through Leveraging Medical Concept and
  Relations","With a neural sequence generation model, this study aims to develop a method
of writing the patient clinical texts given a brief medical history. As a
proof-of-a-concept, we have demonstrated that it can be workable to use medical
concept embedding in clinical text generation. Our model was based on the
Sequence-to-Sequence architecture and trained with a large set of de-identified
clinical text data. The quantitative result shows that our concept embedding
method decreased the perplexity of the baseline architecture. Also, we discuss
the analyzed results from a human evaluation performed by medical doctors.",2019-10-02,2019,2019-10,medical
Deep Semantic Segmentation of Natural and Medical Images: A Review,"The semantic image segmentation task consists of classifying each pixel of an
image into an instance, where each instance corresponds to a class. This task
is a part of the concept of scene understanding or better explaining the global
context of an image. In the medical image analysis domain, image segmentation
can be used for image-guided interventions, radiotherapy, or improved
radiological diagnostics. In this review, we categorize the leading deep
learning-based medical and non-medical image segmentation solutions into six
main groups of deep architectural, data synthesis-based, loss function-based,
sequenced models, weakly supervised, and multi-task methods and provide a
comprehensive review of the contributions in each of these groups. Further, for
each group, we analyze each variant of these groups and discuss the limitations
of the current approaches and present potential future research directions for
semantic image segmentation.",2019-10-16,2019,2019-10,medical
"NCI Workshop on Artificial Intelligence in Radiation Oncology: Training
  the Next Generation","Artificial intelligence (AI) is about to touch every aspect of radiotherapy
from consultation, treatment planning, quality assurance, therapy delivery, to
outcomes modeling. There is an urgent need to train radiation oncologists and
medical physicists in data science to help shepherd AI solutions into clinical
practice. Poorly trained personnel may do more harm than good when attempting
to apply rapidly developing and complex technologies. As the amount of AI
research expands in our field, the radiation oncology community needs to
discuss how to educate future generations in this area. The National Cancer
Institute (NCI) Workshop on AI in Radiation Oncology (Shady Grove, MD, April
4-5, 2019) was the first
(https://dctd.cancer.gov/NewsEvents/20190523_ai_in_radiation_oncology.htm) of
two data science workshops in radiation oncology hosted by the NCI in 2019.
During this workshop, the Training and Education Working Group was formed by
volunteers among the invited attendees. Its members represent radiation
oncology, medical physics, radiology, computer science, industry, and the NCI.
In this perspective article written by members of the Training and Education
Working Group, we provide and discuss Action Points relevant for future
trainees interested in radiation oncology AI: (1) creating AI awareness and
responsible conduct; (2) implementing a practical didactic curriculum; (3)
creating a publicly available database of training resources; and (4)
accelerate learning and funding opportunities. Together, these Action Points
can facilitate the translation of AI into clinical practice.",2019-10-18,2019,2019-10,medical
"CAI4CAI: The Rise of Contextual Artificial Intelligence in Computer
  Assisted Interventions","Data-driven computational approaches have evolved to enable extraction of
information from medical images with a reliability, accuracy and speed which is
already transforming their interpretation and exploitation in clinical
practice. While similar benefits are longed for in the field of interventional
imaging, this ambition is challenged by a much higher heterogeneity. Clinical
workflows within interventional suites and operating theatres are extremely
complex and typically rely on poorly integrated intra-operative devices,
sensors, and support infrastructures. Taking stock of some of the most exciting
developments in machine learning and artificial intelligence for computer
assisted interventions, we highlight the crucial need to take context and human
factors into account in order to address these challenges. Contextual
artificial intelligence for computer assisted intervention, or CAI4CAI, arises
as an emerging opportunity feeding into the broader field of surgical data
science. Central challenges being addressed in CAI4CAI include how to integrate
the ensemble of prior knowledge and instantaneous sensory information from
experts, sensors and actuators; how to create and communicate a faithful and
actionable shared representation of the surgery among a mixed human-AI actor
team; how to design interventional systems and associated cognitive shared
control schemes for online uncertainty-aware collaborative decision making
ultimately producing more precise and reliable interventions.",2019-10-20,2019,2019-10,medical
"Artificial Intelligence and the Future of Psychiatry: Qualitative
  Findings from a Global Physician Survey","The potential for machine learning to disrupt the medical profession is the
subject of ongoing debate within biomedical informatics. This study aimed to
explore psychiatrists' opinions about the potential impact of innovations in
artificial intelligence and machine learning on psychiatric practice. In Spring
2019, we conducted a web-based survey of 791 psychiatrists from 22 countries
worldwide. The survey measured opinions about the likelihood future technology
would fully replace physicians in performing ten key psychiatric tasks. This
study involved qualitative descriptive analysis of written response to three
open-ended questions in the survey. Comments were classified into four major
categories in relation to the impact of future technology on
patient-psychiatric interactions, the quality of patient medical care, the
profession of psychiatry, and health systems. Overwhelmingly, psychiatrists
were skeptical that technology could fully replace human empathy. Many
predicted that 'man and machine' would increasingly collaborate in undertaking
clinical decisions, with mixed opinions about the benefits and harms of such an
arrangement. Participants were optimistic that technology might improve
efficiencies and access to care, and reduce costs. Ethical and regulatory
considerations received limited attention. This study presents timely
information of psychiatrists' view about the scope of artificial intelligence
and machine learning on psychiatric practice. Psychiatrists expressed divergent
views about the value and impact of future technology with worrying omissions
about practice guidelines, and ethical and regulatory issues.",2019-10-22,2019,2019-10,medical
"Potential Applications of Machine Learning at Multidisciplinary Medical
  Team Meetings","While machine learning (ML) systems have produced great advances in several
domains, their use in support of complex cooperative work remains a research
challenge. A particularly challenging setting, and one that may benefit from ML
support is the work of multidisciplinary medical teams (MDTs). This paper
focuses on the activities performed during the multidisciplinary medical team
meeting (MDTM), reviewing their main characteristics in light of a longitudinal
analysis of several MDTs in a large teaching hospital over a period of ten
years and of our development of ML methods to support MDTMs, and identifying
opportunities and possible pitfalls for the use of ML to support MDTMs.",2019-11-03,2019,2019-11,medical
"Opportunities for artificial intelligence in advancing precision
  medicine","Machine learning (ML), deep learning (DL), and artificial intelligence (AI)
are of increasing importance in biomedicine. The goal of this work is to show
progress in ML in digital health, to exemplify future needs and trends, and to
identify any essential prerequisites of AI and ML for precision health.
High-throughput technologies are delivering growing volumes of biomedical data,
such as large-scale genome-wide sequencing assays, libraries of medical images,
or drug perturbation screens of healthy, developing, and diseased tissue.
Multi-omics data in biomedicine is deep and complex, offering an opportunity
for data-driven insights and automated disease classification. Learning from
these data will open our understanding and definition of healthy baselines and
disease signatures. State-of-the-art applications of deep neural networks
include digital image recognition, single cell clustering, and virtual drug
screens, demonstrating breadths and power of ML in biomedicine. Significantly,
AI and systems biology have embraced big data challenges and may enable novel
biotechnology-derived therapies to facilitate the implementation of precision
medicine approaches.",2019-11-17,2019,2019-11,medical
Medication Regimen Extraction From Medical Conversations,"Extracting relevant information from medical conversations and providing it
to doctors and patients might help in addressing doctor burnout and patient
forgetfulness. In this paper, we focus on extracting the Medication Regimen
(dosage and frequency for medications) discussed in a medical conversation. We
frame the problem as a Question Answering (QA) task and perform comparative
analysis over: a QA approach, a new combined QA and Information Extraction
approach, and other baselines. We use a small corpus of 6,692 annotated
doctor-patient conversations for the task. Clinical conversation corpora are
costly to create, difficult to handle (because of data privacy concerns), and
thus scarce. We address this data scarcity challenge through data augmentation
methods, using publicly available embeddings and pretrain part of the network
on a related task (summarization) to improve the model's performance. Compared
to the baseline, our best-performing models improve the dosage and frequency
extractions' ROUGE-1 F1 scores from 54.28 and 37.13 to 89.57 and 45.94,
respectively. Using our best-performing model, we present the first fully
automated system that can extract Medication Regimen tags from spontaneous
doctor-patient conversations with about $\approx$71% accuracy.",2019-12-10,2019,2019-12,medical
Artificial Intelligence in Surgery,"Artificial Intelligence (AI) is gradually changing the practice of surgery
with the advanced technological development of imaging, navigation and robotic
intervention. In this article, the recent successful and influential
applications of AI in surgery are reviewed from pre-operative planning and
intra-operative guidance to the integration of surgical robots. We end with
summarizing the current state, emerging trends and major challenges in the
future development of AI in surgery.",2019-12-23,2019,2019-12,medical
"Unsupervised Online Feature Selection for Cost-Sensitive Medical
  Diagnosis","In medical diagnosis, physicians predict the state of a patient by checking
measurements (features) obtained from a sequence of tests, e.g., blood test,
urine test, followed by invasive tests. As tests are often costly, one would
like to obtain only those features (tests) that can establish the presence or
absence of the state conclusively. Another aspect of medical diagnosis is that
we are often faced with unsupervised prediction tasks as the true state of the
patients may not be known. Motivated by such medical diagnosis problems, we
consider a {\it Cost-Sensitive Medical Diagnosis} (CSMD) problem, where the
true state of patients is unknown. We formulate the CSMD problem as a feature
selection problem where each test gives a feature that can be used in a
prediction model. Our objective is to learn strategies for selecting the
features that give the best trade-off between accuracy and costs. We exploit
the `Weak Dominance' property of problem to develop online algorithms that
identify a set of features which provides an `optimal' trade-off between cost
and accuracy of prediction without requiring to know the true state of the
medical condition. Our empirical results validate the performance of our
algorithms on problem instances generated from real-world datasets.",2019-12-25,2019,2019-12,medical
A New Approach for Explainable Multiple Organ Annotation with Few Data,"Despite the recent successes of deep learning, such models are still far from
some human abilities like learning from few examples, reasoning and explaining
decisions. In this paper, we focus on organ annotation in medical images and we
introduce a reasoning framework that is based on learning fuzzy relations on a
small dataset for generating explanations. Given a catalogue of relations, it
efficiently induces the most relevant relations and combines them for building
constraints in order to both solve the organ annotation task and generate
explanations. We test our approach on a publicly available dataset of medical
images where several organs are already segmented. A demonstration of our model
is proposed with an example of explained annotations. It was trained on a small
training set containing as few as a couple of examples.",2019-12-30,2019,2019-12,medical
"A Preliminary Approach for Learning Relational Policies for the
  Management of Critically Ill Children","The increased use of electronic health records has made possible the
automated extraction of medical policies from patient records to aid in the
development of clinical decision support systems. We adapted a boosted
Statistical Relational Learning (SRL) framework to learn probabilistic rules
from clinical hospital records for the management of physiologic parameters of
children with severe cardiac or respiratory failure who were managed with
extracorporeal membrane oxygenation. In this preliminary study, the results
were promising. In particular, the algorithm returned logic rules for medical
actions that are consistent with medical reasoning.",2020-01-13,2020,2020-01,medical
Practical Approach of Knowledge Management in Medical Science,"Knowledge organization, infrastructure, and knowledge-based activities are
all subjects that help in the creation of business strategies for the new
enterprise. In this paper, the first basics of knowledge-based systems are
studied. Practical issues and challenges of Knowledge Management (KM)
implementations are then illustrated. Finally, a comparison of different
knowledge-based projects is presented along with abstracted information on
their implementation, techniques, and results. Most of these projects are in
the field of medical science. Based on our study and evaluation of different KM
projects, we conclude that KM is being used in every science, industry, and
business. But its importance in medical science and assisted living projects
are highlighted nowadays with the most of research institutes. Most medical
centers are interested in using knowledge-based services like portals and
learning techniques of knowledge for their future innovations and supports.",2020-01-16,2020,2020-01,medical
"The Risk to Population Health Equity Posed by Automated Decision
  Systems: A Narrative Review","Artificial intelligence is already ubiquitous, and is increasingly being used
to autonomously make ever more consequential decisions. However, there has been
relatively little research into the existing and possible consequences for
population health equity. A narrative review was undertaken using a hermeneutic
approach to explore current and future uses of narrow AI and automated decision
systems (ADS) in medicine and public health, issues that have emerged, and
implications for equity. Accounts reveal a tremendous expectation on AI to
transform medical and public health practices. Prominent demonstrations of AI
capability - particularly in diagnostic decision making, risk prediction, and
surveillance - are stimulating rapid adoption, spurred by COVID-19. Automated
decisions being made have significant consequences for individual and
population health and wellbeing. Meanwhile, it is evident that hazards
including bias, incontestability, and privacy erosion have emerged in sensitive
domains such as criminal justice where narrow AI and ADS are in common use.
Reports of issues arising from their use in health are already appearing. As
the use of ADS in health expands, it is probable that these hazards will
manifest more widely. Bias, incontestability, and privacy erosion give rise to
mechanisms by which existing social, economic and health disparities are
perpetuated and amplified. Consequently, there is a significant risk that use
of ADS in health will exacerbate existing population health inequities. The
industrial scale and rapidity with which ADS can be applied heightens the risk
to population health equity. It is incumbent on health practitioners and policy
makers therefore to explore the potential implications of using ADS, to ensure
the use of artificial intelligence promotes population health and equity.",2020-01-18,2020,2020-01,medical
"Artificial intelligence in medicine and healthcare: a review and
  classification of current and near-future applications and their ethical and
  social Impact","This paper provides an overview of the current and near-future applications
of Artificial Intelligence (AI) in Medicine and Health Care and presents a
classification according to their ethical and societal aspects, potential
benefits and pitfalls, and issues that can be considered controversial and are
not deeply discussed in the literature.
  This work is based on an analysis of the state of the art of research and
technology, including existing software, personal monitoring devices, genetic
tests and editing tools, personalized digital models, online platforms,
augmented reality devices, and surgical and companion robotics. Motivated by
our review, we present and describe the notion of 'extended personalized
medicine', we then review existing applications of AI in medicine and
healthcare and explore the public perception of medical AI systems, and how
they show, simultaneously, extraordinary opportunities and drawbacks that even
question fundamental medical concepts. Many of these topics coincide with
urgent priorities recently defined by the World Health Organization for the
coming decade. In addition, we study the transformations of the roles of
doctors and patients in an age of ubiquitous information, identify the risk of
a division of Medicine into 'fake-based', 'patient-generated', and
'scientifically tailored', and draw the attention of some aspects that need
further thorough analysis and public debate.",2020-01-22,2020,2020-01,medical
Bayesian Networks in Healthcare: Distribution by Medical Condition,"Bayesian networks (BNs) have received increasing research attention that is
not matched by adoption in practice and yet have potential to significantly
benefit healthcare. Hitherto, research works have not investigated the types of
medical conditions being modelled with BNs, nor whether any differences exist
in how and why they are applied to different conditions. This research seeks to
identify and quantify the range of medical conditions for which
healthcare-related BN models have been proposed, and the differences in
approach between the most common medical conditions to which they have been
applied. We found that almost two-thirds of all healthcare BNs are focused on
four conditions: cardiac, cancer, psychological and lung disorders. We believe
that a lack of understanding regarding how BNs work and what they are capable
of exists, and that it is only with greater understanding and promotion that we
may ever realise the full potential of BNs to effect positive change in daily
healthcare practice.",2020-02-01,2020,2020-02,medical
"Deepfakes for Medical Video De-Identification: Privacy Protection and
  Diagnostic Information Preservation","Data sharing for medical research has been difficult as open-sourcing
clinical data may violate patient privacy. Traditional methods for face
de-identification wipe out facial information entirely, making it impossible to
analyze facial behavior. Recent advancements on whole-body keypoints detection
also rely on facial input to estimate body keypoints. Both facial and body
keypoints are critical in some medical diagnoses, and keypoints invariability
after de-identification is of great importance. Here, we propose a solution
using deepfake technology, the face swapping technique. While this swapping
method has been criticized for invading privacy and portraiture right, it could
conversely protect privacy in medical video: patients' faces could be swapped
to a proper target face and become unrecognizable. However, it remained an open
question that to what extent the swapping de-identification method could affect
the automatic detection of body keypoints. In this study, we apply deepfake
technology to Parkinson's disease examination videos to de-identify subjects,
and quantitatively show that: face-swapping as a de-identification approach is
reliable, and it keeps the keypoints almost invariant, significantly better
than traditional methods. This study proposes a pipeline for video
de-identification and keypoint preservation, clearing up some ethical
restrictions for medical data sharing. This work could make open-source high
quality medical video datasets more feasible and promote future medical
research that benefits our society.",2020-02-07,2020,2020-02,medical
Development of an Expert System for Diabetic Type-2 Diet,"A successful intelligent control of patient food for treatment purpose must
combines patient interesting food list and doctors efficient treatment food
list. Actually, many rural communities in Sudan have extremely limited access
to diabetic diet centers. People travel long distances to clinics or medical
facilities, and there is a shortage of medical experts in most of these
facilities. This results in slow service, and patients end up waiting long
hours without receiving any attention. Hence diabetic diet expert systems can
play a significant role in such cases where medical experts are not readily
available. This paper presents the design and implementation of an intelligent
medical expert system for diabetes diet that intended to be used in Sudan. The
development of the proposed expert system went through a number of stages such
problem and need identification, requirements analysis, knowledge acquisition,
formalization, design and implementation. Visual prolog was used for designing
the graphical user interface and the implementation of the system. The proposed
expert system is a promising helpful tool that reduces the workload for
physicians and provides diabetics with simple and valuable assistance.",2020-02-22,2020,2020-02,medical
FocalMix: Semi-Supervised Learning for 3D Medical Image Detection,"Applying artificial intelligence techniques in medical imaging is one of the
most promising areas in medicine. However, most of the recent success in this
area highly relies on large amounts of carefully annotated data, whereas
annotating medical images is a costly process. In this paper, we propose a
novel method, called FocalMix, which, to the best of our knowledge, is the
first to leverage recent advances in semi-supervised learning (SSL) for 3D
medical image detection. We conducted extensive experiments on two widely used
datasets for lung nodule detection, LUNA16 and NLST. Results show that our
proposed SSL methods can achieve a substantial improvement of up to 17.3% over
state-of-the-art supervised learning approaches with 400 unlabeled CT scans.",2020-03-20,2020,2020-03,medical
DAISI: Database for AI Surgical Instruction,"Telementoring surgeons as they perform surgery can be essential in the
treatment of patients when in situ expertise is not available. Nonetheless,
expert mentors are often unavailable to provide trainees with real-time medical
guidance. When mentors are unavailable, a fallback autonomous mechanism should
provide medical practitioners with the required guidance. However,
AI/autonomous mentoring in medicine has been limited by the availability of
generalizable prediction models, and surgical procedures datasets to train
those models with. This work presents the initial steps towards the development
of an intelligent artificial system for autonomous medical mentoring.
Specifically, we present the first Database for AI Surgical Instruction
(DAISI). DAISI leverages on images and instructions to provide step-by-step
demonstrations of how to perform procedures from various medical disciplines.
The dataset was acquired from real surgical procedures and data from academic
textbooks. We used DAISI to train an encoder-decoder neural network capable of
predicting medical instructions given a current view of the surgery.
Afterwards, the instructions predicted by the network were evaluated using
cumulative BLEU scores and input from expert physicians. According to the BLEU
scores, the predicted and ground truth instructions were as high as 67%
similar. Additionally, expert physicians subjectively assessed the algorithm
using Likert scale, and considered that the predicted descriptions were related
to the images. This work provides a baseline for AI algorithms to assist in
autonomous medical mentoring.",2020-03-22,2020,2020-03,medical
"From Bit To Bedside: A Practical Framework For Artificial Intelligence
  Product Development In Healthcare","Artificial Intelligence (AI) in healthcare holds great potential to expand
access to high-quality medical care, whilst reducing overall systemic costs.
Despite hitting the headlines regularly and many publications of
proofs-of-concept, certified products are failing to breakthrough to the
clinic. AI in healthcare is a multi-party process with deep knowledge required
in multiple individual domains. The lack of understanding of the specific
challenges in the domain is, therefore, the major contributor to the failure to
deliver on the big promises. Thus, we present a decision perspective framework,
for the development of AI-driven biomedical products, from conception to market
launch. Our framework highlights the risks, objectives and key results which
are typically required to proceed through a three-phase process to the market
launch of a validated medical AI product. We focus on issues related to
Clinical validation, Regulatory affairs, Data strategy and Algorithmic
development. The development process we propose for AI in healthcare software
strongly diverges from modern consumer software development processes. We
highlight the key time points to guide founders, investors and key stakeholders
throughout their relevant part of the process. Our framework should be seen as
a template for innovation frameworks, which can be used to coordinate team
communications and responsibilities towards a reasonable product development
roadmap, thus unlocking the potential of AI in medicine.",2020-03-23,2020,2020-03,medical
"Can Embeddings Adequately Represent Medical Terminology? New Large-Scale
  Medical Term Similarity Datasets Have the Answer!","A large number of embeddings trained on medical data have emerged, but it
remains unclear how well they represent medical terminology, in particular
whether the close relationship of semantically similar medical terms is encoded
in these embeddings. To date, only small datasets for testing medical term
similarity are available, not allowing to draw conclusions about the
generalisability of embeddings to the enormous amount of medical terms used by
doctors. We present multiple automatically created large-scale medical term
similarity datasets and confirm their high quality in an annotation study with
doctors. We evaluate state-of-the-art word and contextual embeddings on our new
datasets, comparing multiple vector similarity metrics and word vector
aggregation techniques. Our results show that current embeddings are limited in
their ability to adequately encode medical terms. The novel datasets thus form
a challenging new benchmark for the development of medical embeddings able to
accurately represent the whole medical terminology.",2020-03-24,2020,2020-03,medical
"Mapping the Landscape of Artificial Intelligence Applications against
  COVID-19","COVID-19, the disease caused by the SARS-CoV-2 virus, has been declared a
pandemic by the World Health Organization, which has reported over 18 million
confirmed cases as of August 5, 2020. In this review, we present an overview of
recent studies using Machine Learning and, more broadly, Artificial
Intelligence, to tackle many aspects of the COVID-19 crisis. We have identified
applications that address challenges posed by COVID-19 at different scales,
including: molecular, by identifying new or existing drugs for treatment;
clinical, by supporting diagnosis and evaluating prognosis based on medical
imaging and non-invasive measures; and societal, by tracking both the epidemic
and the accompanying infodemic using multiple data sources. We also review
datasets, tools, and resources needed to facilitate Artificial Intelligence
research, and discuss strategic considerations related to the operational
implementation of multidisciplinary partnerships and open science. We highlight
the need for international cooperation to maximize the potential of AI in this
and future pandemics.",2020-03-25,2020,2020-03,medical
"Neural translation and automated recognition of ICD10 medical entities
  from natural language","The recognition of medical entities from natural language is an ubiquitous
problem in the medical field, with applications ranging from medical act coding
to the analysis of electronic health data for public health. It is however a
complex task usually requiring human expert intervention, thus making it
expansive and time consuming. The recent advances in artificial intelligence,
specifically the raise of deep learning methods, has enabled computers to make
efficient decisions on a number of complex problems, with the notable example
of neural sequence models and their powerful applications in natural language
processing. They however require a considerable amount of data to learn from,
which is typically their main limiting factor. However, the C\'epiDc stores an
exhaustive database of death certificates at the French national scale,
amounting to several millions of natural language examples provided with their
associated human coded medical entities available to the machine learning
practitioner. This article investigates the applications of deep neural
sequence models to the medical entity recognition from natural language
problem.",2020-03-27,2020,2020-03,medical
"Modeling Rare Interactions in Time Series Data Through Qualitative
  Change: Application to Outcome Prediction in Intensive Care Units","Many areas of research are characterised by the deluge of large-scale
highly-dimensional time-series data. However, using the data available for
prediction and decision making is hampered by the current lag in our ability to
uncover and quantify true interactions that explain the outcomes.We are
interested in areas such as intensive care medicine, which are characterised by
i) continuous monitoring of multivariate variables and non-uniform sampling of
data streams, ii) the outcomes are generally governed by interactions between a
small set of rare events, iii) these interactions are not necessarily definable
by specific values (or value ranges) of a given group of variables, but rather,
by the deviations of these values from the normal state recorded over time, iv)
the need to explain the predictions made by the model. Here, while numerous
data mining models have been formulated for outcome prediction, they are unable
to explain their predictions.
  We present a model for uncovering interactions with the highest likelihood of
generating the outcomes seen from highly-dimensional time series data.
Interactions among variables are represented by a relational graph structure,
which relies on qualitative abstractions to overcome non-uniform sampling and
to capture the semantics of the interactions corresponding to the changes and
deviations from normality of variables of interest over time. Using the
assumption that similar templates of small interactions are responsible for the
outcomes (as prevalent in the medical domains), we reformulate the discovery
task to retrieve the most-likely templates from the data.",2020-04-03,2020,2020-04,medical
"Review of Artificial Intelligence Techniques in Imaging Data
  Acquisition, Segmentation and Diagnosis for COVID-19","(This paper was submitted as an invited paper to IEEE Reviews in Biomedical
Engineering on April 6, 2020.) The pandemic of coronavirus disease 2019
(COVID-19) is spreading all over the world. Medical imaging such as X-ray and
computed tomography (CT) plays an essential role in the global fight against
COVID-19, whereas the recently emerging artificial intelligence (AI)
technologies further strengthen the power of the imaging tools and help medical
specialists. We hereby review the rapid responses in the community of medical
imaging (empowered by AI) toward COVID-19. For example, AI-empowered image
acquisition can significantly help automate the scanning procedure and also
reshape the workflow with minimal contact to patients, providing the best
protection to the imaging technicians. Also, AI can improve work efficiency by
accurate delination of infections in X-ray and CT images, facilitating
subsequent quantification. Moreover, the computer-aided platforms help
radiologists make clinical decisions, i.e., for disease diagnosis, tracking,
and prognosis. In this review paper, we thus cover the entire pipeline of
medical imaging and analysis techniques involved with COVID-19, including image
acquisition, segmentation, diagnosis, and follow-up. We particularly focus on
the integration of AI with X-ray and CT, both of which are widely used in the
frontline hospitals, in order to depict the latest progress of medical imaging
and radiology fighting against COVID-19.",2020-04-06,2020,2020-04,medical
MedDialog: Two Large-scale Medical Dialogue Datasets,"Medical dialogue systems are promising in assisting in telemedicine to
increase access to healthcare services, improve the quality of patient care,
and reduce medical costs. To facilitate the research and development of medical
dialogue systems, we build two large-scale medical dialogue datasets:
MedDialog-EN and MedDialog-CN. MedDialog-EN is an English dataset containing
0.3 million conversations between patients and doctors and 0.5 million
utterances. MedDialog-CN is an Chinese dataset containing 1.1 million
conversations and 4 million utterances. To our best knowledge,
MedDialog-(EN,CN) are the largest medical dialogue datasets to date. The
dataset is available at https://github.com/UCSD-AI4H/Medical-Dialogue-System",2020-04-07,2020,2020-04,medical
"Detecting fake news for the new coronavirus by reasoning on the Covid-19
  ontology","In the context of the Covid-19 pandemic, many were quick to spread deceptive
information. I investigate here how reasoning in Description Logics (DLs) can
detect inconsistencies between trusted medical sources and not trusted ones.
The not-trusted information comes in natural language (e.g. ""Covid-19 affects
only the elderly""). To automatically convert into DLs, I used the FRED
converter. Reasoning in Description Logics is then performed with the Racer
tool.",2020-04-26,2020,2020-04,medical
"Unifying Neural Learning and Symbolic Reasoning for Spinal Medical
  Report Generation","Automated medical report generation in spine radiology, i.e., given spinal
medical images and directly create radiologist-level diagnosis reports to
support clinical decision making, is a novel yet fundamental study in the
domain of artificial intelligence in healthcare. However, it is incredibly
challenging because it is an extremely complicated task that involves visual
perception and high-level reasoning processes. In this paper, we propose the
neural-symbolic learning (NSL) framework that performs human-like learning by
unifying deep neural learning and symbolic logical reasoning for the spinal
medical report generation. Generally speaking, the NSL framework firstly
employs deep neural learning to imitate human visual perception for detecting
abnormalities of target spinal structures. Concretely, we design an adversarial
graph network that interpolates a symbolic graph reasoning module into a
generative adversarial network through embedding prior domain knowledge,
achieving semantic segmentation of spinal structures with high complexity and
variability. NSL secondly conducts human-like symbolic logical reasoning that
realizes unsupervised causal effect analysis of detected entities of
abnormalities through meta-interpretive learning. NSL finally fills these
discoveries of target diseases into a unified template, successfully achieving
a comprehensive medical report generation. When it employed in a real-world
clinical dataset, a series of empirical studies demonstrate its capacity on
spinal medical report generation as well as show that our algorithm remarkably
exceeds existing methods in the detection of spinal structures. These indicate
its potential as a clinical tool that contributes to computer-aided diagnosis.",2020-04-28,2020,2020-04,medical
"Automated Question Answer medical model based on Deep Learning
  Technology","Artificial intelligence can now provide more solutions for different
problems, especially in the medical field. One of those problems the lack of
answers to any given medical/health-related question. The Internet is full of
forums that allow people to ask some specific questions and get great answers
for them. Nevertheless, browsing these questions in order to locate one similar
to your own, also finding a satisfactory answer is a difficult and
time-consuming task. This research will introduce a solution to this problem by
automating the process of generating qualified answers to these questions and
creating a kind of digital doctor. Furthermore, this research will train an
end-to-end model using the framework of RNN and the encoder-decoder to generate
sensible and useful answers to a small set of medical/health issues. The
proposed model was trained and evaluated using data from various online
services, such as WebMD, HealthTap, eHealthForums, and iCliniq.",2020-05-21,2020,2020-05,medical
"Scoring and Assessment in Medical VR Training Simulators with Dynamic
  Time Series Classification","This research proposes and evaluates scoring and assessment methods for
Virtual Reality (VR) training simulators. VR simulators capture detailed
n-dimensional human motion data which is useful for performance analysis.
Custom made medical haptic VR training simulators were developed and used to
record data from 271 trainees of multiple clinical experience levels. DTW
Multivariate Prototyping (DTW-MP) is proposed. VR data was classified as
Novice, Intermediate or Expert. Accuracy of algorithms applied for time-series
classification were: dynamic time warping 1-nearest neighbor (DTW-1NN) 60%,
nearest centroid SoftDTW classification 77.5%, Deep Learning: ResNet 85%, FCN
75%, CNN 72.5% and MCDCNN 28.5%. Expert VR data recordings can be used for
guidance of novices. Assessment feedback can help trainees to improve skills
and consistency. Motion analysis can identify different techniques used by
individuals. Mistakes can be detected dynamically in real-time, raising alarms
to prevent injuries.",2020-06-11,2020,2020-06,medical
"HMIC: Hierarchical Medical Image Classification, A Deep Learning
  Approach","Image classification is central to the big data revolution in medicine.
Improved information processing methods for diagnosis and classification of
digital medical images have shown to be successful via deep learning
approaches. As this field is explored, there are limitations to the performance
of traditional supervised classifiers. This paper outlines an approach that is
different from the current medical image classification tasks that view the
issue as multi-class classification. We performed a hierarchical classification
using our Hierarchical Medical Image classification (HMIC) approach. HMIC uses
stacks of deep learning models to give particular comprehension at each level
of the clinical picture hierarchy. For testing our performance, we use biopsy
of the small bowel images that contain three categories in the parent level
(Celiac Disease, Environmental Enteropathy, and histologically normal
controls). For the child level, Celiac Disease Severity is classified into 4
classes (I, IIIa, IIIb, and IIIC).",2020-06-12,2020,2020-06,medical
"The Threats of Artificial Intelligence Scale (TAI). Development,
  Measurement and Test Over Three Application Domains","In recent years Artificial Intelligence (AI) has gained much popularity, with
the scientific community as well as with the public. AI is often ascribed many
positive impacts for different social domains such as medicine and the economy.
On the other side, there is also growing concern about its precarious impact on
society and individuals. Several opinion polls frequently query the public fear
of autonomous robots and artificial intelligence (FARAI), a phenomenon coming
also into scholarly focus. As potential threat perceptions arguably vary with
regard to the reach and consequences of AI functionalities and the domain of
application, research still lacks necessary precision of a respective
measurement that allows for wide-spread research applicability. We propose a
fine-grained scale to measure threat perceptions of AI that accounts for four
functional classes of AI systems and is applicable to various domains of AI
applications. Using a standardized questionnaire in a survey study (N=891), we
evaluate the scale over three distinct AI domains (loan origination, job
recruitment and medical treatment). The data support the dimensional structure
of the proposed Threats of AI (TAI) scale as well as the internal consistency
and factoral validity of the indicators. Implications of the results and the
empirical application of the scale are discussed in detail. Recommendations for
further empirical use of the TAI scale are provided.",2020-06-12,2020,2020-06,medical
Medical idioms for clinical Bayesian network development,"Bayesian Networks (BNs) are graphical probabilistic models that have proven
popular in medical applications. While numerous medical BNs have been
published, most are presented fait accompli without explanation of how the
network structure was developed or justification of why it represents the
correct structure for the given medical application. This means that the
process of building medical BNs from experts is typically ad hoc and offers
little opportunity for methodological improvement. This paper proposes
generally applicable and reusable medical reasoning patterns to aid those
developing medical BNs. The proposed method complements and extends the
idiom-based approach introduced by Neil, Fenton, and Nielsen in 2000. We
propose instances of their generic idioms that are specific to medical BNs. We
refer to the proposed medical reasoning patterns as medical idioms. In
addition, we extend the use of idioms to represent interventional and
counterfactual reasoning. We believe that the proposed medical idioms are
logical reasoning patterns that can be combined, reused and applied generically
to help develop medical BNs. All proposed medical idioms have been illustrated
using medical examples on coronary artery disease. The method has also been
applied to other ongoing BNs being developed with medical experts. Finally, we
show that applying the proposed medical idioms to published BN models results
in models with a clearer structure.",2020-07-01,2020,2020-07,medical
"Automatic Detection and Classification of Waste Consumer Medications for
  Proper Management and Disposal","Every year, millions of pounds of medicines remain unused in the U.S. and are
subject to an in-home disposal, i.e., kept in medicine cabinets, flushed in
toilet or thrown in regular trash. In-home disposal, however, can negatively
impact the environment and public health. The drug take-back programs (drug
take-backs) sponsored by the Drug Enforcement Administration (DEA) and its
state and industry partners collect unused consumer medications and provide the
best alternative to in-home disposal of medicines. However, the drug take-backs
are expensive to operate and not widely available. In this paper, we show that
artificial intelligence (AI) can be applied to drug take-backs to render them
operationally more efficient. Since identification of any waste is crucial to a
proper disposal, we showed that it is possible to accurately identify loose
consumer medications solely based on the physical features and visual
appearance. We have developed an automatic technique that uses deep neural
networks and computer vision to identify and segregate solid medicines. We
applied the technique to images of about one thousand loose pills and succeeded
in correctly identifying the pills with an accuracy of 0.912 and top-5 accuracy
of 0.984. We also showed that hazardous pills could be distinguished from
non-hazardous pills within the dataset with an accuracy of 0.984. We believe
that the power of artificial intelligence could be harnessed in products that
would facilitate the operation of the drug take-backs more efficiently and help
them become widely available throughout the country.",2020-07-27,2020,2020-07,medical
Ethics of Artificial Intelligence in Surgery,"Here we discuss the four key principles of bio-medical ethics from surgical
context. We elaborate on the definition of 'fairness' and its implications in
AI system design, with taxonomy of algorithmic biases in AI. We discuss the
shifts in ethical paradigms as the degree of autonomy in AI systems continue to
evolve. We also emphasize the need for continuous revisions of ethics in AI due
to evolution and dynamic nature of AI systems and technologies.",2020-07-28,2020,2020-07,medical
"A review of deep learning in medical imaging: Imaging traits, technology
  trends, case studies with progress highlights, and future promises","Since its renaissance, deep learning has been widely used in various medical
imaging tasks and has achieved remarkable success in many medical imaging
applications, thereby propelling us into the so-called artificial intelligence
(AI) era. It is known that the success of AI is mostly attributed to the
availability of big data with annotations for a single task and the advances in
high performance computing. However, medical imaging presents unique challenges
that confront deep learning approaches. In this survey paper, we first present
traits of medical imaging, highlight both clinical needs and technical
challenges in medical imaging, and describe how emerging trends in deep
learning are addressing these issues. We cover the topics of network
architecture, sparse and noisy labels, federating learning, interpretability,
uncertainty quantification, etc. Then, we present several case studies that are
commonly found in clinical practice, including digital pathology and chest,
brain, cardiovascular, and abdominal imaging. Rather than presenting an
exhaustive literature survey, we instead describe some prominent research
highlights related to these case study applications. We conclude with a
discussion and presentation of promising future directions.",2020-08-02,2020,2020-08,medical
"High performance on-demand de-identification of a petabyte-scale medical
  imaging data lake","With the increase in Artificial Intelligence driven approaches, researchers
are requesting unprecedented volumes of medical imaging data which far exceed
the capacity of traditional on-premise client-server approaches for making the
data research analysis-ready. We are making available a flexible solution for
on-demand de-identification that combines the use of mature software
technologies with modern cloud-based distributed computing techniques to enable
faster turnaround in medical imaging research. The solution is part of a
broader platform that supports a secure high performance clinical data science
platform.",2020-08-04,2020,2020-08,medical
"ExplAIn: Explanatory Artificial Intelligence for Diabetic Retinopathy
  Diagnosis","In recent years, Artificial Intelligence (AI) has proven its relevance for
medical decision support. However, the ""black-box"" nature of successful AI
algorithms still holds back their wide-spread deployment. In this paper, we
describe an eXplanatory Artificial Intelligence (XAI) that reaches the same
level of performance as black-box AI, for the task of classifying Diabetic
Retinopathy (DR) severity using Color Fundus Photography (CFP). This algorithm,
called ExplAIn, learns to segment and categorize lesions in images; the final
image-level classification directly derives from these multivariate lesion
segmentations. The novelty of this explanatory framework is that it is trained
from end to end, with image supervision only, just like black-box AI
algorithms: the concepts of lesions and lesion categories emerge by themselves.
For improved lesion localization, foreground/background separation is trained
through self-supervision, in such a way that occluding foreground pixels
transforms the input image into a healthy-looking image. The advantage of such
an architecture is that automatic diagnoses can be explained simply by an image
and/or a few sentences. ExplAIn is evaluated at the image level and at the
pixel level on various CFP image datasets. We expect this new framework, which
jointly offers high classification performance and explainability, to
facilitate AI deployment.",2020-08-13,2020,2020-08,medical
Survey of XAI in digital pathology,"Artificial intelligence (AI) has shown great promise for diagnostic imaging
assessments. However, the application of AI to support medical diagnostics in
clinical routine comes with many challenges. The algorithms should have high
prediction accuracy but also be transparent, understandable and reliable. Thus,
explainable artificial intelligence (XAI) is highly relevant for this domain.
We present a survey on XAI within digital pathology, a medical imaging
sub-discipline with particular characteristics and needs. The review includes
several contributions. Firstly, we give a thorough overview of current XAI
techniques of potential relevance for deep learning methods in pathology
imaging, and categorise them from three different aspects. In doing so, we
incorporate uncertainty estimation methods as an integral part of the XAI
landscape. We also connect the technical methods to the specific prerequisites
in digital pathology and present findings to guide future research efforts. The
survey is intended for both technical researchers and medical professionals,
one of the objectives being to establish a common ground for cross-disciplinary
discussions.",2020-08-14,2020,2020-08,medical
"Trust and Medical AI: The challenges we face and the expertise needed to
  overcome them","Artificial intelligence (AI) is increasingly of tremendous interest in the
medical field. However, failures of medical AI could have serious consequences
for both clinical outcomes and the patient experience. These consequences could
erode public trust in AI, which could in turn undermine trust in our healthcare
institutions. This article makes two contributions. First, it describes the
major conceptual, technical, and humanistic challenges in medical AI. Second,
it proposes a solution that hinges on the education and accreditation of new
expert groups who specialize in the development, verification, and operation of
medical AI technologies. These groups will be required to maintain trust in our
healthcare institutions.",2020-08-18,2020,2020-08,medical
"Patient ADE Risk Prediction through Hierarchical Time-Aware Neural
  Network Using Claim Codes","Adverse drug events (ADEs) are a serious health problem that can be
life-threatening. While a lot of studies have been performed on detect
correlation between a drug and an AE, limited studies have been conducted on
personalized ADE risk prediction. Among treatment alternatives, avoiding the
drug that has high likelihood of causing severe AE can help physicians to
provide safer treatment to patients. Existing work on personalized ADE risk
prediction uses the information obtained in the current medical visit. However,
on the other hand, medical history reveals each patient's unique
characteristics and comprehensive medical information. The goal of this study
is to assess personalized ADE risks that a target drug may induce on a target
patient, based on patient medical history recorded in claims codes, which
provide information about diagnosis, drugs taken, related medical supplies
besides billing information. We developed a HTNNR model (Hierarchical
Time-aware Neural Network for ADE Risk) that capture characteristics of claim
codes and their relationship. The empirical evaluation show that the proposed
HTNNR model substantially outperforms the comparison methods, especially for
rare drugs.",2020-08-20,2020,2020-08,medical
"Knowledge-Empowered Representation Learning for Chinese Medical Reading
  Comprehension: Task, Model and Resources","Machine Reading Comprehension (MRC) aims to extract answers to questions
given a passage. It has been widely studied recently, especially in open
domains. However, few efforts have been made on closed-domain MRC, mainly due
to the lack of large-scale training data. In this paper, we introduce a
multi-target MRC task for the medical domain, whose goal is to predict answers
to medical questions and the corresponding support sentences from medical
information sources simultaneously, in order to ensure the high reliability of
medical knowledge serving. A high-quality dataset is manually constructed for
the purpose, named Multi-task Chinese Medical MRC dataset (CMedMRC), with
detailed analysis conducted. We further propose the Chinese medical BERT model
for the task (CMedBERT), which fuses medical knowledge into pre-trained
language models by the dynamic fusion mechanism of heterogeneous features and
the multi-task learning strategy. Experiments show that CMedBERT consistently
outperforms strong baselines by fusing context-aware and knowledge-aware token
representations.",2020-08-24,2020,2020-08,medical
"Receptivity of an AI Cognitive Assistant by the Radiology Community: A
  Report on Data Collected at RSNA","Due to advances in machine learning and artificial intelligence (AI), a new
role is emerging for machines as intelligent assistants to radiologists in
their clinical workflows. But what systematic clinical thought processes are
these machines using? Are they similar enough to those of radiologists to be
trusted as assistants? A live demonstration of such a technology was conducted
at the 2016 Scientific Assembly and Annual Meeting of the Radiological Society
of North America (RSNA). The demonstration was presented in the form of a
question-answering system that took a radiology multiple choice question and a
medical image as inputs. The AI system then demonstrated a cognitive workflow,
involving text analysis, image analysis, and reasoning, to process the question
and generate the most probable answer. A post demonstration survey was made
available to the participants who experienced the demo and tested the question
answering system. Of the reported 54,037 meeting registrants, 2,927 visited the
demonstration booth, 1,991 experienced the demo, and 1,025 completed a
post-demonstration survey. In this paper, the methodology of the survey is
shown and a summary of its results are presented. The results of the survey
show a very high level of receptiveness to cognitive computing technology and
artificial intelligence among radiologists.",2020-09-13,2020,2020-09,medical
"Focused Clinical Query Understanding and Retrieval of Medical Snippets
  powered through a Healthcare Knowledge Graph","Clinicians face several significant barriers to search and synthesize
accurate, succinct, updated, and trustworthy medical information from several
literature sources during the practice of medicine and patient care. In this
talk, we will be presenting our research behind the development of a Focused
Clinical Search Service, powered by a Healthcare Knowledge Graph, to interpret
the query intent behind clinical search queries and retrieve relevant medical
snippets from a diverse corpus of medical literature.",2020-09-17,2020,2020-09,medical
"Dr. Summarize: Global Summarization of Medical Dialogue by Exploiting
  Local Structures","Understanding a medical conversation between a patient and a physician poses
a unique natural language understanding challenge since it combines elements of
standard open ended conversation with very domain specific elements that
require expertise and medical knowledge. Summarization of medical conversations
is a particularly important aspect of medical conversation understanding since
it addresses a very real need in medical practice: capturing the most important
aspects of a medical encounter so that they can be used for medical decision
making and subsequent follow ups.
  In this paper we present a novel approach to medical conversation
summarization that leverages the unique and independent local structures
created when gathering a patient's medical history. Our approach is a variation
of the pointer generator network where we introduce a penalty on the generator
distribution, and we explicitly model negations. The model also captures
important properties of medical conversations such as medical knowledge coming
from standardized medical ontologies better than when those concepts are
introduced explicitly. Through evaluation by doctors, we show that our approach
is preferred on twice the number of summaries to the baseline pointer generator
model and captures most or all of the information in 80% of the conversations
making it a realistic alternative to costly manual summarization by medical
experts.",2020-09-18,2020,2020-09,medical
"Basic principles and concept design of a real-time clinical decision
  support system for managing medical emergencies on missions to Mars","Space agencies and private companies prepare the beginning of human space
exploration for the 2030s with missions to put the first human on the Mars
surface. The absence of gravity and radiation, along with distance, isolation
and hostile environments, are expected to increase medical events where
previously unseen manifestations may arise. The current healthcare strategy
based on telemedicine and the possibility to stabilize and transport the
injured crewmember to a terrestrial definitive medical facility is not
applicable in exploration class missions. Therefore, the need for deploying the
full autonomous capability to solve medical emergencies may guide the design of
future onboard healthcare systems. We present ten basic principles and concept
design of a software suite to bring onboard decision support to help the crew
dealing with medical emergencies taking into consideration physiological
disturbances in space and spaceflight restrictions. 1) give real-time support
for emergency medical decision making, 2) give patient-specific advice for
executive problem-solving, 3) take into account available information from life
support and monitoring of crewmembers, 4) be fully autonomous from remote
facilities, 5) continuously adapt predictions to physiological disturbance and
changing conditions, 6) optimize emergency medical decision making in terms of
mission fundamental priorities, 7) take into account medical supplies and
equipment on board, 8) apply health standards for the level of care V, 9)
implement ethics responsibilities for spaceflights, and 10) apply ethical
standards for artificial intelligence. Based on these principles, we propose an
autonomous clinical decision support system (CDSS) to provide real-time advice
for emergency medical interventions on board of space exploration missions.",2020-09-29,2020,2020-09,medical
CAD Applications and Emerging Research Potential in Medical Imaging,"Computer Aided Detection (CAD) is a valuable technique for precisely
interpreting medical images and it has a global business opportunity of about
USD 1.8 billion. The current aspects with reference to the four sub stages such
as image pre-processing, segmentation, feature extraction and classification
and the future scope of CAD in medical imaging has been discussed in this
paper. Many reviewers have emphasized the need for synergy between engineers
and medical professionals for successful development of CAD systems and the
current work is a move in that direction. The engineering aspects of the above
four stages in four imaging modalities viz. computed tomography, magnetic
resonance imaging, mammography and bone scintigraphy used in the diagnosis of
five critical diseases have been discussed with a clinical background.
Automatic classification of image can play an important role in preliminary
screening of very critical ailments bringing down the cost of health care.
Another recent advancement is using artificial intelligence and machine
learning techniques. This paper reviews these engineering aspects with a view
to explore the opportunities to researchers as well as the medical industry to
offer affordable medical services with accessibility in even remote locations.",2020-09-30,2020,2020-09,medical
"Artificial intelligence supported anemia control system (AISACS) to
  prevent anemia in maintenance hemodialysis patients","Anemia, for which erythropoiesis-stimulating agents (ESAs) and iron
supplements (ISs) are used as preventive measures, presents important
difficulties for hemodialysis patients. Nevertheless, the number of physicians
able to manage such medications appropriately is not keeping pace with the
rapid increase of hemodialysis patients. Moreover, the high cost of ESAs
imposes heavy burdens on medical insurance systems. An
artificial-intelligence-supported anemia control system (AISACS) trained using
administration direction data from experienced physicians has been developed by
the authors. For the system, appropriate data selection and rectification
techniques play important roles. Decision making related to ESAs poses a
multi-class classification problem for which a two-step classification
technique is introduced. Several validations have demonstrated that AISACS
exhibits high performance with correct classification rates of 72-87% and
clinically appropriate classification rates of 92-98%.",2020-10-06,2020,2020-10,medical
Characterizing the Value of Information in Medical Notes,"Machine learning models depend on the quality of input data. As electronic
health records are widely adopted, the amount of data in health care is
growing, along with complaints about the quality of medical notes. We use two
prediction tasks, readmission prediction and in-hospital mortality prediction,
to characterize the value of information in medical notes. We show that as a
whole, medical notes only provide additional predictive power over structured
information in readmission prediction. We further propose a probing framework
to select parts of notes that enable more accurate predictions than using all
notes, despite that the selected information leads to a distribution shift from
the training data (""all notes""). Finally, we demonstrate that models trained on
the selected valuable information achieve even better predictive performance,
with only 6.8% of all the tokens for readmission prediction.",2020-10-07,2020,2020-10,medical
OnRAMP for Regulating AI in Medical Products,"Medical Artificial Intelligence (AI) involves the application of machine
learning algorithms to biomedical datasets in order to improve medical
practices. Products incorporating medical AI require certification before
deployment in most jurisdictions. To date, clear pathways for regulating
medical AI are still under development. Below the level of formal pathways lies
the actual practice of developing a medical AI solution. This Perspective
proposes best practice guidelines for development compatible with the
production of a regulatory package which, regardless of the formal regulatory
path, will form a core component of a certification process. The approach is
predicated on a statistical risk perspective, typical of medical device
regulators, and a deep understanding of machine learning methodologies. These
guidelines will allow all parties to communicate more clearly in the
development of a common Good Machine Learning Practice (GMLP), and thus lead to
the enhanced development of both medical AI products and regulations.",2020-10-09,2020,2020-10,medical
"MedDG: An Entity-Centric Medical Consultation Dataset for Entity-Aware
  Medical Dialogue Generation","Developing conversational agents to interact with patients and provide
primary clinical advice has attracted increasing attention due to its huge
application potential, especially in the time of COVID-19 Pandemic. However,
the training of end-to-end neural-based medical dialogue system is restricted
by an insufficient quantity of medical dialogue corpus. In this work, we make
the first attempt to build and release a large-scale high-quality Medical
Dialogue dataset related to 12 types of common Gastrointestinal diseases named
MedDG, with more than 17K conversations collected from the online health
consultation community. Five different categories of entities, including
diseases, symptoms, attributes, tests, and medicines, are annotated in each
conversation of MedDG as additional labels. To push forward the future research
on building expert-sensitive medical dialogue system, we proposes two kinds of
medical dialogue tasks based on MedDG dataset. One is the next entity
prediction and the other is the doctor response generation. To acquire a clear
comprehension on these two medical dialogue tasks, we implement several
state-of-the-art benchmarks, as well as design two dialogue models with a
further consideration on the predicted entities. Experimental results show that
the pre-train language models and other baselines struggle on both tasks with
poor performance in our dataset, and the response quality can be enhanced with
the help of auxiliary entity information. From human evaluation, the simple
retrieval model outperforms several state-of-the-art generative models,
indicating that there still remains a large room for improvement on generating
medically meaningful responses.",2020-10-15,2020,2020-10,medical
"Interpretable Disease Prediction based on Reinforcement Path Reasoning
  over Knowledge Graphs","Objective: To combine medical knowledge and medical data to interpretably
predict the risk of disease. Methods: We formulated the disease prediction task
as a random walk along a knowledge graph (KG). Specifically, we build a KG to
record relationships between diseases and risk factors according to validated
medical knowledge. Then, a mathematical object walks along the KG. It starts
walking at a patient entity, which connects the KG based on the patient current
diseases or risk factors and stops at a disease entity, which represents the
predicted disease. The trajectory generated by the object represents an
interpretable disease progression path of the given patient. The dynamics of
the object are controlled by a policy-based reinforcement learning (RL) module,
which is trained by electronic health records (EHRs). Experiments: We utilized
two real-world EHR datasets to evaluate the performance of our model. In the
disease prediction task, our model achieves 0.743 and 0.639 in terms of macro
area under the curve (AUC) in predicting 53 circulation system diseases in the
two datasets, respectively. This performance is comparable to the commonly used
machine learning (ML) models in medical research. In qualitative analysis, our
clinical collaborator reviewed the disease progression paths generated by our
model and advocated their interpretability and reliability. Conclusion:
Experimental results validate the proposed model in interpretably evaluating
and optimizing disease prediction. Significance: Our work contributes to
leveraging the potential of medical knowledge and medical data jointly for
interpretable prediction tasks.",2020-10-16,2020,2020-10,medical
"A Survey on Deep Learning and Explainability for Automatic Report
  Generation from Medical Images","Every year physicians face an increasing demand of image-based diagnosis from
patients, a problem that can be addressed with recent artificial intelligence
methods. In this context, we survey works in the area of automatic report
generation from medical images, with emphasis on methods using deep neural
networks, with respect to: (1) Datasets, (2) Architecture Design, (3)
Explainability and (4) Evaluation Metrics. Our survey identifies interesting
developments, but also remaining challenges. Among them, the current evaluation
of generated reports is especially weak, since it mostly relies on traditional
Natural Language Processing (NLP) metrics, which do not accurately capture
medical correctness.",2020-10-20,2020,2020-10,medical
"Explaining black-box text classifiers for disease-treatment information
  extraction","Deep neural networks and other intricate Artificial Intelligence (AI) models
have reached high levels of accuracy on many biomedical natural language
processing tasks. However, their applicability in real-world use cases may be
limited due to their vague inner working and decision logic. A post-hoc
explanation method can approximate the behavior of a black-box AI model by
extracting relationships between feature values and outcomes. In this paper, we
introduce a post-hoc explanation method that utilizes confident itemsets to
approximate the behavior of black-box classifiers for medical information
extraction. Incorporating medical concepts and semantics into the explanation
process, our explanator finds semantic relations between inputs and outputs in
different parts of the decision space of a black-box classifier. The
experimental results show that our explanation method can outperform
perturbation and decision set based explanators in terms of fidelity and
interpretability of explanations produced for predictions on a
disease-treatment information extraction task.",2020-10-21,2020,2020-10,medical
"MedMNIST Classification Decathlon: A Lightweight AutoML Benchmark for
  Medical Image Analysis","We present MedMNIST, a collection of 10 pre-processed medical open datasets.
MedMNIST is standardized to perform classification tasks on lightweight 28x28
images, which requires no background knowledge. Covering the primary data
modalities in medical image analysis, it is diverse on data scale (from 100 to
100,000) and tasks (binary/multi-class, ordinal regression and multi-label).
MedMNIST could be used for educational purpose, rapid prototyping, multi-modal
machine learning or AutoML in medical image analysis. Moreover, MedMNIST
Classification Decathlon is designed to benchmark AutoML algorithms on all 10
datasets; We have compared several baseline methods, including open-source or
commercial AutoML tools. The datasets, evaluation code and baseline methods for
MedMNIST are publicly available at https://medmnist.github.io/.",2020-10-28,2020,2020-10,medical
Photonics for artificial intelligence and neuromorphic computing,"Research in photonic computing has flourished due to the proliferation of
optoelectronic components on photonic integration platforms. Photonic
integrated circuits have enabled ultrafast artificial neural networks,
providing a framework for a new class of information processing machines.
Algorithms running on such hardware have the potential to address the growing
demand for machine learning and artificial intelligence, in areas such as
medical diagnosis, telecommunications, and high-performance and scientific
computing. In parallel, the development of neuromorphic electronics has
highlighted challenges in that domain, in particular, related to processor
latency. Neuromorphic photonics offers sub-nanosecond latencies, providing a
complementary opportunity to extend the domain of artificial intelligence.
Here, we review recent advances in integrated photonic neuromorphic systems,
discuss current and future challenges, and outline the advances in science and
technology needed to meet those challenges.",2020-10-30,2020,2020-10,medical
Explainable AI meets Healthcare: A Study on Heart Disease Dataset,"With the increasing availability of structured and unstructured data and the
swift progress of analytical techniques, Artificial Intelligence (AI) is
bringing a revolution to the healthcare industry. With the increasingly
indispensable role of AI in healthcare, there are growing concerns over the
lack of transparency and explainability in addition to potential bias
encountered by predictions of the model. This is where Explainable Artificial
Intelligence (XAI) comes into the picture. XAI increases the trust placed in an
AI system by medical practitioners as well as AI researchers, and thus,
eventually, leads to an increasingly widespread deployment of AI in healthcare.
  In this paper, we present different interpretability techniques. The aim is
to enlighten practitioners on the understandability and interpretability of
explainable AI systems using a variety of techniques available which can be
very advantageous in the health-care domain. Medical diagnosis model is
responsible for human life and we need to be confident enough to treat a
patient as instructed by a black-box model. Our paper contains examples based
on the heart disease dataset and elucidates on how the explainability
techniques should be preferred to create trustworthiness while using AI systems
in healthcare.",2020-11-06,2020,2020-11,medical
"Improving Clinical Outcome Predictions Using Convolution over Medical
  Entities with Multimodal Learning","Early prediction of mortality and length of stay(LOS) of a patient is vital
for saving a patient's life and management of hospital resources. Availability
of electronic health records(EHR) makes a huge impact on the healthcare domain
and there has seen several works on predicting clinical problems. However, many
studies did not benefit from the clinical notes because of the sparse, and high
dimensional nature. In this work, we extract medical entities from clinical
notes and use them as additional features besides time-series features to
improve our predictions. We propose a convolution based multimodal
architecture, which not only learns effectively combining medical entities and
time-series ICU signals of patients, but also allows us to compare the effect
of different embedding techniques such as Word2vec, FastText on medical
entities. In the experiments, our proposed method robustly outperforms all
other baseline models including different multimodal architectures for all
clinical tasks. The code for the proposed method is available at
https://github.com/tanlab/ConvolutionMedicalNer.",2020-11-24,2020,2020-11,medical
"Artificial Intelligence for COVID-19 Detection -- A state-of-the-art
  review","The emergence of COVID-19 has necessitated many efforts by the scientific
community for its proper management. An urgent clinical reaction is required in
the face of the unending devastation being caused by the pandemic. These
efforts include technological innovations for improvement in screening,
treatment, vaccine development, contact tracing and, survival prediction. The
use of Deep Learning (DL) and Artificial Intelligence (AI) can be sought in all
of the above-mentioned spheres. This paper aims to review the role of Deep
Learning and Artificial intelligence in various aspects of the overall COVID-19
management and particularly for COVID-19 detection and classification. The DL
models are developed to analyze clinical modalities like CT scans and X-Ray
images of patients and predict their pathological condition. A DL model aims to
detect the COVID-19 pneumonia, classify and distinguish between COVID-19,
Community-Acquired Pneumonia (CAP), Viral and Bacterial pneumonia, and normal
conditions. Furthermore, sophisticated models can be built to segment the
affected area in the lungs and quantify the infection volume for a better
understanding of the extent of damage. Many models have been developed either
independently or with the help of pre-trained models like VGG19, ResNet50, and
AlexNet leveraging the concept of transfer learning. Apart from model
development, data preprocessing and augmentation are also performed to cope
with the challenge of insufficient data samples often encountered in medical
applications. It can be evaluated that DL and AI can be effectively implemented
to withstand the challenges posed by the global emergency",2020-11-25,2020,2020-11,medical
"Transfer learning to enhance amenorrhea status prediction in cancer and
  fertility data with missing values","Collecting sufficient labelled training data for health and medical problems
is difficult (Antropova, et al., 2018). Also, missing values are unavoidable in
health and medical datasets and tackling the problem arising from the
inadequate instances and missingness is not straightforward (Snell, et al.
2017, Sterne, et al. 2009). However, machine learning algorithms have achieved
significant success in many real-world healthcare problems, such as regression
and classification and these techniques could possibly be a way to resolve the
issues.",2020-12-01,2020,2020-12,medical
Privacy-preserving medical image analysis,"The utilisation of artificial intelligence in medicine and healthcare has led
to successful clinical applications in several domains. The conflict between
data usage and privacy protection requirements in such systems must be resolved
for optimal results as well as ethical and legal compliance. This calls for
innovative solutions such as privacy-preserving machine learning (PPML). We
present PriMIA (Privacy-preserving Medical Image Analysis), a software
framework designed for PPML in medical imaging. In a real-life case study we
demonstrate significantly better classification performance of a securely
aggregated federated learning model compared to human experts on unseen
datasets. Furthermore, we show an inference-as-a-service scenario for
end-to-end encrypted diagnosis, where neither the data nor the model are
revealed. Lastly, we empirically evaluate the framework's security against a
gradient-based model inversion attack and demonstrate that no usable
information can be recovered from the model.",2020-12-10,2020,2020-12,medical
"Hospital Capacity Planning Using Discrete Event Simulation Under Special
  Consideration of the COVID-19 Pandemic","We present a resource-planning tool for hospitals under special consideration
of the COVID-19 pandemic, called babsim.hospital. It provides many advantages
for crisis teams, e.g., comparison with their own local planning, simulation of
local events, simulation of several scenarios (worst / best case). There are
benefits for medical professionals, e.g, analysis of the pandemic at local,
regional, state and federal level, the consideration of special risk groups,
tools for validating the length of stays and transition probabilities. Finally,
there are potential advantages for administration, management, e.g., assessment
of the situation of individual hospitals taking local events into account,
consideration of relevant resources such as beds, ventilators, rooms,
protective clothing, and personnel planning, e.g., medical and nursing staff.
babsim.hospital combines simulation, optimization, statistics, and artificial
intelligence processes in a very efficient way. The core is a discrete,
event-based simulation model.",2020-12-14,2020,2020-12,medical
"DeepKeyGen: A Deep Learning-based Stream Cipher Generator for Medical
  Image Encryption and Decryption","The need for medical image encryption is increasingly pronounced, for example
to safeguard the privacy of the patients' medical imaging data. In this paper,
a novel deep learning-based key generation network (DeepKeyGen) is proposed as
a stream cipher generator to generate the private key, which can then be used
for encrypting and decrypting of medical images. In DeepKeyGen, the generative
adversarial network (GAN) is adopted as the learning network to generate the
private key. Furthermore, the transformation domain (that represents the
""style"" of the private key to be generated) is designed to guide the learning
network to realize the private key generation process. The goal of DeepKeyGen
is to learn the mapping relationship of how to transfer the initial image to
the private key. We evaluate DeepKeyGen using three datasets, namely: the
Montgomery County chest X-ray dataset, the Ultrasonic Brachial Plexus dataset,
and the BraTS18 dataset. The evaluation findings and security analysis show
that the proposed key generation network can achieve a high-level security in
generating the private key.",2020-12-21,2020,2020-12,medical
Medical Entity Linking using Triplet Network,"Entity linking (or Normalization) is an essential task in text mining that
maps the entity mentions in the medical text to standard entities in a given
Knowledge Base (KB). This task is of great importance in the medical domain. It
can also be used for merging different medical and clinical ontologies. In this
paper, we center around the problem of disease linking or normalization. This
task is executed in two phases: candidate generation and candidate scoring. In
this paper, we present an approach to rank the candidate Knowledge Base entries
based on their similarity with disease mention. We make use of the Triplet
Network for candidate ranking. While the existing methods have used carefully
generated sieves and external resources for candidate generation, we introduce
a robust and portable candidate generation scheme that does not make use of the
hand-crafted rules. Experimental results on the standard benchmark NCBI disease
dataset demonstrate that our system outperforms the prior methods by a
significant margin.",2020-12-21,2020,2020-12,medical
"A Review of Artificial Intelligence Technologies for Early Prediction of
  Alzheimer's Disease","Alzheimer's Disease (AD) is a severe brain disorder, destroying memories and
brain functions. AD causes chronically, progressively, and irreversibly
cognitive declination and brain damages. The reliable and effective evaluation
of early dementia has become essential research with medical imaging
technologies and computer-aided algorithms. This trend has moved to modern
Artificial Intelligence (AI) technologies motivated by deeplearning success in
image classification and natural language processing. The purpose of this
review is to provide an overview of the latest research involving deep-learning
algorithms in evaluating the process of dementia, diagnosing the early stage of
AD, and discussing an outlook for this research. This review introduces various
applications of modern AI algorithms in AD diagnosis, including Convolutional
Neural Network (CNN), Recurrent Neural Network (RNN), Automatic Image
Segmentation, Autoencoder, Graph CNN (GCN), Ensemble Learning, and Transfer
Learning. The advantages and disadvantages of the proposed methods and their
performance are discussed. The conclusion section summarizes the primary
contributions and medical imaging preprocessing techniques applied in the
reviewed research. Finally, we discuss the limitations and future outlooks.",2020-12-22,2020,2020-12,medical
"GANterfactual - Counterfactual Explanations for Medical Non-Experts
  using Generative Adversarial Learning","With the ongoing rise of machine learning, the need for methods for
explaining decisions made by artificial intelligence systems is becoming a more
and more important topic. Especially for image classification tasks, many
state-of-the-art tools to explain such classifiers rely on visual highlighting
of important areas of the input data. Contrary, counterfactual explanation
systems try to enable a counterfactual reasoning by modifying the input image
in a way such that the classifier would have made a different prediction. By
doing so, the users of counterfactual explanation systems are equipped with a
completely different kind of explanatory information. However, methods for
generating realistic counterfactual explanations for image classifiers are
still rare. Especially in medical contexts, where relevant information often
consists of textural and structural information, high-quality counterfactual
images have the potential to give meaningful insights into decision processes.
In this work, we present GANterfactual, an approach to generate such
counterfactual image explanations based on adversarial image-to-image
translation techniques. Additionally, we conduct a user study to evaluate our
approach in an exemplary medical use case. Our results show that, in the chosen
medical use-case, counterfactual explanations lead to significantly better
results regarding mental models, explanation satisfaction, trust, emotions, and
self-efficacy than two state-of-the-art systems that work with saliency maps,
namely LIME and LRP.",2020-12-22,2020,2020-12,medical
"MeDAL: Medical Abbreviation Disambiguation Dataset for Natural Language
  Understanding Pretraining","One of the biggest challenges that prohibit the use of many current NLP
methods in clinical settings is the availability of public datasets. In this
work, we present MeDAL, a large medical text dataset curated for abbreviation
disambiguation, designed for natural language understanding pre-training in the
medical domain. We pre-trained several models of common architectures on this
dataset and empirically showed that such pre-training leads to improved
performance and convergence speed when fine-tuning on downstream medical tasks.",2020-12-27,2020,2020-12,medical
Order Embeddings from Merged Ontologies using Sketching,"We give a simple, low resource method to produce order embeddings from
ontologies. Such embeddings map words to vectors so that order relations on the
words, such as hypernymy/hyponymy, are represented in a direct way. Our method
uses sketching techniques, in particular countsketch, for dimensionality
reduction. We also study methods to merge ontologies, in particular those in
medical domains, so that order relations are preserved. We give computational
results for medical ontologies and for wordnet, showing that our merging
techniques are effective and our embedding yields an accurate representation in
both generic and specialised domains.",2021-01-06,2021,2021-01,medical
"The Medical Authority of AI: A Study of AI-enabled Consumer-facing
  Health Technology","Recently, consumer-facing health technologies such as Artificial Intelligence
(AI)-based symptom checkers (AISCs) have sprung up in everyday healthcare
practice. AISCs solicit symptom information from users and provide medical
suggestions and possible diagnoses, a responsibility that people usually
entrust with real-person authorities such as physicians and expert patients.
Thus, the advent of AISCs begs a question of whether and how they transform the
notion of medical authority in everyday healthcare practice. To answer this
question, we conducted an interview study with thirty AISC users. We found that
users assess the medical authority of AISCs using various factors including
automated decisions and interaction design patterns of AISC apps, associations
with established medical authorities like hospitals, and comparisons with other
health technologies. We reveal how AISCs are used in healthcare delivery,
discuss how AI transforms conventional understandings of medical authority, and
derive implications for designing AI-enabled health technology.",2021-01-12,2021,2021-01,medical
"Artificial Intelligence for Emotion-Semantic Trending and People Emotion
  Detection During COVID-19 Social Isolation","Taking advantage of social media platforms, such as Twitter, this paper
provides an effective framework for emotion detection among those who are
quarantined. Early detection of emotional feelings and their trends help
implement timely intervention strategies. Given the limitations of medical
diagnosis of early emotional change signs during the quarantine period,
artificial intelligence models provide effective mechanisms in uncovering early
signs, symptoms and escalating trends. Novelty of the approach presented herein
is a multitask methodological framework of text data processing, implemented as
a pipeline for meaningful emotion detection and analysis, based on the
Plutchik/Ekman approach to emotion detection and trend detection. We present an
evaluation of the framework and a pilot system. Results of confirm the
effectiveness of the proposed framework for topic trends and emotion detection
of COVID-19 tweets. Our findings revealed Stay-At-Home restrictions result in
people expressing on twitter both negative and positive emotional semantics.
Semantic trends of safety issues related to staying at home rapidly decreased
within the 28 days and also negative feelings related to friends dying and
quarantined life increased in some days. These findings have potential to
impact public health policy decisions through monitoring trends of emotional
feelings of those who are quarantined. The framework presented here has
potential to assist in such monitoring by using as an online emotion detection
tool kit.",2021-01-16,2021,2021-01,medical
"Medical Information Retrieval and Interpretation: A Question-Answer
  based Interaction Model","The Internet has become a very powerful platform where diverse medical
information are expressed daily. Recently, a huge growth is seen in searches
like symptoms, diseases, medicines, and many other health related queries
around the globe. The search engines typically populate the result by using the
single query provided by the user and hence reaching to the final result may
require a lot of manual filtering from the user's end. Current search engines
and recommendation systems still lack real time interactions that may provide
more precise result generation. This paper proposes an intelligent and
interactive system tied up with the vast medical big data repository on the web
and illustrates its potential in finding medical information.",2021-01-24,2021,2021-01,medical
A Taxonomy of Explainable Bayesian Networks,"Artificial Intelligence (AI), and in particular, the explainability thereof,
has gained phenomenal attention over the last few years. Whilst we usually do
not question the decision-making process of these systems in situations where
only the outcome is of interest, we do however pay close attention when these
systems are applied in areas where the decisions directly influence the lives
of humans. It is especially noisy and uncertain observations close to the
decision boundary which results in predictions which cannot necessarily be
explained that may foster mistrust among end-users. This drew attention to AI
methods for which the outcomes can be explained. Bayesian networks are
probabilistic graphical models that can be used as a tool to manage
uncertainty. The probabilistic framework of a Bayesian network allows for
explainability in the model, reasoning and evidence. The use of these methods
is mostly ad hoc and not as well organised as explainability methods in the
wider AI research field. As such, we introduce a taxonomy of explainability in
Bayesian networks. We extend the existing categorisation of explainability in
the model, reasoning or evidence to include explanation of decisions. The
explanations obtained from the explainability methods are illustrated by means
of a simple medical diagnostic scenario. The taxonomy introduced in this paper
has the potential not only to encourage end-users to efficiently communicate
outcomes obtained, but also support their understanding of how and, more
importantly, why certain predictions were made.",2021-01-28,2021,2021-01,medical
Diagnosis of Acute Poisoning Using Explainable Artificial Intelligence,"Medical toxicology is the clinical specialty that treats the toxic effects of
substances, be it an overdose, a medication error, or a scorpion sting. The
volume of toxicological knowledge and research has, as with other medical
specialties, outstripped the ability of the individual clinician to entirely
master and stay current with it. The application of machine learning techniques
to medical toxicology is challenging because initial treatment decisions are
often based on a few pieces of textual data and rely heavily on prior
knowledge. ML techniques often do not represent knowledge in a way that is
transparent for the physician, raising barriers to usability. Rule-based
systems and decision tree learning are more transparent approaches, but often
generalize poorly and require expert curation to implement and maintain. Here,
we construct a probabilistic logic network to represent a portion of the
knowledge base of a medical toxicologist. Our approach transparently mimics the
knowledge representation and clinical decision-making of practicing clinicians.
The software, dubbed Tak, performs comparably to humans on straightforward
cases and intermediate difficulty cases, but is outperformed by humans on
challenging clinical cases. Tak outperforms a decision tree classifier at all
levels of difficulty. Probabilistic logic provides one form of explainable
artificial intelligence that may be more acceptable for use in healthcare, if
it can achieve acceptable levels of performance.",2021-02-01,2021,2021-02,medical
"Medical Datasets Collections for Artificial Intelligence-based Medical
  Image Analysis","We collected 32 public datasets, of which 28 for medical imaging and 4 for
natural images, to conduct study. The images of these datasets are captured by
different cameras, thus vary from each other in modality, frame size and
capacity. For data accessibility, we also provide the websites of most datasets
and hope this will help the readers reach the datasets.",2021-02-02,2021,2021-02,medical
"Reliability Analysis of Artificial Intelligence Systems Using Recurrent
  Events Data from Autonomous Vehicles","Artificial intelligence (AI) systems have become increasingly common and the
trend will continue. Examples of AI systems include autonomous vehicles (AV),
computer vision, natural language processing, and AI medical experts. To allow
for safe and effective deployment of AI systems, the reliability of such
systems needs to be assessed. Traditionally, reliability assessment is based on
reliability test data and the subsequent statistical modeling and analysis. The
availability of reliability data for AI systems, however, is limited because
such data are typically sensitive and proprietary. The California Department of
Motor Vehicles (DMV) oversees and regulates an AV testing program, in which
many AV manufacturers are conducting AV road tests. Manufacturers participating
in the program are required to report recurrent disengagement events to
California DMV. This information is being made available to the public. In this
paper, we use recurrent disengagement events as a representation of the
reliability of the AI system in AV, and propose a statistical framework for
modeling and analyzing the recurrent events data from AV driving tests. We use
traditional parametric models in software reliability and propose a new
nonparametric model based on monotonic splines to describe the event process.
We develop inference procedures for selecting the best models, quantifying
uncertainty, and testing heterogeneity in the event process. We then analyze
the recurrent events data from four AV manufacturers, and make inferences on
the reliability of the AI systems in AV. We also describe how the proposed
analysis can be applied to assess the reliability of other AI systems.",2021-02-02,2021,2021-02,medical
"The Ethical Implications of Shared Medical Decision Making without
  Providing Adequate Computational Support to the Care Provider and to the
  Patient","There is a clear need to involve patients in medical decisions. However,
cognitive psychological research has highlighted the cognitive limitations of
humans with respect to 1. Probabilistic assessment of the patient state and of
potential outcomes of various decisions, 2. Elicitation of the patient utility
function, and 3. Integration of the probabilistic knowledge and of patient
preferences to determine the optimal strategy. Therefore, without adequate
computational support, current shared decision models have severe ethical
deficiencies. An informed consent model unfairly transfers the responsibility
to a patient who does not have the necessary knowledge, nor the integration
capability. A paternalistic model endows with exaggerated power a physician who
might not be aware of the patient preferences, is prone to multiple cognitive
biases, and whose computational integration capability is bounded. Recent
progress in Artificial Intelligence suggests adding a third agent: a computer,
in all deliberative medical decisions: Non emergency medical decisions in which
more than one alternative exists, the patient preferences can be elicited, the
therapeutic alternatives might be influenced by these preferences, medical
knowledge exists regarding the likelihood of the decision outcomes, and there
is sufficient decision time. Ethical physicians should exploit computational
decision support technologies, neither making the decisions solely on their
own, nor shirking their duty and shifting the responsibility to patients in the
name of informed consent. The resulting three way (patient, care provider,
computer) human machine model that we suggest emphasizes the patient
preferences, the physician knowledge, and the computational integration of both
aspects, does not diminish the physician role, but rather brings out the best
in human and machine.",2021-02-03,2021,2021-02,medical
Applications of Artificial Intelligence in Particle Radiotherapy,"Radiotherapy, due to its technology-intensive nature and reliance on digital
data and human-machine interactions, is particularly suited to benefit from
artificial intelligence (AI) to improve the accuracy and efficiency of its
clinical workflow. Recently, various artificial intelligence (AI) methods have
been successfully developed to exploit the benefit of the inherent physical
properties of particle therapy. Many reviews about AI applications in
radiotherapy have already been published, but none were specifically dedicated
to particle therapy. In this article, we present a comprehensive review of the
recent published works on AI applications in particle therapy, which can be
classified into particle therapy treatment planning, adaptive particle therapy,
range and dose verification and other applications in particle therapy.
Although promising results reported in these works demonstrate how AI-based
methods can help exploit the intrinsic physic advantages of particle therapy,
challenges remained to be address before AI applications in particle therapy
enjoy widespread implementation in clinical practice.",2021-02-05,2021,2021-02,medical
"Artificial Intelligence based Autonomous Molecular Design for Medical
  Therapeutic: A Perspective","Domain-aware machine learning (ML) models have been increasingly adopted for
accelerating small molecule therapeutic design in the recent years. These
models have been enabled by significant advancement in state-of-the-art
artificial intelligence (AI) and computing infrastructures. Several ML
architectures are pre-dominantly and independently used either for predicting
the properties of small molecules, or for generating lead therapeutic
candidates. Synergetically using these individual components along with robust
representation and data generation techniques autonomously in closed loops
holds enormous promise for accelerated drug design which is a time consuming
and expensive task otherwise. In this perspective, we present the most recent
breakthrough achieved by each of the components, and how such autonomous AI and
ML workflow can be realized to radically accelerate the hit identification and
lead optimization. Taken together, this could significantly shorten the
timeline for end-to-end antiviral discovery and optimization times to weeks
upon the arrival of a novel zoonotic transmission event. Our perspective serves
as a guide for researchers to practice autonomous molecular design in
therapeutic discovery.",2021-02-10,2021,2021-02,medical
"MixSearch: Searching for Domain Generalized Medical Image Segmentation
  Architectures","Considering the scarcity of medical data, most datasets in medical image
analysis are an order of magnitude smaller than those of natural images.
However, most Network Architecture Search (NAS) approaches in medical images
focused on specific datasets and did not take into account the generalization
ability of the learned architectures on unseen datasets as well as different
domains. In this paper, we address this point by proposing to search for
generalizable U-shape architectures on a composited dataset that mixes medical
images from multiple segmentation tasks and domains creatively, which is named
MixSearch. Specifically, we propose a novel approach to mix multiple
small-scale datasets from multiple domains and segmentation tasks to produce a
large-scale dataset. Then, a novel weaved encoder-decoder structure is designed
to search for a generalized segmentation network in both cell-level and
network-level. The network produced by the proposed MixSearch framework
achieves state-of-the-art results compared with advanced encoder-decoder
networks across various datasets.",2021-02-26,2021,2021-02,medical
Medical Imaging and Machine Learning,"Advances in computing power, deep learning architectures, and expert labelled
datasets have spurred the development of medical imaging artificial
intelligence systems that rival clinical experts in a variety of scenarios. The
National Institutes of Health in 2018 identified key focus areas for the future
of artificial intelligence in medical imaging, creating a foundational roadmap
for research in image acquisition, algorithms, data standardization, and
translatable clinical decision support systems. Among the key issues raised in
the report: data availability, need for novel computing architectures and
explainable AI algorithms, are still relevant despite the tremendous progress
made over the past few years alone. Furthermore, translational goals of data
sharing, validation of performance for regulatory approval, generalizability
and mitigation of unintended bias must be accounted for early in the
development process. In this perspective paper we explore challenges unique to
high dimensional clinical imaging data, in addition to highlighting some of the
technical and ethical considerations in developing high-dimensional,
multi-modality, machine learning systems for clinical decision support.",2021-03-02,2021,2021-03,medical
"A Comparative Approach to Explainable Artificial Intelligence Methods in
  Application to High-Dimensional Electronic Health Records: Examining the
  Usability of XAI","Explainable Artificial Intelligence (XAI) is a rising field in AI. It aims to
produce a demonstrative factor of trust, which for human subjects is achieved
through communicative means, which Machine Learning (ML) algorithms cannot
solely produce, illustrating the necessity of an extra layer producing support
to the model output. When approaching the medical field, we can see challenges
arise when dealing with the involvement of human-subjects, the ideology behind
trusting a machine to tend towards the livelihood of a human poses an ethical
conundrum - leaving trust as the basis of the human-expert in acceptance to the
machines decision. The aim of this paper is to apply XAI methods to demonstrate
the usability of explainable architectures as a tertiary layer for the medical
domain supporting ML predictions and human-expert opinion, XAI methods produce
visualization of the feature contribution towards a given models output on both
a local and global level. The work in this paper uses XAI to determine feature
importance towards high-dimensional data-driven questions to inform
domain-experts of identifiable trends with a comparison of model-agnostic
methods in application to ML algorithms. The performance metrics for a
glass-box method is also provided as a comparison against black-box capability
for tabular data. Future work will aim to produce a user-study using metrics to
evaluate human-expert usability and opinion of the given models.",2021-03-08,2021,2021-03,medical
"Demographic Aware Probabilistic Medical Knowledge Graph Embeddings of
  Electronic Medical Records","Medical knowledge graphs (KGs) constructed from Electronic Medical Records
(EMR) contain abundant information about patients and medical entities. The
utilization of KG embedding models on these data has proven to be efficient for
different medical tasks. However, existing models do not properly incorporate
patient demographics and most of them ignore the probabilistic features of the
medical KG. In this paper, we propose DARLING (Demographic Aware pRobabiListic
medIcal kNowledge embeddinG), a demographic-aware medical KG embedding
framework that explicitly incorporates demographics in the medical entities
space by associating patient demographics with a corresponding hyperplane. Our
framework leverages the probabilistic features within the medical entities for
learning their representations through demographic guidance. We evaluate
DARLING through link prediction for treatments and medicines, on a medical KG
constructed from EMR data, and illustrate its superior performance compared to
existing KG embedding models.",2021-03-22,2021,2021-03,medical
"Artificial Intelligence in Tumor Subregion Analysis Based on Medical
  Imaging: A Review","Medical imaging is widely used in cancer diagnosis and treatment, and
artificial intelligence (AI) has achieved tremendous success in various tasks
of medical image analysis. This paper reviews AI-based tumor subregion analysis
in medical imaging. We summarize the latest AI-based methods for tumor
subregion analysis and their applications. Specifically, we categorize the
AI-based methods by training strategy: supervised and unsupervised. A detailed
review of each category is presented, highlighting important contributions and
achievements. Specific challenges and potential AI applications in tumor
subregion analysis are discussed.",2021-03-25,2021,2021-03,medical
"MedSelect: Selective Labeling for Medical Image Classification Combining
  Meta-Learning with Deep Reinforcement Learning","We propose a selective learning method using meta-learning and deep
reinforcement learning for medical image interpretation in the setting of
limited labeling resources. Our method, MedSelect, consists of a trainable deep
learning selector that uses image embeddings obtained from contrastive
pretraining for determining which images to label, and a non-parametric
selector that uses cosine similarity to classify unseen images. We demonstrate
that MedSelect learns an effective selection strategy outperforming baseline
selection strategies across seen and unseen medical conditions for chest X-ray
interpretation. We also perform an analysis of the selections performed by
MedSelect comparing the distribution of latent embeddings and clinical
features, and find significant differences compared to the strongest performing
baseline. We believe that our method may be broadly applicable across medical
imaging settings where labels are expensive to acquire.",2021-03-26,2021,2021-03,medical
"MeSIN: Multilevel Selective and Interactive Network for Medication
  Recommendation","Recommending medications for patients using electronic health records (EHRs)
is a crucial data mining task for an intelligent healthcare system. It can
assist doctors in making clinical decisions more efficiently. However, the
inherent complexity of the EHR data renders it as a challenging task: (1)
Multilevel structures: the EHR data typically contains multilevel structures
which are closely related with the decision-making pathways, e.g., laboratory
results lead to disease diagnoses, and then contribute to the prescribed
medications; (2) Multiple sequences interactions: multiple sequences in EHR
data are usually closely correlated with each other; (3) Abundant noise: lots
of task-unrelated features or noise information within EHR data generally
result in suboptimal performance. To tackle the above challenges, we propose a
multilevel selective and interactive network (MeSIN) for medication
recommendation. Specifically, MeSIN is designed with three components. First,
an attentional selective module (ASM) is applied to assign flexible attention
scores to different medical codes embeddings by their relevance to the
recommended medications in every admission. Second, we incorporate a novel
interactive long-short term memory network (InLSTM) to reinforce the
interactions of multilevel medical sequences in EHR data with the help of the
calibrated memory-augmented cell and an enhanced input gate. Finally, we employ
a global selective fusion module (GSFM) to infuse the multi-sourced information
embeddings into final patient representations for medications recommendation.
To validate our method, extensive experiments have been conducted on a
real-world clinical dataset. The results demonstrate a consistent superiority
of our framework over several baselines and testify the effectiveness of our
proposed approach.",2021-04-22,2021,2021-04,medical
"Contextualized Keyword Representations for Multi-modal Retinal Image
  Captioning","Medical image captioning automatically generates a medical description to
describe the content of a given medical image. A traditional medical image
captioning model creates a medical description only based on a single medical
image input. Hence, an abstract medical description or concept is hard to be
generated based on the traditional approach. Such a method limits the
effectiveness of medical image captioning. Multi-modal medical image captioning
is one of the approaches utilized to address this problem. In multi-modal
medical image captioning, textual input, e.g., expert-defined keywords, is
considered as one of the main drivers of medical description generation. Thus,
encoding the textual input and the medical image effectively are both important
for the task of multi-modal medical image captioning. In this work, a new
end-to-end deep multi-modal medical image captioning model is proposed.
Contextualized keyword representations, textual feature reinforcement, and
masked self-attention are used to develop the proposed approach. Based on the
evaluation of the existing multi-modal medical image captioning dataset,
experimental results show that the proposed model is effective with the
increase of +53.2% in BLEU-avg and +18.6% in CIDEr, compared with the
state-of-the-art method.",2021-04-26,2021,2021-04,medical
Medical Transformer: Universal Brain Encoder for 3D MRI Analysis,"Transfer learning has gained attention in medical image analysis due to
limited annotated 3D medical datasets for training data-driven deep learning
models in the real world. Existing 3D-based methods have transferred the
pre-trained models to downstream tasks, which achieved promising results with
only a small number of training samples. However, they demand a massive amount
of parameters to train the model for 3D medical imaging. In this work, we
propose a novel transfer learning framework, called Medical Transformer, that
effectively models 3D volumetric images in the form of a sequence of 2D image
slices. To make a high-level representation in 3D-form empowering spatial
relations better, we take a multi-view approach that leverages plenty of
information from the three planes of 3D volume, while providing
parameter-efficient training. For building a source model generally applicable
to various tasks, we pre-train the model in a self-supervised learning manner
for masked encoding vector prediction as a proxy task, using a large-scale
normal, healthy brain magnetic resonance imaging (MRI) dataset. Our pre-trained
model is evaluated on three downstream tasks: (i) brain disease diagnosis, (ii)
brain age prediction, and (iii) brain tumor segmentation, which are actively
studied in brain MRI research. The experimental results show that our Medical
Transformer outperforms the state-of-the-art transfer learning methods,
efficiently reducing the number of parameters up to about 92% for
classification and",2021-04-28,2021,2021-04,medical
"Explainable Artificial Intelligence for Human Decision-Support System in
  Medical Domain","In the present paper we present the potential of Explainable Artificial
Intelligence methods for decision-support in medical image analysis scenarios.
With three types of explainable methods applied to the same medical image data
set our aim was to improve the comprehensibility of the decisions provided by
the Convolutional Neural Network (CNN). The visual explanations were provided
on in-vivo gastral images obtained from a Video capsule endoscopy (VCE), with
the goal of increasing the health professionals' trust in the black box
predictions. We implemented two post-hoc interpretable machine learning methods
LIME and SHAP and the alternative explanation approach CIU, centered on the
Contextual Value and Utility (CIU). The produced explanations were evaluated
using human evaluation. We conducted three user studies based on the
explanations provided by LIME, SHAP and CIU. Users from different non-medical
backgrounds carried out a series of tests in the web-based survey setting and
stated their experience and understanding of the given explanations. Three user
groups (n=20, 20, 20) with three distinct forms of explanations were
quantitatively analyzed. We have found that, as hypothesized, the CIU
explainable method performed better than both LIME and SHAP methods in terms of
increasing support for human decision-making as well as being more transparent
and thus understandable to users. Additionally, CIU outperformed LIME and SHAP
by generating explanations more rapidly. Our findings suggest that there are
notable differences in human decision-making between various explanation
support settings. In line with that, we present three potential explainable
methods that can with future improvements in implementation be generalized on
different medical data sets and can provide great decision-support for medical
experts.",2021-05-05,2021,2021-05,medical
"Change Matters: Medication Change Prediction with Recurrent Residual
  Networks","Deep learning is revolutionizing predictive healthcare, including
recommending medications to patients with complex health conditions. Existing
approaches focus on predicting all medications for the current visit, which
often overlaps with medications from previous visits. A more clinically
relevant task is to identify medication changes.
  In this paper, we propose a new recurrent residual network, named MICRON, for
medication change prediction. MICRON takes the changes in patient health
records as input and learns to update a hidden medication vector and the
medication set recurrently with a reconstruction design. The medication vector
is like the memory cell that encodes longitudinal information of medications.
Unlike traditional methods that require the entire patient history for
prediction, MICRON has a residual-based inference that allows for sequential
updating based only on new patient features (e.g., new diagnoses in the recent
visit) more efficiently.
  We evaluated MICRON on real inpatient and outpatient datasets. MICRON
achieves 3.5% and 7.8% relative improvements over the best baseline in F1
score, respectively. MICRON also requires fewer parameters, which significantly
reduces the training time to 38.3s per epoch with 1.5x speed-up.",2021-05-05,2021,2021-05,medical
Semi-Supervised Variational Reasoning for Medical Dialogue Generation,"Medical dialogue generation aims to provide automatic and accurate responses
to assist physicians to obtain diagnosis and treatment suggestions in an
efficient manner. In medical dialogues two key characteristics are relevant for
response generation: patient states (such as symptoms, medication) and
physician actions (such as diagnosis, treatments). In medical scenarios
large-scale human annotations are usually not available, due to the high costs
and privacy requirements. Hence, current approaches to medical dialogue
generation typically do not explicitly account for patient states and physician
actions, and focus on implicit representation instead. We propose an end-to-end
variational reasoning approach to medical dialogue generation. To be able to
deal with a limited amount of labeled data, we introduce both patient state and
physician action as latent variables with categorical priors for explicit
patient state tracking and physician policy learning, respectively. We propose
a variational Bayesian generative approach to approximate posterior
distributions over patient states and physician actions. We use an efficient
stochastic gradient variational Bayes estimator to optimize the derived
evidence lower bound, where a 2-stage collapsed inference method is proposed to
reduce the bias during model training. A physician policy network composed of
an action-classifier and two reasoning detectors is proposed for augmented
reasoning ability. We conduct experiments on three datasets collected from
medical platforms. Our experimental results show that the proposed method
outperforms state-of-the-art baselines in terms of objective and subjective
evaluation metrics. Our experiments also indicate that our proposed
semi-supervised reasoning method achieves a comparable performance as
state-of-the-art fully supervised learning baselines for physician policy
learning.",2021-05-13,2021,2021-05,medical
"MedSensor: Medication Adherence Monitoring Using Neural Networks on
  Smartwatch Accelerometer Sensor Data","Poor medication adherence presents serious economic and health problems
including compromised treatment effectiveness, medical complications, and loss
of billions of dollars in wasted medicine or procedures. Though various
interventions have been proposed to address this problem, there is an urgent
need to leverage light, smart, and minimally obtrusive technology such as
smartwatches to develop user tools to improve medication use and adherence. In
this study, we conducted several experiments on medication-taking activities,
developed a smartwatch android application to collect the accelerometer hand
gesture data from the smartwatch, and conveyed the data collected to a central
cloud database. We developed neural networks, then trained the networks on the
sensor data to recognize medication and non-medication gestures. With the
proposed machine learning algorithm approach, this study was able to achieve
average accuracy scores of 97% on the protocol-guided gesture data, and 95% on
natural gesture data.",2021-05-19,2021,2021-05,medical
"Zero-shot Medical Entity Retrieval without Annotation: Learning From
  Rich Knowledge Graph Semantics","Medical entity retrieval is an integral component for understanding and
communicating information across various health systems. Current approaches
tend to work well on specific medical domains but generalize poorly to unseen
sub-specialties. This is of increasing concern under a public health crisis as
new medical conditions and drug treatments come to light frequently. Zero-shot
retrieval is challenging due to the high degree of ambiguity and variability in
medical corpora, making it difficult to build an accurate similarity measure
between mentions and concepts. Medical knowledge graphs (KG), however, contain
rich semantics including large numbers of synonyms as well as its curated
graphical structures. To take advantage of this valuable information, we
propose a suite of learning tasks designed for training efficient zero-shot
entity retrieval models. Without requiring any human annotation, our knowledge
graph enriched architecture significantly outperforms common zero-shot
benchmarks including BM25 and Clinical BERT with 7% to 30% higher recall across
multiple major medical ontologies, such as UMLS, SNOMED, and ICD-10.",2021-05-26,2021,2021-05,medical
Multi-turn Dialog System on Single-turn Data in Medical Domain,"Recently there has been a huge interest in dialog systems. This interest has
also been developed in the field of the medical domain where researchers are
focusing on building a dialog system in the medical domain. This research is
focused on the multi-turn dialog system trained on the multi-turn dialog data.
It is difficult to gather a huge amount of multi-turn conversational data in
the medical domain that is verified by professionals and can be trusted.
However, there are several frequently asked questions (FAQs) or single-turn QA
pairs that have information that is verified by the experts and can be used to
build a multi-turn dialog system.",2021-05-27,2021,2021-05,medical
"Path-based knowledge reasoning with textual semantic information for
  medical knowledge graph completion","Background Knowledge graphs (KGs), especially medical knowledge graphs, are
often significantly incomplete, so it necessitating a demand for medical
knowledge graph completion (MedKGC). MedKGC can find new facts based on the
exited knowledge in the KGs. The path-based knowledge reasoning algorithm is
one of the most important approaches to this task. This type of method has
received great attention in recent years because of its high performance and
interpretability. In fact, traditional methods such as path ranking algorithm
(PRA) take the paths between an entity pair as atomic features. However, the
medical KGs are very sparse, which makes it difficult to model effective
semantic representation for extremely sparse path features. The sparsity in the
medical KGs is mainly reflected in the long-tailed distribution of entities and
paths. Previous methods merely consider the context structure in the paths of
the knowledge graph and ignore the textual semantics of the symbols in the
path. Therefore, their performance cannot be further improved due to the two
aspects of entity sparseness and path sparseness. To address the above issues,
this paper proposes two novel path-based reasoning methods to solve the
sparsity issues of entity and path respectively, which adopts the textual
semantic information of entities and paths for MedKGC. By using the pre-trained
model BERT, combining the textual semantic representations of the entities and
the relationships, we model the task of symbolic reasoning in the medical KG as
a numerical computing issue in textual semantic representation.",2021-05-27,2021,2021-05,medical
"Effect of Pre-Training Scale on Intra- and Inter-Domain Full and
  Few-Shot Transfer Learning for Natural and Medical X-Ray Chest Images","Increasing model, data and compute budget scale in the pre-training has been
shown to strongly improve model generalization and transfer learning in vast
line of work done in language modeling and natural image recognition. However,
most studies on the positive effect of larger scale were done in scope of
in-domain setting, with source and target data being in close proximity. To
study effect of larger scale for both in-domain and out-of-domain setting when
performing full and few-shot transfer, we combine here for the first time
large, openly available medical X-Ray chest imaging datasets to reach a scale
for medical imaging domain comparable to ImageNet-1k, routinely used for
pre-training in natural image domain. We then conduct supervised pre-training,
while varying network size and source data scale and domain, being either large
natural (ImageNet-1k/21k) or large medical chest X-Ray datasets, and transfer
pre-trained models to different natural or medical targets. We observe strong
improvement due to larger pre-training scale for intra-domain natural-natural
and medical-medical transfer. For inter-domain natural-medical transfer, we
find improvements due to larger pre-training scale on larger X-Ray targets in
full shot regime, while for smaller targets and for few-shot regime the
improvement is not visible. Remarkably, large networks pre-trained on very
large natural ImageNet-21k are as good or better than networks pre-trained on
largest available medical X-Ray data when performing transfer to large X-Ray
targets. We conclude that substantially increasing model and generic, medical
domain-agnostic natural image source data scale in the pre-training can enable
high quality out-of-domain transfer to medical domain specific targets,
removing dependency on large medical domain-specific source data often not
available in the practice.",2021-05-31,2021,2021-05,medical
"Explainable AI for medical imaging: Explaining pneumothorax diagnoses
  with Bayesian Teaching","Limited expert time is a key bottleneck in medical imaging. Due to advances
in image classification, AI can now serve as decision-support for medical
experts, with the potential for great gains in radiologist productivity and, by
extension, public health. However, these gains are contingent on building and
maintaining experts' trust in the AI agents. Explainable AI may build such
trust by helping medical experts to understand the AI decision processes behind
diagnostic judgements. Here we introduce and evaluate explanations based on
Bayesian Teaching, a formal account of explanation rooted in the cognitive
science of human learning. We find that medical experts exposed to explanations
generated by Bayesian Teaching successfully predict the AI's diagnostic
decisions and are more likely to certify the AI for cases when the AI is
correct than when it is wrong, indicating appropriate trust. These results show
that Explainable AI can be used to support human-AI collaboration in medical
imaging.",2021-06-08,2021,2021-06,medical
Next-Gen Machine Learning Supported Diagnostic Systems for Spacecraft,"Future short or long-term space missions require a new generation of
monitoring and diagnostic systems due to communication impasses as well as
limitations in specialized crew and equipment. Machine learning supported
diagnostic systems present a viable solution for medical and technical
applications. We discuss challenges and applicability of such systems in light
of upcoming missions and outline an example use case for a next-generation
medical diagnostic system for future space operations. Additionally, we present
approach recommendations and constraints for the successful generation and use
of machine learning models aboard a spacecraft.",2021-06-10,2021,2021-06,medical
Probing Pre-Trained Language Models for Disease Knowledge,"Pre-trained language models such as ClinicalBERT have achieved impressive
results on tasks such as medical Natural Language Inference. At first glance,
this may suggest that these models are able to perform medical reasoning tasks,
such as mapping symptoms to diseases. However, we find that standard benchmarks
such as MedNLI contain relatively few examples that require such forms of
reasoning. To better understand the medical reasoning capabilities of existing
language models, in this paper we introduce DisKnE, a new benchmark for Disease
Knowledge Evaluation. To construct this benchmark, we annotated each positive
MedNLI example with the types of medical reasoning that are needed. We then
created negative examples by corrupting these positive examples in an
adversarial way. Furthermore, we define training-test splits per disease,
ensuring that no knowledge about test diseases can be learned from the training
data, and we canonicalize the formulation of the hypotheses to avoid the
presence of artefacts. This leads to a number of binary classification
problems, one for each type of reasoning and each disease. When analysing
pre-trained models for the clinical/biomedical domain on the proposed
benchmark, we find that their performance drops considerably.",2021-06-14,2021,2021-06,medical
"A Fair and Ethical Healthcare Artificial Intelligence System for
  Monitoring Driver Behavior and Preventing Road Accidents","This paper presents a new approach to prevent transportation accidents and
monitor driver's behavior using a healthcare AI system that incorporates
fairness and ethics. Dangerous medical cases and unusual behavior of the driver
are detected. Fairness algorithm is approached in order to improve
decision-making and address ethical issues such as privacy issues, and to
consider challenges that appear in the wild within AI in healthcare and
driving. A healthcare professional will be alerted about any unusual activity,
and the driver's location when necessary, is provided in order to enable the
healthcare professional to immediately help to the unstable driver. Therefore,
using the healthcare AI system allows for accidents to be predicted and thus
prevented and lives may be saved based on the built-in AI system inside the
vehicle which interacts with the ER system.",2021-06-16,2021,2021-06,medical
"Transformer-based unsupervised patient representation learning based on
  medical claims for risk stratification and analysis","The claims data, containing medical codes, services information, and incurred
expenditure, can be a good resource for estimating an individual's health
condition and medical risk level. In this study, we developed Transformer-based
Multimodal AutoEncoder (TMAE), an unsupervised learning framework that can
learn efficient patient representation by encoding meaningful information from
the claims data. TMAE is motivated by the practical needs in healthcare to
stratify patients into different risk levels for improving care delivery and
management. Compared to previous approaches, TMAE is able to 1) model
inpatient, outpatient, and medication claims collectively, 2) handle irregular
time intervals between medical events, 3) alleviate the sparsity issue of the
rare medical codes, and 4) incorporate medical expenditure information. We
trained TMAE using a real-world pediatric claims dataset containing more than
600,000 patients and compared its performance with various approaches in two
clustering tasks. Experimental results demonstrate that TMAE has superior
performance compared to all baselines. Multiple downstream applications are
also conducted to illustrate the effectiveness of our framework. The promising
results confirm that the TMAE framework is scalable to large claims data and is
able to generate efficient patient embeddings for risk stratification and
analysis.",2021-06-23,2021,2021-06,medical
"Objective task-based evaluation of artificial intelligence-based medical
  imaging methods: Framework, strategies and role of the physician","Artificial intelligence (AI)-based methods are showing promise in multiple
medical-imaging applications. Thus, there is substantial interest in clinical
translation of these methods, requiring in turn, that they be evaluated
rigorously. In this paper, our goal is to lay out a framework for objective
task-based evaluation of AI methods. We will also provide a list of tools
available in the literature to conduct this evaluation. Further, we outline the
important role of physicians in conducting these evaluation studies. The
examples in this paper will be proposed in the context of PET with a focus on
neural-network-based methods. However, the framework is also applicable to
evaluate other medical-imaging modalities and other types of AI methods.",2021-07-09,2021,2021-07,medical
Artificial Intelligence in PET: an Industry Perspective,"Artificial intelligence (AI) has significant potential to positively impact
and advance medical imaging, including positron emission tomography (PET)
imaging applications. AI has the ability to enhance and optimize all aspects of
the PET imaging chain from patient scheduling, patient setup, protocoling, data
acquisition, detector signal processing, reconstruction, image processing and
interpretation. AI poses industry-specific challenges which will need to be
addressed and overcome to maximize the future potentials of AI in PET. This
paper provides an overview of these industry-specific challenges for the
development, standardization, commercialization, and clinical adoption of AI,
and explores the potential enhancements to PET imaging brought on by AI in the
near future. In particular, the combination of on-demand image reconstruction,
AI, and custom designed data processing workflows may open new possibilities
for innovation which would positively impact the industry and ultimately
patients.",2021-07-14,2021,2021-07,medical
"Explainable artificial intelligence (XAI) in deep learning-based medical
  image analysis","With an increase in deep learning-based methods, the call for explainability
of such methods grows, especially in high-stakes decision making areas such as
medical image analysis. This survey presents an overview of eXplainable
Artificial Intelligence (XAI) used in deep learning-based medical image
analysis. A framework of XAI criteria is introduced to classify deep
learning-based medical image analysis methods. Papers on XAI techniques in
medical image analysis are then surveyed and categorized according to the
framework and according to anatomical location. The paper concludes with an
outlook of future opportunities for XAI in medical image analysis.",2021-07-22,2021,2021-07,medical
"Toward High-Throughput Artificial Intelligence-Based Segmentation in
  Oncological PET Imaging","Artificial intelligence (AI) techniques for image-based segmentation have
garnered much attention in recent years. Convolutional neural networks (CNNs)
have shown impressive results and potential towards fully automated
segmentation in medical imaging, and particularly PET imaging. To cope with the
limited access to annotated data needed in supervised AI methods, given tedious
and prone-to-error manual delineations, semi-supervised and unsupervised AI
techniques have also been explored for segmentation of tumors or normal organs
in single and bi-modality scans. This work provides a review of existing AI
techniques for segmentation tasks and the evaluation criteria for translational
AI-based segmentation efforts towards routine adoption in clinical workflows.",2021-07-28,2021,2021-07,medical
"A Method for Medical Data Analysis Using the LogNNet for Clinical
  Decision Support Systems and Edge Computing in Healthcare","Edge computing is a fast-growing and much needed technology in healthcare.
The problem of implementing artificial intelligence on edge devices is the
complexity and high resource intensity of the most known neural network data
analysis methods and algorithms. The difficulty of implementing these methods
on low-power microcontrollers with small memory size calls for the development
of new effective algorithms for neural networks. This study presents a new
method for analyzing medical data based on the LogNNet neural network, which
uses chaotic mappings to transform input information. The method effectively
solves classification problems and calculates risk factors for the presence of
a disease in a patient according to a set of medical health indicators. The
efficiency of LogNNet in assessing perinatal risk is illustrated on
cardiotocogram data obtained from the UC Irvine machine learning repository.
The classification accuracy reaches ~91% with the ~3-10 kB of RAM used on the
Arduino microcontroller. Using the LogNNet network trained on a publicly
available database of the Israeli Ministry of Health, a service concept for
COVID-19 express testing is provided. A classification accuracy of ~95% is
achieved, and ~0.6 kB of RAM is used. In all examples, the model is tested
using standard classification quality metrics: precision, recall, and
F1-measure. The LogNNet architecture allows the implementation of artificial
intelligence on medical peripherals of the Internet of Things with low RAM
resources and can be used in clinical decision support systems.",2021-08-05,2021,2021-08,medical
"Symptom based Hierarchical Classification of Diabetes and Thyroid
  disorders using Fuzzy Cognitive Maps","Fuzzy Cognitive Maps (FCMs) are soft computing technique that follows an
approach similar to human reasoning and human decision-making process, making
them a valuable modeling and simulation methodology. Medical Decision Systems
are complex systems consisting of many factors that may be complementary,
contradictory, and competitive; these factors influence each other and
determine the overall diagnosis with a different degree. Thus, FCMs are
suitable to model Medical Decision Support Systems. The proposed work therefore
uses FCMs arranged in hierarchical structure to classify between Diabetes,
Thyroid disorders and their subtypes. Subtypes include type 1 and type 2 for
diabetes and hyperthyroidism and hypothyroidism for thyroid.",2021-08-08,2021,2021-08,medical
"Improvement of a Prediction Model for Heart Failure Survival through
  Explainable Artificial Intelligence","Cardiovascular diseases and their associated disorder of heart failure are
one of the major death causes globally, being a priority for doctors to detect
and predict its onset and medical consequences. Artificial Intelligence (AI)
allows doctors to discover clinical indicators and enhance their diagnosis and
treatments. Specifically, explainable AI offers tools to improve the clinical
prediction models that experience poor interpretability of their results. This
work presents an explainability analysis and evaluation of a prediction model
for heart failure survival by using a dataset that comprises 299 patients who
suffered heart failure. The model employs a data workflow pipeline able to
select the best ensemble tree algorithm as well as the best feature selection
technique. Moreover, different post-hoc techniques have been used for the
explainability analysis of the model. The paper's main contribution is an
explainability-driven approach to select the best prediction model for HF
survival based on an accuracy-explainability balance. Therefore, the most
balanced explainable prediction model implements an Extra Trees classifier over
5 selected features (follow-up time, serum creatinine, ejection fraction, age
and diabetes) out of 12, achieving a balanced-accuracy of 85.1% and 79.5% with
cross-validation and new unseen data respectively. The follow-up time is the
most influencing feature followed by serum-creatinine and ejection-fraction.
The explainable prediction model for HF survival presented in this paper would
improve a further adoption of clinical prediction models by providing doctors
with intuitions to better understand the reasoning of, usually, black-box AI
clinical solutions, and make more reasonable and data-driven decisions.",2021-08-20,2021,2021-08,medical
"Sinoledge: A Knowledge Engine based on Logical Reasoning and Distributed
  Micro Services","We propose a knowledge engine called Sinoledge mainly for doctors,
physicians, and researchers in medical field to organize thoughts, manage
reasoning process, test and deploy to production environments effortlessly. Our
proposal can be related to rule engine usually used in business or medical
fields. More importantly, our proposal provides a user-friendly interface, an
easy-maintain way of organizing knowledge, an understandable testing
functionality and a highly available and efficient back-end architecture.",2021-08-29,2021,2021-08,medical
"ReMeDi: Resources for Multi-domain, Multi-service, Medical Dialogues","Medical dialogue systems (MDSs) aim to assist doctors and patients with a
range of professional medical services, i.e., diagnosis, treatment and
consultation. The development of MDSs is hindered because of a lack of
resources. In particular. (1) there is no dataset with large-scale medical
dialogues that covers multiple medical services and contains fine-grained
medical labels (i.e., intents, actions, slots, values), and (2) there is no set
of established benchmarks for MDSs for multi-domain, multi-service medical
dialogues. In this paper, we present ReMeDi, a set of resource for medical
dialogues. ReMeDi consists of two parts, the ReMeDi dataset and the ReMeDi
benchmarks. The ReMeDi dataset contains 96,965 conversations between doctors
and patients, including 1,557 conversations with fine-gained labels. It covers
843 types of diseases, 5,228 medical entities, and 3 specialties of medical
services across 40 domains. To the best of our knowledge, the ReMeDi dataset is
the only medical dialogue dataset that covers multiple domains and services,
and has fine-grained medical labels. The second part of the ReMeDi resources
consists of a set of state-of-the-art models for (medical) dialogue generation.
The ReMeDi benchmark has the following methods: (1) pretrained models (i.e.,
BERT-WWM, BERT-MED, GPT2, and MT5) trained, validated, and tested on the ReMeDi
dataset, and (2) a self-supervised contrastive learning(SCL) method to expand
the ReMeDi dataset and enhance the training of the state-of-the-art pretrained
models. We describe the creation of the ReMeDi dataset, the ReMeDi benchmarking
methods, and establish experimental results using the ReMeDi benchmarking
methods on the ReMeDi dataset for future research to compare against. With this
paper, we share the dataset, implementations of the benchmarks, and evaluation
scripts.",2021-09-01,2021,2021-09,medical
Artificial Intelligence in Dry Eye Disease,"Dry eye disease (DED) has a prevalence of between 5 and 50\%, depending on
the diagnostic criteria used and population under study. However, it remains
one of the most underdiagnosed and undertreated conditions in ophthalmology.
Many tests used in the diagnosis of DED rely on an experienced observer for
image interpretation, which may be considered subjective and result in
variation in diagnosis. Since artificial intelligence (AI) systems are capable
of advanced problem solving, use of such techniques could lead to more
objective diagnosis. Although the term `AI' is commonly used, recent success in
its applications to medicine is mainly due to advancements in the sub-field of
machine learning, which has been used to automatically classify images and
predict medical outcomes. Powerful machine learning techniques have been
harnessed to understand nuances in patient data and medical images, aiming for
consistent diagnosis and stratification of disease severity. This is the first
literature review on the use of AI in DED. We provide a brief introduction to
AI, report its current use in DED research and its potential for application in
the clinic. Our review found that AI has been employed in a wide range of DED
clinical tests and research applications, primarily for interpretation of
interferometry, slit-lamp and meibography images. While initial results are
promising, much work is still needed on model development, clinical testing and
standardisation.",2021-09-02,2021,2021-09,medical
"Readying Medical Students for Medical AI: The Need to Embed AI Ethics
  Education","Medical students will almost inevitably encounter powerful medical AI systems
early in their careers. Yet, contemporary medical education does not adequately
equip students with the basic clinical proficiency in medical AI needed to use
these tools safely and effectively. Education reform is urgently needed, but
not easily implemented, largely due to an already jam-packed medical curricula.
In this article, we propose an education reform framework as an effective and
efficient solution, which we call the Embedded AI Ethics Education Framework.
Unlike other calls for education reform to accommodate AI teaching that are
more radical in scope, our framework is modest and incremental. It leverages
existing bioethics or medical ethics curricula to develop and deliver content
on the ethical issues associated with medical AI, especially the harms of
technology misuse, disuse, and abuse that affect the risk-benefit analyses at
the heart of healthcare. In doing so, the framework provides a simple tool for
going beyond the ""What?"" and the ""Why?"" of medical AI ethics education, to
answer the ""How?"", giving universities, course directors, and/or professors a
broad road-map for equipping their students with the necessary clinical
proficiency in medical AI.",2021-09-07,2021,2021-09,medical
"Medically Aware GPT-3 as a Data Generator for Medical Dialogue
  Summarization","In medical dialogue summarization, summaries must be coherent and must
capture all the medically relevant information in the dialogue. However,
learning effective models for summarization require large amounts of labeled
data which is especially hard to obtain. We present an algorithm to create
synthetic training data with an explicit focus on capturing medically relevant
information. We utilize GPT-3 as the backbone of our algorithm and scale 210
human labeled examples to yield results comparable to using 6400 human labeled
examples (~30x) leveraging low-shot learning and an ensemble method. In
detailed experiments, we show that this approach produces high quality training
data that can further be combined with human labeled data to get summaries that
are strongly preferable to those produced by models trained on human data alone
both in terms of medical accuracy and coherency.",2021-09-09,2021,2021-09,medical
Toward a Perspectivist Turn in Ground Truthing for Predictive Computing,"Most Artificial Intelligence applications are based on supervised machine
learning (ML), which ultimately grounds on manually annotated data. The
annotation process is often performed in terms of a majority vote and this has
been proved to be often problematic, as highlighted by recent studies on the
evaluation of ML models. In this article we describe and advocate for a
different paradigm, which we call data perspectivism, which moves away from
traditional gold standard datasets, towards the adoption of methods that
integrate the opinions and perspectives of the human subjects involved in the
knowledge representation step of ML processes. Drawing on previous works which
inspired our proposal we describe the potential of our proposal for not only
the more subjective tasks (e.g. those related to human language) but also to
tasks commonly understood as objective (e.g. medical decision making), and
present the main advantages of adopting a perspectivist stance in ML, as well
as possible disadvantages, and various ways in which such a stance can be
implemented in practice. Finally, we share a set of recommendations and outline
a research agenda to advance the perspectivist stance in ML.",2021-09-09,2021,2021-09,medical
"Risk Management of AI/ML Software as a Medical Device (SaMD): On ISO
  14971 and Related Standards and Guidances","Safety and efficacy are the paramount objectives of medical device
regulation. And in line with the medical ethos of non-maleficence, first do no
harm, safety is the primary goal of regulation also. As such, risk management
is the underlying principle that governs the regulation of medical devices,
whether traditional devices or Software as a Medical Device (SaMD). In this
article, I review how Risk Management Standard ISO 14971:2019 both connects
with and serves as a foundation for the other parts of the Artificial
Intelligence (AI)/Machine Learning (ML) SaMD regulatory framework.",2021-09-11,2021,2021-09,medical
"Co-Correcting: Noise-tolerant Medical Image Classification via mutual
  Label Correction","With the development of deep learning, medical image classification has been
significantly improved. However, deep learning requires massive data with
labels. While labeling the samples by human experts is expensive and
time-consuming, collecting labels from crowd-sourcing suffers from the noises
which may degenerate the accuracy of classifiers. Therefore, approaches that
can effectively handle label noises are highly desired. Unfortunately, recent
progress on handling label noise in deep learning has gone largely unnoticed by
the medical image. To fill the gap, this paper proposes a noise-tolerant
medical image classification framework named Co-Correcting, which significantly
improves classification accuracy and obtains more accurate labels through
dual-network mutual learning, label probability estimation, and curriculum
label correcting. On two representative medical image datasets and the MNIST
dataset, we test six latest Learning-with-Noisy-Labels methods and conduct
comparative studies. The experiments show that Co-Correcting achieves the best
accuracy and generalization under different noise ratios in various tasks. Our
project can be found at: https://github.com/JiarunLiu/Co-Correcting.",2021-09-11,2021,2021-09,medical
"An Apparatus for the Simulation of Breathing Disorders: Physically
  Meaningful Generation of Surrogate Data","The rapidly increasing prevalence of debilitating breathing disorders, such
as chronic obstructive pulmonary disease (COPD), calls for a meaningful
integration of artificial intelligence (AI) into healthcare. While this
promises improved detection and monitoring of breathing disorders, AI
techniques are almost invariably ""data hungry"" which highlights the importance
of generating physically meaningful surrogate data. Indeed, domain aware
surrogates would enable both an improved understanding of respiratory waveform
changes with different breathing disorders, and enhance the training of machine
learning algorithms. To this end, we introduce an apparatus comprising of PVC
tubes and 3D printed parts as a simple yet effective method of simulating both
obstructive and restrictive respiratory waveforms in healthy subjects.
Independent control over both inspiratory and expiratory resistances allows for
the simulation of obstructive breathing disorders through the whole spectrum of
FEV1/FVC spirometry ratios (used to classify COPD), ranging from healthy values
to values seen in severe chronic obstructive pulmonary disease. Moreover,
waveform characteristics of breathing disorders, such as a change in
inspiratory duty cycle or peak flow are also observed in the waveforms
resulting from use of the artificial breathing disorder simulation apparatus.
Overall, the proposed apparatus provides us with a simple, effective and
physically meaningful way to generate faithful surrogate breathing disorder
waveforms, a prerequisite for the use of artificial intelligence in respiratory
health.",2021-09-14,2021,2021-09,medical
"FUTURE-AI: Guiding Principles and Consensus Recommendations for
  Trustworthy Artificial Intelligence in Medical Imaging","The recent advancements in artificial intelligence (AI) combined with the
extensive amount of data generated by today's clinical systems, has led to the
development of imaging AI solutions across the whole value chain of medical
imaging, including image reconstruction, medical image segmentation,
image-based diagnosis and treatment planning. Notwithstanding the successes and
future potential of AI in medical imaging, many stakeholders are concerned of
the potential risks and ethical implications of imaging AI solutions, which are
perceived as complex, opaque, and difficult to comprehend, utilise, and trust
in critical clinical applications. Addressing these concerns and risks, the
FUTURE-AI framework has been proposed, which, sourced from a global
multi-domain expert consensus, comprises guiding principles for increased
trust, safety, and adoption for AI in healthcare. In this paper, we transform
the general FUTURE-AI healthcare principles to a concise and specific AI
implementation guide tailored to the needs of the medical imaging community. To
this end, we carefully assess each building block of the FUTURE-AI framework
consisting of (i) Fairness, (ii) Universality, (iii) Traceability, (iv)
Usability, (v) Robustness and (vi) Explainability, and respectively define
concrete best practices based on accumulated AI implementation experiences from
five large European projects on AI in Health Imaging. We accompany our concrete
step-by-step medical imaging development guide with a practical AI solution
maturity checklist, thus enabling AI development teams to design, evaluate,
maintain, and deploy technically, clinically and ethically trustworthy imaging
AI solutions into clinical practice.",2021-09-20,2021,2021-09,medical
GERNERMED -- An Open German Medical NER Model,"The current state of adoption of well-structured electronic health records
and integration of digital methods for storing medical patient data in
structured formats can often considered as inferior compared to the use of
traditional, unstructured text based patient data documentation. Data mining in
the field of medical data analysis often needs to rely solely on processing of
unstructured data to retrieve relevant data. In natural language processing
(NLP), statistical models have been shown successful in various tasks like
part-of-speech tagging, relation extraction (RE) and named entity recognition
(NER). In this work, we present GERNERMED, the first open, neural NLP model for
NER tasks dedicated to detect medical entity types in German text data. Here,
we avoid the conflicting goals of protection of sensitive patient data from
training data extraction and the publication of the statistical model weights
by training our model on a custom dataset that was translated from publicly
available datasets in foreign language by a pretrained neural machine
translation model. The sample code and the statistical model is available at:
https://github.com/frankkramer-lab/GERNERMED",2021-09-24,2021,2021-09,medical
Predicting COVID-19 Patient Shielding: A Comprehensive Study,"There are many ways machine learning and big data analytics are used in the
fight against the COVID-19 pandemic, including predictions, risk management,
diagnostics, and prevention. This study focuses on predicting COVID-19 patient
shielding -- identifying and protecting patients who are clinically extremely
vulnerable from coronavirus. This study focuses on techniques used for the
multi-label classification of medical text. Using the information published by
the United Kingdom NHS and the World Health Organisation, we present a novel
approach to predicting COVID-19 patient shielding as a multi-label
classification problem. We use publicly available, de-identified ICU medical
text data for our experiments. The labels are derived from the published
COVID-19 patient shielding data. We present an extensive comparison across 12
multi-label classifiers from the simple binary relevance to neural networks and
the most recent transformers. To the best of our knowledge this is the first
comprehensive study, where such a range of multi-label classifiers for medical
text are considered. We highlight the benefits of various approaches, and argue
that, for the task at hand, both predictive accuracy and processing time are
essential.",2021-10-01,2021,2021-10,medical
"Application of quantum computing to a linear non-Gaussian acyclic model
  for novel medical knowledge discovery","Recently, with the digitalization of medicine, the utilization of real-world
medical data collected from clinical sites has been attracting attention. In
this study, quantum computing was applied to a linear non-Gaussian acyclic
model to discover causal relationships from real-world medical data alone.
Specifically, the independence measure of DirectLiNGAM, a causal discovery
algorithm, was calculated using the quantum kernel and its accuracy on
real-world medical data was verified. When DirectLiNGAM with the quantum kernel
(qLiNGAM) was applied to real-world medical data, a case was confirmed in which
the causal structure could be correctly estimated when the amount of data was
small, which was not possible with existing methods. Furthermore, qLiNGAM was
implemented on real quantum hardware in an experiment using IBMQ. It is
suggested that qLiNGAM may be able to discover new medical knowledge and
contribute to the solution of medical problems, even when only a small amount
of data is available.",2021-10-09,2021,2021-10,medical
Anticipation-driven Adaptive Architecture for Assisted Living,"Anticipatory expression underlies human performance. Medical conditions and,
especially, aging result in diminished anticipatory action. In order to
mitigate the loss, means for engaging still available resources (capabilities)
can be provided. In particular, anticipation-driven adaptive environments could
be beneficial in medical care, as well as in assisted living for those seeking
such assistance. These adaptive environments are conceived to be individualized
and individualizable, in order to stimulate independent action instead of
creating dependencies.",2021-10-15,2021,2021-10,medical
"Towards Toxic and Narcotic Medication Detection with Rotated Object
  Detector","Recent years have witnessed the advancement of deep learning vision
technologies and applications in the medical industry. Intelligent devices for
special medication management are in great need of, which requires more precise
detection algorithms to identify the specifications and locations. In this
work, YOLO (You only look once) based object detectors are tailored for toxic
and narcotic medications detection tasks. Specifically, a more flexible
annotation with rotated degree ranging from $0^\circ$ to $90^\circ$ and a
mask-mapping-based non-maximum suppression method are proposed to achieve a
feasible and efficient medication detector aiming at arbitrarily oriented
bounding boxes. Extensive experiments demonstrate that the rotated YOLO
detectors are more suitable for identifying densely arranged drugs. The best
shot mean average precision of the proposed network reaches 0.811 while the
inference time is less than 300ms.",2021-10-19,2021,2021-10,medical
"Drug Similarity and Link Prediction Using Graph Embeddings on Medical
  Knowledge Graphs","The paper utilizes the graph embeddings generated for entities of a large
biomedical database to perform link prediction to capture various new
relationships among different entities. A novel node similarity measure is
proposed that utilizes the graph embeddings and link prediction scores to find
similarity scores among various drugs which can be used by the medical experts
to recommend alternative drugs to avoid side effects from original one.
Utilizing machine learning on knowledge graph for drug similarity and
recommendation will be less costly and less time consuming with higher
scalability as compared to traditional biomedical methods due to the dependency
on costly medical equipment and experts of the latter ones.",2021-10-22,2021,2021-10,medical
Circle Representation for Medical Object Detection,"Box representation has been extensively used for object detection in computer
vision. Such representation is efficacious but not necessarily optimized for
biomedical objects (e.g., glomeruli), which play an essential role in renal
pathology. In this paper, we propose a simple circle representation for medical
object detection and introduce CircleNet, an anchor-free detection framework.
Compared with the conventional bounding box representation, the proposed
bounding circle representation innovates in three-fold: (1) it is optimized for
ball-shaped biomedical objects; (2) The circle representation reduced the
degree of freedom compared with box representation; (3) It is naturally more
rotation invariant. When detecting glomeruli and nuclei on pathological images,
the proposed circle representation achieved superior detection performance and
be more rotation-invariant, compared with the bounding box. The code has been
made publicly available: https://github.com/hrlblab/CircleNet",2021-10-22,2021,2021-10,medical
"Lightweight Mobile Automated Assistant-to-physician for Global
  Lower-resource Areas","Importance: Lower-resource areas in Africa and Asia face a unique set of
healthcare challenges: the dual high burden of communicable and
non-communicable diseases; a paucity of highly trained primary healthcare
providers in both rural and densely populated urban areas; and a lack of
reliable, inexpensive internet connections. Objective: To address these
challenges, we designed an artificial intelligence assistant to help primary
healthcare providers in lower-resource areas document demographic and medical
sign/symptom data and to record and share diagnostic data in real-time with a
centralized database. Design: We trained our system using multiple data sets,
including US-based electronic medical records (EMRs) and open-source medical
literature and developed an adaptive, general medical assistant system based on
machine learning algorithms. Main outcomes and Measure: The application
collects basic information from patients and provides primary care providers
with diagnoses and prescriptions suggestions. The application is unique from
existing systems in that it covers a wide range of common diseases, signs, and
medication typical in lower-resource countries; the application works with or
without an active internet connection. Results: We have built and implemented
an adaptive learning system that assists trained primary care professionals by
means of an Android smartphone application, which interacts with a central
database and collects real-time data. The application has been tested by dozens
of primary care providers. Conclusions and Relevance: Our application would
provide primary healthcare providers in lower-resource areas with a tool that
enables faster and more accurate documentation of medical encounters. This
application could be leveraged to automatically populate local or national EMR
systems.",2021-10-28,2021,2021-10,medical
"Deep AUC Maximization for Medical Image Classification: Challenges and
  Opportunities","In this extended abstract, we will present and discuss opportunities and
challenges brought about by a new deep learning method by AUC maximization (aka
\underline{\bf D}eep \underline{\bf A}UC \underline{\bf M}aximization or {\bf
DAM}) for medical image classification. Since AUC (aka area under ROC curve) is
a standard performance measure for medical image classification, hence directly
optimizing AUC could achieve a better performance for learning a deep neural
network than minimizing a traditional loss function (e.g., cross-entropy loss).
Recently, there emerges a trend of using deep AUC maximization for large-scale
medical image classification. In this paper, we will discuss these recent
results by highlighting (i) the advancements brought by stochastic non-convex
optimization algorithms for DAM; (ii) the promising results on various medical
image classification problems. Then, we will discuss challenges and
opportunities of DAM for medical image classification from three perspectives,
feature learning, large-scale optimization, and learning trustworthy AI models.",2021-11-01,2021,2021-11,medical
"Transparency of Deep Neural Networks for Medical Image Analysis: A
  Review of Interpretability Methods","Artificial Intelligence has emerged as a useful aid in numerous clinical
applications for diagnosis and treatment decisions. Deep neural networks have
shown same or better performance than clinicians in many tasks owing to the
rapid increase in the available data and computational power. In order to
conform to the principles of trustworthy AI, it is essential that the AI system
be transparent, robust, fair and ensure accountability. Current deep neural
solutions are referred to as black-boxes due to a lack of understanding of the
specifics concerning the decision making process. Therefore, there is a need to
ensure interpretability of deep neural networks before they can be incorporated
in the routine clinical workflow. In this narrative review, we utilized
systematic keyword searches and domain expertise to identify nine different
types of interpretability methods that have been used for understanding deep
learning models for medical image analysis applications based on the type of
generated explanations and technical similarities. Furthermore, we report the
progress made towards evaluating the explanations produced by various
interpretability methods. Finally we discuss limitations, provide guidelines
for using interpretability methods and future directions concerning the
interpretability of deep neural networks for medical imaging analysis.",2021-11-01,2021,2021-11,medical
"Artificial Intelligence Technology analysis using Artificial
  Intelligence patent through Deep Learning model and vector space model","Thanks to rapid development of artificial intelligence technology in recent
years, the current artificial intelligence technology is contributing to many
part of society. Education, environment, medical care, military, tourism,
economy, politics, etc. are having a very large impact on society as a whole.
For example, in the field of education, there is an artificial intelligence
tutoring system that automatically assigns tutors based on student's level. In
the field of economics, there are quantitative investment methods that
automatically analyze large amounts of data to find investment laws to create
investment models or predict changes in financial markets. As such, artificial
intelligence technology is being used in various fields. So, it is very
important to know exactly what factors have an important influence on each
field of artificial intelligence technology and how the relationship between
each field is connected. Therefore, it is necessary to analyze artificial
intelligence technology in each field. In this paper, we analyze patent
documents related to artificial intelligence technology. We propose a method
for keyword analysis within factors using artificial intelligence patent data
sets for artificial intelligence technology analysis. This is a model that
relies on feature engineering based on deep learning model named KeyBERT, and
using vector space model. A case study of collecting and analyzing artificial
intelligence patent data was conducted to show how the proposed model can be
applied to real world problems.",2021-11-08,2021,2021-11,medical
JaMIE: A Pipeline Japanese Medical Information Extraction System,"We present an open-access natural language processing toolkit for Japanese
medical information extraction. We first propose a novel relation annotation
schema for investigating the medical and temporal relations between medical
entities in Japanese medical reports. We experiment with the practical
annotation scenarios by separately annotating two different types of reports.
We design a pipeline system with three components for recognizing medical
entities, classifying entity modalities, and extracting relations. The
empirical results show accurate analyzing performance and suggest the
satisfactory annotation quality, the effective annotation strategy for
targeting report types, and the superiority of the latest contextual embedding
models.",2021-11-08,2021,2021-11,medical
Auto-Encoding Knowledge Graph for Unsupervised Medical Report Generation,"Medical report generation, which aims to automatically generate a long and
coherent report of a given medical image, has been receiving growing research
interests. Existing approaches mainly adopt a supervised manner and heavily
rely on coupled image-report pairs. However, in the medical domain, building a
large-scale image-report paired dataset is both time-consuming and expensive.
To relax the dependency on paired data, we propose an unsupervised model
Knowledge Graph Auto-Encoder (KGAE) which accepts independent sets of images
and reports in training. KGAE consists of a pre-constructed knowledge graph, a
knowledge-driven encoder and a knowledge-driven decoder. The knowledge graph
works as the shared latent space to bridge the visual and textual domains; The
knowledge-driven encoder projects medical images and reports to the
corresponding coordinates in this latent space and the knowledge-driven decoder
generates a medical report given a coordinate in this space. Since the
knowledge-driven encoder and decoder can be trained with independent sets of
images and reports, KGAE is unsupervised. The experiments show that the
unsupervised KGAE generates desirable medical reports without using any
image-report training pairs. Moreover, KGAE can also work in both
semi-supervised and supervised settings, and accept paired images and reports
in training. By further fine-tuning with image-report pairs, KGAE consistently
outperforms the current state-of-the-art models on two datasets.",2021-11-08,2021,2021-11,medical
"Measuring Outcomes in Healthcare Economics using Artificial
  Intelligence: with Application to Resource Management","The quality of service in healthcare is constantly challenged by outlier
events such as pandemics (i.e. Covid-19) and natural disasters (such as
hurricanes and earthquakes). In most cases, such events lead to critical
uncertainties in decision making, as well as in multiple medical and economic
aspects at a hospital. External (geographic) or internal factors (medical and
managerial), lead to shifts in planning and budgeting, but most importantly,
reduces confidence in conventional processes. In some cases, support from other
hospitals proves necessary, which exacerbates the planning aspect. This
manuscript presents three data-driven methods that provide data-driven
indicators to help healthcare managers organize their economics and identify
the most optimum plan for resources allocation and sharing. Conventional
decision-making methods fall short in recommending validated policies for
managers. Using reinforcement learning, genetic algorithms, traveling salesman,
and clustering, we experimented with different healthcare variables and
presented tools and outcomes that could be applied at health institutes.
Experiments are performed; the results are recorded, evaluated, and presented.",2021-11-15,2021,2021-11,medical
"Interactive Medical Image Segmentation with Self-Adaptive Confidence
  Calibration","Medical image segmentation is one of the fundamental problems for artificial
intelligence-based clinical decision systems. Current automatic medical image
segmentation methods are often failed to meet clinical requirements. As such, a
series of interactive segmentation algorithms are proposed to utilize expert
correction information. However, existing methods suffer from some segmentation
refining failure problems after long-term interactions and some cost problems
from expert annotation, which hinder clinical applications. This paper proposes
an interactive segmentation framework, called interactive MEdical segmentation
with self-adaptive Confidence CAlibration (MECCA), by introducing the
corrective action evaluation, which combines the action-based confidence
learning and multi-agent reinforcement learning (MARL). The evaluation is
established through a novel action-based confidence network, and the corrective
actions are obtained from MARL. Based on the confidential information, a
self-adaptive reward function is designed to provide more detailed feedback,
and a simulated label generation mechanism is proposed on unsupervised data to
reduce over-reliance on labeled data. Experimental results on various medical
image datasets have shown the significant performance of the proposed
algorithm.",2021-11-15,2021,2021-11,medical
"MEDCOD: A Medically-Accurate, Emotive, Diverse, and Controllable Dialog
  System","We present MEDCOD, a Medically-Accurate, Emotive, Diverse, and Controllable
Dialog system with a unique approach to the natural language generator module.
MEDCOD has been developed and evaluated specifically for the history taking
task. It integrates the advantage of a traditional modular approach to
incorporate (medical) domain knowledge with modern deep learning techniques to
generate flexible, human-like natural language expressions. Two key aspects of
MEDCOD's natural language output are described in detail. First, the generated
sentences are emotive and empathetic, similar to how a doctor would communicate
to the patient. Second, the generated sentence structures and phrasings are
varied and diverse while maintaining medical consistency with the desired
medical concept (provided by the dialogue manager module of MEDCOD).
Experimental results demonstrate the effectiveness of our approach in creating
a human-like medical dialogue system. Relevant code is available at
https://github.com/curai/curai-research/tree/main/MEDCOD",2021-11-17,2021,2021-11,medical
The Prominence of Artificial Intelligence in COVID-19,"In December 2019, a novel virus called COVID-19 had caused an enormous number
of causalities to date. The battle with the novel Coronavirus is baffling and
horrifying after the Spanish Flu 2019. While the front-line doctors and medical
researchers have made significant progress in controlling the spread of the
highly contiguous virus, technology has also proved its significance in the
battle. Moreover, Artificial Intelligence has been adopted in many medical
applications to diagnose many diseases, even baffling experienced doctors.
Therefore, this survey paper explores the methodologies proposed that can aid
doctors and researchers in early and inexpensive methods of diagnosis of the
disease. Most developing countries have difficulties carrying out tests using
the conventional manner, but a significant way can be adopted with Machine and
Deep Learning. On the other hand, the access to different types of medical
images has motivated the researchers. As a result, a mammoth number of
techniques are proposed. This paper first details the background knowledge of
the conventional methods in the Artificial Intelligence domain. Following that,
we gather the commonly used datasets and their use cases to date. In addition,
we also show the percentage of researchers adopting Machine Learning over Deep
Learning. Thus we provide a thorough analysis of this scenario. Lastly, in the
research challenges, we elaborate on the problems faced in COVID-19 research,
and we address the issues with our understanding to build a bright and healthy
environment.",2021-11-18,2021,2021-11,medical
Medical Visual Question Answering: A Survey,"Medical Visual Question Answering~(VQA) is a combination of medical
artificial intelligence and popular VQA challenges. Given a medical image and a
clinically relevant question in natural language, the medical VQA system is
expected to predict a plausible and convincing answer. Although the
general-domain VQA has been extensively studied, the medical VQA still needs
specific investigation and exploration due to its task features. In the first
part of this survey, we collect and discuss the publicly available medical VQA
datasets up-to-date about the data source, data quantity, and task feature. In
the second part, we review the approaches used in medical VQA tasks. We
summarize and discuss their techniques, innovations, and potential
improvements. In the last part, we analyze some medical-specific challenges for
the field and discuss future research directions. Our goal is to provide
comprehensive and helpful information for researchers interested in the medical
visual question answering field and encourage them to conduct further research
in this field.",2021-11-19,2021,2021-11,medical
"Improving Predictions of Tail-end Labels using Concatenated
  BioMed-Transformers for Long Medical Documents","Multi-label learning predicts a subset of labels from a given label set for
an unseen instance while considering label correlations. A known challenge with
multi-label classification is the long-tailed distribution of labels. Many
studies focus on improving the overall predictions of the model and thus do not
prioritise tail-end labels. Improving the tail-end label predictions in
multi-label classifications of medical text enables the potential to understand
patients better and improve care. The knowledge gained by one or more
infrequent labels can impact the cause of medical decisions and treatment
plans. This research presents variations of concatenated domain-specific
language models, including multi-BioMed-Transformers, to achieve two primary
goals. First, to improve F1 scores of infrequent labels across multi-label
problems, especially with long-tail labels; second, to handle long medical text
and multi-sourced electronic health records (EHRs), a challenging task for
standard transformers designed to work on short input sequences. A vital
contribution of this research is new state-of-the-art (SOTA) results obtained
using TransformerXL for predicting medical codes. A variety of experiments are
performed on the Medical Information Mart for Intensive Care (MIMIC-III)
database. Results show that concatenated BioMed-Transformers outperform
standard transformers in terms of overall micro and macro F1 scores and
individual F1 scores of tail-end labels, while incurring lower training times
than existing transformer-based solutions for long input sequences.",2021-12-03,2021,2021-12,medical
"ASC-Net: Unsupervised Medical Anomaly Segmentation Using an
  Adversarial-based Selective Cutting Network","In this paper we consider the problem of unsupervised anomaly segmentation in
medical images, which has attracted increasing attention in recent years due to
the expensive pixel-level annotations from experts and the existence of a large
amount of unannotated normal and abnormal image scans. We introduce a
segmentation network that utilizes adversarial learning to partition an image
into two cuts, with one of them falling into a reference distribution provided
by the user. This Adversarial-based Selective Cutting network (ASC-Net) bridges
the two domains of cluster-based deep segmentation and adversarial-based
anomaly/novelty detection algorithms. Our ASC-Net learns from normal and
abnormal medical scans to segment anomalies in medical scans without any masks
for supervision. We evaluate this unsupervised anomly segmentation model on
three public datasets, i.e., BraTS 2019 for brain tumor segmentation, LiTS for
liver lesion segmentation, and MS-SEG 2015 for brain lesion segmentation, and
also on a private dataset for brain tumor segmentation. Compared to existing
methods, our model demonstrates tremendous performance gains in unsupervised
anomaly segmentation tasks. Although there is still room to further improve
performance compared to supervised learning algorithms, the promising
experimental results and interesting observations shed light on building an
unsupervised learning algorithm for medical anomaly identification using
user-defined knowledge.",2021-12-16,2021,2021-12,medical
Towards a Shapley Value Graph Framework for Medical peer-influence,"eXplainable Artificial Intelligence (XAI) is a sub-field of Artificial
Intelligence (AI) that is at the forefront of AI research. In XAI, feature
attribution methods produce explanations in the form of feature importance.
People often use feature importance as guidance for intervention. However, a
limitation of existing feature attribution methods is that there is a lack of
explanation towards the consequence of intervention. In other words, although
contribution towards a certain prediction is highlighted by feature attribution
methods, the relation between features and the consequence of intervention is
not studied. The aim of this paper is to introduce a new framework, called a
peer influence framework to look deeper into explanations using graph
representation for feature-to-feature interactions to improve the
interpretability of black-box Machine Learning models and inform intervention.",2021-12-29,2021,2021-12,medical
"Machine Learning: Algorithms, Models, and Applications","Recent times are witnessing rapid development in machine learning algorithm
systems, especially in reinforcement learning, natural language processing,
computer and robot vision, image processing, speech, and emotional processing
and understanding. In tune with the increasing importance and relevance of
machine learning models, algorithms, and their applications, and with the
emergence of more innovative uses cases of deep learning and artificial
intelligence, the current volume presents a few innovative research works and
their applications in real world, such as stock trading, medical and healthcare
systems, and software automation. The chapters in the book illustrate how
machine learning and deep learning algorithms and models are designed,
optimized, and deployed. The volume will be useful for advanced graduate and
doctoral students, researchers, faculty members of universities, practicing
data scientists and data engineers, professionals, and consultants working on
the broad areas of machine learning, deep learning, and artificial
intelligence.",2022-01-06,2022,2022-01,medical
"Get your Foes Fooled: Proximal Gradient Split Learning for Defense
  against Model Inversion Attacks on IoMT data","The past decade has seen a rapid adoption of Artificial Intelligence (AI),
specifically the deep learning networks, in Internet of Medical Things (IoMT)
ecosystem. However, it has been shown recently that the deep learning networks
can be exploited by adversarial attacks that not only make IoMT vulnerable to
the data theft but also to the manipulation of medical diagnosis. The existing
studies consider adding noise to the raw IoMT data or model parameters which
not only reduces the overall performance concerning medical inferences but also
is ineffective to the likes of deep leakage from gradients method. In this
work, we propose proximal gradient split learning (PSGL) method for defense
against the model inversion attacks. The proposed method intentionally attacks
the IoMT data when undergoing the deep neural network training process at
client side. We propose the use of proximal gradient method to recover gradient
maps and a decision-level fusion strategy to improve the recognition
performance. Extensive analysis show that the PGSL not only provides effective
defense mechanism against the model inversion attacks but also helps in
improving the recognition performance on publicly available datasets. We report
14.0$\%$, 17.9$\%$, and 36.9$\%$ gains in accuracy over reconstructed and
adversarial attacked images, respectively.",2022-01-12,2022,2022-01,medical
"Artificial Intelligence in Software Testing : Impact, Problems,
  Challenges and Prospect","Artificial Intelligence (AI) is making a significant impact in multiple areas
like medical, military, industrial, domestic, law, arts as AI is capable to
perform several roles such as managing smart factories, driving autonomous
vehicles, creating accurate weather forecasts, detecting cancer and personal
assistants, etc. Software testing is the process of putting the software to
test for some abnormal behaviour of the software. Software testing is a
tedious, laborious and most time-consuming process. Automation tools have been
developed that help to automate some activities of the testing process to
enhance quality and timely delivery. Over time with the inclusion of continuous
integration and continuous delivery (CI/CD) pipeline, automation tools are
becoming less effective. The testing community is turning to AI to fill the gap
as AI is able to check the code for bugs and errors without any human
intervention and in a much faster way than humans. In this study, we aim to
recognize the impact of AI technologies on various software testing activities
or facets in the STLC. Further, the study aims to recognize and explain some of
the biggest challenges software testers face while applying AI to testing. The
paper also proposes some key contributions of AI in the future to the domain of
software testing.",2022-01-14,2022,2022-01,medical
RuMedBench: A Russian Medical Language Understanding Benchmark,"The paper describes the open Russian medical language understanding benchmark
covering several task types (classification, question answering, natural
language inference, named entity recognition) on a number of novel text sets.
Given the sensitive nature of the data in healthcare, such a benchmark
partially closes the problem of Russian medical dataset absence. We prepare the
unified format labeling, data split, and evaluation metrics for new tasks. The
remaining tasks are from existing datasets with a few modifications. A
single-number metric expresses a model's ability to cope with the benchmark.
Moreover, we implement several baseline models, from simple ones to neural
networks with transformer architecture, and release the code. Expectedly, the
more advanced models yield better performance, but even a simple model is
enough for a decent result in some tasks. Furthermore, for all tasks, we
provide a human evaluation. Interestingly the models outperform humans in the
large-scale classification tasks. However, the advantage of natural
intelligence remains in the tasks requiring more knowledge and reasoning.",2022-01-17,2022,2022-01,medical
"Label-dependent and event-guided interpretable disease risk prediction
  using EHRs","Electronic health records (EHRs) contain patients' heterogeneous data that
are collected from medical providers involved in the patient's care, including
medical notes, clinical events, laboratory test results, symptoms, and
diagnoses. In the field of modern healthcare, predicting whether patients would
experience any risks based on their EHRs has emerged as a promising research
area, in which artificial intelligence (AI) plays a key role. To make AI models
practically applicable, it is required that the prediction results should be
both accurate and interpretable. To achieve this goal, this paper proposed a
label-dependent and event-guided risk prediction model (LERP) to predict the
presence of multiple disease risks by mainly extracting information from
unstructured medical notes. Our model is featured in the following aspects.
First, we adopt a label-dependent mechanism that gives greater attention to
words from medical notes that are semantically similar to the names of risk
labels. Secondly, as the clinical events (e.g., treatments and drugs) can also
indicate the health status of patients, our model utilizes the information from
events and uses them to generate an event-guided representation of medical
notes. Thirdly, both label-dependent and event-guided representations are
integrated to make a robust prediction, in which the interpretability is
enabled by the attention weights over words from medical notes. To demonstrate
the applicability of the proposed method, we apply it to the MIMIC-III dataset,
which contains real-world EHRs collected from hospitals. Our method is
evaluated in both quantitative and qualitative ways.",2022-01-18,2022,2022-01,medical
"Benchmark datasets driving artificial intelligence development fail to
  capture the needs of medical professionals","Publicly accessible benchmarks that allow for assessing and comparing model
performances are important drivers of progress in artificial intelligence (AI).
While recent advances in AI capabilities hold the potential to transform
medical practice by assisting and augmenting the cognitive processes of
healthcare professionals, the coverage of clinically relevant tasks by AI
benchmarks is largely unclear. Furthermore, there is a lack of systematized
meta-information that allows clinical AI researchers to quickly determine
accessibility, scope, content and other characteristics of datasets and
benchmark datasets relevant to the clinical domain.
  To address these issues, we curated and released a comprehensive catalogue of
datasets and benchmarks pertaining to the broad domain of clinical and
biomedical natural language processing (NLP), based on a systematic review of
literature and online resources. A total of 450 NLP datasets were manually
systematized and annotated with rich metadata, such as targeted tasks, clinical
applicability, data types, performance metrics, accessibility and licensing
information, and availability of data splits. We then compared tasks covered by
AI benchmark datasets with relevant tasks that medical practitioners reported
as highly desirable targets for automation in a previous empirical study.
  Our analysis indicates that AI benchmarks of direct clinical relevance are
scarce and fail to cover most work activities that clinicians want to see
addressed. In particular, tasks associated with routine documentation and
patient data administration workflows are not represented despite significant
associated workloads. Thus, currently available AI benchmarks are improperly
aligned with desired targets for AI automation in clinical settings, and novel
benchmarks should be created to fill these gaps.",2022-01-18,2022,2022-01,medical
"Label Dependent Attention Model for Disease Risk Prediction Using
  Multimodal Electronic Health Records","Disease risk prediction has attracted increasing attention in the field of
modern healthcare, especially with the latest advances in artificial
intelligence (AI). Electronic health records (EHRs), which contain
heterogeneous patient information, are widely used in disease risk prediction
tasks. One challenge of applying AI models for risk prediction lies in
generating interpretable evidence to support the prediction results while
retaining the prediction ability. In order to address this problem, we propose
the method of jointly embedding words and labels whereby attention modules
learn the weights of words from medical notes according to their relevance to
the names of risk prediction labels. This approach boosts interpretability by
employing an attention mechanism and including the names of prediction tasks in
the model. However, its application is only limited to the handling of textual
inputs such as medical notes. In this paper, we propose a label dependent
attention model LDAM to 1) improve the interpretability by exploiting
Clinical-BERT (a biomedical language model pre-trained on a large clinical
corpus) to encode biomedically meaningful features and labels jointly; 2)
extend the idea of joint embedding to the processing of time-series data, and
develop a multi-modal learning framework for integrating heterogeneous
information from medical notes and time-series health status indicators. To
demonstrate our method, we apply LDAM to the MIMIC-III dataset to predict
different disease risks. We evaluate our method both quantitatively and
qualitatively. Specifically, the predictive power of LDAM will be shown, and
case studies will be carried out to illustrate its interpretability.",2022-01-18,2022,2022-01,medical
"A Cognitive Explainer for Fetal ultrasound images classifier Based on
  Medical Concepts","Fetal standard scan plane detection during 2-D mid-pregnancy examinations is
a highly complex task, which requires extensive medical knowledge and years of
training. Although deep neural networks (DNN) can assist inexperienced
operators in these tasks, their lack of transparency and interpretability limit
their application. Despite some researchers have been committed to visualizing
the decision process of DNN, most of them only focus on the pixel-level
features and do not take into account the medical prior knowledge. In this
work, we propose an interpretable framework based on key medical concepts,
which provides explanations from the perspective of clinicians' cognition.
Moreover, we utilize a concept-based graph convolutional neural(GCN) network to
construct the relationships between key medical concepts. Extensive
experimental analysis on a private dataset has shown that the proposed method
provides easy-to-understand insights about reasoning results for clinicians.",2022-01-19,2022,2022-01,medical
MISeval: a Metric Library for Medical Image Segmentation Evaluation,"Correct performance assessment is crucial for evaluating modern artificial
intelligence algorithms in medicine like deep-learning based medical image
segmentation models. However, there is no universal metric library in Python
for standardized and reproducible evaluation. Thus, we propose our open-source
publicly available Python package MISeval: a metric library for Medical Image
Segmentation Evaluation. The implemented metrics can be intuitively used and
easily integrated into any performance assessment pipeline. The package
utilizes modern CI/CD strategies to ensure functionality and stability. MISeval
is available from PyPI (miseval) and GitHub:
https://github.com/frankkramer-lab/miseval.",2022-01-23,2022,2022-01,medical
"Distantly supervised end-to-end medical entity extraction from
  electronic health records with human-level quality","Medical entity extraction (EE) is a standard procedure used as a first stage
in medical texts processing. Usually Medical EE is a two-step process: named
entity recognition (NER) and named entity normalization (NEN). We propose a
novel method of doing medical EE from electronic health records (EHR) as a
single-step multi-label classification task by fine-tuning a transformer model
pretrained on a large EHR dataset. Our model is trained end-to-end in an
distantly supervised manner using targets automatically extracted from medical
knowledge base. We show that our model learns to generalize for entities that
are present frequently enough, achieving human-level classification quality for
most frequent entities. Our work demonstrates that medical entity extraction
can be done end-to-end without human supervision and with human quality given
the availability of a large enough amount of unlabeled EHR and a medical
knowledge base.",2022-01-25,2022,2022-01,medical
"An Analysis on Ensemble Learning optimized Medical Image Classification
  with Deep Convolutional Neural Networks","Novel and high-performance medical image classification pipelines are heavily
utilizing ensemble learning strategies. The idea of ensemble learning is to
assemble diverse models or multiple predictions and, thus, boost prediction
performance. However, it is still an open question to what extent as well as
which ensemble learning strategies are beneficial in deep learning based
medical image classification pipelines. In this work, we proposed a
reproducible medical image classification pipeline for analyzing the
performance impact of the following ensemble learning techniques: Augmenting,
Stacking, and Bagging. The pipeline consists of state-of-the-art preprocessing
and image augmentation methods as well as 9 deep convolution neural network
architectures. It was applied on four popular medical imaging datasets with
varying complexity. Furthermore, 12 pooling functions for combining multiple
predictions were analyzed, ranging from simple statistical functions like
unweighted averaging up to more complex learning-based functions like support
vector machines. Our results revealed that Stacking achieved the largest
performance gain of up to 13% F1-score increase. Augmenting showed consistent
improvement capabilities by up to 4% and is also applicable to single model
based pipelines. Cross-validation based Bagging demonstrated significant
performance gain close to Stacking, which resulted in an F1-score increase up
to +11%. Furthermore, we demonstrated that simple statistical pooling functions
are equal or often even better than more complex pooling functions. We
concluded that the integration of ensemble learning techniques is a powerful
method for any medical image classification pipeline to improve robustness and
boost performance.",2022-01-27,2022,2022-01,medical
"A Knowledge-Based Decision Support System for In Vitro Fertilization
  Treatment","In Vitro Fertilization (IVF) is the most widely used Assisted Reproductive
Technology (ART). IVF usually involves controlled ovarian stimulation, oocyte
retrieval, fertilization in the laboratory with subsequent embryo transfer. The
first two steps correspond with follicular phase of females and ovulation in
their menstrual cycle. Therefore, we refer to it as the treatment cycle in our
paper. The treatment cycle is crucial because the stimulation medications in
IVF treatment are applied directly on patients. In order to optimize the
stimulation effects and lower the side effects of the stimulation medications,
prompt treatment adjustments are in need. In addition, the quality and quantity
of the retrieved oocytes have a significant effect on the outcome of the
following procedures. To improve the IVF success rate, we propose a
knowledge-based decision support system that can provide medical advice on the
treatment protocol and medication adjustment for each patient visit during IVF
treatment cycle. Our system is efficient in data processing and light-weighted
which can be easily embedded into electronic medical record systems. Moreover,
an oocyte retrieval oriented evaluation demonstrates that our system performs
well in terms of accuracy of advice for the protocols and medications.",2022-01-27,2022,2022-01,medical
Research on Question Classification Methods in the Medical Field,"Question classification is one of the important links in the research of
question and answering system. The existing question classification models are
more trained on public data sets. At present, there is a lack of question
classification data sets in specific fields, especially in the medical field.
To make up for this gap, this paper presents a data set for question
classification in the medical field. Moreover, this paper proposes a
multi-dimensional extraction of the characteristics of the question by
combining multiple neural network models, and proposes a question
classification model based on multi-dimensional feature extraction. The
experimental results show that the proposed method can effectively improve the
performance of question classification.",2022-02-01,2022,2022-02,medical
Analyzing Medical Data with Process Mining: a COVID-19 Case Study,"The recent increase in the availability of medical data, possible through
automation and digitization of medical equipment, has enabled more accurate and
complete analysis on patients' medical data through many branches of data
science. In particular, medical records that include timestamps showing the
history of a patient have enabled the representation of medical information as
sequences of events, effectively allowing to perform process mining analyses.
In this paper, we will present some preliminary findings obtained with
established process mining techniques in regard of the medical data of patients
of the Uniklinik Aachen hospital affected by the recent epidemic of COVID-19.
We show that process mining techniques are able to reconstruct a model of the
ICU treatments for COVID patients.",2022-02-08,2022,2022-02,medical
Towards a Guideline for Evaluation Metrics in Medical Image Segmentation,"In the last decade, research on artificial intelligence has seen rapid growth
with deep learning models, especially in the field of medical image
segmentation. Various studies demonstrated that these models have powerful
prediction capabilities and achieved similar results as clinicians. However,
recent studies revealed that the evaluation in image segmentation studies lacks
reliable model performance assessment and showed statistical bias by incorrect
metric implementation or usage. Thus, this work provides an overview and
interpretation guide on the following metrics for medical image segmentation
evaluation in binary as well as multi-class problems: Dice similarity
coefficient, Jaccard, Sensitivity, Specificity, Rand index, ROC curves, Cohen's
Kappa, and Hausdorff distance. As a summary, we propose a guideline for
standardized medical image segmentation evaluation to improve evaluation
quality, reproducibility, and comparability in the research field.",2022-02-10,2022,2022-02,medical
"Guidelines and Evaluation of Clinical Explainable AI in Medical Image
  Analysis","Explainable artificial intelligence (XAI) is essential for enabling clinical
users to get informed decision support from AI and comply with evidence-based
medical practice. Applying XAI in clinical settings requires proper evaluation
criteria to ensure the explanation technique is both technically sound and
clinically useful, but specific support is lacking to achieve this goal. To
bridge the research gap, we propose the Clinical XAI Guidelines that consist of
five criteria a clinical XAI needs to be optimized for. The guidelines
recommend choosing an explanation form based on Guideline 1 (G1)
Understandability and G2 Clinical relevance. For the chosen explanation form,
its specific XAI technique should be optimized for G3 Truthfulness, G4
Informative plausibility, and G5 Computational efficiency. Following the
guidelines, we conducted a systematic evaluation on a novel problem of
multi-modal medical image explanation with two clinical tasks, and proposed new
evaluation metrics accordingly. Sixteen commonly-used heatmap XAI techniques
were evaluated and found to be insufficient for clinical use due to their
failure in G3 and G4. Our evaluation demonstrated the use of Clinical XAI
Guidelines to support the design and evaluation of clinically viable XAI.",2022-02-16,2022,2022-02,medical
"Graph Convolutional Networks for Multi-modality Medical Imaging:
  Methods, Architectures, and Clinical Applications","Image-based characterization and disease understanding involve integrative
analysis of morphological, spatial, and topological information across
biological scales. The development of graph convolutional networks (GCNs) has
created the opportunity to address this information complexity via graph-driven
architectures, since GCNs can perform feature aggregation, interaction, and
reasoning with remarkable flexibility and efficiency. These GCNs capabilities
have spawned a new wave of research in medical imaging analysis with the
overarching goal of improving quantitative disease understanding, monitoring,
and diagnosis. Yet daunting challenges remain for designing the important
image-to-graph transformation for multi-modality medical imaging and gaining
insights into model interpretation and enhanced clinical decision support. In
this review, we present recent GCNs developments in the context of medical
image analysis including imaging data from radiology and histopathology. We
discuss the fast-growing use of graph network architectures in medical image
analysis to improve disease diagnosis and patient outcomes in clinical
practice. To foster cross-disciplinary research, we present GCNs technical
advancements, emerging medical applications, identify common challenges in the
use of image-based GCNs and their extensions in model interpretation,
large-scale benchmarks that promise to transform the scope of medical image
studies and related graph-driven medical research.",2022-02-17,2022,2022-02,medical
DialMed: A Dataset for Dialogue-based Medication Recommendation,"Medication recommendation is a crucial task for intelligent healthcare
systems. Previous studies mainly recommend medications with electronic health
records (EHRs). However, some details of interactions between doctors and
patients may be ignored or omitted in EHRs, which are essential for automatic
medication recommendation. Therefore, we make the first attempt to recommend
medications with the conversations between doctors and patients. In this work,
we construct DIALMED, the first high-quality dataset for medical dialogue-based
medication recommendation task. It contains 11,996 medical dialogues related to
16 common diseases from 3 departments and 70 corresponding common medications.
Furthermore, we propose a Dialogue structure and Disease knowledge aware
Network (DDN), where a QA Dialogue Graph mechanism is designed to model the
dialogue structure and the knowledge graph is used to introduce external
disease knowledge. The extensive experimental results demonstrate that the
proposed method is a promising solution to recommend medications with medical
dialogues. The dataset and code are available at
https://github.com/f-window/DialMed.",2022-02-22,2022,2022-02,medical
Application of DatasetGAN in medical imaging: preliminary studies,"Generative adversarial networks (GANs) have been widely investigated for many
potential applications in medical imaging. DatasetGAN is a recently proposed
framework based on modern GANs that can synthesize high-quality segmented
images while requiring only a small set of annotated training images. The
synthesized annotated images could be potentially employed for many medical
imaging applications, where images with segmentation information are required.
However, to the best of our knowledge, there are no published studies focusing
on its applications to medical imaging. In this work, preliminary studies were
conducted to investigate the utility of DatasetGAN in medical imaging. Three
improvements were proposed to the original DatasetGAN framework, considering
the unique characteristics of medical images. The synthesized segmented images
by DatasetGAN were visually evaluated. The trained DatasetGAN was further
analyzed by evaluating the performance of a pre-defined image segmentation
technique, which was trained by the use of the synthesized datasets. The
effectiveness, concerns, and potential usage of DatasetGAN were discussed.",2022-02-27,2022,2022-02,medical
Hierarchical BERT for Medical Document Understanding,"Medical document understanding has gained much attention recently. One
representative task is the International Classification of Disease (ICD)
diagnosis code assignment. Existing work adopts either RNN or CNN as the
backbone network because the vanilla BERT cannot handle well long documents
(>2000 to kens). One issue shared across all these approaches is that they are
over specific to the ICD code assignment task, losing generality to give the
whole document-level and sentence-level embedding. As a result, it is not
straight-forward to direct them to other downstream NLU tasks. Motivated by
these observations, we propose Medical Document BERT (MDBERT) for long medical
document understanding tasks. MDBERT is not only effective in learning
representations at different levels of semantics but efficient in encoding long
documents by leveraging a bottom-up hierarchical architecture. Compared to
vanilla BERT solutions: 1, MDBERT boosts the performance up to relatively 20%
on the MIMIC-III dataset, making it comparable to current SOTA solutions; 2, it
cuts the computational complexity on self-attention modules to less than 1/100.
Other than the ICD code assignment, we conduct a variety of other NLU tasks on
a large commercial dataset named as TrialTrove, to showcase MDBERT's strength
in delivering different levels of semantics.",2022-03-11,2022,2022-03,medical
"Evaluating Explainable AI on a Multi-Modal Medical Imaging Task: Can
  Existing Algorithms Fulfill Clinical Requirements?","Being able to explain the prediction to clinical end-users is a necessity to
leverage the power of artificial intelligence (AI) models for clinical decision
support. For medical images, a feature attribution map, or heatmap, is the most
common form of explanation that highlights important features for AI models'
prediction. However, it is unknown how well heatmaps perform on explaining
decisions on multi-modal medical images, where each image modality or channel
visualizes distinct clinical information of the same underlying biomedical
phenomenon. Understanding such modality-dependent features is essential for
clinical users' interpretation of AI decisions. To tackle this clinically
important but technically ignored problem, we propose the modality-specific
feature importance (MSFI) metric. It encodes clinical image and explanation
interpretation patterns of modality prioritization and modality-specific
feature localization. We conduct a clinical requirement-grounded, systematic
evaluation using computational methods and a clinician user study. Results show
that the examined 16 heatmap algorithms failed to fulfill clinical requirements
to correctly indicate AI model decision process or decision quality. The
evaluation and MSFI metric can guide the design and selection of XAI algorithms
to meet clinical requirements on multi-modal explanation.",2022-03-12,2022,2022-03,medical
"Review of Disentanglement Approaches for Medical Applications -- Towards
  Solving the Gordian Knot of Generative Models in Healthcare","Deep neural networks are commonly used for medical purposes such as image
generation, segmentation, or classification. Besides this, they are often
criticized as black boxes as their decision process is often not human
interpretable. Encouraging the latent representation of a generative model to
be disentangled offers new perspectives of control and interpretability.
Understanding the data generation process could help to create artificial
medical data sets without violating patient privacy, synthesizing different
data modalities, or discovering data generating characteristics. These
characteristics might unravel novel relationships that can be related to
genetic traits or patient outcomes. In this paper, we give a comprehensive
overview of popular generative models, like Generative Adversarial Networks
(GANs), Variational Autoencoders (VAEs), and Flow-based Models. Furthermore, we
summarize the different notions of disentanglement, review approaches to
disentangle latent space representations and metrics to evaluate the degree of
disentanglement. After introducing the theoretical frameworks, we give an
overview of recent medical applications and discuss the impact and importance
of disentanglement approaches for medical applications.",2022-03-21,2022,2022-03,medical
"Visual explanations for polyp detection: How medical doctors assess
  intrinsic versus extrinsic explanations","Deep learning has in recent years achieved immense success in all areas of
computer vision and has the potential of assisting medical doctors in analyzing
visual content for disease and other abnormalities. However, the current state
of deep learning is very much a black box, making medical professionals highly
skeptical about integrating these methods into clinical practice. Several
methods have been proposed in order to shine some light onto these black boxes,
but there is no consensus on the opinion of the medical doctors that will
consume these explanations. This paper presents a study asking medical doctors
about their opinion of current state-of-the-art explainable artificial
intelligence methods when applied to a gastrointestinal disease detection use
case. We compare two different categories of explanation methods, intrinsic and
extrinsic, and gauge their opinion of the current value of these explanations.
The results indicate that intrinsic explanations are preferred and that
explanation.",2022-03-23,2022,2022-03,medical
"MedMCQA : A Large-scale Multi-Subject Multi-Choice Dataset for Medical
  domain Question Answering","This paper introduces MedMCQA, a new large-scale, Multiple-Choice Question
Answering (MCQA) dataset designed to address real-world medical entrance exam
questions. More than 194k high-quality AIIMS \& NEET PG entrance exam MCQs
covering 2.4k healthcare topics and 21 medical subjects are collected with an
average token length of 12.77 and high topical diversity. Each sample contains
a question, correct answer(s), and other options which requires a deeper
language understanding as it tests the 10+ reasoning abilities of a model
across a wide range of medical subjects \& topics. A detailed explanation of
the solution, along with the above information, is provided in this study.",2022-03-27,2022,2022-03,medical
"Access to care: analysis of the geographical distribution of healthcare
  using Linked Open Data","Background: Access to medical care is strongly dependent on resource
allocation, such as the geographical distribution of medical facilities.
Nevertheless, this data is usually restricted to country official
documentation, not available to the public. While some medical facilities' data
is accessible as semantic resources on the Web, it is not consistent in its
modeling and has yet to be integrated into a complete, open, and specialized
repository. This work focuses on generating a comprehensive semantic dataset of
medical facilities worldwide containing extensive information about such
facilities' geo-location.
  Results: For this purpose, we collect, align, and link various open-source
databases where medical facilities' information may be present. This work
allows us to evaluate each data source along various dimensions, such as
completeness, correctness, and interlinking with other sources, all critical
aspects of current knowledge representation technologies.
  Conclusions: Our contributions directly benefit stakeholders in the
biomedical and health domain (patients, healthcare professionals, companies,
regulatory authorities, and researchers), who will now have a better overview
of the access to and distribution of medical facilities.",2022-04-11,2022,2022-04,medical
"Optimally Designing Cybersecurity Insurance Contracts to Encourage the
  Sharing of Medical Data","Though the sharing of medical data has the potential to lead to breakthroughs
in health care, the sharing process itself exposes patients and health care
providers to various risks. Patients face risks due to the possible loss in
privacy or livelihood that can occur when medical data is stolen or used in
non-permitted ways, whereas health care providers face risks due to the
associated liability. For medical data, these risks persist even after
anonymizing/deidentifying, according to the standards defined in existing
legislation, the data sets prior to sharing, because shared medical data can
often be deanonymized/reidentified using advanced artificial intelligence and
machine learning methodologies. As a result, health care providers are hesitant
to share medical data. One possible solution to encourage health care providers
to responsibly share data is through the use of cybersecurity insurance
contracts. This paper studies the problem of designing optimal cybersecurity
insurance contracts, with the goal of encouraging the sharing of the medical
data. We use a principal-agent model with moral hazard to model various
scenarios, derive the optimal contract, discuss its implications, and perform
numerical case studies. In particular, we consider two scenarios: the first
scenario is where a health care provider is selling medical data to a
technology firm who is developing an artificial intelligence algorithm using
the shared data. The second scenario is where a group of health care providers
share health data amongst themselves for the purpose of furthering medical
research using the aggregated medical data.",2022-04-13,2022,2022-04,medical
"IOP-FL: Inside-Outside Personalization for Federated Medical Image
  Segmentation","Federated learning (FL) allows multiple medical institutions to
collaboratively learn a global model without centralizing client data. It is
difficult, if possible at all, for such a global model to commonly achieve
optimal performance for each individual client, due to the heterogeneity of
medical images from various scanners and patient demographics. This problem
becomes even more significant when deploying the global model to unseen clients
outside the FL with unseen distributions not presented during federated
training. To optimize the prediction accuracy of each individual client for
medical imaging tasks, we propose a novel unified framework for both
\textit{Inside and Outside model Personalization in FL} (IOP-FL). Our inside
personalization uses a lightweight gradient-based approach that exploits the
local adapted model for each client, by accumulating both the global gradients
for common knowledge and the local gradients for client-specific optimization.
Moreover, and importantly, the obtained local personalized models and the
global model can form a diverse and informative routing space to personalize an
adapted model for outside FL clients. Hence, we design a new test-time routing
scheme using the consistency loss with a shape constraint to dynamically
incorporate the models, given the distribution information conveyed by the test
data. Our extensive experimental results on two medical image segmentation
tasks present significant improvements over SOTA methods on both inside and
outside personalization, demonstrating the potential of our IOP-FL scheme for
clinical practice.",2022-04-16,2022,2022-04,medical
U-Net and its variants for Medical Image Segmentation : A short review,"The paper is a short review of medical image segmentation using U-Net and its
variants. As we understand going through a medical images is not an easy job
for any clinician either radiologist or pathologist. Analysing medical images
is the only way to perform non-invasive diagnosis. Segmenting out the regions
of interest has significant importance in medical images and is key for
diagnosis. This paper also gives a bird eye view of how medical image
segmentation has evolved. Also discusses challenge's and success of the deep
neural architectures. Following how different hybrid architectures have built
upon strong techniques from visual recognition tasks. In the end we will see
current challenges and future directions for medical image segmentation(MIS).",2022-04-17,2022,2022-04,medical
"Factors that influence the adoption of human-AI collaboration in
  clinical decision-making","Recent developments in Artificial Intelligence (AI) have fueled the emergence
of human-AI collaboration, a setting where AI is a coequal partner. Especially
in clinical decision-making, it has the potential to improve treatment quality
by assisting overworked medical professionals. Even though research has started
to investigate the utilization of AI for clinical decision-making, its
potential benefits do not imply its adoption by medical professionals. While
several studies have started to analyze adoption criteria from a technical
perspective, research providing a human-centered perspective with a focus on
AI's potential for becoming a coequal team member in the decision-making
process remains limited. Therefore, in this work, we identify factors for the
adoption of human-AI collaboration by conducting a series of semi-structured
interviews with experts in the healthcare domain. We identify six relevant
adoption factors and highlight existing tensions between them and effective
human-AI collaboration.",2022-04-19,2022,2022-04,medical
"LingYi: Medical Conversational Question Answering System based on
  Multi-modal Knowledge Graphs","The medical conversational system can relieve the burden of doctors and
improve the efficiency of healthcare, especially during the pandemic. This
paper presents a medical conversational question answering (CQA) system based
on the multi-modal knowledge graph, namely ""LingYi"", which is designed as a
pipeline framework to maintain high flexibility. Our system utilizes automated
medical procedures including medical triage, consultation, image-text drug
recommendation and record. To conduct knowledge-grounded dialogues with
patients, we first construct a Chinese Medical Multi-Modal Knowledge Graph
(CM3KG) and collect a large-scale Chinese Medical CQA (CMCQA) dataset. Compared
with the other existing medical question-answering systems, our system adopts
several state-of-the-art technologies including medical entity disambiguation
and medical dialogue generation, which is more friendly to provide medical
services to patients. In addition, we have open-sourced our codes which contain
back-end models and front-end web pages at https://github.com/WENGSYX/LingYi.
The datasets including CM3KG at https://github.com/WENGSYX/CM3KG and CMCQA at
https://github.com/WENGSYX/CMCQA are also released to further promote future
research.",2022-04-20,2022,2022-04,medical
"MedFACT: Modeling Medical Feature Correlations in Patient Health
  Representation Learning via Feature Clustering","In healthcare prediction tasks, it is essential to exploit the correlations
between medical features and learn better patient health representations.
Existing methods try to estimate feature correlations only from data, or
increase the quality of estimation by introducing task-specific medical
knowledge. However, such methods either are difficult to estimate the feature
correlations due to insufficient training samples, or cannot be generalized to
other tasks due to reliance on specific knowledge. There are medical research
revealing that not all the medical features are strongly correlated. Thus, to
address the issues, we expect to group up strongly correlated features and
learn feature correlations in a group-wise manner to reduce the learning
complexity without losing generality. In this paper, we propose a general
patient health representation learning framework MedFACT. We estimate
correlations via measuring similarity between temporal patterns of medical
features with kernel methods, and cluster features with strong correlations
into groups. The feature group is further formulated as a correlation graph,
and we employ graph convolutional networks to conduct group-wise feature
interactions for better representation learning. Experiments on two real-world
datasets demonstrate the superiority of MedFACT. The discovered medical
findings are also confirmed by literature, providing valuable medical insights
and explanations.",2022-04-21,2022,2022-04,medical
"KnowAugNet: Multi-Source Medical Knowledge Augmented Medication
  Prediction Network with Multi-Level Graph Contrastive Learning","Predicting medications is a crucial task in many intelligent healthcare
systems. It can assist doctors in making informed medication decisions for
patients according to electronic medical records (EMRs). However, medication
prediction is a challenging data mining task due to the complex relations
between medical codes. Most existing studies focus on utilizing inherent
relations between homogeneous codes of medical ontology graph to enhance their
representations using supervised methods, and few studies pay attention to the
valuable relations between heterogeneous or homogeneous medical codes from
history EMRs, which further limits the prediction performance and application
scenarios. Therefore, to address these limitations, this paper proposes
KnowAugNet, a multi-sourced medical knowledge augmented medication prediction
network which can fully capture the diverse relations between medical codes via
multi-level graph contrastive learning framework. Specifically, KnowAugNet
first leverages the graph contrastive learning using graph attention network as
the encoder to capture the implicit relations between homogeneous medical codes
from the medical ontology graph and obtains the knowledge augmented medical
codes embedding vectors. Then, it utilizes the graph contrastive learning using
a weighted graph convolutional network as the encoder to capture the
correlative relations between homogeneous or heterogeneous medical codes from
the constructed medical prior relation graph and obtains the relation augmented
medical codes embedding vectors. Finally, the augmented medical codes embedding
vectors and the supervised medical codes embedding vectors are retrieved and
input to the sequential learning network to capture the temporal relations of
medical codes and predict medications for patients.",2022-04-25,2022,2022-04,medical
Masked Image Modeling Advances 3D Medical Image Analysis,"Recently, masked image modeling (MIM) has gained considerable attention due
to its capacity to learn from vast amounts of unlabeled data and has been
demonstrated to be effective on a wide variety of vision tasks involving
natural images. Meanwhile, the potential of self-supervised learning in
modeling 3D medical images is anticipated to be immense due to the high
quantities of unlabeled images, and the expense and difficulty of quality
labels. However, MIM's applicability to medical images remains uncertain. In
this paper, we demonstrate that masked image modeling approaches can also
advance 3D medical images analysis in addition to natural images. We study how
masked image modeling strategies leverage performance from the viewpoints of 3D
medical image segmentation as a representative downstream task: i) when
compared to naive contrastive learning, masked image modeling approaches
accelerate the convergence of supervised training even faster (1.40$\times$)
and ultimately produce a higher dice score; ii) predicting raw voxel values
with a high masking ratio and a relatively smaller patch size is non-trivial
self-supervised pretext-task for medical images modeling; iii) a lightweight
decoder or projection head design for reconstruction is powerful for masked
image modeling on 3D medical images which speeds up training and reduce cost;
iv) finally, we also investigate the effectiveness of MIM methods under
different practical scenarios where different image resolutions and labeled
data ratios are applied.",2022-04-25,2022,2022-04,medical
"A survey on attention mechanisms for medical applications: are we moving
  towards better algorithms?","The increasing popularity of attention mechanisms in deep learning algorithms
for computer vision and natural language processing made these models
attractive to other research domains. In healthcare, there is a strong need for
tools that may improve the routines of the clinicians and the patients.
Naturally, the use of attention-based algorithms for medical applications
occurred smoothly. However, being healthcare a domain that depends on
high-stake decisions, the scientific community must ponder if these
high-performing algorithms fit the needs of medical applications. With this
motto, this paper extensively reviews the use of attention mechanisms in
machine learning (including Transformers) for several medical applications.
This work distinguishes itself from its predecessors by proposing a critical
analysis of the claims and potentialities of attention mechanisms presented in
the literature through an experimental case study on medical image
classification with three different use cases. These experiments focus on the
integrating process of attention mechanisms into established deep learning
architectures, the analysis of their predictive power, and a visual assessment
of their saliency maps generated by post-hoc explanation methods. This paper
concludes with a critical analysis of the claims and potentialities presented
in the literature about attention mechanisms and proposes future research lines
in medical applications that may benefit from these frameworks.",2022-04-26,2022,2022-04,medical
"CATNet: Cross-event Attention-based Time-aware Network for Medical Event
  Prediction","Medical event prediction (MEP) is a fundamental task in the medical domain,
which needs to predict medical events, including medications, diagnosis codes,
laboratory tests, procedures, outcomes, and so on, according to historical
medical records. The task is challenging as medical data is a type of complex
time series data with heterogeneous and temporal irregular characteristics.
Many machine learning methods that consider the two characteristics have been
proposed for medical event prediction. However, most of them consider the two
characteristics separately and ignore the correlations among different types of
medical events, especially relations between historical medical events and
target medical events. In this paper, we propose a novel neural network based
on attention mechanism, called cross-event attention-based time-aware network
(CATNet), for medical event prediction. It is a time-aware, event-aware and
task-adaptive method with the following advantages: 1) modeling heterogeneous
information and temporal information in a unified way and considering temporal
irregular characteristics locally and globally respectively, 2) taking full
advantage of correlations among different types of events via cross-event
attention. Experiments on two public datasets (MIMIC-III and eICU) show CATNet
can be adaptive with different MEP tasks and outperforms other state-of-the-art
methods on various MEP tasks. The source code of CATNet will be released after
this manuscript is accepted.",2022-04-29,2022,2022-04,medical
"Understanding Transfer Learning for Chest Radiograph Clinical Report
  Generation with Modified Transformer Architectures","The image captioning task is increasingly prevalent in artificial
intelligence applications for medicine. One important application is clinical
report generation from chest radiographs. The clinical writing of unstructured
reports is time consuming and error-prone. An automated system would improve
standardization, error reduction, time consumption, and medical accessibility.
In this paper we demonstrate the importance of domain specific pre-training and
propose a modified transformer architecture for the medical image captioning
task. To accomplish this, we train a series of modified transformers to
generate clinical reports from chest radiograph image input. These modified
transformers include: a meshed-memory augmented transformer architecture with
visual extractor using ImageNet pre-trained weights, a meshed-memory augmented
transformer architecture with visual extractor using CheXpert pre-trained
weights, and a meshed-memory augmented transformer whose encoder is passed the
concatenated embeddings using both ImageNet pre-trained weights and CheXpert
pre-trained weights. We use BLEU(1-4), ROUGE-L, CIDEr, and the clinical
CheXbert F1 scores to validate our models and demonstrate competitive scores
with state of the art models. We provide evidence that ImageNet pre-training is
ill-suited for the medical image captioning task, especially for less frequent
conditions (eg: enlarged cardiomediastinum, lung lesion, pneumothorax).
Furthermore, we demonstrate that the double feature model improves performance
for specific medical conditions (edema, consolidation, pneumothorax, support
devices) and overall CheXbert F1 score, and should be further developed in
future work. Such a double feature model, including both ImageNet pre-training
as well as domain specific pre-training, could be used in a wide range of image
captioning models in medicine.",2022-05-05,2022,2022-05,medical
"Deep Supervised Information Bottleneck Hashing for Cross-modal Retrieval
  based Computer-aided Diagnosis","Mapping X-ray images, radiology reports, and other medical data as binary
codes in the common space, which can assist clinicians to retrieve
pathology-related data from heterogeneous modalities (i.e., hashing-based
cross-modal medical data retrieval), provides a new view to promot
computeraided diagnosis. Nevertheless, there remains a barrier to boost medical
retrieval accuracy: how to reveal the ambiguous semantics of medical data
without the distraction of superfluous information. To circumvent this
drawback, we propose Deep Supervised Information Bottleneck Hashing (DSIBH),
which effectively strengthens the discriminability of hash codes. Specifically,
the Deep Deterministic Information Bottleneck (Yu, Yu, and Principe 2021) for
single modality is extended to the cross-modal scenario. Benefiting from this,
the superfluous information is reduced, which facilitates the discriminability
of hash codes. Experimental results demonstrate the superior accuracy of the
proposed DSIBH compared with state-of-the-arts in cross-modal medical data
retrieval tasks.",2022-05-06,2022,2022-05,medical
"Skin disease diagnosis using image analysis and natural language
  processing","In Zambia, there is a serious shortage of medical staff where each
practitioner attends to about 17000 patients in a given district while still,
other patients travel over 10 km to access the basic medical services. In this
research, we implement a deep learning model that can perform the clinical
diagnosis process. The study will prove whether image analysis is capable of
performing clinical diagnosis. It will also enable us to understand if we can
use image analysis to lessen the workload on medical practitioners by
delegating some tasks to an AI. The success of this study has the potential to
increase the accessibility of medical services to Zambians, which is one of the
national goals of Vision 2030.",2022-05-09,2022,2022-05,medical
"Explainable Deep Learning Methods in Medical Image Classification: A
  Survey","The remarkable success of deep learning has prompted interest in its
application to medical imaging diagnosis. Even though state-of-the-art deep
learning models have achieved human-level accuracy on the classification of
different types of medical data, these models are hardly adopted in clinical
workflows, mainly due to their lack of interpretability. The black-box-ness of
deep learning models has raised the need for devising strategies to explain the
decision process of these models, leading to the creation of the topic of
eXplainable Artificial Intelligence (XAI). In this context, we provide a
thorough survey of XAI applied to medical imaging diagnosis, including visual,
textual, example-based and concept-based explanation methods. Moreover, this
work reviews the existing medical imaging datasets and the existing metrics for
evaluating the quality of the explanations. In addition, we include a
performance comparison among a set of report generation-based methods. Finally,
the major challenges in applying XAI to medical imaging and the future research
directions on the topic are also discussed.",2022-05-10,2022,2022-05,medical
"Using artificial intelligence to detect chest X-rays with no significant
  findings in a primary health care setting in Oulu, Finland","Objectives: To assess the use of artificial intelligence-based software in
ruling out chest X-ray cases, with no significant findings in a primary health
care setting.
  Methods: In this retrospective study, a commercially available artificial
intelligence (AI) software was used to analyse 10 000 chest X-rays of Finnish
primary health care patients. In studies with a mismatch between an AI normal
report and the original radiologist report, a consensus read by two
board-certified radiologists was conducted to make the final diagnosis.
  Results: After the exclusion of cases not meeting the study criteria, 9579
cases were analysed by AI. Of these cases, 4451 were considered normal in the
original radiologist report and 4644 after the consensus reading. The number of
cases correctly found nonsignificant by AI was 1692 (17.7% of all studies and
36.4% of studies with no significant findings). After the consensus read, there
were nine confirmed false-negative studies. These studies included four cases
of slightly enlarged heart size, four cases of slightly increased pulmonary
opacification and one case with a small unilateral pleural effusion. This gives
the AI a sensitivity of 99.8% (95% CI= 99.65-99.92) and specificity of 36.4 %
(95% CI= 35.05-37.84) for recognising significant pathology on a chest X-ray.
  Conclusions: AI was able to correctly rule out 36.4% of chest X-rays with no
significant findings of primary health care patients, with a minimal number of
false negatives that would lead to effectively no compromise on patient safety.
No critical findings were missed by the software.",2022-05-17,2022,2022-05,medical
Robust and Efficient Medical Imaging with Self-Supervision,"Recent progress in Medical Artificial Intelligence (AI) has delivered systems
that can reach clinical expert level performance. However, such systems tend to
demonstrate sub-optimal ""out-of-distribution"" performance when evaluated in
clinical settings different from the training environment. A common mitigation
strategy is to develop separate systems for each clinical setting using
site-specific data [1]. However, this quickly becomes impractical as medical
data is time-consuming to acquire and expensive to annotate [2]. Thus, the
problem of ""data-efficient generalization"" presents an ongoing difficulty for
Medical AI development. Although progress in representation learning shows
promise, their benefits have not been rigorously studied, specifically for
out-of-distribution settings. To meet these challenges, we present REMEDIS, a
unified representation learning strategy to improve robustness and
data-efficiency of medical imaging AI. REMEDIS uses a generic combination of
large-scale supervised transfer learning with self-supervised learning and
requires little task-specific customization. We study a diverse range of
medical imaging tasks and simulate three realistic application scenarios using
retrospective data. REMEDIS exhibits significantly improved in-distribution
performance with up to 11.5% relative improvement in diagnostic accuracy over a
strong supervised baseline. More importantly, our strategy leads to strong
data-efficient generalization of medical imaging AI, matching strong supervised
baselines using between 1% to 33% of retraining data across tasks. These
results suggest that REMEDIS can significantly accelerate the life-cycle of
medical imaging AI development thereby presenting an important step forward for
medical imaging AI to deliver broad impact.",2022-05-19,2022,2022-05,medical
"Preparing data for pathological artificial intelligence with
  clinical-grade performance","[Purpose] The pathology is decisive for disease diagnosis, but relies heavily
on the experienced pathologists. Recently, pathological artificial intelligence
(PAI) is thought to improve diagnostic accuracy and efficiency. However, the
high performance of PAI based on deep learning in the laboratory generally
cannot be reproduced in the clinic. [Methods] Because the data preparation is
important for PAI, the paper has reviewed PAI-related studies in the PubMed
database published from January 2017 to February 2022, and 118 studies were
included. The in-depth analysis of methods for preparing data is performed,
including obtaining slides of pathological tissue, cleaning, screening, and
then digitizing. Expert review, image annotation, dataset division for model
training and validation are also discussed. We further discuss the reasons why
the high performance of PAI is not reproducible in the clinical practices and
show some effective ways to improve clinical performances of PAI. [Results] The
robustness of PAI depend on randomized collection of representative disease
slides, including rigorous quality control and screening, correction of digital
discrepancies, reasonable annotation, and the amount of data. The digital
pathology is fundamental of clinical-grade PAI, and the techniques of data
standardization and weakly supervised learning methods based on whole slide
image (WSI) are effective ways to overcome obstacles of performance
reproduction. [Conclusion] The representative data, the amount of labeling and
consistency from multi-centers is the key to performance reproduction. The
digital pathology for clinical diagnosis, data standardization and technique of
WSI-based weakly supervised learning hopefully build clinical-grade PAI.
Keywords: pathological artificial intelligence; data preparation;
clinical-grade; deep learning",2022-05-22,2022,2022-05,medical
"Automatic Quantification of Volumes and Biventricular Function in
  Cardiac Resonance. Validation of a New Artificial Intelligence Approach","Background: Artificial intelligence techniques have shown great potential in
cardiology, especially in quantifying cardiac biventricular function, volume,
mass, and ejection fraction (EF). However, its use in clinical practice is not
straightforward due to its poor reproducibility with cases from daily practice,
among other reasons. Objectives: To validate a new artificial intelligence tool
in order to quantify the cardiac biventricular function (volume, mass, and EF).
To analyze its robustness in the clinical area, and the computational times
compared with conventional methods. Methods: A total of 189 patients were
analyzed: 89 from a regional center and 100 from a public center. The method
proposes two convolutional networks that include anatomical information of the
heart to reduce classification errors. Results: A high concordance (Pearson
coefficient) was observed between manual quantification and the proposed
quantification of cardiac function (0.98, 0.92, 0.96 and 0.8 for volumes and
biventricular EF) in about 5 seconds per study. Conclusions: This method
quantifies biventricular function and volumes in seconds with an accuracy
equivalent to that of a specialist.",2022-06-03,2022,2022-06,medical
Future Artificial Intelligence tools and perspectives in medicine,"Purpose of review: Artificial intelligence (AI) has become popular in medical
applications, specifically as a clinical support tool for computer-aided
diagnosis. These tools are typically employed on medical data (i.e., image,
molecular data, clinical variables, etc.) and used the statistical and machine
learning methods to measure the model performance. In this review, we
summarized and discussed the most recent radiomic pipeline used for clinical
analysis. Recent findings:Currently, limited management of cancers benefits
from artificial intelligence, mostly related to a computer-aided diagnosis that
avoids a biopsy analysis that presents additional risks and costs. Most AI
tools are based on imaging features, known as radiomic analysis that can be
refined into predictive models in non-invasively acquired imaging data. This
review explores the progress of AI-based radiomic tools for clinical
applications with a brief description of necessary technical steps. Explaining
new radiomic approaches based on deep learning techniques will explain how the
new radiomic models (deep radiomic analysis) can benefit from deep
convolutional neural networks and be applied on limited data sets. Summary: To
consider the radiomic algorithms, further investigations are recommended to
involve deep learning in radiomic models with additional validation steps on
various cancer types.",2022-06-04,2022,2022-06,medical
"Bootstrapping Semi-supervised Medical Image Segmentation with
  Anatomical-aware Contrastive Distillation","Contrastive learning has shown great promise over annotation scarcity
problems in the context of medical image segmentation. Existing approaches
typically assume a balanced class distribution for both labeled and unlabeled
medical images. However, medical image data in reality is commonly imbalanced
(i.e., multi-class label imbalance), which naturally yields blurry contours and
usually incorrectly labels rare objects. Moreover, it remains unclear whether
all negative samples are equally negative. In this work, we present ACTION, an
Anatomical-aware ConTrastive dIstillatiON framework, for semi-supervised
medical image segmentation. Specifically, we first develop an iterative
contrastive distillation algorithm by softly labeling the negatives rather than
binary supervision between positive and negative pairs. We also capture more
semantically similar features from the randomly chosen negative set compared to
the positives to enforce the diversity of the sampled data. Second, we raise a
more important question: Can we really handle imbalanced samples to yield
better performance? Hence, the key innovation in ACTION is to learn global
semantic relationship across the entire dataset and local anatomical features
among the neighbouring pixels with minimal additional memory footprint. During
the training, we introduce anatomical contrast by actively sampling a sparse
set of hard negative pixels, which can generate smoother segmentation
boundaries and more accurate predictions. Extensive experiments across two
benchmark datasets and different unlabeled settings show that ACTION
significantly outperforms the current state-of-the-art semi-supervised methods.",2022-06-06,2022,2022-06,medical
"Implementation of a Modified U-Net for Medical Image Segmentation on
  Edge Devices","Deep learning techniques, particularly convolutional neural networks, have
shown great potential in computer vision and medical imaging applications.
However, deep learning models are computationally demanding as they require
enormous computational power and specialized processing hardware for model
training. To make these models portable and compatible for prototyping, their
implementation on low-power devices is imperative. In this work, we present the
implementation of Modified U-Net on Intel Movidius Neural Compute Stick 2
(NCS-2) for the segmentation of medical images. We selected U-Net because, in
medical image segmentation, U-Net is a prominent model that provides improved
performance for medical image segmentation even if the dataset size is small.
The modified U-Net model is evaluated for performance in terms of dice score.
Experiments are reported for segmentation task on three medical imaging
datasets: BraTs dataset of brain MRI, heart MRI dataset, and Ziehl-Neelsen
sputum smear microscopy image (ZNSDB) dataset. For the proposed model, we
reduced the number of parameters from 30 million in the U-Net model to 0.49
million in the proposed architecture. Experimental results show that the
modified U-Net provides comparable performance while requiring significantly
lower resources and provides inference on the NCS-2. The maximum dice scores
recorded are 0.96 for the BraTs dataset, 0.94 for the heart MRI dataset, and
0.74 for the ZNSDB dataset.",2022-06-06,2022,2022-06,medical
"Improving Medical Systems in the United States using Knowledge-Based
  Systems","America has one of the best medical systems in the world. The medical
treatment care options offered by the medical system make it sophisticated.
However, many American patients are not receiving health care on a regular
basis, and at the same time, they cannot afford it. Also, the current medical
system has many flaws such as high medical treatment costs and lack of doctors
to accommodate many patients. This paper presents the principles of medical
artificial intelligence called the knowledge based system. Doctors can remotely
check and monitor their patients health data, medical history, how and what
medical tests were done, and the lab results. The patients have access to
detailed health information online and do not need to make an appointment with
doctors to check their health on a daily basis. One doctor can check many
patients simultaneously online (when medical centers are understaffed) and do
not need to spend a lot of time with patients. Thus, doctors save more money
for patients, because patients will no longer be transporting to medical
centers to receive routine health check-ups. Patients do not need to overpay
for their insurance because they will have access to the knowledge-based
system, and the system will save the patients money to have their health
checked and reduce the number of unnecessary medical exams. This paper
undertakes a brief overview of research work done in a knowledge based system
rule based expert systems in the field of medical practices.",2022-06-07,2022,2022-06,medical
A Review of Causality for Learning Algorithms in Medical Image Analysis,"Medical image analysis is a vibrant research area that offers doctors and
medical practitioners invaluable insight and the ability to accurately diagnose
and monitor disease. Machine learning provides an additional boost for this
area. However, machine learning for medical image analysis is particularly
vulnerable to natural biases like domain shifts that affect algorithmic
performance and robustness. In this paper we analyze machine learning for
medical image analysis within the framework of Technology Readiness Levels and
review how causal analysis methods can fill a gap when creating robust and
adaptable medical image analysis algorithms. We review methods using causality
in medical imaging AI/ML and find that causal analysis has the potential to
mitigate critical problems for clinical translation but that uptake and
clinical downstream research has been limited so far.",2022-06-11,2022,2022-06,medical
Medical Dialogue Response Generation with Pivotal Information Recalling,"Medical dialogue generation is an important yet challenging task. Most
previous works rely on the attention mechanism and large-scale pretrained
language models. However, these methods often fail to acquire pivotal
information from the long dialogue history to yield an accurate and informative
response, due to the fact that the medical entities usually scatters throughout
multiple utterances along with the complex relationships between them. To
mitigate this problem, we propose a medical response generation model with
Pivotal Information Recalling (MedPIR), which is built on two components, i.e.,
knowledge-aware dialogue graph encoder and recall-enhanced generator. The
knowledge-aware dialogue graph encoder constructs a dialogue graph by
exploiting the knowledge relationships between entities in the utterances, and
encodes it with a graph attention network. Then, the recall-enhanced generator
strengthens the usage of these pivotal information by generating a summary of
the dialogue before producing the actual response. Experimental results on two
large-scale medical dialogue datasets show that MedPIR outperforms the strong
baselines in BLEU scores and medical entities F1 measure.",2022-06-17,2022,2022-06,medical
Autoencoder-based Attribute Noise Handling Method for Medical Data,"Medical datasets are particularly subject to attribute noise, that is,
missing and erroneous values. Attribute noise is known to be largely
detrimental to learning performances. To maximize future learning performances
it is primordial to deal with attribute noise before any inference. We propose
a simple autoencoder-based preprocessing method that can correct mixed-type
tabular data corrupted by attribute noise. No other method currently exists to
handle attribute noise in tabular data. We experimentally demonstrate that our
method outperforms both state-of-the-art imputation methods and noise
correction methods on several real-world medical datasets.",2022-06-20,2022,2022-06,medical
"Automated Systems For Diagnosis of Dysgraphia in Children: A Survey and
  Novel Framework","Learning disabilities, which primarily interfere with the basic learning
skills such as reading, writing and math, are known to affect around 10% of
children in the world. The poor motor skills and motor coordination as part of
the neurodevelopmental disorder can become a causative factor for the
difficulty in learning to write (dysgraphia), hindering the academic track of
an individual. The signs and symptoms of dysgraphia include but are not limited
to irregular handwriting, improper handling of writing medium, slow or labored
writing, unusual hand position, etc. The widely accepted assessment criterion
for all the types of learning disabilities is the examination performed by
medical experts. The few available artificial intelligence-powered screening
systems for dysgraphia relies on the distinctive features of handwriting from
the corresponding images.This work presents a review of the existing automated
dysgraphia diagnosis systems for children in the literature. The main focus of
the work is to review artificial intelligence-based systems for dysgraphia
diagnosis in children. This work discusses the data collection method,
important handwriting features, machine learning algorithms employed in the
literature for the diagnosis of dysgraphia. Apart from that, this article
discusses some of the non-artificial intelligence-based automated systems also.
Furthermore, this article discusses the drawbacks of existing systems and
proposes a novel framework for dysgraphia diagnosis.",2022-06-27,2022,2022-06,medical
GERNERMED++: Transfer Learning in German Medical NLP,"We present a statistical model for German medical natural language processing
trained for named entity recognition (NER) as an open, publicly available
model. The work serves as a refined successor to our first GERNERMED model
which is substantially outperformed by our work. We demonstrate the
effectiveness of combining multiple techniques in order to achieve strong
results in entity recognition performance by the means of transfer-learning on
pretrained deep language models (LM), word-alignment and neural machine
translation. Due to the sparse situation on open, public medical entity
recognition models for German texts, this work offers benefits to the German
research community on medical NLP as a baseline model. Since our model is based
on public English data, its weights are provided without legal restrictions on
usage and distribution. The sample code and the statistical model is available
at: https://github.com/frankkramer-lab/GERNERMED-pp",2022-06-29,2022,2022-06,medical
"Backdoor Attack is a Devil in Federated GAN-based Medical Image
  Synthesis","Deep Learning-based image synthesis techniques have been applied in
healthcare research for generating medical images to support open research.
Training generative adversarial neural networks (GAN) usually requires large
amounts of training data. Federated learning (FL) provides a way of training a
central model using distributed data from different medical institutions while
keeping raw data locally. However, FL is vulnerable to backdoor attack, an
adversarial by poisoning training data, given the central server cannot access
the original data directly. Most backdoor attack strategies focus on
classification models and centralized domains. In this study, we propose a way
of attacking federated GAN (FedGAN) by treating the discriminator with a
commonly used data poisoning strategy in backdoor attack classification models.
We demonstrate that adding a small trigger with size less than 0.5 percent of
the original image size can corrupt the FL-GAN model. Based on the proposed
attack, we provide two effective defense strategies: global malicious detection
and local training regularization. We show that combining the two defense
strategies yields a robust medical image generation.",2022-07-02,2022,2022-07,medical
"Complementary artificial intelligence designed to augment human
  discovery","Neither artificial intelligence designed to play Turing's imitation game, nor
augmented intelligence built to maximize the human manipulation of information
are tuned to accelerate innovation and improve humanity's collective advance
against its greatest challenges. We reconceptualize and pilot beneficial AI to
radically augment human understanding by complementing rather than competing
with human cognitive capacity. Our approach to complementary intelligence
builds on insights underlying the wisdom of crowds, which hinges on the
independence and diversity of crowd members' information and approach. By
programmatically incorporating information on the evolving distribution of
scientific expertise from research papers, our approach follows the
distribution of content in the literature while avoiding the scientific crowd
and the hypotheses cognitively available to it. We use this approach to
generate valuable predictions for what materials possess valuable
energy-related properties (e.g., thermoelectricity), and what compounds possess
valuable medical properties (e.g., asthma) that complement the human scientific
crowd. We demonstrate that our complementary predictions, if identified by
human scientists and inventors at all, are only discovered years further into
the future. When we evaluate the promise of our predictions with
first-principles equations, we demonstrate that increased complementarity of
our predictions does not decrease and in some cases increases the probability
that the predictions possess the targeted properties. In summary, by tuning AI
to avoid the crowd, we can generate hypotheses unlikely to be imagined or
pursued until the distant future and promise to punctuate scientific advance.
By identifying and correcting for collective human bias, these models also
suggest opportunities to improve human prediction by reformulating science
education for discovery.",2022-07-02,2022,2022-07,medical
"Efficient Lung Cancer Image Classification and Segmentation Algorithm
  Based on Improved Swin Transformer","With the development of computer technology, various models have emerged in
artificial intelligence. The transformer model has been applied to the field of
computer vision (CV) after its success in natural language processing (NLP).
Radiologists continue to face multiple challenges in today's rapidly evolving
medical field, such as increased workload and increased diagnostic demands.
Although there are some conventional methods for lung cancer detection before,
their accuracy still needs to be improved, especially in realistic diagnostic
scenarios. This paper creatively proposes a segmentation method based on
efficient transformer and applies it to medical image analysis. The algorithm
completes the task of lung cancer classification and segmentation by analyzing
lung cancer data, and aims to provide efficient technical support for medical
staff. In addition, we evaluated and compared the results in various aspects.
For the classification mission, the max accuracy of Swin-T by regular training
and Swin-B in two resolutions by pre-training can be up to 82.3%. For the
segmentation mission, we use pre-training to help the model improve the
accuracy of our experiments. The accuracy of the three models reaches over 95%.
The experiments demonstrate that the algorithm can be well applied to lung
cancer classification and segmentation missions.",2022-07-04,2022,2022-07,medical
"Towards the Use of Saliency Maps for Explaining Low-Quality
  Electrocardiograms to End Users","When using medical images for diagnosis, either by clinicians or artificial
intelligence (AI) systems, it is important that the images are of high quality.
When an image is of low quality, the medical exam that produced the image often
needs to be redone. In telemedicine, a common problem is that the quality issue
is only flagged once the patient has left the clinic, meaning they must return
in order to have the exam redone. This can be especially difficult for people
living in remote regions, who make up a substantial portion of the patients at
Portal Telemedicina, a digital healthcare organization based in Brazil. In this
paper, we report on ongoing work regarding (i) the development of an AI system
for flagging and explaining low-quality medical images in real-time, (ii) an
interview study to understand the explanation needs of stakeholders using the
AI system at OurCompany, and, (iii) a longitudinal user study design to examine
the effect of including explanations on the workflow of the technicians in our
clinics. To the best of our knowledge, this would be the first longitudinal
study on evaluating the effects of XAI methods on end-users -- stakeholders
that use AI systems but do not have AI-specific expertise. We welcome feedback
and suggestions on our experimental setup.",2022-07-06,2022,2022-07,medical
"High-Resolution Swin Transformer for Automatic Medical Image
  Segmentation","The Resolution of feature maps is critical for medical image segmentation.
Most of the existing Transformer-based networks for medical image segmentation
are U-Net-like architecture that contains an encoder that utilizes a sequence
of Transformer blocks to convert the input medical image from high-resolution
representation into low-resolution feature maps and a decoder that gradually
recovers the high-resolution representation from low-resolution feature maps.
Unlike previous studies, in this paper, we utilize the network design style
from the High-Resolution Network (HRNet), replace the convolutional layers with
Transformer blocks, and continuously exchange information from the different
resolution feature maps that are generated by Transformer blocks. The newly
Transformer-based network presented in this paper is denoted as High-Resolution
Swin Transformer Network (HRSTNet). Extensive experiments illustrate that
HRSTNet can achieve comparable performance with the state-of-the-art
Transformer-based U-Net-like architecture on Brain Tumor Segmentation(BraTS)
2021 and the liver dataset from Medical Segmentation Decathlon. The code of
HRSTNet will be publicly available at https://github.com/auroua/HRSTNet.",2022-07-23,2022,2022-07,medical
AI Approaches in Processing and Using Data in Personalized Medicine,"In modern dynamic constantly developing society, more and more people suffer
from chronic and serious diseases and doctors and patients need special and
sophisticated medical and health support. Accordingly, prominent health
stakeholders have recognized the importance of development of such services to
make patients life easier. Such support requires the collection of huge amount
of patients complex data like clinical, environmental, nutritional, daily
activities, variety of data from smart wearable devices, data from clothing
equipped with sensors etc. Holistic patients data must be properly aggregated,
processed, analyzed, and presented to the doctors and caregivers to recommend
adequate treatment and actions to improve patients health related parameters
and general wellbeing. Advanced artificial intelligence techniques offer the
opportunity to analyze such big data, consume them, and derive new knowledge to
support personalized medical decisions. New approaches like those based on
advanced machine learning, federated learning, transfer learning, explainable
artificial intelligence open new paths for more quality use of health and
medical data in future. In this paper, we will present some crucial aspects and
characteristic examples in the area of application of a range of artificial
intelligence approaches in personalized medical decisions.",2022-07-26,2022,2022-07,medical
"Remote Medication Status Prediction for Individuals with Parkinson's
  Disease using Time-series Data from Smartphones","Medication for neurological diseases such as the Parkinson's disease usually
happens remotely away from hospitals. Such out-of-lab environments pose
challenges in collecting timely and accurate health status data. Individual
differences in behavioral signals collected from wearable sensors also lead to
difficulties in adopting current general machine learning analysis pipelines.
To address these challenges, we present a method for predicting the medication
status of Parkinson's disease patients using the public mPower dataset, which
contains 62,182 remote multi-modal test records collected on smartphones from
487 patients. The proposed method shows promising results in predicting three
medication statuses objectively: Before Medication (AUC=0.95), After Medication
(AUC=0.958), and Another Time (AUC=0.976) by examining patient-wise historical
records with the attention weights learned through a Transformer model. Our
method provides an innovative way for personalized remote health sensing in a
timely and objective fashion which could benefit a broad range of similar
applications.",2022-07-26,2022,2022-07,medical
"Decentralized Machine Learning for Intelligent Health Care Systems on
  the Computing Continuum","The introduction of electronic personal health records (EHR) enables
nationwide information exchange and curation among different health care
systems. However, the current EHR systems do not provide transparent means for
diagnosis support, medical research or can utilize the omnipresent data
produced by the personal medical devices. Besides, the EHR systems are
centrally orchestrated, which could potentially lead to a single point of
failure. Therefore, in this article, we explore novel approaches for
decentralizing machine learning over distributed ledgers to create intelligent
EHR systems that can utilize information from personal medical devices for
improved knowledge extraction. Consequently, we proposed and evaluated a
conceptual EHR to enable anonymous predictive analysis across multiple medical
institutions. The evaluation results indicate that the decentralized EHR can be
deployed over the computing continuum with reduced machine learning time of up
to 60% and consensus latency of below 8 seconds.",2022-07-29,2022,2022-07,medical
"Diagnosis of Paratuberculosis in Histopathological Images Based on
  Explainable Artificial Intelligence and Deep Learning","Artificial intelligence holds great promise in medical imaging, especially
histopathological imaging. However, artificial intelligence algorithms cannot
fully explain the thought processes during decision-making. This situation has
brought the problem of explainability, i.e., the black box problem, of
artificial intelligence applications to the agenda: an algorithm simply
responds without stating the reasons for the given images. To overcome the
problem and improve the explainability, explainable artificial intelligence
(XAI) has come to the fore, and piqued the interest of many researchers.
Against this backdrop, this study examines a new and original dataset using the
deep learning algorithm, and visualizes the output with gradient-weighted class
activation mapping (Grad-CAM), one of the XAI applications. Afterwards, a
detailed questionnaire survey was conducted with the pathologists on these
images. Both the decision-making processes and the explanations were verified,
and the accuracy of the output was tested. The research results greatly help
pathologists in the diagnosis of paratuberculosis.",2022-08-02,2022,2022-08,medical
"Advances of Artificial Intelligence in Classical and Novel
  Spectroscopy-Based Approaches for Cancer Diagnostics. A Review","Cancer is one of the leading causes of death worldwide. Fast and safe
early-stage, pre- and intra-operative diagnostics can significantly contribute
to successful cancer identification and treatment. Artificial intelligence has
played an increasing role in the enhancement of cancer diagnostics techniques
in the last 15 years. This review covers the advances of artificial
intelligence applications in well-established techniques such as MRI and CT.
Also, it shows its high potential in combination with optical
spectroscopy-based approaches that are under development for mobile,
ultra-fast, and low-invasive diagnostics. I will show how spectroscopy-based
approaches can reduce the time of tissue preparation for pathological analysis
by making thin-slicing or haematoxylin-and-eosin staining obsolete. I will
present examples of spectroscopic tools for fast and low-invasive ex- and
in-vivo tissue classification for the determination of a tumour and its
boundaries. Also, I will discuss that, contrary to MRI and CT, spectroscopic
measurements do not require the administration of chemical agents to enhance
the quality of cancer imaging which contributes to the development of more
secure diagnostic methods. Overall, we will see that the combination of
spectroscopy and artificial intelligence constitutes a highly promising and
fast-developing field of medical technology that will soon augment available
cancer diagnostic methods.",2022-08-08,2022,2022-08,medical
"Self-supervised Multi-modal Training from Uncurated Image and Reports
  Enables Zero-shot Oversight Artificial Intelligence in Radiology","Oversight AI is an emerging concept in radiology where the AI forms a
symbiosis with radiologists by continuously supporting radiologists in their
decision-making. Recent advances in vision-language models sheds a light on the
long-standing problems of the oversight AI by the understanding both visual and
textual concepts and their semantic correspondences. However, there have been
limited successes in the application of vision-language models in the medical
domain, as the current vision-language models and learning strategies for
photographic images and captions call for the web-scale data corpus of image
and text pairs which was not often feasible in the medical domain. To address
this, here we present a model dubbed Medical Cross-attention Vision-Language
model (Medical X-VL), leveraging the key components to be tailored for the
medical domain. Our medical X-VL model is based on the following components:
self-supervised uni-modal models in medical domain and fusion encoder to bridge
them, momentum distillation, sentence-wise contrastive learning for medical
reports, and the sentence similarity-adjusted hard negative mining. We
experimentally demonstrated that our model enables various zero-shot tasks for
oversight AI, ranging from the zero-shot classification to zero-shot error
correction. Our model outperformed the current state-of-the-art models in two
different medical image database, suggesting the novel clinical usage of our
oversight AI model for monitoring human errors. Our method was especially
successful in the data-limited setting, which is frequently encountered in the
clinics, suggesting the potential widespread applicability in medical domain.",2022-08-10,2022,2022-08,medical
"OpenMedIA: Open-Source Medical Image Analysis Toolbox and Benchmark
  under Heterogeneous AI Computing Platforms","In this paper, we present OpenMedIA, an open-source toolbox library
containing a rich set of deep learning methods for medical image analysis under
heterogeneous Artificial Intelligence (AI) computing platforms. Various medical
image analysis methods, including 2D/3D medical image classification,
segmentation, localisation, and detection, have been included in the toolbox
with PyTorch and/or MindSpore implementations under heterogeneous NVIDIA and
Huawei Ascend computing systems. To our best knowledge, OpenMedIA is the first
open-source algorithm library providing compared PyTorch and MindSpore
implementations and results on several benchmark datasets. The source codes and
models are available at https://git.openi.org.cn/OpenMedIA.",2022-08-11,2022,2022-08,medical
"An Empirical Comparison of Explainable Artificial Intelligence Methods
  for Clinical Data: A Case Study on Traumatic Brain Injury","A longstanding challenge surrounding deep learning algorithms is unpacking
and understanding how they make their decisions. Explainable Artificial
Intelligence (XAI) offers methods to provide explanations of internal functions
of algorithms and reasons behind their decisions in ways that are interpretable
and understandable to human users. . Numerous XAI approaches have been
developed thus far, and a comparative analysis of these strategies seems
necessary to discern their relevance to clinical prediction models. To this
end, we first implemented two prediction models for short- and long-term
outcomes of traumatic brain injury (TBI) utilizing structured tabular as well
as time-series physiologic data, respectively. Six different interpretation
techniques were used to describe both prediction models at the local and global
levels. We then performed a critical analysis of merits and drawbacks of each
strategy, highlighting the implications for researchers who are interested in
applying these methodologies. The implemented methods were compared to one
another in terms of several XAI characteristics such as understandability,
fidelity, and stability. Our findings show that SHAP is the most stable with
the highest fidelity but falls short of understandability. Anchors, on the
other hand, is the most understandable approach, but it is only applicable to
tabular data and not time series data.",2022-08-13,2022,2022-08,medical
"Learn2Trust: A video and streamlit-based educational programme for
  AI-based medical image analysis targeted towards medical students","In order to be able to use artificial intelligence (AI) in medicine without
scepticism and to recognise and assess its growing potential, a basic
understanding of this topic is necessary among current and future medical
staff. Under the premise of ""trust through understanding"", we developed an
innovative online course as a learning opportunity within the framework of the
German KI Campus (AI campus) project, which is a self-guided course that
teaches the basics of AI for the analysis of medical image data. The main goal
is to provide a learning environment for a sufficient understanding of AI in
medical image analysis so that further interest in this topic is stimulated and
inhibitions towards its use can be overcome by means of positive application
experience. The focus was on medical applications and the fundamentals of
machine learning. The online course was divided into consecutive lessons, which
include theory in the form of explanatory videos, practical exercises in the
form of Streamlit and practical exercises and/or quizzes to check learning
progress. A survey among the participating medical students in the first run of
the course was used to analyse our research hypotheses quantitatively.",2022-08-15,2022,2022-08,medical
"End-to-end Clinical Event Extraction from Chinese Electronic Health
  Record","Event extraction is an important work of medical text processing. According
to the complex characteristics of medical text annotation, we use the
end-to-end event extraction model to enhance the output formatting information
of events. Through pre training and fine-tuning, we can extract the attributes
of the four dimensions of medical text: anatomical position, subject word,
description word and occurrence state. On the test set, the accuracy rate was
0.4511, the recall rate was 0.3928, and the F1 value was 0.42. The method of
this model is simple, and it has won the second place in the task of mining
clinical discovery events (task2) in the Chinese electronic medical record of
the seventh China health information processing Conference (chip2021).",2022-08-19,2022,2022-08,medical
"Advancing the cybersecurity of the healthcare system with
  self-optimising and self-adaptative artificial intelligence (part 2)","This article advances the knowledge on teaching and training new artificial
intelligence algorithms, for securing, preparing, and adapting the healthcare
system to cope with future pandemics. The core objective is to develop a
concept healthcare system supported by autonomous artificial intelligence that
can use edge health devices with real-time data. The article constructs two
case scenarios for applying cybersecurity with autonomous artificial
intelligence for (1) self-optimising predictive cyber risk analytics of
failures in healthcare systems during a Disease X event (i.e., undefined future
pandemic), and (2) self-adaptive forecasting of medical production and supply
chain bottlenecks during future pandemics. To construct the two testing
scenarios, the article uses the case of Covid-19 to synthesise data for the
algorithms i.e., for optimising and securing digital healthcare systems in
anticipation of disease X. The testing scenarios are built to tackle the
logistical challenges and disruption of complex production and supply chains
for vaccine distribution with optimisation algorithms.",2022-08-30,2022,2022-08,medical
An Artificial Intelligence Outlook for Colorectal Cancer Screening,"Colorectal cancer is the third most common tumor in men and the second in
women, accounting for 10% of all tumors worldwide. It ranks second in
cancer-related deaths with 9.4%, following lung cancer. The decrease in
mortality rate documented over the last 20 years has shown signs of slowing
down since 2017, necessitating concentrated actions on specific measures that
have exhibited considerable potential. As such, the technical foundation and
research evidence for blood-derived protein markers have been set, pending
comparative validation, clinical implementation and integration into an
artificial intelligence enabled decision support framework that also considers
knowledge on risk factors. The current paper aspires to constitute the driving
force for creating change in colorectal cancer screening by reviewing existing
medical practices through accessible and non-invasive risk estimation,
employing a straightforward artificial intelligence outlook.",2022-09-05,2022,2022-09,medical
"A hybrid Bayesian network for medical device risk assessment and
  management","ISO 14971 is the primary standard used for medical device risk management.
While it specifies the requirements for medical device risk management, it does
not specify a particular method for performing risk management. Hence, medical
device manufacturers are free to develop or use any appropriate methods for
managing the risk of medical devices. The most commonly used methods, such as
Fault Tree Analysis (FTA), are unable to provide a reasonable basis for
computing risk estimates when there are limited or no historical data available
or where there is second-order uncertainty about the data. In this paper, we
present a novel method for medical device risk management using hybrid Bayesian
networks (BNs) that resolves the limitations of classical methods such as FTA
and incorporates relevant factors affecting the risk of medical devices. The
proposed BN method is generic but can be instantiated on a system-by-system
basis, and we apply it to a Defibrillator device to demonstrate the process
involved for medical device risk management during production and
post-production. The example is validated against real-world data.",2022-09-07,2022,2022-09,medical
"Continuous Design Control for Machine Learning in Certified Medical
  Systems","Continuous software engineering has become commonplace in numerous fields.
However, in regulating intensive sectors, where additional concerns needs to be
taken into account, it is often considered difficult to apply continuous
development approaches, such as devops. In this paper, we present an approach
for using pull requests as design controls, and apply this approach to machine
learning in certified medical systems leveraging model cards, a novel technique
developed to add explainability to machine learning systems, as a regulatory
audit trail. The approach is demonstrated with an industrial system that we
have used previously to show how medical systems can be developed in a
continuous fashion.",2022-09-13,2022,2022-09,medical
"Declarative Guideline Conformance Checking of Clinical Treatments: A
  Case Study","Conformance checking is a process mining technique that allows verifying the
conformance of process instances to a given model. Thus, this technique is
predestined to be used in the medical context for the comparison of treatment
cases with clinical guidelines. However, medical processes are highly variable,
highly dynamic, and complex. This makes the use of imperative conformance
checking approaches in the medical domain difficult. Studies show that
declarative approaches can better address these characteristics. However, none
of the approaches has yet gained practical acceptance. Another challenge are
alignments, which usually do not add any value from a medical point of view.
For this reason, we investigate in a case study the usability of the HL7
standard Arden Syntax for declarative, rule-based conformance checking and the
use of manually modeled alignments. Using the approach, it was possible to
check the conformance of treatment cases and create medically meaningful
alignments for large parts of a medical guideline.",2022-09-20,2022,2022-09,medical
"Artificial Intelligence-Based Image Reconstruction in Cardiac Magnetic
  Resonance","Artificial intelligence (AI) and Machine Learning (ML) have shown great
potential in improving the medical imaging workflow, from image acquisition and
reconstruction to disease diagnosis and treatment. Particularly, in recent
years, there has been a significant growth in the use of AI and ML algorithms,
especially Deep Learning (DL) based methods, for medical image reconstruction.
DL techniques have shown to be competitive and often superior over conventional
reconstruction methods in terms of both reconstruction quality and
computational efficiency. The use of DL-based image reconstruction also
provides promising opportunities to transform the way cardiac images are
acquired and reconstructed. In this chapter, we will review recent advances in
DL-based reconstruction techniques for cardiac imaging, with emphasis on
cardiac magnetic resonance (CMR) image reconstruction. We mainly focus on
supervised DL methods for the application, including image post-processing
techniques, model-driven approaches and k-space based methods. Current
limitations, challenges and future opportunities of DL for cardiac image
reconstruction are also discussed.",2022-09-21,2022,2022-09,medical
"DR.BENCH: Diagnostic Reasoning Benchmark for Clinical Natural Language
  Processing","The meaningful use of electronic health records (EHR) continues to progress
in the digital era with clinical decision support systems augmented by
artificial intelligence. A priority in improving provider experience is to
overcome information overload and reduce the cognitive burden so fewer medical
errors and cognitive biases are introduced during patient care. One major type
of medical error is diagnostic error due to systematic or predictable errors in
judgment that rely on heuristics. The potential for clinical natural language
processing (cNLP) to model diagnostic reasoning in humans with forward
reasoning from data to diagnosis and potentially reduce the cognitive burden
and medical error has not been investigated. Existing tasks to advance the
science in cNLP have largely focused on information extraction and named entity
recognition through classification tasks. We introduce a novel suite of tasks
coined as Diagnostic Reasoning Benchmarks, DR.BENCH, as a new benchmark for
developing and evaluating cNLP models with clinical diagnostic reasoning
ability. The suite includes six tasks from ten publicly available datasets
addressing clinical text understanding, medical knowledge reasoning, and
diagnosis generation. DR.BENCH is the first clinical suite of tasks designed to
be a natural language generation framework to evaluate pre-trained language
models. Experiments with state-of-the-art pre-trained generative language
models using large general domain models and models that were continually
trained on a medical corpus demonstrate opportunities for improvement when
evaluated in DR. BENCH. We share DR. BENCH as a publicly available GitLab
repository with a systematic approach to load and evaluate models for the cNLP
community.",2022-09-29,2022,2022-09,medical
"Compressed Gastric Image Generation Based on Soft-Label Dataset
  Distillation for Medical Data Sharing","Background and objective: Sharing of medical data is required to enable the
cross-agency flow of healthcare information and construct high-accuracy
computer-aided diagnosis systems. However, the large sizes of medical datasets,
the massive amount of memory of saved deep convolutional neural network (DCNN)
models, and patients' privacy protection are problems that can lead to
inefficient medical data sharing. Therefore, this study proposes a novel
soft-label dataset distillation method for medical data sharing.
  Methods: The proposed method distills valid information of medical image data
and generates several compressed images with different data distributions for
anonymous medical data sharing. Furthermore, our method can extract essential
weights of DCNN models to reduce the memory required to save trained models for
efficient medical data sharing.
  Results: The proposed method can compress tens of thousands of images into
several soft-label images and reduce the size of a trained model to a few
hundredths of its original size. The compressed images obtained after
distillation have been visually anonymized; therefore, they do not contain the
private information of the patients. Furthermore, we can realize high-detection
performance with a small number of compressed images.
  Conclusions: The experimental results show that the proposed method can
improve the efficiency and security of medical data sharing.",2022-09-29,2022,2022-09,medical
"Medical Image Retrieval via Nearest Neighbor Search on Pre-trained Image
  Features","Nearest neighbor search (NNS) aims to locate the points in high-dimensional
space that is closest to the query point. The brute-force approach for finding
the nearest neighbor becomes computationally infeasible when the number of
points is large. The NNS has multiple applications in medicine, such as
searching large medical imaging databases, disease classification, diagnosis,
etc. With a focus on medical imaging, this paper proposes DenseLinkSearch an
effective and efficient algorithm that searches and retrieves the relevant
images from heterogeneous sources of medical images. Towards this, given a
medical database, the proposed algorithm builds the index that consists of
pre-computed links of each point in the database. The search algorithm utilizes
the index to efficiently traverse the database in search of the nearest
neighbor. We extensively tested the proposed NNS approach and compared the
performance with state-of-the-art NNS approaches on benchmark datasets and our
created medical image datasets. The proposed approach outperformed the existing
approach in terms of retrieving accurate neighbors and retrieval speed. We also
explore the role of medical image feature representation in content-based
medical image retrieval tasks. We propose a Transformer-based feature
representation technique that outperformed the existing pre-trained Transformer
approach on CLEF 2011 medical image retrieval task. The source code of our
experiments are available at https://github.com/deepaknlp/DLS.",2022-10-05,2022,2022-10,medical
Token Classification for Disambiguating Medical Abbreviations,"Abbreviations are unavoidable yet critical parts of the medical text. Using
abbreviations, especially in clinical patient notes, can save time and space,
protect sensitive information, and help avoid repetitions. However, most
abbreviations might have multiple senses, and the lack of a standardized
mapping system makes disambiguating abbreviations a difficult and
time-consuming task. The main objective of this study is to examine the
feasibility of token classification methods for medical abbreviation
disambiguation. Specifically, we explore the capability of token classification
methods to deal with multiple unique abbreviations in a single text. We use two
public datasets to compare and contrast the performance of several transformer
models pre-trained on different scientific and medical corpora. Our proposed
token classification approach outperforms the more commonly used text
classification models for the abbreviation disambiguation task. In particular,
the SciBERT model shows a strong performance for both token and text
classification tasks over the two considered datasets. Furthermore, we find
that abbreviation disambiguation performance for the text classification models
becomes comparable to that of token classification only when postprocessing is
applied to their predictions, which involves filtering possible labels for an
abbreviation based on the training data.",2022-10-05,2022,2022-10,medical
"KG-MTT-BERT: Knowledge Graph Enhanced BERT for Multi-Type Medical Text
  Classification","Medical text learning has recently emerged as a promising area to improve
healthcare due to the wide adoption of electronic health record (EHR) systems.
The complexity of the medical text such as diverse length, mixed text types,
and full of medical jargon, poses a great challenge for developing effective
deep learning models. BERT has presented state-of-the-art results in many NLP
tasks, such as text classification and question answering. However, the
standalone BERT model cannot deal with the complexity of the medical text,
especially the lengthy clinical notes. Herein, we develop a new model called
KG-MTT-BERT (Knowledge Graph Enhanced Multi-Type Text BERT) by extending the
BERT model for long and multi-type text with the integration of the medical
knowledge graph. Our model can outperform all baselines and other
state-of-the-art models in diagnosis-related group (DRG) classification, which
requires comprehensive medical text for accurate classification. We also
demonstrated that our model can effectively handle multi-type text and the
integration of medical knowledge graph can significantly improve the
performance.",2022-10-08,2022,2022-10,medical
"Adapting Pretrained Vision-Language Foundational Models to Medical
  Imaging Domains","Multi-modal foundation models are typically trained on millions of pairs of
natural images and text captions, frequently obtained through web-crawling
approaches. Although such models depict excellent generative capabilities, they
do not typically generalize well to specific domains such as medical images
that have fundamentally shifted distributions compared to natural images.
Building generative models for medical images that faithfully depict clinical
context may help alleviate the paucity of healthcare datasets. Thus, in this
study, we seek to research and expand the representational capabilities of
large pretrained foundation models to medical concepts, specifically for
leveraging the Stable Diffusion model to generate domain specific images found
in medical imaging. We explore the sub-components of the Stable Diffusion
pipeline (the variational autoencoder, the U-Net and the text-encoder) to
fine-tune the model to generate medical images. We benchmark the efficacy of
these efforts using quantitative image quality metrics and qualitative
radiologist-driven evaluations that accurately represent the clinical content
of conditional text prompts. Our best-performing model improves upon the stable
diffusion baseline and can be conditioned to insert a realistic-looking
abnormality on a synthetic radiology image, while maintaining a 95% accuracy on
a classifier trained to detect the abnormality.",2022-10-09,2022,2022-10,medical
Domain-guided data augmentation for deep learning on medical imaging,"While domain-specific data augmentation can be useful in training neural
networks for medical imaging tasks, such techniques have not been widely used
to date. Here, we test whether domain-specific data augmentation is useful for
medical imaging using a well-benchmarked task: view classification on fetal
ultrasound FETAL-125 and OB-125 datasets. We found that using a
context-preserving cut-paste strategy, we could create valid training data as
measured by performance of the resulting trained model on the benchmark test
dataset. When used in an online fashion, models trained on this data performed
similarly to those trained using traditional data augmentation (FETAL-125
F-score 85.33+/-0.24 vs 86.89+/-0.60, p-value 0.0139; OB-125 F-score
74.60+/-0.11 vs 72.43+/-0.62, p-value 0.0039). Furthermore, the ability to
perform augmentations during training time, as well as the ability to apply
chosen augmentations equally across data classes, are important considerations
in designing a bespoke data augmentation. Finally, we provide open-source code
to facilitate running bespoke data augmentations in an online fashion. Taken
together, this work expands the ability to design and apply domain-guided data
augmentations for medical imaging tasks.",2022-10-10,2022,2022-10,medical
The evolution of AI approaches for motor imagery EEG-based BCIs,"The Motor Imagery (MI) electroencephalography (EEG) based Brain Computer
Interfaces (BCIs) allow the direct communication between humans and machines by
exploiting the neural pathways connected to motor imagination. Therefore, these
systems open the possibility of developing applications that could span from
the medical field to the entertainment industry. In this context, Artificial
Intelligence (AI) approaches become of fundamental importance especially when
wanting to provide a correct and coherent feedback to BCI users. Moreover,
publicly available datasets in the field of MI EEG-based BCIs have been widely
exploited to test new techniques from the AI domain. In this work, AI
approaches applied to datasets collected in different years and with different
devices but with coherent experimental paradigms are investigated with the aim
of providing a concise yet sufficiently comprehensive survey on the evolution
and influence of AI techniques on MI EEG-based BCI data.",2022-10-11,2022,2022-10,medical
"Multi-Granularity Cross-modal Alignment for Generalized Medical Visual
  Representation Learning","Learning medical visual representations directly from paired radiology
reports has become an emerging topic in representation learning. However,
existing medical image-text joint learning methods are limited by instance or
local supervision analysis, ignoring disease-level semantic correspondences. In
this paper, we present a novel Multi-Granularity Cross-modal Alignment (MGCA)
framework for generalized medical visual representation learning by harnessing
the naturally exhibited semantic correspondences between medical image and
radiology reports at three different levels, i.e., pathological region-level,
instance-level, and disease-level. Specifically, we first incorporate the
instance-wise alignment module by maximizing the agreement between image-report
pairs. Further, for token-wise alignment, we introduce a bidirectional
cross-attention strategy to explicitly learn the matching between fine-grained
visual tokens and text tokens, followed by contrastive learning to align them.
More important, to leverage the high-level inter-subject relationship semantic
(e.g., disease) correspondences, we design a novel cross-modal disease-level
alignment paradigm to enforce the cross-modal cluster assignment consistency.
Extensive experimental results on seven downstream medical image datasets
covering image classification, object detection, and semantic segmentation
tasks demonstrate the stable and superior performance of our framework.",2022-10-12,2022,2022-10,medical
"Artificial Intelligence-Based Methods for Fusion of Electronic Health
  Records and Imaging Data","Healthcare data are inherently multimodal, including electronic health
records (EHR), medical images, and multi-omics data. Combining these multimodal
data sources contributes to a better understanding of human health and provides
optimal personalized healthcare. Advances in artificial intelligence (AI)
technologies, particularly machine learning (ML), enable the fusion of these
different data modalities to provide multimodal insights. To this end, in this
scoping review, we focus on synthesizing and analyzing the literature that uses
AI techniques to fuse multimodal medical data for different clinical
applications. More specifically, we focus on studies that only fused EHR with
medical imaging data to develop various AI methods for clinical applications.
We present a comprehensive analysis of the various fusion strategies, the
diseases and clinical outcomes for which multimodal fusion was used, the ML
algorithms used to perform multimodal fusion for each clinical application, and
the available multimodal medical datasets. We followed the PRISMA-ScR
guidelines. We searched Embase, PubMed, Scopus, and Google Scholar to retrieve
relevant studies. We extracted data from 34 studies that fulfilled the
inclusion criteria. In our analysis, a typical workflow was observed: feeding
raw data, fusing different data modalities by applying conventional machine
learning (ML) or deep learning (DL) algorithms, and finally, evaluating the
multimodal fusion through clinical outcome predictions. Specifically, early
fusion was the most used technique in most applications for multimodal learning
(22 out of 34 studies). We found that multimodality fusion models outperformed
traditional single-modality models for the same task. Disease diagnosis and
prediction were the most common clinical outcomes (reported in 20 and 10
studies, respectively) from a clinical outcome perspective.",2022-10-23,2022,2022-10,medical
AI Ethics in Smart Healthcare,"This article reviews the landscape of ethical challenges of integrating
artificial intelligence (AI) into smart healthcare products, including medical
electronic devices. Differences between traditional ethics in the medical
domain and emerging ethical challenges with AI-driven healthcare are presented,
particularly as they relate to transparency, bias, privacy, safety,
responsibility, justice, and autonomy. Open challenges and recommendations are
outlined to enable the integration of ethical principles into the design,
validation, clinical trials, deployment, monitoring, repair, and retirement of
AI-based smart healthcare products.",2022-11-02,2022,2022-11,medical
"Spot the fake lungs: Generating Synthetic Medical Images using Neural
  Diffusion Models","Generative models are becoming popular for the synthesis of medical images.
Recently, neural diffusion models have demonstrated the potential to generate
photo-realistic images of objects. However, their potential to generate medical
images is not explored yet. In this work, we explore the possibilities of
synthesis of medical images using neural diffusion models. First, we use a
pre-trained DALLE2 model to generate lungs X-Ray and CT images from an input
text prompt. Second, we train a stable diffusion model with 3165 X-Ray images
and generate synthetic images. We evaluate the synthetic image data through a
qualitative analysis where two independent radiologists label randomly chosen
samples from the generated data as real, fake, or unsure. Results demonstrate
that images generated with the diffusion model can translate characteristics
that are otherwise very specific to certain medical conditions in chest X-Ray
or CT images. Careful tuning of the model can be very promising. To the best of
our knowledge, this is the first attempt to generate lungs X-Ray and CT images
using neural diffusion models. This work aims to introduce a new dimension in
artificial intelligence for medical imaging. Given that this is a new topic,
the paper will serve as an introduction and motivation for the research
community to explore the potential of diffusion models for medical image
synthesis. We have released the synthetic images on
https://www.kaggle.com/datasets/hazrat/awesomelungs.",2022-11-02,2022,2022-11,medical
"Explainable AI over the Internet of Things (IoT): Overview,
  State-of-the-Art and Future Directions","Explainable Artificial Intelligence (XAI) is transforming the field of
Artificial Intelligence (AI) by enhancing the trust of end-users in machines.
As the number of connected devices keeps on growing, the Internet of Things
(IoT) market needs to be trustworthy for the end-users. However, existing
literature still lacks a systematic and comprehensive survey work on the use of
XAI for IoT. To bridge this lacking, in this paper, we address the XAI
frameworks with a focus on their characteristics and support for IoT. We
illustrate the widely-used XAI services for IoT applications, such as security
enhancement, Internet of Medical Things (IoMT), Industrial IoT (IIoT), and
Internet of City Things (IoCT). We also suggest the implementation choice of
XAI models over IoT systems in these applications with appropriate examples and
summarize the key inferences for future works. Moreover, we present the
cutting-edge development in edge XAI structures and the support of
sixth-generation (6G) communication services for IoT applications, along with
key inferences. In a nutshell, this paper constitutes the first holistic
compilation on the development of XAI-based frameworks tailored for the demands
of future IoT use cases.",2022-11-02,2022,2022-11,medical
"Issues and Challenges in Applications of Artificial Intelligence to
  Nuclear Medicine -- The Bethesda Report (AI Summit 2022)","The SNMMI Artificial Intelligence (SNMMI-AI) Summit, organized by the SNMMI
AI Task Force, took place in Bethesda, MD on March 21-22, 2022. It brought
together various community members and stakeholders from academia, healthcare,
industry, patient representatives, and government (NIH, FDA), and considered
various key themes to envision and facilitate a bright future for routine,
trustworthy use of AI in nuclear medicine. In what follows, essential issues,
challenges, controversies and findings emphasized in the meeting are
summarized.",2022-11-07,2022,2022-11,medical
"Nested Named Entity Recognition from Medical Texts: An Adaptive Shared
  Network Architecture with Attentive CRF","Recognizing useful named entities plays a vital role in medical information
processing, which helps drive the development of medical area research. Deep
learning methods have achieved good results in medical named entity recognition
(NER). However, we find that existing methods face great challenges when
dealing with the nested named entities. In this work, we propose a novel
method, referred to as ASAC, to solve the dilemma caused by the nested
phenomenon, in which the core idea is to model the dependency between different
categories of entity recognition. The proposed method contains two key modules:
the adaptive shared (AS) part and the attentive conditional random field (ACRF)
module. The former part automatically assigns adaptive weights across each task
to achieve optimal recognition accuracy in the multi-layer network. The latter
module employs the attention operation to model the dependency between
different entities. In this way, our model could learn better entity
representations by capturing the implicit distinctions and relationships
between different categories of entities. Extensive experiments on public
datasets verify the effectiveness of our method. Besides, we also perform
ablation analyses to deeply understand our methods.",2022-11-09,2022,2022-11,medical
"MF2-MVQA: A Multi-stage Feature Fusion method for Medical Visual
  Question Answering","There is a key problem in the medical visual question answering task that how
to effectively realize the feature fusion of language and medical images with
limited datasets. In order to better utilize multi-scale information of medical
images, previous methods directly embed the multi-stage visual feature maps as
tokens of same size respectively and fuse them with text representation.
However, this will cause the confusion of visual features at different stages.
To this end, we propose a simple but powerful multi-stage feature fusion
method, MF2-MVQA, which stage-wise fuses multi-level visual features with
textual semantics. MF2-MVQA achieves the State-Of-The-Art performance on
VQA-Med 2019 and VQA-RAD dataset. The results of visualization also verify that
our model outperforms previous work.",2022-11-11,2022,2022-11,medical
"Secure and Privacy-Preserving Automated Machine Learning Operations into
  End-to-End Integrated IoT-Edge-Artificial Intelligence-Blockchain Monitoring
  System for Diabetes Mellitus Prediction","Diabetes Mellitus, one of the leading causes of death worldwide, has no cure
to date and can lead to severe health complications, such as retinopathy, limb
amputation, cardiovascular diseases, and neuronal disease, if left untreated.
Consequently, it becomes crucial to take precautionary measures to
avoid/predict the occurrence of diabetes. Machine learning approaches have been
proposed and evaluated in the literature for diabetes prediction. This paper
proposes an IoT-edge-Artificial Intelligence (AI)-blockchain system for
diabetes prediction based on risk factors. The proposed system is underpinned
by the blockchain to obtain a cohesive view of the risk factors data from
patients across different hospitals and to ensure security and privacy of the
user's data. Furthermore, we provide a comparative analysis of different
medical sensors, devices, and methods to measure and collect the risk factors
values in the system. Numerical experiments and comparative analysis were
carried out between our proposed system, using the most accurate random forest
(RF) model, and the two most used state-of-the-art machine learning approaches,
Logistic Regression (LR) and Support Vector Machine (SVM), using three
real-life diabetes datasets. The results show that the proposed system using RF
predicts diabetes with 4.57% more accuracy on average compared to LR and SVM,
with 2.87 times more execution time. Data balancing without feature selection
does not show significant improvement. The performance is improved by 1.14% and
0.02% after feature selection for PIMA Indian and Sylhet datasets respectively,
while it reduces by 0.89% for MIMIC III.",2022-11-13,2022,2022-11,medical
"Robust Alzheimer's Progression Modeling using Cross-Domain
  Self-Supervised Deep Learning","Developing successful artificial intelligence systems in practice depends on
both robust deep learning models and large, high-quality data. However,
acquiring and labeling data can be prohibitively expensive and time-consuming
in many real-world applications, such as clinical disease models.
Self-supervised learning has demonstrated great potential in increasing model
accuracy and robustness in small data regimes. In addition, many clinical
imaging and disease modeling applications rely heavily on regression of
continuous quantities. However, the applicability of self-supervised learning
for these medical-imaging regression tasks has not been extensively studied. In
this study, we develop a cross-domain self-supervised learning approach for
disease prognostic modeling as a regression problem using medical images as
input. We demonstrate that self-supervised pretraining can improve the
prediction of Alzheimer's Disease progression from brain MRI. We also show that
pretraining on extended (but not labeled) brain MRI data outperforms
pretraining on natural images. We further observe that the highest performance
is achieved when both natural images and extended brain-MRI data are used for
pretraining.",2022-11-15,2022,2022-11,medical
"Generalization of Artificial Intelligence Models in Medical Imaging: A
  Case-Based Review","The discussions around Artificial Intelligence (AI) and medical imaging are
centered around the success of deep learning algorithms. As new algorithms
enter the market, it is important for practicing radiologists to understand the
pitfalls of various AI algorithms. This entails having a basic understanding of
how algorithms are developed, the kind of data they are trained on, and the
settings in which they will be deployed. As with all new technologies, use of
AI should be preceded by a fundamental understanding of the risks and benefits
to those it is intended to help. This case-based review is intended to point
out specific factors practicing radiologists who intend to use AI should
consider.",2022-11-15,2022,2022-11,medical
"CDialog: A Multi-turn Covid-19 Conversation Dataset for Entity-Aware
  Dialog Generation","The development of conversational agents to interact with patients and
deliver clinical advice has attracted the interest of many researchers,
particularly in light of the COVID-19 pandemic. The training of an end-to-end
neural based dialog system, on the other hand, is hampered by a lack of
multi-turn medical dialog corpus. We make the very first attempt to release a
high-quality multi-turn Medical Dialog dataset relating to Covid-19 disease
named CDialog, with over 1K conversations collected from the online medical
counselling websites. We annotate each utterance of the conversation with seven
different categories of medical entities, including diseases, symptoms, medical
tests, medical history, remedies, medications and other aspects as additional
labels. Finally, we propose a novel neural medical dialog system based on the
CDialog dataset to advance future research on developing automated medical
dialog systems. We use pre-trained language models for dialogue generation,
incorporating annotated medical entities, to generate a virtual doctor's
response that addresses the patient's query. Experimental results show that the
proposed dialog models perform comparably better when supplemented with entity
information and hence can improve the response quality.",2022-11-16,2022,2022-11,medical
Vision Transformers in Medical Imaging: A Review,"Transformer, a model comprising attention-based encoder-decoder architecture,
have gained prevalence in the field of natural language processing (NLP) and
recently influenced the computer vision (CV) space. The similarities between
computer vision and medical imaging, reviewed the question among researchers if
the impact of transformers on computer vision be translated to medical imaging?
In this paper, we attempt to provide a comprehensive and recent review on the
application of transformers in medical imaging by; describing the transformer
model comparing it with a diversity of convolutional neural networks (CNNs),
detailing the transformer based approaches for medical image classification,
segmentation, registration and reconstruction with a focus on the image
modality, comparing the performance of state-of-the-art transformer
architectures to best performing CNNs on standard medical datasets.",2022-11-18,2022,2022-11,medical
"Social media mining for toxicovigilance of prescription medications:
  End-to-end pipeline, challenges and future work","Substance use, substance use disorder, and overdoses related to substance use
are major public health problems globally and in the United States. A key
aspect of addressing these problems from a public health standpoint is improved
surveillance. Traditional surveillance systems are laggy, and social media are
potentially useful sources of timely data. However, mining knowledge from
social media is challenging, and requires the development of advanced
artificial intelligence, specifically natural language processing (NLP) and
machine learning methods. We developed a sophisticated end-to-end pipeline for
mining information about nonmedical prescription medication use from social
media, namely Twitter and Reddit. Our pipeline employs supervised machine
learning and NLP for filtering out noise and characterizing the chatter. In
this paper, we describe our end-to-end pipeline developed over four years. In
addition to describing our data mining infrastructure, we discuss existing
challenges in social media mining for toxicovigilance, and possible future
research directions.",2022-11-18,2022,2022-11,medical
"Self-supervised vision-language pretraining for Medical visual question
  answering","Medical image visual question answering (VQA) is a task to answer clinical
questions, given a radiographic image, which is a challenging problem that
requires a model to integrate both vision and language information. To solve
medical VQA problems with a limited number of training data, pretrain-finetune
paradigm is widely used to improve the model generalization. In this paper, we
propose a self-supervised method that applies Masked image modeling, Masked
language modeling, Image text matching and Image text alignment via contrastive
learning (M2I2) for pretraining on medical image caption dataset, and finetunes
to downstream medical VQA tasks. The proposed method achieves state-of-the-art
performance on all the three public medical VQA datasets. Our codes and models
are available at https://github.com/pengfeiliHEU/M2I2.",2022-11-24,2022,2022-11,medical
Heterogeneous Graph Learning for Multi-modal Medical Data Analysis,"Routine clinical visits of a patient produce not only image data, but also
non-image data containing clinical information regarding the patient, i.e.,
medical data is multi-modal in nature. Such heterogeneous modalities offer
different and complementary perspectives on the same patient, resulting in more
accurate clinical decisions when they are properly combined. However, despite
its significance, how to effectively fuse the multi-modal medical data into a
unified framework has received relatively little attention. In this paper, we
propose an effective graph-based framework called HetMed (Heterogeneous Graph
Learning for Multi-modal Medical Data Analysis) for fusing the multi-modal
medical data. Specifically, we construct a multiplex network that incorporates
multiple types of non-image features of patients to capture the complex
relationship between patients in a systematic way, which leads to more accurate
clinical decisions. Extensive experiments on various real-world datasets
demonstrate the superiority and practicality of HetMed. The source code for
HetMed is available at https://github.com/Sein-Kim/Multimodal-Medical.",2022-11-28,2022,2022-11,medical
MED-SE: Medical Entity Definition-based Sentence Embedding,"We propose Medical Entity Definition-based Sentence Embedding (MED-SE), a
novel unsupervised contrastive learning framework designed for clinical texts,
which exploits the definitions of medical entities. To this end, we conduct an
extensive analysis of multiple sentence embedding techniques in clinical
semantic textual similarity (STS) settings. In the entity-centric setting that
we have designed, MED-SE achieves significantly better performance, while the
existing unsupervised methods including SimCSE show degraded performance. Our
experiments elucidate the inherent discrepancies between the general- and
clinical-domain texts, and suggest that entity-centric contrastive approaches
may help bridge this gap and lead to a better representation of clinical
sentences.",2022-12-09,2022,2022-12,medical
"Analysis of Explainable Artificial Intelligence Methods on Medical Image
  Classification","The use of deep learning in computer vision tasks such as image
classification has led to a rapid increase in the performance of such systems.
Due to this substantial increment in the utility of these systems, the use of
artificial intelligence in many critical tasks has exploded. In the medical
domain, medical image classification systems are being adopted due to their
high accuracy and near parity with human physicians in many tasks. However,
these artificial intelligence systems are extremely complex and are considered
black boxes by scientists, due to the difficulty in interpreting what exactly
led to the predictions made by these models. When these systems are being used
to assist high-stakes decision-making, it is extremely important to be able to
understand, verify and justify the conclusions reached by the model. The
research techniques being used to gain insight into the black-box models are in
the field of explainable artificial intelligence (XAI). In this paper, we
evaluated three different XAI methods across two convolutional neural network
models trained to classify lung cancer from histopathological images. We
visualized the outputs and analyzed the performance of these methods, in order
to better understand how to apply explainable artificial intelligence in the
medical domain.",2022-12-10,2022,2022-12,medical
Influence of AI in human lives,"Artificial Intelligence is one of the most significant and prominent
technological innovations which has reshaped all aspects of human life on the
lines of ease from magnitudes like shopping, data collection, driving, everyday
life, medical approach and many more. On the contrary, although recent
developments in both subjects that are backed by technology, progress on AI
alongside CE must have mostly been undertaken in isolation, providing little
understanding into how the two areas intersect. Artificial intelligence is now
widely used in services, from back-office tasks to front-line interactions with
customers. This trend has accelerated in recent years. Artificial intelligence
(AI)-based virtual assistants are changing successful engagement away from
being dominated by humans and toward being dominated by technologies. As a
result, people are expected to solve their own problems before calling customer
care representatives, eventually emerging as a crucial component of providing
services as value co-creators. AI-powered chats may potentially go awry, which
could enrage, perplex, and anger customers. Considering all these, the main
objectives of this study will engage the following
  1. To identify the alterations in the scope of human searches for information
offered by the application of AI?
  2. To analyse how AI helps in the way someone drives the car
  3. To evaluate how AI has changed the way customer interact with the
customers",2022-12-15,2022,2022-12,medical
"SADM: Sequence-Aware Diffusion Model for Longitudinal Medical Image
  Generation","Human organs constantly undergo anatomical changes due to a complex mix of
short-term (e.g., heartbeat) and long-term (e.g., aging) factors. Evidently,
prior knowledge of these factors will be beneficial when modeling their future
state, i.e., via image generation. However, most of the medical image
generation tasks only rely on the input from a single image, thus ignoring the
sequential dependency even when longitudinal data is available. Sequence-aware
deep generative models, where model input is a sequence of ordered and
timestamped images, are still underexplored in the medical imaging domain that
is featured by several unique challenges: 1) Sequences with various lengths; 2)
Missing data or frame, and 3) High dimensionality. To this end, we propose a
sequence-aware diffusion model (SADM) for the generation of longitudinal
medical images. Recently, diffusion models have shown promising results in
high-fidelity image generation. Our method extends this new technique by
introducing a sequence-aware transformer as the conditional module in a
diffusion model. The novel design enables learning longitudinal dependency even
with missing data during training and allows autoregressive generation of a
sequence of images during inference. Our extensive experiments on 3D
longitudinal medical images demonstrate the effectiveness of SADM compared with
baselines and alternative methods. The code is available at
https://github.com/ubc-tea/SADM-Longitudinal-Medical-Image-Generation.",2022-12-16,2022,2022-12,medical
"Annotation by Clicks: A Point-Supervised Contrastive Variance Method for
  Medical Semantic Segmentation","Medical image segmentation methods typically rely on numerous dense annotated
images for model training, which are notoriously expensive and time-consuming
to collect. To alleviate this burden, weakly supervised techniques have been
exploited to train segmentation models with less expensive annotations. In this
paper, we propose a novel point-supervised contrastive variance method (PSCV)
for medical image semantic segmentation, which only requires one pixel-point
from each organ category to be annotated. The proposed method trains the base
segmentation network by using a novel contrastive variance (CV) loss to exploit
the unlabeled pixels and a partial cross-entropy loss on the labeled pixels.
The CV loss function is designed to exploit the statistical spatial
distribution properties of organs in medical images and their variance
distribution map representations to enforce discriminative predictions over the
unlabeled pixels. Experimental results on two standard medical image datasets
demonstrate that the proposed method outperforms the state-of-the-art weakly
supervised methods on point-supervised medical image semantic segmentation
tasks.",2022-12-17,2022,2022-12,medical
"Local Differential Privacy Image Generation Using Flow-based Deep
  Generative Models","Diagnostic radiologists need artificial intelligence (AI) for medical
imaging, but access to medical images required for training in AI has become
increasingly restrictive. To release and use medical images, we need an
algorithm that can simultaneously protect privacy and preserve pathologies in
medical images. To develop such an algorithm, here, we propose DP-GLOW, a
hybrid of a local differential privacy (LDP) algorithm and one of the
flow-based deep generative models (GLOW). By applying a GLOW model, we
disentangle the pixelwise correlation of images, which makes it difficult to
protect privacy with straightforward LDP algorithms for images. Specifically,
we map images onto the latent vector of the GLOW model, each element of which
follows an independent normal distribution, and we apply the Laplace mechanism
to the latent vector. Moreover, we applied DP-GLOW to chest X-ray images to
generate LDP images while preserving pathologies.",2022-12-20,2022,2022-12,medical
"UnICLAM:Contrastive Representation Learning with Adversarial Masking for
  Unified and Interpretable Medical Vision Question Answering","Medical Visual Question Answering (Medical-VQA) aims to to answer clinical
questions regarding radiology images, assisting doctors with decision-making
options. Nevertheless, current Medical-VQA models learn cross-modal
representations through residing vision and texture encoders in dual separate
spaces, which lead to indirect semantic alignment. In this paper, we propose
UnICLAM, a Unified and Interpretable Medical-VQA model through Contrastive
Representation Learning with Adversarial Masking. Specifically, to learn an
aligned image-text representation, we first establish a unified dual-stream
pre-training structure with the gradually soft-parameter sharing strategy.
Technically, the proposed strategy learns a constraint for the vision and
texture encoders to be close in a same space, which is gradually loosened as
the higher number of layers. Moreover, for grasping the unified semantic
representation, we extend the adversarial masking data augmentation to the
contrastive representation learning of vision and text in a unified manner.
Concretely, while the encoder training minimizes the distance between original
and masking samples, the adversarial masking module keeps adversarial learning
to conversely maximize the distance. Furthermore, we also intuitively take a
further exploration to the unified adversarial masking augmentation model,
which improves the potential ante-hoc interpretability with remarkable
performance and efficiency. Experimental results on VQA-RAD and SLAKE public
benchmarks demonstrate that UnICLAM outperforms existing 11 state-of-the-art
Medical-VQA models. More importantly, we make an additional discussion about
the performance of UnICLAM in diagnosing heart failure, verifying that UnICLAM
exhibits superior few-shot adaption performance in practical disease diagnosis.",2022-12-21,2022,2022-12,medical
"A New Perspective to Boost Vision Transformer for Medical Image
  Classification","Transformer has achieved impressive successes for various computer vision
tasks. However, most of existing studies require to pretrain the Transformer
backbone on a large-scale labeled dataset (e.g., ImageNet) for achieving
satisfactory performance, which is usually unavailable for medical images.
Additionally, due to the gap between medical and natural images, the
improvement generated by the ImageNet pretrained weights significantly degrades
while transferring the weights to medical image processing tasks. In this
paper, we propose Bootstrap Own Latent of Transformer (BOLT), a self-supervised
learning approach specifically for medical image classification with the
Transformer backbone. Our BOLT consists of two networks, namely online and
target branches, for self-supervised representation learning. Concretely, the
online network is trained to predict the target network representation of the
same patch embedding tokens with a different perturbation. To maximally
excavate the impact of Transformer from limited medical data, we propose an
auxiliary difficulty ranking task. The Transformer is enforced to identify
which branch (i.e., online/target) is processing the more difficult perturbed
tokens. Overall, the Transformer endeavours itself to distill the
transformation-invariant features from the perturbed tokens to simultaneously
achieve difficulty measurement and maintain the consistency of self-supervised
representations. The proposed BOLT is evaluated on three medical image
processing tasks, i.e., skin lesion classification, knee fatigue fracture
grading and diabetic retinopathy grading. The experimental results validate the
superiority of our BOLT for medical image classification, compared to ImageNet
pretrained weights and state-of-the-art self-supervised learning approaches.",2023-01-03,2023,2023-01,medical
"Artificial Intelligence Model for Tumoral Clinical Decision Support
  Systems","Comparative diagnostic in brain tumor evaluation makes possible to use the
available information of a medical center to compare similar cases when a new
patient is evaluated. By leveraging Artificial Intelligence models, the
proposed system is able of retrieving the most similar cases of brain tumors
for a given query. The primary objective is to enhance the diagnostic process
by generating more accurate representations of medical images, with a
particular focus on patient-specific normal features and pathologies. The
proposed model uses Artificial Intelligence to detect patient features to
recommend the most similar cases from a database. The system not only suggests
similar cases but also balances the representation of healthy and abnormal
features in its design. This not only encourages the generalization of its use
but also aids clinicians in their decision-making processes. We conducted a
comparative analysis of our approach in relation to similar studies. The
proposed architecture obtains a Dice coefficient of 0.474 in both tumoral and
healthy regions of the patients, which outperforms previous literature. Our
proposed model excels at extracting and combining anatomical and pathological
features from brain \glspl{mr}, achieving state-of-the-art results while
relying on less expensive label information. This substantially reduces the
overall cost of the training process. This paper provides substantial grounds
for further exploration of the broader applicability and optimization of the
proposed architecture to enhance clinical decision-making. The novel approach
presented in this work marks a significant advancement in the field of medical
diagnosis, particularly in the context of Artificial Intelligence-assisted
image retrieval, and promises to reduce costs and improve the quality of
patient care using Artificial Intelligence as a support tool instead of a black
box system.",2023-01-09,2023,2023-01,medical
"Contrast with Major Classifier Vectors for Federated Medical Relation
  Extraction with Heterogeneous Label Distribution","Federated medical relation extraction enables multiple clients to train a
deep network collaboratively without sharing their raw medical data. In order
to handle the heterogeneous label distribution across clients, most of the
existing works only involve enforcing regularization between local and global
models during optimization. In this paper, we fully utilize the models of all
clients and propose a novel concept of \textit{major classifier vectors}, where
a group of class vectors is obtained in an ensemble rather than the weighted
average method on the server. The major classifier vectors are then distributed
to all clients and the local training of each client is Contrasted with Major
Classifier vectors (FedCMC), so the local model is not prone to overfitting to
the local label distribution. FedCMC requires only a small amount of additional
transfer of classifier parameters without any leakage of raw data, extracted
representations, and label distributions. Our extensive experiments show that
FedCMC outperforms the other state-of-the-art FL algorithms on three medical
relation extraction datasets.",2023-01-13,2023,2023-01,medical
"An Artificial Intelligence-based model for cell killing prediction:
  development, validation and explainability analysis of the ANAKIN model","The present work develops ANAKIN: an Artificial iNtelligence bAsed model for
(radiation induced) cell KIlliNg prediction. ANAKIN is trained and tested over
513 cell survival experiments with different types of radiation contained in
the publicly available PIDE database. We show how ANAKIN accurately predicts
several relevant biological endpoints over a wide broad range on ions beams and
for a high number of cell--lines. We compare the prediction of ANAKIN to the
only two radiobiological model for RBE prediction used in clinics, that is the
Microdosimetric Kinetic Model (MKM) and the Local Effect Model (LEM version
III), showing how ANAKIN has higher accuracy over the all considered biological
endpoints. At last, via modern techniques of Explainable Artificial
Intelligence (XAI), we show how ANAKIN predictions can be understood and
explained, highlighting how ANAKIN is in fact able to reproduce relevant
well-known biological patterns, such as the overkilling effect.",2023-01-19,2023,2023-01,medical
"Redesigning Electronic Health Record Systems to Support Developing
  Countries","Electronic Health Record (EHR) has become an essential tool in the healthcare
ecosystem, providing authorized clinicians with patients' health-related
information for better treatment. While most developed countries are taking
advantage of EHRs to improve their healthcare system, it remains challenging in
developing countries to support clinical decision-making and public health
using a computerized patient healthcare information system. This paper proposes
a novel EHR architecture suitable for developing countries--an architecture
that fosters inclusion and provides solutions tailored to all social classes
and socioeconomic statuses. Our architecture foresees an internet-free
(offline) solution to allow medical transactions between healthcare
organizations, and the storage of EHRs in geographically underserved and rural
areas. Moreover, we discuss how artificial intelligence can leverage anonymous
health-related information to enable better public health policy and
surveillance.",2023-01-31,2023,2023-01,medical
Leveraging Summary Guidance on Medical Report Summarization,"This study presents three deidentified large medical text datasets, named
DISCHARGE, ECHO and RADIOLOGY, which contain 50K, 16K and 378K pairs of report
and summary that are derived from MIMIC-III, respectively. We implement
convincing baselines of automated abstractive summarization on the proposed
datasets with pre-trained encoder-decoder language models, including BERT2BERT,
T5-large and BART. Further, based on the BART model, we leverage the sampled
summaries from the train set as prior knowledge guidance, for encoding
additional contextual representations of the guidance with the encoder and
enhancing the decoding representations in the decoder. The experimental results
confirm the improvement of ROUGE scores and BERTScore made by the proposed
method, outperforming the larger model T5-large.",2023-02-08,2023,2023-02,medical
Multi-Modal Evaluation Approach for Medical Image Segmentation,"Manual segmentation of medical images (e.g., segmenting tumors in CT scans)
is a high-effort task that can be accelerated with machine learning techniques.
However, selecting the right segmentation approach depends on the evaluation
function, particularly in medical image segmentation where we must deal with
dependency between voxels. For instance, in contrast to classical systems where
the predictions are either correct or incorrect, predictions in medical image
segmentation may be partially correct and incorrect simultaneously. In this
paper, we explore this expressiveness to extract the useful properties of these
systems and formally define a novel multi-modal evaluation (MME) approach to
measure the effectiveness of different segmentation methods. This approach
improves the segmentation evaluation by introducing new relevant and
interpretable characteristics, including detection property, boundary
alignment, uniformity, total volume, and relative volume. Our proposed approach
is open-source and publicly available for use. We have conducted several
reproducible experiments, including the segmentation of pancreas, liver tumors,
and multi-organs datasets, to show the applicability of the proposed approach.",2023-02-08,2023,2023-02,medical
"Informing clinical assessment by contextualizing post-hoc explanations
  of risk prediction models in type-2 diabetes","Medical experts may use Artificial Intelligence (AI) systems with greater
trust if these are supported by contextual explanations that let the
practitioner connect system inferences to their context of use. However, their
importance in improving model usage and understanding has not been extensively
studied. Hence, we consider a comorbidity risk prediction scenario and focus on
contexts regarding the patients clinical state, AI predictions about their risk
of complications, and algorithmic explanations supporting the predictions. We
explore how relevant information for such dimensions can be extracted from
Medical guidelines to answer typical questions from clinical practitioners. We
identify this as a question answering (QA) task and employ several
state-of-the-art LLMs to present contexts around risk prediction model
inferences and evaluate their acceptability. Finally, we study the benefits of
contextual explanations by building an end-to-end AI pipeline including data
cohorting, AI risk modeling, post-hoc model explanations, and prototyped a
visual dashboard to present the combined insights from different context
dimensions and data sources, while predicting and identifying the drivers of
risk of Chronic Kidney Disease - a common type-2 diabetes comorbidity. All of
these steps were performed in engagement with medical experts, including a
final evaluation of the dashboard results by an expert medical panel. We show
that LLMs, in particular BERT and SciBERT, can be readily deployed to extract
some relevant explanations to support clinical usage. To understand the
value-add of the contextual explanations, the expert panel evaluated these
regarding actionable insights in the relevant clinical setting. Overall, our
paper is one of the first end-to-end analyses identifying the feasibility and
benefits of contextual explanations in a real-world clinical use case.",2023-02-11,2023,2023-02,medical
Integrating Artificial Intelligence and Humanities in Healthcare,"Artificial Intelligence (AI) and Medical Humanities have become two of the
most crucial and rapidly growing fields in the current world. AI has made
substantial advancements in recent years, enabling the development of
algorithms and systems that can perform tasks traditionally done by humans.
Medical Humanities, on the other hand, is the intersection of medical sciences,
humanities, and the social sciences, and deals with the cultural, historical,
philosophical, ethical, and social aspects of health, illness, and medicine.
The integration of AI and Medical Humanities can offer innovative solutions to
some of the pressing issues in the medical field.",2023-02-13,2023,2023-02,medical
"RFC-Net: Learning High Resolution Global Features for Medical Image
  Segmentation on a Computational Budget","Learning High-Resolution representations is essential for semantic
segmentation. Convolutional neural network (CNN)architectures with downstream
and upstream propagation flow are popular for segmentation in medical
diagnosis. However, due to performing spatial downsampling and upsampling in
multiple stages, information loss is inexorable. On the contrary, connecting
layers densely on high spatial resolution is computationally expensive. In this
work, we devise a Loose Dense Connection Strategy to connect neurons in
subsequent layers with reduced parameters. On top of that, using a m-way Tree
structure for feature propagation we propose Receptive Field Chain Network
(RFC-Net) that learns high resolution global features on a compressed
computational space. Our experiments demonstrates that RFC-Net achieves
state-of-the-art performance on Kvasir and CVC-ClinicDB benchmarks for Polyp
segmentation.",2023-02-13,2023,2023-02,medical
"Validation of artificial intelligence containing products across the
  regulated healthcare industries","Purpose: The introduction of artificial intelligence / machine learning
(AI/ML) products to the regulated fields of pharmaceutical research and
development (R&D) and drug manufacture, and medical devices (MD) and in-vitro
diagnostics (IVD), poses new regulatory problems: a lack of a common
terminology and understanding leads to confusion, delays and product failures.
Validation as a key step in product development, common to each of these
sectors including computerized systems and AI/ML development, offers an
opportune point of comparison for aligning people and processes for
cross-sectoral product development.
  Methods: A comparative approach, built upon workshops and a subsequent
written sequence of exchanges, summarized in a look-up table suitable for
mixed-teams work.
  Results: 1. A bottom-up, definitions led, approach which leads to a
distinction between broad vs narrow validation, and their relationship to
regulatory regimes. 2. Common basis introduction to the primary methodologies
for AI-containing software validation. 3. Pharmaceutical drug development and
MD/IVD specific perspectives on compliant AI software development, as a basis
for collaboration.
  Conclusions: Alignment of the terms and methodologies used in validation of
software products containing artificial intelligence / machine learning (AI/ML)
components across the regulated industries of human health is a vital first
step in streamlining processes and improving workflows.",2023-02-13,2023,2023-02,medical
Tailoring Requirements Engineering for Responsible AI,"Requirements Engineering (RE) is the discipline for identifying, analyzing,
as well as ensuring the implementation and delivery of user, technical, and
societal requirements. Recently reported issues concerning the acceptance of
Artificial Intelligence (AI) solutions after deployment, e.g. in the medical,
automotive, or scientific domains, stress the importance of RE for designing
and delivering Responsible AI systems. In this paper, we argue that RE should
not only be carefully conducted but also tailored for Responsible AI. We
outline related challenges for research and practice.",2023-02-21,2023,2023-02,medical
Medical visual question answering using joint self-supervised learning,"Visual Question Answering (VQA) becomes one of the most active research
problems in the medical imaging domain. A well-known VQA challenge is the
intrinsic diversity between the image and text modalities, and in the medical
VQA task, there is another critical problem relying on the limited size of
labelled image-question-answer data. In this study we propose an
encoder-decoder framework that leverages the image-text joint representation
learned from large-scaled medical image-caption data and adapted to the
small-sized medical VQA task. The encoder embeds across the image-text dual
modalities with self-attention mechanism and is independently pre-trained on
the large-scaled medical image-caption dataset by multiple self-supervised
learning tasks. Then the decoder is connected to the top of the encoder and
fine-tuned using the small-sized medical VQA dataset. The experiment results
present that our proposed method achieves better performance comparing with the
baseline and SOTA methods.",2023-02-25,2023,2023-02,medical
"Improving Medical Speech-to-Text Accuracy with Vision-Language
  Pre-training Model","Automatic Speech Recognition (ASR) is a technology that converts spoken words
into text, facilitating interaction between humans and machines. One of the
most common applications of ASR is Speech-To-Text (STT) technology, which
simplifies user workflows by transcribing spoken words into text. In the
medical field, STT has the potential to significantly reduce the workload of
clinicians who rely on typists to transcribe their voice recordings. However,
developing an STT model for the medical domain is challenging due to the lack
of sufficient speech and text datasets. To address this issue, we propose a
medical-domain text correction method that modifies the output text of a
general STT system using the Vision Language Pre-training (VLP) method. VLP
combines textual and visual information to correct text based on image
knowledge. Our extensive experiments demonstrate that the proposed method
offers quantitatively and clinically significant improvements in STT
performance in the medical field. We further show that multi-modal
understanding of image and text information outperforms single-modal
understanding using only text information.",2023-02-27,2023,2023-02,medical
"Practical Statistical Considerations for the Clinical Validation of
  AI/ML-enabled Medical Diagnostic Devices","Artificial Intelligence (AI) and Machine-Learning (ML) models have been
increasingly used in medical products, such as medical device software. General
considerations on the statistical aspects for the evaluation of AI/ML-enabled
medical diagnostic devices are discussed in this paper. We also provide
relevant academic references and note good practices in addressing various
statistical challenges in the clinical validation of AI/ML-enabled medical
devices in the context of their intended use.",2023-03-02,2023,2023-03,medical
"Decision Support System for Chronic Diseases Based on Drug-Drug
  Interactions","Many patients with chronic diseases resort to multiple medications to relieve
various symptoms, which raises concerns about the safety of multiple medication
use, as severe drug-drug antagonism can lead to serious adverse effects or even
death. This paper presents a Decision Support System, called DSSDDI, based on
drug-drug interactions to support doctors prescribing decisions. DSSDDI
contains three modules, Drug-Drug Interaction (DDI) module, Medical Decision
(MD) module and Medical Support (MS) module. The DDI module learns safer and
more effective drug representations from the drug-drug interactions. To capture
the potential causal relationship between DDI and medication use, the MD module
considers the representations of patients and drugs as context, DDI and
patients' similarity as treatment, and medication use as outcome to construct
counterfactual links for the representation learning. Furthermore, the MS
module provides drug candidates to doctors with explanations. Experiments on
the chronic data collected from the Hong Kong Chronic Disease Study Project and
a public diagnostic data MIMIC-III demonstrate that DSSDDI can be a reliable
reference for doctors in terms of safety and efficiency of clinical diagnosis,
with significant improvements compared to baseline methods.",2023-03-04,2023,2023-03,medical
A Comparison of Methods for Neural Network Aggregation,"Deep learning has been successful in the theoretical aspect. For deep
learning to succeed in industry, we need to have algorithms capable of handling
many inconsistencies appearing in real data. These inconsistencies can have
large effects on the implementation of a deep learning algorithm. Artificial
Intelligence is currently changing the medical industry. However, receiving
authorization to use medical data for training machine learning algorithms is a
huge hurdle. A possible solution is sharing the data without sharing the
patient information. We propose a multi-party computation protocol for the deep
learning algorithm. The protocol enables to conserve both the privacy and the
security of the training data. Three approaches of neural networks assembly are
analyzed: transfer learning, average ensemble learning, and series network
learning. The results are compared to approaches based on data-sharing in
different experiments. We analyze the security issues of the proposed protocol.
Although the analysis is based on medical data, the results of multi-party
computation of machine learning training are theoretical and can be implemented
in multiple research areas.",2023-03-06,2023,2023-03,medical
"Cybersecurity of AI medical devices: risks, legislation, and challenges","Medical devices and artificial intelligence systems rapidly transform
healthcare provisions. At the same time, due to their nature, AI in or as
medical devices might get exposed to cyberattacks, leading to patient safety
and security risks. This book chapter is divided into three parts. The first
part starts by setting the scene where we explain the role of cybersecurity in
healthcare. Then, we briefly define what we refer to when we talk about AI that
is considered a medical device by itself or supports one. To illustrate the
risks such medical devices pose, we provide three examples: the poisoning of
datasets, social engineering, and data or source code extraction. In the second
part, the paper provides an overview of the European Union's regulatory
framework relevant for ensuring the cybersecurity of AI as or in medical
devices (MDR, NIS Directive, Cybersecurity Act, GDPR, the AI Act proposal and
the NIS 2 Directive proposal). Finally, the third part of the paper examines
possible challenges stemming from the EU regulatory framework. In particular,
we look toward the challenges deriving from the two legislative proposals and
their interaction with the existing legislation concerning AI medical devices'
cybersecurity. They are structured as answers to the following questions: (1)
how will the AI Act interact with the MDR regarding the cybersecurity and
safety requirements?; (2) how should we interpret incident notification
requirements from the NIS 2 Directive proposal and MDR?; and (3) what are the
consequences of the evolving term of critical infrastructures?
  [This is a draft chapter. The final version will be available in Research
Handbook on Health, AI and the Law edited by Barry Solaiman & I. Glenn Cohen,
forthcoming 2023, Edward Elgar Publishing Ltd]",2023-03-06,2023,2023-03,medical
Emerging AI Technologies Inspiring the Next Generation of E-textiles,"The smart textile and wearables sector is looking towards advancing
technologies to meet both industry, consumer and new emerging innovative
textile application demands, within a fast paced textile industry. In parallel
inspiration based on the biological neural workings of the human brain is
driving the next generation of artificial intelligence. Artificial intelligence
inspired hardware (neuromorphic computing) and software modules mimicking the
processing capabilities and properties of neural networks and the human nervous
system are taking shape. The textile sector needs to actively look at such
emerging and new technologies taking inspiration from their workings and
processing methods in order to stimulate new and innovative embedded
intelligence advancements in the etextile world. This emerging next generation
of Artificial intelligence(AI) is rapidly gaining interest across varying
industries (textile, medical, automotive, aerospace, military). How such
properties can inspire and drive advancements within the etextiles sector needs
to be considered. This paper will provide an insight into current
nanotechnology and artificial intelligence advancements in the etextiles domain
before focusing specifically on the future vision and direction around the
potential application of neuromorphic computing and spiking neural network
inspired AI technologies within the textile sector. We investigate the core
architectural elements of artificial neural networks, neuromorphic computing
and how such neuroscience inspired technologies could impact and inspire change
and new research developments within the e-textile sector.",2023-03-06,2023,2023-03,medical
Towards Trust of Explainable AI in Thyroid Nodule Diagnosis,"The ability to explain the prediction of deep learning models to end-users is
an important feature to leverage the power of artificial intelligence (AI) for
the medical decision-making process, which is usually considered
non-transparent and challenging to comprehend. In this paper, we apply
state-of-the-art eXplainable artificial intelligence (XAI) methods to explain
the prediction of the black-box AI models in the thyroid nodule diagnosis
application. We propose new statistic-based XAI methods, namely Kernel Density
Estimation and Density map, to explain the case of no nodule detected. XAI
methods' performances are considered under a qualitative and quantitative
comparison as feedback to improve the data quality and the model performance.
Finally, we survey to assess doctors' and patients' trust in XAI explanations
of the model's decisions on thyroid nodule images.",2023-03-08,2023,2023-03,medical
"Contextualized Medication Information Extraction Using Transformer-based
  Deep Learning Architectures","Objective: To develop a natural language processing (NLP) system to extract
medications and contextual information that help understand drug changes. This
project is part of the 2022 n2c2 challenge.
  Materials and methods: We developed NLP systems for medication mention
extraction, event classification (indicating medication changes discussed or
not), and context classification to classify medication changes context into 5
orthogonal dimensions related to drug changes. We explored 6 state-of-the-art
pretrained transformer models for the three subtasks, including GatorTron, a
large language model pretrained using >90 billion words of text (including >80
billion words from >290 million clinical notes identified at the University of
Florida Health). We evaluated our NLP systems using annotated data and
evaluation scripts provided by the 2022 n2c2 organizers.
  Results:Our GatorTron models achieved the best F1-scores of 0.9828 for
medication extraction (ranked 3rd), 0.9379 for event classification (ranked
2nd), and the best micro-average accuracy of 0.9126 for context classification.
GatorTron outperformed existing transformer models pretrained using smaller
general English text and clinical text corpora, indicating the advantage of
large language models.
  Conclusion: This study demonstrated the advantage of using large transformer
models for contextual medication information extraction from clinical
narratives.",2023-03-14,2023,2023-03,medical
"Hybrid Classic-Quantum Computing for Staging of Invasive Ductal
  Carcinoma of Breast","Despite the great current relevance of Artificial Intelligence, and the
extraordinary innovations that this discipline has brought to many fields
-among which, without a doubt, medicine is found-, experts in medical
applications of Artificial Intelligence are looking for new alternatives to
solve problems for which current Artificial Intelligence programs do not
provide with optimal solutions. For this, one promising option could be the use
of the concepts and ideas of Quantum Mechanics, for the construction of
quantum-based Artificial Intelligence systems. From a hybrid classical-quantum
perspective, this article deals with the application of quantum computing
techniques for the staging of Invasive Ductal Carcinoma of the breast. It
includes: (1) a general explanation of a classical, and well-established,
approach for medical reasoning, (2) a description of the clinical problem, (3)
a conceptual model for staging invasive ductal carcinoma, (4) some basic
notions about Quantum Rule-Based Systems, (5) a step-by-step explanation of the
proposed approach for quantum staging of the invasive ductal carcinoma, and (6)
the results obtained after running the quantum system on a significant number
of use cases. A detailed discussion is also provided at the end of this paper.",2023-03-17,2023,2023-03,medical
Multimodal Information Fusion For The Diagnosis Of Diabetic Retinopathy,"Diabetes is a chronic disease characterized by excess sugar in the blood and
affects 422 million people worldwide, including 3.3 million in France. One of
the frequent complications of diabetes is diabetic retinopathy (DR): it is the
leading cause of blindness in the working population of developed countries. As
a result, ophthalmology is on the verge of a revolution in screening,
diagnosing, and managing of pathologies. This upheaval is led by the arrival of
technologies based on artificial intelligence. The ""Evaluation intelligente de
la r\'etinopathie diab\'etique"" (EviRed) project uses artificial intelligence
to answer a medical need: replacing the current classification of diabetic
retinopathy which is mainly based on outdated fundus photography and providing
an insufficient prediction precision. EviRed exploits modern fundus imaging
devices and artificial intelligence to properly integrate the vast amount of
data they provide with other available medical data of the patient. The goal is
to improve diagnosis and prediction and help ophthalmologists to make better
decisions during diabetic retinopathy follow-up. In this study, we investigate
the fusion of different modalities acquired simultaneously with a PLEXElite
9000 (Carl Zeiss Meditec Inc. Dublin, California, USA), namely 3-D structural
optical coherence tomography (OCT), 3-D OCT angiography (OCTA) and 2-D Line
Scanning Ophthalmoscope (LSO), for the automatic detection of proliferative DR.",2023-03-20,2023,2023-03,medical
"How can Deep Learning Retrieve the Write-Missing Additional Diagnosis
  from Chinese Electronic Medical Record For DRG","The purpose of write-missing diagnosis detection is to find diseases that
have been clearly diagnosed from medical records but are missed in the
discharge diagnosis. Unlike the definition of missed diagnosis, the
write-missing diagnosis is clearly manifested in the medical record without
further reasoning. The write-missing diagnosis is a common problem, often
caused by physician negligence. The write-missing diagnosis will result in an
incomplete diagnosis of medical records. While under DRG grouping, the
write-missing diagnoses will miss important additional diagnoses (CC, MCC),
thus affecting the correct rate of DRG enrollment.
  Under the circumstance that countries generally start to adopt DRG enrollment
and payment, the problem of write-missing diagnosis is a common and serious
problem. The current manual-based method is expensive due to the complex
content of the full medical record. We think this problem is suitable to be
solved as natural language processing. But to the best of our knowledge, no
researchers have conducted research on this problem based on natural language
processing methods.
  We propose a framework for solving the problem of write-missing diagnosis,
which mainly includes three modules: disease recall module, disease context
logic judgment module, and disease relationship comparison module. Through this
framework, we verify that the problem of write-missing diagnosis can be solved
well, and the results are interpretable. At the same time, we propose advanced
solutions for the disease context logic judgment module and disease
relationship comparison module, which have obvious advantages compared with the
mainstream methods of the same type of problems. Finally, we verified the value
of our proposed framework under DRG medical insurance payment in a tertiary
hospital.",2023-03-28,2023,2023-03,medical
"A New Deep Learning and XAI-Based Algorithm for Features Selection in
  Genomics","In the field of functional genomics, the analysis of gene expression profiles
through Machine and Deep Learning is increasingly providing meaningful insight
into a number of diseases. The paper proposes a novel algorithm to perform
Feature Selection on genomic-scale data, which exploits the reconstruction
capabilities of autoencoders and an ad-hoc defined Explainable Artificial
Intelligence-based score in order to select the most informative genes for
diagnosis, prognosis, and precision medicine. Results of the application on a
Chronic Lymphocytic Leukemia dataset evidence the effectiveness of the
algorithm, by identifying and suggesting a set of meaningful genes for further
medical investigation.",2023-03-29,2023,2023-03,medical
"Demo Alleviate: Demonstrating Artificial Intelligence Enabled Virtual
  Assistance for Telehealth: The Mental Health Case","After the pandemic, artificial intelligence (AI) powered support for mental
health care has become increasingly important. The breadth and complexity of
significant challenges required to provide adequate care involve: (a)
Personalized patient understanding, (b) Safety-constrained and medically
validated chatbot patient interactions, and (c) Support for continued
feedback-based refinements in design using chatbot-patient interactions. We
propose Alleviate, a chatbot designed to assist patients suffering from mental
health challenges with personalized care and assist clinicians with
understanding their patients better. Alleviate draws from an array of publicly
available clinically valid mental-health texts and databases, allowing
Alleviate to make medically sound and informed decisions. In addition,
Alleviate's modular design and explainable decision-making lends itself to
robust and continued feedback-based refinements to its design. In this paper,
we explain the different modules of Alleviate and submit a short video
demonstrating Alleviate's capabilities to help patients and clinicians
understand each other better to facilitate optimal care strategies.",2023-03-31,2023,2023-03,medical
Medical Pathologies Prediction : Systematic Review and Proposed Approach,"The healthcare sector is an important pillar of every community, numerous
research studies have been carried out in this context to optimize medical
processes and improve care quality and facilitate patient management. In this
article we have analyzed and examined different works concerning the
exploitation of the most recent technologies such as big data, artificial
intelligence, machine learning, and deep learning for the improvement of health
care, which enabled us to propose our general approach concentrating on the
collection, preprocessing and clustering of medical data to facilitate access,
after analysis, to the patients and health professionals to predict the most
frequent pathologies with better precision within a notable timeframe.
  keywords: Healthcare, big data, artificial intelligence, automatic language
processing, data mining, predictive models.",2023-04-01,2023,2023-04,medical
Q2ATransformer: Improving Medical VQA via an Answer Querying Decoder,"Medical Visual Question Answering (VQA) systems play a supporting role to
understand clinic-relevant information carried by medical images. The questions
to a medical image include two categories: close-end (such as Yes/No question)
and open-end. To obtain answers, the majority of the existing medical VQA
methods relies on classification approaches, while a few works attempt to use
generation approaches or a mixture of the two. The classification approaches
are relatively simple but perform poorly on long open-end questions. To bridge
this gap, in this paper, we propose a new Transformer based framework for
medical VQA (named as Q2ATransformer), which integrates the advantages of both
the classification and the generation approaches and provides a unified
treatment for the close-end and open-end questions. Specifically, we introduce
an additional Transformer decoder with a set of learnable candidate answer
embeddings to query the existence of each answer class to a given
image-question pair. Through the Transformer attention, the candidate answer
embeddings interact with the fused features of the image-question pair to make
the decision. In this way, despite being a classification-based approach, our
method provides a mechanism to interact with the answer information for
prediction like the generation-based approaches. On the other hand, by
classification, we mitigate the task difficulty by reducing the search space of
answers. Our method achieves new state-of-the-art performance on two medical
VQA benchmarks. Especially, for the open-end questions, we achieve 79.19% on
VQA-RAD and 54.85% on PathVQA, with 16.09% and 41.45% absolute improvements,
respectively.",2023-04-04,2023,2023-04,medical
"ACTION++: Improving Semi-supervised Medical Image Segmentation with
  Adaptive Anatomical Contrast","Medical data often exhibits long-tail distributions with heavy class
imbalance, which naturally leads to difficulty in classifying the minority
classes (i.e., boundary regions or rare objects). Recent work has significantly
improved semi-supervised medical image segmentation in long-tailed scenarios by
equipping them with unsupervised contrastive criteria. However, it remains
unclear how well they will perform in the labeled portion of data where class
distribution is also highly imbalanced. In this work, we present ACTION++, an
improved contrastive learning framework with adaptive anatomical contrast for
semi-supervised medical segmentation. Specifically, we propose an adaptive
supervised contrastive loss, where we first compute the optimal locations of
class centers uniformly distributed on the embedding space (i.e., off-line),
and then perform online contrastive matching training by encouraging different
class features to adaptively match these distinct and uniformly distributed
class centers. Moreover, we argue that blindly adopting a constant temperature
$\tau$ in the contrastive loss on long-tailed medical data is not optimal, and
propose to use a dynamic $\tau$ via a simple cosine schedule to yield better
separation between majority and minority classes. Empirically, we evaluate
ACTION++ on ACDC and LA benchmarks and show that it achieves state-of-the-art
across two semi-supervised settings. Theoretically, we analyze the performance
of adaptive anatomical contrast and confirm its superiority in label
efficiency.",2023-04-05,2023,2023-04,medical
"Implicit Anatomical Rendering for Medical Image Segmentation with
  Stochastic Experts","Integrating high-level semantically correlated contents and low-level
anatomical features is of central importance in medical image segmentation.
Towards this end, recent deep learning-based medical segmentation methods have
shown great promise in better modeling such information. However, convolution
operators for medical segmentation typically operate on regular grids, which
inherently blur the high-frequency regions, i.e., boundary regions. In this
work, we propose MORSE, a generic implicit neural rendering framework designed
at an anatomical level to assist learning in medical image segmentation. Our
method is motivated by the fact that implicit neural representation has been
shown to be more effective in fitting complex signals and solving computer
graphics problems than discrete grid-based representation. The core of our
approach is to formulate medical image segmentation as a rendering problem in
an end-to-end manner. Specifically, we continuously align the coarse
segmentation prediction with the ambiguous coordinate-based point
representations and aggregate these features to adaptively refine the boundary
region. To parallelly optimize multi-scale pixel-level features, we leverage
the idea from Mixture-of-Expert (MoE) to design and train our MORSE with a
stochastic gating mechanism. Our experiments demonstrate that MORSE can work
well with different medical segmentation backbones, consistently achieving
competitive performance improvements in both 2D and 3D supervised medical
segmentation methods. We also theoretically analyze the superiority of MORSE.",2023-04-06,2023,2023-04,medical
Transformer Utilization in Medical Image Segmentation Networks,"Owing to success in the data-rich domain of natural images, Transformers have
recently become popular in medical image segmentation. However, the pairing of
Transformers with convolutional blocks in varying architectural permutations
leaves their relative effectiveness to open interpretation. We introduce
Transformer Ablations that replace the Transformer blocks with plain linear
operators to quantify this effectiveness. With experiments on 8 models on 2
medical image segmentation tasks, we explore -- 1) the replaceable nature of
Transformer-learnt representations, 2) Transformer capacity alone cannot
prevent representational replaceability and works in tandem with effective
design, 3) The mere existence of explicit feature hierarchies in transformer
blocks is more beneficial than accompanying self-attention modules, 4) Major
spatial downsampling before Transformer modules should be used with caution.",2023-04-09,2023,2023-04,medical
"FrenchMedMCQA: A French Multiple-Choice Question Answering Dataset for
  Medical domain","This paper introduces FrenchMedMCQA, the first publicly available
Multiple-Choice Question Answering (MCQA) dataset in French for medical domain.
It is composed of 3,105 questions taken from real exams of the French medical
specialization diploma in pharmacy, mixing single and multiple answers. Each
instance of the dataset contains an identifier, a question, five possible
answers and their manual correction(s). We also propose first baseline models
to automatically process this MCQA task in order to report on the current
performances and to highlight the difficulty of the task. A detailed analysis
of the results showed that it is necessary to have representations adapted to
the medical domain or to the MCQA task: in our case, English specialized models
yielded better results than generic French ones, even though FrenchMedMCQA is
in French. Corpus, models and tools are available online.",2023-04-09,2023,2023-04,medical
"BerDiff: Conditional Bernoulli Diffusion Model for Medical Image
  Segmentation","Medical image segmentation is a challenging task with inherent ambiguity and
high uncertainty, attributed to factors such as unclear tumor boundaries and
multiple plausible annotations. The accuracy and diversity of segmentation
masks are both crucial for providing valuable references to radiologists in
clinical practice. While existing diffusion models have shown strong capacities
in various visual generation tasks, it is still challenging to deal with
discrete masks in segmentation. To achieve accurate and diverse medical image
segmentation masks, we propose a novel conditional Bernoulli Diffusion model
for medical image segmentation (BerDiff). Instead of using the Gaussian noise,
we first propose to use the Bernoulli noise as the diffusion kernel to enhance
the capacity of the diffusion model for binary segmentation tasks, resulting in
more accurate segmentation masks. Second, by leveraging the stochastic nature
of the diffusion model, our BerDiff randomly samples the initial Bernoulli
noise and intermediate latent variables multiple times to produce a range of
diverse segmentation masks, which can highlight salient regions of interest
that can serve as valuable references for radiologists. In addition, our
BerDiff can efficiently sample sub-sequences from the overall trajectory of the
reverse diffusion, thereby speeding up the segmentation process. Extensive
experimental results on two medical image segmentation datasets with different
modalities demonstrate that our BerDiff outperforms other recently published
state-of-the-art methods. Our results suggest diffusion models could serve as a
strong backbone for medical image segmentation.",2023-04-10,2023,2023-04,medical
"MedAlpaca -- An Open-Source Collection of Medical Conversational AI
  Models and Training Data","As large language models (LLMs) like OpenAI's GPT series continue to make
strides, we witness the emergence of artificial intelligence applications in an
ever-expanding range of fields. In medicine, these LLMs hold considerable
promise for improving medical workflows, diagnostics, patient care, and
education. Yet, there is an urgent need for open-source models that can be
deployed on-premises to safeguard patient privacy. In our work, we present an
innovative dataset consisting of over 160,000 entries, specifically crafted to
fine-tune LLMs for effective medical applications. We investigate the impact of
fine-tuning these datasets on publicly accessible pre-trained LLMs, and
subsequently, we juxtapose the performance of pre-trained-only models against
the fine-tuned models concerning the examinations that future medical doctors
must pass to achieve certification.",2023-04-14,2023,2023-04,medical
Medical Question Summarization with Entity-driven Contrastive Learning,"By summarizing longer consumer health questions into shorter and essential
ones, medical question answering (MQA) systems can more accurately understand
consumer intentions and retrieve suitable answers. However, medical question
summarization is very challenging due to obvious distinctions in health trouble
descriptions from patients and doctors. Although existing works have attempted
to utilize Seq2Seq, reinforcement learning, or contrastive learning to solve
the problem, two challenges remain: how to correctly capture question focus to
model its semantic intention, and how to obtain reliable datasets to fairly
evaluate performance. To address these challenges, this paper proposes a novel
medical question summarization framework using entity-driven contrastive
learning (ECL). ECL employs medical entities in frequently asked questions
(FAQs) as focuses and devises an effective mechanism to generate hard negative
samples. This approach forces models to pay attention to the crucial focus
information and generate more ideal question summarization. Additionally, we
find that some MQA datasets suffer from serious data leakage problems, such as
the iCliniq dataset's 33% duplicate rate. To evaluate the related methods
fairly, this paper carefully checks leaked samples to reorganize more
reasonable datasets. Extensive experiments demonstrate that our ECL method
outperforms state-of-the-art methods by accurately capturing question focus and
generating medical question summaries. The code and datasets are available at
https://github.com/yrbobo/MQS-ECL.",2023-04-15,2023,2023-04,medical
Segment Anything Model for Medical Image Analysis: an Experimental Study,"Training segmentation models for medical images continues to be challenging
due to the limited availability of data annotations. Segment Anything Model
(SAM) is a foundation model that is intended to segment user-defined objects of
interest in an interactive manner. While the performance on natural images is
impressive, medical image domains pose their own set of challenges. Here, we
perform an extensive evaluation of SAM's ability to segment medical images on a
collection of 19 medical imaging datasets from various modalities and
anatomies. We report the following findings: (1) SAM's performance based on
single prompts highly varies depending on the dataset and the task, from
IoU=0.1135 for spine MRI to IoU=0.8650 for hip X-ray. (2) Segmentation
performance appears to be better for well-circumscribed objects with prompts
with less ambiguity and poorer in various other scenarios such as the
segmentation of brain tumors. (3) SAM performs notably better with box prompts
than with point prompts. (4) SAM outperforms similar methods RITM, SimpleClick,
and FocalClick in almost all single-point prompt settings. (5) When
multiple-point prompts are provided iteratively, SAM's performance generally
improves only slightly while other methods' performance improves to the level
that surpasses SAM's point-based performance. We also provide several
illustrations for SAM's performance on all tested datasets, iterative
segmentation, and SAM's behavior given prompt ambiguity. We conclude that SAM
shows impressive zero-shot segmentation performance for certain medical imaging
datasets, but moderate to poor performance for others. SAM has the potential to
make a significant impact in automated medical image segmentation in medical
imaging, but appropriate care needs to be applied when using it.",2023-04-20,2023,2023-04,medical
"Input Augmentation with SAM: Boosting Medical Image Segmentation with
  Segmentation Foundation Model","The Segment Anything Model (SAM) is a recently developed large model for
general-purpose segmentation for computer vision tasks. SAM was trained using
11 million images with over 1 billion masks and can produce segmentation
results for a wide range of objects in natural scene images. SAM can be viewed
as a general perception model for segmentation (partitioning images into
semantically meaningful regions). Thus, how to utilize such a large foundation
model for medical image segmentation is an emerging research target. This paper
shows that although SAM does not immediately give high-quality segmentation for
medical image data, its generated masks, features, and stability scores are
useful for building and training better medical image segmentation models. In
particular, we demonstrate how to use SAM to augment image input for
commonly-used medical image segmentation models (e.g., U-Net). Experiments on
three segmentation tasks show the effectiveness of our proposed SAMAug method.
The code is available at \url{https://github.com/yizhezhang2000/SAMAug}.",2023-04-22,2023,2023-04,medical
Differentiate ChatGPT-generated and Human-written Medical Texts,"Background: Large language models such as ChatGPT are capable of generating
grammatically perfect and human-like text content, and a large number of
ChatGPT-generated texts have appeared on the Internet. However, medical texts
such as clinical notes and diagnoses require rigorous validation, and erroneous
medical content generated by ChatGPT could potentially lead to disinformation
that poses significant harm to healthcare and the general public.
  Objective: This research is among the first studies on responsible and
ethical AIGC (Artificial Intelligence Generated Content) in medicine. We focus
on analyzing the differences between medical texts written by human experts and
generated by ChatGPT, and designing machine learning workflows to effectively
detect and differentiate medical texts generated by ChatGPT.
  Methods: We first construct a suite of datasets containing medical texts
written by human experts and generated by ChatGPT. In the next step, we analyze
the linguistic features of these two types of content and uncover differences
in vocabulary, part-of-speech, dependency, sentiment, perplexity, etc. Finally,
we design and implement machine learning methods to detect medical text
generated by ChatGPT.
  Results: Medical texts written by humans are more concrete, more diverse, and
typically contain more useful information, while medical texts generated by
ChatGPT pay more attention to fluency and logic, and usually express general
terminologies rather than effective information specific to the context of the
problem. A BERT-based model can effectively detect medical texts generated by
ChatGPT, and the F1 exceeds 95%.",2023-04-23,2023,2023-04,medical
"A optimization framework for herbal prescription planning based on deep
  reinforcement learning","Treatment planning for chronic diseases is a critical task in medical
artificial intelligence, particularly in traditional Chinese medicine (TCM).
However, generating optimized sequential treatment strategies for patients with
chronic diseases in different clinical encounters remains a challenging issue
that requires further exploration. In this study, we proposed a TCM herbal
prescription planning framework based on deep reinforcement learning for
chronic disease treatment (PrescDRL). PrescDRL is a sequential herbal
prescription optimization model that focuses on long-term effectiveness rather
than achieving maximum reward at every step, thereby ensuring better patient
outcomes. We constructed a high-quality benchmark dataset for sequential
diagnosis and treatment of diabetes and evaluated PrescDRL against this
benchmark. Our results showed that PrescDRL achieved a higher curative effect,
with the single-step reward improving by 117% and 153% compared to doctors.
Furthermore, PrescDRL outperformed the benchmark in prescription prediction,
with precision improving by 40.5% and recall improving by 63%. Overall, our
study demonstrates the potential of using artificial intelligence to improve
clinical intelligent diagnosis and treatment in TCM.",2023-04-25,2023,2023-04,medical
"Towards Medical Artificial General Intelligence via Knowledge-Enhanced
  Multimodal Pretraining","Medical artificial general intelligence (MAGI) enables one foundation model
to solve different medical tasks, which is very practical in the medical
domain. It can significantly reduce the requirement of large amounts of
task-specific data by sufficiently sharing medical knowledge among different
tasks. However, due to the challenges of designing strongly generalizable
models with limited and complex medical data, most existing approaches tend to
develop task-specific models. To take a step towards MAGI, we propose a new
paradigm called Medical-knOwledge-enhanced mulTimOdal pretRaining (MOTOR). In
MOTOR, we combine two kinds of basic medical knowledge, i.e., general and
specific knowledge, in a complementary manner to boost the general pretraining
process. As a result, the foundation model with comprehensive basic knowledge
can learn compact representations from pretraining radiographic data for better
cross-modal alignment. MOTOR unifies the understanding and generation, which
are two kinds of core intelligence of an AI system, into a single medical
foundation model, to flexibly handle more diverse medical tasks. To enable a
comprehensive evaluation and facilitate further research, we construct a
medical multimodal benchmark including a wide range of downstream tasks, such
as chest x-ray report generation and medical visual question answering.
Extensive experiments on our benchmark show that MOTOR obtains promising
results through simple task-oriented adaptation. The visualization shows that
the injected knowledge successfully highlights key information in the medical
data, demonstrating the excellent interpretability of MOTOR. Our MOTOR
successfully mimics the human practice of fulfilling a ""medical student"" to
accelerate the process of becoming a ""specialist"". We believe that our work
makes a significant stride in realizing MAGI.",2023-04-26,2023,2023-04,medical
"Zero-shot performance of the Segment Anything Model (SAM) in 2D medical
  imaging: A comprehensive evaluation and practical guidelines","Segmentation in medical imaging is a critical component for the diagnosis,
monitoring, and treatment of various diseases and medical conditions.
Presently, the medical segmentation landscape is dominated by numerous
specialized deep learning models, each fine-tuned for specific segmentation
tasks and image modalities. The recently-introduced Segment Anything Model
(SAM) employs the ViT neural architecture and harnesses a massive training
dataset to segment nearly any object; however, its suitability to the medical
domain has not yet been investigated. In this study, we explore the zero-shot
performance of SAM in medical imaging by implementing eight distinct prompt
strategies across six datasets from four imaging modalities, including X-ray,
ultrasound, dermatoscopy, and colonoscopy. Our findings reveal that SAM's
zero-shot performance is not only comparable to, but in certain cases,
surpasses the current state-of-the-art. Based on these results, we propose
practical guidelines that require minimal interaction while consistently
yielding robust outcomes across all assessed contexts. The source code, along
with a demonstration of the recommended guidelines, can be accessed at
https://github.com/Malta-Lab/SAM-zero-shot-in-Medical-Imaging.",2023-04-28,2023,2023-04,medical
"DIAMANT: Dual Image-Attention Map Encoders For Medical Image
  Segmentation","Although purely transformer-based architectures showed promising performance
in many computer vision tasks, many hybrid models consisting of CNN and
transformer blocks are introduced to fit more specialized tasks. Nevertheless,
despite the performance gain of both pure and hybrid transformer-based
architectures compared to CNNs in medical imaging segmentation, their high
training cost and complexity make it challenging to use them in real scenarios.
In this work, we propose simple architectures based on purely convolutional
layers, and show that by just taking advantage of the attention map
visualizations obtained from a self-supervised pretrained vision transformer
network (e.g., DINO) one can outperform complex transformer-based networks with
much less computation costs. The proposed architecture is composed of two
encoder branches with the original image as input in one branch and the
attention map visualizations of the same image from multiple self-attention
heads from a pre-trained DINO model (as multiple channels) in the other branch.
The results of our experiments on two publicly available medical imaging
datasets show that the proposed pipeline outperforms U-Net and the
state-of-the-art medical image segmentation models.",2023-04-28,2023,2023-04,medical
SCOPE: Structural Continuity Preservation for Medical Image Segmentation,"Although the preservation of shape continuity and physiological anatomy is a
natural assumption in the segmentation of medical images, it is often neglected
by deep learning methods that mostly aim for the statistical modeling of input
data as pixels rather than interconnected structures. In biological structures,
however, organs are not separate entities; for example, in reality, a severed
vessel is an indication of an underlying problem, but traditional segmentation
models are not designed to strictly enforce the continuity of anatomy,
potentially leading to inaccurate medical diagnoses. To address this issue, we
propose a graph-based approach that enforces the continuity and connectivity of
anatomical topology in medical images. Our method encodes the continuity of
shapes as a graph constraint, ensuring that the network's predictions maintain
this continuity. We evaluate our method on two public benchmarks on retinal
vessel segmentation, showing significant improvements in connectivity metrics
compared to traditional methods while getting better or on-par performance on
segmentation metrics.",2023-04-28,2023,2023-04,medical
SAM on Medical Images: A Comprehensive Study on Three Prompt Modes,"The Segment Anything Model (SAM) made an eye-catching debut recently and
inspired many researchers to explore its potential and limitation in terms of
zero-shot generalization capability. As the first promptable foundation model
for segmentation tasks, it was trained on a large dataset with an unprecedented
number of images and annotations. This large-scale dataset and its promptable
nature endow the model with strong zero-shot generalization. Although the SAM
has shown competitive performance on several datasets, we still want to
investigate its zero-shot generalization on medical images. As we know, the
acquisition of medical image annotation usually requires a lot of effort from
professional practitioners. Therefore, if there exists a foundation model that
can give high-quality mask prediction simply based on a few point prompts, this
model will undoubtedly become the game changer for medical image analysis. To
evaluate whether SAM has the potential to become the foundation model for
medical image segmentation tasks, we collected more than 12 public medical
image datasets that cover various organs and modalities. We also explore what
kind of prompt can lead to the best zero-shot performance with different
modalities. Furthermore, we find that a pattern shows that the perturbation of
the box size will significantly change the prediction accuracy. Finally,
Extensive experiments show that the predicted mask quality varied a lot among
different datasets. And providing proper prompts, such as bounding boxes, to
the SAM will significantly increase its performance.",2023-04-28,2023,2023-04,medical
"Generating medically-accurate summaries of patient-provider dialogue: A
  multi-stage approach using large language models","A medical provider's summary of a patient visit serves several critical
purposes, including clinical decision-making, facilitating hand-offs between
providers, and as a reference for the patient. An effective summary is required
to be coherent and accurately capture all the medically relevant information in
the dialogue, despite the complexity of patient-generated language. Even minor
inaccuracies in visit summaries (for example, summarizing ""patient does not
have a fever"" when a fever is present) can be detrimental to the outcome of
care for the patient.
  This paper tackles the problem of medical conversation summarization by
discretizing the task into several smaller dialogue-understanding tasks that
are sequentially built upon. First, we identify medical entities and their
affirmations within the conversation to serve as building blocks. We study
dynamically constructing few-shot prompts for tasks by conditioning on relevant
patient information and use GPT-3 as the backbone for our experiments. We also
develop GPT-derived summarization metrics to measure performance against
reference summaries quantitatively. Both our human evaluation study and metrics
for medical correctness show that summaries generated using this approach are
clinically accurate and outperform the baseline approach of summarizing the
dialog in a zero-shot, single-prompt setting.",2023-05-10,2023,2023-05,medical
"MedGPTEval: A Dataset and Benchmark to Evaluate Responses of Large
  Language Models in Medicine","METHODS: First, a set of evaluation criteria is designed based on a
comprehensive literature review. Second, existing candidate criteria are
optimized for using a Delphi method by five experts in medicine and
engineering. Third, three clinical experts design a set of medical datasets to
interact with LLMs. Finally, benchmarking experiments are conducted on the
datasets. The responses generated by chatbots based on LLMs are recorded for
blind evaluations by five licensed medical experts. RESULTS: The obtained
evaluation criteria cover medical professional capabilities, social
comprehensive capabilities, contextual capabilities, and computational
robustness, with sixteen detailed indicators. The medical datasets include
twenty-seven medical dialogues and seven case reports in Chinese. Three
chatbots are evaluated, ChatGPT by OpenAI, ERNIE Bot by Baidu Inc., and Doctor
PuJiang (Dr. PJ) by Shanghai Artificial Intelligence Laboratory. Experimental
results show that Dr. PJ outperforms ChatGPT and ERNIE Bot in both
multiple-turn medical dialogue and case report scenarios.",2023-05-12,2023,2023-05,medical
eXplainable Artificial Intelligence on Medical Images: A Survey,"Over the last few years, the number of works about deep learning applied to
the medical field has increased enormously. The necessity of a rigorous
assessment of these models is required to explain these results to all people
involved in medical exams. A recent field in the machine learning area is
explainable artificial intelligence, also known as XAI, which targets to
explain the results of such black box models to permit the desired assessment.
This survey analyses several recent studies in the XAI field applied to medical
diagnosis research, allowing some explainability of the machine learning
results in several different diseases, such as cancers and COVID-19.",2023-05-12,2023,2023-05,medical
"Towards Expert-Level Medical Question Answering with Large Language
  Models","Recent artificial intelligence (AI) systems have reached milestones in ""grand
challenges"" ranging from Go to protein-folding. The capability to retrieve
medical knowledge, reason over it, and answer medical questions comparably to
physicians has long been viewed as one such grand challenge.
  Large language models (LLMs) have catalyzed significant progress in medical
question answering; Med-PaLM was the first model to exceed a ""passing"" score in
US Medical Licensing Examination (USMLE) style questions with a score of 67.2%
on the MedQA dataset. However, this and other prior work suggested significant
room for improvement, especially when models' answers were compared to
clinicians' answers. Here we present Med-PaLM 2, which bridges these gaps by
leveraging a combination of base LLM improvements (PaLM 2), medical domain
finetuning, and prompting strategies including a novel ensemble refinement
approach.
  Med-PaLM 2 scored up to 86.5% on the MedQA dataset, improving upon Med-PaLM
by over 19% and setting a new state-of-the-art. We also observed performance
approaching or exceeding state-of-the-art across MedMCQA, PubMedQA, and MMLU
clinical topics datasets.
  We performed detailed human evaluations on long-form questions along multiple
axes relevant to clinical applications. In pairwise comparative ranking of 1066
consumer medical questions, physicians preferred Med-PaLM 2 answers to those
produced by physicians on eight of nine axes pertaining to clinical utility (p
< 0.001). We also observed significant improvements compared to Med-PaLM on
every evaluation axis (p < 0.001) on newly introduced datasets of 240 long-form
""adversarial"" questions to probe LLM limitations.
  While further studies are necessary to validate the efficacy of these models
in real-world settings, these results highlight rapid progress towards
physician-level performance in medical question answering.",2023-05-16,2023,2023-05,medical
"Trustworthy Privacy-preserving Hierarchical Ensemble and Federated
  Learning in Healthcare 4.0 with Blockchain","The advancement of Internet and Communication Technologies (ICTs) has led to
the era of Industry 4.0. This shift is followed by healthcare industries
creating the term Healthcare 4.0. In Healthcare 4.0, the use of IoT-enabled
medical imaging devices for early disease detection has enabled medical
practitioners to increase healthcare institutions' quality of service. However,
Healthcare 4.0 is still lagging in Artificial Intelligence and big data
compared to other Industry 4.0 due to data privacy concerns. In addition,
institutions' diverse storage and computing capabilities restrict institutions
from incorporating the same training model structure. This paper presents a
secure multi-party computation-based ensemble federated learning with
blockchain that enables heterogeneous models to collaboratively learn from
healthcare institutions' data without violating users' privacy. Blockchain
properties also allow the party to enjoy data integrity without trust in a
centralized server while also providing each healthcare institution with
auditability and version control capability.",2023-05-16,2023,2023-05,medical
PMC-VQA: Visual Instruction Tuning for Medical Visual Question Answering,"Medical Visual Question Answering (MedVQA) presents a significant opportunity
to enhance diagnostic accuracy and healthcare delivery by leveraging artificial
intelligence to interpret and answer questions based on medical images. In this
study, we reframe the problem of MedVQA as a generation task that naturally
follows the human-machine interaction and propose a generative-based model for
medical visual understanding by aligning visual information from a pre-trained
vision encoder with a large language model. We establish a scalable pipeline to
construct a large-scale medical visual question-answering dataset, named
PMC-VQA, which contains 227k VQA pairs of 149k images that cover various
modalities or diseases. We train the proposed model on PMC-VQA and then
fine-tune it on multiple public benchmarks, e.g., VQA-RAD, SLAKE, and
Image-Clef-2019, significantly outperforming existing MedVQA models in
generating relevant, accurate free-form answers. In addition, we propose a test
set that has undergone manual verification, which is significantly more
challenging, serving to better monitor the development of generative MedVQA
methods. To facilitate comprehensive evaluation and comparison, we have
maintained a leaderboard at
https://paperswithcode.com/paper/pmc-vqa-visual-instruction-tuning-for-medical,
offering a centralized resource for tracking progress and benchmarking
state-of-the-art approaches. The PMC-VQA dataset emerges as a vital resource
for the field of research, and the MedVInT presents a significant breakthrough
in the area of MedVQA.",2023-05-17,2023,2023-05,medical
Taxonomy of AISecOps Threat Modeling for Cloud Based Medical Chatbots,"Artificial Intelligence (AI) is playing a vital role in all aspects of
technology including cyber security. Application of Conversational AI like the
chatbots are also becoming very popular in the medical field to provide timely
and immediate medical assistance to patients in need. As medical chatbots deal
with a lot of sensitive information, the security of these chatbots is crucial.
To secure the confidentiality, integrity, and availability of cloud-hosted
assets like these, medical chatbots can be monitored using AISecOps (Artificial
Intelligence for Secure IT Operations). AISecOPs is an emerging field that
integrates three different but interrelated domains like the IT operation, AI,
and security as one domain, where the expertise from all these three domains
are used cohesively to secure the cyber assets. It considers cloud operations
and security in a holistic framework to collect the metrics required to assess
the security threats and train the AI models to take immediate actions. This
work is focused on applying the STRIDE threat modeling framework to model the
possible threats involved in each component of the chatbot to enable the
automatic threat detection using the AISecOps techniques. This threat modeling
framework is tailored to the medical chatbots that involves sensitive data
sharing but could also be applied for chatbots used in other sectors like the
financial services, public sector, and government sectors that are concerned
with security and compliance.",2023-05-18,2023,2023-05,medical
"MedLens: Improve Mortality Prediction Via Medical Signs Selecting and
  Regression","Monitoring the health status of patients and predicting mortality in advance
is vital for providing patients with timely care and treatment. Massive medical
signs in electronic health records (EHR) are fitted into advanced machine
learning models to make predictions. However, the data-quality problem of
original clinical signs is less discussed in the literature. Based on an
in-depth measurement of the missing rate and correlation score across various
medical signs and a large amount of patient hospital admission records, we
discovered the comprehensive missing rate is extremely high, and a large number
of useless signs could hurt the performance of prediction models. Then we
concluded that only improving data-quality could improve the baseline accuracy
of different prediction algorithms. We designed MEDLENS, with an automatic
vital medical signs selection approach via statistics and a flexible
interpolation approach for high missing rate time series. After augmenting the
data-quality of original medical signs, MEDLENS applies ensemble classifiers to
boost the accuracy and reduce the computation overhead at the same time. It
achieves a very high accuracy performance of 0.96 AUC-ROC and 0.81 AUC-PR,
which exceeds the previous benchmark.",2023-05-19,2023,2023-05,medical
"PlugMed: Improving Specificity in Patient-Centered Medical Dialogue
  Generation using In-Context Learning","The patient-centered medical dialogue systems strive to offer diagnostic
interpretation services to users who are less knowledgeable about medical
knowledge, through emphasizing the importance of providing responses specific
to the patients. It is difficult for the large language models (LLMs) to
guarantee the specificity of responses in spite of its promising performance
even in some tasks in medical field. Inspired by in-context learning, we
propose PlugMed, a Plug-and-Play Medical Dialogue System, for addressing this
challenge. PlugMed is equipped with two modules, the prompt generation (PG)
module and the response ranking (RR) module, to enhances LLMs' dialogue
strategies for improving the specificity of the dialogue. The PG module is
designed to stimulate the imitative ability of LLMs by providing them with real
dialogues from similar patients as prompts. The RR module incorporates
fine-tuned small model as response filter to enable the selection of
appropriate responses generated by LLMs. Furthermore, we introduce a new
evaluation method based on matching both user's intent and high-frequency
medical term to effectively assess the specificity of the responses. We conduct
experimental evaluations on three medical dialogue datasets, and the results,
including both automatic and human evaluation, demonstrate the effectiveness of
our approach.",2023-05-19,2023,2023-05,medical
"Enhancing Small Medical Learners with Privacy-preserving Contextual
  Prompting","Large language models (LLMs) demonstrate remarkable medical expertise, but
data privacy concerns impede their direct use in healthcare environments.
Although offering improved data privacy protection, domain-specific small
language models (SLMs) often underperform LLMs, emphasizing the need for
methods that reduce this performance gap while alleviating privacy concerns. In
this paper, we present a simple yet effective method that harnesses LLMs'
medical proficiency to boost SLM performance in medical tasks under
privacy-restricted scenarios. Specifically, we mitigate patient privacy issues
by extracting keywords from medical data and prompting the LLM to generate a
medical knowledge-intensive context by simulating clinicians' thought
processes. This context serves as additional input for SLMs, augmenting their
decision-making capabilities. Our method significantly enhances performance in
both few-shot and full training settings across three medical
knowledge-intensive tasks, achieving up to a 22.57% increase in absolute
accuracy compared to SLM fine-tuning without context, and sets new
state-of-the-art results in two medical tasks within privacy-restricted
scenarios. Further out-of-domain testing and experiments in two general domain
datasets showcase its generalizability and broad applicability. Our code can be
found at https://github.com/XZhang97666/PrivacyBoost-SLM.",2023-05-22,2023,2023-05,medical
Medical Dialogue Generation via Dual Flow Modeling,"Medical dialogue systems (MDS) aim to provide patients with medical services,
such as diagnosis and prescription. Since most patients cannot precisely
describe their symptoms, dialogue understanding is challenging for MDS.
Previous studies mainly addressed this by extracting the mentioned medical
entities as critical dialogue history information. In this work, we argue that
it is also essential to capture the transitions of the medical entities and the
doctor's dialogue acts in each turn, as they help the understanding of how the
dialogue flows and enhance the prediction of the entities and dialogue acts to
be adopted in the following turn. Correspondingly, we propose a Dual Flow
enhanced Medical (DFMed) dialogue generation framework. It extracts the medical
entities and dialogue acts used in the dialogue history and models their
transitions with an entity-centric graph flow and a sequential act flow,
respectively. We employ two sequential models to encode them and devise an
interweaving component to enhance their interactions. Experiments on two
datasets demonstrate that our method exceeds baselines in both automatic and
manual evaluations.",2023-05-29,2023,2023-05,medical
"Med-UniC: Unifying Cross-Lingual Medical Vision-Language Pre-Training by
  Diminishing Bias","The scarcity of data presents a critical obstacle to the efficacy of medical
visionlanguage pre-training (VLP). A potential solution lies in the combination
of datasets from various language communities. Nevertheless, the main challenge
stems from the complexity of integrating diverse syntax and semantics,
language-specific medical terminology, and culture-specific implicit knowledge.
Therefore, one crucial aspect to consider is the presence of community bias
caused by different languages. This paper presents a novel framework named
Unifying Cross-Lingual Medical Vision-Language Pre-Training (Med-UniC),
designed to integrate multimodal medical data from the two most prevalent
languages, English and Spanish. Specifically, we propose Cross-lingual Text
Alignment Regularization (CTR) to explicitly unify cross-lingual semantic
representations of medical reports originating from diverse language
communities. CTR is optimized through latent language disentanglement,
rendering our optimization objective to not depend on negative samples, thereby
significantly mitigating the bias from determining positive-negative sample
pairs within analogous medical reports. Furthermore, it ensures that the
cross-lingual representation is not biased toward any specific language
community. Med-UniC reaches superior performance across 5 medical image tasks
and 10 datasets encompassing over 30 diseases, offering a versatile framework
for unifying multi-modal medical data within diverse linguistic communities.
The experimental outcomes highlight the presence of community bias in
cross-lingual VLP. Reducing this bias enhances the performance not only in
vision-language tasks but also in uni-modal visual tasks.",2023-05-31,2023,2023-05,medical
"DKINet: Medication Recommendation via Domain Knowledge Informed Deep
  Learning","Medication recommendation is a fundamental yet crucial branch of healthcare
that presents opportunities to assist physicians in making more accurate
medication prescriptions for patients with complex health conditions. Previous
studies have primarily focused on learning patient representation from
electronic health records (EHR). While considering the clinical manifestations
of the patient is important, incorporating domain-specific prior knowledge is
equally significant in diagnosing the patient's health conditions. However,
effectively integrating domain knowledge with the patient's clinical
manifestations can be challenging, particularly when dealing with complex
clinical manifestations. Therefore, in this paper, we first identify
comprehensive domain-specific prior knowledge, namely the Unified Medical
Language System (UMLS), which is a comprehensive repository of biomedical
vocabularies and standards, for knowledge extraction. Subsequently, we propose
a knowledge injection module that addresses the effective integration of domain
knowledge with complex clinical manifestations, enabling an effective
characterization of the health conditions of the patient. Furthermore,
considering the significant impact of a patient's medication history on their
current medication, we introduce a historical medication-aware patient
representation module to capture the longitudinal influence of historical
medication information on the representation of current patients. Extensive
experiments on three publicly benchmark datasets verify the superiority of our
proposed method, which outperformed other methods by a significant margin. The
code is available at: https://github.com/sherry6247/DKINet.",2023-05-31,2023,2023-05,medical
"XAI Renaissance: Redefining Interpretability in Medical Diagnostic
  Models","As machine learning models become increasingly prevalent in medical
diagnostics, the need for interpretability and transparency becomes paramount.
The XAI Renaissance signifies a significant shift in the field, aiming to
redefine the interpretability of medical diagnostic models. This paper explores
the innovative approaches and methodologies within the realm of Explainable AI
(XAI) that are revolutionizing the interpretability of medical diagnostic
models. By shedding light on the underlying decision-making process, XAI
techniques empower healthcare professionals to understand, trust, and
effectively utilize these models for accurate and reliable medical diagnoses.
This review highlights the key advancements in XAI for medical diagnostics and
their potential to transform the healthcare landscape, ultimately improving
patient outcomes and fostering trust in AI-driven diagnostic systems.",2023-06-02,2023,2023-06,medical
"Case Studies on X-Ray Imaging, MRI and Nuclear Imaging","The field of medical imaging is an essential aspect of the medical sciences,
involving various forms of radiation to capture images of the internal tissues
and organs of the body. These images provide vital information for clinical
diagnosis, and in this chapter, we will explore the use of X-ray, MRI, and
nuclear imaging in detecting severe illnesses. However, manual evaluation and
storage of these images can be a challenging and time-consuming process. To
address this issue, artificial intelligence (AI)-based techniques, particularly
deep learning (DL), have become increasingly popular for systematic feature
extraction and classification from imaging modalities, thereby aiding doctors
in making rapid and accurate diagnoses. In this review study, we will focus on
how AI-based approaches, particularly the use of Convolutional Neural Networks
(CNN), can assist in disease detection through medical imaging technology. CNN
is a commonly used approach for image analysis due to its ability to extract
features from raw input images, and as such, will be the primary area of
discussion in this study. Therefore, we have considered CNN as our discussion
area in this study to diagnose ailments using medical imaging technology.",2023-06-03,2023,2023-06,medical
"Generative Text-Guided 3D Vision-Language Pretraining for Unified
  Medical Image Segmentation","Vision-Language Pretraining (VLP) has demonstrated remarkable capabilities in
learning visual representations from textual descriptions of images without
annotations. Yet, effective VLP demands large-scale image-text pairs, a
resource that suffers scarcity in the medical domain. Moreover, conventional
VLP is limited to 2D images while medical images encompass diverse modalities,
often in 3D, making the learning process more challenging. To address these
challenges, we present Generative Text-Guided 3D Vision-Language Pretraining
for Unified Medical Image Segmentation (GTGM), a framework that extends of VLP
to 3D medical images without relying on paired textual descriptions.
Specifically, GTGM utilizes large language models (LLM) to generate
medical-style text from 3D medical images. This synthetic text is then used to
supervise 3D visual representation learning. Furthermore, a negative-free
contrastive learning objective strategy is introduced to cultivate consistent
visual representations between augmented 3D medical image patches, which
effectively mitigates the biases associated with strict positive-negative
sample pairings. We evaluate GTGM on three imaging modalities - Computed
Tomography (CT), Magnetic Resonance Imaging (MRI), and electron microscopy (EM)
over 13 datasets. GTGM's superior performance across various medical image
segmentation tasks underscores its effectiveness and versatility, by enabling
VLP extension into 3D medical imagery while bypassing the need for paired text.",2023-06-07,2023,2023-06,medical
AutoML Systems For Medical Imaging,"The integration of machine learning in medical image analysis can greatly
enhance the quality of healthcare provided by physicians. The combination of
human expertise and computerized systems can result in improved diagnostic
accuracy. An automated machine learning approach simplifies the creation of
custom image recognition models by utilizing neural architecture search and
transfer learning techniques. Medical imaging techniques are used to
non-invasively create images of internal organs and body parts for diagnostic
and procedural purposes. This article aims to highlight the potential
applications, strategies, and techniques of AutoML in medical imaging through
theoretical and empirical evidence.",2023-06-07,2023,2023-06,medical
XInsight: Revealing Model Insights for GNNs with Flow-based Explanations,"Progress in graph neural networks has grown rapidly in recent years, with
many new developments in drug discovery, medical diagnosis, and recommender
systems. While this progress is significant, many networks are `black boxes'
with little understanding of the `what' exactly the network is learning. Many
high-stakes applications, such as drug discovery, require human-intelligible
explanations from the models so that users can recognize errors and discover
new knowledge. Therefore, the development of explainable AI algorithms is
essential for us to reap the benefits of AI.
  We propose an explainability algorithm for GNNs called eXplainable Insight
(XInsight) that generates a distribution of model explanations using GFlowNets.
Since GFlowNets generate objects with probabilities proportional to a reward,
XInsight can generate a diverse set of explanations, compared to previous
methods that only learn the maximum reward sample. We demonstrate XInsight by
generating explanations for GNNs trained on two graph classification tasks:
classifying mutagenic compounds with the MUTAG dataset and classifying acyclic
graphs with a synthetic dataset that we have open-sourced. We show the utility
of XInsight's explanations by analyzing the generated compounds using QSAR
modeling, and we find that XInsight generates compounds that cluster by
lipophilicity, a known correlate of mutagenicity. Our results show that
XInsight generates a distribution of explanations that uncovers the underlying
relationships demonstrated by the model. They also highlight the importance of
generating a diverse set of explanations, as it enables us to discover hidden
relationships in the model and provides valuable guidance for further analysis.",2023-06-07,2023,2023-06,medical
Artificial General Intelligence for Medical Imaging Analysis,"Large-scale Artificial General Intelligence (AGI) models, including Large
Language Models (LLMs) such as ChatGPT/GPT-4, have achieved unprecedented
success in a variety of general domain tasks. Yet, when applied directly to
specialized domains like medical imaging, which require in-depth expertise,
these models face notable challenges arising from the medical field's inherent
complexities and unique characteristics. In this review, we delve into the
potential applications of AGI models in medical imaging and healthcare, with a
primary focus on LLMs, Large Vision Models, and Large Multimodal Models. We
provide a thorough overview of the key features and enabling techniques of LLMs
and AGI, and further examine the roadmaps guiding the evolution and
implementation of AGI models in the medical sector, summarizing their present
applications, potentialities, and associated challenges. In addition, we
highlight potential future research directions, offering a holistic view on
upcoming ventures. This comprehensive review aims to offer insights into the
future implications of AGI in medical imaging, healthcare, and beyond.",2023-06-08,2023,2023-06,medical
"Customizing General-Purpose Foundation Models for Medical Report
  Generation","Medical caption prediction which can be regarded as a task of medical report
generation (MRG), requires the automatic generation of coherent and accurate
captions for the given medical images. However, the scarcity of labelled
medical image-report pairs presents great challenges in the development of deep
and large-scale neural networks capable of harnessing the potential artificial
general intelligence power like large language models (LLMs). In this work, we
propose customizing off-the-shelf general-purpose large-scale pre-trained
models, i.e., foundation models (FMs), in computer vision and natural language
processing with a specific focus on medical report generation. Specifically,
following BLIP-2, a state-of-the-art vision-language pre-training approach, we
introduce our encoder-decoder-based MRG model. This model utilizes a
lightweight query Transformer to connect two FMs: the giant vision Transformer
EVA-ViT-g and a bilingual LLM trained to align with human intentions (referred
to as ChatGLM-6B). Furthermore, we conduct ablative experiments on the
trainable components of the model to identify the crucial factors for effective
transfer learning. Our findings demonstrate that unfreezing EVA-ViT-g to learn
medical image representations, followed by parameter-efficient training of
ChatGLM-6B to capture the writing styles of medical reports, is essential for
achieving optimal results. Our best attempt (PCLmed Team) achieved the 4th and
the 2nd, respectively, out of 13 participating teams, based on the BERTScore
and ROUGE-1 metrics, in the ImageCLEFmedical Caption 2023 Caption Prediction
Task competition.",2023-06-09,2023,2023-06,medical
"Medical Data Augmentation via ChatGPT: A Case Study on Medication
  Identification and Medication Event Classification","The identification of key factors such as medications, diseases, and
relationships within electronic health records and clinical notes has a wide
range of applications in the clinical field. In the N2C2 2022 competitions,
various tasks were presented to promote the identification of key factors in
electronic health records (EHRs) using the Contextualized Medication Event
Dataset (CMED). Pretrained large language models (LLMs) demonstrated
exceptional performance in these tasks. This study aims to explore the
utilization of LLMs, specifically ChatGPT, for data augmentation to overcome
the limited availability of annotated data for identifying the key factors in
EHRs. Additionally, different pre-trained BERT models, initially trained on
extensive datasets like Wikipedia and MIMIC, were employed to develop models
for identifying these key variables in EHRs through fine-tuning on augmented
datasets. The experimental results of two EHR analysis tasks, namely medication
identification and medication event classification, indicate that data
augmentation based on ChatGPT proves beneficial in improving performance for
both medication identification and medication event classification.",2023-06-10,2023,2023-06,medical
"Online learning for X-ray, CT or MRI","Medical imaging plays an important role in the medical sector in identifying
diseases. X-ray, computed tomography (CT) scans, and magnetic resonance imaging
(MRI) are a few examples of medical imaging. Most of the time, these imaging
techniques are utilized to examine and diagnose diseases. Medical professionals
identify the problem after analyzing the images. However, manual identification
can be challenging because the human eye is not always able to recognize
complex patterns in an image. Because of this, it is difficult for any
professional to recognize a disease with rapidity and accuracy. In recent
years, medical professionals have started adopting Computer-Aided Diagnosis
(CAD) systems to evaluate medical images. This system can analyze the image and
detect the disease very precisely and quickly. However, this system has certain
drawbacks in that it needs to be processed before analysis. Medical research is
already entered a new era of research which is called Artificial Intelligence
(AI). AI can automatically find complex patterns from an image and identify
diseases. Methods for medical imaging that uses AI techniques will be covered
in this chapter.",2023-06-10,2023,2023-06,medical
"Multi-modal Pre-training for Medical Vision-language Understanding and
  Generation: An Empirical Study with A New Benchmark","With the availability of large-scale, comprehensive, and general-purpose
vision-language (VL) datasets such as MSCOCO, vision-language pre-training
(VLP) has become an active area of research and proven to be effective for
various VL tasks such as visual-question answering. However, studies on VLP in
the medical domain have so far been scanty. To provide a comprehensive
perspective on VLP for medical VL tasks, we conduct a thorough experimental
analysis to study key factors that may affect the performance of VLP with a
unified vision-language Transformer. To allow making sound and quick
pre-training decisions, we propose RadioGraphy Captions (RGC), a high-quality,
multi-modality radiographic dataset containing 18,434 image-caption pairs
collected from an open-access online database MedPix. RGC can be used as a
pre-training dataset or a new benchmark for medical report generation and
medical image-text retrieval. By utilizing RGC and other available datasets for
pre-training, we develop several key insights that can guide future medical VLP
research and new strong baselines for various medical VL tasks.",2023-06-10,2023,2023-06,medical
"Preserving privacy in domain transfer of medical AI models comes at no
  performance costs: The integral role of differential privacy","Developing robust and effective artificial intelligence (AI) models in
medicine requires access to large amounts of patient data. The use of AI models
solely trained on large multi-institutional datasets can help with this, yet
the imperative to ensure data privacy remains, particularly as membership
inference risks breaching patient confidentiality. As a proposed remedy, we
advocate for the integration of differential privacy (DP). We specifically
investigate the performance of models trained with DP as compared to models
trained without DP on data from institutions that the model had not seen during
its training (i.e., external validation) - the situation that is reflective of
the clinical use of AI models. By leveraging more than 590,000 chest
radiographs from five institutions, we evaluated the efficacy of DP-enhanced
domain transfer (DP-DT) in diagnosing cardiomegaly, pleural effusion,
pneumonia, atelectasis, and in identifying healthy subjects. We juxtaposed
DP-DT with non-DP-DT and examined diagnostic accuracy and demographic fairness
using the area under the receiver operating characteristic curve (AUC) as the
main metric, as well as accuracy, sensitivity, and specificity. Our results
show that DP-DT, even with exceptionally high privacy levels (epsilon around
1), performs comparably to non-DP-DT (P>0.119 across all domains). Furthermore,
DP-DT led to marginal AUC differences - less than 1% - for nearly all
subgroups, relative to non-DP-DT. Despite consistent evidence suggesting that
DP models induce significant performance degradation for on-domain
applications, we show that off-domain performance is almost not affected.
Therefore, we ardently advocate for the adoption of DP in training diagnostic
medical AI models, given its minimal impact on performance.",2023-06-10,2023,2023-06,medical
Visual Question Answering (VQA) on Images with Superimposed Text,"Superimposed text annotations have been under-investigated, yet are
ubiquitous, useful and important, especially in medical images. Medical images
also highlight the challenges posed by low resolution, noise and superimposed
textual meta-information. Therefor we probed the impact of superimposing text
onto medical images on VQA. Our results revealed that this textual
meta-information can be added without severely degrading key measures of VQA
performance. Our findings are significant because they validate the practice of
superimposing text on images, even for medical images subjected to the VQA task
using AI techniques. The work helps advance understanding of VQA in general
and, in particular, in the domain of healthcare and medicine.",2023-06-13,2023,2023-06,medical
"Temporally-Extended Prompts Optimization for SAM in Interactive Medical
  Image Segmentation","The Segmentation Anything Model (SAM) has recently emerged as a foundation
model for addressing image segmentation. Owing to the intrinsic complexity of
medical images and the high annotation cost, the medical image segmentation
(MIS) community has been encouraged to investigate SAM's zero-shot capabilities
to facilitate automatic annotation. Inspired by the extraordinary
accomplishments of interactive medical image segmentation (IMIS) paradigm, this
paper focuses on assessing the potential of SAM's zero-shot capabilities within
the IMIS paradigm to amplify its benefits in the MIS domain. Regrettably, we
observe that SAM's vulnerability to prompt forms (e.g., points, bounding boxes)
becomes notably pronounced in IMIS. This leads us to develop a framework that
adaptively offers suitable prompt forms for human experts. We refer to the
framework above as temporally-extended prompts optimization (TEPO) and model it
as a Markov decision process, solvable through reinforcement learning.
Numerical experiments on the standardized benchmark BraTS2020 demonstrate that
the learned TEPO agent can further enhance SAM's zero-shot capability in the
MIS context.",2023-06-15,2023,2023-06,medical
"Path to Medical AGI: Unify Domain-specific Medical LLMs with the Lowest
  Cost","Medical artificial general intelligence (AGI) is an emerging field that aims
to develop systems specifically designed for medical applications that possess
the ability to understand, learn, and apply knowledge across a wide range of
tasks and domains. Large language models (LLMs) represent a significant step
towards AGI. However, training cross-domain LLMs in the medical field poses
significant challenges primarily attributed to the requirement of collecting
data from diverse domains. This task becomes particularly difficult due to
privacy restrictions and the scarcity of publicly available medical datasets.
Here, we propose Medical AGI (MedAGI), a paradigm to unify domain-specific
medical LLMs with the lowest cost, and suggest a possible path to achieve
medical AGI. With an increasing number of domain-specific professional
multimodal LLMs in the medical field being developed, MedAGI is designed to
automatically select appropriate medical models by analyzing users' questions
with our novel adaptive expert selection algorithm. It offers a unified
approach to existing LLMs in the medical field, eliminating the need for
retraining regardless of the introduction of new models. This characteristic
renders it a future-proof solution in the dynamically advancing medical domain.
To showcase the resilience of MedAGI, we conducted an evaluation across three
distinct medical domains: dermatology diagnosis, X-ray diagnosis, and analysis
of pathology pictures. The results demonstrated that MedAGI exhibited
remarkable versatility and scalability, delivering exceptional performance
across diverse domains. Our code is publicly available to facilitate further
research at https://github.com/JoshuaChou2018/MedAGI.",2023-06-19,2023,2023-06,medical
"Utilizing Segment Anything Model For Assessing Localization of GRAD-CAM
  in Medical Imaging","The introduction of saliency map algorithms as an approach for assessing the
interoperability of images has allowed for a deeper understanding of current
black-box models with Artificial Intelligence. Their rise in popularity has led
to these algorithms being applied in multiple fields, including medical
imaging. With a classification task as important as those in the medical
domain, a need for rigorous testing of their capabilities arises. Current works
examine capabilities through assessing the localization of saliency maps upon
medical abnormalities within an image, through comparisons with human
annotations. We propose utilizing Segment Anything Model (SAM) to both further
the accuracy of such existing metrics, while also generalizing beyond the need
for human annotations. Our results show both high degrees of similarity to
existing metrics while also highlighting the capabilities of this methodology
to beyond human-annotation. Furthermore, we explore the applications (and
challenges) of SAM within the medical domain, including image pre-processing
before segmenting, natural language proposals to SAM in the form of CLIP-SAM,
and SAM accuracy across multiple medical imaging datasets.",2023-06-24,2023,2023-06,medical
Regular SE(3) Group Convolutions for Volumetric Medical Image Analysis,"Regular group convolutional neural networks (G-CNNs) have been shown to
increase model performance and improve equivariance to different geometrical
symmetries. This work addresses the problem of SE(3), i.e., roto-translation
equivariance, on volumetric data. Volumetric image data is prevalent in many
medical settings. Motivated by the recent work on separable group convolutions,
we devise a SE(3) group convolution kernel separated into a continuous SO(3)
(rotation) kernel and a spatial kernel. We approximate equivariance to the
continuous setting by sampling uniform SO(3) grids. Our continuous SO(3) kernel
is parameterized via RBF interpolation on similarly uniform grids. We
demonstrate the advantages of our approach in volumetric medical image
analysis. Our SE(3) equivariant models consistently outperform CNNs and regular
discrete G-CNNs on challenging medical classification tasks and show
significantly improved generalization capabilities. Our approach achieves up to
a 16.5% gain in accuracy over regular CNNs.",2023-06-24,2023,2023-06,medical
"Multi-Scale Cross Contrastive Learning for Semi-Supervised Medical Image
  Segmentation","Semi-supervised learning has demonstrated great potential in medical image
segmentation by utilizing knowledge from unlabeled data. However, most existing
approaches do not explicitly capture high-level semantic relations between
distant regions, which limits their performance. In this paper, we focus on
representation learning for semi-supervised learning, by developing a novel
Multi-Scale Cross Supervised Contrastive Learning (MCSC) framework, to segment
structures in medical images. We jointly train CNN and Transformer models,
regularising their features to be semantically consistent across different
scales. Our approach contrasts multi-scale features based on ground-truth and
cross-predicted labels, in order to extract robust feature representations that
reflect intra- and inter-slice relationships across the whole dataset. To
tackle class imbalance, we take into account the prevalence of each class to
guide contrastive learning and ensure that features adequately capture
infrequent classes. Extensive experiments on two multi-structure medical
segmentation datasets demonstrate the effectiveness of MCSC. It not only
outperforms state-of-the-art semi-supervised methods by more than 3.0% in Dice,
but also greatly reduces the performance gap with fully supervised methods.",2023-06-25,2023,2023-06,medical
"Medical Federated Model with Mixture of Personalized and Sharing
  Components","Although data-driven methods usually have noticeable performance on disease
diagnosis and treatment, they are suspected of leakage of privacy due to
collecting data for model training. Recently, federated learning provides a
secure and trustable alternative to collaboratively train model without any
exchange of medical data among multiple institutes. Therefore, it has draw much
attention due to its natural merit on privacy protection. However, when
heterogenous medical data exists between different hospitals, federated
learning usually has to face with degradation of performance. In the paper, we
propose a new personalized framework of federated learning to handle the
problem. It successfully yields personalized models based on awareness of
similarity between local data, and achieves better tradeoff between
generalization and personalization than existing methods. After that, we
further design a differentially sparse regularizer to improve communication
efficiency during procedure of model training. Additionally, we propose an
effective method to reduce the computational cost, which improves computation
efficiency significantly. Furthermore, we collect 5 real medical datasets,
including 2 public medical image datasets and 3 private multi-center clinical
diagnosis datasets, and evaluate its performance by conducting nodule
classification, tumor segmentation, and clinical risk prediction tasks.
Comparing with 13 existing related methods, the proposed method successfully
achieves the best model performance, and meanwhile up to 60% improvement of
communication efficiency. Source code is public, and can be accessed at:
https://github.com/ApplicationTechnologyOfMedicalBigData/pFedNet-code.",2023-06-26,2023,2023-06,medical
"Stone Needle: A General Multimodal Large-scale Model Framework towards
  Healthcare","In healthcare, multimodal data is prevalent and requires to be
comprehensively analyzed before diagnostic decisions, including medical images,
clinical reports, etc. However, current large-scale artificial intelligence
models predominantly focus on single-modal cognitive abilities and neglect the
integration of multiple modalities. Therefore, we propose Stone Needle, a
general multimodal large-scale model framework tailored explicitly for
healthcare applications. Stone Needle serves as a comprehensive medical
multimodal model foundation, integrating various modalities such as text,
images, videos, and audio to surpass the limitations of single-modal systems.
Through the framework components of intent analysis, medical foundation models,
prompt manager, and medical language module, our architecture can perform
multi-modal interaction in multiple rounds of dialogue. Our method is a general
multimodal large-scale model framework, integrating diverse modalities and
allowing us to tailor for specific tasks. The experimental results demonstrate
the superior performance of our method compared to single-modal systems. The
fusion of different modalities and the ability to process complex medical
information in Stone Needle benefits accurate diagnosis, treatment
recommendations, and patient care.",2023-06-28,2023,2023-06,medical
Transformers in Healthcare: A Survey,"With Artificial Intelligence (AI) increasingly permeating various aspects of
society, including healthcare, the adoption of the Transformers neural network
architecture is rapidly changing many applications. Transformer is a type of
deep learning architecture initially developed to solve general-purpose Natural
Language Processing (NLP) tasks and has subsequently been adapted in many
fields, including healthcare. In this survey paper, we provide an overview of
how this architecture has been adopted to analyze various forms of data,
including medical imaging, structured and unstructured Electronic Health
Records (EHR), social media, physiological signals, and biomolecular sequences.
Those models could help in clinical diagnosis, report generation, data
reconstruction, and drug/protein synthesis. We identified relevant studies
using the Preferred Reporting Items for Systematic Reviews and Meta-Analyses
(PRISMA) guidelines. We also discuss the benefits and limitations of using
transformers in healthcare and examine issues such as computational cost, model
interpretability, fairness, alignment with human values, ethical implications,
and environmental impact.",2023-06-30,2023,2023-06,medical
"Performance of ChatGPT on USMLE: Unlocking the Potential of Large
  Language Models for AI-Assisted Medical Education","Artificial intelligence is gaining traction in more ways than ever before.
The popularity of language models and AI-based businesses has soared since
ChatGPT was made available to the general public via OpenAI. It is becoming
increasingly common for people to use ChatGPT both professionally and
personally. Considering the widespread use of ChatGPT and the reliance people
place on it, this study determined how reliable ChatGPT can be for answering
complex medical and clinical questions. Harvard University gross anatomy along
with the United States Medical Licensing Examination (USMLE) questionnaire were
used to accomplish the objective. The paper evaluated the obtained results
using a 2-way ANOVA and posthoc analysis. Both showed systematic covariation
between format and prompt. Furthermore, the physician adjudicators
independently rated the outcome's accuracy, concordance, and insight. As a
result of the analysis, ChatGPT-generated answers were found to be more
context-oriented and represented a better model for deductive reasoning than
regular Google search results. Furthermore, ChatGPT obtained 58.8% on logical
questions and 60% on ethical questions. This means that the ChatGPT is
approaching the passing range for logical questions and has crossed the
threshold for ethical questions. The paper believes ChatGPT and other language
learning models can be invaluable tools for e-learners; however, the study
suggests that there is still room to improve their accuracy. In order to
improve ChatGPT's performance in the future, further research is needed to
better understand how it can answer different types of questions.",2023-06-30,2023,2023-06,medical
"Beyond Known Reality: Exploiting Counterfactual Explanations for Medical
  Research","The field of explainability in artificial intelligence (AI) has witnessed a
growing number of studies and increasing scholarly interest. However, the lack
of human-friendly and individual interpretations in explaining the outcomes of
machine learning algorithms has significantly hindered the acceptance of these
methods by clinicians in their research and clinical practice. To address this
issue, our study uses counterfactual explanations to explore the applicability
of ""what if?"" scenarios in medical research. Our aim is to expand our
understanding of magnetic resonance imaging (MRI) features used for diagnosing
pediatric posterior fossa brain tumors beyond existing boundaries. In our case
study, the proposed concept provides a novel way to examine alternative
decision-making scenarios that offer personalized and context-specific
insights, enabling the validation of predictions and clarification of
variations under diverse circumstances. Additionally, we explore the potential
use of counterfactuals for data augmentation and evaluate their feasibility as
an alternative approach in our medical research case. The results demonstrate
the promising potential of using counterfactual explanations to improve
AI-driven methods in clinical research.",2023-07-05,2023,2023-07,medical
"The Role of Subgroup Separability in Group-Fair Medical Image
  Classification","We investigate performance disparities in deep classifiers. We find that the
ability of classifiers to separate individuals into subgroups varies
substantially across medical imaging modalities and protected characteristics;
crucially, we show that this property is predictive of algorithmic bias.
Through theoretical analysis and extensive empirical evaluation, we find a
relationship between subgroup separability, subgroup disparities, and
performance degradation when models are trained on data with systematic bias
such as underdiagnosis. Our findings shed new light on the question of how
models become biased, providing important insights for the development of fair
medical imaging AI.",2023-07-06,2023,2023-07,medical
"Masked Vision and Language Pre-training with Unimodal and Multimodal
  Contrastive Losses for Medical Visual Question Answering","Medical visual question answering (VQA) is a challenging task that requires
answering clinical questions of a given medical image, by taking consider of
both visual and language information. However, due to the small scale of
training data for medical VQA, pre-training fine-tuning paradigms have been a
commonly used solution to improve model generalization performance. In this
paper, we present a novel self-supervised approach that learns unimodal and
multimodal feature representations of input images and text using medical image
caption datasets, by leveraging both unimodal and multimodal contrastive
losses, along with masked language modeling and image text matching as
pretraining objectives. The pre-trained model is then transferred to downstream
medical VQA tasks. The proposed approach achieves state-of-the-art (SOTA)
performance on three publicly available medical VQA datasets with significant
accuracy improvements of 2.2%, 14.7%, and 1.7% respectively. Besides, we
conduct a comprehensive analysis to validate the effectiveness of different
components of the approach and study different pre-training settings. Our codes
and models are available at https://github.com/pengfeiliHEU/MUMC.",2023-07-11,2023,2023-07,medical
"Measuring Perceived Trust in XAI-Assisted Decision-Making by Eliciting a
  Mental Model","This empirical study proposes a novel methodology to measure users' perceived
trust in an Explainable Artificial Intelligence (XAI) model. To do so, users'
mental models are elicited using Fuzzy Cognitive Maps (FCMs). First, we exploit
an interpretable Machine Learning (ML) model to classify suspected COVID-19
patients into positive or negative cases. Then, Medical Experts' (MEs) conduct
a diagnostic decision-making task based on their knowledge and then prediction
and interpretations provided by the XAI model. In order to evaluate the impact
of interpretations on perceived trust, explanation satisfaction attributes are
rated by MEs through a survey. Then, they are considered as FCM's concepts to
determine their influences on each other and, ultimately, on the perceived
trust. Moreover, to consider MEs' mental subjectivity, fuzzy linguistic
variables are used to determine the strength of influences. After reaching the
steady state of FCMs, a quantified value is obtained to measure the perceived
trust of each ME. The results show that the quantified values can determine
whether MEs trust or distrust the XAI model. We analyze this behavior by
comparing the quantified values with MEs' performance in completing diagnostic
tasks.",2023-07-15,2023,2023-07,medical
"M-FLAG: Medical Vision-Language Pre-training with Frozen Language Models
  and Latent Space Geometry Optimization","Medical vision-language models enable co-learning and integrating features
from medical imaging and clinical text. However, these models are not easy to
train and the latent representation space can be complex. Here we propose a
novel way for pre-training and regularising medical vision-language models. The
proposed method, named Medical vision-language pre-training with Frozen
language models and Latent spAce Geometry optimization (M-FLAG), leverages a
frozen language model for training stability and efficiency and introduces a
novel orthogonality loss to harmonize the latent space geometry. We demonstrate
the potential of the pre-trained model on three downstream tasks: medical image
classification, segmentation, and object detection. Extensive experiments
across five public datasets demonstrate that M-FLAG significantly outperforms
existing medical vision-language pre-training approaches and reduces the number
of parameters by 78\%. Notably, M-FLAG achieves outstanding performance on the
segmentation task while using only 1\% of the RSNA dataset, even outperforming
ImageNet pre-trained models that have been fine-tuned using 100\% of the data.",2023-07-17,2023,2023-07,medical
"Balancing Privacy and Progress in Artificial Intelligence: Anonymization
  in Histopathology for Biomedical Research and Education","The advancement of biomedical research heavily relies on access to large
amounts of medical data. In the case of histopathology, Whole Slide Images
(WSI) and clinicopathological information are valuable for developing
Artificial Intelligence (AI) algorithms for Digital Pathology (DP).
Transferring medical data ""as open as possible"" enhances the usability of the
data for secondary purposes but poses a risk to patient privacy. At the same
time, existing regulations push towards keeping medical data ""as closed as
necessary"" to avoid re-identification risks. Generally, these legal regulations
require the removal of sensitive data but do not consider the possibility of
data linkage attacks due to modern image-matching algorithms. In addition, the
lack of standardization in DP makes it harder to establish a single solution
for all formats of WSIs. These challenges raise problems for bio-informatics
researchers in balancing privacy and progress while developing AI algorithms.
This paper explores the legal regulations and terminologies for medical
data-sharing. We review existing approaches and highlight challenges from the
histopathological perspective. We also present a data-sharing guideline for
histological data to foster multidisciplinary research and education.",2023-07-18,2023,2023-07,medical
Interpreting and Correcting Medical Image Classification with PIP-Net,"Part-prototype models are explainable-by-design image classifiers, and a
promising alternative to black box AI. This paper explores the applicability
and potential of interpretable machine learning, in particular PIP-Net, for
automated diagnosis support on real-world medical imaging data. PIP-Net learns
human-understandable prototypical image parts and we evaluate its accuracy and
interpretability for fracture detection and skin cancer diagnosis. We find that
PIP-Net's decision making process is in line with medical classification
standards, while only provided with image-level class labels. Because of
PIP-Net's unsupervised pretraining of prototypes, data quality problems such as
undesired text in an X-ray or labelling errors can be easily identified.
Additionally, we are the first to show that humans can manually correct the
reasoning of PIP-Net by directly disabling undesired prototypes. We conclude
that part-prototype models are promising for medical applications due to their
interpretability and potential for advanced model debugging.",2023-07-19,2023,2023-07,medical
Is Grad-CAM Explainable in Medical Images?,"Explainable Deep Learning has gained significant attention in the field of
artificial intelligence (AI), particularly in domains such as medical imaging,
where accurate and interpretable machine learning models are crucial for
effective diagnosis and treatment planning. Grad-CAM is a baseline that
highlights the most critical regions of an image used in a deep learning
model's decision-making process, increasing interpretability and trust in the
results. It is applied in many computer vision (CV) tasks such as
classification and explanation. This study explores the principles of
Explainable Deep Learning and its relevance to medical imaging, discusses
various explainability techniques and their limitations, and examines medical
imaging applications of Grad-CAM. The findings highlight the potential of
Explainable Deep Learning and Grad-CAM in improving the accuracy and
interpretability of deep learning models in medical imaging. The code is
available in (will be available).",2023-07-20,2023,2023-07,medical
IvyGPT: InteractiVe Chinese pathwaY language model in medical domain,"General large language models (LLMs) such as ChatGPT have shown remarkable
success. However, such LLMs have not been widely adopted for medical purposes,
due to poor accuracy and inability to provide medical advice. We propose
IvyGPT, an LLM based on LLaMA that is trained and fine-tuned with high-quality
medical question-answer (QA) instances and Reinforcement Learning from Human
Feedback (RLHF). After supervised fine-tuning, IvyGPT has good multi-turn
conversation capabilities, but it cannot perform like a doctor in other
aspects, such as comprehensive diagnosis. Through RLHF, IvyGPT can output
richer diagnosis and treatment answers that are closer to human. In the
training, we used QLoRA to train 33 billion parameters on a small number of
NVIDIA A100 (80GB) GPUs. Experimental results show that IvyGPT has outperformed
other medical GPT models.",2023-07-20,2023,2023-07,medical
"Probabilistic Modeling of Inter- and Intra-observer Variability in
  Medical Image Segmentation","Medical image segmentation is a challenging task, particularly due to inter-
and intra-observer variability, even between medical experts. In this paper, we
propose a novel model, called Probabilistic Inter-Observer and iNtra-Observer
variation NetwOrk (Pionono). It captures the labeling behavior of each rater
with a multidimensional probability distribution and integrates this
information with the feature maps of the image to produce probabilistic
segmentation predictions. The model is optimized by variational inference and
can be trained end-to-end. It outperforms state-of-the-art models such as
STAPLE, Probabilistic U-Net, and models based on confusion matrices.
Additionally, Pionono predicts multiple coherent segmentation maps that mimic
the rater's expert opinion, which provides additional valuable information for
the diagnostic process. Experiments on real-world cancer segmentation datasets
demonstrate the high accuracy and efficiency of Pionono, making it a powerful
tool for medical image analysis.",2023-07-21,2023,2023-07,medical
"A Revolution of Personalized Healthcare: Enabling Human Digital Twin
  with Mobile AIGC","Mobile Artificial Intelligence-Generated Content (AIGC) technology refers to
the adoption of AI algorithms deployed at mobile edge networks to automate the
information creation process while fulfilling the requirements of end users.
Mobile AIGC has recently attracted phenomenal attentions and can be a key
enabling technology for an emerging application, called human digital twin
(HDT). HDT empowered by the mobile AIGC is expected to revolutionize the
personalized healthcare by generating rare disease data, modeling high-fidelity
digital twin, building versatile testbeds, and providing 24/7 customized
medical services. To promote the development of this new breed of paradigm, in
this article, we propose a system architecture of mobile AIGC-driven HDT and
highlight the corresponding design requirements and challenges. Moreover, we
illustrate two use cases, i.e., mobile AIGC-driven HDT in customized surgery
planning and personalized medication. In addition, we conduct an experimental
study to prove the effectiveness of the proposed mobile AIGC-driven HDT
solution, which shows a particular application in a virtual physical therapy
teaching platform. Finally, we conclude this article by briefly discussing
several open issues and future directions.",2023-07-22,2023,2023-07,medical
"Client-Level Differential Privacy via Adaptive Intermediary in Federated
  Medical Imaging","Despite recent progress in enhancing the privacy of federated learning (FL)
via differential privacy (DP), the trade-off of DP between privacy protection
and performance is still underexplored for real-world medical scenario. In this
paper, we propose to optimize the trade-off under the context of client-level
DP, which focuses on privacy during communications. However, FL for medical
imaging involves typically much fewer participants (hospitals) than other
domains (e.g., mobile devices), thus ensuring clients be differentially private
is much more challenging. To tackle this problem, we propose an adaptive
intermediary strategy to improve performance without harming privacy.
Specifically, we theoretically find splitting clients into sub-clients, which
serve as intermediaries between hospitals and the server, can mitigate the
noises introduced by DP without harming privacy. Our proposed approach is
empirically evaluated on both classification and segmentation tasks using two
public datasets, and its effectiveness is demonstrated with significant
performance improvements and comprehensive analytical studies. Code is
available at: https://github.com/med-air/Client-DP-FL.",2023-07-24,2023,2023-07,medical
"SL: Stable Learning in Source-Free Domain Adaption for Medical Image
  Segmentation","Deep learning techniques for medical image analysis usually suffer from the
domain shift between source and target data. Most existing works focus on
unsupervised domain adaptation (UDA). However, in practical applications,
privacy issues are much more severe. For example, the data of different
hospitals have domain shifts due to equipment problems, and data of the two
domains cannot be available simultaneously because of privacy. In this
challenge defined as Source-Free UDA, the previous UDA medical methods are
limited. Although a variety of medical source-free unsupervised domain adaption
(MSFUDA) methods have been proposed, we found they fall into an over-fitting
dilemma called ""longer training, worse performance."" Therefore, we propose the
Stable Learning (SL) strategy to address the dilemma. SL is a scalable method
and can be integrated with other research, which consists of Weight
Consolidation and Entropy Increase. First, we apply Weight Consolidation to
retain domain-invariant knowledge and then we design Entropy Increase to avoid
over-learning. Comparative experiments prove the effectiveness of SL. We also
have done extensive ablation experiments. Besides, We will release codes
including a variety of MSFUDA methods.",2023-07-24,2023,2023-07,medical
Is attention all you need in medical image analysis? A review,"Medical imaging is a key component in clinical diagnosis, treatment planning
and clinical trial design, accounting for almost 90% of all healthcare data.
CNNs achieved performance gains in medical image analysis (MIA) over the last
years. CNNs can efficiently model local pixel interactions and be trained on
small-scale MI data. The main disadvantage of typical CNN models is that they
ignore global pixel relationships within images, which limits their
generalisation ability to understand out-of-distribution data with different
'global' information. The recent progress of Artificial Intelligence gave rise
to Transformers, which can learn global relationships from data. However, full
Transformer models need to be trained on large-scale data and involve
tremendous computational complexity. Attention and Transformer compartments
(Transf/Attention) which can well maintain properties for modelling global
relationships, have been proposed as lighter alternatives of full Transformers.
Recently, there is an increasing trend to co-pollinate complementary
local-global properties from CNN and Transf/Attention architectures, which led
to a new era of hybrid models. The past years have witnessed substantial growth
in hybrid CNN-Transf/Attention models across diverse MIA problems. In this
systematic review, we survey existing hybrid CNN-Transf/Attention models,
review and unravel key architectural designs, analyse breakthroughs, and
evaluate current and future opportunities as well as challenges. We also
introduced a comprehensive analysis framework on generalisation opportunities
of scientific and clinical impact, based on which new data-driven domain
generalisation and adaptation methods can be stimulated.",2023-07-24,2023,2023-07,medical
Med-Flamingo: a Multimodal Medical Few-shot Learner,"Medicine, by its nature, is a multifaceted domain that requires the synthesis
of information across various modalities. Medical generative vision-language
models (VLMs) make a first step in this direction and promise many exciting
clinical applications. However, existing models typically have to be fine-tuned
on sizeable down-stream datasets, which poses a significant limitation as in
many medical applications data is scarce, necessitating models that are capable
of learning from few examples in real-time. Here we propose Med-Flamingo, a
multimodal few-shot learner adapted to the medical domain. Based on
OpenFlamingo-9B, we continue pre-training on paired and interleaved medical
image-text data from publications and textbooks. Med-Flamingo unlocks few-shot
generative medical visual question answering (VQA) abilities, which we evaluate
on several datasets including a novel challenging open-ended VQA dataset of
visual USMLE-style problems. Furthermore, we conduct the first human evaluation
for generative medical VQA where physicians review the problems and blinded
generations in an interactive app. Med-Flamingo improves performance in
generative medical VQA by up to 20\% in clinician's rating and firstly enables
multimodal medical few-shot adaptations, such as rationale generation. We
release our model, code, and evaluation app under
https://github.com/snap-stanford/med-flamingo.",2023-07-27,2023,2023-07,medical
Med-HALT: Medical Domain Hallucination Test for Large Language Models,"This research paper focuses on the challenges posed by hallucinations in
large language models (LLMs), particularly in the context of the medical
domain. Hallucination, wherein these models generate plausible yet unverified
or incorrect information, can have serious consequences in healthcare
applications. We propose a new benchmark and dataset, Med-HALT (Medical Domain
Hallucination Test), designed specifically to evaluate and reduce
hallucinations. Med-HALT provides a diverse multinational dataset derived from
medical examinations across various countries and includes multiple innovative
testing modalities. Med-HALT includes two categories of tests reasoning and
memory-based hallucination tests, designed to assess LLMs's problem-solving and
information retrieval abilities.
  Our study evaluated leading LLMs, including Text Davinci, GPT-3.5, LlaMa-2,
MPT, and Falcon, revealing significant differences in their performance. The
paper provides detailed insights into the dataset, promoting transparency and
reproducibility. Through this work, we aim to contribute to the development of
safer and more reliable language models in healthcare. Our benchmark can be
found at medhalt.github.io",2023-07-28,2023,2023-07,medical
"Recent advancement in Disease Diagnostic using machine learning:
  Systematic survey of decades, comparisons, and challenges","Computer-aided diagnosis (CAD), a vibrant medical imaging research field, is
expanding quickly. Because errors in medical diagnostic systems might lead to
seriously misleading medical treatments, major efforts have been made in recent
years to improve computer-aided diagnostics applications. The use of machine
learning in computer-aided diagnosis is crucial. A simple equation may result
in a false indication of items like organs. Therefore, learning from examples
is a vital component of pattern recognition. Pattern recognition and machine
learning in the biomedical area promise to increase the precision of disease
detection and diagnosis. They also support the decision-making process's
objectivity. Machine learning provides a practical method for creating elegant
and autonomous algorithms to analyze high-dimensional and multimodal
bio-medical data. This review article examines machine-learning algorithms for
detecting diseases, including hepatitis, diabetes, liver disease, dengue fever,
and heart disease. It draws attention to the collection of machine learning
techniques and algorithms employed in studying conditions and the ensuing
decision-making process.",2023-07-31,2023,2023-07,medical
"Retrieval Augmented Generation and Representative Vector Summarization
  for large unstructured textual data in Medical Education","Large Language Models are increasingly being used for various tasks including
content generation and as chatbots. Despite their impressive performances in
general tasks, LLMs need to be aligned when applying for domain specific tasks
to mitigate the problems of hallucination and producing harmful answers.
Retrieval Augmented Generation (RAG) allows to easily attach and manipulate a
non-parametric knowledgebases to LLMs. Applications of RAG in the field of
medical education are discussed in this paper. A combined extractive and
abstractive summarization method for large unstructured textual data using
representative vectors is proposed.",2023-08-01,2023,2023-08,medical
"Data-Centric Diet: Effective Multi-center Dataset Pruning for Medical
  Image Segmentation","This paper seeks to address the dense labeling problems where a significant
fraction of the dataset can be pruned without sacrificing much accuracy. We
observe that, on standard medical image segmentation benchmarks, the loss
gradient norm-based metrics of individual training examples applied in image
classification fail to identify the important samples. To address this issue,
we propose a data pruning method by taking into consideration the training
dynamics on target regions using Dynamic Average Dice (DAD) score. To the best
of our knowledge, we are among the first to address the data importance in
dense labeling tasks in the field of medical image analysis, making the
following contributions: (1) investigating the underlying causes with rigorous
empirical analysis, and (2) determining effective data pruning approach in
dense labeling problems. Our solution can be used as a strong yet simple
baseline to select important examples for medical image segmentation with
combined data sources.",2023-08-02,2023,2023-08,medical
"From Military to Healthcare: Adopting and Expanding Ethical Principles
  for Generative Artificial Intelligence","In 2020, the U.S. Department of Defense officially disclosed a set of ethical
principles to guide the use of Artificial Intelligence (AI) technologies on
future battlefields. Despite stark differences, there are core similarities
between the military and medical service. Warriors on battlefields often face
life-altering circumstances that require quick decision-making. Medical
providers experience similar challenges in a rapidly changing healthcare
environment, such as in the emergency department or during surgery treating a
life-threatening condition. Generative AI, an emerging technology designed to
efficiently generate valuable information, holds great promise. As computing
power becomes more accessible and the abundance of health data, such as
electronic health records, electrocardiograms, and medical images, increases,
it is inevitable that healthcare will be revolutionized by this technology.
Recently, generative AI has captivated the research community, leading to
debates about its application in healthcare, mainly due to concerns about
transparency and related issues. Meanwhile, concerns about the potential
exacerbation of health disparities due to modeling biases have raised notable
ethical concerns regarding the use of this technology in healthcare. However,
the ethical principles for generative AI in healthcare have been understudied,
and decision-makers often fail to consider the significance of generative AI.
In this paper, we propose GREAT PLEA ethical principles, encompassing
governance, reliability, equity, accountability, traceability, privacy,
lawfulness, empathy, and autonomy, for generative AI in healthcare. We aim to
proactively address the ethical dilemmas and challenges posed by the
integration of generative AI in healthcare.",2023-08-04,2023,2023-08,medical
"Coupling Symbolic Reasoning with Language Modeling for Efficient
  Longitudinal Understanding of Unstructured Electronic Medical Records","The application of Artificial Intelligence (AI) in healthcare has been
revolutionary, especially with the recent advancements in transformer-based
Large Language Models (LLMs). However, the task of understanding unstructured
electronic medical records remains a challenge given the nature of the records
(e.g., disorganization, inconsistency, and redundancy) and the inability of
LLMs to derive reasoning paradigms that allow for comprehensive understanding
of medical variables. In this work, we examine the power of coupling symbolic
reasoning with language modeling toward improved understanding of unstructured
clinical texts. We show that such a combination improves the extraction of
several medical variables from unstructured records. In addition, we show that
the state-of-the-art commercially-free LLMs enjoy retrieval capabilities
comparable to those provided by their commercial counterparts. Finally, we
elaborate on the need for LLM steering through the application of symbolic
reasoning as the exclusive use of LLMs results in the lowest performance.",2023-08-07,2023,2023-08,medical
"Rapid Training Data Creation by Synthesizing Medical Images for
  Classification and Localization","While the use of artificial intelligence (AI) for medical image analysis is
gaining wide acceptance, the expertise, time and cost required to generate
annotated data in the medical field are significantly high, due to limited
availability of both data and expert annotation. Strongly supervised object
localization models require data that is exhaustively annotated, meaning all
objects of interest in an image are identified. This is difficult to achieve
and verify for medical images. We present a method for the transformation of
real data to train any Deep Neural Network to solve the above problems. We show
the efficacy of this approach on both a weakly supervised localization model
and a strongly supervised localization model. For the weakly supervised model,
we show that the localization accuracy increases significantly using the
generated data. For the strongly supervised model, this approach overcomes the
need for exhaustive annotation on real images. In the latter model, we show
that the accuracy, when trained with generated images, closely parallels the
accuracy when trained with exhaustively annotated real images. The results are
demonstrated on images of human urine samples obtained using microscopy.",2023-08-09,2023,2023-08,medical
Explainable AI applications in the Medical Domain: a systematic review,"Artificial Intelligence in Medicine has made significant progress with
emerging applications in medical imaging, patient care, and other areas. While
these applications have proven successful in retrospective studies, very few of
them were applied in practice.The field of Medical AI faces various challenges,
in terms of building user trust, complying with regulations, using data
ethically.Explainable AI (XAI) aims to enable humans understand AI and trust
its results. This paper presents a literature review on the recent developments
of XAI solutions for medical decision support, based on a representative sample
of 198 articles published in recent years. The systematic synthesis of the
relevant articles resulted in several findings. (1) model-agnostic XAI
techniques were mostly employed in these solutions, (2) deep learning models
are utilized more than other types of machine learning models, (3)
explainability was applied to promote trust, but very few works reported the
physicians participation in the loop, (4) visual and interactive user interface
is more useful in understanding the explanation and the recommendation of the
system. More research is needed in collaboration between medical and AI
experts, that could guide the development of suitable frameworks for the
design, implementation, and evaluation of XAI solutions in medicine.",2023-08-10,2023,2023-08,medical
"Ground Truth Or Dare: Factors Affecting The Creation Of Medical Datasets
  For Training AI","One of the core goals of responsible AI development is ensuring high-quality
training datasets. Many researchers have pointed to the importance of the
annotation step in the creation of high-quality data, but less attention has
been paid to the work that enables data annotation. We define this work as the
design of ground truth schema and explore the challenges involved in the
creation of datasets in the medical domain even before any annotations are
made. Based on extensive work in three health-tech organisations, we describe
five external and internal factors that condition medical dataset creation
processes. Three external factors include regulatory constraints, the context
of creation and use, and commercial and operational pressures. These factors
condition medical data collection and shape the ground truth schema design. Two
internal factors include epistemic differences and limits of labelling. These
directly shape the design of the ground truth schema. Discussions of what
constitutes high-quality data need to pay attention to the factors that shape
and constrain what is possible to be created, to ensure responsible AI design.",2023-08-12,2023,2023-08,medical
"The Performance of Transferability Metrics does not Translate to Medical
  Tasks","Transfer learning boosts the performance of medical image analysis by
enabling deep learning (DL) on small datasets through the knowledge acquired
from large ones. As the number of DL architectures explodes, exhaustively
attempting all candidates becomes unfeasible, motivating cheaper alternatives
for choosing them. Transferability scoring methods emerge as an enticing
solution, allowing to efficiently calculate a score that correlates with the
architecture accuracy on any target dataset. However, since transferability
scores have not been evaluated on medical datasets, their use in this context
remains uncertain, preventing them from benefiting practitioners. We fill that
gap in this work, thoroughly evaluating seven transferability scores in three
medical applications, including out-of-distribution scenarios. Despite
promising results in general-purpose datasets, our results show that no
transferability score can reliably and consistently estimate target performance
in medical contexts, inviting further work in that direction.",2023-08-14,2023,2023-08,medical
"Exploring Transfer Learning in Medical Image Segmentation using
  Vision-Language Models","Medical image segmentation allows quantifying target structure size and
shape, aiding in disease diagnosis, prognosis, surgery planning, and
comprehension.Building upon recent advancements in foundation Vision-Language
Models (VLMs) from natural image-text pairs, several studies have proposed
adapting them to Vision-Language Segmentation Models (VLSMs) that allow using
language text as an additional input to segmentation models. Introducing
auxiliary information via text with human-in-the-loop prompting during
inference opens up unique opportunities, such as open vocabulary segmentation
and potentially more robust segmentation models against out-of-distribution
data. Although transfer learning from natural to medical images has been
explored for image-only segmentation models, the joint representation of
vision-language in segmentation problems remains underexplored. This study
introduces the first systematic study on transferring VLSMs to 2D medical
images, using carefully curated $11$ datasets encompassing diverse modalities
and insightful language prompts and experiments. Our findings demonstrate that
although VLSMs show competitive performance compared to image-only models for
segmentation after finetuning in limited medical image datasets, not all VLSMs
utilize the additional information from language prompts, with image features
playing a dominant role. While VLSMs exhibit enhanced performance in handling
pooled datasets with diverse modalities and show potential robustness to domain
shifts compared to conventional segmentation models, our results suggest that
novel approaches are required to enable VLSMs to leverage the various auxiliary
information available through language prompts. The code and datasets are
available at https://github.com/naamiinepal/medvlsm.",2023-08-15,2023,2023-08,medical
CMB: A Comprehensive Medical Benchmark in Chinese,"Large Language Models (LLMs) provide a possibility to make a great
breakthrough in medicine. The establishment of a standardized medical benchmark
becomes a fundamental cornerstone to measure progression. However, medical
environments in different regions have their local characteristics, e.g., the
ubiquity and significance of traditional Chinese medicine within China.
Therefore, merely translating English-based medical evaluation may result in
\textit{contextual incongruities} to a local region. To solve the issue, we
propose a localized medical benchmark called CMB, a Comprehensive Medical
Benchmark in Chinese, designed and rooted entirely within the native Chinese
linguistic and cultural framework. While traditional Chinese medicine is
integral to this evaluation, it does not constitute its entirety. Using this
benchmark, we have evaluated several prominent large-scale LLMs, including
ChatGPT, GPT-4, dedicated Chinese LLMs, and LLMs specialized in the medical
domain. We hope this benchmark provide first-hand experience in existing LLMs
for medicine and also facilitate the widespread adoption and enhancement of
medical LLMs within China. Our data and code are publicly available at
https://github.com/FreedomIntelligence/CMB.",2023-08-17,2023,2023-08,medical
"Deciphering knee osteoarthritis diagnostic features with explainable
  artificial intelligence: A systematic review","Existing artificial intelligence (AI) models for diagnosing knee
osteoarthritis (OA) have faced criticism for their lack of transparency and
interpretability, despite achieving medical-expert-like performance. This
opacity makes them challenging to trust in clinical practice. Recently,
explainable artificial intelligence (XAI) has emerged as a specialized
technique that can provide confidence in the model's prediction by revealing
how the prediction is derived, thus promoting the use of AI systems in
healthcare. This paper presents the first survey of XAI techniques used for
knee OA diagnosis. The XAI techniques are discussed from two perspectives: data
interpretability and model interpretability. The aim of this paper is to
provide valuable insights into XAI's potential towards a more reliable knee OA
diagnosis approach and encourage its adoption in clinical practice.",2023-08-18,2023,2023-08,medical
False Negative/Positive Control for SAM on Noisy Medical Images,"The Segment Anything Model (SAM) is a recently developed all-range foundation
model for image segmentation. It can use sparse manual prompts such as bounding
boxes to generate pixel-level segmentation in natural images but struggles in
medical images such as low-contrast, noisy ultrasound images. We propose a
refined test-phase prompt augmentation technique designed to improve SAM's
performance in medical image segmentation. The method couples multi-box prompt
augmentation and an aleatoric uncertainty-based false-negative (FN) and
false-positive (FP) correction (FNPC) strategy. We evaluate the method on two
ultrasound datasets and show improvement in SAM's performance and robustness to
inaccurate prompts, without the necessity for further training or tuning.
Moreover, we present the Single-Slice-to-Volume (SS2V) method, enabling 3D
pixel-level segmentation using only the bounding box annotation from a single
2D slice. Our results allow efficient use of SAM in even noisy, low-contrast
medical images. The source code will be released soon.",2023-08-20,2023,2023-08,medical
"Enhancing Medical Image Segmentation: Optimizing Cross-Entropy Weights
  and Post-Processing with Autoencoders","The task of medical image segmentation presents unique challenges,
necessitating both localized and holistic semantic understanding to accurately
delineate areas of interest, such as critical tissues or aberrant features.
This complexity is heightened in medical image segmentation due to the high
degree of inter-class similarities, intra-class variations, and possible image
obfuscation. The segmentation task further diversifies when considering the
study of histopathology slides for autoimmune diseases like dermatomyositis.
The analysis of cell inflammation and interaction in these cases has been less
studied due to constraints in data acquisition pipelines. Despite the
progressive strides in medical science, we lack a comprehensive collection of
autoimmune diseases. As autoimmune diseases globally escalate in prevalence and
exhibit associations with COVID-19, their study becomes increasingly essential.
While there is existing research that integrates artificial intelligence in the
analysis of various autoimmune diseases, the exploration of dermatomyositis
remains relatively underrepresented. In this paper, we present a deep-learning
approach tailored for Medical image segmentation. Our proposed method
outperforms the current state-of-the-art techniques by an average of 12.26% for
U-Net and 12.04% for U-Net++ across the ResNet family of encoders on the
dermatomyositis dataset. Furthermore, we probe the importance of optimizing
loss function weights and benchmark our methodology on three challenging
medical image segmentation tasks",2023-08-21,2023,2023-08,medical
"Exploration of the Rashomon Set Assists Trustworthy Explanations for
  Medical Data","The machine learning modeling process conventionally culminates in selecting
a single model that maximizes a selected performance metric. However, this
approach leads to abandoning a more profound analysis of slightly inferior
models. Particularly in medical and healthcare studies, where the objective
extends beyond predictions to valuable insight generation, relying solely on a
single model can result in misleading or incomplete conclusions. This problem
is particularly pertinent when dealing with a set of models known as
$\textit{Rashomon set}$, with performance close to maximum one. Such a set can
be numerous and may contain models describing the data in a different way,
which calls for comprehensive analysis. This paper introduces a novel process
to explore models in the Rashomon set, extending the conventional modeling
approach. We propose the $\texttt{Rashomon_DETECT}$ algorithm to detect models
with different behavior. It is based on recent developments in the eXplainable
Artificial Intelligence (XAI) field. To quantify differences in variable
effects among models, we introduce the Profile Disparity Index (PDI) based on
measures from functional data analysis. To illustrate the effectiveness of our
approach, we showcase its application in predicting survival among
hemophagocytic lymphohistiocytosis (HLH) patients - a foundational case study.
Additionally, we benchmark our approach on other medical data sets,
demonstrating its versatility and utility in various contexts. If differently
behaving models are detected in the Rashomon set, their combined analysis leads
to more trustworthy conclusions, which is of vital importance for high-stakes
applications such as medical applications.",2023-08-22,2023,2023-08,medical
"A Generative Approach for Image Registration of Visible-Thermal (VT)
  Cancer Faces","Since thermal imagery offers a unique modality to investigate pain, the U.S.
National Institutes of Health (NIH) has collected a large and diverse set of
cancer patient facial thermograms for AI-based pain research. However,
differing angles from camera capture between thermal and visible sensors has
led to misalignment between Visible-Thermal (VT) images. We modernize the
classic computer vision task of image registration by applying and modifying a
generative alignment algorithm to register VT cancer faces, without the need
for a reference or alignment parameters. By registering VT faces, we
demonstrate that the quality of thermal images produced in the generative AI
downstream task of Visible-to-Thermal (V2T) image translation significantly
improves up to 52.5\%, than without registration. Images in this paper have
been approved by the NIH NCI for public dissemination.",2023-08-23,2023,2023-08,medical
"DISC-MedLLM: Bridging General Large Language Models and Real-World
  Medical Consultation","We propose DISC-MedLLM, a comprehensive solution that leverages Large
Language Models (LLMs) to provide accurate and truthful medical response in
end-to-end conversational healthcare services. To construct high-quality
Supervised Fine-Tuning (SFT) datasets, we employ three strategies: utilizing
medical knowledge-graphs, reconstructing real-world dialogues, and
incorporating human-guided preference rephrasing. These datasets are
instrumental in training DISC-MedLLM, surpassing existing medical LLMs in both
single-turn and multi-turn consultation scenarios. Extensive experimental
results demonstrate the effectiveness of the proposed model in bridging the gap
between general language models and real-world medical consultation.
Additionally, we release the constructed dataset and model weights to further
contribute to research and development. Further details and resources can be
found at https://github.com/FudanDISC/DISC-MedLLM",2023-08-28,2023,2023-08,medical
"Patient-specific, mechanistic models of tumor growth incorporating
  artificial intelligence and big data","Despite the remarkable advances in cancer diagnosis, treatment, and
management that have occurred over the past decade, malignant tumors remain a
major public health problem. Further progress in combating cancer may be
enabled by personalizing the delivery of therapies according to the predicted
response for each individual patient. The design of personalized therapies
requires patient-specific information integrated into an appropriate
mathematical model of tumor response. A fundamental barrier to realizing this
paradigm is the current lack of a rigorous, yet practical, mathematical theory
of tumor initiation, development, invasion, and response to therapy. In this
review, we begin by providing an overview of different approaches to modeling
tumor growth and treatment, including mechanistic as well as data-driven models
based on ``big data"" and artificial intelligence. Next, we present illustrative
examples of mathematical models manifesting their utility and discussing the
limitations of stand-alone mechanistic and data-driven models. We further
discuss the potential of mechanistic models for not only predicting, but also
optimizing response to therapy on a patient-specific basis. We then discuss
current efforts and future possibilities to integrate mechanistic and
data-driven models. We conclude by proposing five fundamental challenges that
must be addressed to fully realize personalized care for cancer patients driven
by computational models.",2023-08-28,2023,2023-08,medical
AutoProSAM: Automated Prompting SAM for 3D Multi-Organ Segmentation,"Segment Anything Model (SAM) is one of the pioneering prompt-based foundation
models for image segmentation and has been rapidly adopted for various medical
imaging applications. However, in clinical settings, creating effective prompts
is notably challenging and time-consuming, requiring the expertise of domain
specialists such as physicians. This requirement significantly diminishes SAM's
primary advantage, its interactive capability with end users, in medical
applications. Moreover, recent studies have indicated that SAM, originally
designed for 2D natural images, performs suboptimally on 3D medical image
segmentation tasks. This subpar performance is attributed to the domain gaps
between natural and medical images and the disparities in spatial arrangements
between 2D and 3D images, particularly in multi-organ segmentation
applications. To overcome these challenges, we present a novel technique termed
AutoProSAM. This method automates 3D multi-organ CT-based segmentation by
leveraging SAM's foundational model capabilities without relying on domain
experts for prompts. The approach utilizes parameter-efficient adaptation
techniques to adapt SAM for 3D medical imagery and incorporates an effective
automatic prompt learning paradigm specific to this domain. By eliminating the
need for manual prompts, it enhances SAM's capabilities for 3D medical image
segmentation and achieves state-of-the-art (SOTA) performance in CT-based
multi-organ segmentation tasks. The code is in this
{\href{https://github.com/ChengyinLee/AutoProSAM_2024}{link}}.",2023-08-28,2023,2023-08,medical
"StratMed: Relevance Stratification between Biomedical Entities for
  Sparsity on Medication Recommendation","With the growing imbalance between limited medical resources and escalating
demands, AI-based clinical tasks have become paramount. As a sub-domain,
medication recommendation aims to amalgamate longitudinal patient history with
medical knowledge, assisting physicians in prescribing safer and more accurate
medication combinations. Existing works ignore the inherent long-tailed
distribution of medical data, have uneven learning strengths for hot and sparse
data, and fail to balance safety and accuracy. To address the above
limitations, we propose StratMed, which introduces a stratification strategy
that overcomes the long-tailed problem and achieves fuller learning of sparse
data. It also utilizes a dual-property network to address the issue of mutual
constraints on the safety and accuracy of medication combinations,
synergistically enhancing these two properties. Specifically, we construct a
pre-training method using deep learning networks to obtain medication and
disease representations. After that, we design a pyramid-like stratification
method based on relevance to strengthen the expressiveness of sparse data.
Based on this relevance, we design two graph structures to express medication
safety and precision at the same level to obtain patient representations.
Finally, the patient's historical clinical information is fitted to generate
medication combinations for the current health condition. We employed the
MIMIC-III dataset to evaluate our model against state-of-the-art methods in
three aspects comprehensively. Compared to the sub-optimal baseline model, our
model reduces safety risk by 15.08\%, improves accuracy by 0.36\%, and reduces
training time consumption by 81.66\%.",2023-08-31,2023,2023-08,medical
"Interpretable Medical Imagery Diagnosis with Self-Attentive
  Transformers: A Review of Explainable AI for Health Care","Recent advancements in artificial intelligence (AI) have facilitated its
widespread adoption in primary medical services, addressing the demand-supply
imbalance in healthcare. Vision Transformers (ViT) have emerged as
state-of-the-art computer vision models, benefiting from self-attention
modules. However, compared to traditional machine-learning approaches,
deep-learning models are complex and are often treated as a ""black box"" that
can cause uncertainty regarding how they operate. Explainable Artificial
Intelligence (XAI) refers to methods that explain and interpret machine
learning models' inner workings and how they come to decisions, which is
especially important in the medical domain to guide the healthcare
decision-making process. This review summarises recent ViT advancements and
interpretative approaches to understanding the decision-making process of ViT,
enabling transparency in medical diagnosis applications.",2023-09-01,2023,2023-09,medical
MedChatZH: a Better Medical Adviser Learns from Better Instructions,"Generative large language models (LLMs) have shown great success in various
applications, including question-answering (QA) and dialogue systems. However,
in specialized domains like traditional Chinese medical QA, these models may
perform unsatisfactorily without fine-tuning on domain-specific datasets. To
address this, we introduce MedChatZH, a dialogue model designed specifically
for traditional Chinese medical QA. Our model is pre-trained on Chinese
traditional medical books and fine-tuned with a carefully curated medical
instruction dataset. It outperforms several solid baselines on a real-world
medical dialogue dataset. We release our model, code, and dataset on
https://github.com/tyang816/MedChatZH to facilitate further research in the
domain of traditional Chinese medicine and LLMs.",2023-09-03,2023,2023-09,medical
"Augmenting Black-box LLMs with Medical Textbooks for Biomedical Question
  Answering","Large-scale language models (LLMs) like ChatGPT have demonstrated impressive
abilities in generating responses based on human instructions. However, their
use in the medical field can be challenging due to their lack of specific,
in-depth knowledge. In this study, we present a system called LLMs Augmented
with Medical Textbooks (LLM-AMT) designed to enhance the proficiency of LLMs in
specialized domains. LLM-AMT integrates authoritative medical textbooks into
the LLMs' framework using plug-and-play modules. These modules include a Query
Augmenter, a Hybrid Textbook Retriever, and a Knowledge Self-Refiner. Together,
they incorporate authoritative medical knowledge. Additionally, an LLM Reader
aids in contextual understanding. Our experimental results on three medical QA
tasks demonstrate that LLMAMT significantly improves response quality, with
accuracy gains ranging from 11.6% to 16.6%. Notably, with GPT-4-Turbo as the
base model, LLM-AMT outperforms the specialized Med-PaLM 2 model pre-trained on
a massive amount of medical corpus by 2-3%. We found that despite being 100x
smaller in size, medical textbooks as a retrieval corpus is proven to be a more
effective knowledge database than Wikipedia in the medical domain, boosting
performance by 7.8%-13.7%.",2023-09-05,2023,2023-09,medical
"Knowledge-tuning Large Language Models with Structured Medical Knowledge
  Bases for Reliable Response Generation in Chinese","Large Language Models (LLMs) have demonstrated remarkable success in diverse
natural language processing (NLP) tasks in general domains. However, LLMs
sometimes generate responses with the hallucination about medical facts due to
limited domain knowledge. Such shortcomings pose potential risks in the
utilization of LLMs within medical contexts. To address this challenge, we
propose knowledge-tuning, which leverages structured medical knowledge bases
for the LLMs to grasp domain knowledge efficiently and facilitate reliable
response generation. We also release cMedKnowQA, a Chinese medical knowledge
question-answering dataset constructed from medical knowledge bases to assess
the medical knowledge proficiency of LLMs. Experimental results show that the
LLMs which are knowledge-tuned with cMedKnowQA, can exhibit higher levels of
accuracy in response generation compared with vanilla instruction-tuning and
offer a new reliable way for the domain adaptation of LLMs.",2023-09-08,2023,2023-09,medical
"Systematic Review of Techniques in Brain Image Synthesis using Deep
  Learning","This review paper delves into the present state of medical imaging, with a
specific focus on the use of deep learning techniques for brain image
synthesis. The need for medical image synthesis to improve diagnostic accuracy
and decrease invasiveness in medical procedures is emphasized, along with the
role of deep learning in enabling these advancements. The paper examines
various methods and techniques for brain image synthesis, including 2D to 3D
constructions, MRI synthesis, and the use of transformers. It also addresses
limitations and challenges faced in these methods, such as obtaining
well-curated training data and addressing brain ultrasound issues. The review
concludes by exploring the future potential of this field and the opportunities
for further advancements in medical imaging using deep learning techniques. The
significance of transformers and their potential to revolutionize the medical
imaging field is highlighted. Additionally, the paper discusses the potential
solutions to the shortcomings and limitations faced in this field. The review
provides researchers with an updated reference on the present state of the
field and aims to inspire further research and bridge the gap between the
present state of medical imaging and the future possibilities offered by deep
learning techniques.",2023-09-08,2023,2023-09,medical
"SHAPE: A Sample-adaptive Hierarchical Prediction Network for Medication
  Recommendation","Effectively medication recommendation with complex multimorbidity conditions
is a critical task in healthcare. Most existing works predicted medications
based on longitudinal records, which assumed the information transmitted
patterns of learning longitudinal sequence data are stable and intra-visit
medical events are serialized. However, the following conditions may have been
ignored: 1) A more compact encoder for intra-relationship in the intra-visit
medical event is urgent; 2) Strategies for learning accurate representations of
the variable longitudinal sequences of patients are different. In this paper,
we proposed a novel Sample-adaptive Hierarchical medicAtion Prediction nEtwork,
termed SHAPE, to tackle the above challenges in the medication recommendation
task. Specifically, we design a compact intra-visit set encoder to encode the
relationship in the medical event for obtaining visit-level representation and
then develop an inter-visit longitudinal encoder to learn the patient-level
longitudinal representation efficiently. To endow the model with the capability
of modeling the variable visit length, we introduce a soft curriculum learning
method to assign the difficulty of each sample automatically by the visit
length. Extensive experiments on a benchmark dataset verify the superiority of
our model compared with several state-of-the-art baselines.",2023-09-09,2023,2023-09,medical
"Functional requirements to mitigate the Risk of Harm to Patients from
  Artificial Intelligence in Healthcare","The Directorate General for Parliamentary Research Services of the European
Parliament has prepared a report to the Members of the European Parliament
where they enumerate seven main risks of Artificial Intelligence (AI) in
medicine and healthcare: patient harm due to AI errors, misuse of medical AI
tools, bias in AI and the perpetuation of existing inequities, lack of
transparency, privacy and security issues, gaps in accountability, and
obstacles in implementation.
  In this study, we propose fourteen functional requirements that AI systems
may implement to reduce the risks associated with their medical purpose: AI
passport, User management, Regulation check, Academic use only disclaimer, data
quality assessment, Clinicians double check, Continuous performance evaluation,
Audit trail, Continuous usability test, Review of retrospective/simulated
cases, Bias check, eXplainable AI, Encryption and use of field-tested
libraries, and Semantic interoperability.
  Our intention here is to provide specific high-level specifications of
technical solutions to ensure continuous good performance and use of AI systems
to benefit patients in compliance with the future EU regulatory framework.",2023-09-19,2023,2023-09,medical
"When to Trust AI: Advances and Challenges for Certification of Neural
  Networks","Artificial intelligence (AI) has been advancing at a fast pace and it is now
poised for deployment in a wide range of applications, such as autonomous
systems, medical diagnosis and natural language processing. Early adoption of
AI technology for real-world applications has not been without problems,
particularly for neural networks, which may be unstable and susceptible to
adversarial examples. In the longer term, appropriate safety assurance
techniques need to be developed to reduce potential harm due to avoidable
system failures and ensure trustworthiness. Focusing on certification and
explainability, this paper provides an overview of techniques that have been
developed to ensure safety of AI decisions and discusses future challenges.",2023-09-20,2023,2023-09,medical
A Systematic Review of Few-Shot Learning in Medical Imaging,"The lack of annotated medical images limits the performance of deep learning
models, which usually need large-scale labelled datasets. Few-shot learning
techniques can reduce data scarcity issues and enhance medical image analysis,
especially with meta-learning. This systematic review gives a comprehensive
overview of few-shot learning in medical imaging. We searched the literature
systematically and selected 80 relevant articles published from 2018 to 2023.
We clustered the articles based on medical outcomes, such as tumour
segmentation, disease classification, and image registration; anatomical
structure investigated (i.e. heart, lung, etc.); and the meta-learning method
used. For each cluster, we examined the papers' distributions and the results
provided by the state-of-the-art. In addition, we identified a generic pipeline
shared among all the studies. The review shows that few-shot learning can
overcome data scarcity in most outcomes and that meta-learning is a popular
choice to perform few-shot learning because it can adapt to new tasks with few
labelled samples. In addition, following meta-learning, supervised learning and
semi-supervised learning stand out as the predominant techniques employed to
tackle few-shot learning challenges in medical imaging and also best
performing. Lastly, we observed that the primary application areas
predominantly encompass cardiac, pulmonary, and abdominal domains. This
systematic review aims to inspire further research to improve medical image
analysis and patient care.",2023-09-20,2023,2023-09,medical
"Towards using Cough for Respiratory Disease Diagnosis by leveraging
  Artificial Intelligence: A Survey","Cough acoustics contain multitudes of vital information about
pathomorphological alterations in the respiratory system. Reliable and accurate
detection of cough events by investigating the underlying cough latent features
and disease diagnosis can play an indispensable role in revitalizing the
healthcare practices. The recent application of Artificial Intelligence (AI)
and advances of ubiquitous computing for respiratory disease prediction has
created an auspicious trend and myriad of future possibilities in the medical
domain. In particular, there is an expeditiously emerging trend of Machine
learning (ML) and Deep Learning (DL)-based diagnostic algorithms exploiting
cough signatures. The enormous body of literature on cough-based AI algorithms
demonstrate that these models can play a significant role for detecting the
onset of a specific respiratory disease. However, it is pertinent to collect
the information from all relevant studies in an exhaustive manner for the
medical experts and AI scientists to analyze the decisive role of AI/ML. This
survey offers a comprehensive overview of the cough data-driven ML/DL detection
and preliminary diagnosis frameworks, along with a detailed list of significant
features. We investigate the mechanism that causes cough and the latent cough
features of the respiratory modalities. We also analyze the customized cough
monitoring application, and their AI-powered recognition algorithms. Challenges
and prospective future research directions to develop practical, robust, and
ubiquitous solutions are also discussed in detail.",2023-09-24,2023,2023-09,medical
"Can-SAVE: Mass Cancer Risk Prediction via Survival Analysis Variables
  and EHR","Specific medical cancer screening methods are often costly, time-consuming,
and weakly applicable on a large scale. Advanced Artificial Intelligence (AI)
methods greatly help cancer detection but require specific or deep medical
data. These aspects prevent the mass implementation of cancer screening
methods. For this reason, it is a disruptive change for healthcare to apply AI
methods for mass personalized assessment of the cancer risk among patients
based on the existing Electronic Health Records (EHR) volume. This paper
presents a novel Can-SAVE cancer risk assessment method combining a survival
analysis approach with a gradient-boosting algorithm. It is highly accessible
and resource-efficient, utilizing only a sequence of high-level medical events.
We tested the proposed method in a long-term retrospective experiment covering
more than 1.1 million people and four regions of Russia. The Can-SAVE method
significantly exceeds the baselines by the Average Precision metric of
22.8%$\pm$2.7% vs 15.1%$\pm$2.6%. The extensive ablation study also confirmed
the proposed method's dominant performance. The experiment supervised by
oncologists shows a reliable cancer patient detection rate of up to 84 out of
1000 selected. Such results surpass the medical screening strategies estimates;
the typical age-specific Number Needed to Screen is only 9 out of 1000 (for
colorectal cancer). Overall, our experiments show a 4.7-6.4 times improvement
in cancer detection rate (TOP@1k) compared to the traditional healthcare risk
estimation approach.",2023-09-26,2023,2023-09,medical
"Experience and Evidence are the eyes of an excellent summarizer! Towards
  Knowledge Infused Multi-modal Clinical Conversation Summarization","With the advancement of telemedicine, both researchers and medical
practitioners are working hand-in-hand to develop various techniques to
automate various medical operations, such as diagnosis report generation. In
this paper, we first present a multi-modal clinical conversation summary
generation task that takes a clinician-patient interaction (both textual and
visual information) and generates a succinct synopsis of the conversation. We
propose a knowledge-infused, multi-modal, multi-tasking medical domain
identification and clinical conversation summary generation
(MM-CliConSummation) framework. It leverages an adapter to infuse knowledge and
visual features and unify the fused feature vector using a gated mechanism.
Furthermore, we developed a multi-modal, multi-intent clinical conversation
summarization corpus annotated with intent, symptom, and summary. The extensive
set of experiments, both quantitatively and qualitatively, led to the following
findings: (a) critical significance of visuals, (b) more precise and medical
entity preserving summary with additional knowledge infusion, and (c) a
correlation between medical department identification and clinical synopsis
generation. Furthermore, the dataset and source code are available at
https://github.com/NLP-RL/MM-CliConSummation.",2023-09-27,2023,2023-09,medical
"MKRAG: Medical Knowledge Retrieval Augmented Generation for Medical
  Question Answering","Large Language Models (LLMs), although powerful in general domains, often
perform poorly on domain-specific tasks such as medical question answering
(QA). In addition, LLMs tend to function as ""black-boxes"", making it
challenging to modify their behavior. To address the problem, our work employs
a transparent process of retrieval augmented generation (RAG), aiming to
improve LLM responses without the need for fine-tuning or retraining.
Specifically, we propose a comprehensive retrieval strategy to extract medical
facts from an external knowledge base, and then inject them into the LLM's
query prompt. Focusing on medical QA, we evaluate the impact of different
retrieval models and the number of facts on LLM performance using the
MedQA-SMILE dataset. Notably, our retrieval-augmented Vicuna-7B model exhibited
an accuracy improvement from 44.46% to 48.54%. This work underscores the
potential of RAG to enhance LLM performance, offering a practical approach to
mitigate the challenges posed by black-box LLMs.",2023-09-27,2023,2023-09,medical
"Medical Foundation Models are Susceptible to Targeted Misinformation
  Attacks","Large language models (LLMs) have broad medical knowledge and can reason
about medical information across many domains, holding promising potential for
diverse medical applications in the near future. In this study, we demonstrate
a concerning vulnerability of LLMs in medicine. Through targeted manipulation
of just 1.1% of the model's weights, we can deliberately inject an incorrect
biomedical fact. The erroneous information is then propagated in the model's
output, whilst its performance on other biomedical tasks remains intact. We
validate our findings in a set of 1,038 incorrect biomedical facts. This
peculiar susceptibility raises serious security and trustworthiness concerns
for the application of LLMs in healthcare settings. It accentuates the need for
robust protective measures, thorough verification mechanisms, and stringent
management of access to these models, ensuring their reliable and safe use in
medical practice.",2023-09-29,2023,2023-09,medical
"A Foundation Model for General Moving Object Segmentation in Medical
  Images","Medical image segmentation aims to delineate the anatomical or pathological
structures of interest, playing a crucial role in clinical diagnosis. A
substantial amount of high-quality annotated data is crucial for constructing
high-precision deep segmentation models. However, medical annotation is highly
cumbersome and time-consuming, especially for medical videos or 3D volumes, due
to the huge labeling space and poor inter-frame consistency. Recently, a
fundamental task named Moving Object Segmentation (MOS) has made significant
advancements in natural images. Its objective is to delineate moving objects
from the background within image sequences, requiring only minimal annotations.
In this paper, we propose the first foundation model, named iMOS, for MOS in
medical images. Extensive experiments on a large multi-modal medical dataset
validate the effectiveness of the proposed iMOS. Specifically, with the
annotation of only a small number of images in the sequence, iMOS can achieve
satisfactory tracking and segmentation performance of moving objects throughout
the entire sequence in bi-directions. We hope that the proposed iMOS can help
accelerate the annotation speed of experts, and boost the development of
medical foundation models.",2023-09-29,2023,2023-09,medical
A Comprehensive Review of Generative AI in Healthcare,"The advancement of Artificial Intelligence (AI) has catalyzed revolutionary
changes across various sectors, notably in healthcare. Among the significant
developments in this field are the applications of generative AI models,
specifically transformers and diffusion models. These models have played a
crucial role in analyzing diverse forms of data, including medical imaging
(encompassing image reconstruction, image-to-image translation, image
generation, and image classification), protein structure prediction, clinical
documentation, diagnostic assistance, radiology interpretation, clinical
decision support, medical coding, and billing, as well as drug design and
molecular representation. Such applications have enhanced clinical diagnosis,
data reconstruction, and drug synthesis. This review paper aims to offer a
thorough overview of the generative AI applications in healthcare, focusing on
transformers and diffusion models. Additionally, we propose potential
directions for future research to tackle the existing limitations and meet the
evolving demands of the healthcare sector. Intended to serve as a comprehensive
guide for researchers and practitioners interested in the healthcare
applications of generative AI, this review provides valuable insights into the
current state of the art, challenges faced, and prospective future directions.",2023-10-01,2023,2023-10,medical
"Generating Explanations in Medical Question-Answering by Expectation
  Maximization Inference over Evidence","Medical Question Answering~(medical QA) systems play an essential role in
assisting healthcare workers in finding answers to their questions. However, it
is not sufficient to merely provide answers by medical QA systems because users
might want explanations, that is, more analytic statements in natural language
that describe the elements and context that support the answer. To do so, we
propose a novel approach for generating natural language explanations for
answers predicted by medical QA systems. As high-quality medical explanations
require additional medical knowledge, so that our system extract knowledge from
medical textbooks to enhance the quality of explanations during the explanation
generation process. Concretely, we designed an expectation-maximization
approach that makes inferences about the evidence found in these texts,
offering an efficient way to focus attention on lengthy evidence passages.
Experimental results, conducted on two datasets MQAE-diag and MQAE, demonstrate
the effectiveness of our framework for reasoning with textual evidence. Our
approach outperforms state-of-the-art models, achieving a significant
improvement of \textbf{6.86} and \textbf{9.43} percentage points on the Rouge-1
score; \textbf{8.23} and \textbf{7.82} percentage points on the Bleu-4 score on
the respective datasets.",2023-10-02,2023,2023-10,medical
"Extraction of Medication and Temporal Relation from Clinical Text using
  Neural Language Models","Clinical texts, represented in electronic medical records (EMRs), contain
rich medical information and are essential for disease prediction, personalised
information recommendation, clinical decision support, and medication pattern
mining and measurement. Relation extractions between medication mentions and
temporal information can further help clinicians better understand the
patients' treatment history. To evaluate the performances of deep learning (DL)
and large language models (LLMs) in medication extraction and temporal
relations classification, we carry out an empirical investigation of
\textbf{MedTem} project using several advanced learning structures including
BiLSTM-CRF and CNN-BiLSTM for a clinical domain named entity recognition (NER),
and BERT-CNN for temporal relation extraction (RE), in addition to the
exploration of different word embedding techniques. Furthermore, we also
designed a set of post-processing roles to generate structured output on
medications and the temporal relation. Our experiments show that CNN-BiLSTM
slightly wins the BiLSTM-CRF model on the i2b2-2009 clinical NER task yielding
75.67, 77.83, and 78.17 for precision, recall, and F1 scores using Macro
Average. BERT-CNN model also produced reasonable evaluation scores 64.48,
67.17, and 65.03 for P/R/F1 using Macro Avg on the temporal relation extraction
test set from i2b2-2012 challenges. Code and Tools from MedTem will be hosted
at \url{https://github.com/HECTA-UoM/MedTem}",2023-10-03,2023,2023-10,medical
A ModelOps-based Framework for Intelligent Medical Knowledge Extraction,"Extracting medical knowledge from healthcare texts enhances downstream tasks
like medical knowledge graph construction and clinical decision-making.
However, the construction and application of knowledge extraction models lack
automation, reusability and unified management, leading to inefficiencies for
researchers and high barriers for non-AI experts such as doctors, to utilize
knowledge extraction. To address these issues, we propose a ModelOps-based
intelligent medical knowledge extraction framework that offers a low-code
system for model selection, training, evaluation and optimization.
Specifically, the framework includes a dataset abstraction mechanism based on
multi-layer callback functions, a reusable model training, monitoring and
management mechanism. We also propose a model recommendation method based on
dataset similarity, which helps users quickly find potentially suitable models
for a given dataset. Our framework provides convenience for researchers to
develop models and simplifies model access for non-AI experts such as doctors.",2023-10-04,2023,2023-10,medical
"Integrating UMLS Knowledge into Large Language Models for Medical
  Question Answering","Large language models (LLMs) have demonstrated powerful text generation
capabilities, bringing unprecedented innovation to the healthcare field. While
LLMs hold immense promise for applications in healthcare, applying them to real
clinical scenarios presents significant challenges, as these models may
generate content that deviates from established medical facts and even exhibit
potential biases. In our research, we develop an augmented LLM framework based
on the Unified Medical Language System (UMLS), aiming to better serve the
healthcare community. We employ LLaMa2-13b-chat and ChatGPT-3.5 as our
benchmark models, and conduct automatic evaluations using the ROUGE Score and
BERTScore on 104 questions from the LiveQA test set. Additionally, we establish
criteria for physician-evaluation based on four dimensions: Factuality,
Completeness, Readability and Relevancy. ChatGPT-3.5 is used for physician
evaluation with 20 questions on the LiveQA test set. Multiple resident
physicians conducted blind reviews to evaluate the generated content, and the
results indicate that this framework effectively enhances the factuality,
completeness, and relevance of generated content. Our research demonstrates the
effectiveness of using UMLS-augmented LLMs and highlights the potential
application value of LLMs in in medical question-answering.",2023-10-04,2023,2023-10,medical
"Comprehensive Multimodal Segmentation in Medical Imaging: Combining
  YOLOv8 with SAM and HQ-SAM Models","This paper introduces a comprehensive approach for segmenting regions of
interest (ROI) in diverse medical imaging datasets, encompassing ultrasound, CT
scans, and X-ray images. The proposed method harnesses the capabilities of the
YOLOv8 model for approximate boundary box detection across modalities,
alongside the Segment Anything Model (SAM) and High Quality (HQ) SAM for fully
automatic and precise segmentation. To generate boundary boxes, the YOLOv8
model was trained using a limited set of 100 images and masks from each
modality. The results obtained from our approach are extensively computed and
analyzed, demonstrating its effectiveness and potential in medical image
analysis. Various evaluation metrics, including precision, recall, F1 score,
and Dice Score, were employed to quantify the accuracy of the segmentation
results. A comparative analysis was conducted to assess the individual and
combined performance of the YOLOv8, YOLOv8+SAM, and YOLOv8+HQ-SAM models. The
results indicate that the SAM model performs better than the other two models,
exhibiting higher segmentation accuracy and overall performance. While HQ-SAM
offers potential advantages, its incremental gains over the standard SAM model
may not justify the additional computational cost. The YOLOv8+SAM model shows
promise for enhancing medical image segmentation and its clinical implications.",2023-10-04,2023,2023-10,medical
"DKEC: Domain Knowledge Enhanced Multi-Label Classification for Diagnosis
  Prediction","Multi-label text classification (MLTC) tasks in the medical domain often face
the long-tail label distribution problem. Prior works have explored
hierarchical label structures to find relevant information for few-shot
classes, but mostly neglected to incorporate external knowledge from medical
guidelines. This paper presents DKEC, Domain Knowledge Enhanced Classification
for diagnosis prediction with two innovations: (1) automated construction of
heterogeneous knowledge graphs from external sources to capture semantic
relations among diverse medical entities, (2) incorporating the heterogeneous
knowledge graphs in few-shot classification using a label-wise attention
mechanism. We construct DKEC using three online medical knowledge sources and
evaluate it on a real-world Emergency Medical Services (EMS) dataset and a
public electronic health record (EHR) dataset. Results show that DKEC
outperforms the state-of-the-art label-wise attention networks and transformer
models of different sizes, particularly for the few-shot classes. More
importantly, it helps the smaller language models achieve comparable
performance to large language models.",2023-10-10,2023,2023-10,medical
Histogram- and Diffusion-Based Medical Out-of-Distribution Detection,"Out-of-distribution (OOD) detection is crucial for the safety and reliability
of artificial intelligence algorithms, especially in the medical domain. In the
context of the Medical OOD (MOOD) detection challenge 2023, we propose a
pipeline that combines a histogram-based method and a diffusion-based method.
The histogram-based method is designed to accurately detect homogeneous
anomalies in the toy examples of the challenge, such as blobs with constant
intensity values. The diffusion-based method is based on one of the latest
methods for unsupervised anomaly detection, called DDPM-OOD. We explore this
method and propose extensive post-processing steps for pixel-level and
sample-level anomaly detection on brain MRI and abdominal CT data provided by
the challenge. Our results show that the proposed DDPM method is sensitive to
blur and bias field samples, but faces challenges with anatomical deformation,
black slice, and swapped patches. These findings suggest that further research
is needed to improve the performance of DDPM for OOD detection in medical
images.",2023-10-12,2023,2023-10,medical
"Medical Text Simplification: Optimizing for Readability with
  Unlikelihood Training and Reranked Beam Search Decoding","Text simplification has emerged as an increasingly useful application of AI
for bridging the communication gap in specialized fields such as medicine,
where the lexicon is often dominated by technical jargon and complex
constructs. Despite notable progress, methods in medical simplification
sometimes result in the generated text having lower quality and diversity. In
this work, we explore ways to further improve the readability of text
simplification in the medical domain. We propose (1) a new unlikelihood loss
that encourages generation of simpler terms and (2) a reranked beam search
decoding method that optimizes for simplicity, which achieve better performance
on readability metrics on three datasets. This study's findings offer promising
avenues for improving text simplification in the medical field.",2023-10-17,2023,2023-10,medical
"Cloud-Magnetic Resonance Imaging System: In the Era of 6G and Artificial
  Intelligence","Magnetic Resonance Imaging (MRI) plays an important role in medical
diagnosis, generating petabytes of image data annually in large hospitals. This
voluminous data stream requires a significant amount of network bandwidth and
extensive storage infrastructure. Additionally, local data processing demands
substantial manpower and hardware investments. Data isolation across different
healthcare institutions hinders cross-institutional collaboration in clinics
and research. In this work, we anticipate an innovative MRI system and its four
generations that integrate emerging distributed cloud computing, 6G bandwidth,
edge computing, federated learning, and blockchain technology. This system is
called Cloud-MRI, aiming at solving the problems of MRI data storage security,
transmission speed, AI algorithm maintenance, hardware upgrading, and
collaborative work. The workflow commences with the transformation of k-space
raw data into the standardized Imaging Society for Magnetic Resonance in
Medicine Raw Data (ISMRMRD) format. Then, the data are uploaded to the cloud or
edge nodes for fast image reconstruction, neural network training, and
automatic analysis. Then, the outcomes are seamlessly transmitted to clinics or
research institutes for diagnosis and other services. The Cloud-MRI system will
save the raw imaging data, reduce the risk of data loss, facilitate
inter-institutional medical collaboration, and finally improve diagnostic
accuracy and work efficiency.",2023-10-18,2023,2023-10,medical
"Quantifying Self-diagnostic Atomic Knowledge in Chinese Medical
  Foundation Model: A Computational Analysis","Foundation Models (FMs) have the potential to revolutionize the way users
self-diagnose through search engines by offering direct and efficient
suggestions. Recent studies primarily focused on the quality of FMs evaluated
by GPT-4 or their ability to pass medical exams, no studies have quantified the
extent of self-diagnostic atomic knowledge stored in FMs' memory, which is the
basis of foundation models to provide factual and reliable suggestions. In this
paper, we first constructed a benchmark of Self-diagnostic Atomic Knowledge
(SdAK), including the most common types of atomic knowledge involved in
self-diagnostic queries, with 17 atomic types and a total of 14, 048 pieces of
atomic knowledge. Then, we evaluated both generic and open-source Chinese
medical FMs on the benchmark. The experimental results showcase that generic
FMs perform better than medical FMs in terms of self-diagnostic atomic
knowledge. Error analysis revealed that both generic and medical FMs are
sycophantic, e.g., always catering to users' claims when it comes to unknown
knowledge. We further explored different types of data commonly adopted for
fine-tuning medical FMs, i.e., real-world, semi-distilled, and distilled data,
and found that distilled data can benefit FMs most. The code and data are
available at https://github.com/FreedomIntelligence/SDAK.",2023-10-18,2023,2023-10,medical
"MTS-LOF: Medical Time-Series Representation Learning via
  Occlusion-Invariant Features","Medical time series data are indispensable in healthcare, providing critical
insights for disease diagnosis, treatment planning, and patient management. The
exponential growth in data complexity, driven by advanced sensor technologies,
has presented challenges related to data labeling. Self-supervised learning
(SSL) has emerged as a transformative approach to address these challenges,
eliminating the need for extensive human annotation. In this study, we
introduce a novel framework for Medical Time Series Representation Learning,
known as MTS-LOF. MTS-LOF leverages the strengths of contrastive learning and
Masked Autoencoder (MAE) methods, offering a unique approach to representation
learning for medical time series data. By combining these techniques, MTS-LOF
enhances the potential of healthcare applications by providing more
sophisticated, context-rich representations. Additionally, MTS-LOF employs a
multi-masking strategy to facilitate occlusion-invariant feature learning. This
approach allows the model to create multiple views of the data by masking
portions of it. By minimizing the discrepancy between the representations of
these masked patches and the fully visible patches, MTS-LOF learns to capture
rich contextual information within medical time series datasets. The results of
experiments conducted on diverse medical time series datasets demonstrate the
superiority of MTS-LOF over other methods. These findings hold promise for
significantly enhancing healthcare applications by improving representation
learning. Furthermore, our work delves into the integration of joint-embedding
SSL and MAE techniques, shedding light on the intricate interplay between
temporal and structural dependencies in healthcare data. This understanding is
crucial, as it allows us to grasp the complexities of healthcare data analysis.",2023-10-19,2023,2023-10,medical
The Hidden Adversarial Vulnerabilities of Medical Federated Learning,"In this paper, we delve into the susceptibility of federated medical image
analysis systems to adversarial attacks. Our analysis uncovers a novel
exploitation avenue: using gradient information from prior global model
updates, adversaries can enhance the efficiency and transferability of their
attacks. Specifically, we demonstrate that single-step attacks (e.g. FGSM),
when aptly initialized, can outperform the efficiency of their iterative
counterparts but with reduced computational demand. Our findings underscore the
need to revisit our understanding of AI security in federated healthcare
settings.",2023-10-21,2023,2023-10,medical
PromptCBLUE: A Chinese Prompt Tuning Benchmark for the Medical Domain,"Biomedical language understanding benchmarks are the driving forces for
artificial intelligence applications with large language model (LLM) back-ends.
However, most current benchmarks: (a) are limited to English which makes it
challenging to replicate many of the successes in English for other languages,
or (b) focus on knowledge probing of LLMs and neglect to evaluate how LLMs
apply these knowledge to perform on a wide range of bio-medical tasks, or (c)
have become a publicly available corpus and are leaked to LLMs during
pre-training. To facilitate the research in medical LLMs, we re-build the
Chinese Biomedical Language Understanding Evaluation (CBLUE) benchmark into a
large scale prompt-tuning benchmark, PromptCBLUE. Our benchmark is a suitable
test-bed and an online platform for evaluating Chinese LLMs' multi-task
capabilities on a wide range bio-medical tasks including medical entity
recognition, medical text classification, medical natural language inference,
medical dialogue understanding and medical content/dialogue generation. To
establish evaluation on these tasks, we have experimented and report the
results with the current 9 Chinese LLMs fine-tuned with differtent fine-tuning
techniques.",2023-10-22,2023,2023-10,medical
AlpaCare:Instruction-tuned Large Language Models for Medical Application,"Instruction-finetuning (IFT) has become crucial in aligning Large Language
Models (LLMs) with diverse human needs and has shown great potential in medical
applications. However, previous studies mainly fine-tune LLMs on biomedical
datasets with limited diversity, which often rely on benchmarks or narrow task
scopes, and hence significantly limit the effectiveness on their medical
instruction-following ability and generalizability. To bridge this gap, we
propose creating a diverse, machine-generated medical IFT dataset,
MedInstruct-52k, using GPT-4 and ChatGPT with a high-quality expert-curated
seed set. We then fine-tune LLaMA-series models on the dataset to develop
AlpaCare. Despite using a smaller domain-specific dataset than previous medical
LLMs, AlpaCare not only demonstrates superior performance on medical
applications, with up to 38.1% absolute gain over best baselines in medical
free-form instruction evaluations, but also achieves 6.7% absolute gains
averaged over multiple general domain benchmarks. Human evaluation further
shows that AlpaCare consistently outperforms best baselines in terms of both
correctness and helpfulness. We offer public access to our data, model, and
codebase in https://github.com/XZhang97666/AlpaCare.",2023-10-23,2023,2023-10,medical
"Three-dimensional Bone Image Synthesis with Generative Adversarial
  Networks","Medical image processing has been highlighted as an area where deep
learning-based models have the greatest potential. However, in the medical
field in particular, problems of data availability and privacy are hampering
research progress and thus rapid implementation in clinical routine. The
generation of synthetic data not only ensures privacy, but also allows to
\textit{draw} new patients with specific characteristics, enabling the
development of data-driven models on a much larger scale. This work
demonstrates that three-dimensional generative adversarial networks (GANs) can
be efficiently trained to generate high-resolution medical volumes with finely
detailed voxel-based architectures. In addition, GAN inversion is successfully
implemented for the three-dimensional setting and used for extensive research
on model interpretability and applications such as image morphing, attribute
editing and style mixing. The results are comprehensively validated on a
database of three-dimensional HR-pQCT instances representing the bone
micro-architecture of the distal radius.",2023-10-26,2023,2023-10,medical
Generating Medical Prescriptions with Conditional Transformer,"Access to real-world medication prescriptions is essential for medical
research and healthcare quality improvement. However, access to real medication
prescriptions is often limited due to the sensitive nature of the information
expressed. Additionally, manually labelling these instructions for training and
fine-tuning Natural Language Processing (NLP) models can be tedious and
expensive. We introduce a novel task-specific model architecture,
Label-To-Text-Transformer (\textbf{LT3}), tailored to generate synthetic
medication prescriptions based on provided labels, such as a vocabulary list of
medications and their attributes. LT3 is trained on a set of around 2K lines of
medication prescriptions extracted from the MIMIC-III database, allowing the
model to produce valuable synthetic medication prescriptions. We evaluate LT3's
performance by contrasting it with a state-of-the-art Pre-trained Language
Model (PLM), T5, analysing the quality and diversity of generated texts. We
deploy the generated synthetic data to train the SpacyNER model for the Named
Entity Recognition (NER) task over the n2c2-2018 dataset. The experiments show
that the model trained on synthetic data can achieve a 96-98\% F1 score at
Label Recognition on Drug, Frequency, Route, Strength, and Form. LT3 codes and
data will be shared at
\url{https://github.com/HECTA-UoM/Label-To-Text-Transformer}",2023-10-30,2023,2023-10,medical
Medical Image Denosing via Explainable AI Feature Preserving Loss,"Denoising algorithms play a crucial role in medical image processing and
analysis. However, classical denoising algorithms often ignore explanatory and
critical medical features preservation, which may lead to misdiagnosis and
legal liabilities. In this work, we propose a new denoising method for medical
images that not only efficiently removes various types of noise, but also
preserves key medical features throughout the process. To achieve this goal, we
utilize a gradient-based eXplainable Artificial Intelligence (XAI) approach to
design a feature preserving loss function. Our feature preserving loss function
is motivated by the characteristic that gradient-based XAI is sensitive to
noise. Through backpropagation, medical image features before and after
denoising can be kept consistent. We conducted extensive experiments on three
available medical image datasets, including synthesized 13 different types of
noise and artifacts. The experimental results demonstrate the superiority of
our method in terms of denoising performance, model explainability, and
generalization.",2023-10-31,2023,2023-10,medical
"A Systematic Evaluation of GPT-4V's Multimodal Capability for Medical
  Image Analysis","This work conducts an evaluation of GPT-4V's multimodal capability for
medical image analysis, with a focus on three representative tasks of radiology
report generation, medical visual question answering, and medical visual
grounding. For the evaluation, a set of prompts is designed for each task to
induce the corresponding capability of GPT-4V to produce sufficiently good
outputs. Three evaluation ways including quantitative analysis, human
evaluation, and case study are employed to achieve an in-depth and extensive
evaluation. Our evaluation shows that GPT-4V excels in understanding medical
images and is able to generate high-quality radiology reports and effectively
answer questions about medical images. Meanwhile, it is found that its
performance for medical visual grounding needs to be substantially improved. In
addition, we observe the discrepancy between the evaluation outcome from
quantitative analysis and that from human evaluation. This discrepancy suggests
the limitations of conventional metrics in assessing the performance of large
language models like GPT-4V and the necessity of developing new metrics for
automatic quantitative analysis.",2023-10-31,2023,2023-10,medical
"healthAIChain: Improving security and safety using Blockchain Technology
  applications in AI-based healthcare systems","Blockchain as a digital ledger for keeping records of digital transactions
and other information, it is secure and decentralized technology. The globally
growing number of digital population every day possesses a significant threat
to online data including the medical and patients data. After bitcoin,
blockchain technology has emerged into a general-purpose technology with
applications in medical industries and healthcare. Blockchain can promote
highly configurable openness while retaining the highest security standards for
critical data of medical patients. Referred to as distributed record keeping
for healthcare systems which makes digital assets unalterable and transparent
via a cryptographic hash and decentralized network. The study delves into the
security and safety improvement associated with implementing blockchain in
AI-based healthcare systems. Blockchain-enabled AI tackles the existing issues
related to security, performance efficiencies, and safety in healthcare
systems. We have also examined the Artificial Intelligence in healthcare and
medical industry, potential areas, open questions concerning the blockchain in
healthcare systems. Finally, the article proposed an AI-based healthcare
blockchain model (healthAIChain) to improve patients data and security.",2023-11-01,2023,2023-11,medical
"Continuous Training and Fine-tuning for Domain-Specific Language Models
  in Medical Question Answering","Large language models exhibit promising general capabilities but often lack
specialized knowledge for domain-specific tasks. Developing domain experts from
a base model enables a range of applications without prohibitive training
costs. This work demonstrates a method using continuous training and
instruction fine-tuning to rapidly adapt Llama 2 base models to the Chinese
medical domain. We first conduct continuous training on 1B tokens from Chinese
medical references to teach relevant vocabulary and knowledge. The models are
then fine-tuned on 54K examples sourced from the Chinese National Medical
Licensing Examination. Experiments on Chinese medical data confirm the
effectiveness of this approach, producing a model comparable to GPT-3.5-turbo
while using way less computational resource. The resulting domain-specific
model could be useful for various Chinese medical applications. More broadly,
this provides a template for domain-specific training of large language models
in areas where pre-trained models lack the required expertise, such as law,
science, and engineering.",2023-11-01,2023,2023-11,medical
"Sam-Guided Enhanced Fine-Grained Encoding with Mixed Semantic Learning
  for Medical Image Captioning","With the development of multimodality and large language models, the deep
learning-based technique for medical image captioning holds the potential to
offer valuable diagnostic recommendations. However, current generic text and
image pre-trained models do not yield satisfactory results when it comes to
describing intricate details within medical images. In this paper, we present a
novel medical image captioning method guided by the segment anything model
(SAM) to enable enhanced encoding with both general and detailed feature
extraction. In addition, our approach employs a distinctive pre-training
strategy with mixed semantic learning to simultaneously capture both the
overall information and finer details within medical images. We demonstrate the
effectiveness of this approach, as it outperforms the pre-trained BLIP2 model
on various evaluation metrics for generating descriptions of medical images.",2023-11-02,2023,2023-11,medical
"Towards objective and systematic evaluation of bias in artificial
  intelligence for medical imaging","Artificial intelligence (AI) models trained using medical images for clinical
tasks often exhibit bias in the form of disparities in performance between
subgroups. Since not all sources of biases in real-world medical imaging data
are easily identifiable, it is challenging to comprehensively assess how those
biases are encoded in models, and how capable bias mitigation methods are at
ameliorating performance disparities. In this article, we introduce a novel
analysis framework for systematically and objectively investigating the impact
of biases in medical images on AI models. We developed and tested this
framework for conducting controlled in silico trials to assess bias in medical
imaging AI using a tool for generating synthetic magnetic resonance images with
known disease effects and sources of bias. The feasibility is showcased by
using three counterfactual bias scenarios to measure the impact of simulated
bias effects on a convolutional neural network (CNN) classifier and the
efficacy of three bias mitigation strategies. The analysis revealed that the
simulated biases resulted in expected subgroup performance disparities when the
CNN was trained on the synthetic datasets. Moreover, reweighing was identified
as the most successful bias mitigation strategy for this setup, and we
demonstrated how explainable AI methods can aid in investigating the
manifestation of bias in the model using this framework. Developing fair AI
models is a considerable challenge given that many and often unknown sources of
biases can be present in medical imaging datasets. In this work, we present a
novel methodology to objectively study the impact of biases and mitigation
strategies on deep learning pipelines, which can support the development of
clinical AI that is robust and responsible.",2023-11-03,2023,2023-11,medical
"FaMeSumm: Investigating and Improving Faithfulness of Medical
  Summarization","Summaries of medical text shall be faithful by being consistent and factual
with source inputs, which is an important but understudied topic for safety and
efficiency in healthcare. In this paper, we investigate and improve
faithfulness in summarization on a broad range of medical summarization tasks.
Our investigation reveals that current summarization models often produce
unfaithful outputs for medical input text. We then introduce FaMeSumm, a
framework to improve faithfulness by fine-tuning pre-trained language models
based on medical knowledge. FaMeSumm performs contrastive learning on designed
sets of faithful and unfaithful summaries, and it incorporates medical terms
and their contexts to encourage faithful generation of medical terms. We
conduct comprehensive experiments on three datasets in two languages: health
question and radiology report summarization datasets in English, and a
patient-doctor dialogue dataset in Chinese. Results demonstrate that FaMeSumm
is flexible and effective by delivering consistent improvements over mainstream
language models such as BART, T5, mT5, and PEGASUS, yielding state-of-the-art
performances on metrics for faithfulness and general quality. Human evaluation
by doctors also shows that FaMeSumm generates more faithful outputs. Our code
is available at https://github.com/psunlpgroup/FaMeSumm .",2023-11-03,2023,2023-11,medical
"Large Language Models Illuminate a Progressive Pathway to Artificial
  Healthcare Assistant: A Review","With the rapid development of artificial intelligence, large language models
(LLMs) have shown promising capabilities in mimicking human-level language
comprehension and reasoning. This has sparked significant interest in applying
LLMs to enhance various aspects of healthcare, ranging from medical education
to clinical decision support. However, medicine involves multifaceted data
modalities and nuanced reasoning skills, presenting challenges for integrating
LLMs. This paper provides a comprehensive review on the applications and
implications of LLMs in medicine. It begins by examining the fundamental
applications of general-purpose and specialized LLMs, demonstrating their
utilities in knowledge retrieval, research support, clinical workflow
automation, and diagnostic assistance. Recognizing the inherent multimodality
of medicine, the review then focuses on multimodal LLMs, investigating their
ability to process diverse data types like medical imaging and EHRs to augment
diagnostic accuracy. To address LLMs' limitations regarding personalization and
complex clinical reasoning, the paper explores the emerging development of
LLM-powered autonomous agents for healthcare. Furthermore, it summarizes the
evaluation methodologies for assessing LLMs' reliability and safety in medical
contexts. Overall, this review offers an extensive analysis on the
transformative potential of LLMs in modern medicine. It also highlights the
pivotal need for continuous optimizations and ethical oversight before these
models can be effectively integrated into clinical practice. Visit
https://github.com/mingze-yuan/Awesome-LLM-Healthcare for an accompanying
GitHub repository containing latest papers.",2023-11-03,2023,2023-11,medical
"Class-Incremental Continual Learning for General Purpose Healthcare
  Models","Healthcare clinics regularly encounter dynamic data that changes due to
variations in patient populations, treatment policies, medical devices, and
emerging disease patterns. Deep learning models can suffer from catastrophic
forgetting when fine-tuned in such scenarios, causing poor performance on
previously learned tasks. Continual learning allows learning on new tasks
without performance drop on previous tasks. In this work, we investigate the
performance of continual learning models on four different medical imaging
scenarios involving ten classification datasets from diverse modalities,
clinical specialties, and hospitals. We implement various continual learning
approaches and evaluate their performance in these scenarios. Our results
demonstrate that a single model can sequentially learn new tasks from different
specialties and achieve comparable performance to naive methods. These findings
indicate the feasibility of recycling or sharing models across the same or
different medical specialties, offering another step towards the development of
general-purpose medical imaging AI that can be shared across institutions.",2023-11-07,2023,2023-11,medical
Evaluating Large Language Models in Ophthalmology,"Purpose: The performance of three different large language models (LLMS)
(GPT-3.5, GPT-4, and PaLM2) in answering ophthalmology professional questions
was evaluated and compared with that of three different professional
populations (medical undergraduates, medical masters, and attending
physicians). Methods: A 100-item ophthalmology single-choice test was
administered to three different LLMs (GPT-3.5, GPT-4, and PaLM2) and three
different professional levels (medical undergraduates, medical masters, and
attending physicians), respectively. The performance of LLM was comprehensively
evaluated and compared with the human group in terms of average score,
stability, and confidence. Results: Each LLM outperformed undergraduates in
general, with GPT-3.5 and PaLM2 being slightly below the master's level, while
GPT-4 showed a level comparable to that of attending physicians. In addition,
GPT-4 showed significantly higher answer stability and confidence than GPT-3.5
and PaLM2. Conclusion: Our study shows that LLM represented by GPT-4 performs
better in the field of ophthalmology. With further improvements, LLM will bring
unexpected benefits in medical education and clinical decision making in the
near future.",2023-11-07,2023,2023-11,medical
"Generalization in medical AI: a perspective on developing scalable
  models","The scientific community is increasingly recognizing the importance of
generalization in medical AI for translating research into practical clinical
applications. A three-level scale is introduced to characterize
out-of-distribution generalization performance of medical AI models. This scale
addresses the diversity of real-world medical scenarios as well as whether
target domain data and labels are available for model recalibration. It serves
as a tool to help researchers characterize their development settings and
determine the best approach to tackling the challenge of out-of-distribution
generalization.",2023-11-09,2023,2023-11,medical
"Multimodal Foundation Models Exploit Text to Make Medical Image
  Predictions","Multimodal foundation models have shown compelling but conflicting
performance in medical image interpretation. However, the mechanisms by which
these models integrate and prioritize different data modalities, including
images and text, remain poorly understood. Here, using a diverse collection of
1014 multimodal medical cases, we evaluate the unimodal and multimodal image
interpretation abilities of proprietary (GPT-4, Gemini Pro 1.0) and open-source
(Llama-3.2-90B, LLaVA-Med-v1.5) multimodal foundational models with and without
the use of text descriptions. Across all models, image predictions were largely
driven by exploiting text, with accuracy increasing monotonically with the
amount of informative text. By contrast, human performance on medical image
interpretation did not improve with informative text. Exploitation of text is a
double-edged sword; we show that even mild suggestions of an incorrect
diagnosis in text diminishes image-based classification, reducing performance
dramatically in cases the model could previously answer with images alone.
Finally, we conducted a physician evaluation of model performance on long-form
medical cases, finding that the provision of images either reduced or had no
effect on model performance when text is already highly informative. Our
results suggest that multimodal AI models may be useful in medical diagnostic
reasoning but that their accuracy is largely driven, for better and worse, by
their exploitation of text.",2023-11-09,2023,2023-11,medical
"A Diagnosis and Treatment of Liver Diseases: Integrating Batch
  Processing, Rule-Based Event Detection and Explainable Artificial
  Intelligence","Liver diseases pose a significant global health burden, impacting many
individuals and having substantial economic and social consequences. Rising
liver problems are considered a fatal disease in many countries, such as Egypt
and Moldova. This study aims to develop a diagnosis and treatment model for
liver disease using Basic Formal Ontology (BFO), Patient Clinical Data (PCD)
ontology, and detection rules derived from a decision tree algorithm. For the
development of the ontology, the National Viral Hepatitis Control Program
(NVHCP) guidelines were used, which made the ontology more accurate and
reliable. The Apache Jena framework uses batch processing to detect events
based on these rules. Based on the event detected, queries can be directly
processed using SPARQL. We convert these Decision Tree (DT) and medical
guidelines-based rules into Semantic Web Rule Language (SWRL) to operationalize
the ontology. Using this SWRL in the ontology to predict different types of
liver disease with the help of the Pellet and Drools inference engines in
Protege Tools, a total of 615 records were taken from different liver diseases.
After inferring the rules, the result can be generated for the patient
according to the rules, and other patient-related details, along with different
precautionary suggestions, can be obtained based on these results. These rules
can make suggestions more accurate with the help of Explainable Artificial
Intelligence (XAI) with open API-based suggestions. When the patient has
prescribed a medical test, the model accommodates this result using optical
character recognition (OCR), and the same process applies when the patient has
prescribed a further medical suggestion according to the test report. These
models combine to form a comprehensive Decision Support System (DSS) for the
diagnosis of liver disease.",2023-11-10,2023,2023-11,medical
PEFT-MedAware: Large Language Model for Medical Awareness,"Chat models are capable of answering a wide range of questions, however, the
accuracy of their responses is highly uncertain. In this research, we propose a
specialized PEFT-MedAware model where we utilize parameter-efficient
fine-tuning (PEFT) to enhance the Falcon-1b large language model on specialized
MedQuAD data consisting of 16,407 medical QA pairs, leveraging only 0.44% of
its trainable parameters to enhance computational efficiency. The paper adopts
data preprocessing and PEFT to optimize model performance, complemented by a
BitsAndBytesConfig for efficient transformer training. The resulting model was
capable of outperforming other LLMs in medical question-answering tasks in
specific domains with greater accuracy utilizing limited computational
resources making it suitable for deployment in resource-constrained
environments. We propose further improvements through expanded datasets, larger
models, and feedback mechanisms for sustained medical relevancy. Our work
highlights the efficiency gains and specialized capabilities of PEFT in medical
AI, outpacing standard models in precision without extensive resource demands.
The proposed model and data are released for research purposes only.",2023-11-17,2023,2023-11,medical
"INSPECT: A Multimodal Dataset for Pulmonary Embolism Diagnosis and
  Prognosis","Synthesizing information from multiple data sources plays a crucial role in
the practice of modern medicine. Current applications of artificial
intelligence in medicine often focus on single-modality data due to a lack of
publicly available, multimodal medical datasets. To address this limitation, we
introduce INSPECT, which contains de-identified longitudinal records from a
large cohort of patients at risk for pulmonary embolism (PE), along with ground
truth labels for multiple outcomes. INSPECT contains data from 19,402 patients,
including CT images, radiology report impression sections, and structured
electronic health record (EHR) data (i.e. demographics, diagnoses, procedures,
vitals, and medications). Using INSPECT, we develop and release a benchmark for
evaluating several baseline modeling approaches on a variety of important PE
related tasks. We evaluate image-only, EHR-only, and multimodal fusion models.
Trained models and the de-identified dataset are made available for
non-commercial use under a data use agreement. To the best of our knowledge,
INSPECT is the largest multimodal dataset integrating 3D medical imaging and
EHR for reproducible methods evaluation and research.",2023-11-17,2023,2023-11,medical
"SA-Med2D-20M Dataset: Segment Anything in 2D Medical Imaging with 20
  Million masks","Segment Anything Model (SAM) has achieved impressive results for natural
image segmentation with input prompts such as points and bounding boxes. Its
success largely owes to massive labeled training data. However, directly
applying SAM to medical image segmentation cannot perform well because SAM
lacks medical knowledge -- it does not use medical images for training. To
incorporate medical knowledge into SAM, we introduce SA-Med2D-20M, a
large-scale segmentation dataset of 2D medical images built upon numerous
public and private datasets. It consists of 4.6 million 2D medical images and
19.7 million corresponding masks, covering almost the whole body and showing
significant diversity. This paper describes all the datasets collected in
SA-Med2D-20M and details how to process these datasets. Furthermore,
comprehensive statistics of SA-Med2D-20M are presented to facilitate the better
use of our dataset, which can help the researchers build medical vision
foundation models or apply their models to downstream medical applications. We
hope that the large scale and diversity of SA-Med2D-20M can be leveraged to
develop medical artificial intelligence for enhancing diagnosis, medical image
analysis, knowledge sharing, and education. The data with the redistribution
license is publicly available at https://github.com/OpenGVLab/SAM-Med2D.",2023-11-20,2023,2023-11,medical
"Energy efficiency in Edge TPU vs. embedded GPU for computer-aided
  medical imaging segmentation and classification","In this work, we evaluate the energy usage of fully embedded medical
diagnosis aids based on both segmentation and classification of medical images
implemented on Edge TPU and embedded GPU processors. We use glaucoma diagnosis
based on color fundus images as an example to show the possibility of
performing segmentation and classification in real time on embedded boards and
to highlight the different energy requirements of the studied implementations.
  Several other works develop the use of segmentation and feature extraction
techniques to detect glaucoma, among many other pathologies, with deep neural
networks. Memory limitations and low processing capabilities of embedded
accelerated systems (EAS) limit their use for deep network-based system
training. However, including specific acceleration hardware, such as NVIDIA's
Maxwell GPU or Google's Edge TPU, enables them to perform inferences using
complex pre-trained networks in very reasonable times.
  In this study, we evaluate the timing and energy performance of two EAS
equipped with Machine Learning (ML) accelerators executing an example
diagnostic tool developed in a previous work. For optic disc (OD) and cup (OC)
segmentation, the obtained prediction times per image are under 29 and 43 ms
using Edge TPUs and Maxwell GPUs, respectively. Prediction times for the
classification subsystem are lower than 10 and 14 ms for Edge TPUs and Maxwell
GPUs, respectively. Regarding energy usage, in approximate terms, for OD
segmentation Edge TPUs and Maxwell GPUs use 38 and 190 mJ per image,
respectively. For fundus classification, Edge TPUs and Maxwell GPUs use 45 and
70 mJ, respectively.",2023-11-20,2023,2023-11,medical
Medical Image Retrieval Using Pretrained Embeddings,"A wide range of imaging techniques and data formats available for medical
images make accurate retrieval from image databases challenging.
  Efficient retrieval systems are crucial in advancing medical research,
enabling large-scale studies and innovative diagnostic tools. Thus, addressing
the challenges of medical image retrieval is essential for the continued
enhancement of healthcare and research.
  In this study, we evaluated the feasibility of employing four
state-of-the-art pretrained models for medical image retrieval at modality,
body region, and organ levels and compared the results of two similarity
indexing approaches. Since the employed networks take 2D images, we analyzed
the impacts of weighting and sampling strategies to incorporate 3D information
during retrieval of 3D volumes. We showed that medical image retrieval is
feasible using pretrained networks without any additional training or
fine-tuning steps. Using pretrained embeddings, we achieved a recall of 1 for
various tasks at modality, body region, and organ level.",2023-11-22,2023,2023-11,medical
"Comparative Experimentation of Accuracy Metrics in Automated Medical
  Reporting: The Case of Otitis Consultations","Generative Artificial Intelligence (AI) can be used to automatically generate
medical reports based on transcripts of medical consultations. The aim is to
reduce the administrative burden that healthcare professionals face. The
accuracy of the generated reports needs to be established to ensure their
correctness and usefulness. There are several metrics for measuring the
accuracy of AI generated reports, but little work has been done towards the
application of these metrics in medical reporting. A comparative
experimentation of 10 accuracy metrics has been performed on AI generated
medical reports against their corresponding General Practitioner's (GP) medical
reports concerning Otitis consultations. The number of missing, incorrect, and
additional statements of the generated reports have been correlated with the
metric scores. In addition, we introduce and define a Composite Accuracy Score
which produces a single score for comparing the metrics within the field of
automated medical reporting. Findings show that based on the correlation study
and the Composite Accuracy Score, the ROUGE-L and Word Mover's Distance metrics
are the preferred metrics, which is not in line with previous work. These
findings help determine the accuracy of an AI generated medical report, which
aids the development of systems that generate medical reports for GPs to reduce
the administrative burden.",2023-11-22,2023,2023-11,medical
Machine Learning For An Explainable Cost Prediction of Medical Insurance,"Predictive modeling in healthcare continues to be an active actuarial
research topic as more insurance companies aim to maximize the potential of
Machine Learning approaches to increase their productivity and efficiency. In
this paper, the authors deployed three regression-based ensemble ML models that
combine variations of decision trees through Extreme Gradient Boosting,
Gradient-boosting Machine, and Random Forest) methods in predicting medical
insurance costs. Explainable Artificial Intelligence methods SHapley Additive
exPlanations and Individual Conditional Expectation plots were deployed to
discover and explain the key determinant factors that influence medical
insurance premium prices in the dataset. The dataset used comprised 986 records
and is publicly available in the KAGGLE repository. The models were evaluated
using four performance evaluation metrics, including R-squared, Mean Absolute
Error, Root Mean Squared Error, and Mean Absolute Percentage Error. The results
show that all models produced impressive outcomes; however, the XGBoost model
achieved a better overall performance although it also expanded more
computational resources, while the RF model recorded a lesser prediction error
and consumed far fewer computing resources than the XGBoost model. Furthermore,
we compared the outcome of both XAi methods in identifying the key determinant
features that influenced the PremiumPrices for each model and whereas both XAi
methods produced similar outcomes, we found that the ICE plots showed in more
detail the interactions between each variable than the SHAP analysis which
seemed to be more high-level. It is the aim of the authors that the
contributions of this study will help policymakers, insurers, and potential
medical insurance buyers in their decision-making process for selecting the
right policies that meet their specific needs.",2023-11-23,2023,2023-11,medical
"CMed-GPT: Prompt Tuning for Entity-Aware Chinese Medical Dialogue
  Generation","Medical dialogue generation relies on natural language generation techniques
to enable online medical consultations. Recently, the widespread adoption of
large-scale models in the field of natural language processing has facilitated
rapid advancements in this technology. Existing medical dialogue models are
mostly based on BERT and pre-trained on English corpora, but there is a lack of
high-performing models on the task of Chinese medical dialogue generation. To
solve the above problem, this paper proposes CMed-GPT, which is the GPT
pre-training language model based on Chinese medical domain text. The model is
available in two versions, namely, base and large, with corresponding
perplexity values of 8.64 and 8.01. Additionally, we incorporate lexical and
entity embeddings into the dialogue text in a uniform manner to meet the
requirements of downstream dialogue generation tasks. By applying both
fine-tuning and p-tuning to CMed-GPT, we lowered the PPL from 8.44 to 7.35.
This study not only confirms the exceptional performance of the CMed-GPT model
in generating Chinese biomedical text but also highlights the advantages of
p-tuning over traditional fine-tuning with prefix prompts. Furthermore, we
validate the significance of incorporating external information in medical
dialogue generation, which enhances the quality of dialogue generation.",2023-11-24,2023,2023-11,medical
"MRxaI: Black-Box Explainability for Image Classifiers in a Medical
  Setting","Existing tools for explaining the output of image classifiers can be divided
into white-box, which rely on access to the model internals, and black-box,
agnostic to the model. As the usage of AI in the medical domain grows, so too
does the usage of explainability tools. Existing work on medical image
explanations focuses on white-box tools, such as gradcam. However, there are
clear advantages to switching to a black-box tool, including the ability to use
it with any classifier and the wide selection of black-box tools available. On
standard images, black-box tools are as precise as white-box. In this paper we
compare the performance of several black-box methods against gradcam on a brain
cancer MRI dataset. We demonstrate that most black-box tools are not suitable
for explaining medical image classifications and present a detailed analysis of
the reasons for their shortcomings. We also show that one black-box tool, a
causal explainability-based rex, performs as well as \gradcam.",2023-11-24,2023,2023-11,medical
MEDITRON-70B: Scaling Medical Pretraining for Large Language Models,"Large language models (LLMs) can potentially democratize access to medical
knowledge. While many efforts have been made to harness and improve LLMs'
medical knowledge and reasoning capacities, the resulting models are either
closed-source (e.g., PaLM, GPT-4) or limited in scale (<= 13B parameters),
which restricts their abilities. In this work, we improve access to large-scale
medical LLMs by releasing MEDITRON: a suite of open-source LLMs with 7B and 70B
parameters adapted to the medical domain. MEDITRON builds on Llama-2 (through
our adaptation of Nvidia's Megatron-LM distributed trainer), and extends
pretraining on a comprehensively curated medical corpus, including selected
PubMed articles, abstracts, and internationally-recognized medical guidelines.
Evaluations using four major medical benchmarks show significant performance
gains over several state-of-the-art baselines before and after task-specific
finetuning. Overall, MEDITRON achieves a 6% absolute performance gain over the
best public baseline in its parameter class and 3% over the strongest baseline
we finetuned from Llama-2. Compared to closed-source LLMs, MEDITRON-70B
outperforms GPT-3.5 and Med-PaLM and is within 5% of GPT-4 and 10% of
Med-PaLM-2. We release our code for curating the medical pretraining corpus and
the MEDITRON model weights to drive open-source development of more capable
medical LLMs.",2023-11-27,2023,2023-11,medical
"De-identification of clinical free text using natural language
  processing: A systematic review of current approaches","Background: Electronic health records (EHRs) are a valuable resource for
data-driven medical research. However, the presence of protected health
information (PHI) makes EHRs unsuitable to be shared for research purposes.
De-identification, i.e. the process of removing PHI is a critical step in
making EHR data accessible. Natural language processing has repeatedly
demonstrated its feasibility in automating the de-identification process.
Objectives: Our study aims to provide systematic evidence on how the
de-identification of clinical free text has evolved in the last thirteen years,
and to report on the performances and limitations of the current
state-of-the-art systems. In addition, we aim to identify challenges and
potential research opportunities in this field. Methods: A systematic search in
PubMed, Web of Science and the DBLP was conducted for studies published between
January 2010 and February 2023. Titles and abstracts were examined to identify
the relevant studies. Selected studies were then analysed in-depth, and
information was collected on de-identification methodologies, data sources, and
measured performance. Results: A total of 2125 publications were identified for
the title and abstract screening. 69 studies were found to be relevant. Machine
learning (37 studies) and hybrid (26 studies) approaches are predominant, while
six studies relied only on rules. Majority of the approaches were trained and
evaluated on public corpora. The 2014 i2b2/UTHealth corpus is the most
frequently used (36 studies), followed by the 2006 i2b2 (18 studies) and 2016
CEGS N-GRID (10 studies) corpora.",2023-11-28,2023,2023-11,medical
"Explanatory Argument Extraction of Correct Answers in Resident Medical
  Exams","Developing the required technology to assist medical experts in their
everyday activities is currently a hot topic in the Artificial Intelligence
research field. Thus, a number of large language models (LLMs) and automated
benchmarks have recently been proposed with the aim of facilitating information
extraction in Evidence-Based Medicine (EBM) using natural language as a tool
for mediating in human-AI interaction. The most representative benchmarks are
limited to either multiple-choice or long-form answers and are available only
in English. In order to address these shortcomings, in this paper we present a
new dataset which, unlike previous work: (i) includes not only explanatory
arguments for the correct answer, but also arguments to reason why the
incorrect answers are not correct; (ii) the explanations are written originally
by medical doctors to answer questions from the Spanish Residency Medical
Exams. Furthermore, this new benchmark allows us to setup a novel extractive
task which consists of identifying the explanation of the correct answer
written by medical doctors. An additional benefit of our setting is that we can
leverage the extractive QA paradigm to automatically evaluate performance of
LLMs without resorting to costly manual evaluation by medical experts.
Comprehensive experimentation with language models for Spanish shows that
sometimes multilingual models fare better than monolingual ones, even
outperforming models which have been adapted to the medical domain.
Furthermore, results across the monolingual models are mixed, with supposedly
smaller and inferior models performing competitively. In any case, the obtained
results show that our novel dataset and approach can be an effective technique
to help medical practitioners in identifying relevant evidence-based
explanations for medical questions.",2023-12-01,2023,2023-12,medical
From Beginner to Expert: Modeling Medical Knowledge into General LLMs,"Recently, large language model (LLM) based artificial intelligence (AI)
systems have demonstrated remarkable capabilities in natural language
understanding and generation. However, these models face a significant
challenge when it comes to sensitive applications, such as reasoning over
medical knowledge and answering medical questions in a physician-like manner.
Prior studies attempted to overcome this challenge by increasing the model size
(>100B) to learn more general medical knowledge, while there is still room for
improvement in LLMs with smaller-scale model sizes (<100B). In this work, we
start from a pre-trained general LLM model (AntGLM-10B) and fine-tune it from a
medical beginner towards a medical expert (called AntGLM-Med-10B), which
leverages a 3-stage optimization procedure, i.e., general medical knowledge
injection, medical domain instruction tuning, and specific medical task
adaptation. Our contributions are threefold: (1) We specifically investigate
how to adapt a pre-trained general LLM in medical domain, especially for a
specific medical task. (2) We collect and construct large-scale medical
datasets for each stage of the optimization process. These datasets encompass
various data types and tasks, such as question-answering, medical reasoning,
multi-choice questions, and medical conversations. (3) Specifically for
multi-choice questions in the medical domain, we propose a novel
Verification-of-Choice approach for prompting engineering, which significantly
enhances the reasoning ability of LLMs. Remarkably, by combining the above
approaches, our AntGLM-Med-10B model can outperform the most of LLMs on
PubMedQA, including both general and medical LLMs, even when these LLMs have
larger model size.",2023-12-02,2023,2023-12,medical
"MKA: A Scalable Medical Knowledge Assisted Mechanism for Generative
  Models on Medical Conversation Tasks","Using natural language processing (NLP) technologies to develop medical
chatbots makes the diagnosis of the patient more convenient and efficient,
which is a typical application in healthcare AI. Because of its importance,
lots of research have been come out. Recently, the neural generative models
have shown their impressive ability as the core of chatbot, while it cannot
scale well when directly applied to medical conversation due to the lack of
medical-specific knowledge. To address the limitation, a scalable Medical
Knowledge Assisted mechanism, MKA, is proposed in this paper. The mechanism
aims to assist general neural generative models to achieve better performance
on the medical conversation task. The medical-specific knowledge graph is
designed within the mechanism, which contains 6 types of medical-related
information, including department, drug, check, symptom, disease, food.
Besides, the specific token concatenation policy is defined to effectively
inject medical information into the input data. Evaluation of our method is
carried out on two typical medical datasets, MedDG and MedDialog-CN. The
evaluation results demonstrate that models combined with our mechanism
outperform original methods in multiple automatic evaluation metrics. Besides,
MKA-Bert-GPT achieves state-of-the-art performance. The open-sourced codes are
public:
https://github.com/LIANGKE23/Knowledge_Assisted_Medical_Dialogue_Generation_Mechanism",2023-12-05,2023,2023-12,medical
Detecting algorithmic bias in medical-AI models using trees,"With the growing prevalence of machine learning and artificial
intelligence-based medical decision support systems, it is equally important to
ensure that these systems provide patient outcomes in a fair and equitable
fashion. This paper presents an innovative framework for detecting areas of
algorithmic bias in medical-AI decision support systems. Our approach
efficiently identifies potential biases in medical-AI models, specifically in
the context of sepsis prediction, by employing the Classification and
Regression Trees (CART) algorithm with conformity scores. We verify our
methodology by conducting a series of synthetic data experiments, showcasing
its ability to estimate areas of bias in controlled settings precisely. The
effectiveness of the concept is further validated by experiments using
electronic medical records from Grady Memorial Hospital in Atlanta, Georgia.
These tests demonstrate the practical implementation of our strategy in a
clinical environment, where it can function as a vital instrument for
guaranteeing fairness and equity in AI-based medical decisions.",2023-12-05,2023,2023-12,medical
"Improving Medical Report Generation with Adapter Tuning and Knowledge
  Enhancement in Vision-Language Foundation Models","Medical report generation demands automatic creation of coherent and precise
descriptions for medical images. However, the scarcity of labelled medical
image-report pairs poses formidable challenges in developing large-scale neural
networks capable of harnessing the potential of artificial intelligence,
exemplified by large language models. This study builds upon the
state-of-the-art vision-language pre-training and fine-tuning approach, BLIP-2,
to customize general large-scale foundation models. Integrating adapter tuning
and a medical knowledge enhancement loss, our model significantly improves
accuracy and coherence. Validation on the dataset of ImageCLEFmedical 2023
demonstrates our model's prowess, achieving the best-averaged results against
several state-of-the-art methods. Significant improvements in ROUGE and CIDEr
underscore our method's efficacy, highlighting promising outcomes for the rapid
medical-domain adaptation of the vision-language foundation models in
addressing challenges posed by data scarcity.",2023-12-07,2023,2023-12,medical
"Enhancing Medical Task Performance in GPT-4V: A Comprehensive Study on
  Prompt Engineering Strategies","OpenAI's latest large vision-language model (LVLM), GPT-4V(ision), has piqued
considerable interest for its potential in medical applications. Despite its
promise, recent studies and internal reviews highlight its underperformance in
specialized medical tasks. This paper explores the boundary of GPT-4V's
capabilities in medicine, particularly in processing complex imaging data from
endoscopies, CT scans, and MRIs etc. Leveraging open-source datasets, we
assessed its foundational competencies, identifying substantial areas for
enhancement. Our research emphasizes prompt engineering, an often-underutilized
strategy for improving AI responsiveness. Through iterative testing, we refined
the model's prompts, significantly improving its interpretative accuracy and
relevance in medical imaging. From our comprehensive evaluations, we distilled
10 effective prompt engineering techniques, each fortifying GPT-4V's medical
acumen. These methodical enhancements facilitate more reliable, precise, and
clinically valuable insights from GPT-4V, advancing its operability in critical
healthcare environments. Our findings are pivotal for those employing AI in
medicine, providing clear, actionable guidance on harnessing GPT-4V's full
diagnostic potential.",2023-12-07,2023,2023-12,medical
"ALGNet: Attention Light Graph Memory Network for Medical Recommendation
  System","Medication recommendation is a vital task for improving patient care and
reducing adverse events. However, existing methods often fail to capture the
complex and dynamic relationships among patient medical records, drug efficacy
and safety, and drug-drug interactions (DDI). In this paper, we propose ALGNet,
a novel model that leverages light graph convolutional networks (LGCN) and
augmentation memory networks (AMN) to enhance medication recommendation. LGCN
can efficiently encode the patient records and the DDI graph into
low-dimensional embeddings, while AMN can augment the patient representation
with external knowledge from a memory module. We evaluate our model on the
MIMIC-III dataset and show that it outperforms several baselines in terms of
recommendation accuracy and DDI avoidance. We also conduct an ablation study to
analyze the effects of different components of our model. Our results
demonstrate that ALGNet can achieve superior performance with less computation
and more interpretability. The implementation of this paper can be found at:
https://github.com/huyquoctrinh/ALGNet.",2023-12-09,2023,2023-12,medical
The Limits of Fair Medical Imaging AI In The Wild,"As artificial intelligence (AI) rapidly approaches human-level performance in
medical imaging, it is crucial that it does not exacerbate or propagate
healthcare disparities. Prior research has established AI's capacity to infer
demographic data from chest X-rays, leading to a key concern: do models using
demographic shortcuts have unfair predictions across subpopulations? In this
study, we conduct a thorough investigation into the extent to which medical AI
utilizes demographic encodings, focusing on potential fairness discrepancies
within both in-distribution training sets and external test sets. Our analysis
covers three key medical imaging disciplines: radiology, dermatology, and
ophthalmology, and incorporates data from six global chest X-ray datasets. We
confirm that medical imaging AI leverages demographic shortcuts in disease
classification. While correcting shortcuts algorithmically effectively
addresses fairness gaps to create ""locally optimal"" models within the original
data distribution, this optimality is not true in new test settings.
Surprisingly, we find that models with less encoding of demographic attributes
are often most ""globally optimal"", exhibiting better fairness during model
evaluation in new test environments. Our work establishes best practices for
medical imaging models which maintain their performance and fairness in
deployments beyond their initial training contexts, underscoring critical
considerations for AI clinical deployments across populations and sites.",2023-12-11,2023,2023-12,medical
SM70: A Large Language Model for Medical Devices,"We are introducing SM70, a 70 billion-parameter Large Language Model that is
specifically designed for SpassMed's medical devices under the brand name
'JEE1' (pronounced as G1 and means 'Life'). This large language model provides
more accurate and safe responses to medical-domain questions. To fine-tune
SM70, we used around 800K data entries from the publicly available dataset
MedAlpaca. The Llama2 70B open-sourced model served as the foundation for SM70,
and we employed the QLoRA technique for fine-tuning. The evaluation is
conducted across three benchmark datasets - MEDQA - USMLE, PUBMEDQA, and USMLE
- each representing a unique aspect of medical knowledge and reasoning. The
performance of SM70 is contrasted with other notable LLMs, including Llama2
70B, Clinical Camel 70 (CC70), GPT 3.5, GPT 4, and Med-Palm, to provide a
comparative understanding of its capabilities within the medical domain. Our
results indicate that SM70 outperforms several established models in these
datasets, showcasing its proficiency in handling a range of medical queries,
from fact-based questions derived from PubMed abstracts to complex clinical
decision-making scenarios. The robust performance of SM70, particularly in the
USMLE and PUBMEDQA datasets, suggests its potential as an effective tool in
clinical decision support and medical information retrieval. Despite its
promising results, the paper also acknowledges the areas where SM70 lags behind
the most advanced model, GPT 4, thereby highlighting the need for further
development, especially in tasks demanding extensive medical knowledge and
intricate reasoning.",2023-12-12,2023,2023-12,medical
"A Distributed Privacy Preserving Model for the Detection of Alzheimer's
  Disease","In the era of rapidly advancing medical technologies, the segmentation of
medical data has become inevitable, necessitating the development of privacy
preserving machine learning algorithms that can train on distributed data.
Consolidating sensitive medical data is not always an option particularly due
to the stringent privacy regulations imposed by the Health Insurance
Portability and Accountability Act (HIPAA). In this paper, I introduce a HIPAA
compliant framework that can train from distributed data. I then propose a
multimodal vertical federated model for Alzheimer's Disease (AD) detection, a
serious neurodegenerative condition that can cause dementia, severely impairing
brain function and hindering simple tasks, especially without preventative
care. This vertical federated learning (VFL) model offers a distributed
architecture that enables collaborative learning across diverse sources of
medical data while respecting privacy constraints imposed by HIPAA. The VFL
architecture proposed herein offers a novel distributed architecture, enabling
collaborative learning across diverse sources of medical data while respecting
statutory privacy constraints. By leveraging multiple modalities of data, the
robustness and accuracy of AD detection can be enhanced. This model not only
contributes to the advancement of federated learning techniques but also holds
promise for overcoming the hurdles posed by data segmentation in medical
research.",2023-12-15,2023,2023-12,medical
"CLIPSyntel: CLIP and LLM Synergy for Multimodal Question Summarization
  in Healthcare","In the era of modern healthcare, swiftly generating medical question
summaries is crucial for informed and timely patient care. Despite the
increasing complexity and volume of medical data, existing studies have focused
solely on text-based summarization, neglecting the integration of visual
information. Recognizing the untapped potential of combining textual queries
with visual representations of medical conditions, we introduce the Multimodal
Medical Question Summarization (MMQS) Dataset. This dataset, a major
contribution to our work, pairs medical queries with visual aids, facilitating
a richer and more nuanced understanding of patient needs. We also propose a
framework, utilizing the power of Contrastive Language Image Pretraining(CLIP)
and Large Language Models(LLMs), consisting of four modules that identify
medical disorders, generate relevant context, filter medical concepts, and
craft visually aware summaries. Our comprehensive framework harnesses the power
of CLIP, a multimodal foundation model, and various general-purpose LLMs,
comprising four main modules: the medical disorder identification module, the
relevant context generation module, the context filtration module for
distilling relevant medical concepts and knowledge, and finally, a
general-purpose LLM to generate visually aware medical question summaries.
Leveraging our MMQS dataset, we showcase how visual cues from images enhance
the generation of medically nuanced summaries. This multimodal approach not
only enhances the decision-making process in healthcare but also fosters a more
nuanced understanding of patient queries, laying the groundwork for future
research in personalized and responsive medical care",2023-12-16,2023,2023-12,medical
An Interpretable Deep Learning Approach for Skin Cancer Categorization,"Skin cancer is a serious worldwide health issue, precise and early detection
is essential for better patient outcomes and effective treatment. In this
research, we use modern deep learning methods and explainable artificial
intelligence (XAI) approaches to address the problem of skin cancer detection.
To categorize skin lesions, we employ four cutting-edge pre-trained models:
XceptionNet, EfficientNetV2S, InceptionResNetV2, and EfficientNetV2M. Image
augmentation approaches are used to reduce class imbalance and improve the
generalization capabilities of our models. Our models decision-making process
can be clarified because of the implementation of explainable artificial
intelligence (XAI). In the medical field, interpretability is essential to
establish credibility and make it easier to implement AI driven diagnostic
technologies into clinical workflows. We determined the XceptionNet
architecture to be the best performing model, achieving an accuracy of 88.72%.
Our study shows how deep learning and explainable artificial intelligence (XAI)
can improve skin cancer diagnosis, laying the groundwork for future
developments in medical image analysis. These technologies ability to allow for
early and accurate detection could enhance patient care, lower healthcare
costs, and raise the survival rates for those with skin cancer. Source Code:
https://github.com/Faysal-MD/An-Interpretable-Deep-Learning?Approach-for-Skin-Cancer-Categorization-IEEE2023",2023-12-17,2023,2023-12,medical
"UniDCP: Unifying Multiple Medical Vision-language Tasks via Dynamic
  Cross-modal Learnable Prompts","Medical vision-language pre-training (Med-VLP) models have recently
accelerated the fast-growing medical diagnostics application. However, most
Med-VLP models learn task-specific representations independently from scratch,
thereby leading to great inflexibility when they work across multiple
fine-tuning tasks. In this work, we propose UniDCP, a Unified medical
vision-language model with Dynamic Cross-modal learnable Prompts, which can be
plastically applied to multiple medical vision-language tasks. Specifically, we
explicitly construct a unified framework to harmonize diverse inputs from
multiple pretraining tasks by leveraging cross-modal prompts for unification,
which accordingly can accommodate heterogeneous medical fine-tuning tasks.
Furthermore, we conceive a dynamic cross-modal prompt optimizing strategy that
optimizes the prompts within the shareable space for implicitly processing the
shareable clinic knowledge. UniDCP is the first Med-VLP model capable of
performing all 8 medical uni-modal and cross-modal tasks over 14 corresponding
datasets, consistently yielding superior results over diverse state-of-the-art
methods.",2023-12-18,2023,2023-12,medical
"VITA: 'Carefully Chosen and Weighted Less' Is Better in Medication
  Recommendation","We address the medication recommendation problem, which aims to recommend
effective medications for a patient's current visit by utilizing information
(e.g., diagnoses and procedures) given at the patient's current and past
visits. While there exist a number of recommender systems designed for this
problem, we point out that they are challenged in accurately capturing the
relation (spec., the degree of relevance) between the current and each of the
past visits for the patient when obtaining her current health status, which is
the basis for recommending medications. To address this limitation, we propose
a novel medication recommendation framework, named VITA, based on the following
two novel ideas: (1) relevant-Visit selectIon; (2) Target-aware Attention.
Through extensive experiments using real-world datasets, we demonstrate the
superiority of VITA (spec., up to 5.56% higher accuracy, in terms of Jaccard,
than the best competitor) and the effectiveness of its two core ideas. The code
is available at https://github.com/jhheo0123/VITA.",2023-12-19,2023,2023-12,medical
"MedBench: A Large-Scale Chinese Benchmark for Evaluating Medical Large
  Language Models","The emergence of various medical large language models (LLMs) in the medical
domain has highlighted the need for unified evaluation standards, as manual
evaluation of LLMs proves to be time-consuming and labor-intensive. To address
this issue, we introduce MedBench, a comprehensive benchmark for the Chinese
medical domain, comprising 40,041 questions sourced from authentic examination
exercises and medical reports of diverse branches of medicine. In particular,
this benchmark is composed of four key components: the Chinese Medical
Licensing Examination, the Resident Standardization Training Examination, the
Doctor In-Charge Qualification Examination, and real-world clinic cases
encompassing examinations, diagnoses, and treatments. MedBench replicates the
educational progression and clinical practice experiences of doctors in
Mainland China, thereby establishing itself as a credible benchmark for
assessing the mastery of knowledge and reasoning abilities in medical language
learning models. We perform extensive experiments and conduct an in-depth
analysis from diverse perspectives, which culminate in the following findings:
(1) Chinese medical LLMs underperform on this benchmark, highlighting the need
for significant advances in clinical knowledge and diagnostic precision. (2)
Several general-domain LLMs surprisingly possess considerable medical
knowledge. These findings elucidate both the capabilities and limitations of
LLMs within the context of MedBench, with the ultimate goal of aiding the
medical research community.",2023-12-20,2023,2023-12,medical
Responsible Deep Learning for Software as a Medical Device,"Tools, models and statistical methods for signal processing and medical image
analysis and training deep learning models to create research prototypes for
eventual clinical applications are of special interest to the biomedical
imaging community. But material and optical properties of biological tissues
are complex and not easily captured by imaging devices. Added complexity can be
introduced by datasets with underrepresentation of medical images from races
and ethnicities for deep learning, and limited knowledge about the regulatory
framework needed for commercialization and safety of emerging Artificial
Intelligence (AI) and Machine Learning (ML) technologies for medical image
analysis. This extended version of the workshop paper presented at the special
session of the 2022 IEEE 19th International Symposium on Biomedical Imaging,
describes strategy and opportunities by University of California professors
engaged in machine learning (section I) and clinical research (section II), the
Office of Science and Engineering Laboratories (OSEL) section III, and
officials at the US FDA in Center for Devices & Radiological Health (CDRH)
section IV. Performance evaluations of AI/ML models of skin (RGB), tissue
biopsy (digital pathology), and lungs and kidneys (Magnetic Resonance, X-ray,
Computed Tomography) medical images for regulatory evaluations and real-world
deployment are discussed.",2023-12-20,2023,2023-12,medical
Towards Detecting Cascades of Biased Medical Claims on Twitter,"Social media may disseminate medical claims that highlight misleading
correlations between social identifiers and diseases due to not accounting for
structural determinants of health. Our research aims to identify biased medical
claims on Twitter and measure their spread. We propose a machine learning
framework that uses two models in tandem: RoBERTa to detect medical claims and
DistilBERT to classify bias. After identifying original biased medical claims,
we conducted a retweet cascade analysis, computing their individual reach and
rate of spread. Tweets containing biased claims were found to circulate faster
and further than unbiased claims.",2023-12-22,2023,2023-12,medical
"Medical Report Generation based on Segment-Enhanced Contrastive
  Representation Learning","Automated radiology report generation has the potential to improve radiology
reporting and alleviate the workload of radiologists. However, the medical
report generation task poses unique challenges due to the limited availability
of medical data and the presence of data bias. To maximize the utility of
available data and reduce data bias, we propose MSCL (Medical image
Segmentation with Contrastive Learning), a framework that utilizes the Segment
Anything Model (SAM) to segment organs, abnormalities, bones, etc., and can pay
more attention to the meaningful ROIs in the image to get better visual
representations. Then we introduce a supervised contrastive loss that assigns
more weight to reports that are semantically similar to the target while
training. The design of this loss function aims to mitigate the impact of data
bias and encourage the model to capture the essential features of a medical
image and generate high-quality reports. Experimental results demonstrate the
effectiveness of our proposed model, where we achieve state-of-the-art
performance on the IU X-Ray public dataset.",2023-12-26,2023,2023-12,medical
"Deploying ADVISER: Impact and Lessons from Using Artificial Intelligence
  for Child Vaccination Uptake in Nigeria","More than 5 million children under five years die from largely preventable or
treatable medical conditions every year, with an overwhelmingly large
proportion of deaths occurring in underdeveloped countries with low vaccination
uptake. One of the United Nations' sustainable development goals (SDG 3) aims
to end preventable deaths of newborns and children under five years of age. We
focus on Nigeria, where the rate of infant mortality is appalling. In
particular, low vaccination uptake in Nigeria is a major driver of more than
2,000 daily deaths of children under the age of five years. In this paper, we
describe our collaboration with government partners in Nigeria to deploy
ADVISER: AI-Driven Vaccination Intervention Optimiser. The framework, based on
an integer linear program that seeks to maximize the cumulative probability of
successful vaccination, is the first successful deployment of an AI-enabled
toolchain for optimizing the allocation of health interventions in Nigeria. In
this paper, we provide a background of the ADVISER framework and present
results, lessons, and success stories of deploying ADVISER to more than 13,000
families in the state of Oyo, Nigeria.",2023-12-30,2023,2023-12,medical
A generic model of consciousness,"This is a model of consciousness. The hard problem of consciousness, what it
feels like, is answered. The work builds on medical research analyzing the
source and mechanisms associated with our feelings. It goes further by
describing a generic model with wide applicability. The model is fully
consistent with medical pathways in humans, but easily extends to animals and
AI. The essence of the model is the interplay between associative memory and
physiology. The model is a clear and concrete counterexample to the famous
philosophical objections to a scientific explanation.",2024-01-02,2024,2024-01,medical
"Freeze the backbones: A Parameter-Efficient Contrastive Approach to
  Robust Medical Vision-Language Pre-training","Modern healthcare often utilises radiographic images alongside textual
reports for diagnostics, encouraging the use of Vision-Language Self-Supervised
Learning (VL-SSL) with large pre-trained models to learn versatile medical
vision representations. However, most existing VL-SSL frameworks are trained
end-to-end, which is computation-heavy and can lose vital prior information
embedded in pre-trained encoders. To address both issues, we introduce the
backbone-agnostic Adaptor framework, which preserves medical knowledge in
pre-trained image and text encoders by keeping them frozen, and employs a
lightweight Adaptor module for cross-modal learning. Experiments on medical
image classification and segmentation tasks across three datasets reveal that
our framework delivers competitive performance while cutting trainable
parameters by over 90% compared to current pre-training approaches. Notably,
when fine-tuned with just 1% of data, Adaptor outperforms several
Transformer-based methods trained on full datasets in medical image
segmentation.",2024-01-02,2024,2024-01,medical
"MedSumm: A Multimodal Approach to Summarizing Code-Mixed Hindi-English
  Clinical Queries","In the healthcare domain, summarizing medical questions posed by patients is
critical for improving doctor-patient interactions and medical decision-making.
Although medical data has grown in complexity and quantity, the current body of
research in this domain has primarily concentrated on text-based methods,
overlooking the integration of visual cues. Also prior works in the area of
medical question summarisation have been limited to the English language. This
work introduces the task of multimodal medical question summarization for
codemixed input in a low-resource setting. To address this gap, we introduce
the Multimodal Medical Codemixed Question Summarization MMCQS dataset, which
combines Hindi-English codemixed medical queries with visual aids. This
integration enriches the representation of a patient's medical condition,
providing a more comprehensive perspective. We also propose a framework named
MedSumm that leverages the power of LLMs and VLMs for this task. By utilizing
our MMCQS dataset, we demonstrate the value of integrating visual information
from images to improve the creation of medically detailed summaries. This
multimodal strategy not only improves healthcare decision-making but also
promotes a deeper comprehension of patient queries, paving the way for future
exploration in personalized and responsive medical care. Our dataset, code, and
pre-trained models will be made publicly available.",2024-01-03,2024,2024-01,medical
"TRLS: A Time Series Representation Learning Framework via Spectrogram
  for Medical Signal Processing","Representation learning frameworks in unlabeled time series have been
proposed for medical signal processing. Despite the numerous excellent
progresses have been made in previous works, we observe the representation
extracted for the time series still does not generalize well. In this paper, we
present a Time series (medical signal) Representation Learning framework via
Spectrogram (TRLS) to get more informative representations. We transform the
input time-domain medical signals into spectrograms and design a time-frequency
encoder named Time Frequency RNN (TFRNN) to capture more robust multi-scale
representations from the augmented spectrograms. Our TRLS takes spectrogram as
input with two types of different data augmentations and maximizes the
similarity between positive ones, which effectively circumvents the problem of
designing negative samples. Our evaluation of four real-world medical signal
datasets focusing on medical signal classification shows that TRLS is superior
to the existing frameworks.",2024-01-06,2024,2024-01,medical
MISS: A Generative Pretraining and Finetuning Approach for Med-VQA,"Medical visual question answering (VQA) is a challenging multimodal task,
where Vision-Language Pre-training (VLP) models can effectively improve the
generalization performance. However, most methods in the medical field treat
VQA as an answer classification task which is difficult to transfer to
practical application scenarios. Additionally, due to the privacy of medical
images and the expensive annotation process, large-scale medical image-text
pairs datasets for pretraining are severely lacking. In this paper, we propose
a large-scale MultI-task Self-Supervised learning based framework (MISS) for
medical VQA tasks. Unlike existing methods, we treat medical VQA as a
generative task. We unify the text encoder and multimodal encoder and align
image-text features through multi-task learning. Furthermore, we propose a
Transfer-and-Caption method that extends the feature space of single-modal
image datasets using Large Language Models (LLMs), enabling those traditional
medical vision field task data to be applied to VLP. Experiments show that our
method achieves excellent results with fewer multimodal datasets and
demonstrates the advantages of generative VQA models.",2024-01-10,2024,2024-01,medical
"Yes, this is what I was looking for! Towards Multi-modal Medical
  Consultation Concern Summary Generation","Over the past few years, the use of the Internet for healthcare-related tasks
has grown by leaps and bounds, posing a challenge in effectively managing and
processing information to ensure its efficient utilization. During moments of
emotional turmoil and psychological challenges, we frequently turn to the
internet as our initial source of support, choosing this over discussing our
feelings with others due to the associated social stigma. In this paper, we
propose a new task of multi-modal medical concern summary (MMCS) generation,
which provides a short and precise summary of patients' major concerns brought
up during the consultation. Nonverbal cues, such as patients' gestures and
facial expressions, aid in accurately identifying patients' concerns. Doctors
also consider patients' personal information, such as age and gender, in order
to describe the medical condition appropriately. Motivated by the potential
efficacy of patients' personal context and visual gestures, we propose a
transformer-based multi-task, multi-modal intent-recognition, and medical
concern summary generation (IR-MMCSG) system. Furthermore, we propose a
multitasking framework for intent recognition and medical concern summary
generation for doctor-patient consultations. We construct the first multi-modal
medical concern summary generation (MM-MediConSummation) corpus, which includes
patient-doctor consultations annotated with medical concern summaries, intents,
patient personal information, doctor's recommendations, and keywords. Our
experiments and analysis demonstrate (a) the significant role of patients'
expressions/gestures and their personal information in intent identification
and medical concern summary generation, and (b) the strong correlation between
intent recognition and patients' medical concern summary generation
  The dataset and source code are available at https://github.com/NLP-RL/MMCSG.",2024-01-10,2024,2024-01,medical
Hallucination Benchmark in Medical Visual Question Answering,"The recent success of large language and vision models (LLVMs) on vision
question answering (VQA), particularly their applications in medicine
(Med-VQA), has shown a great potential of realizing effective visual assistants
for healthcare. However, these models are not extensively tested on the
hallucination phenomenon in clinical settings. Here, we created a hallucination
benchmark of medical images paired with question-answer sets and conducted a
comprehensive evaluation of the state-of-the-art models. The study provides an
in-depth analysis of current models' limitations and reveals the effectiveness
of various prompting strategies.",2024-01-11,2024,2024-01,medical
"Medical Dialogue Generation via Intuitive-then-Analytical Differential
  Diagnosis","Medical dialogue systems have attracted growing research attention as they
have the potential to provide rapid diagnoses, treatment plans, and health
consultations. In medical dialogues, a proper diagnosis is crucial as it
establishes the foundation for future consultations. Clinicians typically
employ both intuitive and analytic reasoning to formulate a differential
diagnosis. This reasoning process hypothesizes and verifies a variety of
possible diseases and strives to generate a comprehensive and rigorous
diagnosis. However, recent studies on medical dialogue generation have
overlooked the significance of modeling a differential diagnosis, which hinders
the practical application of these systems. To address the above issue, we
propose a medical dialogue generation framework with the
Intuitive-then-Analytic Differential Diagnosis (IADDx). Our method starts with
a differential diagnosis via retrieval-based intuitive association and
subsequently refines it through a graph-enhanced analytic procedure. The
resulting differential diagnosis is then used to retrieve medical knowledge and
guide response generation. Experimental results on two datasets validate the
efficacy of our method. Besides, we demonstrate how our framework assists both
clinicians and patients in understanding the diagnostic process, for instance,
by producing intermediate results and graph-based diagnosis paths.",2024-01-12,2024,2024-01,medical
"Empowering Medical Imaging with Artificial Intelligence: A Review of
  Machine Learning Approaches for the Detection, and Segmentation of COVID-19
  Using Radiographic and Tomographic Images","Since 2019, the global dissemination of the Coronavirus and its novel strains
has resulted in a surge of new infections. The use of X-ray and computed
tomography (CT) imaging techniques is critical in diagnosing and managing
COVID-19. Incorporating artificial intelligence (AI) into the field of medical
imaging is a powerful combination that can provide valuable support to
healthcare professionals.This paper focuses on the methodological approach of
using machine learning (ML) to enhance medical imaging for COVID-19
diagnosis.For example, deep learning can accurately distinguish lesions from
other parts of the lung without human intervention in a matter of
minutes.Moreover, ML can enhance performance efficiency by assisting
radiologists in making more precise clinical decisions, such as detecting and
distinguishing Covid-19 from different respiratory infections and segmenting
infections in CT and X-ray images, even when the lesions have varying sizes and
shapes.This article critically assesses machine learning methodologies utilized
for the segmentation, classification, and detection of Covid-19 within CT and
X-ray images, which are commonly employed tools in clinical and hospital
settings to represent the lung in various aspects and extensive detail.There is
a widespread expectation that this technology will continue to hold a central
position within the healthcare sector, driving further progress in the
management of the pandemic.",2024-01-13,2024,2024-01,medical
"Developing ChatGPT for Biology and Medicine: A Complete Review of
  Biomedical Question Answering","ChatGPT explores a strategic blueprint of question answering (QA) in
delivering medical diagnosis, treatment recommendations, and other healthcare
support. This is achieved through the increasing incorporation of medical
domain data via natural language processing (NLP) and multimodal paradigms. By
transitioning the distribution of text, images, videos, and other modalities
from the general domain to the medical domain, these techniques have expedited
the progress of medical domain question answering (MDQA). They bridge the gap
between human natural language and sophisticated medical domain knowledge or
expert manual annotations, handling large-scale, diverse, unbalanced, or even
unlabeled data analysis scenarios in medical contexts. Central to our focus is
the utilizing of language models and multimodal paradigms for medical question
answering, aiming to guide the research community in selecting appropriate
mechanisms for their specific medical research requirements. Specialized tasks
such as unimodal-related question answering, reading comprehension, reasoning,
diagnosis, relation extraction, probability modeling, and others, as well as
multimodal-related tasks like vision question answering, image caption,
cross-modal retrieval, report summarization, and generation, are discussed in
detail. Each section delves into the intricate specifics of the respective
method under consideration. This paper highlights the structures and
advancements of medical domain explorations against general domain methods,
emphasizing their applications across different tasks and datasets. It also
outlines current challenges and opportunities for future medical domain
research, paving the way for continued innovation and application in this
rapidly evolving field.",2024-01-15,2024,2024-01,medical
"MICA: Towards Explainable Skin Lesion Diagnosis via Multi-Level
  Image-Concept Alignment","Black-box deep learning approaches have showcased significant potential in
the realm of medical image analysis. However, the stringent trustworthiness
requirements intrinsic to the medical field have catalyzed research into the
utilization of Explainable Artificial Intelligence (XAI), with a particular
focus on concept-based methods. Existing concept-based methods predominantly
apply concept annotations from a single perspective (e.g., global level),
neglecting the nuanced semantic relationships between sub-regions and concepts
embedded within medical images. This leads to underutilization of the valuable
medical information and may cause models to fall short in harmoniously
balancing interpretability and performance when employing inherently
interpretable architectures such as Concept Bottlenecks. To mitigate these
shortcomings, we propose a multi-modal explainable disease diagnosis framework
that meticulously aligns medical images and clinical-related concepts
semantically at multiple strata, encompassing the image level, token level, and
concept level. Moreover, our method allows for model intervention and offers
both textual and visual explanations in terms of human-interpretable concepts.
Experimental results on three skin image datasets demonstrate that our method,
while preserving model interpretability, attains high performance and label
efficiency for concept detection and disease diagnosis.",2024-01-16,2024,2024-01,medical
"Artificial Intelligence-based algorithms in medical image scan
  seg-mentation and intelligent visual-content generation -- a concise overview","Recently, Artificial Intelligence (AI)-based algorithms have revolutionized
the medical image segmentation processes. Thus, the precise segmentation of
organs and their lesions may contribute to an efficient diagnostics process and
a more effective selection of targeted therapies as well as increasing the
effectiveness of the training process. In this context, AI may contribute to
the automatization of the image scan segmentation process and increase the
quality of the resulting 3D objects, which may lead to the generation of more
realistic virtual objects. In this paper, we focus on the AI-based solutions
applied in the medical image scan segmentation, and intelligent visual-content
generation, i.e. computer-generated three-dimensional (3D) images in the
context of Extended Reality (XR). We consider different types of neural
networks used with a special emphasis on the learning rules applied, taking
into account algorithm accuracy and performance, as well as open data
availability. This paper attempts to summarize the current development of
AI-based segmentation methods in medical imaging and intelligent visual content
generation that are applied in XR. It concludes also with possible developments
and open challenges in AI application in Extended Reality-based solutions.
Finally, the future lines of research and development directions of Artificial
Intelligence applications both in medical image segmentation and Extended
Reality-based medical solutions are discussed",2024-01-18,2024,2024-01,medical
Aprendizado de máquina aplicado na eletroquímica,"This systematic review focuses on analyzing the use of machine learning
techniques for identifying and quantifying analytes in various electrochemical
applications, presenting the available applications in the literature. Machine
learning is a tool that can facilitate the analysis and enhance the
understanding of processes involving various analytes. In electrochemical
biosensors, it increases the precision of medical diagnostics, improving the
identification of biomarkers and pathogens with high reliability. It can be
effectively used for the classification of complex chemical products; in
environmental monitoring, using low-cost sensors; in portable devices and
wearable systems; among others. Currently, the analysis of some analytes is
still performed manually, requiring the expertise of a specialist in the field
and thus hindering the generalization of results. In light of the advancements
in artificial intelligence today, this work proposes to carry out a systematic
review of the literature on the applications of artificial intelligence
techniques. A set of articles has been identified that address electrochemical
problems using machine learning techniques, more specifically, supervised
learning.",2024-01-20,2024,2024-01,medical
MedLM: Exploring Language Models for Medical Question Answering Systems,"In the face of rapidly expanding online medical literature, automated systems
for aggregating and summarizing information are becoming increasingly crucial
for healthcare professionals and patients. Large Language Models (LLMs), with
their advanced generative capabilities, have shown promise in various NLP
tasks, and their potential in the healthcare domain, particularly for
Closed-Book Generative QnA, is significant. However, the performance of these
models in domain-specific tasks such as medical Q&A remains largely unexplored.
This study aims to fill this gap by comparing the performance of general and
medical-specific distilled LMs for medical Q&A. We aim to evaluate the
effectiveness of fine-tuning domain-specific LMs and compare the performance of
different families of Language Models. The study will address critical
questions about these models' reliability, comparative performance, and
effectiveness in the context of medical Q&A. The findings will provide valuable
insights into the suitability of different LMs for specific applications in the
medical domain.",2024-01-21,2024,2024-01,medical
"Next Visit Diagnosis Prediction via Medical Code-Centric Multimodal
  Contrastive EHR Modelling with Hierarchical Regularisation","Predicting next visit diagnosis using Electronic Health Records (EHR) is an
essential task in healthcare, critical for devising proactive future plans for
both healthcare providers and patients. Nonetheless, many preceding studies
have not sufficiently addressed the heterogeneous and hierarchical
characteristics inherent in EHR data, inevitably leading to sub-optimal
performance. To this end, we propose NECHO, a novel medical code-centric
multimodal contrastive EHR learning framework with hierarchical regularisation.
First, we integrate multifaceted information encompassing medical codes,
demographics, and clinical notes using a tailored network design and a pair of
bimodal contrastive losses, all of which pivot around a medical codes
representation. We also regularise modality-specific encoders using a parental
level information in medical ontology to learn hierarchical structure of EHR
data. A series of experiments on MIMIC-III data demonstrates effectiveness of
our approach.",2024-01-22,2024,2024-01,medical
Free Form Medical Visual Question Answering in Radiology,"Visual Question Answering (VQA) in the medical domain presents a unique,
interdisciplinary challenge, combining fields such as Computer Vision, Natural
Language Processing, and Knowledge Representation. Despite its importance,
research in medical VQA has been scant, only gaining momentum since 2018.
Addressing this gap, our research delves into the effective representation of
radiology images and the joint learning of multimodal representations,
surpassing existing methods. We innovatively augment the SLAKE dataset,
enabling our model to respond to a more diverse array of questions, not limited
to the immediate content of radiology or pathology images. Our model achieves a
top-1 accuracy of 79.55\% with a less complex architecture, demonstrating
comparable performance to current state-of-the-art models. This research not
only advances medical VQA but also opens avenues for practical applications in
diagnostic settings.",2024-01-23,2024,2024-01,medical
"Exploiting Liver CT scans in Colorectal Carcinoma genomics mutation
  classification","The liver is the most involved organ by distant metastasis in colon-rectal
cancer (CRC) patients and it comes necessary to be aware of the mutational
status of the lesions to correctly design the best individual treatment. So
far, efforts have been made in order to develop non-invasive and real-time
methods that permit the analysis of the whole tumor, using new artificial
intelligence tools to analyze the tumor's image obtained by Computed Tomography
(CT) scan. In order to address the current medical workflow, that is biopsy
analysis-based, we propose the first DeepLearning-based exploration, to our
knowledge, of such classification approach from the patient medical imaging. We
propose i) a solid pipeline for managing undersized datasets of available CT
scans and ii) a baseline study for genomics mutation diagnosis support for
preemptive patient follow-up. Our method is able to identify CRC RAS mutation
family from CT images with 0.73 F1 score.",2024-01-25,2024,2024-01,medical
"Application analysis of ai technology combined with spiral CT scanning
  in early lung cancer screening","At present, the incidence and fatality rate of lung cancer in China rank
first among all malignant tumors. Despite the continuous development and
improvement of China's medical level, the overall 5-year survival rate of lung
cancer patients is still lower than 20% and is staged. A number of studies have
confirmed that early diagnosis and treatment of early stage lung cancer is of
great significance to improve the prognosis of patients. In recent years,
artificial intelligence technology has gradually begun to be applied in
oncology. ai is used in cancer screening, clinical diagnosis, radiation therapy
(image acquisition, at-risk organ segmentation, image calibration and delivery)
and other aspects of rapid development. However, whether medical ai can be
socialized depends on the public's attitude and acceptance to a certain extent.
However, at present, there are few studies on the diagnosis of early lung
cancer by AI technology combined with SCT scanning. In view of this, this study
applied the combined method in early lung cancer screening, aiming to find a
safe and efficient screening mode and provide a reference for clinical
diagnosis and treatment.",2024-01-26,2024,2024-01,medical
"Evaluating LLM -- Generated Multimodal Diagnosis from Medical Images and
  Symptom Analysis","Large language models (LLMs) constitute a breakthrough state-of-the-art
Artificial Intelligence technology which is rapidly evolving and promises to
aid in medical diagnosis. However, the correctness and the accuracy of their
returns has not yet been properly evaluated. In this work, we propose an LLM
evaluation paradigm that incorporates two independent steps of a novel
methodology, namely (1) multimodal LLM evaluation via structured interactions
and (2) follow-up, domain-specific analysis based on data extracted via the
previous interactions. Using this paradigm, (1) we evaluate the correctness and
accuracy of LLM-generated medical diagnosis with publicly available multimodal
multiple-choice questions(MCQs) in the domain of Pathology and (2) proceed to a
systemic and comprehensive analysis of extracted results. We used
GPT-4-Vision-Preview as the LLM to respond to complex, medical questions
consisting of both images and text, and we explored a wide range of diseases,
conditions, chemical compounds, and related entity types that are included in
the vast knowledge domain of Pathology. GPT-4-Vision-Preview performed quite
well, scoring approximately 84\% of correct diagnoses. Next, we further
analyzed the findings of our work, following an analytical approach which
included Image Metadata Analysis, Named Entity Recognition and Knowledge
Graphs. Weaknesses of GPT-4-Vision-Preview were revealed on specific knowledge
paths, leading to a further understanding of its shortcomings in specific
areas. Our methodology and findings are not limited to the use of
GPT-4-Vision-Preview, but a similar approach can be followed to evaluate the
usefulness and accuracy of other LLMs and, thus, improve their use with further
optimization.",2024-01-28,2024,2024-01,medical
"A Medical Data-Effective Learning Benchmark for Highly Efficient
  Pre-training of Foundation Models","Foundation models, pre-trained on massive datasets, have achieved
unprecedented generalizability. However, is it truly necessary to involve such
vast amounts of data in pre-training, consuming extensive computational
resources? This paper introduces data-effective learning, aiming to use data in
the most impactful way to pre-train foundation models. This involves strategies
that focus on data quality rather than quantity, ensuring the data used for
training has high informational value. Data-effective learning plays a profound
role in accelerating foundation model training, reducing computational costs,
and saving data storage, which is very important as the volume of medical data
in recent years has grown beyond many people's expectations. However, due to
the lack of standards and comprehensive benchmarks, research on medical
data-effective learning is poorly studied. To address this gap, our paper
introduces a comprehensive benchmark specifically for evaluating data-effective
learning in the medical field. This benchmark includes a dataset with millions
of data samples from 31 medical centers (DataDEL), a baseline method for
comparison (MedDEL), and a new evaluation metric (NormDEL) to objectively
measure data-effective learning performance. Our extensive experimental results
show the baseline MedDEL can achieve performance comparable to the original
large dataset with only 5% of the data. Establishing such an open
data-effective learning benchmark is crucial for the medical foundation model
research community because it facilitates efficient data use, promotes
collaborative breakthroughs, and fosters the development of cost-effective,
scalable, and impactful healthcare solutions.",2024-01-31,2024,2024-01,medical
"SA-MDKIF: A Scalable and Adaptable Medical Domain Knowledge Injection
  Framework for Large Language Models","Recent advances in large language models (LLMs) have demonstrated exceptional
performance in various natural language processing (NLP) tasks. However, their
effective application in the medical domain is hampered by a lack of medical
domain knowledge. In this study, we present SA-MDKIF, a scalable and adaptable
framework that aims to inject medical knowledge into general-purpose LLMs
through instruction tuning, thereby enabling adaptability for various
downstream tasks. SA-MDKIF consists of two stages: skill training and skill
adaptation. In the first stage, we define 12 basic medical skills and use
AdaLoRA to train these skills based on uniformly formatted instructional
datasets that we have constructed. In the next stage, we train the skill router
using task-specific downstream data and use this router to integrate the
acquired skills with LLMs during inference. Experimental results on 9 different
medical tasks show that SA-MDKIF improves performance by 10-20% compared to the
original LLMs. Notably, this improvement is particularly pronounced for unseen
medical tasks, showing an improvement of up to 30%.",2024-02-01,2024,2024-02,medical
"How well do LLMs cite relevant medical references? An evaluation
  framework and analyses","Large language models (LLMs) are currently being used to answer medical
questions across a variety of clinical domains. Recent top-performing
commercial LLMs, in particular, are also capable of citing sources to support
their responses. In this paper, we ask: do the sources that LLMs generate
actually support the claims that they make? To answer this, we propose three
contributions. First, as expert medical annotations are an expensive and
time-consuming bottleneck for scalable evaluation, we demonstrate that GPT-4 is
highly accurate in validating source relevance, agreeing 88% of the time with a
panel of medical doctors. Second, we develop an end-to-end, automated pipeline
called \textit{SourceCheckup} and use it to evaluate five top-performing LLMs
on a dataset of 1200 generated questions, totaling over 40K pairs of statements
and sources. Interestingly, we find that between ~50% to 90% of LLM responses
are not fully supported by the sources they provide. We also evaluate GPT-4
with retrieval augmented generation (RAG) and find that, even still, around
30\% of individual statements are unsupported, while nearly half of its
responses are not fully supported. Third, we open-source our curated dataset of
medical questions and expert annotations for future evaluations. Given the
rapid pace of LLM development and the potential harms of incorrect or outdated
medical information, it is crucial to also understand and quantify their
capability to produce relevant, trustworthy medical references.",2024-02-03,2024,2024-02,medical
"Exploring Intrinsic Properties of Medical Images for Self-Supervised
  Binary Semantic Segmentation","Recent advancements in self-supervised learning have unlocked the potential
to harness unlabeled data for auxiliary tasks, facilitating the learning of
beneficial priors. This has been particularly advantageous in fields like
medical image analysis, where labeled data are scarce. Although effective for
classification tasks, this methodology has shown limitations in more complex
applications, such as medical image segmentation. In this paper, we introduce
Medical imaging Enhanced with Dynamic Self-Adaptive Semantic Segmentation
(MedSASS), a dedicated self-supervised framework tailored for medical image
segmentation. We evaluate MedSASS against existing state-of-the-art methods
across four diverse medical datasets, showcasing its superiority. MedSASS
outperforms existing CNN-based self-supervised methods by 3.83% and matches the
performance of ViT-based methods. Furthermore, when MedSASS is trained
end-to-end, covering both encoder and decoder, it demonstrates significant
improvements of 14.4% for CNNs and 6% for ViT-based architectures compared to
existing state-of-the-art self-supervised strategies.",2024-02-04,2024,2024-02,medical
"COMPRER: A Multimodal Multi-Objective Pretraining Framework for Enhanced
  Medical Image Representation","Substantial advances in multi-modal Artificial Intelligence (AI) facilitate
the combination of diverse medical modalities to achieve holistic health
assessments. We present COMPRER , a novel multi-modal, multi-objective
pretraining framework which enhances medical-image representation, diagnostic
inferences, and prognosis of diseases. COMPRER employs a multi-objective
training framework, where each objective introduces distinct knowledge to the
model. This includes a multimodal loss that consolidates information across
different imaging modalities; A temporal loss that imparts the ability to
discern patterns over time; Medical-measure prediction adds appropriate medical
insights; Lastly, reconstruction loss ensures the integrity of image structure
within the latent space. Despite the concern that multiple objectives could
weaken task performance, our findings show that this combination actually
boosts outcomes on certain tasks. Here, we apply this framework to both fundus
images and carotid ultrasound, and validate our downstream tasks capabilities
by predicting both current and future cardiovascular conditions. COMPRER
achieved higher Area Under the Curve (AUC) scores in evaluating medical
conditions compared to existing models on held-out data. On the
Out-of-distribution (OOD) UK-Biobank dataset COMPRER maintains favorable
performance over well-established models with more parameters, even though
these models were trained on $75\times$ more data than COMPRER. In addition, to
better assess our model's performance in contrastive learning, we introduce a
novel evaluation metric, providing deeper understanding of the effectiveness of
the latent space pairing.",2024-02-04,2024,2024-02,medical
AI-Enhanced Virtual Reality in Medicine: A Comprehensive Survey,"With the rapid advance of computer graphics and artificial intelligence
technologies, the ways we interact with the world have undergone a
transformative shift. Virtual Reality (VR) technology, aided by artificial
intelligence (AI), has emerged as a dominant interaction media in multiple
application areas, thanks to its advantage of providing users with immersive
experiences. Among those applications, medicine is considered one of the most
promising areas. In this paper, we present a comprehensive examination of the
burgeoning field of AI-enhanced VR applications in medical care and services.
By introducing a systematic taxonomy, we meticulously classify the pertinent
techniques and applications into three well-defined categories based on
different phases of medical diagnosis and treatment: Visualization Enhancement,
VR-related Medical Data Processing, and VR-assisted Intervention. This
categorization enables a structured exploration of the diverse roles that
AI-powered VR plays in the medical domain, providing a framework for a more
comprehensive understanding and evaluation of these technologies. To our best
knowledge, this is the first systematic survey of AI-powered VR systems in
medical settings, laying a foundation for future research in this
interdisciplinary domain.",2024-02-05,2024,2024-02,medical
Large Language Model Distilling Medication Recommendation Model,"The recommendation of medication is a vital aspect of intelligent healthcare
systems, as it involves prescribing the most suitable drugs based on a
patient's specific health needs. Unfortunately, many sophisticated models
currently in use tend to overlook the nuanced semantics of medical data, while
only relying heavily on identities. Furthermore, these models face significant
challenges in handling cases involving patients who are visiting the hospital
for the first time, as they lack prior prescription histories to draw upon. To
tackle these issues, we harness the powerful semantic comprehension and
input-agnostic characteristics of Large Language Models (LLMs). Our research
aims to transform existing medication recommendation methodologies using LLMs.
In this paper, we introduce a novel approach called Large Language Model
Distilling Medication Recommendation (LEADER). We begin by creating appropriate
prompt templates that enable LLMs to suggest medications effectively. However,
the straightforward integration of LLMs into recommender systems leads to an
out-of-corpus issue specific to drugs. We handle it by adapting the LLMs with a
novel output layer and a refined tuning loss function. Although LLM-based
models exhibit remarkable capabilities, they are plagued by high computational
costs during inference, which is impractical for the healthcare sector. To
mitigate this, we have developed a feature-level knowledge distillation
technique, which transfers the LLM's proficiency to a more compact model.
Extensive experiments conducted on two real-world datasets, MIMIC-III and
MIMIC-IV, demonstrate that our proposed model not only delivers effective
results but also is efficient. To ease the reproducibility of our experiments,
we release the implementation code online.",2024-02-05,2024,2024-02,medical
"Neural machine translation of clinical procedure codes for medical
  diagnosis and uncertainty quantification","A Clinical Decision Support System (CDSS) is designed to enhance clinician
decision-making by combining system-generated recommendations with medical
expertise. Given the high costs, intensive labor, and time-sensitive nature of
medical treatments, there is a pressing need for efficient decision support,
especially in complex emergency scenarios. In these scenarios, where
information can be limited, an advanced CDSS framework that leverages AI
(artificial intelligence) models to effectively reduce diagnostic uncertainty
has utility. Such an AI-enabled CDSS framework with quantified uncertainty
promises to be practical and beneficial in the demanding context of real-world
medical care. In this study, we introduce the concept of Medical Entropy,
quantifying uncertainties in patient outcomes predicted by neural machine
translation based on the ICD-9 code of procedures. Our experimental results not
only show strong correlations between procedure and diagnosis sequences based
on the simple ICD-9 code but also demonstrate the promising capacity to model
trends of uncertainties during hospitalizations through a data-driven approach.",2024-02-07,2024,2024-02,medical
Using text embedding models as text classifiers with medical data,"The advent of Large Language Models (LLMs) is promising and LLMs have been
applied to numerous fields. However, it is not trivial to implement LLMs in the
medical field, due to the high standards for precision and accuracy. Currently,
the diagnosis of medical ailments must be done by hand, as it is costly to
build a sufficiently broad LLM that can diagnose a wide range of diseases.
Here, we explore the use of vector databases and embedding models as a means of
encoding and classifying text with medical text data without the need to train
a new model altogether. We used various LLMs to generate the medical data, then
encoded the data with a text embedding model and stored it in a vector
database. We hypothesized that higher embedding dimensions coupled with
descriptive data in the vector database would lead to better classifications
and designed a robustness test to test our hypothesis. By using vector
databases and text embedding models to classify a clinician's notes on a
patient presenting with a certain ailment, we showed that these tools can be
successful at classifying medical text data. We found that a higher embedding
dimension did indeed yield better results, however, querying with simple data
in the database was optimal for performance. We have shown in this study the
applicability of text embedding models and vector databases on a small scale,
and our work lays the groundwork for applying these tools on a larger scale.",2024-02-07,2024,2024-02,medical
"Benchmarking Large Language Models on Communicative Medical Coaching: a
  Novel System and Dataset","Traditional applications of natural language processing (NLP) in healthcare
have predominantly focused on patient-centered services, enhancing patient
interactions and care delivery, such as through medical dialogue systems.
However, the potential of NLP to benefit inexperienced doctors, particularly in
areas such as communicative medical coaching, remains largely unexplored. We
introduce ""ChatCoach"", a human-AI cooperative framework designed to assist
medical learners in practicing their communication skills during patient
consultations. ChatCoach (Our data and code are available online:
https://github.com/zerowst/Chatcoach)differentiates itself from conventional
dialogue systems by offering a simulated environment where medical learners can
practice dialogues with a patient agent, while a coach agent provides
immediate, structured feedback. This is facilitated by our proposed Generalized
Chain-of-Thought (GCoT) approach, which fosters the generation of structured
feedback and enhances the utilization of external knowledge sources.
Additionally, we have developed a dataset specifically for evaluating Large
Language Models (LLMs) within the ChatCoach framework on communicative medical
coaching tasks. Our empirical results validate the effectiveness of ChatCoach.",2024-02-08,2024,2024-02,medical
"Gemini Goes to Med School: Exploring the Capabilities of Multimodal
  Large Language Models on Medical Challenge Problems & Hallucinations","Large language models have the potential to be valuable in the healthcare
industry, but it's crucial to verify their safety and effectiveness through
rigorous evaluation. For this purpose, we comprehensively evaluated both
open-source LLMs and Google's new multimodal LLM called Gemini across Medical
reasoning, hallucination detection, and Medical Visual Question Answering
tasks. While Gemini showed competence, it lagged behind state-of-the-art models
like MedPaLM 2 and GPT-4 in diagnostic accuracy. Additionally, Gemini achieved
an accuracy of 61.45\% on the medical VQA dataset, significantly lower than
GPT-4V's score of 88\%. Our analysis revealed that Gemini is highly susceptible
to hallucinations, overconfidence, and knowledge gaps, which indicate risks if
deployed uncritically. We also performed a detailed analysis by medical subject
and test type, providing actionable feedback for developers and clinicians. To
mitigate risks, we applied prompting strategies that improved performance.
Additionally, we facilitated future research and development by releasing a
Python module for medical LLM evaluation and establishing a dedicated
leaderboard on Hugging Face for medical domain LLMs. Python module can be found
at https://github.com/promptslab/RosettaEval",2024-02-10,2024,2024-02,medical
"FESS Loss: Feature-Enhanced Spatial Segmentation Loss for Optimizing
  Medical Image Analysis","Medical image segmentation is a critical process in the field of medical
imaging, playing a pivotal role in diagnosis, treatment, and research. It
involves partitioning of an image into multiple regions, representing distinct
anatomical or pathological structures. Conventional methods often grapple with
the challenge of balancing spatial precision and comprehensive feature
representation due to their reliance on traditional loss functions. To overcome
this, we propose Feature-Enhanced Spatial Segmentation Loss (FESS Loss), that
integrates the benefits of contrastive learning (which extracts intricate
features, particularly in the nuanced domain of medical imaging) with the
spatial accuracy inherent in the Dice loss. The objective is to augment both
spatial precision and feature-based representation in the segmentation of
medical images. FESS Loss signifies a notable advancement, offering a more
accurate and refined segmentation process, ultimately contributing to
heightened precision in the analysis of medical images. Further, FESS loss
demonstrates superior performance in limited annotated data availability
scenarios often present in the medical domain.",2024-02-13,2024,2024-02,medical
"BioMistral: A Collection of Open-Source Pretrained Large Language Models
  for Medical Domains","Large Language Models (LLMs) have demonstrated remarkable versatility in
recent years, offering potential applications across specialized domains such
as healthcare and medicine. Despite the availability of various open-source
LLMs tailored for health contexts, adapting general-purpose LLMs to the medical
domain presents significant challenges. In this paper, we introduce BioMistral,
an open-source LLM tailored for the biomedical domain, utilizing Mistral as its
foundation model and further pre-trained on PubMed Central. We conduct a
comprehensive evaluation of BioMistral on a benchmark comprising 10 established
medical question-answering (QA) tasks in English. We also explore lightweight
models obtained through quantization and model merging approaches. Our results
demonstrate BioMistral's superior performance compared to existing open-source
medical models and its competitive edge against proprietary counterparts.
Finally, to address the limited availability of data beyond English and to
assess the multilingual generalization of medical LLMs, we automatically
translated and evaluated this benchmark into 7 other languages. This marks the
first large-scale multilingual evaluation of LLMs in the medical domain.
Datasets, multilingual evaluation benchmarks, scripts, and all the models
obtained during our experiments are freely released.",2024-02-15,2024,2024-02,medical
"LLMs in the Heart of Differential Testing: A Case Study on a Medical
  Rule Engine","The Cancer Registry of Norway (CRN) uses an automated cancer registration
support system (CaReSS) to support core cancer registry activities, i.e, data
capture, data curation, and producing data products and statistics for various
stakeholders. GURI is a core component of CaReSS, which is responsible for
validating incoming data with medical rules. Such medical rules are manually
implemented by medical experts based on medical standards, regulations, and
research. Since large language models (LLMs) have been trained on a large
amount of public information, including these documents, they can be employed
to generate tests for GURI. Thus, we propose an LLM-based test generation and
differential testing approach (LLMeDiff) to test GURI. We experimented with
four different LLMs, two medical rule engine implementations, and 58 real
medical rules to investigate the hallucination, success, time efficiency, and
robustness of the LLMs to generate tests, and these tests' ability to find
potential issues in GURI. Our results showed that GPT-3.5 hallucinates the
least, is the most successful, and is generally the most robust; however, it
has the worst time efficiency. Our differential testing revealed 22 medical
rules where implementation inconsistencies were discovered (e.g., regarding
handling rule versions). Finally, we provide insights for practitioners and
researchers based on the results.",2024-02-16,2024,2024-02,medical
Benchmarking Retrieval-Augmented Generation for Medicine,"While large language models (LLMs) have achieved state-of-the-art performance
on a wide range of medical question answering (QA) tasks, they still face
challenges with hallucinations and outdated knowledge. Retrieval-augmented
generation (RAG) is a promising solution and has been widely adopted. However,
a RAG system can involve multiple flexible components, and there is a lack of
best practices regarding the optimal RAG setting for various medical purposes.
To systematically evaluate such systems, we propose the Medical Information
Retrieval-Augmented Generation Evaluation (MIRAGE), a first-of-its-kind
benchmark including 7,663 questions from five medical QA datasets. Using
MIRAGE, we conducted large-scale experiments with over 1.8 trillion prompt
tokens on 41 combinations of different corpora, retrievers, and backbone LLMs
through the MedRAG toolkit introduced in this work. Overall, MedRAG improves
the accuracy of six different LLMs by up to 18% over chain-of-thought
prompting, elevating the performance of GPT-3.5 and Mixtral to GPT-4-level. Our
results show that the combination of various medical corpora and retrievers
achieves the best performance. In addition, we discovered a log-linear scaling
property and the ""lost-in-the-middle"" effects in medical RAG. We believe our
comprehensive evaluations can serve as practical guidelines for implementing
RAG systems for medicine.",2024-02-20,2024,2024-02,medical
"From Cloud to Edge: Rethinking Generative AI for Low-Resource Design
  Challenges","Generative Artificial Intelligence (AI) has shown tremendous prospects in all
aspects of technology, including design. However, due to its heavy demand on
resources, it is usually trained on large computing infrastructure and often
made available as a cloud-based service. In this position paper, we consider
the potential, challenges, and promising approaches for generative AI for
design on the edge, i.e., in resource-constrained settings where memory,
compute, energy (battery) and network connectivity may be limited. Adapting
generative AI for such settings involves overcoming significant hurdles,
primarily in how to streamline complex models to function efficiently in
low-resource environments. This necessitates innovative approaches in model
compression, efficient algorithmic design, and perhaps even leveraging edge
computing. The objective is to harness the power of generative AI in creating
bespoke solutions for design problems, such as medical interventions, farm
equipment maintenance, and educational material design, tailored to the unique
constraints and needs of remote areas. These efforts could democratize access
to advanced technology and foster sustainable development, ensuring universal
accessibility and environmental consideration of AI-driven design benefits.",2024-02-20,2024,2024-02,medical
"Word-Sequence Entropy: Towards Uncertainty Estimation in Free-Form
  Medical Question Answering Applications and Beyond","Uncertainty estimation is crucial for the reliability of safety-critical
human and artificial intelligence (AI) interaction systems, particularly in the
domain of healthcare engineering. However, a robust and general uncertainty
measure for free-form answers has not been well-established in open-ended
medical question-answering (QA) tasks, where generative inequality introduces a
large number of irrelevant words and sequences within the generated set for
uncertainty quantification (UQ), which can lead to biases. This paper
introduces Word-Sequence Entropy (WSE), a method that calibrates uncertainty at
both the word and sequence levels, considering semantic relevance. WSE
quantifies uncertainty in a way that is more closely aligned with the
reliability of LLMs during uncertainty quantification (UQ). We compare WSE with
six baseline methods on five free-form medical QA datasets, utilizing seven
popular large language models (LLMs). Experimental results demonstrate that WSE
exhibits superior performance in UQ under two standard criteria for correctness
evaluation. Additionally, in terms of real-world medical QA applications, the
performance of LLMs is significantly enhanced (e.g., a 6.36% improvement in
model accuracy on the COVID-QA dataset) by employing responses with lower
uncertainty that are identified by WSE as final answers, without any additional
task-specific fine-tuning or architectural modifications.",2024-02-22,2024,2024-02,medical
"Demographic Bias of Expert-Level Vision-Language Foundation Models in
  Medical Imaging","Advances in artificial intelligence (AI) have achieved expert-level
performance in medical imaging applications. Notably, self-supervised
vision-language foundation models can detect a broad spectrum of pathologies
without relying on explicit training annotations. However, it is crucial to
ensure that these AI models do not mirror or amplify human biases, thereby
disadvantaging historically marginalized groups such as females or Black
patients. The manifestation of such biases could systematically delay essential
medical care for certain patient subgroups. In this study, we investigate the
algorithmic fairness of state-of-the-art vision-language foundation models in
chest X-ray diagnosis across five globally-sourced datasets. Our findings
reveal that compared to board-certified radiologists, these foundation models
consistently underdiagnose marginalized groups, with even higher rates seen in
intersectional subgroups, such as Black female patients. Such demographic
biases present over a wide range of pathologies and demographic attributes.
Further analysis of the model embedding uncovers its significant encoding of
demographic information. Deploying AI systems with these biases in medical
imaging can intensify pre-existing care disparities, posing potential
challenges to equitable healthcare access and raising ethical questions about
their clinical application.",2024-02-22,2024,2024-02,medical
"Adversarial-Robust Transfer Learning for Medical Imaging via Domain
  Assimilation","In the field of Medical Imaging, extensive research has been dedicated to
leveraging its potential in uncovering critical diagnostic features in
patients. Artificial Intelligence (AI)-driven medical diagnosis relies on
sophisticated machine learning and deep learning models to analyze, detect, and
identify diseases from medical images. Despite the remarkable performance of
these models, characterized by high accuracy, they grapple with trustworthiness
issues. The introduction of a subtle perturbation to the original image
empowers adversaries to manipulate the prediction output, redirecting it to
other targeted or untargeted classes. Furthermore, the scarcity of publicly
available medical images, constituting a bottleneck for reliable training, has
led contemporary algorithms to depend on pretrained models grounded on a large
set of natural images -- a practice referred to as transfer learning. However,
a significant {\em domain discrepancy} exists between natural and medical
images, which causes AI models resulting from transfer learning to exhibit
heightened {\em vulnerability} to adversarial attacks. This paper proposes a
{\em domain assimilation} approach that introduces texture and color adaptation
into transfer learning, followed by a texture preservation component to
suppress undesired distortion. We systematically analyze the performance of
transfer learning in the face of various adversarial attacks under different
data modalities, with the overarching goal of fortifying the model's robustness
and security in medical imaging tasks. The results demonstrate high
effectiveness in reducing attack efficacy, contributing toward more trustworthy
transfer learning in biomedical applications.",2024-02-25,2024,2024-02,medical
GigaPevt: Multimodal Medical Assistant,"Building an intelligent and efficient medical assistant is still a
challenging AI problem. The major limitation comes from the data modality
scarceness, which reduces comprehensive patient perception. This demo paper
presents the GigaPevt, the first multimodal medical assistant that combines the
dialog capabilities of large language models with specialized medical models.
Such an approach shows immediate advantages in dialog quality and metric
performance, with a 1.18% accuracy improvement in the question-answering task.",2024-02-26,2024,2024-02,medical
An Overview of the Development of Stereotactic Body Radiation Therapy,"Stereotactic body radiation therapy (SBRT) refers to focusing high-energy
rays in three-dimensional space on the tumor lesion area, reducing the dose
received by surrounding normal tissues, which can effectively improve the local
control rate of the tumor and reduce the probability of complications. With the
comprehensive development of medical imaging, radiation biology and other
disciplines, this less-fractional, high-dose radiotherapy method has been
increasingly developed and applied in clinical practice. The background,
radio-biological basis, key technologies and main equipment of SBRT are
discussed, and its future development direction is prospected.",2024-02-26,2024,2024-02,medical
ICE-SEARCH: A Language Model-Driven Feature Selection Approach,"This study unveils the In-Context Evolutionary Search (ICE-SEARCH) method,
which is among the first works that melds large language models (LLMs) with
evolutionary algorithms for feature selection (FS) tasks and demonstrates its
effectiveness in Medical Predictive Analytics (MPA) applications. ICE-SEARCH
harnesses the crossover and mutation capabilities inherent in LLMs within an
evolutionary framework, significantly improving FS through the model's
comprehensive world knowledge and its adaptability to a variety of roles. Our
evaluation of this methodology spans three crucial MPA tasks: stroke,
cardiovascular disease, and diabetes, where ICE-SEARCH outperforms traditional
FS methods in pinpointing essential features for medical applications.
ICE-SEARCH achieves State-of-the-Art (SOTA) performance in stroke prediction
and diabetes prediction; the Decision-Randomized ICE-SEARCH ranks as SOTA in
cardiovascular disease prediction. The study emphasizes the critical role of
incorporating domain-specific insights, illustrating ICE-SEARCH's robustness,
generalizability, and convergence. This opens avenues for further research into
comprehensive and intricate FS landscapes, marking a significant stride in the
application of artificial intelligence in medical predictive analytics.",2024-02-28,2024,2024-02,medical
"MedAide: Leveraging Large Language Models for On-Premise Medical
  Assistance on Edge Devices","Large language models (LLMs) are revolutionizing various domains with their
remarkable natural language processing (NLP) abilities. However, deploying LLMs
in resource-constrained edge computing and embedded systems presents
significant challenges. Another challenge lies in delivering medical assistance
in remote areas with limited healthcare facilities and infrastructure. To
address this, we introduce MedAide, an on-premise healthcare chatbot. It
leverages tiny-LLMs integrated with LangChain, providing efficient edge-based
preliminary medical diagnostics and support. MedAide employs model
optimizations for minimal memory footprint and latency on embedded edge devices
without server infrastructure. The training process is optimized using low-rank
adaptation (LoRA). Additionally, the model is trained on diverse medical
datasets, employing reinforcement learning from human feedback (RLHF) to
enhance its domain-specific capabilities. The system is implemented on various
consumer GPUs and Nvidia Jetson development board. MedAide achieves 77\%
accuracy in medical consultations and scores 56 in USMLE benchmark, enabling an
energy-efficient healthcare assistance platform that alleviates privacy
concerns due to edge-based deployment, thereby empowering the community.",2024-02-28,2024,2024-02,medical
"OpenMedLM: Prompt engineering can out-perform fine-tuning in medical
  question-answering with open-source large language models","LLMs have become increasingly capable at accomplishing a range of
specialized-tasks and can be utilized to expand equitable access to medical
knowledge. Most medical LLMs have involved extensive fine-tuning, leveraging
specialized medical data and significant, thus costly, amounts of computational
power. Many of the top performing LLMs are proprietary and their access is
limited to very few research groups. However, open-source (OS) models represent
a key area of growth for medical LLMs due to significant improvements in
performance and an inherent ability to provide the transparency and compliance
required in healthcare. We present OpenMedLM, a prompting platform which
delivers state-of-the-art (SOTA) performance for OS LLMs on medical benchmarks.
We evaluated a range of OS foundation LLMs (7B-70B) on four medical benchmarks
(MedQA, MedMCQA, PubMedQA, MMLU medical-subset). We employed a series of
prompting strategies, including zero-shot, few-shot, chain-of-thought (random
selection and kNN selection), and ensemble/self-consistency voting. We found
that OpenMedLM delivers OS SOTA results on three common medical LLM benchmarks,
surpassing the previous best performing OS models that leveraged
computationally costly extensive fine-tuning. The model delivers a 72.6%
accuracy on the MedQA benchmark, outperforming the previous SOTA by 2.4%, and
achieves 81.7% accuracy on the MMLU medical-subset, establishing itself as the
first OS LLM to surpass 80% accuracy on this benchmark. Our results highlight
medical-specific emergent properties in OS LLMs which have not yet been
documented to date elsewhere, and showcase the benefits of further leveraging
prompt engineering to improve the performance of accessible LLMs for medical
applications.",2024-02-29,2024,2024-02,medical
EyeGPT: Ophthalmic Assistant with Large Language Models,"Artificial intelligence (AI) has gained significant attention in healthcare
consultation due to its potential to improve clinical workflow and enhance
medical communication. However, owing to the complex nature of medical
information, large language models (LLM) trained with general world knowledge
might not possess the capability to tackle medical-related tasks at an expert
level. Here, we introduce EyeGPT, a specialized LLM designed specifically for
ophthalmology, using three optimization strategies including role-playing,
finetuning, and retrieval-augmented generation. In particular, we proposed a
comprehensive evaluation framework that encompasses a diverse dataset, covering
various subspecialties of ophthalmology, different users, and diverse inquiry
intents. Moreover, we considered multiple evaluation metrics, including
accuracy, understandability, trustworthiness, empathy, and the proportion of
hallucinations. By assessing the performance of different EyeGPT variants, we
identify the most effective one, which exhibits comparable levels of
understandability, trustworthiness, and empathy to human ophthalmologists (all
Ps>0.05). Overall, ur study provides valuable insights for future research,
facilitating comprehensive comparisons and evaluations of different strategies
for developing specialized LLMs in ophthalmology. The potential benefits
include enhancing the patient experience in eye care and optimizing
ophthalmologists' services.",2024-02-29,2024,2024-02,medical
"CIDGMed: Causal Inference-Driven Medication Recommendation with Enhanced
  Dual-Granularity Learning","Medication recommendation aims to integrate patients' long-term health
records to provide accurate and safe medication combinations for specific
health states. Existing methods often fail to deeply explore the true causal
relationships between diseases/procedures and medications, resulting in biased
recommendations. Additionally, in medication representation learning, the
relationships between information at different granularities of medications,
coarse-grained (medication itself) and fine-grained (molecular level), are not
effectively integrated, leading to biases in representation learning. To
address these limitations, we propose the Causal Inference-driven
Dual-Granularity Medication Recommendation method (CIDGMed). Our approach
leverages causal inference to uncover the relationships between
diseases/procedures and medications, thereby enhancing the rationality and
interpretability of recommendations. By integrating coarse-grained medication
effects with fine-grained molecular structure information, CIDGMed provides a
comprehensive representation of medications. Additionally, we employ a bias
correction model during the prediction phase to further refine recommendations,
ensuring both accuracy and safety. Through extensive experiments, CIDGMed
significantly outperforms current state-of-the-art models across multiple
metrics, achieving a 2.54% increase in accuracy, a 3.65% reduction in side
effects, and a 39.42% improvement in time efficiency. Additionally, we
demonstrate the rationale of CIDGMed through a case study.",2024-03-01,2024,2024-03,medical
"AutoRD: An Automatic and End-to-End System for Rare Disease Knowledge
  Graph Construction Based on Ontologies-enhanced Large Language Models","Rare diseases affect millions worldwide but often face limited research focus
due to their low prevalence. This results in prolonged diagnoses and a lack of
approved therapies. Recent advancements in Large Language Models (LLMs) have
shown promise in automating the extraction of medical information, offering
potential to improve medical diagnosis and management. However, most LLMs lack
professional medical knowledge, especially concerning rare diseases, and
struggle to handle the latest rare disease information. They also cannot
effectively manage rare disease data and are not directly suitable for
diagnosis and management tasks. Our objective is to create an end-to-end system
called AutoRD, which automates the extraction of information from medical texts
about rare diseases, focusing on entities and their relations. AutoRD
integrates up-to-date structured knowledge and demonstrates superior
performance in rare disease extraction tasks. We conduct various experiments to
evaluate AutoRD's performance, aiming to surpass common LLMs and traditional
methods.",2024-03-01,2024,2024-03,medical
"MedSafetyBench: Evaluating and Improving the Medical Safety of Large
  Language Models","As large language models (LLMs) develop increasingly sophisticated
capabilities and find applications in medical settings, it becomes important to
assess their medical safety due to their far-reaching implications for personal
and public health, patient safety, and human rights. However, there is little
to no understanding of the notion of medical safety in the context of LLMs, let
alone how to evaluate and improve it. To address this gap, we first define the
notion of medical safety in LLMs based on the Principles of Medical Ethics set
forth by the American Medical Association. We then leverage this understanding
to introduce MedSafetyBench, the first benchmark dataset designed to measure
the medical safety of LLMs. We demonstrate the utility of MedSafetyBench by
using it to evaluate and improve the medical safety of LLMs. Our results show
that publicly-available medical LLMs do not meet standards of medical safety
and that fine-tuning them using MedSafetyBench improves their medical safety
while preserving their medical performance. By introducing this new benchmark
dataset, our work enables a systematic study of the state of medical safety in
LLMs and motivates future work in this area, paving the way to mitigate the
safety risks of LLMs in medicine. The benchmark dataset and code are available
at https://github.com/AI4LIFE-GROUP/med-safety-bench.",2024-03-06,2024,2024-03,medical
"Apollo: A Lightweight Multilingual Medical LLM towards Democratizing
  Medical AI to 6B People","Despite the vast repository of global medical knowledge predominantly being
in English, local languages are crucial for delivering tailored healthcare
services, particularly in areas with limited medical resources. To extend the
reach of medical AI advancements to a broader population, we aim to develop
medical LLMs across the six most widely spoken languages, encompassing a global
population of 6.1 billion. This effort culminates in the creation of the
ApolloCorpora multilingual medical dataset and the XMedBench benchmark. In the
multilingual medical benchmark, the released Apollo models, at various
relatively-small sizes (i.e., 0.5B, 1.8B, 2B, 6B, and 7B), achieve the best
performance among models of equivalent size. Especially, Apollo-7B is the
state-of-the-art multilingual medical LLMs up to 70B. Additionally, these lite
models could be used to improve the multi-lingual medical capabilities of
larger models without fine-tuning in a proxy-tuning fashion. We will
open-source training corpora, code, model weights and evaluation benchmark.",2024-03-06,2024,2024-03,medical
"An Explainable AI Framework for Artificial Intelligence of Medical
  Things","The healthcare industry has been revolutionized by the convergence of
Artificial Intelligence of Medical Things (AIoMT), allowing advanced
data-driven solutions to improve healthcare systems. With the increasing
complexity of Artificial Intelligence (AI) models, the need for Explainable
Artificial Intelligence (XAI) techniques become paramount, particularly in the
medical domain, where transparent and interpretable decision-making becomes
crucial. Therefore, in this work, we leverage a custom XAI framework,
incorporating techniques such as Local Interpretable Model-Agnostic
Explanations (LIME), SHapley Additive exPlanations (SHAP), and
Gradient-weighted Class Activation Mapping (Grad-Cam), explicitly designed for
the domain of AIoMT. The proposed framework enhances the effectiveness of
strategic healthcare methods and aims to instill trust and promote
understanding in AI-driven medical applications. Moreover, we utilize a
majority voting technique that aggregates predictions from multiple
convolutional neural networks (CNNs) and leverages their collective
intelligence to make robust and accurate decisions in the healthcare system.
Building upon this decision-making process, we apply the XAI framework to brain
tumor detection as a use case demonstrating accurate and transparent diagnosis.
Evaluation results underscore the exceptional performance of the XAI framework,
achieving high precision, recall, and F1 scores with a training accuracy of 99%
and a validation accuracy of 98%. Combining advanced XAI techniques with
ensemble-based deep-learning (DL) methodologies allows for precise and reliable
brain tumor diagnoses as an application of AIoMT.",2024-03-07,2024,2024-03,medical
Medical Speech Symptoms Classification via Disentangled Representation,"Intent is defined for understanding spoken language in existing works. Both
textual features and acoustic features involved in medical speech contain
intent, which is important for symptomatic diagnosis. In this paper, we propose
a medical speech classification model named DRSC that automatically learns to
disentangle intent and content representations from textual-acoustic data for
classification. The intent representations of the text domain and the
Mel-spectrogram domain are extracted via intent encoders, and then the
reconstructed text feature and the Mel-spectrogram feature are obtained through
two exchanges. After combining the intent from two domains into a joint
representation, the integrated intent representation is fed into a decision
layer for classification. Experimental results show that our model obtains an
average accuracy rate of 95% in detecting 25 different medical symptoms.",2024-03-08,2024,2024-03,medical
"All-in-one platform for AI R&D in medical imaging, encompassing data
  collection, selection, annotation, and pre-processing","Deep Learning is advancing medical imaging Research and Development (R&D),
leading to the frequent clinical use of Artificial Intelligence/Machine
Learning (AI/ML)-based medical devices. However, to advance AI R&D, two
challenges arise: 1) significant data imbalance, with most data from
Europe/America and under 10% from Asia, despite its 60% global population
share; and 2) hefty time and investment needed to curate proprietary datasets
for commercial use. In response, we established the first commercial medical
imaging platform, encompassing steps like: 1) data collection, 2) data
selection, 3) annotation, and 4) pre-processing. Moreover, we focus on
harnessing under-represented data from Japan and broader Asia, including
Computed Tomography, Magnetic Resonance Imaging, and Whole Slide Imaging scans.
Using the collected data, we are preparing/providing ready-to-use datasets for
medical AI R&D by 1) offering these datasets to AI firms, biopharma, and
medical device makers and 2) using them as training/test data to develop
tailored AI solutions for such entities. We also aim to merge Blockchain for
data security and plan to synthesize rare disease data via generative AI.
DataHub Website: https://medical-datahub.ai/",2024-03-10,2024,2024-03,medical
"MedKP: Medical Dialogue with Knowledge Enhancement and Clinical Pathway
  Encoding","With appropriate data selection and training techniques, Large Language
Models (LLMs) have demonstrated exceptional success in various medical
examinations and multiple-choice questions. However, the application of LLMs in
medical dialogue generation-a task more closely aligned with actual medical
practice-has been less explored. This gap is attributed to the insufficient
medical knowledge of LLMs, which leads to inaccuracies and hallucinated
information in the generated medical responses. In this work, we introduce the
Medical dialogue with Knowledge enhancement and clinical Pathway encoding
(MedKP) framework, which integrates an external knowledge enhancement module
through a medical knowledge graph and an internal clinical pathway encoding via
medical entities and physician actions. Evaluated with comprehensive metrics,
our experiments on two large-scale, real-world online medical consultation
datasets (MedDG and KaMed) demonstrate that MedKP surpasses multiple baselines
and mitigates the incidence of hallucinations, achieving a new
state-of-the-art. Extensive ablation studies further reveal the effectiveness
of each component of MedKP. This enhancement advances the development of
reliable, automated medical consultation responses using LLMs, thereby
broadening the potential accessibility of precise and real-time medical
assistance.",2024-03-11,2024,2024-03,medical
"Medical Image Synthesis via Fine-Grained Image-Text Alignment and
  Anatomy-Pathology Prompting","Data scarcity and privacy concerns limit the availability of high-quality
medical images for public use, which can be mitigated through medical image
synthesis. However, current medical image synthesis methods often struggle to
accurately capture the complexity of detailed anatomical structures and
pathological conditions. To address these challenges, we propose a novel
medical image synthesis model that leverages fine-grained image-text alignment
and anatomy-pathology prompts to generate highly detailed and accurate
synthetic medical images. Our method integrates advanced natural language
processing techniques with image generative modeling, enabling precise
alignment between descriptive text prompts and the synthesized images'
anatomical and pathological details. The proposed approach consists of two key
components: an anatomy-pathology prompting module and a fine-grained
alignment-based synthesis module. The anatomy-pathology prompting module
automatically generates descriptive prompts for high-quality medical images. To
further synthesize high-quality medical images from the generated prompts, the
fine-grained alignment-based synthesis module pre-defines a visual codebook for
the radiology dataset and performs fine-grained alignment between the codebook
and generated prompts to obtain key patches as visual clues, facilitating
accurate image synthesis. We validate the superiority of our method through
experiments on public chest X-ray datasets and demonstrate that our synthetic
images preserve accurate semantic information, making them valuable for various
medical applications.",2024-03-11,2024,2024-03,medical
"When Eye-Tracking Meets Machine Learning: A Systematic Review on
  Applications in Medical Image Analysis","Eye-gaze tracking research offers significant promise in enhancing various
healthcare-related tasks, above all in medical image analysis and
interpretation. Eye tracking, a technology that monitors and records the
movement of the eyes, provides valuable insights into human visual attention
patterns. This technology can transform how healthcare professionals and
medical specialists engage with and analyze diagnostic images, offering a more
insightful and efficient approach to medical diagnostics. Hence, extracting
meaningful features and insights from medical images by leveraging eye-gaze
data improves our understanding of how radiologists and other medical experts
monitor, interpret, and understand images for diagnostic purposes. Eye-tracking
data, with intricate human visual attention patterns embedded, provides a
bridge to integrating artificial intelligence (AI) development and human
cognition. This integration allows novel methods to incorporate domain
knowledge into machine learning (ML) and deep learning (DL) approaches to
enhance their alignment with human-like perception and decision-making.
Moreover, extensive collections of eye-tracking data have also enabled novel
ML/DL methods to analyze human visual patterns, paving the way to a better
understanding of human vision, attention, and cognition. This systematic review
investigates eye-gaze tracking applications and methodologies for enhancing
ML/DL algorithms for medical image analysis in depth.",2024-03-12,2024,2024-03,medical
"Explainable Machine Learning-Based Security and Privacy Protection
  Framework for Internet of Medical Things Systems","The Internet of Medical Things (IoMT) transcends traditional medical
boundaries, enabling a transition from reactive treatment to proactive
prevention. This innovative method revolutionizes healthcare by facilitating
early disease detection and tailored care, particularly in chronic disease
management, where IoMT automates treatments based on real-time health data
collection. Nonetheless, its benefits are countered by significant security
challenges that endanger the lives of its users due to the sensitivity and
value of the processed data, thereby attracting malicious interests. Moreover,
the utilization of wireless communication for data transmission exposes medical
data to interception and tampering by cybercriminals. Additionally, anomalies
may arise due to human error, network interference, or hardware malfunctions.
In this context, anomaly detection based on Machine Learning (ML) is an
interesting solution, but it comes up against obstacles in terms of
explicability and privacy protection. To address these challenges, a new
framework for Intrusion Detection Systems is introduced, leveraging Artificial
Neural Networks for intrusion detection while utilizing Federated Learning (FL)
for privacy preservation. Additionally, eXplainable Artificial Intelligence
methods are incorporated to enhance model explanation and interpretation. The
efficacy of the proposed framework is evaluated and compared with centralized
approaches using multiple datasets containing network and medical data,
simulating various attack types impacting the confidentiality, integrity, and
availability of medical and physiological data. The results obtained offer
compelling evidence that the FL method performs comparably to the centralized
method, demonstrating high performance. Additionally, it affords the dual
advantage of safeguarding privacy and providing model explanation while
adhering to ethical principles.",2024-03-14,2024,2024-03,medical
"A Continued Pretrained LLM Approach for Automatic Medical Note
  Generation","LLMs are revolutionizing NLP tasks. However, the use of the most advanced
LLMs, such as GPT-4, is often prohibitively expensive for most specialized
fields. We introduce HEAL, the first continuously trained 13B LLaMA2-based LLM
that is purpose-built for medical conversations and measured on automated
scribing. Our results demonstrate that HEAL outperforms GPT-4 and PMC-LLaMA in
PubMedQA, with an accuracy of 78.4\%. It also achieves parity with GPT-4 in
generating medical notes. Remarkably, HEAL surpasses GPT-4 and Med-PaLM 2 in
identifying more correct medical concepts and exceeds the performance of human
scribes and other comparable models in correctness and completeness.",2024-03-14,2024,2024-03,medical
"Emotional Intelligence Through Artificial Intelligence : NLP and Deep
  Learning in the Analysis of Healthcare Texts","This manuscript presents a methodical examination of the utilization of
Artificial Intelligence in the assessment of emotions in texts related to
healthcare, with a particular focus on the incorporation of Natural Language
Processing and deep learning technologies. We scrutinize numerous research
studies that employ AI to augment sentiment analysis, categorize emotions, and
forecast patient outcomes based on textual information derived from clinical
narratives, patient feedback on medications, and online health discussions. The
review demonstrates noteworthy progress in the precision of algorithms used for
sentiment classification, the prognostic capabilities of AI models for
neurodegenerative diseases, and the creation of AI-powered systems that offer
support in clinical decision-making. Remarkably, the utilization of AI
applications has exhibited an enhancement in personalized therapy plans by
integrating patient sentiment and contributing to the early identification of
mental health disorders. There persist challenges, which encompass ensuring the
ethical application of AI, safeguarding patient confidentiality, and addressing
potential biases in algorithmic procedures. Nevertheless, the potential of AI
to revolutionize healthcare practices is unmistakable, offering a future where
healthcare is not only more knowledgeable and efficient but also more
empathetic and centered around the needs of patients. This investigation
underscores the transformative influence of AI on healthcare, delivering a
comprehensive comprehension of its role in examining emotional content in
healthcare texts and highlighting the trajectory towards a more compassionate
approach to patient care. The findings advocate for a harmonious synergy
between AI's analytical capabilities and the human aspects of healthcare.",2024-03-14,2024,2024-03,medical
"VisionCLIP: An Med-AIGC based Ethical Language-Image Foundation Model
  for Generalizable Retina Image Analysis","Generalist foundation model has ushered in newfound capabilities in medical
domain. However, the contradiction between the growing demand for high-quality
annotated data with patient privacy continues to intensify. The utilization of
medical artificial intelligence generated content (Med-AIGC) as an
inexhaustible resource repository arises as a potential solution to address the
aforementioned challenge. Here we harness 1 million open-source synthetic
fundus images paired with natural language descriptions, to curate an ethical
language-image foundation model for retina image analysis named VisionCLIP.
VisionCLIP achieves competitive performance on three external datasets compared
with the existing method pre-trained on real-world data in a zero-shot fashion.
The employment of artificially synthetic images alongside corresponding textual
data for training enables the medical foundation model to successfully
assimilate knowledge of disease symptomatology, thereby circumventing potential
breaches of patient confidentiality.",2024-03-16,2024,2024-03,medical
"Machine Learning and Transformers for Thyroid Carcinoma Diagnosis: A
  Review","The growing interest in developing smart diagnostic systems to help medical
experts process extensive data for treating incurable diseases has been
notable. In particular, the challenge of identifying thyroid cancer (TC) has
seen progress with the use of machine learning (ML) and big data analysis,
incorporating Transformers to evaluate TC prognosis and determine the risk of
malignancy in individuals. This review article presents a summary of various
studies on AI-based approaches, especially those employing Transformers, for
diagnosing TC. It introduces a new categorization system for these methods
based on artificial intelligence (AI) algorithms, the goals of the framework,
and the computing environments used. Additionally, it scrutinizes and contrasts
the available TC datasets by their features. The paper highlights the
importance of AI instruments in aiding the diagnosis and treatment of TC
through supervised, unsupervised, or mixed approaches, with a special focus on
the ongoing importance of Transformers and large language models (LLMs) in
medical diagnostics and disease management. It further discusses the progress
made and the continuing obstacles in this area. Lastly, it explores future
directions and focuses within this research field.",2024-03-17,2024,2024-03,medical
"Deep learning with noisy labels in medical prediction problems: a
  scoping review","Objectives: Medical research faces substantial challenges from noisy labels
attributed to factors like inter-expert variability and machine-extracted
labels. Despite this, the adoption of label noise management remains limited,
and label noise is largely ignored. To this end, there is a critical need to
conduct a scoping review focusing on the problem space. This scoping review
aims to comprehensively review label noise management in deep learning-based
medical prediction problems, which includes label noise detection, label noise
handling, and evaluation. Research involving label uncertainty is also
included.
  Methods: Our scoping review follows the Preferred Reporting Items for
Systematic Reviews and Meta-Analyses (PRISMA) guidelines. We searched 4
databases, including PubMed, IEEE Xplore, Google Scholar, and Semantic Scholar.
Our search terms include ""noisy label AND medical / healthcare / clinical"",
""un-certainty AND medical / healthcare / clinical"", and ""noise AND medical /
healthcare / clinical"".
  Results: A total of 60 papers met inclusion criteria between 2016 and 2023. A
series of practical questions in medical research are investigated. These
include the sources of label noise, the impact of label noise, the detection of
label noise, label noise handling techniques, and their evaluation.
Categorization of both label noise detection methods and handling techniques
are provided.
  Discussion: From a methodological perspective, we observe that the medical
community has been up to date with the broader deep-learning community, given
that most techniques have been evaluated on medical data. We recommend
considering label noise as a standard element in medical research, even if it
is not dedicated to handling noisy labels. Initial experiments can start with
easy-to-implement methods, such as noise-robust loss functions, weighting, and
curriculum learning.",2024-03-19,2024,2024-03,medical
"Large Language Models for Multi-Choice Question Classification of
  Medical Subjects","The aim of this paper is to evaluate whether large language models trained on
multi-choice question data can be used to discriminate between medical
subjects. This is an important and challenging task for automatic question
answering. To achieve this goal, we train deep neural networks for multi-class
classification of questions into the inferred medical subjects. Using our
Multi-Question (MQ) Sequence-BERT method, we outperform the state-of-the-art
results on the MedMCQA dataset with an accuracy of 0.68 and 0.60 on their
development and test sets, respectively. In this sense, we show the capability
of AI and LLMs in particular for multi-classification tasks in the Healthcare
domain.",2024-03-21,2024,2024-03,medical
"Dermacen Analytica: A Novel Methodology Integrating Multi-Modal Large
  Language Models with Machine Learning in tele-dermatology","The rise of Artificial Intelligence creates great promise in the field of
medical discovery, diagnostics and patient management. However, the vast
complexity of all medical domains require a more complex approach that combines
machine learning algorithms, classifiers, segmentation algorithms and, lately,
large language models. In this paper, we describe, implement and assess an
Artificial Intelligence-empowered system and methodology aimed at assisting the
diagnosis process of skin lesions and other skin conditions within the field of
dermatology that aims to holistically address the diagnostic process in this
domain. The workflow integrates large language, transformer-based vision models
and sophisticated machine learning tools. This holistic approach achieves a
nuanced interpretation of dermatological conditions that simulates and
facilitates a dermatologist's workflow. We assess our proposed methodology
through a thorough cross-model validation technique embedded in an evaluation
pipeline that utilizes publicly available medical case studies of skin
conditions and relevant images. To quantitatively score the system performance,
advanced machine learning and natural language processing tools are employed
which focus on similarity comparison and natural language inference.
Additionally, we incorporate a human expert evaluation process based on a
structured checklist to further validate our results. We implemented the
proposed methodology in a system which achieved approximate (weighted) scores
of 0.87 for both contextual understanding and diagnostic accuracy,
demonstrating the efficacy of our approach in enhancing dermatological
analysis. The proposed methodology is expected to prove useful in the
development of next-generation tele-dermatology applications, enhancing remote
consultation capabilities and access to care, especially in underserved areas.",2024-03-21,2024,2024-03,medical
"Practical Applications of Advanced Cloud Services and Generative AI
  Systems in Medical Image Analysis","The medical field is one of the important fields in the application of
artificial intelligence technology. With the explosive growth and
diversification of medical data, as well as the continuous improvement of
medical needs and challenges, artificial intelligence technology is playing an
increasingly important role in the medical field. Artificial intelligence
technologies represented by computer vision, natural language processing, and
machine learning have been widely penetrated into diverse scenarios such as
medical imaging, health management, medical information, and drug research and
development, and have become an important driving force for improving the level
and quality of medical services.The article explores the transformative
potential of generative AI in medical imaging, emphasizing its ability to
generate syntheticACM-2 data, enhance images, aid in anomaly detection, and
facilitate image-to-image translation. Despite challenges like model
complexity, the applications of generative models in healthcare, including
Med-PaLM 2 technology, show promising results. By addressing limitations in
dataset size and diversity, these models contribute to more accurate diagnoses
and improved patient outcomes. However, ethical considerations and
collaboration among stakeholders are essential for responsible implementation.
Through experiments leveraging GANs to augment brain tumor MRI datasets, the
study demonstrates how generative AI can enhance image quality and diversity,
ultimately advancing medical diagnostics and patient care.",2024-03-26,2024,2024-03,medical
"Medical Visual Prompting (MVP): A Unified Framework for Versatile and
  High-Quality Medical Image Segmentation","Accurate segmentation of lesion regions is crucial for clinical diagnosis and
treatment across various diseases. While deep convolutional networks have
achieved satisfactory results in medical image segmentation, they face
challenges such as loss of lesion shape information due to continuous
convolution and downsampling, as well as the high cost of manually labeling
lesions with varying shapes and sizes. To address these issues, we propose a
novel medical visual prompting (MVP) framework that leverages pre-training and
prompting concepts from natural language processing (NLP). The framework
utilizes three key components: Super-Pixel Guided Prompting (SPGP) for
superpixelating the input image, Image Embedding Guided Prompting (IEGP) for
freezing patch embedding and merging with superpixels to provide visual
prompts, and Adaptive Attention Mechanism Guided Prompting (AAGP) for
pinpointing prompt content and efficiently adapting all layers. By integrating
SPGP, IEGP, and AAGP, the MVP enables the segmentation network to better learn
shape prompting information and facilitates mutual learning across different
tasks. Extensive experiments conducted on five datasets demonstrate superior
performance of this method in various challenging medical image tasks, while
simplifying single-task medical segmentation models. This novel framework
offers improved performance with fewer parameters and holds significant
potential for accurate segmentation of lesion regions in various medical tasks,
making it clinically valuable.",2024-04-01,2024,2024-04,medical
"Data-Efficient Unsupervised Interpolation Without Any Intermediate Frame
  for 4D Medical Images","4D medical images, which represent 3D images with temporal information, are
crucial in clinical practice for capturing dynamic changes and monitoring
long-term disease progression. However, acquiring 4D medical images poses
challenges due to factors such as radiation exposure and imaging duration,
necessitating a balance between achieving high temporal resolution and
minimizing adverse effects. Given these circumstances, not only is data
acquisition challenging, but increasing the frame rate for each dataset also
proves difficult. To address this challenge, this paper proposes a simple yet
effective Unsupervised Volumetric Interpolation framework, UVI-Net. This
framework facilitates temporal interpolation without the need for any
intermediate frames, distinguishing it from the majority of other existing
unsupervised methods. Experiments on benchmark datasets demonstrate significant
improvements across diverse evaluation metrics compared to unsupervised and
supervised baselines. Remarkably, our approach achieves this superior
performance even when trained with a dataset as small as one, highlighting its
exceptional robustness and efficiency in scenarios with sparse supervision.
This positions UVI-Net as a compelling alternative for 4D medical imaging,
particularly in settings where data availability is limited. The source code is
available at https://github.com/jungeun122333/UVI-Net.",2024-04-01,2024,2024-04,medical
"Non-negative Subspace Feature Representation for Few-shot Learning in
  Medical Imaging","Unlike typical visual scene recognition domains, in which massive datasets
are accessible to deep neural networks, medical image interpretations are often
obstructed by the paucity of data. In this paper, we investigate the
effectiveness of data-based few-shot learning in medical imaging by exploring
different data attribute representations in a low-dimensional space. We
introduce different types of non-negative matrix factorization (NMF) in
few-shot learning, addressing the data scarcity issue in medical image
classification. Extensive empirical studies are conducted in terms of
validating the effectiveness of NMF, especially its supervised variants (e.g.,
discriminative NMF, and supervised and constrained NMF with sparseness), and
the comparison with principal component analysis (PCA), i.e., the collaborative
representation-based dimensionality reduction technique derived from
eigenvectors. With 14 different datasets covering 11 distinct illness
categories, thorough experimental results and comparison with related
techniques demonstrate that NMF is a competitive alternative to PCA for
few-shot learning in medical imaging, and the supervised NMF algorithms are
more discriminative in the subspace with greater effectiveness. Furthermore, we
show that the part-based representation of NMF, especially its supervised
variants, is dramatically impactful in detecting lesion areas in medical
imaging with limited samples.",2024-04-03,2024,2024-04,medical
"Investigation of Energy-efficient AI Model Architectures and Compression
  Techniques for ""Green"" Fetal Brain Segmentation","Artificial intelligence have contributed to advancements across various
industries. However, the rapid growth of artificial intelligence technologies
also raises concerns about their environmental impact, due to associated carbon
footprints to train computational models. Fetal brain segmentation in medical
imaging is challenging due to the small size of the fetal brain and the limited
image quality of fast 2D sequences. Deep neural networks are a promising method
to overcome this challenge. In this context, the construction of larger models
requires extensive data and computing power, leading to high energy
consumption. Our study aims to explore model architectures and compression
techniques that promote energy efficiency by optimizing the trade-off between
accuracy and energy consumption through various strategies such as lightweight
network design, architecture search, and optimized distributed training tools.
We have identified several effective strategies including optimization of data
loading, modern optimizers, distributed training strategy implementation, and
reduced floating point operations precision usage with light model
architectures while tuning parameters according to available computer
resources. Our findings demonstrate that these methods lead to satisfactory
model performance with low energy consumption during deep neural network
training for medical image segmentation.",2024-04-03,2024,2024-04,medical
"Conversational Disease Diagnosis via External Planner-Controlled Large
  Language Models","The development of large language models (LLMs) has brought unprecedented
possibilities for artificial intelligence (AI) based medical diagnosis.
However, the application perspective of LLMs in real diagnostic scenarios is
still unclear because they are not adept at collecting patient data
proactively. This study presents a LLM-based diagnostic system that enhances
planning capabilities by emulating doctors. Our system involves two external
planners to handle planning tasks. The first planner employs a reinforcement
learning approach to formulate disease screening questions and conduct initial
diagnoses. The second planner uses LLMs to parse medical guidelines and conduct
differential diagnoses. By utilizing real patient electronic medical record
data, we constructed simulated dialogues between virtual patients and doctors
and evaluated the diagnostic abilities of our system. We demonstrated that our
system obtained impressive performance in both disease screening and
differential diagnoses tasks. This research represents a step towards more
seamlessly integrating AI into clinical settings, potentially enhancing the
accuracy and accessibility of medical diagnostics.",2024-04-04,2024,2024-04,medical
Does Biomedical Training Lead to Better Medical Performance?,"Large Language Models (LLMs) are expected to significantly contribute to
patient care, diagnostics, and administrative processes. Emerging biomedical
LLMs aim to address healthcare-specific challenges, including privacy demands
and computational constraints. Assessing the models' suitability for this
sensitive application area is of the utmost importance. However, biomedical
training has not been systematically evaluated on medical tasks. This study
investigates the effect of biomedical training in the context of six practical
medical tasks evaluating $25$ models. In contrast to previous evaluations, our
results reveal a performance decline in nine out of twelve biomedical models
after fine-tuning, particularly on tasks involving hallucinations, ICD10
coding, and instruction adherence. General-domain models like
Meta-Llama-3.1-70B-Instruct outperformed their biomedical counterparts,
indicating a trade-off between domain-specific fine-tuning and general medical
task performance. We open-source all evaluation scripts and datasets at
https://github.com/TIO-IKIM/CLUE to support further research in this critical
area.",2024-04-05,2024,2024-04,medical
"Autonomous Artificial Intelligence Agents for Clinical Decision Making
  in Oncology","Multimodal artificial intelligence (AI) systems have the potential to enhance
clinical decision-making by interpreting various types of medical data.
However, the effectiveness of these models across all medical fields is
uncertain. Each discipline presents unique challenges that need to be addressed
for optimal performance. This complexity is further increased when attempting
to integrate different fields into a single model. Here, we introduce an
alternative approach to multimodal medical AI that utilizes the generalist
capabilities of a large language model (LLM) as a central reasoning engine.
This engine autonomously coordinates and deploys a set of specialized medical
AI tools. These tools include text, radiology and histopathology image
interpretation, genomic data processing, web searches, and document retrieval
from medical guidelines. We validate our system across a series of clinical
oncology scenarios that closely resemble typical patient care workflows. We
show that the system has a high capability in employing appropriate tools
(97%), drawing correct conclusions (93.6%), and providing complete (94%), and
helpful (89.2%) recommendations for individual patient cases while consistently
referencing relevant literature (82.5%) upon instruction. This work provides
evidence that LLMs can effectively plan and execute domain-specific models to
retrieve or synthesize new information when used as autonomous agents. This
enables them to function as specialist, patient-tailored clinical assistants.
It also simplifies regulatory compliance by allowing each component tool to be
individually validated and approved. We believe, that our work can serve as a
proof-of-concept for more advanced LLM-agents in the medical domain.",2024-04-06,2024,2024-04,medical
"ProtoAL: Interpretable Deep Active Learning with prototypes for medical
  imaging","The adoption of Deep Learning algorithms in the medical imaging field is a
prominent area of research, with high potential for advancing AI-based
Computer-aided diagnosis (AI-CAD) solutions. However, current solutions face
challenges due to a lack of interpretability features and high data demands,
prompting recent efforts to address these issues. In this study, we propose the
ProtoAL method, where we integrate an interpretable DL model into the Deep
Active Learning (DAL) framework. This approach aims to address both challenges
by focusing on the medical imaging context and utilizing an inherently
interpretable model based on prototypes. We evaluated ProtoAL on the Messidor
dataset, achieving an area under the precision-recall curve of 0.79 while
utilizing only 76.54\% of the available labeled data. These capabilities can
enhances the practical usability of a DL model in the medical field, providing
a means of trust calibration in domain experts and a suitable solution for
learning in the data scarcity context often found.",2024-04-06,2024,2024-04,medical
"MedExpQA: Multilingual Benchmarking of Large Language Models for Medical
  Question Answering","Large Language Models (LLMs) have the potential of facilitating the
development of Artificial Intelligence technology to assist medical experts for
interactive decision support, which has been demonstrated by their competitive
performances in Medical QA. However, while impressive, the required quality bar
for medical applications remains far from being achieved. Currently, LLMs
remain challenged by outdated knowledge and by their tendency to generate
hallucinated content. Furthermore, most benchmarks to assess medical knowledge
lack reference gold explanations which means that it is not possible to
evaluate the reasoning of LLMs predictions. Finally, the situation is
particularly grim if we consider benchmarking LLMs for languages other than
English which remains, as far as we know, a totally neglected topic. In order
to address these shortcomings, in this paper we present MedExpQA, the first
multilingual benchmark based on medical exams to evaluate LLMs in Medical
Question Answering. To the best of our knowledge, MedExpQA includes for the
first time reference gold explanations written by medical doctors which can be
leveraged to establish various gold-based upper-bounds for comparison with LLMs
performance. Comprehensive multilingual experimentation using both the gold
reference explanations and Retrieval Augmented Generation (RAG) approaches show
that performance of LLMs still has large room for improvement, especially for
languages other than English. Furthermore, and despite using state-of-the-art
RAG methods, our results also demonstrate the difficulty of obtaining and
integrating readily available medical knowledge that may positively impact
results on downstream evaluations for Medical Question Answering. So far the
benchmark is available in four languages, but we hope that this work may
encourage further development to other languages.",2024-04-08,2024,2024-04,medical
"VietMed: A Dataset and Benchmark for Automatic Speech Recognition of
  Vietnamese in the Medical Domain","Due to privacy restrictions, there's a shortage of publicly available speech
recognition datasets in the medical domain. In this work, we present VietMed -
a Vietnamese speech recognition dataset in the medical domain comprising 16h of
labeled medical speech, 1000h of unlabeled medical speech and 1200h of
unlabeled general-domain speech. To our best knowledge, VietMed is by far the
world's largest public medical speech recognition dataset in 7 aspects: total
duration, number of speakers, diseases, recording conditions, speaker roles,
unique medical terms and accents. VietMed is also by far the largest public
Vietnamese speech dataset in terms of total duration. Additionally, we are the
first to present a medical ASR dataset covering all ICD-10 disease groups and
all accents within a country. Moreover, we release the first public large-scale
pre-trained models for Vietnamese ASR, w2v2-Viet and XLSR-53-Viet, along with
the first public large-scale fine-tuned models for medical ASR. Even without
any medical data in unsupervised pre-training, our best pre-trained model
XLSR-53-Viet generalizes very well to the medical domain by outperforming
state-of-the-art XLSR-53, from 51.8% to 29.6% WER on test set (a relative
reduction of more than 40%). All code, data and models are made publicly
available: https://github.com/leduckhai/MultiMed/tree/master/VietMed.",2024-04-08,2024,2024-04,medical
"Iterative Refinement Strategy for Automated Data Labeling: Facial
  Landmark Diagnosis in Medical Imaging","Automated data labeling techniques are crucial for accelerating the
development of deep learning models, particularly in complex medical imaging
applications. However, ensuring accuracy and efficiency remains challenging.
This paper presents iterative refinement strategies for automated data labeling
in facial landmark diagnosis to enhance accuracy and efficiency for deep
learning models in medical applications, including dermatology, plastic
surgery, and ophthalmology. Leveraging feedback mechanisms and advanced
algorithms, our approach iteratively refines initial labels, reducing reliance
on manual intervention while improving label quality. Through empirical
evaluation and case studies, we demonstrate the effectiveness of our proposed
strategies in deep learning tasks across medical imaging domains. Our results
highlight the importance of iterative refinement in automated data labeling to
enhance the capabilities of deep learning systems in medical imaging
applications.",2024-04-08,2024,2024-04,medical
"Medical mT5: An Open-Source Multilingual Text-to-Text LLM for The
  Medical Domain","Research on language technology for the development of medical applications
is currently a hot topic in Natural Language Understanding and Generation.
Thus, a number of large language models (LLMs) have recently been adapted to
the medical domain, so that they can be used as a tool for mediating in
human-AI interaction. While these LLMs display competitive performance on
automated medical texts benchmarks, they have been pre-trained and evaluated
with a focus on a single language (English mostly). This is particularly true
of text-to-text models, which typically require large amounts of
domain-specific pre-training data, often not easily accessible for many
languages. In this paper, we address these shortcomings by compiling, to the
best of our knowledge, the largest multilingual corpus for the medical domain
in four languages, namely English, French, Italian and Spanish. This new corpus
has been used to train Medical mT5, the first open-source text-to-text
multilingual model for the medical domain. Additionally, we present two new
evaluation benchmarks for all four languages with the aim of facilitating
multilingual research in this domain. A comprehensive evaluation shows that
Medical mT5 outperforms both encoders and similarly sized text-to-text models
for the Spanish, French, and Italian benchmarks, while being competitive with
current state-of-the-art LLMs in English.",2024-04-11,2024,2024-04,medical
"Introducing L2M3, A Multilingual Medical Large Language Model to Advance
  Health Equity in Low-Resource Regions","Addressing the imminent shortfall of 10 million health workers by 2030,
predominantly in Low- and Middle-Income Countries (LMICs), this paper
introduces an innovative approach that harnesses the power of Large Language
Models (LLMs) integrated with machine translation models. This solution is
engineered to meet the unique needs of Community Health Workers (CHWs),
overcoming language barriers, cultural sensitivities, and the limited
availability of medical dialog datasets. I have crafted a model that not only
boasts superior translation capabilities but also undergoes rigorous
fine-tuning on open-source datasets to ensure medical accuracy and is equipped
with comprehensive safety features to counteract the risks of misinformation.
  Featuring a modular design, this approach is specifically structured for
swift adaptation across various linguistic and cultural contexts, utilizing
open-source components to significantly reduce healthcare operational costs.
This strategic innovation markedly improves the accessibility and quality of
healthcare services by providing CHWs with contextually appropriate medical
knowledge and diagnostic tools. This paper highlights the transformative impact
of this context-aware LLM, underscoring its crucial role in addressing the
global healthcare workforce deficit and propelling forward healthcare outcomes
in LMICs.",2024-04-11,2024,2024-04,medical
"Leveraging Large Language Model as Simulated Patients for Clinical
  Education","Simulated Patients (SPs) play a crucial role in clinical medical education by
providing realistic scenarios for student practice. However, the high cost of
training and hiring qualified SPs, along with the heavy workload and potential
risks they face in consistently portraying actual patients, limit students'
access to this type of clinical training. Consequently, the integration of
computer program-based simulated patients has emerged as a valuable educational
tool in recent years. With the rapid development of Large Language Models
(LLMs), their exceptional capabilities in conversational artificial
intelligence and role-playing have been demonstrated, making them a feasible
option for implementing Virtual Simulated Patient (VSP). In this paper, we
present an integrated model-agnostic framework called CureFun that harnesses
the potential of LLMs in clinical medical education. This framework facilitates
natural conversations between students and simulated patients, evaluates their
dialogue, and provides suggestions to enhance students' clinical inquiry
skills. Through comprehensive evaluations, our approach demonstrates more
authentic and professional SP-scenario dialogue flows compared to other
LLM-based chatbots, thus proving its proficiency in simulating patients.
Additionally, leveraging CureFun's evaluation ability, we assess several
medical LLMs and discuss the possibilities and limitations of using LLMs as
virtual doctors from the perspective of their diagnostic abilities.",2024-04-13,2024,2024-04,medical
Ethical Framework for Responsible Foundational Models in Medical Imaging,"Foundational models (FMs) have tremendous potential to revolutionize medical
imaging. However, their deployment in real-world clinical settings demands
extensive ethical considerations. This paper aims to highlight the ethical
concerns related to FMs and propose a framework to guide their responsible
development and implementation within medicine. We meticulously examine ethical
issues such as privacy of patient data, bias mitigation, algorithmic
transparency, explainability and accountability. The proposed framework is
designed to prioritize patient welfare, mitigate potential risks, and foster
trust in AI-assisted healthcare.",2024-04-14,2024,2024-04,medical
A Sentiment Analysis of Medical Text Based on Deep Learning,"The field of natural language processing (NLP) has made significant progress
with the rapid development of deep learning technologies. One of the research
directions in text sentiment analysis is sentiment analysis of medical texts,
which holds great potential for application in clinical diagnosis. However, the
medical field currently lacks sufficient text datasets, and the effectiveness
of sentiment analysis is greatly impacted by different model design approaches,
which presents challenges. Therefore, this paper focuses on the medical domain,
using bidirectional encoder representations from transformers (BERT) as the
basic pre-trained model and experimenting with modules such as convolutional
neural network (CNN), fully connected network (FCN), and graph convolutional
networks (GCN) at the output layer. Experiments and analyses were conducted on
the METS-CoV dataset to explore the training performance after integrating
different deep learning networks. The results indicate that CNN models
outperform other networks when trained on smaller medical text datasets in
combination with pre-trained models like BERT. This study highlights the
significance of model selection in achieving effective sentiment analysis in
the medical domain and provides a reference for future research to develop more
efficient model architectures.",2024-04-16,2024,2024-04,medical
"Integration of Self-Supervised BYOL in Semi-Supervised Medical Image
  Recognition","Image recognition techniques heavily rely on abundant labeled data,
particularly in medical contexts. Addressing the challenges associated with
obtaining labeled data has led to the prominence of self-supervised learning
and semi-supervised learning, especially in scenarios with limited annotated
data. In this paper, we proposed an innovative approach by integrating
self-supervised learning into semi-supervised models to enhance medical image
recognition. Our methodology commences with pre-training on unlabeled data
utilizing the BYOL method. Subsequently, we merge pseudo-labeled and labeled
datasets to construct a neural network classifier, refining it through
iterative fine-tuning. Experimental results on three different datasets
demonstrate that our approach optimally leverages unlabeled data, outperforming
existing methods in terms of accuracy for medical image recognition.",2024-04-16,2024,2024-04,medical
"CausalMed: Causality-Based Personalized Medication Recommendation
  Centered on Patient health state","Medication recommendation systems are developed to recommend suitable
medications tailored to specific patient. Previous researches primarily focus
on learning medication representations, which have yielded notable advances.
However, these methods are limited to capturing personalized patient
representations due to the following primary limitations: (i) unable to capture
the differences in the impact of diseases/procedures on patients across various
patient health states; (ii) fail to model the direct causal relationships
between medications and specific health state of patients, resulting in an
inability to determine which specific disease each medication is treating. To
address these limitations, we propose CausalMed, a patient health state-centric
model capable of enhancing the personalization of patient representations.
Specifically, CausalMed first captures the causal relationship between
diseases/procedures and medications through causal discovery and evaluates
their causal effects. Building upon this, CausalMed focuses on analyzing the
health state of patients, capturing the dynamic differences of
diseases/procedures in different health states of patients, and transforming
diseases/procedures into medications on direct causal relationships.
Ultimately, CausalMed integrates information from longitudinal visits to
recommend medication combinations. Extensive experiments on real-world datasets
show that our method learns more personalized patient representation and
outperforms state-of-the-art models in accuracy and safety.",2024-04-18,2024,2024-04,medical
A Large-scale Medical Visual Task Adaptation Benchmark,"Visual task adaptation has been demonstrated to be effective in adapting
pre-trained Vision Transformers (ViTs) to general downstream visual tasks using
specialized learnable layers or tokens. However, there is yet a large-scale
benchmark to fully explore the effect of visual task adaptation on the
realistic and important medical domain, particularly across diverse medical
visual modalities, such as color images, X-ray, and CT. To close this gap, we
present Med-VTAB, a large-scale Medical Visual Task Adaptation Benchmark
consisting of 1.68 million medical images for diverse organs, modalities, and
adaptation approaches. Based on Med-VTAB, we explore the scaling law of medical
prompt tuning concerning tunable parameters and the generalizability of medical
visual adaptation using non-medical/medical pre-train weights. Besides, we
study the impact of patient ID out-of-distribution on medical visual
adaptation, which is a real and challenging scenario. Furthermore, results from
Med-VTAB indicate that a single pre-trained model falls short in medical task
adaptation. Therefore, we introduce GMoE-Adapter, a novel method that combines
medical and general pre-training weights through a gated mixture-of-experts
adapter, achieving state-of-the-art results in medical visual task adaptation.",2024-04-19,2024,2024-04,medical
"COIN: Counterfactual inpainting for weakly supervised semantic
  segmentation for medical images","Deep learning is dramatically transforming the field of medical imaging and
radiology, enabling the identification of pathologies in medical images,
including computed tomography (CT) and X-ray scans. However, the performance of
deep learning models, particularly in segmentation tasks, is often limited by
the need for extensive annotated datasets. To address this challenge, the
capabilities of weakly supervised semantic segmentation are explored through
the lens of Explainable AI and the generation of counterfactual explanations.
The scope of this research is development of a novel counterfactual inpainting
approach (COIN) that flips the predicted classification label from abnormal to
normal by using a generative model. For instance, if the classifier deems an
input medical image X as abnormal, indicating the presence of a pathology, the
generative model aims to inpaint the abnormal region, thus reversing the
classifier's original prediction label. The approach enables us to produce
precise segmentations for pathologies without depending on pre-existing
segmentation masks. Crucially, image-level labels are utilized, which are
substantially easier to acquire than creating detailed segmentation masks. The
effectiveness of the method is demonstrated by segmenting synthetic targets and
actual kidney tumors from CT images acquired from Tartu University Hospital in
Estonia. The findings indicate that COIN greatly surpasses established
attribution methods, such as RISE, ScoreCAM, and LayerCAM, as well as an
alternative counterfactual explanation method introduced by Singla et al. This
evidence suggests that COIN is a promising approach for semantic segmentation
of tumors in CT images, and presents a step forward in making deep learning
applications more accessible and effective in healthcare, where annotated data
is scarce.",2024-04-19,2024,2024-04,medical
"Accelerating Medical Knowledge Discovery through Automated Knowledge
  Graph Generation and Enrichment","Knowledge graphs (KGs) serve as powerful tools for organizing and
representing structured knowledge. While their utility is widely recognized,
challenges persist in their automation and completeness. Despite efforts in
automation and the utilization of expert-created ontologies, gaps in
connectivity remain prevalent within KGs. In response to these challenges, we
propose an innovative approach termed ``Medical Knowledge Graph Automation
(M-KGA)"". M-KGA leverages user-provided medical concepts and enriches them
semantically using BioPortal ontologies, thereby enhancing the completeness of
knowledge graphs through the integration of pre-trained embeddings. Our
approach introduces two distinct methodologies for uncovering hidden
connections within the knowledge graph: a cluster-based approach and a
node-based approach. Through rigorous testing involving 100 frequently
occurring medical concepts in Electronic Health Records (EHRs), our M-KGA
framework demonstrates promising results, indicating its potential to address
the limitations of existing knowledge graph automation techniques.",2024-04-21,2024,2024-04,medical
MDAgents: An Adaptive Collaboration of LLMs for Medical Decision-Making,"Foundation models are becoming valuable tools in medicine. Yet despite their
promise, the best way to leverage Large Language Models (LLMs) in complex
medical tasks remains an open question. We introduce a novel multi-agent
framework, named Medical Decision-making Agents (MDAgents) that helps address
this gap by automatically assigning a collaboration structure to a team of
LLMs. The assigned solo or group collaboration structure is tailored to the
medical task at hand, emulating real-world medical decision-making processes
adapted to tasks of varying complexities. We evaluate our framework and
baseline methods using state-of-the-art LLMs across a suite of real-world
medical knowledge and medical diagnosis benchmarks, including a comparison of
LLMs' medical complexity classification against human physicians. MDAgents
achieved the best performance in seven out of ten benchmarks on tasks requiring
an understanding of medical knowledge and multi-modal reasoning, showing a
significant improvement of up to 4.2% (p < 0.05) compared to previous methods'
best performances. Ablation studies reveal that MDAgents effectively determines
medical complexity to optimize for efficiency and accuracy across diverse
medical tasks. Notably, the combination of moderator review and external
medical knowledge in group collaboration resulted in an average accuracy
improvement of 11.8%. Our code can be found at
https://github.com/mitmedialab/MDAgents.",2024-04-22,2024,2024-04,medical
"Grounded Knowledge-Enhanced Medical Vision-Language Pre-training for
  Chest X-Ray","Medical foundation models have the potential to revolutionize healthcare by
providing robust and generalized representations of medical data. Medical
vision-language pre-training has emerged as a promising approach for learning
domain-general representations of medical image and text. Current algorithms
that exploit global and local alignment between medical image and text could
however be marred by redundant information in medical data. To address this
issue, we propose a grounded knowledge-enhanced medical vision-language
pre-training (GK-MVLP) framework for chest X-ray. In this framework, medical
knowledge was grounded to the appropriate anatomical regions by using a
transformer-based grounded knowledge-enhanced module for fine-grained alignment
between textural features of medical knowledge and the corresponding anatomical
region-level visual features. The performance of GK-MVLP was competitive with
or exceeded the state of the art on downstream image understanding tasks (chest
X-ray disease classification, disease localization), generative task (report
generation), and vision-language understanding task (medical visual
question-answering). Our results demonstrate the advantage of incorporating
grounding mechanism to remove biases and improve the alignment between chest
X-ray image and radiology report.",2024-04-23,2024,2024-04,medical
"Gallbladder Cancer Detection in Ultrasound Images based on YOLO and
  Faster R-CNN","Medical image analysis is a significant application of artificial
intelligence for disease diagnosis. A crucial step in this process is the
identification of regions of interest within the images. This task can be
automated using object detection algorithms. YOLO and Faster R-CNN are renowned
for such algorithms, each with its own strengths and weaknesses. This study
aims to explore the advantages of both techniques to select more accurate
bounding boxes for gallbladder detection from ultrasound images, thereby
enhancing gallbladder cancer classification. A fusion method that leverages the
benefits of both techniques is presented in this study. The proposed method
demonstrated superior classification performance, with an accuracy of 92.62%,
compared to the individual use of Faster R-CNN and YOLOv8, which yielded
accuracies of 90.16% and 82.79%, respectively.",2024-04-23,2024,2024-04,medical
"Report on Candidate Computational Indicators for Conscious Valenced
  Experience","This report enlists 13 functional conditions cashed out in computational
terms that have been argued to be constituent of conscious valenced experience.
These are extracted from existing empirical and theoretical literature on,
among others, animal sentience, medical disorders, anaesthetics, philosophy,
evolution, neuroscience, and artificial intelligence.",2024-04-25,2024,2024-04,medical
"Hippocrates: An Open-Source Framework for Advancing Large Language
  Models in Healthcare","The integration of Large Language Models (LLMs) into healthcare promises to
transform medical diagnostics, research, and patient care. Yet, the progression
of medical LLMs faces obstacles such as complex training requirements, rigorous
evaluation demands, and the dominance of proprietary models that restrict
academic exploration. Transparent, comprehensive access to LLM resources is
essential for advancing the field, fostering reproducibility, and encouraging
innovation in healthcare AI. We present Hippocrates, an open-source LLM
framework specifically developed for the medical domain. In stark contrast to
previous efforts, it offers unrestricted access to its training datasets,
codebase, checkpoints, and evaluation protocols. This open approach is designed
to stimulate collaborative research, allowing the community to build upon,
refine, and rigorously evaluate medical LLMs within a transparent ecosystem.
Also, we introduce Hippo, a family of 7B models tailored for the medical
domain, fine-tuned from Mistral and LLaMA2 through continual pre-training,
instruction tuning, and reinforcement learning from human and AI feedback. Our
models outperform existing open medical LLMs models by a large-margin, even
surpassing models with 70B parameters. Through Hippocrates, we aspire to unlock
the full potential of LLMs not just to advance medical knowledge and patient
care but also to democratize the benefits of AI research in healthcare, making
them available across the globe.",2024-04-25,2024,2024-04,medical
"Processing HSV Colored Medical Images and Adapting Color Thresholds for
  Computational Image Analysis: a Practical Introduction to an open-source tool","Background: Using artificial intelligence (AI) techniques for computational
medical image analysis has shown promising results. However, colored images are
often not readily available for AI analysis because of different coloring
thresholds used across centers and physicians as well as the removal of
clinical annotations. We aimed to develop an open-source tool that can adapt
different color thresholds of HSV-colored medical images and remove annotations
with a simple click.
  Materials and Methods: We built a function using MATLAB and used multi-center
international shear wave elastography data (NCT 02638935) to test the function.
We provide step-by-step instructions with accompanying code lines.
  Results: We demonstrate that the newly developed pre-processing function
successfully removed letters and adapted different color thresholds of
HSV-colored medical images.
  Conclusion: We developed an open-source tool for removing letters and
adapting different color thresholds in HSV-colored medical images. We hope this
contributes to advancing medical image processing for developing robust
computational imaging algorithms using diverse multi-center big data. The
open-source Matlab tool is available at
https://github.com/cailiemed/image-threshold-adapting.",2024-04-27,2024,2024-04,medical
"Advancing Healthcare Automation: Multi-Agent System for Medical
  Necessity Justification","Prior Authorization delivers safe, appropriate, and cost-effective care that
is medically justified with evidence-based guidelines. However, the process
often requires labor-intensive manual comparisons between patient medical
records and clinical guidelines, that is both repetitive and time-consuming.
Recent developments in Large Language Models (LLMs) have shown potential in
addressing complex medical NLP tasks with minimal supervision. This paper
explores the application of Multi-Agent System (MAS) that utilize specialized
LLM agents to automate Prior Authorization task by breaking them down into
simpler and manageable sub-tasks. Our study systematically investigates the
effects of various prompting strategies on these agents and benchmarks the
performance of different LLMs. We demonstrate that GPT-4 achieves an accuracy
of 86.2% in predicting checklist item-level judgments with evidence, and 95.6%
in determining overall checklist judgment. Additionally, we explore how these
agents can contribute to explainability of steps taken in the process, thereby
enhancing trust and transparency in the system.",2024-04-27,2024,2024-04,medical
"MediFact at MEDIQA-M3G 2024: Medical Question Answering in Dermatology
  with Multimodal Learning","The MEDIQA-M3G 2024 challenge necessitates novel solutions for Multilingual &
Multimodal Medical Answer Generation in dermatology (wai Yim et al., 2024a).
This paper addresses the limitations of traditional methods by proposing a
weakly supervised learning approach for open-ended medical question-answering
(QA). Our system leverages readily available MEDIQA-M3G images via a
VGG16-CNN-SVM model, enabling multilingual (English, Chinese, Spanish) learning
of informative skin condition representations. Using pre-trained QA models, we
further bridge the gap between visual and textual information through
multimodal fusion. This approach tackles complex, open-ended questions even
without predefined answer choices. We empower the generation of comprehensive
answers by feeding the ViT-CLIP model with multiple responses alongside images.
This work advances medical QA research, paving the way for clinical decision
support systems and ultimately improving healthcare delivery.",2024-04-27,2024,2024-04,medical
"ConPro: Learning Severity Representation for Medical Images using
  Contrastive Learning and Preference Optimization","Understanding the severity of conditions shown in images in medical diagnosis
is crucial, serving as a key guide for clinical assessment, treatment, as well
as evaluating longitudinal progression. This paper proposes Con- PrO: a novel
representation learning method for severity assessment in medical images using
Contrastive learningintegrated Preference Optimization. Different from
conventional contrastive learning methods that maximize the distance between
classes, ConPrO injects into the latent vector the distance preference
knowledge between various severity classes and the normal class. We
systematically examine the key components of our framework to illuminate how
contrastive prediction tasks acquire valuable representations. We show that our
representation learning framework offers valuable severity ordering in the
feature space while outperforming previous state-of-the-art methods on
classification tasks. We achieve a 6% and 20% relative improvement compared to
a supervised and a self-supervised baseline, respectively. In addition, we
derived discussions on severity indicators and related applications of
preference comparison in the medical domain.",2024-04-29,2024,2024-04,medical
"Artificial Intelligence in Bone Metastasis Analysis: Current
  Advancements, Opportunities and Challenges","In recent years, Artificial Intelligence (AI) has been widely used in
medicine, particularly in the analysis of medical imaging, which has been
driven by advances in computer vision and deep learning methods. This is
particularly important in overcoming the challenges posed by diseases such as
Bone Metastases (BM), a common and complex malignancy of the bones. Indeed,
there have been an increasing interest in developing Machine Learning (ML)
techniques into oncologic imaging for BM analysis. In order to provide a
comprehensive overview of the current state-of-the-art and advancements for BM
analysis using artificial intelligence, this review is conducted with the
accordance with PRISMA guidelines. Firstly, this review highlights the clinical
and oncologic perspectives of BM and the used medical imaging modalities, with
discussing their advantages and limitations. Then the review focuses on modern
approaches with considering the main BM analysis tasks, which includes:
classification, detection and segmentation. The results analysis show that ML
technologies can achieve promising performance for BM analysis and have
significant potential to improve clinician efficiency and cope with time and
cost limitations. Furthermore, there are requirements for further research to
validate the clinical performance of ML tools and facilitate their integration
into routine clinical practice.",2024-04-30,2024,2024-04,medical
Agent Hospital: A Simulacrum of Hospital with Evolvable Medical Agents,"The recent rapid development of large language models (LLMs) has sparked a
new wave of technological revolution in medical artificial intelligence (AI).
While LLMs are designed to understand and generate text like a human,
autonomous agents that utilize LLMs as their ""brain"" have exhibited
capabilities beyond text processing such as planning, reflection, and using
tools by enabling their ""bodies"" to interact with the environment. We introduce
a simulacrum of hospital called Agent Hospital that simulates the entire
process of treating illness, in which all patients, nurses, and doctors are
LLM-powered autonomous agents. Within the simulacrum, doctor agents are able to
evolve by treating a large number of patient agents without the need to label
training data manually. After treating tens of thousands of patient agents in
the simulacrum (human doctors may take several years in the real world), the
evolved doctor agents outperform state-of-the-art medical agent methods on the
MedQA benchmark comprising US Medical Licensing Examination (USMLE) test
questions. Our methods of simulacrum construction and agent evolution have the
potential in benefiting a broad range of applications beyond medical AI.",2024-05-05,2024,2024-05,medical
"Automated Computation of Therapies Using Failure Mode and Effects
  Analysis in the Medical Domain","Failure mode and effects analysis (FMEA) is a systematic approach to identify
and analyse potential failures and their effects in a system or process. The
FMEA approach, however, requires domain experts to manually analyse the FMEA
model to derive risk-reducing actions that should be applied. In this paper, we
provide a formal framework to allow for automatic planning and acting in FMEA
models. More specifically, we cast the FMEA model into a Markov decision
process which can then be solved by existing solvers. We show that the FMEA
approach can not only be used to support medical experts during the modelling
process but also to automatically derive optimal therapies for the treatment of
patients.",2024-05-06,2024,2024-05,medical
"MEDVOC: Vocabulary Adaptation for Fine-tuning Pre-trained Language
  Models on Medical Text Summarization","This work presents a dynamic vocabulary adaptation strategy, MEDVOC, for
fine-tuning pre-trained language models (PLMs) like BertSumAbs, BART, and
PEGASUS for improved medical text summarization. In contrast to existing domain
adaptation approaches in summarization, MEDVOC treats vocabulary as an
optimizable parameter and optimizes the PLM vocabulary based on fragment score
conditioned only on the downstream task's reference summaries. Unlike previous
works on vocabulary adaptation (limited only to classification tasks),
optimizing vocabulary based on summarization tasks requires an extremely costly
intermediate fine-tuning step on large summarization datasets. To that end, our
novel fragment score-based hyperparameter search very significantly reduces
this fine-tuning time -- from 450 days to less than 2 days on average.
Furthermore, while previous works on vocabulary adaptation are often primarily
tied to single PLMs, MEDVOC is designed to be deployable across multiple PLMs
(with varying model vocabulary sizes, pre-training objectives, and model sizes)
-- bridging the limited vocabulary overlap between the biomedical literature
domain and PLMs. MEDVOC outperforms baselines by 15.74% in terms of Rouge-L in
zero-shot setting and shows gains of 17.29% in high Out-Of-Vocabulary (OOV)
concentrations. Our human evaluation shows MEDVOC generates more faithful
medical summaries (88% compared to 59% in baselines). We make the codebase
publicly available at https://github.com/gb-kgp/MEDVOC.",2024-05-07,2024,2024-05,medical
Summarizing Radiology Reports Findings into Impressions,"Patient hand-off and triage are two fundamental problems in health care.
Often doctors must painstakingly summarize complex findings to efficiently
communicate with specialists and quickly make decisions on which patients have
the most urgent cases. In pursuit of these challenges, we present (1) a model
with state-of-art radiology report summarization performance using (2) a novel
method for augmenting medical data, and (3) an analysis of the model
limitations and radiology knowledge gain. We also provide a data processing
pipeline for future models developed on the the MIMIC CXR dataset. Our best
performing model was a fine-tuned BERT-to-BERT encoder-decoder with 58.75/100
ROUGE-L F1, which outperformed specialized checkpoints with more sophisticated
attention mechanisms. We investigate these aspects in this work.",2024-05-10,2024,2024-05,medical
A Generalist Learner for Multifaceted Medical Image Interpretation,"Current medical artificial intelligence systems are often limited to narrow
applications, hindering their widespread adoption in clinical practice. To
address this limitation, we propose MedVersa, a generalist learner that enables
flexible learning and tasking for medical image interpretation. By leveraging a
large language model as a learnable orchestrator, MedVersa can learn from both
visual and linguistic supervision, support multimodal inputs, and perform
real-time task specification. This versatility allows MedVersa to adapt to
various clinical scenarios and perform multifaceted medical image analysis. We
introduce MedInterp, the largest multimodal dataset to date for medical image
interpretation, consisting of over 13 million annotated instances spanning 11
tasks across 3 modalities, to support the development of MedVersa. Our
experiments demonstrate that MedVersa achieves state-of-the-art performance in
9 tasks, sometimes outperforming specialist counterparts by over 10%. MedVersa
is the first to showcase the viability of multimodal generative medical AI in
implementing multimodal outputs, inputs, and dynamic task specification,
highlighting its potential as a multifunctional system for comprehensive
medical image analysis. This generalist approach to medical image
interpretation paves the way for more adaptable and efficient AI-assisted
clinical decision-making.",2024-05-13,2024,2024-05,medical
"Evaluating the Explainable AI Method Grad-CAM for Breath Classification
  on Newborn Time Series Data","With the digitalization of health care systems, artificial intelligence
becomes more present in medicine. Especially machine learning shows great
potential for complex tasks such as time series classification, usually at the
cost of transparency and comprehensibility. This leads to a lack of trust by
humans and thus hinders its active usage. Explainable artificial intelligence
tries to close this gap by providing insight into the decision-making process,
the actual usefulness of its different methods is however unclear. This paper
proposes a user study based evaluation of the explanation method Grad-CAM with
application to a neural network for the classification of breaths in time
series neonatal ventilation data. We present the perceived usefulness of the
explainability method by different stakeholders, exposing the difficulty to
achieve actual transparency and the wish for more in-depth explanations by many
of the participants.",2024-05-13,2024,2024-05,medical
Evaluating large language models in medical applications: a survey,"Large language models (LLMs) have emerged as powerful tools with
transformative potential across numerous domains, including healthcare and
medicine. In the medical domain, LLMs hold promise for tasks ranging from
clinical decision support to patient education. However, evaluating the
performance of LLMs in medical contexts presents unique challenges due to the
complex and critical nature of medical information. This paper provides a
comprehensive overview of the landscape of medical LLM evaluation, synthesizing
insights from existing studies and highlighting evaluation data sources, task
scenarios, and evaluation methods. Additionally, it identifies key challenges
and opportunities in medical LLM evaluation, emphasizing the need for continued
research and innovation to ensure the responsible integration of LLMs into
clinical practice.",2024-05-13,2024,2024-05,medical
"MoVL:Exploring Fusion Strategies for the Domain-Adaptive Application of
  Pretrained Models in Medical Imaging Tasks","Medical images are often more difficult to acquire than natural images due to
the specialism of the equipment and technology, which leads to less medical
image datasets. So it is hard to train a strong pretrained medical vision
model. How to make the best of natural pretrained vision model and adapt in
medical domain still pends. For image classification, a popular method is
linear probe (LP). However, LP only considers the output after feature
extraction. Yet, there exists a gap between input medical images and natural
pretrained vision model. We introduce visual prompting (VP) to fill in the gap,
and analyze the strategies of coupling between LP and VP. We design a joint
learning loss function containing categorisation loss and discrepancy loss,
which describe the variance of prompted and plain images, naming this joint
training strategy MoVL (Mixture of Visual Prompting and Linear Probe). We
experiment on 4 medical image classification datasets, with two mainstream
architectures, ResNet and CLIP. Results shows that without changing the
parameters and architecture of backbone model and with less parameters, there
is potential for MoVL to achieve full finetune (FF) accuracy (on four medical
datasets, average 90.91% for MoVL and 91.13% for FF). On out of distribution
medical dataset, our method(90.33%) can outperform FF (85.15%) with absolute
5.18 % lead.",2024-05-13,2024,2024-05,medical
CTS: A Consistency-Based Medical Image Segmentation Model,"In medical image segmentation tasks, diffusion models have shown significant
potential. However, mainstream diffusion models suffer from drawbacks such as
multiple sampling times and slow prediction results. Recently, consistency
models, as a standalone generative network, have resolved this issue. Compared
to diffusion models, consistency models can reduce the sampling times to once,
not only achieving similar generative effects but also significantly speeding
up training and prediction. However, they are not suitable for image
segmentation tasks, and their application in the medical imaging field has not
yet been explored. Therefore, this paper applies the consistency model to
medical image segmentation tasks, designing multi-scale feature signal
supervision modes and loss function guidance to achieve model convergence.
Experiments have verified that the CTS model can obtain better medical image
segmentation results with a single sampling during the test phase.",2024-05-15,2024,2024-05,medical
"Content-Based Image Retrieval for Multi-Class Volumetric Radiology
  Images: A Benchmark Study","While content-based image retrieval (CBIR) has been extensively studied in
natural image retrieval, its application to medical images presents ongoing
challenges, primarily due to the 3D nature of medical images. Recent studies
have shown the potential use of pre-trained vision embeddings for CBIR in the
context of radiology image retrieval. However, a benchmark for the retrieval of
3D volumetric medical images is still lacking, hindering the ability to
objectively evaluate and compare the efficiency of proposed CBIR approaches in
medical imaging. In this study, we extend previous work and establish a
benchmark for region-based and localized multi-organ retrieval using the
TotalSegmentator dataset (TS) with detailed multi-organ annotations. We
benchmark embeddings derived from pre-trained supervised models on medical
images against embeddings derived from pre-trained unsupervised models on
non-medical images for 29 coarse and 104 detailed anatomical structures in
volume and region levels. For volumetric image retrieval, we adopt a late
interaction re-ranking method inspired by text matching. We compare it against
the original method proposed for volume and region retrieval and achieve a
retrieval recall of 1.0 for diverse anatomical regions with a wide size range.
The findings and methodologies presented in this paper provide insights and
benchmarks for further development and evaluation of CBIR approaches in the
context of medical imaging.",2024-05-15,2024,2024-05,medical
"COGNET-MD, an evaluation framework and dataset for Large Language Model
  benchmarks in the medical domain","Large Language Models (LLMs) constitute a breakthrough state-of-the-art
Artificial Intelligence (AI) technology which is rapidly evolving and promises
to aid in medical diagnosis either by assisting doctors or by simulating a
doctor's workflow in more advanced and complex implementations. In this
technical paper, we outline Cognitive Network Evaluation Toolkit for Medical
Domains (COGNET-MD), which constitutes a novel benchmark for LLM evaluation in
the medical domain. Specifically, we propose a scoring-framework with increased
difficulty to assess the ability of LLMs in interpreting medical text. The
proposed framework is accompanied with a database of Multiple Choice Quizzes
(MCQs). To ensure alignment with current medical trends and enhance safety,
usefulness, and applicability, these MCQs have been constructed in
collaboration with several associated medical experts in various medical
domains and are characterized by varying degrees of difficulty. The current
(first) version of the database includes the medical domains of Psychiatry,
Dentistry, Pulmonology, Dermatology and Endocrinology, but it will be
continuously extended and expanded to include additional medical domains.",2024-05-17,2024,2024-05,medical
"Medical Dialogue: A Survey of Categories, Methods, Evaluation and
  Challenges","This paper surveys and organizes research works on medical dialog systems,
which is an important yet challenging task. Although these systems have been
surveyed in the medical community from an application perspective, a systematic
review from a rigorous technical perspective has to date remained noticeably
absent. As a result, an overview of the categories, methods, and evaluation of
medical dialogue systems remain limited and underspecified, hindering the
further improvement of this area. To fill this gap, we investigate an initial
pool of 325 papers from well-known computer science, and natural language
processing conferences and journals, and make an overview. Recently, large
language models have shown strong model capacity on downstream tasks, which
also reshaped medical dialog systems' foundation. Despite the alluring
practical application value, current medical dialogue systems still suffer from
problems. To this end, this paper lists the grand challenges of medical dialog
systems, especially of large language models.",2024-05-17,2024,2024-05,medical
"Application of Artificial Intelligence in Schizophrenia Rehabilitation
  Management: A Systematic Scoping Review","This systematic review assessed the current state and future prospects of
artificial intelligence (AI) in schizophrenia rehabilitation management. We
reviewed 61 studies on AI-related data types, feature engineering methods,
algorithmic models, and evaluation metrics published from 2012-2024. The review
categorizes AI applications into the following key application areas: symptom
monitoring, medication management, risk management, functional training, and
psychosocial support. Findings indicate that supervised machine learning
techniques, particularly for symptom monitoring and relapse risk management,
remain the predominant approaches, effectively leveraging structured data while
incorporating interpretable algorithms. This study underscores the potential of
AI in transforming long-term management strategies for schizophrenia, offering
valuable insights into improving the quality of life of patients. Future
research should focus on expanding data sources through multimodal data
integration, exploring deep learning models, and integrating AI-driven
interventions into training tasks to fully capitalize on AI's potential in
schizophrenia rehabilitation.",2024-05-17,2024,2024-05,medical
"Overcoming Medical Overuse with AI Assistance: An Experimental
  Investigation","This study evaluates the effectiveness of Artificial Intelligence (AI) in
mitigating medical overtreatment, a significant issue characterized by
unnecessary interventions that inflate healthcare costs and pose risks to
patients. We conducted a lab-in-the-field experiment at a medical school,
utilizing a novel medical prescription task, manipulating monetary incentives
and the availability of AI assistance among medical students using a
three-by-two factorial design. We tested three incentive schemes: Flat
(constant pay regardless of treatment quantity), Progressive (pay increases
with the number of treatments), and Regressive (penalties for overtreatment) to
assess their influence on the adoption and effectiveness of AI assistance. Our
findings demonstrate that AI significantly reduced overtreatment rates by up to
62% in the Regressive incentive conditions where (prospective) physician and
patient interests were most aligned. Diagnostic accuracy improved by 17% to
37%, depending on the incentive scheme. Adoption of AI advice was high, with
approximately half of the participants modifying their decisions based on AI
input across all settings. For policy implications, we quantified the monetary
(57%) and non-monetary (43%) incentives of overtreatment and highlighted AI's
potential to mitigate non-monetary incentives and enhance social welfare. Our
results provide valuable insights for healthcare administrators considering AI
integration into healthcare systems.",2024-05-17,2024,2024-05,medical
Generative Artificial Intelligence: A Systematic Review and Applications,"In recent years, the study of artificial intelligence (AI) has undergone a
paradigm shift. This has been propelled by the groundbreaking capabilities of
generative models both in supervised and unsupervised learning scenarios.
Generative AI has shown state-of-the-art performance in solving perplexing
real-world conundrums in fields such as image translation, medical diagnostics,
textual imagery fusion, natural language processing, and beyond. This paper
documents the systematic review and analysis of recent advancements and
techniques in Generative AI with a detailed discussion of their applications
including application-specific models. Indeed, the major impact that generative
AI has made to date, has been in language generation with the development of
large language models, in the field of image translation and several other
interdisciplinary applications of generative AI. Moreover, the primary
contribution of this paper lies in its coherent synthesis of the latest
advancements in these areas, seamlessly weaving together contemporary
breakthroughs in the field. Particularly, how it shares an exploration of the
future trajectory for generative AI. In conclusion, the paper ends with a
discussion of Responsible AI principles, and the necessary ethical
considerations for the sustainability and growth of these generative models.",2024-05-17,2024,2024-05,medical
"Inquire, Interact, and Integrate: A Proactive Agent Collaborative
  Framework for Zero-Shot Multimodal Medical Reasoning","The adoption of large language models (LLMs) in healthcare has attracted
significant research interest. However, their performance in healthcare remains
under-investigated and potentially limited, due to i) they lack rich
domain-specific knowledge and medical reasoning skills; and ii) most
state-of-the-art LLMs are unimodal, text-only models that cannot directly
process multimodal inputs. To this end, we propose a multimodal medical
collaborative reasoning framework \textbf{MultiMedRes}, which incorporates a
learner agent to proactively gain essential information from domain-specific
expert models, to solve medical multimodal reasoning problems. Our method
includes three steps: i) \textbf{Inquire}: The learner agent first decomposes
given complex medical reasoning problems into multiple domain-specific
sub-problems; ii) \textbf{Interact}: The agent then interacts with
domain-specific expert models by repeating the ``ask-answer'' process to
progressively obtain different domain-specific knowledge; iii)
\textbf{Integrate}: The agent finally integrates all the acquired
domain-specific knowledge to accurately address the medical reasoning problem.
We validate the effectiveness of our method on the task of difference visual
question answering for X-ray images. The experiments demonstrate that our
zero-shot prediction achieves state-of-the-art performance, and even
outperforms the fully supervised methods. Besides, our approach can be
incorporated into various LLMs and multimodal LLMs to significantly boost their
performance.",2024-05-19,2024,2024-05,medical
Large Language Models for Medicine: A Survey,"To address challenges in the digital economy's landscape of digital
intelligence, large language models (LLMs) have been developed. Improvements in
computational power and available resources have significantly advanced LLMs,
allowing their integration into diverse domains for human life. Medical LLMs
are essential application tools with potential across various medical
scenarios. In this paper, we review LLM developments, focusing on the
requirements and applications of medical LLMs. We provide a concise overview of
existing models, aiming to explore advanced research directions and benefit
researchers for future medical applications. We emphasize the advantages of
medical LLMs in applications, as well as the challenges encountered during
their development. Finally, we suggest directions for technical integration to
mitigate challenges and potential research directions for the future of medical
LLMs, aiming to meet the demands of the medical field better.",2024-05-20,2024,2024-05,medical
"A Survey of Artificial Intelligence in Gait-Based Neurodegenerative
  Disease Diagnosis","Recent years have witnessed an increasing global population affected by
neurodegenerative diseases (NDs), which traditionally require extensive
healthcare resources and human effort for medical diagnosis and monitoring. As
a crucial disease-related motor symptom, human gait can be exploited to
characterize different NDs. The current advances in artificial intelligence
(AI) models enable automatic gait analysis for NDs identification and
classification, opening a new avenue to facilitate faster and more
cost-effective diagnosis of NDs. In this paper, we provide a comprehensive
survey on recent progress of machine learning and deep learning based AI
techniques applied to diagnosis of five typical NDs through gait. We provide an
overview of the process of AI-assisted NDs diagnosis, and present a systematic
taxonomy of existing gait data and AI models. Meanwhile, a novel quality
evaluation criterion is proposed to quantitatively assess the quality of
existing studies. Through an extensive review and analysis of 169 studies, we
present recent technical advancements, discuss existing challenges, potential
solutions, and future directions in this field. Finally, we envision the
prospective utilization of 3D skeleton data for human gait representation and
the development of more efficient AI models for NDs diagnosis.",2024-05-21,2024,2024-05,medical
"Reducing Biases towards Minoritized Populations in Medical Curricular
  Content via Artificial Intelligence for Fairer Health Outcomes","Biased information (recently termed bisinformation) continues to be taught in
medical curricula, often long after having been debunked. In this paper, we
introduce BRICC, a firstin-class initiative that seeks to mitigate medical
bisinformation using machine learning to systematically identify and flag text
with potential biases, for subsequent review in an expert-in-the-loop fashion,
thus greatly accelerating an otherwise labor-intensive process. A gold-standard
BRICC dataset was developed throughout several years, and contains over 12K
pages of instructional materials. Medical experts meticulously annotated these
documents for bias according to comprehensive coding guidelines, emphasizing
gender, sex, age, geography, ethnicity, and race. Using this labeled dataset,
we trained, validated, and tested medical bias classifiers. We test three
classifier approaches: a binary type-specific classifier, a general bias
classifier; an ensemble combining bias type-specific classifiers
independently-trained; and a multitask learning (MTL) model tasked with
predicting both general and type-specific biases. While MTL led to some
improvement on race bias detection in terms of F1-score, it did not outperform
binary classifiers trained specifically on each task. On general bias
detection, the binary classifier achieves up to 0.923 of AUC, a 27.8%
improvement over the baseline. This work lays the foundations for debiasing
medical curricula by exploring a novel dataset and evaluating different
training model strategies. Hence, it offers new pathways for more nuanced and
effective mitigation of bisinformation.",2024-05-21,2024,2024-05,medical
"Efficient Medical Question Answering with Knowledge-Augmented Question
  Generation","In the expanding field of language model applications, medical knowledge
representation remains a significant challenge due to the specialized nature of
the domain. Large language models, such as GPT-4, obtain reasonable scores on
medical question answering tasks, but smaller models are far behind. In this
work, we introduce a method to improve the proficiency of a small language
model in the medical domain by employing a two-fold approach. We first
fine-tune the model on a corpus of medical textbooks. Then, we use GPT-4 to
generate questions similar to the downstream task, prompted with textbook
knowledge, and use them to fine-tune the model. Additionally, we introduce
ECN-QA, a novel medical question answering dataset containing ``progressive
questions'' composed of related sequential questions. We show the benefits of
our training strategy on this dataset. The study's findings highlight the
potential of small language models in the medical domain when appropriately
fine-tuned. The code and weights are available at
https://github.com/raidium-med/MQG.",2024-05-23,2024,2024-05,medical
"Investigation of Customized Medical Decision Algorithms Utilizing Graph
  Neural Networks","Aiming at the limitations of traditional medical decision system in
processing large-scale heterogeneous medical data and realizing highly
personalized recommendation, this paper introduces a personalized medical
decision algorithm utilizing graph neural network (GNN). This research
innovatively integrates graph neural network technology into the medical and
health field, aiming to build a high-precision representation model of patient
health status by mining the complex association between patients' clinical
characteristics, genetic information, living habits. In this study, medical
data is preprocessed to transform it into a graph structure, where nodes
represent different data entities (such as patients, diseases, genes, etc.) and
edges represent interactions or relationships between entities. The core of the
algorithm is to design a novel multi-scale fusion mechanism, combining the
historical medical records, physiological indicators and genetic
characteristics of patients, to dynamically adjust the attention allocation
strategy of the graph neural network, so as to achieve highly customized
analysis of individual cases. In the experimental part, this study selected
several publicly available medical data sets for validation, and the results
showed that compared with traditional machine learning methods and a single
graph neural network model, the proposed personalized medical decision
algorithm showed significantly superior performance in terms of disease
prediction accuracy, treatment effect evaluation and patient risk
stratification.",2024-05-23,2024,2024-05,medical
"Integrating Medical Imaging and Clinical Reports Using Multimodal Deep
  Learning for Advanced Disease Analysis","In this paper, an innovative multi-modal deep learning model is proposed to
deeply integrate heterogeneous information from medical images and clinical
reports. First, for medical images, convolutional neural networks were used to
extract high-dimensional features and capture key visual information such as
focal details, texture and spatial distribution. Secondly, for clinical report
text, a two-way long and short-term memory network combined with an attention
mechanism is used for deep semantic understanding, and key statements related
to the disease are accurately captured. The two features interact and integrate
effectively through the designed multi-modal fusion layer to realize the joint
representation learning of image and text. In the empirical study, we selected
a large medical image database covering a variety of diseases, combined with
corresponding clinical reports for model training and validation. The proposed
multimodal deep learning model demonstrated substantial superiority in the
realms of disease classification, lesion localization, and clinical description
generation, as evidenced by the experimental results.",2024-05-23,2024,2024-05,medical
"PriCE: Privacy-Preserving and Cost-Effective Scheduling for
  Parallelizing the Large Medical Image Processing Workflow over Hybrid Clouds","Running deep neural networks for large medical images is a resource-hungry
and time-consuming task with centralized computing. Outsourcing such medical
image processing tasks to hybrid clouds has benefits, such as a significant
reduction of execution time and monetary cost. However, due to privacy
concerns, it is still challenging to process sensitive medical images over
clouds, which would hinder their deployment in many real-world applications. To
overcome this, we first formulate the overall optimization objectives of the
privacy-preserving distributed system model, i.e., minimizing the amount of
information about the private data learned by the adversaries throughout the
process, reducing the maximum execution time and cost under the user budget
constraint. We propose a novel privacy-preserving and cost-effective method
called PriCE to solve this multi-objective optimization problem. We performed
extensive simulation experiments for artifact detection tasks on medical images
using an ensemble of five deep convolutional neural network inferences as the
workflow task. Experimental results show that PriCE successfully splits a wide
range of input gigapixel medical images with graph-coloring-based strategies,
yielding desired output utility and lowering the privacy risk, makespan, and
monetary cost under user's budget.",2024-05-24,2024,2024-05,medical
Transductive Confidence Machine and its application to Medical Data Sets,"The Transductive Confidence Machine Nearest Neighbours (TCMNN) algorithm and
a supporting, simple user interface was developed. Different settings of the
TCMNN algorithms' parameters were tested on medical data sets, in addition to
the use of different Minkowski metrics and polynomial kernels. The effect of
increasing the number of nearest neighbours and marking results with
significance was also investigated. SVM implementation of the Transductive
Confidence Machine was compared with Nearest Neighbours implementation. The
application of neural networks was investigated as a useful comparison to the
transductive algorithms.",2024-05-25,2024,2024-05,medical
"Medical MLLM is Vulnerable: Cross-Modality Jailbreak and Mismatched
  Attacks on Medical Multimodal Large Language Models","Security concerns related to Large Language Models (LLMs) have been
extensively explored, yet the safety implications for Multimodal Large Language
Models (MLLMs), particularly in medical contexts (MedMLLMs), remain
insufficiently studied. This paper delves into the underexplored security
vulnerabilities of MedMLLMs, especially when deployed in clinical environments
where the accuracy and relevance of question-and-answer interactions are
critically tested against complex medical challenges. By combining existing
clinical medical data with atypical natural phenomena, we define the mismatched
malicious attack (2M-attack) and introduce its optimized version, known as the
optimized mismatched malicious attack (O2M-attack or 2M-optimization). Using
the voluminous 3MAD dataset that we construct, which covers a wide range of
medical image modalities and harmful medical scenarios, we conduct a
comprehensive analysis and propose the MCM optimization method, which
significantly enhances the attack success rate on MedMLLMs. Evaluations with
this dataset and attack methods, including white-box attacks on LLaVA-Med and
transfer attacks (black-box) on four other SOTA models, indicate that even
MedMLLMs designed with enhanced security features remain vulnerable to security
breaches. Our work underscores the urgent need for a concerted effort to
implement robust security measures and enhance the safety and efficacy of
open-source MedMLLMs, particularly given the potential severity of jailbreak
attacks and other malicious or clinically significant exploits in medical
settings. Our code is available at https://github.com/dirtycomputer/O2M_attack.",2024-05-26,2024,2024-05,medical
"""It depends"": Configuring AI to Improve Clinical Usefulness Across
  Contexts","Artificial Intelligence (AI) repeatedly match or outperform radiologists in
lab experiments. However, real-world implementations of radiological AI-based
systems are found to provide little to no clinical value. This paper explores
how to design AI for clinical usefulness in different contexts. We conducted 19
design sessions and design interventions with 13 radiologists from 7 clinical
sites in Denmark and Kenya, based on three iterations of a functional AI-based
prototype. Ten sociotechnical dependencies were identified as crucial for the
design of AI in radiology. We conceptualised four technical dimensions that
must be configured to the intended clinical context of use: AI functionality,
AI medical focus, AI decision threshold, and AI Explainability. We present four
design recommendations on how to address dependencies pertaining to the medical
knowledge, clinic type, user expertise level, patient context, and user
situation that condition the configuration of these technical dimensions.",2024-05-27,2024,2024-05,medical
"SkinCAP: A Multi-modal Dermatology Dataset Annotated with Rich Medical
  Captions","With the widespread application of artificial intelligence (AI), particularly
deep learning (DL) and vision-based large language models (VLLMs), in skin
disease diagnosis, the need for interpretability becomes crucial. However,
existing dermatology datasets are limited in their inclusion of concept-level
meta-labels, and none offer rich medical descriptions in natural language. This
deficiency impedes the advancement of LLM-based methods in dermatological
diagnosis. To address this gap and provide a meticulously annotated dermatology
dataset with comprehensive natural language descriptions, we introduce SkinCAP:
a multi-modal dermatology dataset annotated with rich medical captions. SkinCAP
comprises 4,000 images sourced from the Fitzpatrick 17k skin disease dataset
and the Diverse Dermatology Images dataset, annotated by board-certified
dermatologists to provide extensive medical descriptions and captions. Notably,
SkinCAP represents the world's first such dataset and is publicly available at
https://huggingface.co/datasets/joshuachou/SkinCAP.",2024-05-28,2024,2024-05,medical
"Worse than Random? An Embarrassingly Simple Probing Evaluation of Large
  Multimodal Models in Medical VQA","Large Multimodal Models (LMMs) have shown remarkable progress in medical
Visual Question Answering (Med-VQA), achieving high accuracy on existing
benchmarks. However, their reliability under robust evaluation is questionable.
This study reveals that when subjected to simple probing evaluation,
state-of-the-art models perform worse than random guessing on medical diagnosis
questions. To address this critical evaluation problem, we introduce the
Probing Evaluation for Medical Diagnosis (ProbMed) dataset to rigorously assess
LMM performance in medical imaging through probing evaluation and procedural
diagnosis. Particularly, probing evaluation features pairing original questions
with negation questions with hallucinated attributes, while procedural
diagnosis requires reasoning across various diagnostic dimensions for each
image, including modality recognition, organ identification, clinical findings,
abnormalities, and positional grounding. Our evaluation reveals that
top-performing models like GPT-4o, GPT-4V, and Gemini Pro perform worse than
random guessing on specialized diagnostic questions, indicating significant
limitations in handling fine-grained medical inquiries. Besides, models like
LLaVA-Med struggle even with more general questions, and results from CheXagent
demonstrate the transferability of expertise across different modalities of the
same organ, showing that specialized domain knowledge is still crucial for
improving performance. This study underscores the urgent need for more robust
evaluation to ensure the reliability of LMMs in critical fields like medical
diagnosis, and current LMMs are still far from applicable to those fields.",2024-05-30,2024,2024-05,medical
The Explanation Necessity for Healthcare AI,"Explainability is a critical factor in enhancing the trustworthiness and
acceptance of artificial intelligence (AI) in healthcare, where decisions
directly impact patient outcomes. Despite advancements in AI interpretability,
clear guidelines on when and to what extent explanations are required in
medical applications remain lacking. We propose a novel categorization system
comprising four classes of explanation necessity (self-explainable,
semi-explainable, non-explainable, and new-patterns discovery), guiding the
required level of explanation; whether local (patient or sample level), global
(cohort or dataset level), or both. To support this system, we introduce a
mathematical formulation that incorporates three key factors: (i) robustness of
the evaluation protocol, (ii) variability of expert observations, and (iii)
representation dimensionality of the application. This framework provides a
practical tool for researchers to determine the appropriate depth of
explainability needed, addressing the critical question: When does an AI
medical application need to be explained, and at what level of detail?",2024-05-31,2024,2024-05,medical
"GAMedX: Generative AI-based Medical Entity Data Extractor Using Large
  Language Models","In the rapidly evolving field of healthcare and beyond, the integration of
generative AI in Electronic Health Records (EHRs) represents a pivotal
advancement, addressing a critical gap in current information extraction
techniques. This paper introduces GAMedX, a Named Entity Recognition (NER)
approach utilizing Large Language Models (LLMs) to efficiently extract entities
from medical narratives and unstructured text generated throughout various
phases of the patient hospital visit. By addressing the significant challenge
of processing unstructured medical text, GAMedX leverages the capabilities of
generative AI and LLMs for improved data extraction. Employing a unified
approach, the methodology integrates open-source LLMs for NER, utilizing
chained prompts and Pydantic schemas for structured output to navigate the
complexities of specialized medical jargon. The findings reveal significant
ROUGE F1 score on one of the evaluation datasets with an accuracy of 98\%. This
innovation enhances entity extraction, offering a scalable, cost-effective
solution for automated forms filling from unstructured data. As a result,
GAMedX streamlines the processing of unstructured narratives, and sets a new
standard in NER applications, contributing significantly to theoretical and
practical advancements beyond the medical technology sphere.",2024-05-31,2024,2024-05,medical
"Breast Cancer Diagnosis: A Comprehensive Exploration of Explainable
  Artificial Intelligence (XAI) Techniques","Breast cancer (BC) stands as one of the most common malignancies affecting
women worldwide, necessitating advancements in diagnostic methodologies for
better clinical outcomes. This article provides a comprehensive exploration of
the application of Explainable Artificial Intelligence (XAI) techniques in the
detection and diagnosis of breast cancer. As Artificial Intelligence (AI)
technologies continue to permeate the healthcare sector, particularly in
oncology, the need for transparent and interpretable models becomes imperative
to enhance clinical decision-making and patient care. This review discusses the
integration of various XAI approaches, such as SHAP, LIME, Grad-CAM, and
others, with machine learning and deep learning models utilized in breast
cancer detection and classification. By investigating the modalities of breast
cancer datasets, including mammograms, ultrasounds and their processing with
AI, the paper highlights how XAI can lead to more accurate diagnoses and
personalized treatment plans. It also examines the challenges in implementing
these techniques and the importance of developing standardized metrics for
evaluating XAI's effectiveness in clinical settings. Through detailed analysis
and discussion, this article aims to highlight the potential of XAI in bridging
the gap between complex AI models and practical healthcare applications,
thereby fostering trust and understanding among medical professionals and
improving patient outcomes.",2024-06-01,2024,2024-06,medical
Lightening Anything in Medical Images,"The development of medical imaging techniques has made a significant
contribution to clinical decision-making. However, the existence of suboptimal
imaging quality, as indicated by irregular illumination or imbalanced
intensity, presents significant obstacles in automating disease screening,
analysis, and diagnosis. Existing approaches for natural image enhancement are
mostly trained with numerous paired images, presenting challenges in data
collection and training costs, all while lacking the ability to generalize
effectively. Here, we introduce a pioneering training-free Diffusion Model for
Universal Medical Image Enhancement, named UniMIE. UniMIE demonstrates its
unsupervised enhancement capabilities across various medical image modalities
without the need for any fine-tuning. It accomplishes this by relying solely on
a single pre-trained model from ImageNet. We conduct a comprehensive evaluation
on 13 imaging modalities and over 15 medical types, demonstrating better
qualities, robustness, and accuracy than other modality-specific and
data-inefficient models. By delivering high-quality enhancement and
corresponding accuracy downstream tasks across a wide range of tasks, UniMIE
exhibits considerable potential to accelerate the advancement of diagnostic
tools and customized treatment plans.",2024-06-01,2024,2024-06,medical
"An Early Investigation into the Utility of Multimodal Large Language
  Models in Medical Imaging","Recent developments in multimodal large language models (MLLMs) have spurred
significant interest in their potential applications across various medical
imaging domains. On the one hand, there is a temptation to use these generative
models to synthesize realistic-looking medical image data, while on the other
hand, the ability to identify synthetic image data in a pool of data is also
significantly important. In this study, we explore the potential of the Gemini
(\textit{gemini-1.0-pro-vision-latest}) and GPT-4V (gpt-4-vision-preview)
models for medical image analysis using two modalities of medical image data.
Utilizing synthetic and real imaging data, both Gemini AI and GPT-4V are first
used to classify real versus synthetic images, followed by an interpretation
and analysis of the input images. Experimental results demonstrate that both
Gemini and GPT-4 could perform some interpretation of the input images. In this
specific experiment, Gemini was able to perform slightly better than the GPT-4V
on the classification task. In contrast, responses associated with GPT-4V were
mostly generic in nature. Our early investigation presented in this work
provides insights into the potential of MLLMs to assist with the classification
and interpretation of retinal fundoscopy and lung X-ray images. We also
identify key limitations associated with the early investigation study on MLLMs
for specialized tasks in medical image analysis.",2024-06-02,2024,2024-06,medical
"Nuclear Medicine Artificial Intelligence in Action: The Bethesda Report
  (AI Summit 2024)","The 2nd SNMMI Artificial Intelligence (AI) Summit, organized by the SNMMI AI
Task Force, took place in Bethesda, MD, on February 29 - March 1, 2024.
Bringing together various community members and stakeholders, and following up
on a prior successful 2022 AI Summit, the summit theme was: AI in Action. Six
key topics included (i) an overview of prior and ongoing efforts by the AI task
force, (ii) emerging needs and tools for computational nuclear oncology, (iii)
new frontiers in large language and generative models, (iv) defining the value
proposition for the use of AI in nuclear medicine, (v) open science including
efforts for data and model repositories, and (vi) issues of reimbursement and
funding. The primary efforts, findings, challenges, and next steps are
summarized in this manuscript.",2024-06-03,2024,2024-06,medical
"Multiple Choice Questions and Large Languages Models: A Case Study with
  Fictional Medical Data","Large Language Models (LLMs) like ChatGPT demonstrate significant potential
in the medical field, often evaluated using multiple-choice questions (MCQs)
similar to those found on the USMLE. Despite their prevalence in medical
education, MCQs have limitations that might be exacerbated when assessing LLMs.
To evaluate the effectiveness of MCQs in assessing the performance of LLMs, we
developed a fictional medical benchmark focused on a non-existent gland, the
Glianorex. This approach allowed us to isolate the knowledge of the LLM from
its test-taking abilities. We used GPT-4 to generate a comprehensive textbook
on the Glianorex in both English and French and developed corresponding
multiple-choice questions in both languages. We evaluated various open-source,
proprietary, and domain-specific LLMs using these questions in a zero-shot
setting. The models achieved average scores around 67%, with minor performance
differences between larger and smaller models. Performance was slightly higher
in English than in French. Fine-tuned medical models showed some improvement
over their base versions in English but not in French. The uniformly high
performance across models suggests that traditional MCQ-based benchmarks may
not accurately measure LLMs' clinical knowledge and reasoning abilities,
instead highlighting their pattern recognition skills. This study underscores
the need for more robust evaluation methods to better assess the true
capabilities of LLMs in medical contexts.",2024-06-04,2024,2024-06,medical
"A Survey on Medical Large Language Models: Technology, Application,
  Trustworthiness, and Future Directions","With the advent of Large Language Models (LLMs), medical artificial
intelligence (AI) has experienced substantial technological progress and
paradigm shifts, highlighting the potential of LLMs to streamline healthcare
delivery and improve patient outcomes. Considering this rapid technical
progress, in this survey, we trace the recent advances of Medical Large
Language Models (Med-LLMs), including the background, key findings, and
mainstream techniques, especially for the evolution from general-purpose models
to medical-specialized applications. Firstly, we delve into the foundational
technology of Med-LLMs, indicating how general models can be progressively
adapted and refined for the complicated medical tasks. Secondly, the
wide-ranging applications of Med-LLMs are investigated across various
healthcare domains, as well as an up-to-date review of existing Med-LLMs. The
transformative impact of these models on daily medical practice is evident
through their ability to assist clinicians, educators, and patients.
Recognizing the importance of responsible innovation, we discuss the challenges
associated with ensuring fairness, accountability, privacy, and robustness.
Ethical considerations, rigorous evaluation methodologies, and the
establishment of regulatory frameworks are crucial for building trustworthiness
in the real-world system. We emphasize the need for ongoing scrutiny and
development to maintain high standards of safety and reliability. Finally, we
anticipate possible future trajectories for Med-LLMs, identifying key avenues
for prudent expansion. By consolidating these insights, our review aims to
provide professionals and researchers with a thorough understanding of the
strengths and limitations of Med-LLMs, fostering a balanced and ethical
approach to their integration into the healthcare ecosystem.",2024-06-06,2024,2024-06,medical
"Transforming Dental Diagnostics with Artificial Intelligence: Advanced
  Integration of ChatGPT and Large Language Models for Patient Care","Artificial intelligence has dramatically reshaped our interaction with
digital technologies, ushering in an era where advancements in AI algorithms
and Large Language Models (LLMs) have natural language processing (NLP) systems
like ChatGPT. This study delves into the impact of cutting-edge LLMs, notably
OpenAI's ChatGPT, on medical diagnostics, with a keen focus on the dental
sector. Leveraging publicly accessible datasets, these models augment the
diagnostic capabilities of medical professionals, streamline communication
between patients and healthcare providers, and enhance the efficiency of
clinical procedures. The advent of ChatGPT-4 is poised to make substantial
inroads into dental practices, especially in the realm of oral surgery. This
paper sheds light on the current landscape and explores potential future
research directions in the burgeoning field of LLMs, offering valuable insights
for both practitioners and developers. Furthermore, it critically assesses the
broad implications and challenges within various sectors, including academia
and healthcare, thus mapping out an overview of AI's role in transforming
dental diagnostics for enhanced patient care.",2024-06-07,2024,2024-06,medical
"Development and Validation of a Deep-Learning Model for Differential
  Treatment Benefit Prediction for Adults with Major Depressive Disorder
  Deployed in the Artificial Intelligence in Depression Medication Enhancement
  (AIDME) Study","INTRODUCTION: The pharmacological treatment of Major Depressive Disorder
(MDD) relies on a trial-and-error approach. We introduce an artificial
intelligence (AI) model aiming to personalize treatment and improve outcomes,
which was deployed in the Artificial Intelligence in Depression Medication
Enhancement (AIDME) Study. OBJECTIVES: 1) Develop a model capable of predicting
probabilities of remission across multiple pharmacological treatments for
adults with at least moderate major depression. 2) Validate model predictions
and examine them for amplification of harmful biases. METHODS: Data from
previous clinical trials of antidepressant medications were standardized into a
common framework and included 9,042 adults with moderate to severe major
depression. Feature selection retained 25 clinical and demographic variables.
Using Bayesian optimization, a deep learning model was trained on the training
set, refined using the validation set, and tested once on the held-out test
set. RESULTS: In the evaluation on the held-out test set, the model
demonstrated achieved an AUC of 0.65. The model outperformed a null model on
the test set (p = 0.01). The model demonstrated clinical utility, achieving an
absolute improvement in population remission rate in hypothetical and actual
improvement testing. While the model did identify one drug (escitalopram) as
generally outperforming the other drugs (consistent with the input data), there
was otherwise significant variation in drug rankings. On bias testing, the
model did not amplify potentially harmful biases. CONCLUSIONS: We demonstrate
the first model capable of predicting outcomes for 10 different treatment
options for patients with MDD, intended to be used at or near the start of
treatment to personalize treatment. The model was put into clinical practice
during the AIDME randomized controlled trial whose results are reported
separately.",2024-06-07,2024,2024-06,medical
Rapid Review of Generative AI in Smart Medical Applications,"With the continuous advancement of technology, artificial intelligence has
significantly impacted various fields, particularly healthcare. Generative
models, a key AI technology, have revolutionized medical image generation, data
analysis, and diagnosis. This article explores their application in intelligent
medical devices. Generative models enhance diagnostic speed and accuracy,
improving medical service quality and efficiency while reducing equipment
costs. These models show great promise in medical image generation, data
analysis, and diagnosis. Additionally, integrating generative models with IoT
technology facilitates real-time data analysis and predictions, offering
smarter healthcare services and aiding in telemedicine. Challenges include
computational demands, ethical concerns, and scenario-specific limitations.",2024-06-08,2024,2024-06,medical
"DeviceBERT: Applied Transfer Learning With Targeted Annotations and
  Vocabulary Enrichment to Identify Medical Device and Component Terminology in
  FDA Recall Summaries","FDA Medical Device recalls are critical and time-sensitive events, requiring
swift identification of impacted devices to inform the public of a recall event
and ensure patient safety. The OpenFDA device recall dataset contains valuable
information about ongoing device recall actions, but manually extracting
relevant device information from the recall action summaries is a
time-consuming task. Named Entity Recognition (NER) is a task in Natural
Language Processing (NLP) that involves identifying and categorizing named
entities in unstructured text. Existing NER models, including domain-specific
models like BioBERT, struggle to correctly identify medical device trade names,
part numbers and component terms within these summaries. To address this, we
propose DeviceBERT, a medical device annotation, pre-processing and enrichment
pipeline, which builds on BioBERT to identify and label medical device
terminology in the device recall summaries with improved accuracy. Furthermore,
we demonstrate that our approach can be applied effectively for performing
entity recognition tasks where training data is limited or sparse.",2024-06-08,2024,2024-06,medical
MedExQA: Medical Question Answering Benchmark with Multiple Explanations,"This paper introduces MedExQA, a novel benchmark in medical
question-answering, to evaluate large language models' (LLMs) understanding of
medical knowledge through explanations. By constructing datasets across five
distinct medical specialties that are underrepresented in current datasets and
further incorporating multiple explanations for each question-answer pair, we
address a major gap in current medical QA benchmarks which is the absence of
comprehensive assessments of LLMs' ability to generate nuanced medical
explanations. Our work highlights the importance of explainability in medical
LLMs, proposes an effective methodology for evaluating models beyond
classification accuracy, and sheds light on one specific domain, speech
language pathology, where current LLMs including GPT4 lack good understanding.
Our results show generation evaluation with multiple explanations aligns better
with human assessment, highlighting an opportunity for a more robust automated
comprehension assessment for LLMs. To diversify open-source medical LLMs
(currently mostly based on Llama2), this work also proposes a new medical
model, MedPhi-2, based on Phi-2 (2.7B). The model outperformed medical LLMs
based on Llama2-70B in generating explanations, showing its effectiveness in
the resource-constrained medical domain. We will share our benchmark datasets
and the trained model.",2024-06-10,2024,2024-06,medical
"Overcoming Limitations in Artificial Intelligence-based Prostate Cancer
  Detection through Better Datasets and a Bayesian Approach to Aggregate Panel
  Predictions","Despite considerable progress in developing artificial intelligence (AI)
algorithms for prostate cancer detection from whole slide images, the clinical
applicability of these models remains limited due to variability in
pathological annotations and existing dataset limitations. This article
proposes a novel approach to overcome these challenges by leveraging a Bayesian
framework to seamlessly integrate new data, and present results as a panel of
annotations. The framework is demonstrated by integrating a Bayesian prior with
one trained AI model to generate a distribution of Gleason patterns for each
pixel of an image. It is shown that using this distribution of Gleason patterns
rather than a ground-truth label can improve model applicability, mitigate
errors, and highlight areas of interest for pathologists. Additionally, we
present a high-quality, hand-curated dataset of prostate histopathological
images annotated at the gland level by trained pre-medical students and
verified by an expert pathologist. We highlight the potential of this adaptive
and uncertainty-aware framework for developing clinically deployable AI tools
that can support pathologists in accurate prostate cancer grading, improve
diagnostic accuracy, and create positive patient outcomes.",2024-06-10,2024,2024-06,medical
"Global AI Governance in Healthcare: A Cross-Jurisdictional Regulatory
  Analysis","Artificial Intelligence (AI) is being adopted across the world and promises a
new revolution in healthcare. While AI-enabled medical devices in North America
dominate 42.3% of the global market, the use of AI-enabled medical devices in
other countries is still a story waiting to be unfolded. We aim to delve deeper
into global regulatory approaches towards AI use in healthcare, with a focus on
how common themes are emerging globally. We compare these themes to the World
Health Organization's (WHO) regulatory considerations and principles on ethical
use of AI for healthcare applications. Our work seeks to take a global
perspective on AI policy by analyzing 14 legal jurisdictions including
countries representative of various regions in the world (North America, South
America, South East Asia, Middle East, Africa, Australia, and the
Asia-Pacific). Our eventual goal is to foster a global conversation on the
ethical use of AI in healthcare and the regulations that will guide it. We
propose solutions to promote international harmonization of AI regulations and
examine the requirements for regulating generative AI, using China and
Singapore as examples of countries with well-developed policies in this area.",2024-06-12,2024,2024-06,medical
"A Survey on Large Language Models from General Purpose to Medical
  Applications: Datasets, Methodologies, and Evaluations","Large Language Models (LLMs) have demonstrated surprising performance across
various natural language processing tasks. Recently, medical LLMs enhanced with
domain-specific knowledge have exhibited excellent capabilities in medical
consultation and diagnosis. These models can smoothly simulate doctor-patient
dialogues and provide professional medical advice. Most medical LLMs are
developed through continued training of open-source general LLMs, which require
significantly fewer computational resources than training LLMs from scratch.
Additionally, this approach offers better patient privacy protection than
API-based solutions. Given the above advantages, this survey systematically
summarizes how to train medical LLMs based on open-source general LLMs from a
more fine-grained perspective. It covers (a) how to acquire training corpus and
construct customized medical training sets, (b) how to choose an appropriate
training paradigm, (c) how to choose a suitable evaluation benchmark, and (d)
existing challenges and promising research directions are discussed. This
survey can provide guidance for the development of LLMs focused on various
medical applications, such as medical education, diagnostic planning, and
clinical assistants. Related resources and supplemental information can be
found on the GitHub repository.",2024-06-14,2024,2024-06,medical
"CliBench: A Multifaceted and Multigranular Evaluation of Large Language
  Models for Clinical Decision Making","The integration of Artificial Intelligence (AI), especially Large Language
Models (LLMs), into the clinical diagnosis process offers significant potential
to improve the efficiency and accessibility of medical care. While LLMs have
shown some promise in the medical domain, their application in clinical
diagnosis remains underexplored, especially in real-world clinical practice,
where highly sophisticated, patient-specific decisions need to be made. Current
evaluations of LLMs in this field are often narrow in scope, focusing on
specific diseases or specialties and employing simplified diagnostic tasks. To
bridge this gap, we introduce CliBench, a novel benchmark developed from the
MIMIC IV dataset, offering a comprehensive and realistic assessment of LLMs'
capabilities in clinical diagnosis. This benchmark not only covers diagnoses
from a diverse range of medical cases across various specialties but also
incorporates tasks of clinical significance: treatment procedure
identification, lab test ordering and medication prescriptions. Supported by
structured output ontologies, CliBench enables a precise and multi-granular
evaluation, offering an in-depth understanding of LLM's capability on diverse
clinical tasks of desired granularity. We conduct a zero-shot evaluation of
leading LLMs to assess their proficiency in clinical decision-making. Our
preliminary results shed light on the potential and limitations of current LLMs
in clinical settings, providing valuable insights for future advancements in
LLM-powered healthcare.",2024-06-14,2024,2024-06,medical
Boosting Medical Image Classification with Segmentation Foundation Model,"The Segment Anything Model (SAM) exhibits impressive capabilities in
zero-shot segmentation for natural images. Recently, SAM has gained a great
deal of attention for its applications in medical image segmentation. However,
to our best knowledge, no studies have shown how to harness the power of SAM
for medical image classification. To fill this gap and make SAM a true
``foundation model'' for medical image analysis, it is highly desirable to
customize SAM specifically for medical image classification. In this paper, we
introduce SAMAug-C, an innovative augmentation method based on SAM for
augmenting classification datasets by generating variants of the original
images. The augmented datasets can be used to train a deep learning
classification model, thereby boosting the classification performance.
Furthermore, we propose a novel framework that simultaneously processes raw and
SAMAug-C augmented image input, capitalizing on the complementary information
that is offered by both. Experiments on three public datasets validate the
effectiveness of our new approach.",2024-06-16,2024,2024-06,medical
"Retrieval-Augmented Generation for Generative Artificial Intelligence in
  Medicine","Generative artificial intelligence (AI) has brought revolutionary innovations
in various fields, including medicine. However, it also exhibits limitations.
In response, retrieval-augmented generation (RAG) provides a potential
solution, enabling models to generate more accurate contents by leveraging the
retrieval of external knowledge. With the rapid advancement of generative AI,
RAG can pave the way for connecting this transformative technology with medical
applications and is expected to bring innovations in equity, reliability, and
personalization to health care.",2024-06-18,2024,2024-06,medical
"Privacy Preserving Federated Learning in Medical Imaging with
  Uncertainty Estimation","Machine learning (ML) and Artificial Intelligence (AI) have fueled remarkable
advancements, particularly in healthcare. Within medical imaging, ML models
hold the promise of improving disease diagnoses, treatment planning, and
post-treatment monitoring. Various computer vision tasks like image
classification, object detection, and image segmentation are poised to become
routine in clinical analysis. However, privacy concerns surrounding patient
data hinder the assembly of large training datasets needed for developing and
training accurate, robust, and generalizable models. Federated Learning (FL)
emerges as a compelling solution, enabling organizations to collaborate on ML
model training by sharing model training information (gradients) rather than
data (e.g., medical images). FL's distributed learning framework facilitates
inter-institutional collaboration while preserving patient privacy. However,
FL, while robust in privacy preservation, faces several challenges. Sensitive
information can still be gleaned from shared gradients that are passed on
between organizations during model training. Additionally, in medical imaging,
quantifying model confidence\uncertainty accurately is crucial due to the noise
and artifacts present in the data. Uncertainty estimation in FL encounters
unique hurdles due to data heterogeneity across organizations. This paper
offers a comprehensive review of FL, privacy preservation, and uncertainty
estimation, with a focus on medical imaging. Alongside a survey of current
research, we identify gaps in the field and suggest future directions for FL
research to enhance privacy and address noisy medical imaging data challenges.",2024-06-18,2024,2024-06,medical
"Aqulia-Med LLM: Pioneering Full-Process Open-Source Medical Language
  Models","Recently, both closed-source LLMs and open-source communities have made
significant strides, outperforming humans in various general domains. However,
their performance in specific professional fields such as medicine, especially
within the open-source community, remains suboptimal due to the complexity of
medical knowledge. We propose Aquila-Med, a bilingual medical LLM based on
Aquila, addressing these challenges through continue pre-training, supervised
fine-tuning (SFT), and reinforcement learning from human feedback (RLHF). We
construct a large-scale Chinese and English medical dataset for continue
pre-training and a high-quality SFT dataset, covering extensive medical
specialties. Additionally, we develop a high-quality Direct Preference
Optimization (DPO) dataset for further alignment. Aquila-Med achieves notable
results across single-turn, multi-turn dialogues, and medical multiple-choice
questions, demonstrating the effectiveness of our approach. We open-source the
datasets and the entire training process, contributing valuable resources to
the research community. Our models and datasets will released at
https://huggingface.co/BAAI/AquilaMed-RL.",2024-06-18,2024,2024-06,medical
Adversarial Attacks on Large Language Models in Medicine,"The integration of Large Language Models (LLMs) into healthcare applications
offers promising advancements in medical diagnostics, treatment
recommendations, and patient care. However, the susceptibility of LLMs to
adversarial attacks poses a significant threat, potentially leading to harmful
outcomes in delicate medical contexts. This study investigates the
vulnerability of LLMs to two types of adversarial attacks in three medical
tasks. Utilizing real-world patient data, we demonstrate that both open-source
and proprietary LLMs are susceptible to manipulation across multiple tasks.
This research further reveals that domain-specific tasks demand more
adversarial data in model fine-tuning than general domain tasks for effective
attack execution, especially for more capable models. We discover that while
integrating adversarial data does not markedly degrade overall model
performance on medical benchmarks, it does lead to noticeable shifts in
fine-tuned model weights, suggesting a potential pathway for detecting and
countering model attacks. This research highlights the urgent need for robust
security measures and the development of defensive mechanisms to safeguard LLMs
in medical applications, to ensure their safe and effective deployment in
healthcare settings.",2024-06-18,2024,2024-06,medical
"Reasoning Like a Doctor: Improving Medical Dialogue Systems via
  Diagnostic Reasoning Process Alignment","Medical dialogue systems have attracted significant attention for their
potential to act as medical assistants. Enabling these medical systems to
emulate clinicians' diagnostic reasoning process has been the long-standing
research focus. Previous studies rudimentarily realized the simulation of
clinicians' diagnostic process by fine-tuning language models on high-quality
dialogue datasets. Nonetheless, they overly focus on the outcomes of the
clinician's reasoning process while ignoring their internal thought processes
and alignment with clinician preferences. Our work aims to build a medical
dialogue system that aligns with clinicians' diagnostic reasoning processes. We
propose a novel framework, Emulation, designed to generate an appropriate
response that relies on abductive and deductive diagnostic reasoning analyses
and aligns with clinician preferences through thought process modeling.
Experimental results on two datasets confirm the efficacy of Emulation.
Crucially, our framework furnishes clear explanations for the generated
responses, enhancing its transparency in medical consultations.",2024-06-20,2024,2024-06,medical
A Data-Driven Guided Decoding Mechanism for Diagnostic Captioning,"Diagnostic Captioning (DC) automatically generates a diagnostic text from one
or more medical images (e.g., X-rays, MRIs) of a patient. Treated as a draft,
the generated text may assist clinicians, by providing an initial estimation of
the patient's condition, speeding up and helping safeguard the diagnostic
process. The accuracy of a diagnostic text, however, strongly depends on how
well the key medical conditions depicted in the images are expressed. We
propose a new data-driven guided decoding method that incorporates medical
information, in the form of existing tags capturing key conditions of the
image(s), into the beam search of the diagnostic text generation process. We
evaluate the proposed method on two medical datasets using four DC systems that
range from generic image-to-text systems with CNN encoders and RNN decoders to
pre-trained Large Language Models. The latter can also be used in few- and
zero-shot learning scenarios. In most cases, the proposed mechanism improves
performance with respect to all evaluation measures. We provide an open-source
implementation of the proposed method at https://github.com/nlpaueb/dmmcs.",2024-06-20,2024,2024-06,medical
Human-AI collectives produce the most accurate differential diagnoses,"Artificial intelligence systems, particularly large language models (LLMs),
are increasingly being employed in high-stakes decisions that impact both
individuals and society at large, often without adequate safeguards to ensure
safety, quality, and equity. Yet LLMs hallucinate, lack common sense, and are
biased - shortcomings that may reflect LLMs' inherent limitations and thus may
not be remedied by more sophisticated architectures, more data, or more human
feedback. Relying solely on LLMs for complex, high-stakes decisions is
therefore problematic. Here we present a hybrid collective intelligence system
that mitigates these risks by leveraging the complementary strengths of human
experience and the vast information processed by LLMs. We apply our method to
open-ended medical diagnostics, combining 40,762 differential diagnoses made by
physicians with the diagnoses of five state-of-the art LLMs across 2,133
medical cases. We show that hybrid collectives of physicians and LLMs
outperform both single physicians and physician collectives, as well as single
LLMs and LLM ensembles. This result holds across a range of medical specialties
and professional experience, and can be attributed to humans' and LLMs'
complementary contributions that lead to different kinds of errors. Our
approach highlights the potential for collective human and machine intelligence
to improve accuracy in complex, open-ended domains like medical diagnostics.",2024-06-21,2024,2024-06,medical
Real-time Speech Summarization for Medical Conversations,"In doctor-patient conversations, identifying medically relevant information
is crucial, posing the need for conversation summarization. In this work, we
propose the first deployable real-time speech summarization system for
real-world applications in industry, which generates a local summary after
every N speech utterances within a conversation and a global summary after the
end of a conversation. Our system could enhance user experience from a business
standpoint, while also reducing computational costs from a technical
perspective. Secondly, we present VietMed-Sum which, to our knowledge, is the
first speech summarization dataset for medical conversations. Thirdly, we are
the first to utilize LLM and human annotators collaboratively to create gold
standard and synthetic summaries for medical conversation summarization.
Finally, we present baseline results of state-of-the-art models on VietMed-Sum.
All code, data (English-translated and Vietnamese) and models are available
online: https://github.com/leduckhai/MultiMed/tree/master/VietMed-Sum",2024-06-22,2024,2024-06,medical
"The Potential and Perils of Generative Artificial Intelligence for
  Quality Improvement and Patient Safety","Generative artificial intelligence (GenAI) has the potential to improve
healthcare through automation that enhances the quality and safety of patient
care. Powered by foundation models that have been pretrained and can generate
complex content, GenAI represents a paradigm shift away from the more
traditional focus on task-specific classifiers that have dominated the AI
landscape thus far. We posit that the imminent application of GenAI in
healthcare will be through well-defined, low risk, high value, and narrow
applications that automate healthcare workflows at the point of care using
smaller foundation models. These models will be finetuned for different
capabilities and application specific scenarios and will have the ability to
provide medical explanations, reference evidence within a retrieval augmented
framework and utilizing external tools. We contrast this with a general,
all-purpose AI model for end-to-end clinical decision making that improves
clinician performance, including safety-critical diagnostic tasks, which will
require greater research prior to implementation. We consider areas where
'human in the loop' Generative AI can improve healthcare quality and safety by
automating mundane tasks. Using the principles of implementation science will
be critical for integrating 'end to end' GenAI systems that will be accepted by
healthcare teams.",2024-06-23,2024,2024-06,medical
"Scalable Artificial Intelligence for Science: Perspectives, Methods and
  Exemplars","In a post-ChatGPT world, this paper explores the potential of leveraging
scalable artificial intelligence for scientific discovery. We propose that
scaling up artificial intelligence on high-performance computing platforms is
essential to address such complex problems. This perspective focuses on
scientific use cases like cognitive simulations, large language models for
scientific inquiry, medical image analysis, and physics-informed approaches.
The study outlines the methodologies needed to address such challenges at scale
on supercomputers or the cloud and provides exemplars of such approaches
applied to solve a variety of scientific problems.",2024-06-24,2024,2024-06,medical
"Assessing the role of clinical summarization and patient chart review
  within communications, medical management, and diagnostics","Effective summarization of unstructured patient data in electronic health
records (EHRs) is crucial for accurate diagnosis and efficient patient care,
yet clinicians often struggle with information overload and time constraints.
This review dives into recent literature and case studies on both the
significant impacts and outstanding issues of patient chart review on
communications, diagnostics, and management. It also discusses recent efforts
to integrate artificial intelligence (AI) into clinical summarization tasks,
and its transformative impact on the clinician's potential, including but not
limited to reductions of administrative burden and improved patient-centered
care.",2024-06-24,2024,2024-06,medical
"Guardrails for avoiding harmful medical product recommendations and
  off-label promotion in generative AI models","Generative AI (GenAI) models have demonstrated remarkable capabilities in a
wide variety of medical tasks. However, as these models are trained using
generalist datasets with very limited human oversight, they can learn uses of
medical products that have not been adequately evaluated for safety and
efficacy, nor approved by regulatory agencies. Given the scale at which GenAI
may reach users, unvetted recommendations pose a public health risk. In this
work, we propose an approach to identify potentially harmful product
recommendations, and demonstrate it using a recent multimodal large language
model.",2024-06-24,2024,2024-06,medical
"MedBench: A Comprehensive, Standardized, and Reliable Benchmarking
  System for Evaluating Chinese Medical Large Language Models","Ensuring the general efficacy and goodness for human beings from medical
large language models (LLM) before real-world deployment is crucial. However, a
widely accepted and accessible evaluation process for medical LLM, especially
in the Chinese context, remains to be established. In this work, we introduce
""MedBench"", a comprehensive, standardized, and reliable benchmarking system for
Chinese medical LLM. First, MedBench assembles the currently largest evaluation
dataset (300,901 questions) to cover 43 clinical specialties and performs
multi-facet evaluation on medical LLM. Second, MedBench provides a standardized
and fully automatic cloud-based evaluation infrastructure, with physical
separations for question and ground truth. Third, MedBench implements dynamic
evaluation mechanisms to prevent shortcut learning and answer remembering.
Applying MedBench to popular general and medical LLMs, we observe unbiased,
reproducible evaluation results largely aligning with medical professionals'
perspectives. This study establishes a significant foundation for preparing the
practical applications of Chinese medical LLMs. MedBench is publicly accessible
at https://medbench.opencompass.org.cn.",2024-06-24,2024,2024-06,medical
"Evaluation of Language Models in the Medical Context Under
  Resource-Constrained Settings","Since the Transformer architecture emerged, language model development has
grown, driven by their promising potential. Releasing these models into
production requires properly understanding their behavior, particularly in
sensitive domains like medicine. Despite this need, the medical literature
still lacks practical assessment of pre-trained language models, which are
especially valuable in settings where only consumer-grade computational
resources are available. To address this gap, we have conducted a comprehensive
survey of language models in the medical field and evaluated a subset of these
for medical text classification and conditional text generation. The subset
includes 53 models with 110 million to 13 billion parameters, spanning the
Transformer-based model families and knowledge domains. Different approaches
are employed for text classification, including zero-shot learning, enabling
tuning without the need to train the model. These approaches are helpful in our
target settings, where many users of language models find themselves. The
results reveal remarkable performance across the tasks and datasets evaluated,
underscoring the potential of certain models to contain medical knowledge, even
without domain specialization. This study thus advocates for further
exploration of model applications in medical contexts, particularly in
computational resource-constrained settings, to benefit a wide range of users.
The code is available on https://github.com/anpoc/Language-models-in-medicine.",2024-06-24,2024,2024-06,medical
"HuatuoGPT-Vision, Towards Injecting Medical Visual Knowledge into
  Multimodal LLMs at Scale","The rapid development of multimodal large language models (MLLMs), such as
GPT-4V, has led to significant advancements. However, these models still face
challenges in medical multimodal capabilities due to limitations in the
quantity and quality of medical vision-text data, stemming from data privacy
concerns and high annotation costs. While pioneering approaches utilize
PubMed's large-scale, de-identified medical image-text pairs to address these
limitations, they still fall short due to inherent data noise. To tackle this,
we refined medical image-text pairs from PubMed and employed MLLMs (GPT-4V) in
an 'unblinded' capacity to denoise and reformat the data, resulting in the
creation of the PubMedVision dataset with 1.3 million medical VQA samples. Our
validation demonstrates that: (1) PubMedVision can significantly enhance the
medical multimodal capabilities of current MLLMs, showing significant
improvement in benchmarks including the MMMU Health & Medicine track; (2)
manual checks by medical experts and empirical results validate the superior
data quality of our dataset compared to other data construction methods. Using
PubMedVision, we train a 34B medical MLLM HuatuoGPT-Vision, which shows
superior performance in medical multimodal scenarios among open-source MLLMs.",2024-06-27,2024,2024-06,medical
"Generative AI for Synthetic Data Across Multiple Medical Modalities: A
  Systematic Review of Recent Developments and Challenges","This paper presents a comprehensive systematic review of generative models
(GANs, VAEs, DMs, and LLMs) used to synthesize various medical data types,
including imaging (dermoscopic, mammographic, ultrasound, CT, MRI, and X-ray),
text, time-series, and tabular data (EHR). Unlike previous narrowly focused
reviews, our study encompasses a broad array of medical data modalities and
explores various generative models. Our search strategy queries databases such
as Scopus, PubMed, and ArXiv, focusing on recent works from January 2021 to
November 2023, excluding reviews and perspectives. This period emphasizes
recent advancements beyond GANs, which have been extensively covered
previously.
  The survey reveals insights from three key aspects: (1) Synthesis
applications and purpose of synthesis, (2) generation techniques, and (3)
evaluation methods. It highlights clinically valid synthesis applications,
demonstrating the potential of synthetic data to tackle diverse clinical
requirements. While conditional models incorporating class labels, segmentation
masks and image translations are prevalent, there is a gap in utilizing prior
clinical knowledge and patient-specific context, suggesting a need for more
personalized synthesis approaches and emphasizing the importance of tailoring
generative approaches to the unique characteristics of medical data.
Additionally, there is a significant gap in using synthetic data beyond
augmentation, such as for validation and evaluation of downstream medical AI
models. The survey uncovers that the lack of standardized evaluation
methodologies tailored to medical images is a barrier to clinical application,
underscoring the need for in-depth evaluation approaches, benchmarking, and
comparative studies to promote openness and collaboration.",2024-06-27,2024,2024-06,medical
"MH-pFLGB: Model Heterogeneous personalized Federated Learning via Global
  Bypass for Medical Image Analysis","In the evolving application of medical artificial intelligence, federated
learning is notable for its ability to protect training data privacy. Federated
learning facilitates collaborative model development without the need to share
local data from healthcare institutions. Yet, the statistical and system
heterogeneity among these institutions poses substantial challenges, which
affects the effectiveness of federated learning and hampers the exchange of
information between clients. To address these issues, we introduce a novel
approach, MH-pFLGB, which employs a global bypass strategy to mitigate the
reliance on public datasets and navigate the complexities of non-IID data
distributions. Our method enhances traditional federated learning by
integrating a global bypass model, which would share the information among the
clients, but also serves as part of the network to enhance the performance on
each client. Additionally, MH-pFLGB provides a feature fusion module to better
combine the local and global features. We validate \model{}'s effectiveness and
adaptability through extensive testing on different medical tasks,
demonstrating superior performance compared to existing state-of-the-art
methods.",2024-06-29,2024,2024-06,medical
"TrialBench: Multi-Modal Artificial Intelligence-Ready Clinical Trial
  Datasets","Clinical trials are pivotal for developing new medical treatments, yet they
typically pose some risks such as patient mortality, adverse events, and
enrollment failure that waste immense efforts spanning over a decade. Applying
artificial intelligence (AI) to forecast or simulate key events in clinical
trials holds great potential for providing insights to guide trial designs.
However, complex data collection and question definition requiring medical
expertise and a deep understanding of trial designs have hindered the
involvement of AI thus far. This paper tackles these challenges by presenting a
comprehensive suite of meticulously curated AIready datasets covering
multi-modal data (e.g., drug molecule, disease code, text,
categorical/numerical features) and 8 crucial prediction challenges in clinical
trial design, encompassing prediction of trial duration, patient dropout rate,
serious adverse event, mortality rate, trial approval outcome, trial failure
reason, drug dose finding, design of eligibility criteria. Furthermore, we
provide basic validation methods for each task to ensure the datasets'
usability and reliability. We anticipate that the availability of such
open-access datasets will catalyze the development of advanced AI approaches
for clinical trial design, ultimately advancing clinical trial research and
accelerating medical solution development. The curated dataset, metrics, and
basic models are publicly available at
https://github.com/ML2Health/ML2ClinicalTrials/tree/main/AI4Trial.",2024-06-30,2024,2024-06,medical
"Evaluation of Bias Towards Medical Professionals in Large Language
  Models","This study evaluates whether large language models (LLMs) exhibit biases
towards medical professionals. Fictitious candidate resumes were created to
control for identity factors while maintaining consistent qualifications. Three
LLMs (GPT-4, Claude-3-haiku, and Mistral-Large) were tested using a
standardized prompt to evaluate resumes for specific residency programs.
Explicit bias was tested by changing gender and race information, while
implicit bias was tested by changing names while hiding race and gender.
Physician data from the Association of American Medical Colleges was used to
compare with real-world demographics. 900,000 resumes were evaluated. All LLMs
exhibited significant gender and racial biases across medical specialties.
Gender preferences varied, favoring male candidates in surgery and orthopedics,
while preferring females in dermatology, family medicine, obstetrics and
gynecology, pediatrics, and psychiatry. Claude-3 and Mistral-Large generally
favored Asian candidates, while GPT-4 preferred Black and Hispanic candidates
in several specialties. Tests revealed strong preferences towards Hispanic
females and Asian males in various specialties. Compared to real-world data,
LLMs consistently chose higher proportions of female and underrepresented
racial candidates than their actual representation in the medical workforce.
GPT-4, Claude-3, and Mistral-Large showed significant gender and racial biases
when evaluating medical professionals for residency selection. These findings
highlight the potential for LLMs to perpetuate biases and compromise healthcare
workforce diversity if used without proper bias mitigation strategies.",2024-06-30,2024,2024-06,medical
"First Place Solution of 2023 Global Artificial Intelligence Technology
  Innovation Competition Track 1","In this paper, we present our champion solution to the Global Artificial
Intelligence Technology Innovation Competition Track 1: Medical Imaging
Diagnosis Report Generation. We select CPT-BASE as our base model for the text
generation task. During the pre-training stage, we delete the mask language
modeling task of CPT-BASE and instead reconstruct the vocabulary, adopting a
span mask strategy and gradually increasing the number of masking ratios to
perform the denoising auto-encoder pre-training task. In the fine-tuning stage,
we design iterative retrieval augmentation and noise-aware similarity bucket
prompt strategies. The retrieval augmentation constructs a mini-knowledge base,
enriching the input information of the model, while the similarity bucket
further perceives the noise information within the mini-knowledge base, guiding
the model to generate higher-quality diagnostic reports based on the similarity
prompts. Surprisingly, our single model has achieved a score of 2.321 on
leaderboard A, and the multiple model fusion scores are 2.362 and 2.320 on the
A and B leaderboards respectively, securing first place in the rankings.",2024-07-01,2024,2024-07,medical
"Hybrid RAG-empowered Multi-modal LLM for Secure Data Management in
  Internet of Medical Things: A Diffusion-based Contract Approach","Secure data management and effective data sharing have become paramount in
the rapidly evolving healthcare landscape, especially with the growing
integration of the Internet of Medical Things (IoMT). The rise of generative
artificial intelligence has further elevated Multi-modal Large Language Models
(MLLMs) as essential tools for managing and optimizing healthcare data in IoMT.
MLLMs can support multi-modal inputs and generate diverse types of content by
leveraging large-scale training on vast amounts of multi-modal data. However,
critical challenges persist in developing medical MLLMs, including security and
freshness issues of healthcare data, affecting the output quality of MLLMs. To
this end, in this paper, we propose a hybrid Retrieval-Augmented Generation
(RAG)-empowered medical MLLM framework for healthcare data management. This
framework leverages a hierarchical cross-chain architecture to facilitate
secure data training. Moreover, it enhances the output quality of MLLMs through
hybrid RAG, which employs multi-modal metrics to filter various unimodal RAG
results and incorporates these retrieval results as additional inputs to MLLMs.
Additionally, we employ age of information to indirectly evaluate the data
freshness impact of MLLMs and utilize contract theory to incentivize healthcare
data holders to share their fresh data, mitigating information asymmetry during
data sharing. Finally, we utilize a generative diffusion model-based deep
reinforcement learning algorithm to identify the optimal contract for efficient
data sharing. Numerical results demonstrate the effectiveness of the proposed
schemes, which achieve secure and efficient healthcare data management.",2024-07-01,2024,2024-07,medical
MMedAgent: Learning to Use Medical Tools with Multi-modal Agent,"Multi-Modal Large Language Models (MLLMs), despite being successful, exhibit
limited generality and often fall short when compared to specialized models.
Recently, LLM-based agents have been developed to address these challenges by
selecting appropriate specialized models as tools based on user inputs.
However, such advancements have not been extensively explored within the
medical domain. To bridge this gap, this paper introduces the first agent
explicitly designed for the medical field, named \textbf{M}ulti-modal
\textbf{Med}ical \textbf{Agent} (MMedAgent). We curate an instruction-tuning
dataset comprising six medical tools solving seven tasks across five
modalities, enabling the agent to choose the most suitable tools for a given
task. Comprehensive experiments demonstrate that MMedAgent achieves superior
performance across a variety of medical tasks compared to state-of-the-art
open-source methods and even the closed-source model, GPT-4o. Furthermore,
MMedAgent exhibits efficiency in updating and integrating new medical tools.
Codes and models are all available.",2024-07-02,2024,2024-07,medical
"FedIA: Federated Medical Image Segmentation with Heterogeneous
  Annotation Completeness","Federated learning has emerged as a compelling paradigm for medical image
segmentation, particularly in light of increasing privacy concerns. However,
most of the existing research relies on relatively stringent assumptions
regarding the uniformity and completeness of annotations across clients.
Contrary to this, this paper highlights a prevalent challenge in medical
practice: incomplete annotations. Such annotations can introduce incorrectly
labeled pixels, potentially undermining the performance of neural networks in
supervised learning. To tackle this issue, we introduce a novel solution, named
FedIA. Our insight is to conceptualize incomplete annotations as noisy data
(i.e., low-quality data), with a focus on mitigating their adverse effects. We
begin by evaluating the completeness of annotations at the client level using a
designed indicator. Subsequently, we enhance the influence of clients with more
comprehensive annotations and implement corrections for incomplete ones,
thereby ensuring that models are trained on accurate data. Our method's
effectiveness is validated through its superior performance on two extensively
used medical image segmentation datasets, outperforming existing solutions. The
code is available at https://github.com/HUSTxyy/FedIA.",2024-07-02,2024,2024-07,medical
"MedVH: Towards Systematic Evaluation of Hallucination for Large Vision
  Language Models in the Medical Context","Large Vision Language Models (LVLMs) have recently achieved superior
performance in various tasks on natural image and text data, which inspires a
large amount of studies for LVLMs fine-tuning and training. Despite their
advancements, there has been scant research on the robustness of these models
against hallucination when fine-tuned on smaller datasets. In this study, we
introduce a new benchmark dataset, the Medical Visual Hallucination Test
(MedVH), to evaluate the hallucination of domain-specific LVLMs. MedVH
comprises five tasks to evaluate hallucinations in LVLMs within the medical
context, which includes tasks for comprehensive understanding of textual and
visual input, as well as long textual response generation. Our extensive
experiments with both general and medical LVLMs reveal that, although medical
LVLMs demonstrate promising performance on standard medical tasks, they are
particularly susceptible to hallucinations, often more so than the general
models, raising significant concerns about the reliability of these
domain-specific models. For medical LVLMs to be truly valuable in real-world
applications, they must not only accurately integrate medical knowledge but
also maintain robust reasoning abilities to prevent hallucination. Our work
paves the way for future evaluations of these studies.",2024-07-03,2024,2024-07,medical
"A Survey on Trustworthiness in Foundation Models for Medical Image
  Analysis","The rapid advancement of foundation models in medical imaging represents a
significant leap toward enhancing diagnostic accuracy and personalized
treatment. However, the deployment of foundation models in healthcare
necessitates a rigorous examination of their trustworthiness, encompassing
privacy, robustness, reliability, explainability, and fairness. The current
body of survey literature on foundation models in medical imaging reveals
considerable gaps, particularly in the area of trustworthiness. Additionally,
existing surveys on the trustworthiness of foundation models do not adequately
address their specific variations and applications within the medical imaging
domain. This survey aims to fill that gap by presenting a novel taxonomy of
foundation models used in medical imaging and analyzing the key motivations for
ensuring their trustworthiness. We review current research on foundation models
in major medical imaging applications, focusing on segmentation, medical report
generation, medical question and answering (Q\&A), and disease diagnosis. These
areas are highlighted because they have seen a relatively mature and
substantial number of foundation models compared to other applications. We
focus on literature that discusses trustworthiness in medical image analysis
manuscripts. We explore the complex challenges of building trustworthy
foundation models for each application, summarizing current concerns and
strategies for enhancing trustworthiness. Furthermore, we examine the potential
of these models to revolutionize patient care. Our analysis underscores the
imperative for advancing towards trustworthy AI in medical image analysis,
advocating for a balanced approach that fosters innovation while ensuring
ethical and equitable healthcare delivery.",2024-07-03,2024,2024-07,medical
"MedPix 2.0: A Comprehensive Multimodal Biomedical Data set for Advanced
  AI Applications","The increasing interest in developing Artificial Intelligence applications in
the medical domain, suffers from the lack of high-quality data set, mainly due
to privacy-related issues. Moreover, the recent rising of Large Multimodal
Models (LMM) leads to a need for multimodal medical data sets, where clinical
reports and findings are attached to the corresponding CT or MR scans. This
paper illustrates the entire workflow for building the data set MedPix 2.0.
Starting from the well-known multimodal data set MedPix, mainly used by
physicians, nurses and healthcare students for Continuing Medical Education
purposes, a semi-automatic pipeline was developed to extract visual and textual
data followed by a manual curing procedure where noisy samples were removed,
thus creating a MongoDB database. Along with the data set, we developed a GUI
aimed at navigating efficiently the MongoDB instance, and obtaining the raw
data that can be easily used for training and/or fine-tuning LMMs. To enforce
this point, we also propose a CLIP-based model trained on MedPix 2.0 for
scanning modality and location classification tasks. MedPix 2.0 is available on
GitHub",2024-07-03,2024,2024-07,medical
"MiniGPT-Med: Large Language Model as a General Interface for Radiology
  Diagnosis","Recent advancements in artificial intelligence (AI) have precipitated
significant breakthroughs in healthcare, particularly in refining diagnostic
procedures. However, previous studies have often been constrained to limited
functionalities. This study introduces MiniGPT-Med, a vision-language model
derived from large-scale language models and tailored for medical applications.
MiniGPT-Med demonstrates remarkable versatility across various imaging
modalities, including X-rays, CT scans, and MRIs, enhancing its utility. The
model is capable of performing tasks such as medical report generation, visual
question answering (VQA), and disease identification within medical imagery.
Its integrated processing of both image and textual clinical data markedly
improves diagnostic accuracy. Our empirical assessments confirm MiniGPT-Med's
superior performance in disease grounding, medical report generation, and VQA
benchmarks, representing a significant step towards reducing the gap in
assisting radiology practice. Furthermore, it achieves state-of-the-art
performance on medical report generation, higher than the previous best model
by 19\% accuracy. MiniGPT-Med promises to become a general interface for
radiology diagnoses, enhancing diagnostic efficiency across a wide range of
medical imaging applications.",2024-07-04,2024,2024-07,medical
"PubTrend: General Overview of Artificial Intelligence for Colorectal
  cancer diagnosis from 2010-2022","Colorectal cancer (CRC) is among the most prevalent cancers in the world. Due
to numerous scholarly papers and broad enquiries about specific use cases for
artificial intelligence (AI) in colorectal cancer, researchers find it
challenging to explore relevant papers on the current knowledge, comprehensive
knowledge, and past methodologies in the literature review. This review
extracts recent AI technology advances for diagnosing colorectal cancer from
January 2010 to March 2022. PubTrends was used to identify and automate the
intellectual structure and comparable papers on the use of AI in colorectal
cancer diagnosis using the most cited papers, keywords, and similar papers.
Papers with quantitative results were represented with a tabular summary, and
other paper contributions were in a sentence summary. Twenty-four (24) out of
the forty-nine (49) top-cited papers were quantitative results, with one (1)
outlier about lung cancer comprehensive screening. The most frequently used
words were: ""polyps,"" ""detected"", ""image,"" and ""colonoscopy."" In addition, 83
per cent of the terms frequently used shortly before 2022 were image, polyps,
detected, colonoscopy, and learning. In addition, 16 per cent are preparation,
variant, classification, sample, and surgery. The review showcases 49 of the 50
most cited papers, their notable contributions, objectives, specific AI
methods, results, conclusions, and further recommendations. These papers
highlight the limitations of colonoscopy for therapeutic use. The review
concluded that despite the enormous benefits of using artificial intelligence,
from improving diagnosis, the medical AI programmer still needs to be actively
involved in the diagnosis team for effective results in CRC diagnosis.",2024-07-06,2024,2024-07,medical
"Integrating AI in College Education: Positive yet Mixed Experiences with
  ChatGPT","The integration of artificial intelligence (AI) chatbots into higher
education marks a shift towards a new generation of pedagogical tools,
mirroring the arrival of milestones like the internet. With the launch of
ChatGPT-4 Turbo in November 2023, we developed a ChatGPT-based teaching
application (https://chat.openai.com/g/g-1imx1py4K-chatge-medical-imaging) and
integrated it into our undergraduate medical imaging course in the Spring 2024
semester. This study investigates the use of ChatGPT throughout a semester-long
trial, providing insights into students' engagement, perception, and the
overall educational effectiveness of the technology. We systematically
collected and analyzed data concerning students' interaction with ChatGPT,
focusing on their attitudes, concerns, and usage patterns. The findings
indicate that ChatGPT offers significant advantages such as improved
information access and increased interactivity, but its adoption is accompanied
by concerns about the accuracy of the information provided and the necessity
for well-defined guidelines to optimize its use.",2024-07-08,2024,2024-07,medical
"Potential of Multimodal Large Language Models for Data Mining of Medical
  Images and Free-text Reports","Medical images and radiology reports are crucial for diagnosing medical
conditions, highlighting the importance of quantitative analysis for clinical
decision-making. However, the diversity and cross-source heterogeneity of these
data challenge the generalizability of current data-mining methods. Multimodal
large language models (MLLMs) have recently transformed many domains,
significantly affecting the medical field. Notably, Gemini-Vision-series
(Gemini) and GPT-4-series (GPT-4) models have epitomized a paradigm shift in
Artificial General Intelligence (AGI) for computer vision, showcasing their
potential in the biomedical domain. In this study, we evaluated the performance
of the Gemini, GPT-4, and 4 popular large models for an exhaustive evaluation
across 14 medical imaging datasets, including 5 medical imaging categories
(dermatology, radiology, dentistry, ophthalmology, and endoscopy), and 3
radiology report datasets. The investigated tasks encompass disease
classification, lesion segmentation, anatomical localization, disease
diagnosis, report generation, and lesion detection. Our experimental results
demonstrated that Gemini-series models excelled in report generation and lesion
detection but faces challenges in disease classification and anatomical
localization. Conversely, GPT-series models exhibited proficiency in lesion
segmentation and anatomical localization but encountered difficulties in
disease diagnosis and lesion detection. Additionally, both the Gemini series
and GPT series contain models that have demonstrated commendable generation
efficiency. While both models hold promise in reducing physician workload,
alleviating pressure on limited healthcare resources, and fostering
collaboration between clinical practitioners and artificial intelligence
technologies, substantial enhancements and comprehensive validations remain
imperative before clinical deployment.",2024-07-08,2024,2024-07,medical
"Promoting AI Competencies for Medical Students: A Scoping Review on
  Frameworks, Programs, and Tools","As more clinical workflows continue to be augmented by artificial
intelligence (AI), AI literacy among physicians will become a critical
requirement for ensuring safe and ethical AI-enabled patient care. Despite the
evolving importance of AI in healthcare, the extent to which it has been
adopted into traditional and often-overloaded medical curricula is currently
unknown. In a scoping review of 1,699 articles published between January 2016
and June 2024, we identified 18 studies which propose guiding frameworks, and
11 studies documenting real-world instruction, centered around the integration
of AI into medical education. We found that comprehensive guidelines will
require greater clinical relevance and personalization to suit medical student
interests and career trajectories. Current efforts highlight discrepancies in
the teaching guidelines, emphasizing AI evaluation and ethics over technical
topics such as data science and coding. Additionally, we identified several
challenges associated with integrating AI training into the medical education
program, including a lack of guidelines to define medical students AI literacy,
a perceived lack of proven clinical value, and a scarcity of qualified
instructors. With this knowledge, we propose an AI literacy framework to define
competencies for medical students. To prioritize relevant and personalized AI
education, we categorize literacy into four dimensions: Foundational,
Practical, Experimental, and Ethical, with tailored learning objectives to the
pre-clinical, clinical, and clinical research stages of medical education. This
review provides a road map for developing practical and relevant education
strategies for building an AI-competent healthcare workforce.",2024-07-10,2024,2024-07,medical
Weakly-supervised Medical Image Segmentation with Gaze Annotations,"Eye gaze that reveals human observational patterns has increasingly been
incorporated into solutions for vision tasks. Despite recent explorations on
leveraging gaze to aid deep networks, few studies exploit gaze as an efficient
annotation approach for medical image segmentation which typically entails
heavy annotating costs. In this paper, we propose to collect dense weak
supervision for medical image segmentation with a gaze annotation scheme. To
train with gaze, we propose a multi-level framework that trains multiple
networks from discriminative human attention, simulated with a set of
pseudo-masks derived by applying hierarchical thresholds on gaze heatmaps.
Furthermore, to mitigate gaze noise, a cross-level consistency is exploited to
regularize overfitting noisy labels, steering models toward clean patterns
learned by peer networks. The proposed method is validated on two public
medical datasets of polyp and prostate segmentation tasks. We contribute a
high-quality gaze dataset entitled GazeMedSeg as an extension to the popular
medical segmentation datasets. To the best of our knowledge, this is the first
gaze dataset for medical image segmentation. Our experiments demonstrate that
gaze annotation outperforms previous label-efficient annotation schemes in
terms of both performance and annotation time. Our collected gaze data and code
are available at: https://github.com/med-air/GazeMedSeg.",2024-07-10,2024,2024-07,medical
"FedMedICL: Towards Holistic Evaluation of Distribution Shifts in
  Federated Medical Imaging","For medical imaging AI models to be clinically impactful, they must
generalize. However, this goal is hindered by (i) diverse types of distribution
shifts, such as temporal, demographic, and label shifts, and (ii) limited
diversity in datasets that are siloed within single medical institutions. While
these limitations have spurred interest in federated learning, current
evaluation benchmarks fail to evaluate different shifts simultaneously.
However, in real healthcare settings, multiple types of shifts co-exist, yet
their impact on medical imaging performance remains unstudied. In response, we
introduce FedMedICL, a unified framework and benchmark to holistically evaluate
federated medical imaging challenges, simultaneously capturing label,
demographic, and temporal distribution shifts. We comprehensively evaluate
several popular methods on six diverse medical imaging datasets (totaling 550
GPU hours). Furthermore, we use FedMedICL to simulate COVID-19 propagation
across hospitals and evaluate whether methods can adapt to pandemic changes in
disease prevalence. We find that a simple batch balancing technique surpasses
advanced methods in average performance across FedMedICL experiments. This
finding questions the applicability of results from previous, narrow benchmarks
in real-world medical settings.",2024-07-11,2024,2024-07,medical
"Explainable artificial intelligence in breast cancer detection and risk
  prediction: A systematic scoping review","With the advances in artificial intelligence (AI), data-driven algorithms are
becoming increasingly popular in the medical domain. However, due to the
nonlinear and complex behavior of many of these algorithms, decision-making by
such algorithms is not trustworthy for clinicians and is considered a black-box
process. Hence, the scientific community has introduced explainable artificial
intelligence (XAI) to remedy the problem. This systematic scoping review
investigates the application of XAI in breast cancer detection and risk
prediction. We conducted a comprehensive search on Scopus, IEEE Explore,
PubMed, and Google Scholar (first 50 citations) using a systematic search
strategy. The search spanned from January 2017 to July 2023, focusing on
peer-reviewed studies implementing XAI methods in breast cancer datasets.
Thirty studies met our inclusion criteria and were included in the analysis.
The results revealed that SHapley Additive exPlanations (SHAP) is the top
model-agnostic XAI technique in breast cancer research in terms of usage,
explaining the model prediction results, diagnosis and classification of
biomarkers, and prognosis and survival analysis. Additionally, the SHAP model
primarily explained tree-based ensemble machine learning models. The most
common reason is that SHAP is model agnostic, which makes it both popular and
useful for explaining any model prediction. Additionally, it is relatively easy
to implement effectively and completely suits performant models, such as
tree-based models. Explainable AI improves the transparency, interpretability,
fairness, and trustworthiness of AI-enabled health systems and medical devices
and, ultimately, the quality of care and outcomes.",2024-07-12,2024,2024-07,medical
"Fine-Tuning Medical Language Models for Enhanced Long-Contextual
  Understanding and Domain Expertise","Large Language Models (LLMs) have been widely applied in various professional
fields. By fine-tuning the models using domain specific question and answer
datasets, the professional domain knowledge and Q\&A abilities of these models
have significantly improved, for example, medical professional LLMs that use
fine-tuning of doctor-patient Q\&A data exhibit extraordinary disease
diagnostic abilities. However, we observed that despite improvements in
specific domain knowledge, the performance of medical LLM in long-context
understanding has significantly declined, especially compared to general
language models with similar parameters. The purpose of this study is to
investigate the phenomenon of reduced performance in understanding long-context
in medical LLM. We designed a series of experiments to conduct open-book
professional knowledge exams on all models to evaluate their ability to read
long-context. By adjusting the proportion and quantity of general data and
medical data in the process of fine-tuning, we can determine the best data
composition to optimize the professional model and achieve a balance between
long-context performance and specific domain knowledge.",2024-07-16,2024,2024-07,medical
"LLMs-in-the-loop Part-1: Expert Small AI Models for Bio-Medical Text
  Translation","Machine translation is indispensable in healthcare for enabling the global
dissemination of medical knowledge across languages. However, complex medical
terminology poses unique challenges to achieving adequate translation quality
and accuracy. This study introduces a novel ""LLMs-in-the-loop"" approach to
develop supervised neural machine translation models optimized specifically for
medical texts. While large language models (LLMs) have demonstrated powerful
capabilities, this research shows that small, specialized models trained on
high-quality in-domain (mostly synthetic) data can outperform even vastly
larger LLMs.
  Custom parallel corpora in six languages were compiled from scientific
articles, synthetically generated clinical documents, and medical texts. Our
LLMs-in-the-loop methodology employs synthetic data generation, rigorous
evaluation, and agent orchestration to enhance performance. We developed small
medical translation models using the MarianMT base model. We introduce a new
medical translation test dataset to standardize evaluation in this domain.
Assessed using BLEU, METEOR, ROUGE, and BERT scores on this test set, our
MarianMT-based models outperform Google Translate, DeepL, and GPT-4-Turbo.
  Results demonstrate that our LLMs-in-the-loop approach, combined with
fine-tuning high-quality, domain-specific data, enables specialized models to
outperform general-purpose and some larger systems. This research, part of a
broader series on expert small models, paves the way for future
healthcare-related AI developments, including deidentification and bio-medical
entity extraction models. Our study underscores the potential of tailored
neural translation models and the LLMs-in-the-loop methodology to advance the
field through improved data generation, evaluation, agent, and modeling
techniques.",2024-07-16,2024,2024-07,medical
"Applying Conditional Generative Adversarial Networks for Imaging
  Diagnosis","This study introduces an innovative application of Conditional Generative
Adversarial Networks (C-GAN) integrated with Stacked Hourglass Networks (SHGN)
aimed at enhancing image segmentation, particularly in the challenging
environment of medical imaging. We address the problem of overfitting, common
in deep learning models applied to complex imaging datasets, by augmenting data
through rotation and scaling. A hybrid loss function combining L1 and L2
reconstruction losses, enriched with adversarial training, is introduced to
refine segmentation processes in intravascular ultrasound (IVUS) imaging. Our
approach is unique in its capacity to accurately delineate distinct regions
within medical images, such as tissue boundaries and vascular structures,
without extensive reliance on domain-specific knowledge. The algorithm was
evaluated using a standard medical image library, showing superior performance
metrics compared to existing methods, thereby demonstrating its potential in
enhancing automated medical diagnostics through deep learning",2024-07-17,2024,2024-07,medical
"Addressing Imbalance for Class Incremental Learning in Medical Image
  Classification","Deep convolutional neural networks have made significant breakthroughs in
medical image classification, under the assumption that training samples from
all classes are simultaneously available. However, in real-world medical
scenarios, there's a common need to continuously learn about new diseases,
leading to the emerging field of class incremental learning (CIL) in the
medical domain. Typically, CIL suffers from catastrophic forgetting when
trained on new classes. This phenomenon is mainly caused by the imbalance
between old and new classes, and it becomes even more challenging with
imbalanced medical datasets. In this work, we introduce two simple yet
effective plug-in methods to mitigate the adverse effects of the imbalance.
First, we propose a CIL-balanced classification loss to mitigate the classifier
bias toward majority classes via logit adjustment. Second, we propose a
distribution margin loss that not only alleviates the inter-class overlap in
embedding space but also enforces the intra-class compactness. We evaluate the
effectiveness of our method with extensive experiments on three benchmark
datasets (CCH5000, HAM10000, and EyePACS). The results demonstrate that our
approach outperforms state-of-the-art methods.",2024-07-18,2024,2024-07,medical
"MedSAGa: Few-shot Memory Efficient Medical Image Segmentation using
  Gradient Low-Rank Projection in SAM","The application of large-scale models in medical image segmentation demands
substantial quantities of meticulously annotated data curated by experts along
with high computational resources, both of which are challenges in
resource-poor settings. In this study, we present the Medical Segment Anything
Model with Galore MedSAGa where we adopt the Segment Anything Model (SAM) to
achieve memory-efficient, few-shot medical image segmentation by applying
Gradient Low-Rank Projection GaLore to the parameters of the image encoder of
SAM. Meanwhile, the weights of the prompt encoder and mask decoder undergo full
parameter fine-tuning using standard optimizers. We further assess MedSAGa's
few-shot learning capabilities, reporting on its memory efficiency and
segmentation performance across multiple standard medical image segmentation
datasets. We compare it with several baseline models, including LoRA fine-tuned
SAM (SAMed) and DAE-Former. Experiments across multiple datasets and these
baseline models with different number of images for fine tuning demonstrated
that the GPU memory consumption of MedSAGa is significantly less than that of
the baseline models, achieving an average memory efficiency of 66% more than
current state-of-the-art (SOTA) models for medical image segmentation. The
combination of substantially lower memory requirements and comparable to SOTA
results in few-shot learning for medical image segmentation positions MedSAGa
as an optimal solution for deployment in resource-constrained settings.",2024-07-21,2024,2024-07,medical
"MiranDa: Mimicking the Learning Processes of Human Doctors to Achieve
  Causal Inference for Medication Recommendation","To enhance therapeutic outcomes from a pharmacological perspective, we
propose MiranDa, designed for medication recommendation, which is the first
actionable model capable of providing the estimated length of stay in hospitals
(ELOS) as counterfactual outcomes that guide clinical practice and model
training. In detail, MiranDa emulates the educational trajectory of doctors
through two gradient-scaling phases shifted by ELOS: an Evidence-based Training
Phase that utilizes supervised learning and a Therapeutic Optimization Phase
grounds in reinforcement learning within the gradient space, explores optimal
medications by perturbations from ELOS. Evaluation of the Medical Information
Mart for Intensive Care III dataset and IV dataset, showcased the superior
results of our model across five metrics, particularly in reducing the ELOS.
Surprisingly, our model provides structural attributes of medication
combinations proved in hyperbolic space and advocated ""procedure-specific""
medication combinations. These findings posit that MiranDa enhanced medication
efficacy. Notably, our paradigm can be applied to nearly all medical tasks and
those with information to evaluate predicted outcomes. The source code of the
MiranDa model is available at https://github.com/azusakou/MiranDa.",2024-07-23,2024,2024-07,medical
Prompt Injection Attacks on Large Language Models in Oncology,"Vision-language artificial intelligence models (VLMs) possess medical
knowledge and can be employed in healthcare in numerous ways, including as
image interpreters, virtual scribes, and general decision support systems.
However, here, we demonstrate that current VLMs applied to medical tasks
exhibit a fundamental security flaw: they can be attacked by prompt injection
attacks, which can be used to output harmful information just by interacting
with the VLM, without any access to its parameters. We performed a quantitative
study to evaluate the vulnerabilities to these attacks in four state of the art
VLMs which have been proposed to be of utility in healthcare: Claude 3 Opus,
Claude 3.5 Sonnet, Reka Core, and GPT-4o. Using a set of N=297 attacks, we show
that all of these models are susceptible. Specifically, we show that embedding
sub-visual prompts in medical imaging data can cause the model to provide
harmful output, and that these prompts are non-obvious to human observers.
Thus, our study demonstrates a key vulnerability in medical VLMs which should
be mitigated before widespread clinical adoption.",2024-07-23,2024,2024-07,medical
"An Active Inference Strategy for Prompting Reliable Responses from Large
  Language Models in Medical Practice","Continuing advances in Large Language Models (LLMs) in artificial
intelligence offer important capacities in intuitively accessing and using
medical knowledge in many contexts, including education and training as well as
assessment and treatment. Most of the initial literature on LLMs in medicine
has emphasized that LLMs are unsuitable for medical use because they are
non-deterministic, may provide incorrect or harmful responses, and cannot be
regulated to assure quality control. If these issues could be corrected,
optimizing LLM technology could benefit patients and physicians by providing
affordable, point-of-care medical knowledge. Our proposed framework refines LLM
responses by restricting their primary knowledge base to domain-specific
datasets containing validated medical information. Additionally, we introduce
an actor-critic LLM prompting protocol based on active inference principles of
human cognition, where a Therapist agent initially responds to patient queries,
and a Supervisor agent evaluates and adjusts responses to ensure accuracy and
reliability. We conducted a validation study where expert cognitive behaviour
therapy for insomnia (CBT-I) therapists evaluated responses from the LLM in a
blind format. Experienced human CBT-I therapists assessed responses to 100
patient queries, comparing LLM-generated responses with appropriate and
inappropriate responses crafted by experienced CBT-I therapists. Results showed
that LLM responses received high ratings from the CBT-I therapists, often
exceeding those of therapist-generated appropriate responses. This structured
approach aims to integrate advanced LLM technology into medical applications,
meeting regulatory requirements for establishing the safe and effective use of
special purpose validated LLMs in medicine.",2024-07-23,2024,2024-07,medical
"Open Challenges on Fairness of Artificial Intelligence in Medical
  Imaging Applications","Recently, the research community of computerized medical imaging has started
to discuss and address potential fairness issues that may emerge when
developing and deploying AI systems for medical image analysis. This chapter
covers some of the pressing challenges encountered when doing research in this
area, and it is intended to raise questions and provide food for thought for
those aiming to enter this research field. The chapter first discusses various
sources of bias, including data collection, model training, and clinical
deployment, and their impact on the fairness of machine learning algorithms in
medical image computing. We then turn to discussing open challenges that we
believe require attention from researchers and practitioners, as well as
potential pitfalls of naive application of common methods in the field. We
cover a variety of topics including the impact of biased metrics when auditing
for fairness, the leveling down effect, task difficulty variations among
subgroups, discovering biases in unseen populations, and explaining biases
beyond standard demographic attributes.",2024-07-24,2024,2024-07,medical
Yucca: A Deep Learning Framework For Medical Image Analysis,"Medical image analysis using deep learning frameworks has advanced healthcare
by automating complex tasks, but many existing frameworks lack flexibility,
modularity, and user-friendliness. To address these challenges, we introduce
Yucca, an open-source AI framework available at
https://github.com/Sllambias/yucca, designed specifically for medical imaging
applications and built on PyTorch and PyTorch Lightning. Yucca features a
three-tiered architecture: Functional, Modules, and Pipeline, providing a
comprehensive and customizable solution. Evaluated across diverse tasks such as
cerebral microbleeds detection, white matter hyperintensity segmentation, and
hippocampus segmentation, Yucca achieves state-of-the-art results,
demonstrating its robustness and versatility. Yucca offers a powerful,
flexible, and user-friendly platform for medical image analysis, inviting
community contributions to advance its capabilities and impact.",2024-07-29,2024,2024-07,medical
Robust Conformal Volume Estimation in 3D Medical Images,"Volumetry is one of the principal downstream applications of 3D medical image
segmentation, for example, to detect abnormal tissue growth or for surgery
planning. Conformal Prediction is a promising framework for uncertainty
quantification, providing calibrated predictive intervals associated with
automatic volume measurements. However, this methodology is based on the
hypothesis that calibration and test samples are exchangeable, an assumption
that is in practice often violated in medical image applications. A weighted
formulation of Conformal Prediction can be framed to mitigate this issue, but
its empirical investigation in the medical domain is still lacking. A potential
reason is that it relies on the estimation of the density ratio between the
calibration and test distributions, which is likely to be intractable in
scenarios involving high-dimensional data. To circumvent this, we propose an
efficient approach for density ratio estimation relying on the compressed
latent representations generated by the segmentation model. Our experiments
demonstrate the efficiency of our approach to reduce the coverage error in the
presence of covariate shifts, in both synthetic and real-world settings. Our
implementation is available at https://github.com/benolmbrt/wcp_miccai",2024-07-29,2024,2024-07,medical
"S-SYNTH: Knowledge-Based, Synthetic Generation of Skin Images","Development of artificial intelligence (AI) techniques in medical imaging
requires access to large-scale and diverse datasets for training and
evaluation. In dermatology, obtaining such datasets remains challenging due to
significant variations in patient populations, illumination conditions, and
acquisition system characteristics. In this work, we propose S-SYNTH, the first
knowledge-based, adaptable open-source skin simulation framework to rapidly
generate synthetic skin, 3D models and digitally rendered images, using an
anatomically inspired multi-layer, multi-component skin and growing lesion
model. The skin model allows for controlled variation in skin appearance, such
as skin color, presence of hair, lesion shape, and blood fraction among other
parameters. We use this framework to study the effect of possible variations on
the development and evaluation of AI models for skin lesion segmentation, and
show that results obtained using synthetic data follow similar comparative
trends as real dermatologic images, while mitigating biases and limitations
from existing datasets including small dataset size, lack of diversity, and
underrepresentation.",2024-07-31,2024,2024-07,medical
"Enhanced Uncertainty Estimation in Ultrasound Image Segmentation with
  MSU-Net","Efficient intravascular access in trauma and critical care significantly
impacts patient outcomes. However, the availability of skilled medical
personnel in austere environments is often limited. Autonomous robotic
ultrasound systems can aid in needle insertion for medication delivery and
support non-experts in such tasks. Despite advances in autonomous needle
insertion, inaccuracies in vessel segmentation predictions pose risks.
Understanding the uncertainty of predictive models in ultrasound imaging is
crucial for assessing their reliability. We introduce MSU-Net, a novel
multistage approach for training an ensemble of U-Nets to yield accurate
ultrasound image segmentation maps. We demonstrate substantial improvements,
18.1% over a single Monte Carlo U-Net, enhancing uncertainty evaluations, model
transparency, and trustworthiness. By highlighting areas of model certainty,
MSU-Net can guide safe needle insertions, empowering non-experts to accomplish
such tasks.",2024-07-31,2024,2024-07,medical
"MIST: A Simple and Scalable End-To-End 3D Medical Imaging Segmentation
  Framework","Medical imaging segmentation is a highly active area of research, with deep
learning-based methods achieving state-of-the-art results in several
benchmarks. However, the lack of standardized tools for training, testing, and
evaluating new methods makes the comparison of methods difficult. To address
this, we introduce the Medical Imaging Segmentation Toolkit (MIST), a simple,
modular, and end-to-end medical imaging segmentation framework designed to
facilitate consistent training, testing, and evaluation of deep learning-based
medical imaging segmentation methods. MIST standardizes data analysis,
preprocessing, and evaluation pipelines, accommodating multiple architectures
and loss functions. This standardization ensures reproducible and fair
comparisons across different methods. We detail MIST's data format
requirements, pipelines, and auxiliary features and demonstrate its efficacy
using the BraTS Adult Glioma Post-Treatment Challenge dataset. Our results
highlight MIST's ability to produce accurate segmentation masks and its
scalability across multiple GPUs, showcasing its potential as a powerful tool
for future medical imaging research and development.",2024-07-31,2024,2024-07,medical
"Advancing Medical Image Segmentation: Morphology-Driven Learning with
  Diffusion Transformer","Understanding the morphological structure of medical images and precisely
segmenting the region of interest or abnormality is an important task that can
assist in diagnosis. However, the unique properties of medical imaging make
clear segmentation difficult,and the high cost and time-consuming task of
labeling leads to a coarse-grained representation of ground truth. Facing with
these problems, we propose a novel Diffusion Transformer Segmentation (DTS)
model for robust segmentation in the presence of noise. We propose an
alternative to the dominant Denoising U-Net encoder through experiments
applying a transformer architecture, which captures global dependency through
self-attention. Additionally, we propose k-neighbor label smoothing, reverse
boundary attention, and self-supervised learning with morphology-driven
learning to improve the ability to identify complex structures. Our model,
which analyzes the morphological representation of images, shows better results
than the previous models in various medical imaging modalities, including CT,
MRI, and lesion images.",2024-08-01,2024,2024-08,medical
"Securing the Diagnosis of Medical Imaging: An In-depth Analysis of
  AI-Resistant Attacks","Machine learning (ML) is a rapidly developing area of medicine that uses
significant resources to apply computer science and statistics to medical
issues. ML's proponents laud its capacity to handle vast, complicated, and
erratic medical data. It's common knowledge that attackers might cause
misclassification by deliberately creating inputs for machine learning
classifiers. Research on adversarial examples has been extensively conducted in
the field of computer vision applications. Healthcare systems are thought to be
highly difficult because of the security and life-or-death considerations they
include, and performance accuracy is very important. Recent arguments have
suggested that adversarial attacks could be made against medical image analysis
(MedIA) technologies because of the accompanying technology infrastructure and
powerful financial incentives. Since the diagnosis will be the basis for
important decisions, it is essential to assess how strong medical DNN tasks are
against adversarial attacks. Simple adversarial attacks have been taken into
account in several earlier studies. However, DNNs are susceptible to more risky
and realistic attacks. The present paper covers recent proposed adversarial
attack strategies against DNNs for medical imaging as well as countermeasures.
In this study, we review current techniques for adversarial imaging attacks,
detections. It also encompasses various facets of these techniques and offers
suggestions for the robustness of neural networks to be improved in the future.",2024-08-01,2024,2024-08,medical
"More Than Positive and Negative: Communicating Fine Granularity in
  Medical Diagnosis","With the advance of deep learning, much progress has been made in building
powerful artificial intelligence (AI) systems for automatic Chest X-ray (CXR)
analysis. Most existing AI models are trained to be a binary classifier with
the aim of distinguishing positive and negative cases. However, a large gap
exists between the simple binary setting and complicated real-world medical
scenarios. In this work, we reinvestigate the problem of automatic radiology
diagnosis. We first observe that there is considerable diversity among cases
within the positive class, which means simply classifying them as positive
loses many important details. This motivates us to build AI models that can
communicate fine-grained knowledge from medical images like human experts. To
this end, we first propose a new benchmark on fine granularity learning from
medical images. Specifically, we devise a division rule based on medical
knowledge to divide positive cases into two subcategories, namely atypical
positive and typical positive. Then, we propose a new metric termed
AUC$^\text{FG}$ on the two subcategories for evaluation of the ability to
separate them apart. With the proposed benchmark, we encourage the community to
develop AI diagnosis systems that could better learn fine granularity from
medical images. Last, we propose a simple risk modulation approach to this
problem by only using coarse labels in training. Empirical results show that
despite its simplicity, the proposed method achieves superior performance and
thus serves as a strong baseline.",2024-08-05,2024,2024-08,medical
"Enhancing Healthcare through Large Language Models: A Study on Medical
  Question Answering","In recent years, the application of Large Language Models (LLMs) in
healthcare has shown significant promise in improving the accessibility and
dissemination of medical knowledge. This paper presents a detailed study of
various LLMs trained on the MedQuAD medical question-answering dataset, with a
focus on identifying the most effective model for providing accurate medical
information. Among the models tested, the Sentence-t5 combined with Mistral 7B
demonstrated superior performance, achieving a precision score of 0.762. This
model's enhanced capabilities are attributed to its advanced pretraining
techniques, robust architecture, and effective prompt construction
methodologies. By leveraging these strengths, the Sentence-t5 + Mistral 7B
model excels in understanding and generating precise medical answers. Our
findings highlight the potential of integrating sophisticated LLMs in medical
contexts to facilitate efficient and accurate medical knowledge retrieval, thus
significantly enhancing patient education and support.",2024-08-08,2024,2024-08,medical
"People over trust AI-generated medical responses and view them to be as
  valid as doctors, despite low accuracy","This paper presents a comprehensive analysis of how AI-generated medical
responses are perceived and evaluated by non-experts. A total of 300
participants gave evaluations for medical responses that were either written by
a medical doctor on an online healthcare platform, or generated by a large
language model and labeled by physicians as having high or low accuracy.
Results showed that participants could not effectively distinguish between
AI-generated and Doctors' responses and demonstrated a preference for
AI-generated responses, rating High Accuracy AI-generated responses as
significantly more valid, trustworthy, and complete/satisfactory. Low Accuracy
AI-generated responses on average performed very similar to Doctors' responses,
if not more. Participants not only found these low-accuracy AI-generated
responses to be valid, trustworthy, and complete/satisfactory but also
indicated a high tendency to follow the potentially harmful medical advice and
incorrectly seek unnecessary medical attention as a result of the response
provided. This problematic reaction was comparable if not more to the reaction
they displayed towards doctors' responses. This increased trust placed on
inaccurate or inappropriate AI-generated medical advice can lead to
misdiagnosis and harmful consequences for individuals seeking help. Further,
participants were more trusting of High Accuracy AI-generated responses when
told they were given by a doctor and experts rated AI-generated responses
significantly higher when the source of the response was unknown. Both experts
and non-experts exhibited bias, finding AI-generated responses to be more
thorough and accurate than Doctors' responses but still valuing the involvement
of a Doctor in the delivery of their medical advice. Ensuring AI systems are
implemented with medical professionals should be the future of using AI for the
delivery of medical advice.",2024-08-11,2024,2024-08,medical
"Automated Retinal Image Analysis and Medical Report Generation through
  Deep Learning","The increasing prevalence of retinal diseases poses a significant challenge
to the healthcare system, as the demand for ophthalmologists surpasses the
available workforce. This imbalance creates a bottleneck in diagnosis and
treatment, potentially delaying critical care. Traditional methods of
generating medical reports from retinal images rely on manual interpretation,
which is time-consuming and prone to errors, further straining
ophthalmologists' limited resources. This thesis investigates the potential of
Artificial Intelligence (AI) to automate medical report generation for retinal
images. AI can quickly analyze large volumes of image data, identifying subtle
patterns essential for accurate diagnosis. By automating this process, AI
systems can greatly enhance the efficiency of retinal disease diagnosis,
reducing doctors' workloads and enabling them to focus on more complex cases.
The proposed AI-based methods address key challenges in automated report
generation: (1) Improved methods for medical keyword representation enhance the
system's ability to capture nuances in medical terminology; (2) A multi-modal
deep learning approach captures interactions between textual keywords and
retinal images, resulting in more comprehensive medical reports; (3) Techniques
to enhance the interpretability of the AI-based report generation system,
fostering trust and acceptance in clinical practice. These methods are
rigorously evaluated using various metrics and achieve state-of-the-art
performance. This thesis demonstrates AI's potential to revolutionize retinal
disease diagnosis by automating medical report generation, ultimately improving
clinical efficiency, diagnostic accuracy, and patient care.
[https://github.com/Jhhuangkay/DeepOpht-Medical-Report-Generation-for-Retinal-Images-via-Deep-Models-and-Visual-Explanation]",2024-08-14,2024,2024-08,medical
"Navigating Data Scarcity using Foundation Models: A Benchmark of
  Few-Shot and Zero-Shot Learning Approaches in Medical Imaging","Data scarcity is a major limiting factor for applying modern machine learning
techniques to clinical tasks. Although sufficient data exists for some
well-studied medical tasks, there remains a long tail of clinically relevant
tasks with poor data availability. Recently, numerous foundation models have
demonstrated high suitability for few-shot learning (FSL) and zero-shot
learning (ZSL), potentially making them more accessible to practitioners.
However, it remains unclear which foundation model performs best on FSL medical
image analysis tasks and what the optimal methods are for learning from limited
data. We conducted a comprehensive benchmark study of ZSL and FSL using 16
pretrained foundation models on 19 diverse medical imaging datasets. Our
results indicate that BiomedCLIP, a model pretrained exclusively on medical
data, performs best on average for very small training set sizes, while very
large CLIP models pretrained on LAION-2B perform best with slightly more
training samples. However, simply fine-tuning a ResNet-18 pretrained on
ImageNet performs similarly with more than five training examples per class.
Our findings also highlight the need for further research on foundation models
specifically tailored for medical applications and the collection of more
datasets to train these models.",2024-08-15,2024,2024-08,medical
"A Disease-Specific Foundation Model Using Over 100K Fundus Images:
  Release and Validation for Abnormality and Multi-Disease Classification on
  Downstream Tasks","Artificial intelligence applied to retinal images offers significant
potential for recognizing signs and symptoms of retinal conditions and
expediting the diagnosis of eye diseases and systemic disorders. However,
developing generalized artificial intelligence models for medical data often
requires a large number of labeled images representing various disease signs,
and most models are typically task-specific, focusing on major retinal
diseases. In this study, we developed a Fundus-Specific Pretrained Model
(Image+Fundus), a supervised artificial intelligence model trained to detect
abnormalities in fundus images. A total of 57,803 images were used to develop
this pretrained model, which achieved superior performance across various
downstream tasks, indicating that our proposed model outperforms other general
methods. Our Image+Fundus model offers a generalized approach to improve model
performance while reducing the number of labeled datasets required.
Additionally, it provides more disease-specific insights into fundus images,
with visualizations generated by our model. These disease-specific foundation
models are invaluable in enhancing the performance and efficiency of deep
learning models in the field of fundus imaging.",2024-08-16,2024,2024-08,medical
"FEDKIM: Adaptive Federated Knowledge Injection into Medical Foundation
  Models","Foundation models have demonstrated remarkable capabilities in handling
diverse modalities and tasks, outperforming conventional artificial
intelligence (AI) approaches that are highly task-specific and
modality-reliant. In the medical domain, however, the development of
comprehensive foundation models is constrained by limited access to diverse
modalities and stringent privacy regulations. To address these constraints,
this study introduces a novel knowledge injection approach, FedKIM, designed to
scale the medical foundation model within a federated learning framework.
FedKIM leverages lightweight local models to extract healthcare knowledge from
private data and integrates this knowledge into a centralized foundation model
using a designed adaptive Multitask Multimodal Mixture Of Experts (M3OE)
module. This method not only preserves privacy but also enhances the model's
ability to handle complex medical tasks involving multiple modalities. Our
extensive experiments across twelve tasks in seven modalities demonstrate the
effectiveness of FedKIM in various settings, highlighting its potential to
scale medical foundation models without direct access to sensitive data.",2024-08-17,2024,2024-08,medical
"FEDMEKI: A Benchmark for Scaling Medical Foundation Models via Federated
  Knowledge Injection","This study introduces the Federated Medical Knowledge Injection (FEDMEKI)
platform, a new benchmark designed to address the unique challenges of
integrating medical knowledge into foundation models under privacy constraints.
By leveraging a cross-silo federated learning approach, FEDMEKI circumvents the
issues associated with centralized data collection, which is often prohibited
under health regulations like the Health Insurance Portability and
Accountability Act (HIPAA) in the USA. The platform is meticulously designed to
handle multi-site, multi-modal, and multi-task medical data, which includes 7
medical modalities, including images, signals, texts, laboratory test results,
vital signs, input variables, and output variables. The curated dataset to
validate FEDMEKI covers 8 medical tasks, including 6 classification tasks (lung
opacity detection, COVID-19 detection, electrocardiogram (ECG) abnormal
detection, mortality prediction, sepsis prediction, and enlarged
cardiomediastinum detection) and 2 generation tasks (medical visual question
answering (MedVQA) and ECG noise clarification). This comprehensive dataset is
partitioned across several clients to facilitate the decentralized training
process under 16 benchmark approaches. FEDMEKI not only preserves data privacy
but also enhances the capability of medical foundation models by allowing them
to learn from a broader spectrum of medical knowledge without direct data
exposure, thereby setting a new benchmark in the application of foundation
models within the healthcare sector.",2024-08-17,2024,2024-08,medical
"Tipta uzmanlik sinavinda (tus) buyuk dil modelleri insanlardan daha mi
  basarili?","The potential of artificial intelligence in medical education and assessment
has been made evident by recent developments in natural language processing and
artificial intelligence. Medical questions can now be successfully answered by
artificial intelligence algorithms. It can help medical practitioners. This
study evaluates the performance of three different artificial intelligence
models in answering Turkish medical questions in the 2021 1st Term Medical
Specialization Examination (MSE). MSE consists of a total of 240 questions
across clinical (CMST) and basic (BMST) medical sciences. According to the
results in CMST, it was concluded that Gemini correctly answered 82 questions,
ChatGPT-4 answered 105 questions and ChatGPT-4o answered 117 questions. In
BMST, Gemini and ChatGPT-4 answered 93 questions and ChatGPT-4o answered 107
questions correctly according to the answer key. ChatGPT-4o outperformed the
candidate with the highest scores of 113 and 106 according to CMST and BMST
respectively. This study highlights the importance of the potential of
artificial intelligence in medical education and assessment. It demonstrates
that advanced models can achieve high accuracy and contextual understanding,
demonstrating their potential role in medical education and evaluation.",2024-08-22,2024,2024-08,medical
MultiMed: Massively Multimodal and Multitask Medical Understanding,"Biomedical data is inherently multimodal, consisting of electronic health
records, medical imaging, digital pathology, genome sequencing, wearable
sensors, and more. The application of artificial intelligence tools to these
multifaceted sensing technologies has the potential to revolutionize the
prognosis, diagnosis, and management of human health and disease. However,
current approaches to biomedical AI typically only train and evaluate with one
or a small set of medical modalities and tasks. This limitation hampers the
development of comprehensive tools that can leverage the rich interconnected
information across many heterogeneous biomedical sensors. To address this
challenge, we present MultiMed, a benchmark designed to evaluate and enable
large-scale learning across a wide spectrum of medical modalities and tasks.
MultiMed consists of 2.56 million samples across ten medical modalities such as
medical reports, pathology, genomics, and protein data, and is structured into
eleven challenging tasks, including disease prognosis, protein structure
prediction, and medical question answering. Using MultiMed, we conduct
comprehensive experiments benchmarking state-of-the-art unimodal, multimodal,
and multitask models. Our analysis highlights the advantages of training
large-scale medical models across many related modalities and tasks. Moreover,
MultiMed enables studies of generalization across related medical concepts,
robustness to real-world noisy data and distribution shifts, and novel modality
combinations to improve prediction performance. MultiMed will be publicly
available and regularly updated and welcomes inputs from the community.",2024-08-22,2024,2024-08,medical
"MedDiT: A Knowledge-Controlled Diffusion Transformer Framework for
  Dynamic Medical Image Generation in Virtual Simulated Patient","Medical education relies heavily on Simulated Patients (SPs) to provide a
safe environment for students to practice clinical skills, including medical
image analysis. However, the high cost of recruiting qualified SPs and the lack
of diverse medical imaging datasets have presented significant challenges. To
address these issues, this paper introduces MedDiT, a novel
knowledge-controlled conversational framework that can dynamically generate
plausible medical images aligned with simulated patient symptoms, enabling
diverse diagnostic skill training. Specifically, MedDiT integrates various
patient Knowledge Graphs (KGs), which describe the attributes and symptoms of
patients, to dynamically prompt Large Language Models' (LLMs) behavior and
control the patient characteristics, mitigating hallucination during medical
conversation. Additionally, a well-tuned Diffusion Transformer (DiT) model is
incorporated to generate medical images according to the specified patient
attributes in the KG. In this paper, we present the capabilities of MedDiT
through a practical demonstration, showcasing its ability to act in diverse
simulated patient cases and generate the corresponding medical images. This can
provide an abundant and interactive learning experience for students, advancing
medical education by offering an immersive simulation platform for future
healthcare professionals. The work sheds light on the feasibility of
incorporating advanced technologies like LLM, KG, and DiT in education
applications, highlighting their potential to address the challenges faced in
simulated patient-based medical education.",2024-08-22,2024,2024-08,medical
MEDCO: Medical Education Copilots Based on A Multi-Agent Framework,"Large language models (LLMs) have had a significant impact on diverse
research domains, including medicine and healthcare. However, the potential of
LLMs as copilots in medical education remains underexplored. Current
AI-assisted educational tools are limited by their solitary learning approach
and inability to simulate the multi-disciplinary and interactive nature of
actual medical training. To address these limitations, we propose MEDCO
(Medical EDucation COpilots), a novel multi-agent-based copilot system
specially developed to emulate real-world medical training environments. MEDCO
incorporates three primary agents: an agentic patient, an expert doctor, and a
radiologist, facilitating a multi-modal and interactive learning environment.
Our framework emphasizes the learning of proficient question-asking skills,
multi-disciplinary collaboration, and peer discussions between students. Our
experiments show that simulated virtual students who underwent training with
MEDCO not only achieved substantial performance enhancements comparable to
those of advanced models, but also demonstrated human-like learning behaviors
and improvements, coupled with an increase in the number of learning samples.
This work contributes to medical education by introducing a copilot that
implements an interactive and collaborative learning approach. It also provides
valuable insights into the effectiveness of AI-integrated training paradigms.",2024-08-22,2024,2024-08,medical
Automatic Medical Report Generation: Methods and Applications,"The increasing demand for medical imaging has surpassed the capacity of
available radiologists, leading to diagnostic delays and potential
misdiagnoses. Artificial intelligence (AI) techniques, particularly in
automatic medical report generation (AMRG), offer a promising solution to this
dilemma. This review comprehensively examines AMRG methods from 2021 to 2024.
It (i) presents solutions to primary challenges in this field, (ii) explores
AMRG applications across various imaging modalities, (iii) introduces publicly
available datasets, (iv) outlines evaluation metrics, (v) identifies techniques
that significantly enhance model performance, and (vi) discusses unresolved
issues and potential future research directions. This paper aims to provide a
comprehensive understanding of the existing literature and inspire valuable
future research.",2024-08-26,2024,2024-08,medical
"MEDSAGE: Enhancing Robustness of Medical Dialogue Summarization to ASR
  Errors with LLM-generated Synthetic Dialogues","Automatic Speech Recognition (ASR) systems are pivotal in transcribing speech
into text, yet the errors they introduce can significantly degrade the
performance of downstream tasks like summarization. This issue is particularly
pronounced in clinical dialogue summarization, a low-resource domain where
supervised data for fine-tuning is scarce, necessitating the use of ASR models
as black-box solutions. Employing conventional data augmentation for enhancing
the noise robustness of summarization models is not feasible either due to the
unavailability of sufficient medical dialogue audio recordings and
corresponding ASR transcripts. To address this challenge, we propose MEDSAGE,
an approach for generating synthetic samples for data augmentation using Large
Language Models (LLMs). Specifically, we leverage the in-context learning
capabilities of LLMs and instruct them to generate ASR-like errors based on a
few available medical dialogue examples with audio recordings. Experimental
results show that LLMs can effectively model ASR noise, and incorporating this
noisy data into the training process significantly improves the robustness and
accuracy of medical dialogue summarization systems. This approach addresses the
challenges of noisy ASR outputs in critical applications, offering a robust
solution to enhance the reliability of clinical dialogue summarization.",2024-08-26,2024,2024-08,medical
"Aligning XAI with EU Regulations for Smart Biomedical Devices: A
  Methodology for Compliance Analysis","Significant investment and development have gone into integrating Artificial
Intelligence (AI) in medical and healthcare applications, leading to advanced
control systems in medical technology. However, the opacity of AI systems
raises concerns about essential characteristics needed in such sensitive
applications, like transparency and trustworthiness. Our study addresses these
concerns by investigating a process for selecting the most adequate Explainable
AI (XAI) methods to comply with the explanation requirements of key EU
regulations in the context of smart bioelectronics for medical devices. The
adopted methodology starts with categorising smart devices by their control
mechanisms (open-loop, closed-loop, and semi-closed-loop systems) and delving
into their technology. Then, we analyse these regulations to define their
explainability requirements for the various devices and related goals.
Simultaneously, we classify XAI methods by their explanatory objectives. This
allows for matching legal explainability requirements with XAI explanatory
goals and determining the suitable XAI algorithms for achieving them. Our
findings provide a nuanced understanding of which XAI algorithms align better
with EU regulations for different types of medical devices. We demonstrate this
through practical case studies on different neural implants, from chronic
disease management to advanced prosthetics. This study fills a crucial gap in
aligning XAI applications in bioelectronics with stringent provisions of EU
regulations. It provides a practical framework for developers and researchers,
ensuring their AI innovations advance healthcare technology and adhere to legal
and ethical standards.",2024-08-27,2024,2024-08,medical
"Disease Classification and Impact of Pretrained Deep Convolution Neural
  Networks on Diverse Medical Imaging Datasets across Imaging Modalities","Imaging techniques such as Chest X-rays, whole slide images, and optical
coherence tomography serve as the initial screening and detection for a wide
variety of medical pulmonary and ophthalmic conditions respectively. This paper
investigates the intricacies of using pretrained deep convolutional neural
networks with transfer learning across diverse medical imaging datasets with
varying modalities for binary and multiclass classification. We conducted a
comprehensive performance analysis with ten network architectures and model
families each with pretraining and random initialization. Our finding showed
that the use of pretrained models as fixed feature extractors yields poor
performance irrespective of the datasets. Contrary, histopathology microscopy
whole slide images have better performance. It is also found that deeper and
more complex architectures did not necessarily result in the best performance.
This observation implies that the improvements in ImageNet are not parallel to
the medical imaging tasks. Within a medical domain, the performance of the
network architectures varies within model families with shifts in datasets.
This indicates that the performance of models within a specific modality may
not be conclusive for another modality within the same domain. This study
provides a deeper understanding of the applications of deep learning techniques
in medical imaging and highlights the impact of pretrained networks across
different medical imaging datasets under five different experimental settings.",2024-08-30,2024,2024-08,medical
Medical Report Generation Is A Multi-label Classification Problem,"Medical report generation is a critical task in healthcare that involves the
automatic creation of detailed and accurate descriptions from medical images.
Traditionally, this task has been approached as a sequence generation problem,
relying on vision-and-language techniques to generate coherent and contextually
relevant reports. However, in this paper, we propose a novel perspective:
rethinking medical report generation as a multi-label classification problem.
By framing the task this way, we leverage the radiology nodes from the commonly
used knowledge graph, which can be better captured through classification
techniques. To verify our argument, we introduce a novel report generation
framework based on BLIP integrated with classified key nodes, which allows for
effective report generation with accurate classification of multiple key
aspects within the medical images. This approach not only simplifies the report
generation process but also significantly enhances performance metrics. Our
extensive experiments demonstrate that leveraging key nodes can achieve
state-of-the-art (SOTA) performance, surpassing existing approaches across two
benchmark datasets. The results underscore the potential of re-envisioning
traditional tasks with innovative methodologies, paving the way for more
efficient and accurate medical report generation.",2024-08-30,2024,2024-08,medical
Curriculum Prompting Foundation Models for Medical Image Segmentation,"Adapting large pre-trained foundation models, e.g., SAM, for medical image
segmentation remains a significant challenge. A crucial step involves the
formulation of a series of specialized prompts that incorporate specific
clinical instructions. Past works have been heavily reliant on a singular type
of prompt for each instance, necessitating manual input of an ideally correct
prompt, which is less efficient. To tackle this issue, we propose to utilize
prompts of different granularity, which are sourced from original images to
provide a broader scope of clinical insights. However, combining prompts of
varying types can pose a challenge due to potential conflicts. In response, we
have designed a coarse-to-fine mechanism, referred to as curriculum prompting,
that progressively integrates prompts of different types. Through extensive
experiments on three public medical datasets across various modalities, we
demonstrate the effectiveness of our proposed approach, which not only
automates the prompt generation process but also yields superior performance
compared to other SAM-based medical image segmentation methods. Code is
available at: https://github.com/AnnaZzz-zxq/Curriculum-Prompting.",2024-09-01,2024,2024-09,medical
"SeCo-INR: Semantically Conditioned Implicit Neural Representations for
  Improved Medical Image Super-Resolution","Implicit Neural Representations (INRs) have recently advanced the field of
deep learning due to their ability to learn continuous representations of
signals without the need for large training datasets. Although INR methods have
been studied for medical image super-resolution, their adaptability to
localized priors in medical images has not been extensively explored. Medical
images contain rich anatomical divisions that could provide valuable local
prior information to enhance the accuracy and robustness of INRs. In this work,
we propose a novel framework, referred to as the Semantically Conditioned INR
(SeCo-INR), that conditions an INR using local priors from a medical image,
enabling accurate model fitting and interpolation capabilities to achieve
super-resolution. Our framework learns a continuous representation of the
semantic segmentation features of a medical image and utilizes it to derive the
optimal INR for each semantic region of the image. We tested our framework
using several medical imaging modalities and achieved higher quantitative
scores and more realistic super-resolution outputs compared to state-of-the-art
methods.",2024-09-02,2024,2024-09,medical
"The Era of Foundation Models in Medical Imaging is Approaching : A
  Scoping Review of the Clinical Value of Large-Scale Generative AI
  Applications in Radiology","Social problems stemming from the shortage of radiologists are intensifying,
and artificial intelligence is being highlighted as a potential solution.
Recently emerging large-scale generative AI has expanded from large language
models (LLMs) to multi-modal models, showing potential to revolutionize the
entire process of medical imaging. However, comprehensive reviews on their
development status and future challenges are currently lacking. This scoping
review systematically organizes existing literature on the clinical value of
large-scale generative AI applications by following PCC guidelines. A
systematic search was conducted across four databases: PubMed, EMbase,
IEEE-Xplore, and Google Scholar, and 15 studies meeting the inclusion/exclusion
criteria set by the researchers were reviewed. Most of these studies focused on
improving the efficiency of report generation in specific parts of the
interpretation process or on translating reports to aid patient understanding,
with the latest studies extending to AI applications performing direct
interpretations. All studies were quantitatively evaluated by clinicians, with
most utilizing LLMs and only three employing multi-modal models. Both LLMs and
multi-modal models showed excellent results in specific areas, but none yet
outperformed radiologists in diagnostic performance. Most studies utilized GPT,
with few using models specialized for the medical imaging domain. This study
provides insights into the current state and limitations of large-scale
generative AI-based applications in the medical imaging field, offering
foundational data and suggesting that the era of medical imaging foundation
models is on the horizon, which may fundamentally transform clinical practice
in the near future.",2024-09-03,2024,2024-09,medical
"Coupling AI and Citizen Science in Creation of Enhanced Training Dataset
  for Medical Image Segmentation","Recent advancements in medical imaging and artificial intelligence (AI) have
greatly enhanced diagnostic capabilities, but the development of effective deep
learning (DL) models is still constrained by the lack of high-quality annotated
datasets. The traditional manual annotation process by medical experts is time-
and resource-intensive, limiting the scalability of these datasets. In this
work, we introduce a robust and versatile framework that combines AI and
crowdsourcing to improve both the quality and quantity of medical image
datasets across different modalities. Our approach utilises a user-friendly
online platform that enables a diverse group of crowd annotators to label
medical images efficiently. By integrating the MedSAM segmentation AI with this
platform, we accelerate the annotation process while maintaining expert-level
quality through an algorithm that merges crowd-labelled images. Additionally,
we employ pix2pixGAN, a generative AI model, to expand the training dataset
with synthetic images that capture realistic morphological features. These
methods are combined into a cohesive framework designed to produce an enhanced
dataset, which can serve as a universal pre-processing pipeline to boost the
training of any medical deep learning segmentation model. Our results
demonstrate that this framework significantly improves model performance,
especially when training data is limited.",2024-09-04,2024,2024-09,medical
"MEDIC: Towards a Comprehensive Framework for Evaluating LLMs in Clinical
  Applications","The rapid development of Large Language Models (LLMs) for healthcare
applications has spurred calls for holistic evaluation beyond frequently-cited
benchmarks like USMLE, to better reflect real-world performance. While
real-world assessments are valuable indicators of utility, they often lag
behind the pace of LLM evolution, likely rendering findings obsolete upon
deployment. This temporal disconnect necessitates a comprehensive upfront
evaluation that can guide model selection for specific clinical applications.
We introduce MEDIC, a framework assessing LLMs across five critical dimensions
of clinical competence: medical reasoning, ethics and bias, data and language
understanding, in-context learning, and clinical safety. MEDIC features a novel
cross-examination framework quantifying LLM performance across areas like
coverage and hallucination detection, without requiring reference outputs. We
apply MEDIC to evaluate LLMs on medical question-answering, safety,
summarization, note generation, and other tasks. Our results show performance
disparities across model sizes, baseline vs medically finetuned models, and
have implications on model selection for applications requiring specific model
strengths, such as low hallucination or lower cost of inference. MEDIC's
multifaceted evaluation reveals these performance trade-offs, bridging the gap
between theoretical capabilities and practical implementation in healthcare
settings, ensuring that the most promising models are identified and adapted
for diverse healthcare applications.",2024-09-11,2024,2024-09,medical
Safety challenges of AI in medicine in the era of large language models,"Recent advancements in artificial intelligence (AI), particularly in large
language models (LLMs), have unlocked significant potential to enhance the
quality and efficiency of medical care. By introducing a novel way to interact
with AI and data through natural language, LLMs offer new opportunities for
medical practitioners, patients, and researchers. However, as AI and LLMs
become more powerful and especially achieve superhuman performance in some
medical tasks, public concerns over their safety have intensified. These
concerns about AI safety have emerged as the most significant obstacles to the
adoption of AI in medicine. In response, this review examines emerging risks in
AI utilization during the LLM era. First, we explore LLM-specific safety
challenges from functional and communication perspectives, addressing issues
across data collection, model training, and real-world application. We then
consider inherent safety problems shared by all AI systems, along with
additional complications introduced by LLMs. Last, we discussed how safety
issues of using AI in clinical practice and healthcare system operation would
undermine trust among patient, clinicians and the public, and how to build
confidence in these systems. By emphasizing the development of safe AI, we
believe these technologies can be more rapidly and reliably integrated into
everyday medical practice to benefit both patients and clinicians.",2024-09-11,2024,2024-09,medical
"Privacy-Preserving SAM Quantization for Efficient Edge Intelligence in
  Healthcare","The disparity in healthcare personnel expertise and medical resources across
different regions of the world is a pressing social issue. Artificial
intelligence technology offers new opportunities to alleviate this issue.
Segment Anything Model (SAM), which excels in intelligent image segmentation,
has demonstrated exceptional performance in medical monitoring and assisted
diagnosis. Unfortunately, the huge computational and storage overhead of SAM
poses significant challenges for deployment on resource-limited edge devices.
Quantization is an effective solution for model compression; however,
traditional methods rely heavily on original data for calibration, which raises
widespread concerns about medical data privacy and security. In this paper, we
propose a data-free quantization framework for SAM, called DFQ-SAM, which
learns and calibrates quantization parameters without any original data, thus
effectively preserving data privacy during model compression. Specifically, we
propose pseudo-positive label evolution for segmentation, combined with patch
similarity, to fully leverage the semantic and distribution priors in
pre-trained models, which facilitates high-quality data synthesis as a
substitute for real data. Furthermore, we introduce scale reparameterization to
ensure the accuracy of low-bit quantization. We perform extensive segmentation
experiments on various datasets, and DFQ-SAM consistently provides significant
performance on low-bit quantization. DFQ-SAM eliminates the need for data
transfer in cloud-edge collaboration, thereby protecting sensitive data from
potential attacks. It enables secure, fast, and personalized healthcare
services at the edge, which enhances system efficiency and optimizes resource
allocation, and thus facilitating the pervasive application of artificial
intelligence in worldwide healthcare.",2024-09-14,2024,2024-09,medical
"Protecting Copyright of Medical Pre-trained Language Models:
  Training-Free Backdoor Model Watermarking","With the advancement of intelligent healthcare, medical pre-trained language
models (Med-PLMs) have emerged and demonstrated significant effectiveness in
downstream medical tasks. While these models are valuable assets, they are
vulnerable to misuse and theft, requiring copyright protection. However,
existing watermarking methods for pre-trained language models (PLMs) cannot be
directly applied to Med-PLMs due to domain-task mismatch and inefficient
watermark embedding. To fill this gap, we propose the first training-free
backdoor model watermarking for Med-PLMs. Our method employs low-frequency
words as triggers, embedding the watermark by replacing their embeddings in the
model's word embedding layer with those of specific medical terms. The
watermarked Med-PLMs produce the same output for triggers as for the
corresponding specified medical terms. We leverage this unique mapping to
design tailored watermark extraction schemes for different downstream tasks,
thereby addressing the challenge of domain-task mismatch in previous methods.
Experiments demonstrate superior effectiveness of our watermarking method
across medical downstream tasks. Moreover, the method exhibits robustness
against model extraction, pruning, fusion-based backdoor removal attacks, while
maintaining high efficiency with 10-second watermark embedding.",2024-09-14,2024,2024-09,medical
"Efficient Fine-Tuning of Large Language Models for Automated Medical
  Documentation","Scientific research indicates that for every hour spent in direct patient
care, physicians spend nearly two additional hours on administrative tasks,
particularly on electronic health records (EHRs) and desk work. This excessive
administrative burden not only reduces the time available for patient care but
also contributes to physician burnout and inefficiencies in healthcare
delivery. To address these challenges, this study introduces MediGen, a
fine-tuned large language model (LLM) designed to automate the generation of
medical reports from medical dialogues. By leveraging state-of-the-art
methodologies for fine-tuning open-source pretrained models, including
LLaMA3-8B, MediGen achieves high accuracy in transcribing and summarizing
clinical interactions. The fine-tuned LLaMA3-8B model demonstrated promising
results, achieving a ROUGE score of 58% and a BERTScore-F1 of 72%, indicating
its effectiveness in generating accurate and clinically relevant medical
reports. These findings suggest that MediGen has the potential to significantly
reduce the administrative workload on physicians, improving both healthcare
efficiency and physician well-being.",2024-09-14,2024,2024-09,medical
MedCodER: A Generative AI Assistant for Medical Coding,"Medical coding is essential for standardizing clinical data and communication
but is often time-consuming and prone to errors. Traditional Natural Language
Processing (NLP) methods struggle with automating coding due to the large label
space, lengthy text inputs, and the absence of supporting evidence annotations
that justify code selection. Recent advancements in Generative Artificial
Intelligence (AI) offer promising solutions to these challenges. In this work,
we introduce MedCodER, a Generative AI framework for automatic medical coding
that leverages extraction, retrieval, and re-ranking techniques as core
components. MedCodER achieves a micro-F1 score of 0.60 on International
Classification of Diseases (ICD) code prediction, significantly outperforming
state-of-the-art methods. Additionally, we present a new dataset containing
medical records annotated with disease diagnoses, ICD codes, and supporting
evidence texts (https://doi.org/10.5281/zenodo.13308316). Ablation tests
confirm that MedCodER's performance depends on the integration of each of its
aforementioned components, as performance declines when these components are
evaluated in isolation.",2024-09-18,2024,2024-09,medical
Reliable and diverse evaluation of LLM medical knowledge mastery,"Mastering medical knowledge is crucial for medical-specific LLMs. However,
despite the existence of medical benchmarks like MedQA, a unified framework
that fully leverages existing knowledge bases to evaluate LLMs' mastery of
medical knowledge is still lacking. In the study, we propose a novel framework
PretexEval that dynamically generates reliable and diverse test samples to
evaluate LLMs for any given medical knowledge base. We notice that test samples
produced directly from knowledge bases by templates or LLMs may introduce
factual errors and also lack diversity. To address these issues, we introduce a
novel schema into our proposed evaluation framework that employs predicate
equivalence transformations to produce a series of variants for any given
medical knowledge point. Finally, these produced predicate variants are
converted into textual language, resulting in a series of reliable and diverse
test samples to evaluate whether LLMs fully master the given medical factual
knowledge point. Here, we use our proposed framework to systematically
investigate the mastery of medical factual knowledge of 12 well-known LLMs,
based on two knowledge bases that are crucial for clinical diagnosis and
treatment. The evaluation results illustrate that current LLMs still exhibit
significant deficiencies in fully mastering medical knowledge, despite
achieving considerable success on some famous public benchmarks. These new
findings provide valuable insights for developing medical-specific LLMs,
highlighting that current LLMs urgently need to strengthen their comprehensive
and in-depth mastery of medical knowledge before being applied to real-world
medical scenarios.",2024-09-22,2024,2024-09,medical
Pareto-Optimized Open-Source LLMs for Healthcare via Context Retrieval,"This study leverages optimized context retrieval to enhance open-source Large
Language Models (LLMs) for cost-effective, high performance healthcare AI. We
demonstrate that this approach achieves state-of-the-art accuracy on medical
question answering at a fraction of the cost of proprietary models,
significantly improving the cost-accuracy Pareto frontier on the MedQA
benchmark. Key contributions include: (1) OpenMedQA, a novel benchmark
revealing a performance gap in open-ended medical QA compared to
multiple-choice formats; (2) a practical, reproducible pipeline for context
retrieval optimization; and (3) open-source resources (Prompt Engine,
CoT/ToT/Thinking databases) to empower healthcare AI development. By advancing
retrieval techniques and QA evaluation, we enable more affordable and reliable
LLM solutions for healthcare.",2024-09-23,2024,2024-09,medical
"Future-Proofing Medical Imaging with Privacy-Preserving Federated
  Learning and Uncertainty Quantification: A Review","Artificial Intelligence (AI) has demonstrated significant potential in
automating various medical imaging tasks, which could soon become routine in
clinical practice for disease diagnosis, prognosis, treatment planning, and
post-treatment surveillance. However, the privacy concerns surrounding patient
data present a major barrier to the widespread adoption of AI in medical
imaging, as large, diverse training datasets are essential for developing
accurate, generalizable, and robust Artificial intelligence models. Federated
Learning (FL) offers a solution that enables organizations to train AI models
collaboratively without sharing sensitive data. federated learning exchanges
model training information, such as gradients, between the participating sites.
Despite its promise, federated learning is still in its developmental stages
and faces several challenges. Notably, sensitive information can still be
inferred from the gradients shared during model training. Quantifying AI
models' uncertainty is vital due to potential data distribution shifts
post-deployment, which can affect model performance. Uncertainty quantification
(UQ) in FL is particularly challenging due to data heterogeneity across
participating sites. This review provides a comprehensive examination of FL,
privacy-preserving FL (PPFL), and UQ in FL. We identify key gaps in current FL
methodologies and propose future research directions to enhance data privacy
and trustworthiness in medical imaging applications.",2024-09-24,2024,2024-09,medical
"Development and Validation of Heparin Dosing Policies Using an Offline
  Reinforcement Learning Algorithm","Appropriate medication dosages in the intensive care unit (ICU) are critical
for patient survival. Heparin, used to treat thrombosis and inhibit blood
clotting in the ICU, requires careful administration due to its complexity and
sensitivity to various factors, including patient clinical characteristics,
underlying medical conditions, and potential drug interactions. Incorrect
dosing can lead to severe complications such as strokes or excessive bleeding.
To address these challenges, this study proposes a reinforcement learning
(RL)-based personalized optimal heparin dosing policy that guides dosing
decisions reliably within the therapeutic range based on individual patient
conditions. A batch-constrained policy was implemented to minimize
out-of-distribution errors in an offline RL environment and effectively
integrate RL with existing clinician policies. The policy's effectiveness was
evaluated using weighted importance sampling, an off-policy evaluation method,
and the relationship between state representations and Q-values was explored
using t-SNE. Both quantitative and qualitative analyses were conducted using
the Medical Information Mart for Intensive Care III (MIMIC-III) database,
demonstrating the efficacy of the proposed RL-based medication policy.
Leveraging advanced machine learning techniques and extensive clinical data,
this research enhances heparin administration practices and establishes a
precedent for the development of sophisticated decision-support tools in
medicine.",2024-09-24,2024,2024-09,medical
The Role of Language Models in Modern Healthcare: A Comprehensive Review,"The application of large language models (LLMs) in healthcare has gained
significant attention due to their ability to process complex medical data and
provide insights for clinical decision-making. These models have demonstrated
substantial capabilities in understanding and generating natural language,
which is crucial for medical documentation, diagnostics, and patient
interaction. This review examines the trajectory of language models from their
early stages to the current state-of-the-art LLMs, highlighting their strengths
in healthcare applications and discussing challenges such as data privacy,
bias, and ethical considerations. The potential of LLMs to enhance healthcare
delivery is explored, alongside the necessary steps to ensure their ethical and
effective integration into medical practice.",2024-09-25,2024,2024-09,medical
"CBIDR: A novel method for information retrieval combining image and data
  by means of TOPSIS applied to medical diagnosis","Content-Based Image Retrieval (CBIR) have shown promising results in the
field of medical diagnosis, which aims to provide support to medical
professionals (doctor or pathologist). However, the ultimate decision regarding
the diagnosis is made by the medical professional, drawing upon their
accumulated experience. In this context, we believe that artificial
intelligence can play a pivotal role in addressing the challenges in medical
diagnosis not by making the final decision but by assisting in the diagnosis
process with the most relevant information. The CBIR methods use similarity
metrics to compare feature vectors generated from images using Convolutional
Neural Networks (CNNs). In addition to the information contained in medical
images, clinical data about the patient is often available and is also relevant
in the final decision-making process by medical professionals. In this paper,
we propose a novel method named CBIDR, which leverage both medical images and
clinical data of patient, combining them through the ranking algorithm TOPSIS.
The goal is to aid medical professionals in their final diagnosis by retrieving
images and clinical data of patient that are most similar to query data from
the database. As a case study, we illustrate our CBIDR for diagnostic of oral
cancer including histopathological images and clinical data of patient.
Experimental results in terms of accuracy achieved 97.44% in Top-1 and 100% in
Top-5 showing the effectiveness of the proposed approach.",2024-09-26,2024,2024-09,medical
"Evaluation of Large Language Models for Summarization Tasks in the
  Medical Domain: A Narrative Review","Large Language Models have advanced clinical Natural Language Generation,
creating opportunities to manage the volume of medical text. However, the
high-stakes nature of medicine requires reliable evaluation, which remains a
challenge. In this narrative review, we assess the current evaluation state for
clinical summarization tasks and propose future directions to address the
resource constraints of expert human evaluation.",2024-09-26,2024,2024-09,medical
Global-Local Medical SAM Adaptor Based on Full Adaption,"Emerging of visual language models, such as the segment anything model (SAM),
have made great breakthroughs in the field of universal semantic segmentation
and significantly aid the improvements of medical image segmentation, in
particular with the help of Medical SAM adaptor (Med-SA). However, Med-SA still
can be improved, as it fine-tunes SAM in a partial adaption manner. To resolve
this problem, we present a novel global medical SAM adaptor (GMed-SA) with full
adaption, which can adapt SAM globally. We further combine GMed-SA and Med-SA
to propose a global-local medical SAM adaptor (GLMed-SA) to adapt SAM both
globally and locally. Extensive experiments have been performed on the
challenging public 2D melanoma segmentation dataset. The results show that
GLMed-SA outperforms several state-of-the-art semantic segmentation methods on
various evaluation metrics, demonstrating the superiority of our methods.",2024-09-26,2024,2024-09,medical
"Zero- and Few-shot Named Entity Recognition and Text Expansion in
  Medication Prescriptions using ChatGPT","Introduction: Medication prescriptions are often in free text and include a
mix of two languages, local brand names, and a wide range of idiosyncratic
formats and abbreviations. Large language models (LLMs) have shown promising
ability to generate text in response to input prompts. We use ChatGPT 3.5 to
automatically structure and expand medication statements in discharge summaries
and thus make them easier to interpret for people and machines. Methods:
Named-entity Recognition (NER) and Text Expansion (EX) are used in a zero- and
few-shot setting with different prompt strategies. 100 medication statements
were manually annotated and curated. NER performance was measured by using
strict and partial matching. For the task EX, two experts interpreted the
results by assessing semantic equivalence between original and expanded
statements. The model performance was measured by precision, recall, and F1
score. Results: For NER, the best-performing prompt reached an average F1 score
of 0.94 in the test set. For EX, the few-shot prompt showed superior
performance among other prompts, with an average F1 score of 0.87. Conclusion:
Our study demonstrates good performance for NER and EX tasks in free-text
medication statements using ChatGPT. Compared to a zero-shot baseline, a
few-shot approach prevented the system from hallucinating, which would be
unacceptable when processing safety-relevant medication data.",2024-09-26,2024,2024-09,medical
"Building a Chinese Medical Dialogue System: Integrating Large-scale
  Corpora and Novel Models","The global COVID-19 pandemic underscored major deficiencies in traditional
healthcare systems, hastening the advancement of online medical services,
especially in medical triage and consultation. However, existing studies face
two main challenges. First, the scarcity of large-scale, publicly available,
domain-specific medical datasets due to privacy concerns, with current datasets
being small and limited to a few diseases, limiting the effectiveness of triage
methods based on Pre-trained Language Models (PLMs). Second, existing methods
lack medical knowledge and struggle to accurately understand professional terms
and expressions in patient-doctor consultations. To overcome these obstacles,
we construct the Large-scale Chinese Medical Dialogue Corpora (LCMDC), thereby
addressing the data shortage in this field. Moreover, we further propose a
novel triage system that combines BERT-based supervised learning with prompt
learning, as well as a GPT-based medical consultation model. To enhance domain
knowledge acquisition, we pre-trained PLMs using our self-constructed
background corpus. Experimental results on the LCMDC demonstrate the efficacy
of our proposed systems.",2024-09-27,2024,2024-09,medical
A GEN AI Framework for Medical Note Generation,"The increasing administrative burden of medical documentation, particularly
through Electronic Health Records (EHR), significantly reduces the time
available for direct patient care and contributes to physician burnout. To
address this issue, we propose MediNotes, an advanced generative AI framework
designed to automate the creation of SOAP (Subjective, Objective, Assessment,
Plan) notes from medical conversations. MediNotes integrates Large Language
Models (LLMs), Retrieval-Augmented Generation (RAG), and Automatic Speech
Recognition (ASR) to capture and process both text and voice inputs in real
time or from recorded audio, generating structured and contextually accurate
medical notes. The framework also incorporates advanced techniques like
Quantized Low-Rank Adaptation (QLoRA) and Parameter-Efficient Fine-Tuning
(PEFT) for efficient model fine-tuning in resource-constrained environments.
Additionally, MediNotes offers a query-based retrieval system, allowing
healthcare providers and patients to access relevant medical information
quickly and accurately. Evaluations using the ACI-BENCH dataset demonstrate
that MediNotes significantly improves the accuracy, efficiency, and usability
of automated medical documentation, offering a robust solution to reduce the
administrative burden on healthcare professionals while improving the quality
of clinical workflows.",2024-09-27,2024,2024-09,medical
"INSIGHTBUDDY-AI: Medication Extraction and Entity Linking using Large
  Language Models and Ensemble Learning","Medication Extraction and Mining play an important role in healthcare NLP
research due to its practical applications in hospital settings, such as their
mapping into standard clinical knowledge bases (SNOMED-CT, BNF, etc.). In this
work, we investigate state-of-the-art LLMs in text mining tasks on medications
and their related attributes such as dosage, route, strength, and adverse
effects. In addition, we explore different ensemble learning methods
(\textsc{Stack-Ensemble} and \textsc{Voting-Ensemble}) to augment the model
performances from individual LLMs. Our ensemble learning result demonstrated
better performances than individually fine-tuned base models BERT, RoBERTa,
RoBERTa-L, BioBERT, BioClinicalBERT, BioMedRoBERTa, ClinicalBERT, and
PubMedBERT across general and specific domains. Finally, we build up an entity
linking function to map extracted medical terminologies into the SNOMED-CT
codes and the British National Formulary (BNF) codes, which are further mapped
to the Dictionary of Medicines and Devices (dm+d), and ICD. Our model's toolkit
and desktop applications are publicly available (at
\url{https://github.com/HECTA-UoM/ensemble-NER}).",2024-09-28,2024,2024-09,medical
"Adapting LLMs for the Medical Domain in Portuguese: A Study on
  Fine-Tuning and Model Evaluation","This study evaluates the performance of large language models (LLMs) as
medical agents in Portuguese, aiming to develop a reliable and relevant virtual
assistant for healthcare professionals. The HealthCareMagic-100k-en and MedQuAD
datasets, translated from English using GPT-3.5, were used to fine-tune the
ChatBode-7B model using the PEFT-QLoRA method. The InternLM2 model, with
initial training on medical data, presented the best overall performance, with
high precision and adequacy in metrics such as accuracy, completeness and
safety. However, DrBode models, derived from ChatBode, exhibited a phenomenon
of catastrophic forgetting of acquired medical knowledge. Despite this, these
models performed frequently or even better in aspects such as grammaticality
and coherence. A significant challenge was low inter-rater agreement,
highlighting the need for more robust assessment protocols. This work paves the
way for future research, such as evaluating multilingual models specific to the
medical field, improving the quality of training data, and developing more
consistent evaluation methodologies for the medical field.",2024-09-30,2024,2024-09,medical
"MedQA-CS: Benchmarking Large Language Models Clinical Skills Using an
  AI-SCE Framework","Artificial intelligence (AI) and large language models (LLMs) in healthcare
require advanced clinical skills (CS), yet current benchmarks fail to evaluate
these comprehensively. We introduce MedQA-CS, an AI-SCE framework inspired by
medical education's Objective Structured Clinical Examinations (OSCEs), to
address this gap. MedQA-CS evaluates LLMs through two instruction-following
tasks, LLM-as-medical-student and LLM-as-CS-examiner, designed to reflect real
clinical scenarios. Our contributions include developing MedQA-CS, a
comprehensive evaluation framework with publicly available data and expert
annotations, and providing the quantitative and qualitative assessment of LLMs
as reliable judges in CS evaluation. Our experiments show that MedQA-CS is a
more challenging benchmark for evaluating clinical skills than traditional
multiple-choice QA benchmarks (e.g., MedQA). Combined with existing benchmarks,
MedQA-CS enables a more comprehensive evaluation of LLMs' clinical capabilities
for both open- and closed-source LLMs.",2024-10-02,2024,2024-10,medical
"Taming the Tail: Leveraging Asymmetric Loss and Pade Approximation to
  Overcome Medical Image Long-Tailed Class Imbalance","Long-tailed problems in healthcare emerge from data imbalance due to
variability in the prevalence and representation of different medical
conditions, warranting the requirement of precise and dependable classification
methods. Traditional loss functions such as cross-entropy and binary
cross-entropy are often inadequate due to their inability to address the
imbalances between the classes with high representation and the classes with
low representation found in medical image datasets. We introduce a novel
polynomial loss function based on Pade approximation, designed specifically to
overcome the challenges associated with long-tailed classification. This
approach incorporates asymmetric sampling techniques to better classify
under-represented classes. We conducted extensive evaluations on three publicly
available medical datasets and a proprietary medical dataset. Our
implementation of the proposed loss function is open-sourced in the public
repository:https://github.com/ipankhi/ALPA.",2024-10-05,2024,2024-10,medical
"CasiMedicos-Arg: A Medical Question Answering Dataset Annotated with
  Explanatory Argumentative Structures","Explaining Artificial Intelligence (AI) decisions is a major challenge
nowadays in AI, in particular when applied to sensitive scenarios like medicine
and law. However, the need to explain the rationale behind decisions is a main
issue also for human-based deliberation as it is important to justify
\textit{why} a certain decision has been taken. Resident medical doctors for
instance are required not only to provide a (possibly correct) diagnosis, but
also to explain how they reached a certain conclusion. Developing new tools to
aid residents to train their explanation skills is therefore a central
objective of AI in education. In this paper, we follow this direction, and we
present, to the best of our knowledge, the first multilingual dataset for
Medical Question Answering where correct and incorrect diagnoses for a clinical
case are enriched with a natural language explanation written by doctors. These
explanations have been manually annotated with argument components (i.e.,
premise, claim) and argument relations (i.e., attack, support), resulting in
the Multilingual CasiMedicos-Arg dataset which consists of 558 clinical cases
in four languages (English, Spanish, French, Italian) with explanations, where
we annotated 5021 claims, 2313 premises, 2431 support relations, and 1106
attack relations. We conclude by showing how competitive baselines perform over
this challenging dataset for the argument mining task.",2024-10-07,2024,2024-10,medical
KGARevion: An AI Agent for Knowledge-Intensive Biomedical QA,"Biomedical reasoning integrates structured, codified knowledge with tacit,
experience-driven insights. Depending on the context, quantity, and nature of
available evidence, researchers and clinicians use diverse strategies,
including rule-based, prototype-based, and case-based reasoning. Effective
medical AI models must handle this complexity while ensuring reliability and
adaptability. We introduce KGARevion, a knowledge graph-based agent that
answers knowledge-intensive questions. Upon receiving a query, KGARevion
generates relevant triplets by leveraging the latent knowledge embedded in a
large language model. It then verifies these triplets against a grounded
knowledge graph, filtering out errors and retaining only accurate, contextually
relevant information for the final answer. This multi-step process strengthens
reasoning, adapts to different models of medical inference, and outperforms
retrieval-augmented generation-based approaches that lack effective
verification mechanisms. Evaluations on medical QA benchmarks show that
KGARevion improves accuracy by over 5.2% over 15 models in handling complex
medical queries. To further assess its effectiveness, we curated three new
medical QA datasets with varying levels of semantic complexity, where KGARevion
improved accuracy by 10.4%. The agent integrates with different LLMs and
biomedical knowledge graphs for broad applicability across knowledge-intensive
tasks. We evaluated KGARevion on AfriMed-QA, a newly introduced dataset focused
on African healthcare, demonstrating its strong zero-shot generalization to
underrepresented medical contexts.",2024-10-07,2024,2024-10,medical
"Large Language Models for Medical OSCE Assessment: A Novel Approach to
  Transcript Analysis","Grading Objective Structured Clinical Examinations (OSCEs) is a
time-consuming and expensive process, traditionally requiring extensive manual
effort from human experts. In this study, we explore the potential of Large
Language Models (LLMs) to assess skills related to medical student
communication. We analyzed 2,027 video-recorded OSCE examinations from the
University of Texas Southwestern Medical Center (UTSW), spanning four years
(2019-2022), and several different medical cases or ""stations."" Specifically,
our focus was on evaluating students' ability to summarize patients' medical
history: we targeted the rubric item 'did the student summarize the patients'
medical history?' from the communication skills rubric. After transcribing
speech audio captured by OSCE videos using Whisper-v3, we studied the
performance of various LLM-based approaches for grading students on this
summarization task based on their examination transcripts. Using various
frontier-level open-source and proprietary LLMs, we evaluated different
techniques such as zero-shot chain-of-thought prompting, retrieval augmented
generation, and multi-model ensemble methods. Our results show that frontier
LLM models like GPT-4 achieved remarkable alignment with human graders,
demonstrating a Cohen's kappa agreement of 0.88 and indicating strong potential
for LLM-based OSCE grading to augment the current grading process. Open-source
models also showed promising results, suggesting potential for widespread,
cost-effective deployment. Further, we present a failure analysis identifying
conditions where LLM grading may be less reliable in this context and recommend
best practices for deploying LLMs in medical education settings.",2024-10-11,2024,2024-10,medical
"MIRAGE: Multimodal Identification and Recognition of Annotations in
  Indian General Prescriptions","Hospitals in India still rely on handwritten medical records despite the
availability of Electronic Medical Records (EMR), complicating statistical
analysis and record retrieval. Handwritten records pose a unique challenge,
requiring specialized data for training models to recognize medications and
their recommendation patterns. While traditional handwriting recognition
approaches employ 2-D LSTMs, recent studies have explored using Multimodal
Large Language Models (MLLMs) for OCR tasks. Building on this approach, we
focus on extracting medication names and dosages from simulated medical
records. Our methodology MIRAGE (Multimodal Identification and Recognition of
Annotations in indian GEneral prescriptions) involves fine-tuning the QWEN VL,
LLaVA 1.6 and Idefics2 models on 743,118 high resolution simulated medical
record images-fully annotated from 1,133 doctors across India. Our approach
achieves 82% accuracy in extracting medication names and dosages.",2024-10-13,2024,2024-10,medical
IMAS: A Comprehensive Agentic Approach to Rural Healthcare Delivery,"Since the onset of COVID-19, rural communities worldwide have faced
significant challenges in accessing healthcare due to the migration of
experienced medical professionals to urban centers. Semi-trained caregivers,
such as Community Health Workers (CHWs) and Registered Medical Practitioners
(RMPs), have stepped in to fill this gap, but often lack formal training. This
paper proposes an advanced agentic medical assistant system designed to improve
healthcare delivery in rural areas by utilizing Large Language Models (LLMs)
and agentic approaches. The system is composed of five crucial components:
translation, medical complexity assessment, expert network integration, final
medical advice generation, and response simplification. Our innovative
framework ensures context-sensitive, adaptive, and reliable medical assistance,
capable of clinical triaging, diagnostics, and identifying cases requiring
specialist intervention. The system is designed to handle cultural nuances and
varying literacy levels, providing clear and actionable medical advice in local
languages. Evaluation results using the MedQA, PubMedQA, and JAMA datasets
demonstrate that this integrated approach significantly enhances the
effectiveness of rural healthcare workers, making healthcare more accessible
and understandable for underserved populations. All code and supplemental
materials associated with the paper and IMAS are available at
https://github.com/uheal/imas.",2024-10-13,2024,2024-10,medical
Adaptive Reasoning and Acting in Medical Language Agents,"This paper presents an innovative large language model (LLM) agent framework
for enhancing diagnostic accuracy in simulated clinical environments using the
AgentClinic benchmark. The proposed automatic correction enables doctor agents
to iteratively refine their reasoning and actions following incorrect
diagnoses, fostering improved decision-making over time. Experiments show that
the implementation of the adaptive LLM-based doctor agents achieve correct
diagnoses through dynamic interactions with simulated patients. The evaluations
highlight the capacity of autonomous agents to adapt and improve in complex
medical scenarios. Future enhancements will focus on refining the algorithm and
expanding its applicability across a wider range of tasks and different large
language models.",2024-10-13,2024,2024-10,medical
Large-Scale 3D Medical Image Pre-training with Geometric Context Priors,"The scarcity of annotations poses a significant challenge in medical image
analysis. Large-scale pre-training has emerged as a promising label-efficient
solution, owing to the utilization of large-scale data, large models, and
advanced pre-training techniques. However, its development in medical images
remains underexplored. The primary challenge lies in harnessing large-scale
unlabeled data and learning high-level semantics without annotations. We
observe that 3D medical images exhibit consistent geometric context, i.e.,
consistent geometric relations between different organs, which leads to a
promising way for learning consistent representations. Motivated by this, we
introduce a simple-yet-effective Volume Contrast (VoCo) framework to leverage
geometric context priors for self-supervision. Given an input volume, we
extract base crops from different regions to construct positive and negative
pairs for contrastive learning. Then we predict the contextual position of a
random crop by contrasting its similarity to the base crops. In this way, VoCo
encodes the inherent geometric context into model representations, facilitating
high-level semantic learning without annotations. Specifically, we (1)
introduce the largest medical pre-training dataset PreCT-160K; (2) investigate
scaling laws and propose guidelines for tailoring different model sizes to
various medical tasks; (3) build a benchmark encompassing 48 medical tasks.
Extensive experiments highlight the superiority of VoCo. Codes at
https://github.com/Luffy03/Large-Scale-Medical.",2024-10-13,2024,2024-10,medical
Study on the Helpfulness of Explainable Artificial Intelligence,"Explainable Artificial Intelligence (XAI) is essential for building advanced
machine learning-powered applications, especially in critical domains such as
medical diagnostics or autonomous driving. Legal, business, and ethical
requirements motivate using effective XAI, but the increasing number of
different methods makes it challenging to pick the right ones. Further, as
explanations are highly context-dependent, measuring the effectiveness of XAI
methods without users can only reveal a limited amount of information,
excluding human factors such as the ability to understand it. We propose to
evaluate XAI methods via the user's ability to successfully perform a proxy
task, designed such that a good performance is an indicator for the explanation
to provide helpful information. In other words, we address the helpfulness of
XAI for human decision-making. Further, a user study on state-of-the-art
methods was conducted, showing differences in their ability to generate trust
and skepticism and the ability to judge the rightfulness of an AI decision
correctly. Based on the results, we highly recommend using and extending this
approach for more objective-based human-centered user studies to measure XAI
performance in an end-to-end fashion.",2024-10-14,2024,2024-10,medical
"HR-Agent: A Task-Oriented Dialogue (TOD) LLM Agent Tailored for HR
  Applications","Recent LLM (Large Language Models) advancements benefit many fields such as
education and finance, but HR has hundreds of repetitive processes, such as
access requests, medical claim filing and time-off submissions, which are
unaddressed. We relate these tasks to the LLM agent, which has addressed tasks
such as writing assisting and customer support. We present HR-Agent, an
efficient, confidential, and HR-specific LLM-based task-oriented dialogue
system tailored for automating repetitive HR processes such as medical claims
and access requests. Since conversation data is not sent to an LLM during
inference, it preserves confidentiality required in HR-related tasks.",2024-10-15,2024,2024-10,medical
"Advancing Healthcare: Innovative ML Approaches for Improved Medical
  Imaging in Data-Constrained Environments","Healthcare industries face challenges when experiencing rare diseases due to
limited samples. Artificial Intelligence (AI) communities overcome this
situation to create synthetic data which is an ethical and privacy issue in the
medical domain. This research introduces the CAT-U-Net framework as a new
approach to overcome these limitations, which enhances feature extraction from
medical images without the need for large datasets. The proposed framework adds
an extra concatenation layer with downsampling parts, thereby improving its
ability to learn from limited data while maintaining patient privacy. To
validate, the proposed framework's robustness, different medical conditioning
datasets were utilized including COVID-19, brain tumors, and wrist fractures.
The framework achieved nearly 98% reconstruction accuracy, with a Dice
coefficient close to 0.946. The proposed CAT-U-Net has the potential to make a
big difference in medical image diagnostics in settings with limited data.",2024-10-16,2024,2024-10,medical
"Toward a Unified Graph-Based Representation of Medical Data for
  Precision Oncology Medicine","We present a new unified graph-based representation of medical data,
combining genetic information and medical records of patients with medical
knowledge via a unique knowledge graph. This approach allows us to infer
meaningful information and explanations that would be unavailable by looking at
each data set separately. The systematic use of different databases, managed
throughout the built knowledge graph, gives new insights toward a better
understanding of oncology medicine. Indeed, we reduce some useful medical tasks
to well-known problems in theoretical computer science for which efficient
algorithms exist.",2024-10-17,2024,2024-10,medical
Representation Learning of Structured Data for Medical Foundation Models,"Large Language Models (LLMs) have demonstrated remarkable performance across
various domains, including healthcare. However, their ability to effectively
represent structured non-textual data, such as the alphanumeric medical codes
used in records like ICD-10 or SNOMED-CT, is limited and has been particularly
exposed in recent research. This paper examines the challenges LLMs face in
processing medical codes due to the shortcomings of current tokenization
methods. As a result, we introduce the UniStruct architecture to design a
multimodal medical foundation model of unstructured text and structured data,
which addresses these challenges by adapting subword tokenization techniques
specifically for the structured medical codes. Our approach is validated
through model pre-training on both an extensive internal medical database and a
public repository of structured medical records. Trained on over 1 billion
tokens on the internal medical database, the proposed model achieves up to a
23% improvement in evaluation metrics, with around 2% gain attributed to our
proposed tokenization. Additionally, when evaluated on the EHRSHOT public
benchmark with a 1/1000 fraction of the pre-training data, the UniStruct model
improves performance on over 42% of the downstream tasks. Our approach not only
enhances the representation and generalization capabilities of patient-centric
models but also bridges a critical gap in representation learning models'
ability to handle complex structured medical data, alongside unstructured text.",2024-10-17,2024,2024-10,medical
"MeNTi: Bridging Medical Calculator and LLM Agent with Nested Tool
  Calling","Integrating tools into Large Language Models (LLMs) has facilitated the
widespread application. Despite this, in specialized downstream task contexts,
reliance solely on tools is insufficient to fully address the complexities of
the real world. This particularly restricts the effective deployment of LLMs in
fields such as medicine. In this paper, we focus on the downstream tasks of
medical calculators, which use standardized tests to assess an individual's
health status. We introduce MeNTi, a universal agent architecture for LLMs.
MeNTi integrates a specialized medical toolkit and employs meta-tool and nested
calling mechanisms to enhance LLM tool utilization. Specifically, it achieves
flexible tool selection and nested tool calling to address practical issues
faced in intricate medical scenarios, including calculator selection, slot
filling, and unit conversion. To assess the capabilities of LLMs for
quantitative assessment throughout the clinical process of calculator
scenarios, we introduce CalcQA. This benchmark requires LLMs to use medical
calculators to perform calculations and assess patient health status. CalcQA is
constructed by professional physicians and includes 100 case-calculator pairs,
complemented by a toolkit of 281 medical tools. The experimental results
demonstrate significant performance improvements with our framework. This
research paves new directions for applying LLMs in demanding scenarios of
medicine.",2024-10-17,2024,2024-10,medical
"Deep Learning Applications in Medical Image Analysis: Advancements,
  Challenges, and Future Directions","Medical image analysis has emerged as an essential element of contemporary
healthcare, facilitating physicians in achieving expedited and precise
diagnosis. Recent breakthroughs in deep learning, a subset of artificial
intelligence, have markedly revolutionized the analysis of medical pictures,
improving the accuracy and efficiency of clinical procedures. Deep learning
algorithms, especially convolutional neural networks (CNNs), have demonstrated
remarkable proficiency in autonomously learning features from multidimensional
medical pictures, including MRI, CT, and X-ray scans, without the necessity for
manual feature extraction. These models have been utilized across multiple
medical disciplines, including pathology, radiology, ophthalmology, and
cardiology, where they aid in illness detection, classification, and
segmentation tasks......",2024-10-18,2024,2024-10,medical
Enabling Scalable Evaluation of Bias Patterns in Medical LLMs,"Large language models (LLMs) have shown impressive potential in helping with
numerous medical challenges. Deploying LLMs in high-stakes applications such as
medicine, however, brings in many concerns. One major area of concern relates
to biased behaviors of LLMs in medical applications, leading to unfair
treatment of individuals. To pave the way for the responsible and impactful
deployment of Med LLMs, rigorous evaluation is a key prerequisite. Due to the
huge complexity and variability of different medical scenarios, existing work
in this domain has primarily relied on using manually crafted datasets for bias
evaluation. In this study, we present a new method to scale up such bias
evaluations by automatically generating test cases based on rigorous medical
evidence. We specifically target the challenges of a) domain-specificity of
bias characterization, b) hallucinating while generating the test cases, and c)
various dependencies between the health outcomes and sensitive attributes. To
that end, we offer new methods to address these challenges integrated with our
generative pipeline, using medical knowledge graphs, medical ontologies, and
customized general LLM evaluation frameworks in our method. Through a series of
extensive experiments, we show that the test cases generated by our proposed
method can effectively reveal bias patterns in Med LLMs at larger and more
flexible scales than human-crafted datasets. We publish a large bias evaluation
dataset using our pipeline, which is dedicated to a few medical case studies. A
live demo of our application for vignette generation is available at
https://vignette.streamlit.app. Our code is also available at
https://github.com/healthylaife/autofair.",2024-10-18,2024,2024-10,medical
LLaVA-Ultra: Large Chinese Language and Vision Assistant for Ultrasound,"Multimodal Large Language Model (MLLM) has recently garnered attention as a
prominent research focus. By harnessing powerful LLM, it facilitates a
transition of conversational generative AI from unimodal text to performing
multimodal tasks. This boom begins to significantly impact medical field.
However, general visual language model (VLM) lacks sophisticated comprehension
for medical visual question answering (Med-VQA). Even models specifically
tailored for medical domain tend to produce vague answers with weak visual
relevance. In this paper, we propose a fine-grained adaptive VLM architecture
for Chinese medical visual conversations through parameter-efficient tuning.
Specifically, we devise a fusion module with fine-grained vision encoders to
achieve enhancement for subtle medical visual semantics. Then we note data
redundancy common to medical scenes is ignored in most prior works. In cases of
a single text paired with multiple figures, we utilize weighted scoring with
knowledge distillation to adaptively screen valid images mirroring text
descriptions. For execution, we leverage a large-scale multimodal Chinese
ultrasound dataset obtained from the hospital. We create instruction-following
data based on text from professional doctors, which ensures effective tuning.
With enhanced model and quality data, our Large Chinese Language and Vision
Assistant for Ultrasound (LLaVA-Ultra) shows strong capability and robustness
to medical scenarios. On three Med-VQA datasets, LLaVA-Ultra surpasses previous
state-of-the-art models on various metrics.",2024-10-19,2024,2024-10,medical
"MMDS: A Multimodal Medical Diagnosis System Integrating Image Analysis
  and Knowledge-based Departmental Consultation","We present MMDS, a system capable of recognizing medical images and patient
facial details, and providing professional medical diagnoses. The system
consists of two core components:The first component is the analysis of medical
images and videos. We trained a specialized multimodal medical model capable of
interpreting medical images and accurately analyzing patients' facial emotions
and facial paralysis conditions. The model achieved an accuracy of 72.59% on
the FER2013 facial emotion recognition dataset, with a 91.1% accuracy in
recognizing the ""happy"" emotion. In facial paralysis recognition, the model
reached an accuracy of 92%, which is 30% higher than that of GPT-4o. Based on
this model, we developed a parser for analyzing facial movement videos of
patients with facial paralysis, achieving precise grading of the paralysis
severity. In tests on 30 videos of facial paralysis patients, the system
demonstrated a grading accuracy of 83.3%.The second component is the generation
of professional medical responses. We employed a large language model,
integrated with a medical knowledge base, to generate professional diagnoses
based on the analysis of medical images or videos. The core innovation lies in
our development of a department-specific knowledge base routing management
mechanism, in which the large language model categorizes data by medical
departments and, during the retrieval process, determines the appropriate
knowledge base to query. This significantly improves retrieval accuracy in the
RAG (retrieval-augmented generation) process.",2024-10-20,2024,2024-10,medical
"Concept Complement Bottleneck Model for Interpretable Medical Image
  Diagnosis","Models based on human-understandable concepts have received extensive
attention to improve model interpretability for trustworthy artificial
intelligence in the field of medical image analysis. These methods can provide
convincing explanations for model decisions but heavily rely on the detailed
annotation of pre-defined concepts. Consequently, they may not be effective in
cases where concepts or annotations are incomplete or low-quality. Although
some methods automatically discover effective and new visual concepts rather
than using pre-defined concepts or could find some human-understandable
concepts via large Language models, they are prone to veering away from medical
diagnostic evidence and are challenging to understand. In this paper, we
propose a concept complement bottleneck model for interpretable medical image
diagnosis with the aim of complementing the existing concept set and finding
new concepts bridging the gap between explainable models. Specifically, we
propose to use concept adapters for specific concepts to mine the concept
differences and score concepts in their own attention channels to support
almost fairly concept learning. Then, we devise a concept complement strategy
to learn new concepts while jointly using known concepts to improve model
performance. Comprehensive experiments on medical datasets demonstrate that our
model outperforms the state-of-the-art competitors in concept detection and
disease diagnosis tasks while providing diverse explanations to ensure model
interpretability effectively.",2024-10-20,2024,2024-10,medical
"On Creating an English-Thai Code-switched Machine Translation in Medical
  Domain","Machine translation (MT) in the medical domain plays a pivotal role in
enhancing healthcare quality and disseminating medical knowledge. Despite
advancements in English-Thai MT technology, common MT approaches often
underperform in the medical field due to their inability to precisely translate
medical terminologies. Our research prioritizes not merely improving
translation accuracy but also maintaining medical terminology in English within
the translated text through code-switched (CS) translation. We developed a
method to produce CS medical translation data, fine-tuned a CS translation
model with this data, and evaluated its performance against strong baselines,
such as Google Neural Machine Translation (NMT) and GPT-3.5/GPT-4. Our model
demonstrated competitive performance in automatic metrics and was highly
favored in human preference evaluations. Our evaluation result also shows that
medical professionals significantly prefer CS translations that maintain
critical English terms accurately, even if it slightly compromises fluency. Our
code and test set are publicly available
https://github.com/preceptorai-org/NLLB_CS_EM_NLP2024.",2024-10-21,2024,2024-10,medical
GenAI Assisting Medical Training,"Medical procedures such as venipuncture and cannulation are essential for
nurses and require precise skills. Learning this skill, in turn, is a challenge
for educators due to the number of teachers per class and the complexity of the
task. The study aims to help students with skill acquisition and alleviate the
educator's workload by integrating generative AI methods to provide real-time
feedback on medical procedures such as venipuncture and cannulation.",2024-10-21,2024,2024-10,medical
Resource-Efficient Medical Report Generation using Large Language Models,"Medical report generation is the task of automatically writing radiology
reports for chest X-ray images. Manually composing these reports is a
time-consuming process that is also prone to human errors. Generating medical
reports can therefore help reduce the burden on radiologists. In other words,
we can promote greater clinical automation in the medical domain. In this work,
we propose a new framework leveraging vision-enabled Large Language Models
(LLM) for the task of medical report generation. We introduce a lightweight
solution that achieves better or comparative performance as compared to
previous solutions on the task of medical report generation. We conduct
extensive experiments exploring different model sizes and enhancement
approaches, such as prefix tuning to improve the text generation abilities of
the LLMs. We evaluate our approach on a prominent large-scale radiology report
dataset - MIMIC-CXR. Our results demonstrate the capability of our
resource-efficient framework to generate patient-specific reports with strong
medical contextual understanding and high precision.",2024-10-21,2024,2024-10,medical
MAC Revivo: Artificial Intelligence Paves the Way,"The vast adoption of Wi-Fi and/or Bluetooth capabilities in Internet of
Things (IoT) devices, along with the rapid growth of deployed smart devices,
has caused significant interference and congestion in the industrial,
scientific, and medical (ISM) bands. Traditional Wi-Fi Medium Access Control
(MAC) design faces significant challenges in managing increasingly complex
wireless environments while ensuring network Quality of Service (QoS)
performance. This paper explores the potential integration of advanced
Artificial Intelligence (AI) methods into the design of Wi-Fi MAC protocols. We
propose AI-MAC, an innovative approach that employs machine learning algorithms
to dynamically adapt to changing network conditions, optimize channel access,
mitigate interference, and ensure deterministic latency. By intelligently
predicting and managing interference, AI-MAC aims to provide a robust solution
for next generation of Wi-Fi networks, enabling seamless connectivity and
enhanced QoS. Our experimental results demonstrate that AI-MAC significantly
reduces both interference and latency, paving the way for more reliable and
efficient wireless communications in the increasingly crowded ISM band.",2024-10-21,2024,2024-10,medical
Random Token Fusion for Multi-View Medical Diagnosis,"In multi-view medical diagnosis, deep learning-based models often fuse
information from different imaging perspectives to improve diagnostic
performance. However, existing approaches are prone to overfitting and rely
heavily on view-specific features, which can lead to trivial solutions. In this
work, we introduce Random Token Fusion (RTF), a novel technique designed to
enhance multi-view medical image analysis using vision transformers. By
integrating randomness into the feature fusion process during training, RTF
addresses the issue of overfitting and enhances the robustness and accuracy of
diagnostic models without incurring any additional cost at inference. We
validate our approach on standard mammography and chest X-ray benchmark
datasets. Through extensive experiments, we demonstrate that RTF consistently
improves the performance of existing fusion methods, paving the way for a new
generation of multi-view medical foundation models.",2024-10-21,2024,2024-10,medical
Fine-Tuning LLMs for Reliable Medical Question-Answering Services,"We present an advanced approach to medical question-answering (QA) services,
using fine-tuned Large Language Models (LLMs) to improve the accuracy and
reliability of healthcare information. Our study focuses on optimizing models
like LLaMA-2 and Mistral, which have shown great promise in delivering precise,
reliable medical answers. By leveraging comprehensive datasets, we applied
fine-tuning techniques such as rsDoRA+ and ReRAG. rsDoRA+ enhances model
performance through a combination of decomposed model weights, varied learning
rates for low-rank matrices, and rank stabilization, leading to improved
efficiency. ReRAG, which integrates retrieval on demand and question rewriting,
further refines the accuracy of the responses. This approach enables healthcare
providers to access fast, dependable information, aiding in more efficient
decision-making and fostering greater patient trust. Our work highlights the
potential of fine-tuned LLMs to significantly improve the quality and
accessibility of medical information services, ultimately contributing to
better healthcare outcomes for all.",2024-10-21,2024,2024-10,medical
"Development of CNN Architectures using Transfer Learning Methods for
  Medical Image Classification","The application of deep learning-based architecture has seen a tremendous
rise in recent years. For example, medical image classification using deep
learning achieved breakthrough results. Convolutional Neural Networks (CNNs)
are implemented predominantly in medical image classification and segmentation.
On the other hand, transfer learning has emerged as a prominent supporting tool
for enhancing the efficiency and accuracy of deep learning models. This paper
investigates the development of CNN architectures using transfer learning
techniques in the field of medical image classification using a timeline
mapping model for key image classification challenges. Our findings help make
an informed decision while selecting the optimum and state-of-the-art CNN
architectures.",2024-10-22,2024,2024-10,medical
"Explaining Bayesian Networks in Natural Language using Factor Arguments.
  Evaluation in the medical domain","In this paper, we propose a model for building natural language explanations
for Bayesian Network Reasoning in terms of factor arguments, which are
argumentation graphs of flowing evidence, relating the observed evidence to a
target variable we want to learn about. We introduce the notion of factor
argument independence to address the outstanding question of defining when
arguments should be presented jointly or separately and present an algorithm
that, starting from the evidence nodes and a target node, produces a list of
all independent factor arguments ordered by their strength. Finally, we
implemented a scheme to build natural language explanations of Bayesian
Reasoning using this approach. Our proposal has been validated in the medical
domain through a human-driven evaluation study where we compare the Bayesian
Network Reasoning explanations obtained using factor arguments with an
alternative explanation method. Evaluation results indicate that our proposed
explanation approach is deemed by users as significantly more useful for
understanding Bayesian Network Reasoning than another existing explanation
method it is compared to.",2024-10-23,2024,2024-10,medical
"Which Client is Reliable?: A Reliable and Personalized Prompt-based
  Federated Learning for Medical Image Question Answering","Conventional medical artificial intelligence (AI) models face barriers in
clinical application and ethical issues owing to their inability to handle the
privacy-sensitive characteristics of medical data. We present a novel
personalized federated learning (pFL) method for medical visual question
answering (VQA) models, addressing privacy reliability challenges in the
medical domain. Our method introduces learnable prompts into a Transformer
architecture to efficiently train it on diverse medical datasets without
massive computational costs. Then we introduce a reliable client VQA model that
incorporates Dempster-Shafer evidence theory to quantify uncertainty in
predictions, enhancing the model's reliability. Furthermore, we propose a novel
inter-client communication mechanism that uses maximum likelihood estimation to
balance accuracy and uncertainty, fostering efficient integration of insights
across clients.",2024-10-23,2024,2024-10,medical
AI Readiness in Healthcare through Storytelling XAI,"Artificial Intelligence is rapidly advancing and radically impacting everyday
life, driven by the increasing availability of computing power. Despite this
trend, the adoption of AI in real-world healthcare is still limited. One of the
main reasons is the trustworthiness of AI models and the potential hesitation
of domain experts with model predictions. Explainable Artificial Intelligence
(XAI) techniques aim to address these issues. However, explainability can mean
different things to people with different backgrounds, expertise, and goals. To
address the target audience with diverse needs, we develop storytelling XAI. In
this research, we have developed an approach that combines multi-task
distillation with interpretability techniques to enable audience-centric
explainability. Using multi-task distillation allows the model to exploit the
relationships between tasks, potentially improving interpretability as each
task supports the other leading to an enhanced interpretability from the
perspective of a domain expert. The distillation process allows us to extend
this research to large deep models that are highly complex. We focus on both
model-agnostic and model-specific methods of interpretability, supported by
textual justification of the results in healthcare through our use case. Our
methods increase the trust of both the domain experts and the machine learning
experts to enable a responsible AI.",2024-10-24,2024,2024-10,medical
"AutoMIR: Effective Zero-Shot Medical Information Retrieval without
  Relevance Labels","Medical information retrieval (MIR) is essential for retrieving relevant
medical knowledge from diverse sources, including electronic health records,
scientific literature, and medical databases. However, achieving effective
zero-shot dense retrieval in the medical domain poses substantial challenges
due to the lack of relevance-labeled data. In this paper, we introduce a novel
approach called Self-Learning Hypothetical Document Embeddings (SL-HyDE) to
tackle this issue. SL-HyDE leverages large language models (LLMs) as generators
to generate hypothetical documents based on a given query. These generated
documents encapsulate key medical context, guiding a dense retriever in
identifying the most relevant documents. The self-learning framework
progressively refines both pseudo-document generation and retrieval, utilizing
unlabeled medical corpora without requiring any relevance-labeled data.
Additionally, we present the Chinese Medical Information Retrieval Benchmark
(CMIRB), a comprehensive evaluation framework grounded in real-world medical
scenarios, encompassing five tasks and ten datasets. By benchmarking ten models
on CMIRB, we establish a rigorous standard for evaluating medical information
retrieval systems. Experimental results demonstrate that SL-HyDE significantly
surpasses existing methods in retrieval accuracy while showcasing strong
generalization and scalability across various LLM and retriever configurations.
CMIRB data and evaluation code are publicly available at:
https://github.com/CMIRB-benchmark/CMIRB.",2024-10-26,2024,2024-10,medical
MedGo: A Chinese Medical Large Language Model,"Large models are a hot research topic in the field of artificial
intelligence. Leveraging their generative capabilities has the potential to
enhance the level and quality of medical services. In response to the
limitations of current large language models, which often struggle with
accuracy and have narrow capabilities in medical applications, this paper
presents a Chinese medical large language model, MedGo. MedGo was trained using
a combination of high quality unsupervised medical data, supervised data, and
preference alignment data, aimed at enhancing both its versatility and
precision in medical tasks. The model was evaluated through the public CBLUE
benchmark and a manually constructed dataset ClinicalQA. The results
demonstrate that MedGo achieved promising performance across various Chinese
medical information processing tasks, achieved the first place in the CBLUE
evaluation. Additionally, on our constructed dataset ClinicalQA, MedGo
outperformed its base model Qwen2, highlighting its potential to improve both
automated medical question answering and clinical decision support. These
experimental results demonstrate that MedGo possesses strong information
processing capabilities in the medical field. At present, we have successfully
deployed MedGo at Shanghai East Hospital.",2024-10-27,2024,2024-10,medical
"R-LLaVA: Improving Med-VQA Understanding through Visual Region of
  Interest","Artificial intelligence has made significant strides in medical visual
question answering (Med-VQA), yet prevalent studies often interpret images
holistically, overlooking the visual regions of interest that may contain
crucial information, potentially aligning with a doctor's prior knowledge that
can be incorporated with minimal annotations (e.g., bounding boxes). To address
this gap, this paper introduces R-LLaVA, designed to enhance biomedical VQA
understanding by integrating simple medical annotations as prior knowledge
directly into the image space through CLIP. These annotated visual regions of
interest are then fed into the LLaVA model during training, aiming to enrich
the model's understanding of biomedical queries. Experimental evaluation on
four standard Med-VQA datasets demonstrates R-LLaVA's superiority over existing
state-of-the-art (SoTA) methods. Additionally, to verify the model's capability
in visual comprehension, a novel multiple-choice medical visual understanding
dataset is introduced, confirming the positive impact of focusing on visual
regions of interest in advancing biomedical VQA understanding.",2024-10-27,2024,2024-10,medical
Large Language Model Benchmarks in Medical Tasks,"With the increasing application of large language models (LLMs) in the
medical domain, evaluating these models' performance using benchmark datasets
has become crucial. This paper presents a comprehensive survey of various
benchmark datasets employed in medical LLM tasks. These datasets span multiple
modalities including text, image, and multimodal benchmarks, focusing on
different aspects of medical knowledge such as electronic health records
(EHRs), doctor-patient dialogues, medical question-answering, and medical image
captioning. The survey categorizes the datasets by modality, discussing their
significance, data structure, and impact on the development of LLMs for
clinical tasks such as diagnosis, report generation, and predictive decision
support. Key benchmarks include MIMIC-III, MIMIC-IV, BioASQ, PubMedQA, and
CheXpert, which have facilitated advancements in tasks like medical report
generation, clinical summarization, and synthetic data generation. The paper
summarizes the challenges and opportunities in leveraging these benchmarks for
advancing multimodal medical intelligence, emphasizing the need for datasets
with a greater degree of language diversity, structured omics data, and
innovative approaches to synthesis. This work also provides a foundation for
future research in the application of LLMs in medicine, contributing to the
evolving field of medical artificial intelligence.",2024-10-28,2024,2024-10,medical
"A Perspective for Adapting Generalist AI to Specialized Medical AI
  Applications and Their Challenges","The integration of Large Language Models (LLMs) into medical applications has
sparked widespread interest across the healthcare industry, from drug discovery
and development to clinical decision support, assisting telemedicine, medical
devices, and healthcare insurance applications. This perspective paper aims to
discuss the inner workings of building LLM-powered medical AI applications and
introduces a comprehensive framework for their development. We review existing
literature and outline the unique challenges of applying LLMs in specialized
medical contexts. Additionally, we introduce a three-step framework to organize
medical LLM research activities: 1) Modeling: breaking down complex medical
workflows into manageable steps for developing medical-specific models; 2)
Optimization: optimizing the model performance with crafted prompts and
integrating external knowledge and tools, and 3) System engineering:
decomposing complex tasks into subtasks and leveraging human expertise for
building medical AI applications. Furthermore, we offer a detailed use case
playbook that describes various LLM-powered medical AI applications, such as
optimizing clinical trial design, enhancing clinical decision support, and
advancing medical imaging analysis. Finally, we discuss various challenges and
considerations for building medical AI applications with LLMs, such as handling
hallucination issues, data ownership and compliance, privacy, intellectual
property considerations, compute cost, sustainability issues, and responsible
AI requirements.",2024-10-28,2024,2024-10,medical
"Efficient Bilinear Attention-based Fusion for Medical Visual Question
  Answering","Medical Visual Question Answering (MedVQA) has attracted growing interest at
the intersection of computer vision and natural language processing. By
interpreting medical images and providing precise answers to relevant clinical
inquiries, MedVQA has the potential to support diagnostic decision-making and
reduce workload across various domains, particularly radiology. While recent
approaches rely heavily on unified large pre-trained Visual-Language Models,
research on more efficient fusion mechanisms remains relatively limited in this
domain. In this paper, we introduce a novel fusion model, OMniBAN, that
integrates Orthogonality loss, Multi-head attention, and a Bilinear Attention
Network to achieve high computational efficiency alongside solid performance.
We conduct comprehensive experiments and provide insights into how bilinear
attention fusion can approximate the performance of larger fusion models like
cross-modal Transformer. Our results demonstrate that OMniBAN outperforms
traditional approaches on key MedVQA benchmarks while maintaining a lower
computational cost. This balance between efficiency and accuracy suggests that
OMniBAN could be a viable option for real-world medical image question
answering, where computational resources are often constrained.",2024-10-28,2024,2024-10,medical
"MAPUNetR: A Hybrid Vision Transformer and U-Net Architecture for
  Efficient and Interpretable Medical Image Segmentation","Medical image segmentation is pivotal in healthcare, enhancing diagnostic
accuracy, informing treatment strategies, and tracking disease progression.
This process allows clinicians to extract critical information from visual
data, enabling personalized patient care. However, developing neural networks
for segmentation remains challenging, especially when preserving image
resolution, which is essential in detecting subtle details that influence
diagnoses. Moreover, the lack of transparency in these deep learning models has
slowed their adoption in clinical practice. Efforts in model interpretability
are increasingly focused on making these models' decision-making processes more
transparent. In this paper, we introduce MAPUNetR, a novel architecture that
synergizes the strengths of transformer models with the proven U-Net framework
for medical image segmentation. Our model addresses the resolution preservation
challenge and incorporates attention maps highlighting segmented regions,
increasing accuracy and interpretability. Evaluated on the BraTS 2020 dataset,
MAPUNetR achieved a dice score of 0.88 and a dice coefficient of 0.92 on the
ISIC 2018 dataset. Our experiments show that the model maintains stable
performance and potential as a powerful tool for medical image segmentation in
clinical practice.",2024-10-29,2024,2024-10,medical
"Parameter-Efficient Fine-Tuning Medical Multimodal Large Language Models
  for Medical Visual Grounding","Multimodal Large Language Models (MLLMs) inherit the superior text
understanding capabilities of LLMs and extend these capabilities to multimodal
scenarios. These models achieve excellent results in the general domain of
multimodal tasks. However, in the medical domain, the substantial training
costs and the requirement for extensive medical data pose challenges to the
development of medical MLLMs. Furthermore, due to the free-text form of
answers, tasks such as visual grounding that need to produce output in a
prescribed form become difficult for MLLMs. So far, there have been no medical
MLLMs works in medical visual grounding area. For the medical vision grounding
task, which involves identifying locations in medical images based on short
text descriptions, we propose Parameter-efficient Fine-tuning medical
multimodal large language models for Medcial Visual Grounding (PFMVG). To
validate the performance of the model, we evaluate it on a public benchmark
dataset for medical visual grounding, where it achieves competitive results,
and significantly outperforming GPT-4v. Our code will be open sourced after
peer review.",2024-10-31,2024,2024-10,medical
"Beyond Label Attention: Transparency in Language Models for Automated
  Medical Coding via Dictionary Learning","Medical coding, the translation of unstructured clinical text into
standardized medical codes, is a crucial but time-consuming healthcare
practice. Though large language models (LLM) could automate the coding process
and improve the efficiency of such tasks, interpretability remains paramount
for maintaining patient trust. Current efforts in interpretability of medical
coding applications rely heavily on label attention mechanisms, which often
leads to the highlighting of extraneous tokens irrelevant to the ICD code. To
facilitate accurate interpretability in medical language models, this paper
leverages dictionary learning that can efficiently extract sparsely activated
representations from dense language model embeddings in superposition. Compared
with common label attention mechanisms, our model goes beyond token-level
representations by building an interpretable dictionary which enhances the
mechanistic-based explanations for each ICD code prediction, even when the
highlighted tokens are medically irrelevant. We show that dictionary features
can steer model behavior, elucidate the hidden meanings of upwards of 90% of
medically irrelevant tokens, and are human interpretable.",2024-10-31,2024,2024-10,medical
"Medical X-Ray Image Enhancement Using Global Contrast-Limited Adaptive
  Histogram Equalization","In medical imaging, accurate diagnosis heavily relies on effective image
enhancement techniques, particularly for X-ray images. Existing methods often
suffer from various challenges such as sacrificing global image characteristics
over local image characteristics or vice versa. In this paper, we present a
novel approach, called G-CLAHE (Global-Contrast Limited Adaptive Histogram
Equalization), which perfectly suits medical imaging with a focus on X-rays.
This method adapts from Global Histogram Equalization (GHE) and Contrast
Limited Adaptive Histogram Equalization (CLAHE) to take both advantages and
avoid weakness to preserve local and global characteristics. Experimental
results show that it can significantly improve current state-of-the-art
algorithms to effectively address their limitations and enhance the contrast
and quality of X-ray images for diagnostic accuracy.",2024-11-02,2024,2024-11,medical
"Optical Flow Representation Alignment Mamba Diffusion Model for Medical
  Video Generation","Medical video generation models are expected to have a profound impact on the
healthcare industry, including but not limited to medical education and
training, surgical planning, and simulation. Current video diffusion models
typically build on image diffusion architecture by incorporating temporal
operations (such as 3D convolution and temporal attention). Although this
approach is effective, its oversimplification limits spatio-temporal
performance and consumes substantial computational resources. To counter this,
we propose Medical Simulation Video Generator (MedSora), which incorporates
three key elements: i) a video diffusion framework integrates the advantages of
attention and Mamba, balancing low computational load with high-quality video
generation, ii) an optical flow representation alignment method that implicitly
enhances attention to inter-frame pixels, and iii) a video variational
autoencoder (VAE) with frequency compensation addresses the information loss of
medical features that occurs when transforming pixel space into latent features
and then back to pixel frames. Extensive experiments and applications
demonstrate that MedSora exhibits superior visual quality in generating medical
videos, outperforming the most advanced baseline methods. Further results and
code are available at https://wongzbb.github.io/MedSora",2024-11-03,2024,2024-11,medical
Diagnosing Medical Datasets with Training Dynamics,"This study explores the potential of using training dynamics as an automated
alternative to human annotation for evaluating the quality of training data.
The framework used is Data Maps, which classifies data points into categories
such as easy-to-learn, hard-to-learn, and ambiguous (Swayamdipta et al., 2020).
Swayamdipta et al. (2020) highlight that difficult-to-learn examples often
contain errors, and ambiguous cases significantly impact model training. To
confirm the reliability of these findings, we replicated the experiments using
a challenging dataset, with a focus on medical question answering. In addition
to text comprehension, this field requires the acquisition of detailed medical
knowledge, which further complicates the task. A comprehensive evaluation was
conducted to assess the feasibility and transferability of the Data Maps
framework to the medical domain. The evaluation indicates that the framework is
unsuitable for addressing datasets' unique challenges in answering medical
questions.",2024-11-03,2024,2024-11,medical
"Simulation of Nanorobots with Artificial Intelligence and Reinforcement
  Learning for Advanced Cancer Cell Detection and Tracking","Nanorobots are a promising development in targeted drug delivery and the
treatment of neurological disorders, with potential for crossing the
blood-brain barrier (BBB). These small devices leverage advancements in
nanotechnology and bioengineering for precise navigation and targeted payload
delivery, particularly for conditions like brain tumors, Alzheimer's disease,
and Parkinson's disease. Recent progress in artificial intelligence (AI) and
machine learning (ML) has improved the navigation and effectiveness of
nanorobots, allowing them to detect and interact with cancer cells through
biomarker analysis. This study presents a new reinforcement learning (RL)
framework for optimizing nanorobot navigation in complex biological
environments, focusing on cancer cell detection by analyzing the concentration
gradients of surrounding biomarkers. We utilize a computer simulation model to
explore the behavior of nanorobots in a three-dimensional space with cancer
cells and biological barriers. The proposed method uses Q-learning to refine
movement strategies based on real-time biomarker concentration data, enabling
nanorobots to autonomously navigate to cancerous tissues for targeted drug
delivery. This research lays the groundwork for future laboratory experiments
and clinical applications, with implications for personalized medicine and less
invasive cancer treatments. The integration of intelligent nanorobots could
revolutionize therapeutic strategies, reducing side effects and enhancing
treatment effectiveness for cancer patients. Further research will investigate
the practical deployment of these technologies in medical settings, aiming to
unlock the full potential of nanorobotics in healthcare.",2024-11-04,2024,2024-11,medical
Foundation AI Model for Medical Image Segmentation,"Foundation models refer to artificial intelligence (AI) models that are
trained on massive amounts of data and demonstrate broad generalizability
across various tasks with high accuracy. These models offer versatile,
one-for-many or one-for-all solutions, eliminating the need for developing
task-specific AI models. Examples of such foundation models include the Chat
Generative Pre-trained Transformer (ChatGPT) and the Segment Anything Model
(SAM). These models have been trained on millions to billions of samples and
have shown wide-ranging and accurate applications in numerous tasks such as
text processing (using ChatGPT) and natural image segmentation (using SAM). In
medical image segmentation - finding target regions in medical images - there
is a growing need for these one-for-many or one-for-all foundation models. Such
models could obviate the need to develop thousands of task-specific AI models,
which is currently standard practice in the field. They can also be adapted to
tasks with datasets too small for effective training. We discuss two paths to
achieve foundation models for medical image segmentation and comment on
progress, challenges, and opportunities. One path is to adapt or fine-tune
existing models, originally developed for natural images, for use with medical
images. The second path entails building models from scratch, exclusively
training on medical images.",2024-11-05,2024,2024-11,medical
"Medical Adaptation of Large Language and Vision-Language Models: Are We
  Making Progress?","Several recent works seek to develop foundation models specifically for
medical applications, adapting general-purpose large language models (LLMs) and
vision-language models (VLMs) via continued pretraining on publicly available
biomedical corpora. These works typically claim that such domain-adaptive
pretraining (DAPT) improves performance on downstream medical tasks, such as
answering medical licensing exam questions. In this paper, we compare seven
public ""medical"" LLMs and two VLMs against their corresponding base models,
arriving at a different conclusion: all medical VLMs and nearly all medical
LLMs fail to consistently improve over their base models in the zero-/few-shot
prompting regime for medical question-answering (QA) tasks. For instance,
across the tasks and model pairs we consider in the 3-shot setting, medical
LLMs only outperform their base models in 12.1% of cases, reach a (statistical)
tie in 49.8% of cases, and are significantly worse than their base models in
the remaining 38.2% of cases. Our conclusions are based on (i) comparing each
medical model head-to-head, directly against the corresponding base model; (ii)
optimizing the prompts for each model separately; and (iii) accounting for
statistical uncertainty in comparisons. While these basic practices are not
consistently adopted in the literature, our ablations show that they
substantially impact conclusions. Our findings suggest that state-of-the-art
general-domain models may already exhibit strong medical knowledge and
reasoning capabilities, and offer recommendations to strengthen the conclusions
of future studies.",2024-11-06,2024,2024-11,medical
"Humans and Large Language Models in Clinical Decision Support: A Study
  with Medical Calculators","Although large language models (LLMs) have been assessed for general medical
knowledge using licensing exams, their ability to support clinical
decision-making, such as selecting medical calculators, remains uncertain. We
assessed nine LLMs, including open-source, proprietary, and domain-specific
models, with 1,009 multiple-choice question-answer pairs across 35 clinical
calculators and compared LLMs to humans on a subset of questions. While the
highest-performing LLM, OpenAI o1, provided an answer accuracy of 66.0% (CI:
56.7-75.3%) on the subset of 100 questions, two human annotators nominally
outperformed LLMs with an average answer accuracy of 79.5% (CI: 73.5-85.0%).
Ultimately, we evaluated medical trainees and LLMs in recommending medical
calculators across clinical scenarios like risk stratification and diagnosis.
With error analysis showing that the highest-performing LLMs continue to make
mistakes in comprehension (49.3% of errors) and calculator knowledge (7.1% of
errors), our findings highlight that LLMs are not superior to humans in
calculator recommendation.",2024-11-08,2024,2024-11,medical
"GuidelineGuard: An Agentic Framework for Medical Note Evaluation with
  Guideline Adherence","Although rapid advancements in Large Language Models (LLMs) are facilitating
the integration of artificial intelligence-based applications and services in
healthcare, limited research has focused on the systematic evaluation of
medical notes for guideline adherence. This paper introduces GuidelineGuard, an
agentic framework powered by LLMs that autonomously analyzes medical notes,
such as hospital discharge and office visit notes, to ensure compliance with
established healthcare guidelines. By identifying deviations from recommended
practices and providing evidence-based suggestions, GuidelineGuard helps
clinicians adhere to the latest standards from organizations like the WHO and
CDC. This framework offers a novel approach to improving documentation quality
and reducing clinical errors.",2024-11-09,2024,2024-11,medical
"Data-Driven Analysis of AI in Medical Device Software in China: Deep
  Learning and General AI Trends Based on Regulatory Data","Artificial intelligence (AI) in medical device software (MDSW) represents a
transformative clinical technology, attracting increasing attention within both
the medical community and the regulators. In this study, we leverage a
data-driven approach to automatically extract and analyze AI-enabled medical
devices (AIMD) from the National Medical Products Administration (NMPA)
regulatory database. The continued increase in publicly available regulatory
data requires scalable methods for analysis. Automation of regulatory
information screening is essential to create reproducible insights that can be
quickly updated in an ever changing medical device landscape. More than 4
million entries were assessed, identifying 2,174 MDSW registrations, including
531 standalone applications and 1,643 integrated within medical devices, of
which 43 were AI-enabled. It was shown that the leading medical specialties
utilizing AIMD include respiratory (20.5%), ophthalmology/endocrinology
(12.8%), and orthopedics (10.3%). This approach greatly improves the speed of
data extracting providing a greater ability to compare and contrast. This study
provides the first extensive, data-driven exploration of AIMD in China,
showcasing the potential of automated regulatory data analysis in understanding
and advancing the landscape of AI in medical technology.",2024-11-11,2024,2024-11,medical
"The Limited Impact of Medical Adaptation of Large Language and
  Vision-Language Models","Several recent works seek to adapt general-purpose large language models
(LLMs) and vision-language models (VLMs) for medical applications through
continued pretraining on publicly available biomedical corpora. These works
typically claim that such domain-adaptive pretraining improves performance on
various downstream medical tasks, such as answering medical exam questions. In
this paper, we compare ten ""medical"" LLMs and two VLMs against their
corresponding base models, arriving at a different conclusion: all medical VLMs
and nearly all medical LLMs fail to consistently improve over their base models
in the zero-/few-shot prompting and supervised fine-tuning regimes for medical
question answering (QA). For instance, on clinical-note-based QA tasks in the
3-shot setting, medical LLMs outperform their base models in only 26.7% of
cases, reach a (statistical) tie in 16.7% of cases, and perform significantly
worse in the remaining 56.7% of cases. Our conclusions are based on (i)
comparing each medical model directly against its base model; (ii) optimizing
the prompts for each model separately in zero-/few-shot prompting; and (iii)
accounting for statistical uncertainty in comparisons. Our findings suggest
that state-of-the-art general-domain models may already exhibit strong medical
knowledge and reasoning capabilities, and offer recommendations to strengthen
the conclusions of future studies.",2024-11-13,2024,2024-11,medical
"Comprehensive and Practical Evaluation of Retrieval-Augmented Generation
  Systems for Medical Question Answering","Retrieval-augmented generation (RAG) has emerged as a promising approach to
enhance the performance of large language models (LLMs) in knowledge-intensive
tasks such as those from medical domain. However, the sensitive nature of the
medical domain necessitates a completely accurate and trustworthy system. While
existing RAG benchmarks primarily focus on the standard retrieve-answer
setting, they overlook many practical scenarios that measure crucial aspects of
a reliable medical system. This paper addresses this gap by providing a
comprehensive evaluation framework for medical question-answering (QA) systems
in a RAG setting for these situations, including sufficiency, integration, and
robustness. We introduce Medical Retrieval-Augmented Generation Benchmark
(MedRGB) that provides various supplementary elements to four medical QA
datasets for testing LLMs' ability to handle these specific scenarios.
Utilizing MedRGB, we conduct extensive evaluations of both state-of-the-art
commercial LLMs and open-source models across multiple retrieval conditions.
Our experimental results reveals current models' limited ability to handle
noise and misinformation in the retrieved documents. We further analyze the
LLMs' reasoning processes to provides valuable insights and future directions
for developing RAG systems in this critical medical domain.",2024-11-14,2024,2024-11,medical
A Benchmark for Long-Form Medical Question Answering,"There is a lack of benchmarks for evaluating large language models (LLMs) in
long-form medical question answering (QA). Most existing medical QA evaluation
benchmarks focus on automatic metrics and multiple-choice questions. While
valuable, these benchmarks fail to fully capture or assess the complexities of
real-world clinical applications where LLMs are being deployed. Furthermore,
existing studies on evaluating long-form answer generation in medical QA are
primarily closed-source, lacking access to human medical expert annotations,
which makes it difficult to reproduce results and enhance existing baselines.
In this work, we introduce a new publicly available benchmark featuring
real-world consumer medical questions with long-form answer evaluations
annotated by medical doctors. We performed pairwise comparisons of responses
from various open and closed-source medical and general-purpose LLMs based on
criteria such as correctness, helpfulness, harmfulness, and bias. Additionally,
we performed a comprehensive LLM-as-a-judge analysis to study the alignment
between human judgments and LLMs. Our preliminary results highlight the strong
potential of open LLMs in medical QA compared to leading closed models. Code &
Data: https://github.com/lavita-ai/medical-eval-sphere",2024-11-14,2024,2024-11,medical
"Artificial Intelligence for Infectious Disease Prediction and
  Prevention: A Comprehensive Review","Artificial Intelligence (AI) and infectious diseases prediction have recently
experienced a common development and advancement. Machine learning (ML)
apparition, along with deep learning (DL) emergence, extended many approaches
against diseases apparition and their spread. And despite their outstanding
results in predicting infectious diseases, conflicts appeared regarding the
types of data used and how they can be studied, analyzed, and exploited using
various emerging methods. This has led to some ongoing discussions in the
field. This research aims not only to provide an overview of what has been
accomplished, but also to highlight the difficulties related to the types of
data used, and the learning methods applied for each research objective. It
categorizes these contributions into three areas: predictions using Public
Health Data to prevent the spread of a transmissible disease within a region;
predictions using Patients' Medical Data to detect whether a person is infected
by a transmissible disease; and predictions using both Public and patient
medical data to estimate the extent of disease spread in a population. The
paper also critically assesses the potential of AI and outlines its limitations
in infectious disease management.",2024-11-14,2024,2024-11,medical
"Exploring Zero-Shot Anomaly Detection with CLIP in Medical Imaging: Are
  We There Yet?","Zero-shot anomaly detection (ZSAD) offers potential for identifying anomalies
in medical imaging without task-specific training. In this paper, we evaluate
CLIP-based models, originally developed for industrial tasks, on brain tumor
detection using the BraTS-MET dataset. Our analysis examines their ability to
detect medical-specific anomalies with no or minimal supervision, addressing
the challenges posed by limited data annotation. While these models show
promise in transferring general knowledge to medical tasks, their performance
falls short of the precision required for clinical use. Our findings highlight
the need for further adaptation before CLIP-based models can be reliably
applied to medical anomaly detection.",2024-11-14,2024,2024-11,medical
"Med-Bot: An AI-Powered Assistant to Provide Accurate and Reliable
  Medical Information","This paper introduces Med-Bot, an AI-powered chatbot designed to provide
users with accurate and reliable medical information. Utilizing advanced
libraries and frameworks such as PyTorch, Chromadb, Langchain and Autogptq,
Med-Bot is built to handle the complexities of natural language understanding
in a healthcare context. The integration of llamaassisted data processing and
AutoGPT-Q provides enhanced performance in processing and responding to queries
based on PDFs of medical literature, ensuring that users receive precise and
trustworthy information. This research details the methodologies employed in
developing Med-Bot and evaluates its effectiveness in disseminating healthcare
information.",2024-11-14,2024,2024-11,medical
Explainable Artificial Intelligence for Medical Applications: A Review,"The continuous development of artificial intelligence (AI) theory has
propelled this field to unprecedented heights, owing to the relentless efforts
of scholars and researchers. In the medical realm, AI takes a pivotal role,
leveraging robust machine learning (ML) algorithms. AI technology in medical
imaging aids physicians in X-ray, computed tomography (CT) scans, and magnetic
resonance imaging (MRI) diagnoses, conducts pattern recognition and disease
prediction based on acoustic data, delivers prognoses on disease types and
developmental trends for patients, and employs intelligent health management
wearable devices with human-computer interaction technology to name but a few.
While these well-established applications have significantly assisted in
medical field diagnoses, clinical decision-making, and management,
collaboration between the medical and AI sectors faces an urgent challenge: How
to substantiate the reliability of decision-making? The underlying issue stems
from the conflict between the demand for accountability and result transparency
in medical scenarios and the black-box model traits of AI. This article reviews
recent research grounded in explainable artificial intelligence (XAI), with an
emphasis on medical practices within the visual, audio, and multimodal
perspectives. We endeavour to categorise and synthesise these practices, aiming
to provide support and guidance for future researchers and healthcare
professionals.",2024-11-15,2024,2024-11,medical
"Towards Next-Generation Medical Agent: How o1 is Reshaping
  Decision-Making in Medical Scenarios","Artificial Intelligence (AI) has become essential in modern healthcare, with
large language models (LLMs) offering promising advances in clinical
decision-making. Traditional model-based approaches, including those leveraging
in-context demonstrations and those with specialized medical fine-tuning, have
demonstrated strong performance in medical language processing but struggle
with real-time adaptability, multi-step reasoning, and handling complex medical
tasks. Agent-based AI systems address these limitations by incorporating
reasoning traces, tool selection based on context, knowledge retrieval, and
both short- and long-term memory. These additional features enable the medical
AI agent to handle complex medical scenarios where decision-making should be
built on real-time interaction with the environment. Therefore, unlike
conventional model-based approaches that treat medical queries as isolated
questions, medical AI agents approach them as complex tasks and behave more
like human doctors. In this paper, we study the choice of the backbone LLM for
medical AI agents, which is the foundation for the agent's overall reasoning
and action generation. In particular, we consider the emergent o1 model and
examine its impact on agents' reasoning, tool-use adaptability, and real-time
information retrieval across diverse clinical scenarios, including high-stakes
settings such as intensive care units (ICUs). Our findings demonstrate o1's
ability to enhance diagnostic accuracy and consistency, paving the way for
smarter, more responsive AI tools that support better patient outcomes and
decision-making efficacy in clinical practice.",2024-11-16,2024,2024-11,medical
BianCang: A Traditional Chinese Medicine Large Language Model,"The rise of large language models (LLMs) has driven significant progress in
medical applications, including traditional Chinese medicine (TCM). However,
current medical LLMs struggle with TCM diagnosis and syndrome differentiation
due to substantial differences between TCM and modern medical theory, and the
scarcity of specialized, high-quality corpora. This paper addresses these
challenges by proposing BianCang, a TCM-specific LLM, using a two-stage
training process that first injects domain-specific knowledge and then aligns
it through targeted stimulation. To enhance diagnostic and differentiation
capabilities, we constructed pre-training corpora, instruction-aligned datasets
based on real hospital records, and the ChP-TCM dataset derived from the
Pharmacopoeia of the People's Republic of China. We compiled extensive TCM and
medical corpora for continuous pre-training and supervised fine-tuning,
building a comprehensive dataset to refine the model's understanding of TCM.
Evaluations across 11 test sets involving 29 models and 4 tasks demonstrate the
effectiveness of BianCang, offering valuable insights for future research.
Code, datasets, and models are available at
https://github.com/QLU-NLP/BianCang.",2024-11-17,2024,2024-11,medical
TP-UNet: Temporal Prompt Guided UNet for Medical Image Segmentation,"The advancement of medical image segmentation techniques has been propelled
by the adoption of deep learning techniques, particularly UNet-based
approaches, which exploit semantic information to improve the accuracy of
segmentations. However, the order of organs in scanned images has been
disregarded by current medical image segmentation approaches based on UNet.
Furthermore, the inherent network structure of UNet does not provide direct
capabilities for integrating temporal information. To efficiently integrate
temporal information, we propose TP-UNet that utilizes temporal prompts,
encompassing organ-construction relationships, to guide the segmentation UNet
model. Specifically, our framework is featured with cross-attention and
semantic alignment based on unsupervised contrastive learning to combine
temporal prompts and image features effectively. Extensive evaluations on two
medical image segmentation datasets demonstrate the state-of-the-art
performance of TP-UNet. Our implementation will be open-sourced after
acceptance.",2024-11-18,2024,2024-11,medical
"Ethical Challenges and Evolving Strategies in the Integration of
  Artificial Intelligence into Clinical Practice","Artificial intelligence (AI) has rapidly transformed various sectors,
including healthcare, where it holds the potential to revolutionize clinical
practice and improve patient outcomes. However, its integration into medical
settings brings significant ethical challenges that need careful consideration.
This paper examines the current state of AI in healthcare, focusing on five
critical ethical concerns: justice and fairness, transparency, patient consent
and confidentiality, accountability, and patient-centered and equitable care.
These concerns are particularly pressing as AI systems can perpetuate or even
exacerbate existing biases, often resulting from non-representative datasets
and opaque model development processes. The paper explores how bias, lack of
transparency, and challenges in maintaining patient trust can undermine the
effectiveness and fairness of AI applications in healthcare. In addition, we
review existing frameworks for the regulation and deployment of AI, identifying
gaps that limit the widespread adoption of these systems in a just and
equitable manner. Our analysis provides recommendations to address these
ethical challenges, emphasizing the need for fairness in algorithm design,
transparency in model decision-making, and patient-centered approaches to
consent and data privacy. By highlighting the importance of continuous ethical
scrutiny and collaboration between AI developers, clinicians, and ethicists, we
outline pathways for achieving more responsible and inclusive AI implementation
in healthcare. These strategies, if adopted, could enhance both the clinical
value of AI and the trustworthiness of AI systems among patients and healthcare
professionals, ensuring that these technologies serve all populations
equitably.",2024-11-18,2024,2024-11,medical
Medical Video Generation for Disease Progression Simulation,"Modeling disease progression is crucial for improving the quality and
efficacy of clinical diagnosis and prognosis, but it is often hindered by a
lack of longitudinal medical image monitoring for individual patients. To
address this challenge, we propose the first Medical Video Generation (MVG)
framework that enables controlled manipulation of disease-related image and
video features, allowing precise, realistic, and personalized simulations of
disease progression. Our approach begins by leveraging large language models
(LLMs) to recaption prompt for disease trajectory. Next, a controllable
multi-round diffusion model simulates the disease progression state for each
patient, creating realistic intermediate disease state sequence. Finally, a
diffusion-based video transition generation model interpolates disease
progression between these states. We validate our framework across three
medical imaging domains: chest X-ray, fundus photography, and skin image. Our
results demonstrate that MVG significantly outperforms baseline models in
generating coherent and clinically plausible disease trajectories. Two user
studies by veteran physicians, provide further validation and insights into the
clinical utility of the generated sequences. MVG has the potential to assist
healthcare providers in modeling disease trajectories, interpolating missing
medical image data, and enhancing medical education through realistic, dynamic
visualizations of disease progression.",2024-11-18,2024,2024-11,medical
Conversational Medical AI: Ready for Practice,"The shortage of doctors is creating a critical squeeze in access to medical
expertise. While conversational Artificial Intelligence (AI) holds promise in
addressing this problem, its safe deployment in patient-facing roles remains
largely unexplored in real-world medical settings. We present the first
large-scale evaluation of a physician-supervised LLM-based conversational agent
in a real-world medical setting.
  Our agent, Mo, was integrated into an existing medical advice chat service.
Over a three-week period, we conducted a randomized controlled experiment with
926 cases to evaluate patient experience and satisfaction. Among these, Mo
handled 298 complete patient interactions, for which we report
physician-assessed measures of safety and medical accuracy.
  Patients reported higher clarity of information (3.73 vs 3.62 out of 4, p <
0.05) and overall satisfaction (4.58 vs 4.42 out of 5, p < 0.05) with
AI-assisted conversations compared to standard care, while showing equivalent
levels of trust and perceived empathy. The high opt-in rate (81% among
respondents) exceeded previous benchmarks for AI acceptance in healthcare.
Physician oversight ensured safety, with 95% of conversations rated as ""good""
or ""excellent"" by general practitioners experienced in operating a medical
advice chat service.
  Our findings demonstrate that carefully implemented AI medical assistants can
enhance patient experience while maintaining safety standards through physician
supervision. This work provides empirical evidence for the feasibility of AI
deployment in healthcare communication and insights into the requirements for
successful integration into existing healthcare services.",2024-11-19,2024,2024-11,medical
"Enhancing Multi-Class Disease Classification: Neoplasms, Cardiovascular,
  Nervous System, and Digestive Disorders Using Advanced LLMs","In this research, we explored the improvement in terms of multi-class disease
classification via pre-trained language models over Medical-Abstracts-TC-Corpus
that spans five medical conditions. We excluded non-cancer conditions and
examined four specific diseases. We assessed four LLMs, BioBERT, XLNet, and
BERT, as well as a novel base model (Last-BERT). BioBERT, which was pre-trained
on medical data, demonstrated superior performance in medical text
classification (97% accuracy). Surprisingly, XLNet followed closely (96%
accuracy), demonstrating its generalizability across domains even though it was
not pre-trained on medical data. LastBERT, a custom model based on the lighter
version of BERT, also proved competitive with 87.10% accuracy (just under
BERT's 89.33%). Our findings confirm the importance of specialized models such
as BioBERT and also support impressions around more general solutions like
XLNet and well-tuned transformer architectures with fewer parameters (in this
case, LastBERT) in medical domain tasks.",2024-11-19,2024,2024-11,medical
"GraphCL: Graph-based Clustering for Semi-Supervised Medical Image
  Segmentation","Semi-supervised learning (SSL) has made notable advancements in medical image
segmentation (MIS), particularly in scenarios with limited labeled data and
significantly enhancing data utilization efficiency. Previous methods primarily
focus on complex training strategies to utilize unlabeled data but neglect the
importance of graph structural information. Different from existing methods, we
propose a graph-based clustering for semi-supervised medical image segmentation
(GraphCL) by jointly modeling graph data structure in a unified deep model. The
proposed GraphCL model enjoys several advantages. Firstly, to the best of our
knowledge, this is the first work to model the data structure information for
semi-supervised medical image segmentation (SSMIS). Secondly, to get the
clustered features across different graphs, we integrate both pairwise
affinities between local image features and raw features as inputs. Extensive
experimental results on three standard benchmarks show that the proposed
GraphCL algorithm outperforms state-of-the-art semi-supervised medical image
segmentation methods.",2024-11-20,2024,2024-11,medical
"Uni-Mlip: Unified Self-supervision for Medical Vision Language
  Pre-training","Recent advancements in vision-language pre-training via contrastive learning
have significantly improved performance across computer vision tasks. However,
in the medical domain, obtaining multimodal data is often costly and
challenging due to privacy, sensitivity, and annotation complexity. To mitigate
data scarcity while boosting model performance, we introduce \textbf{Uni-Mlip},
a unified self-supervision framework specifically designed to enhance medical
vision-language pre-training. Uni-Mlip seamlessly integrates cross-modality,
uni-modality, and fused-modality self-supervision techniques at the data-level
and the feature-level. Additionally, Uni-Mlip tailors uni-modal image
self-supervision to accommodate the unique characteristics of medical images.
Our experiments across datasets of varying scales demonstrate that Uni-Mlip
significantly surpasses current state-of-the-art methods in three key
downstream tasks: image-text retrieval, image classification, and visual
question answering (VQA).",2024-11-20,2024,2024-11,medical
Uterine Ultrasound Image Captioning Using Deep Learning Techniques,"Medical imaging has significantly revolutionized medical diagnostics and
treatment planning, progressing from early X-ray usage to sophisticated methods
like MRIs, CT scans, and ultrasounds. This paper investigates the use of deep
learning for medical image captioning, with a particular focus on uterine
ultrasound images. These images are vital in obstetrics and gynecology for
diagnosing and monitoring various conditions across different age groups.
However, their interpretation is often challenging due to their complexity and
variability. To address this, a deep learning-based medical image captioning
system was developed, integrating Convolutional Neural Networks with a
Bidirectional Gated Recurrent Unit network. This hybrid model processes both
image and text features to generate descriptive captions for uterine ultrasound
images. Our experimental results demonstrate the effectiveness of this approach
over baseline methods, with the proposed model achieving superior performance
in generating accurate and informative captions, as indicated by higher BLEU
and ROUGE scores. By enhancing the interpretation of uterine ultrasound images,
our research aims to assist medical professionals in making timely and accurate
diagnoses, ultimately contributing to improved patient care.",2024-11-21,2024,2024-11,medical
"Med-PerSAM: One-Shot Visual Prompt Tuning for Personalized Segment
  Anything Model in Medical Domain","Leveraging pre-trained models with tailored prompts for in-context learning
has proven highly effective in NLP tasks. Building on this success, recent
studies have applied a similar approach to the Segment Anything Model (SAM)
within a ``one-shot"" framework, where only a single reference image and its
label are employed. However, these methods face limitations in the medical
domain, primarily due to SAM's essential requirement for visual prompts and the
over-reliance on pixel similarity for generating them. This dependency may lead
to (1) inaccurate prompt generation and (2) clustering of point prompts,
resulting in suboptimal outcomes. To address these challenges, we introduce
\textbf{Med-PerSAM}, a novel and straightforward one-shot framework designed
for the medical domain. Med-PerSAM uses only visual prompt engineering and
eliminates the need for additional training of the pretrained SAM or human
intervention, owing to our novel automated prompt generation process. By
integrating our lightweight warping-based prompt tuning model with SAM, we
enable the extraction and iterative refinement of visual prompts, enhancing the
performance of the pre-trained SAM. This advancement is particularly meaningful
in the medical domain, where creating visual prompts poses notable challenges
for individuals lacking medical expertise. Our model outperforms various
foundational models and previous SAM-based approaches across diverse 2D medical
imaging datasets.",2024-11-25,2024,2024-11,medical
HOPPR Medical-Grade Platform for Medical Imaging AI,"Technological advances in artificial intelligence (AI) have enabled the
development of large vision language models (LVLMs) that are trained on
millions of paired image and text samples. Subsequent research efforts have
demonstrated great potential of LVLMs to achieve high performance in medical
imaging use cases (e.g., radiology report generation), but there remain
barriers that hinder the ability to deploy these solutions broadly. These
include the cost of extensive computational requirements for developing large
scale models, expertise in the development of sophisticated AI models, and the
difficulty in accessing substantially large, high-quality datasets that
adequately represent the population in which the LVLM solution is to be
deployed. The HOPPR Medical-Grade Platform addresses these barriers by
providing powerful computational infrastructure, a suite of foundation models
on top of which developers can fine-tune for their specific use cases, and a
robust quality management system that sets a standard for evaluating fine-tuned
models for deployment in clinical settings. The HOPPR Platform has access to
millions of imaging studies and text reports sourced from hundreds of imaging
centers from diverse populations to pretrain foundation models and enable use
case-specific cohorts for fine-tuning. All data are deidentified and securely
stored for HIPAA compliance. Additionally, developers can securely host models
on the HOPPR platform and access them via an API to make inferences using these
models within established clinical workflows. With the Medical-Grade Platform,
HOPPR's mission is to expedite the deployment of LVLM solutions for medical
imaging and ultimately optimize radiologist's workflows and meet the growing
demands of the field.",2024-11-26,2024,2024-11,medical
"Mapping Public Perception of Artificial Intelligence: Expectations,
  Risk-Benefit Tradeoffs, and Value As Determinants for Societal Acceptance","Understanding public perception of artificial intelligence (AI) and the
tradeoffs between potential risks and benefits is crucial, as these perceptions
might shape policy decisions, influence innovation trajectories for successful
market strategies, and determine individual and societal acceptance of AI
technologies. Using a representative sample of 1100 participants from Germany,
this study examines mental models of AI. Participants quantitatively evaluated
71 statements about AI's future capabilities (e.g., autonomous driving, medical
care, art, politics, warfare, and societal divides), assessing the expected
likelihood of occurrence, perceived risks, benefits, and overall value. We
present rankings of these projections alongside visual mappings illustrating
public risk-benefit tradeoffs. While many scenarios were deemed likely,
participants often associated them with high risks, limited benefits, and low
overall value. Across all scenarios, 96.4% ($r^2=96.4\%$) of the variance in
value assessment can be explained by perceived risks ($\beta=-.504$) and
perceived benefits ($\beta=+.710$), with no significant relation to expected
likelihood. Demographics and personality traits influenced perceptions of
risks, benefits, and overall evaluations, underscoring the importance of
increasing AI literacy and tailoring public information to diverse user needs.
These findings provide actionable insights for researchers, developers, and
policymakers by highlighting critical public concerns and individual factors
essential to align AI development with individual values.",2024-11-28,2024,2024-11,medical
"Adaptive Interactive Segmentation for Multimodal Medical Imaging via
  Selection Engine","In medical image analysis, achieving fast, efficient, and accurate
segmentation is essential for automated diagnosis and treatment. Although
recent advancements in deep learning have significantly improved segmentation
accuracy, current models often face challenges in adaptability and
generalization, particularly when processing multi-modal medical imaging data.
These limitations stem from the substantial variations between imaging
modalities and the inherent complexity of medical data. To address these
challenges, we propose the Strategy-driven Interactive Segmentation Model
(SISeg), built on SAM2, which enhances segmentation performance across various
medical imaging modalities by integrating a selection engine. To mitigate
memory bottlenecks and optimize prompt frame selection during the inference of
2D image sequences, we developed an automated system, the Adaptive Frame
Selection Engine (AFSE). This system dynamically selects the optimal prompt
frames without requiring extensive prior medical knowledge and enhances the
interpretability of the model's inference process through an interactive
feedback mechanism. We conducted extensive experiments on 10 datasets covering
7 representative medical imaging modalities, demonstrating the SISeg model's
robust adaptability and generalization in multi-modal tasks. The project page
and code will be available at: [URL].",2024-11-29,2024,2024-11,medical
"Polish Medical Exams: A new dataset for cross-lingual medical knowledge
  transfer assessment","Large Language Models (LLMs) have demonstrated significant potential in
handling specialized tasks, including medical problem-solving. However, most
studies predominantly focus on English-language contexts. This study introduces
a novel benchmark dataset based on Polish medical licensing and specialization
exams (LEK, LDEK, PES) taken by medical doctor candidates and practicing
doctors pursuing specialization. The dataset was web-scraped from publicly
available resources provided by the Medical Examination Center and the Chief
Medical Chamber. It comprises over 24,000 exam questions, including a subset of
parallel Polish-English corpora, where the English portion was professionally
translated by the examination center for foreign candidates. By creating a
structured benchmark from these existing exam questions, we systematically
evaluate state-of-the-art LLMs, including general-purpose, domain-specific, and
Polish-specific models, and compare their performance against human medical
students. Our analysis reveals that while models like GPT-4o achieve near-human
performance, significant challenges persist in cross-lingual translation and
domain-specific understanding. These findings underscore disparities in model
performance across languages and medical specialties, highlighting the
limitations and ethical considerations of deploying LLMs in clinical practice.",2024-11-30,2024,2024-11,medical
"Medchain: Bridging the Gap Between LLM Agents and Clinical Practice
  through Interactive Sequential Benchmarking","Clinical decision making (CDM) is a complex, dynamic process crucial to
healthcare delivery, yet it remains a significant challenge for artificial
intelligence systems. While Large Language Model (LLM)-based agents have been
tested on general medical knowledge using licensing exams and knowledge
question-answering tasks, their performance in the CDM in real-world scenarios
is limited due to the lack of comprehensive testing datasets that mirror actual
medical practice. To address this gap, we present MedChain, a dataset of 12,163
clinical cases that covers five key stages of clinical workflow. MedChain
distinguishes itself from existing benchmarks with three key features of
real-world clinical practice: personalization, interactivity, and
sequentiality. Further, to tackle real-world CDM challenges, we also propose
MedChain-Agent, an AI system that integrates a feedback mechanism and a
MCase-RAG module to learn from previous cases and adapt its responses.
MedChain-Agent demonstrates remarkable adaptability in gathering information
dynamically and handling sequential clinical tasks, significantly outperforming
existing approaches. The relevant dataset and code will be released upon
acceptance of this paper.",2024-12-02,2024,2024-12,medical
"U-Net in Medical Image Segmentation: A Review of Its Applications Across
  Modalities","Medical imaging is essential in healthcare to provide key insights into
patient anatomy and pathology, aiding in diagnosis and treatment. Non-invasive
techniques such as X-ray, Magnetic Resonance Imaging (MRI), Computed Tomography
(CT), and Ultrasound (US), capture detailed images of organs, tissues, and
abnormalities. Effective analysis of these images requires precise segmentation
to delineate regions of interest (ROI), such as organs or lesions. Traditional
segmentation methods, relying on manual feature-extraction, are labor-intensive
and vary across experts. Recent advancements in Artificial Intelligence (AI)
and Deep Learning (DL), particularly convolutional models such as U-Net and its
variants (U-Net++ and U-Net 3+), have transformed medical image segmentation
(MIS) by automating the process and enhancing accuracy. These models enable
efficient, precise pixel-wise classification across various imaging modalities,
overcoming the limitations of manual segmentation. This review explores various
medical imaging techniques, examines the U-Net architectures and their
adaptations, and discusses their application across different modalities. It
also identifies common challenges in MIS and proposes potential solutions.",2024-12-03,2024,2024-12,medical
"Intuitive Axial Augmentation Using Polar-Sine-Based Piecewise Distortion
  for Medical Slice-Wise Segmentation","Most data-driven models for medical image analysis rely on universal
augmentations to improve accuracy. Experimental evidence has confirmed their
effectiveness, but the unclear mechanism underlying them poses a barrier to the
widespread acceptance and trust in such methods within the medical community.
We revisit and acknowledge the unique characteristics of medical images apart
from traditional digital images, and consequently, proposed a medical-specific
augmentation algorithm that is more elastic and aligns well with radiology scan
procedure. The method performs piecewise affine with sinusoidal distorted ray
according to radius on polar coordinates, thus simulating uncertain postures of
human lying flat on the scanning table. Our method could generate human
visceral distribution without affecting the fundamental relative position on
axial plane. Two non-adaptive algorithms, namely Meta-based Scan Table Removal
and Similarity-Guided Parameter Search, are introduced to bolster robustness of
our augmentation method. In contrast to other methodologies, our method is
highlighted for its intuitive design and ease of understanding for medical
professionals, thereby enhancing its applicability in clinical scenarios.
Experiments show our method improves accuracy with two modality across multiple
famous segmentation frameworks without requiring more data samples. Our preview
code is available in: https://github.com/MGAMZ/PSBPD.",2024-12-04,2024,2024-12,medical
"Privacy-Preserving in Medical Image Analysis: A Review of Methods and
  Applications","With the rapid advancement of artificial intelligence and deep learning,
medical image analysis has become a critical tool in modern healthcare,
significantly improving diagnostic accuracy and efficiency. However, AI-based
methods also raise serious privacy concerns, as medical images often contain
highly sensitive patient information. This review offers a comprehensive
overview of privacy-preserving techniques in medical image analysis, including
encryption, differential privacy, homomorphic encryption, federated learning,
and generative adversarial networks. We explore the application of these
techniques across various medical image analysis tasks, such as diagnosis,
pathology, and telemedicine. Notably, we organizes the review based on specific
challenges and their corresponding solutions in different medical image
analysis applications, so that technical applications are directly aligned with
practical issues, addressing gaps in the current research landscape.
Additionally, we discuss emerging trends, such as zero-knowledge proofs and
secure multi-party computation, offering insights for future research. This
review serves as a valuable resource for researchers and practitioners and can
help advance privacy-preserving in medical image analysis.",2024-12-05,2024,2024-12,medical
"Electrocardiogram (ECG) Based Cardiac Arrhythmia Detection and
  Classification using Machine Learning Algorithms","The rapid advancements in Artificial Intelligence, specifically Machine
Learning (ML) and Deep Learning (DL), have opened new prospects in medical
sciences for improved diagnosis, prognosis, and treatment of severe health
conditions. This paper focuses on the development of an ML model with high
predictive accuracy to classify arrhythmic electrocardiogram (ECG) signals. The
ECG signals datasets utilized in this study were sourced from the PhysioNet and
MIT-BIH databases. The research commenced with binary classification, where an
optimized Bidirectional Long Short-Term Memory (Bi-LSTM) model yielded
excellent results in differentiating normal and atrial fibrillation signals. A
pivotal aspect of this research was a survey among medical professionals, which
not only validated the practicality of AI-based ECG classifiers but also
identified areas for improvement, including accuracy and the inclusion of more
arrhythmia types. These insights drove the development of an advanced
Convolutional Neural Network (CNN) system capable of classifying five different
types of ECG signals with better accuracy and precision. The CNN model's robust
performance was ensured through rigorous stratified 5-fold cross validation. A
web portal was also developed to demonstrate real-world utility, offering
access to the trained model for real-time classification. This study highlights
the potential applications of such models in remote health monitoring,
predictive healthcare, assistive diagnostic tools, and simulated environments
for educational training and interdisciplinary collaboration between data
scientists and medical personnel.",2024-12-07,2024,2024-12,medical
"Participatory Assessment of Large Language Model Applications in an
  Academic Medical Center","Although Large Language Models (LLMs) have shown promising performance in
healthcare-related applications, their deployment in the medical domain poses
unique challenges of ethical, regulatory, and technical nature. In this study,
we employ a systematic participatory approach to investigate the needs and
expectations regarding clinical applications of LLMs at Lausanne University
Hospital, an academic medical center in Switzerland. Having identified
potential LLM use-cases in collaboration with thirty stakeholders, including
clinical staff across 11 departments as well nursing and patient
representatives, we assess the current feasibility of these use-cases taking
into account the regulatory frameworks, data protection regulation, bias,
hallucinations, and deployment constraints. This study provides a framework for
a participatory approach to identifying institutional needs with respect to
introducing advanced technologies into healthcare practice, and a realistic
analysis of the technology readiness level of LLMs for medical applications,
highlighting the issues that would need to be overcome LLMs in healthcare to be
ethical, and regulatory compliant.",2024-12-09,2024,2024-12,medical
"Advancing Music Therapy: Integrating Eastern Five-Element Music Theory
  and Western Techniques with AI in the Novel Five-Element Harmony System","In traditional medical practices, music therapy has proven effective in
treating various psychological and physiological ailments. Particularly in
Eastern traditions, the Five Elements Music Therapy (FEMT), rooted in
traditional Chinese medicine, possesses profound cultural significance and
unique therapeutic philosophies. With the rapid advancement of Information
Technology and Artificial Intelligence, applying these modern technologies to
FEMT could enhance the personalization and cultural relevance of the therapy
and potentially improve therapeutic outcomes. In this article, we developed a
music therapy system for the first time by applying the theory of the five
elements in music therapy to practice. This innovative approach integrates
advanced Information Technology and Artificial Intelligence with Five-Element
Music Therapy (FEMT) to enhance personalized music therapy practices. As
traditional music therapy predominantly follows Western methodologies, the
unique aspects of Eastern practices, specifically the Five-Element theory from
traditional Chinese medicine, should be considered. This system aims to bridge
this gap by utilizing computational technologies to provide a more
personalized, culturally relevant, and therapeutically effective music therapy
experience.",2024-12-09,2024,2024-12,medical
"MMedPO: Aligning Medical Vision-Language Models with Clinical-Aware
  Multimodal Preference Optimization","The advancement of Large Vision-Language Models (LVLMs) has propelled their
application in the medical field. However, Medical LVLMs (Med-LVLMs) encounter
factuality challenges due to modality misalignment, where the models prioritize
textual knowledge over visual input, leading to hallucinations that contradict
information in medical images. Previous attempts to enhance modality alignment
in Med-LVLMs through preference optimization have inadequately mitigated
clinical relevance in preference data, making these samples easily
distinguishable and reducing alignment effectiveness. To address this
challenge, we propose MMedPO, a novel multimodal medical preference
optimization approach that considers the clinical relevance of preference
samples to enhance Med-LVLM alignment. MMedPO curates multimodal preference
data by introducing two types of dispreference: (1) plausible hallucinations
injected through target Med-LVLMs or GPT-4o to produce medically inaccurate
responses, and (2) lesion region neglect achieved through local lesion-noising,
disrupting visual understanding of critical areas. We then calculate clinical
relevance for each sample based on scores from multiple Med-LLMs and visual
tools, and integrate these scores into the preference optimization process as
weights, enabling effective alignment. Our experiments demonstrate that MMedPO
significantly enhances factual accuracy in Med-LVLMs, achieving substantial
improvements over existing preference optimization methods by averaging 14.2%
and 51.7% across the Med-VQA and report generation tasks. Our code are
available in https://github.com/aiming-lab/MMedPO.",2024-12-09,2024,2024-12,medical
"Performance of a large language model-Artificial Intelligence based
  chatbot for counseling patients with sexually transmitted infections and
  genital diseases","Introduction: Global burden of sexually transmitted infections (STIs) is
rising out of proportion to specialists. Current chatbots like ChatGPT are not
tailored for handling STI-related concerns out of the box. We developed Otiz,
an Artificial Intelligence-based (AI-based) chatbot platform designed
specifically for STI detection and counseling, and assessed its performance.
Methods: Otiz employs a multi-agent system architecture based on GPT4-0613,
leveraging large language model (LLM) and Deterministic Finite Automaton
principles to provide contextually relevant, medically accurate, and empathetic
responses. Its components include modules for general STI information,
emotional recognition, Acute Stress Disorder detection, and psychotherapy. A
question suggestion agent operates in parallel. Four STIs (anogenital warts,
herpes, syphilis, urethritis/cervicitis) and 2 non-STIs (candidiasis, penile
cancer) were evaluated using prompts mimicking patient language. Each prompt
was independently graded by two venereologists conversing with Otiz as patient
actors on 6 criteria using Numerical Rating Scale ranging from 0 (poor) to 5
(excellent). Results: Twenty-three venereologists did 60 evaluations of 30
prompts. Across STIs, Otiz scored highly on diagnostic accuracy (4.1-4.7),
overall accuracy (4.3-4.6), correctness of information (5.0), comprehensibility
(4.2-4.4), and empathy (4.5-4.8). However, relevance scores were lower
(2.9-3.6), suggesting some redundancy. Diagnostic scores for non-STIs were
lower (p=0.038). Inter-observer agreement was strong, with differences greater
than 1 point occurring in only 12.7% of paired evaluations. Conclusions: AI
conversational agents like Otiz can provide accurate, correct, discrete,
non-judgmental, readily accessible and easily understandable STI-related
information in an empathetic manner, and can alleviate the burden on healthcare
systems.",2024-12-11,2024,2024-12,medical
CareBot: A Pioneering Full-Process Open-Source Medical Language Model,"Recently, both closed-source LLMs and open-source communities have made
significant strides, outperforming humans in various general domains. However,
their performance in specific professional domains such as medicine, especially
within the open-source community, remains suboptimal due to the complexity of
medical knowledge. In this paper, we propose CareBot, a bilingual medical LLM,
which leverages a comprehensive approach integrating continuous pre-training
(CPT), supervised fine-tuning (SFT), and reinforcement learning with human
feedback (RLHF). Our novel two-stage CPT method, comprising Stable CPT and
Boost CPT, effectively bridges the gap between general and domain-specific
data, facilitating a smooth transition from pre-training to fine-tuning and
enhancing domain knowledge progressively. We also introduce DataRater, a model
designed to assess data quality during CPT, ensuring that the training data is
both accurate and relevant. For SFT, we develope a large and diverse bilingual
dataset, along with ConFilter, a metric to enhance multi-turn dialogue quality,
which is crucial to improving the model's ability to handle more complex
dialogues. The combination of high-quality data sources and innovative
techniques significantly improves CareBot's performance across a range of
medical applications. Our rigorous evaluations on Chinese and English
benchmarks confirm CareBot's effectiveness in medical consultation and
education. These advancements not only address current limitations in medical
LLMs but also set a new standard for developing effective and reliable
open-source models in the medical domain. We will open-source the datasets and
models later, contributing valuable resources to the research community.",2024-12-12,2024,2024-12,medical
"FAMNet: Frequency-aware Matching Network for Cross-domain Few-shot
  Medical Image Segmentation","Existing few-shot medical image segmentation (FSMIS) models fail to address a
practical issue in medical imaging: the domain shift caused by different
imaging techniques, which limits the applicability to current FSMIS tasks. To
overcome this limitation, we focus on the cross-domain few-shot medical image
segmentation (CD-FSMIS) task, aiming to develop a generalized model capable of
adapting to a broader range of medical image segmentation scenarios with
limited labeled data from the novel target domain. Inspired by the
characteristics of frequency domain similarity across different domains, we
propose a Frequency-aware Matching Network (FAMNet), which includes two key
components: a Frequency-aware Matching (FAM) module and a Multi-Spectral Fusion
(MSF) module. The FAM module tackles two problems during the meta-learning
phase: 1) intra-domain variance caused by the inherent support-query bias, due
to the different appearances of organs and lesions, and 2) inter-domain
variance caused by different medical imaging techniques. Additionally, we
design an MSF module to integrate the different frequency features decoupled by
the FAM module, and further mitigate the impact of inter-domain variance on the
model's segmentation performance. Combining these two modules, our FAMNet
surpasses existing FSMIS models and Cross-domain Few-shot Semantic Segmentation
models on three cross-domain datasets, achieving state-of-the-art performance
in the CD-FSMIS task.",2024-12-12,2024,2024-12,medical
"Embeddings are all you need! Achieving High Performance Medical Image
  Classification through Training-Free Embedding Analysis","Developing artificial intelligence (AI) and machine learning (ML) models for
medical imaging typically involves extensive training and testing on large
datasets, consuming significant computational time, energy, and resources.
There is a need for more efficient methods that can achieve comparable or
superior diagnostic performance without the associated resource burden. We
investigated the feasibility of replacing conventional training procedures with
an embedding-based approach that leverages concise and semantically meaningful
representations of medical images. Using pre-trained foundational
models-specifically, convolutional neural networks (CNN) like ResNet and
multimodal models like Contrastive Language-Image Pre-training (CLIP)-we
generated image embeddings for multi-class classification tasks. Simple linear
classifiers were then applied to these embeddings. The approach was evaluated
across diverse medical imaging modalities, including retinal images,
mammography, dermatoscopic images, and chest radiographs. Performance was
compared to benchmark models trained and tested using traditional methods. The
embedding-based models surpassed the benchmark area under the receiver
operating characteristic curve (AUC-ROC) scores by up to 87 percentage in
multi-class classification tasks across the various medical imaging modalities.
Notably, CLIP embedding models achieved the highest AUC-ROC scores,
demonstrating superior classification performance while significantly reducing
computational demands. Our study indicates that leveraging embeddings from
pre-trained foundational models can effectively replace conventional,
resource-intensive training and testing procedures in medical image analysis.
This embedding-based approach offers a more efficient alternative for image
segmentation, classification, and prediction, potentially accelerating AI
technology integration into clinical practice.",2024-12-12,2024,2024-12,medical
Medical Manifestation-Aware De-Identification,"Face de-identification (DeID) has been widely studied for common scenes, but
remains under-researched for medical scenes, mostly due to the lack of
large-scale patient face datasets. In this paper, we release MeMa, consisting
of over 40,000 photo-realistic patient faces. MeMa is re-generated from massive
real patient photos. By carefully modulating the generation and data-filtering
procedures, MeMa avoids breaching real patient privacy, while ensuring rich and
plausible medical manifestations. We recruit expert clinicians to annotate MeMa
with both coarse- and fine-grained labels, building the first medical-scene
DeID benchmark. Additionally, we propose a baseline approach for this new
medical-aware DeID task, by integrating data-driven medical semantic priors
into the DeID procedure. Despite its conciseness and simplicity, our approach
substantially outperforms previous ones. Dataset is available at
https://github.com/tianyuan168326/MeMa-Pytorch.",2024-12-14,2024,2024-12,medical
Overview of TREC 2024 Medical Video Question Answering (MedVidQA) Track,"One of the key goals of artificial intelligence (AI) is the development of a
multimodal system that facilitates communication with the visual world (image
and video) using a natural language query. Earlier works on medical question
answering primarily focused on textual and visual (image) modalities, which may
be inefficient in answering questions requiring demonstration. In recent years,
significant progress has been achieved due to the introduction of large-scale
language-vision datasets and the development of efficient deep neural
techniques that bridge the gap between language and visual understanding.
Improvements have been made in numerous vision-and-language tasks, such as
visual captioning visual question answering, and natural language video
localization. Most of the existing work on language vision focused on creating
datasets and developing solutions for open-domain applications. We believe
medical videos may provide the best possible answers to many first aid, medical
emergency, and medical education questions. With increasing interest in AI to
support clinical decision-making and improve patient engagement, there is a
need to explore such challenges and develop efficient algorithms for medical
language-video understanding and generation. Toward this, we introduced new
tasks to foster research toward designing systems that can understand medical
videos to provide visual answers to natural language questions, and are
equipped with multimodal capability to generate instruction steps from the
medical video. These tasks have the potential to support the development of
sophisticated downstream applications that can benefit the public and medical
professionals.",2024-12-15,2024,2024-12,medical
ACE-$M^3$: Automatic Capability Evaluator for Multimodal Medical Models,"As multimodal large language models (MLLMs) gain prominence in the medical
field, the need for precise evaluation methods to assess their effectiveness
has become critical. While benchmarks provide a reliable means to evaluate the
capabilities of MLLMs, traditional metrics like ROUGE and BLEU employed for
open domain evaluation only focus on token overlap and may not align with human
judgment. Although human evaluation is more reliable, it is labor-intensive,
costly, and not scalable. LLM-based evaluation methods have proven promising,
but to date, there is still an urgent need for open-source multimodal LLM-based
evaluators in the medical field. To address this issue, we introduce ACE-$M^3$,
an open-sourced \textbf{A}utomatic \textbf{C}apability \textbf{E}valuator for
\textbf{M}ultimodal \textbf{M}edical \textbf{M}odels specifically designed to
assess the question answering abilities of medical MLLMs. It first utilizes a
branch-merge architecture to provide both detailed analysis and a concise final
score based on standard medical evaluation criteria. Subsequently, a reward
token-based direct preference optimization (RTDPO) strategy is incorporated to
save training time without compromising performance of our model. Extensive
experiments have demonstrated the effectiveness of our ACE-$M^3$
model\footnote{\url{https://huggingface.co/collections/AIUSRTMP/ace-m3-67593297ff391b93e3e5d068}}
in evaluating the capabilities of medical MLLMs.",2024-12-16,2024,2024-12,medical
In-context learning for medical image segmentation,"Annotation of medical images, such as MRI and CT scans, is crucial for
evaluating treatment efficacy and planning radiotherapy. However, the extensive
workload of medical professionals limits their ability to annotate large image
datasets, posing a bottleneck for AI applications in medical imaging. To
address this, we propose In-context Cascade Segmentation (ICS), a novel method
that minimizes annotation requirements while achieving high segmentation
accuracy for sequential medical images. ICS builds on the UniverSeg framework,
which performs few-shot segmentation using support images without additional
training. By iteratively adding the inference results of each slice to the
support set, ICS propagates information forward and backward through the
sequence, ensuring inter-slice consistency. We evaluate the proposed method on
the HVSMR dataset, which includes segmentation tasks for eight cardiac regions.
Experimental results demonstrate that ICS significantly improves segmentation
performance in complex anatomical regions, particularly in maintaining boundary
consistency across slices, compared to baseline methods. The study also
highlights the impact of the number and position of initial support slices on
segmentation accuracy. ICS offers a promising solution for reducing annotation
burdens while delivering robust segmentation results, paving the way for its
broader adoption in clinical and research applications.",2024-12-17,2024,2024-12,medical
Clinical Trials Ontology Engineering with Large Language Models,"Managing clinical trial information is currently a significant challenge for
the medical industry, as traditional methods are both time-consuming and
costly. This paper proposes a simple yet effective methodology to extract and
integrate clinical trial data in a cost-effective and time-efficient manner.
Allowing the medical industry to stay up-to-date with medical developments.
Comparing time, cost, and quality of the ontologies created by humans, GPT3.5,
GPT4, and Llama3 (8b & 70b). Findings suggest that large language models (LLM)
are a viable option to automate this process both from a cost and time
perspective. This study underscores significant implications for medical
research where real-time data integration from clinical trials could become the
norm.",2024-12-18,2024,2024-12,medical
"Critique of Impure Reason: Unveiling the reasoning behaviour of medical
  Large Language Models","Background: Despite the current ubiquity of Large Language Models (LLMs)
across the medical domain, there is a surprising lack of studies which address
their reasoning behaviour. We emphasise the importance of understanding
reasoning behaviour as opposed to high-level prediction accuracies, since it is
equivalent to explainable AI (XAI) in this context. In particular, achieving
XAI in medical LLMs used in the clinical domain will have a significant impact
across the healthcare sector. Results: Therefore, we define the concept of
reasoning behaviour in the specific context of medical LLMs. We then categorise
and discuss the current state of the art of methods which evaluate reasoning
behaviour in medical LLMs. Finally, we propose theoretical frameworks which can
empower medical professionals or machine learning engineers to gain insight
into the low-level reasoning operations of these previously obscure models.
Conclusion: The subsequent increased transparency and trust in medical machine
learning models by clinicians as well as patients will accelerate the
integration, application as well as further development of medical AI for the
healthcare system as a whole",2024-12-20,2024,2024-12,medical
"From General to Specific: Tailoring Large Language Models for
  Personalized Healthcare","The rapid development of large language models (LLMs) has transformed many
industries, including healthcare. However, previous medical LLMs have largely
focused on leveraging general medical knowledge to provide responses, without
accounting for patient variability and lacking true personalization at the
individual level. To address this, we propose a novel method called
personalized medical language model (PMLM), which explores and optimizes
personalized LLMs through recommendation systems and reinforcement learning
(RL). Specifically, by utilizing self-informed and peer-informed
personalization, PMLM captures changes in behaviors and preferences to design
initial personalized prompts tailored to individual needs. We further refine
these initial personalized prompts through RL, ultimately enhancing the
precision of LLM guidance. Notably, the personalized prompt are hard prompt,
which grants PMLM high adaptability and reusability, allowing it to directly
leverage high-quality proprietary LLMs. We evaluate PMLM using real-world
obstetrics and gynecology data, and the experimental results demonstrate that
PMLM achieves personalized responses, and it provides more refined and
individualized services, offering a potential way for personalized medical
LLMs.",2024-12-20,2024,2024-12,medical
"FairREAD: Re-fusing Demographic Attributes after Disentanglement for
  Fair Medical Image Classification","Recent advancements in deep learning have shown transformative potential in
medical imaging, yet concerns about fairness persist due to performance
disparities across demographic subgroups. Existing methods aim to address these
biases by mitigating sensitive attributes in image data; however, these
attributes often carry clinically relevant information, and their removal can
compromise model performance-a highly undesirable outcome. To address this
challenge, we propose Fair Re-fusion After Disentanglement (FairREAD), a novel,
simple, and efficient framework that mitigates unfairness by re-integrating
sensitive demographic attributes into fair image representations. FairREAD
employs orthogonality constraints and adversarial training to disentangle
demographic information while using a controlled re-fusion mechanism to
preserve clinically relevant details. Additionally, subgroup-specific threshold
adjustments ensure equitable performance across demographic groups.
Comprehensive evaluations on a large-scale clinical X-ray dataset demonstrate
that FairREAD significantly reduces unfairness metrics while maintaining
diagnostic accuracy, establishing a new benchmark for fairness and performance
in medical image classification.",2024-12-20,2024,2024-12,medical
"KG4Diagnosis: A Hierarchical Multi-Agent LLM Framework with Knowledge
  Graph Enhancement for Medical Diagnosis","Integrating Large Language Models (LLMs) in healthcare diagnosis demands
systematic frameworks that can handle complex medical scenarios while
maintaining specialized expertise. We present KG4Diagnosis, a novel
hierarchical multi-agent framework that combines LLMs with automated knowledge
graph construction, encompassing 362 common diseases across medical
specialties. Our framework mirrors real-world medical systems through a
two-tier architecture: a general practitioner (GP) agent for initial assessment
and triage, coordinating with specialized agents for in-depth diagnosis in
specific domains. The core innovation lies in our end-to-end knowledge graph
generation methodology, incorporating: (1) semantic-driven entity and relation
extraction optimized for medical terminology, (2) multi-dimensional decision
relationship reconstruction from unstructured medical texts, and (3)
human-guided reasoning for knowledge expansion. KG4Diagnosis serves as an
extensible foundation for specialized medical diagnosis systems, with
capabilities to incorporate new diseases and medical knowledge. The framework's
modular design enables seamless integration of domain-specific enhancements,
making it valuable for developing targeted medical diagnosis systems. We
provide architectural guidelines and protocols to facilitate adoption across
medical contexts.",2024-12-22,2024,2024-12,medical
"Enhancing Cancer Diagnosis with Explainable & Trustworthy Deep Learning
  Models","This research presents an innovative approach to cancer diagnosis and
prediction using explainable Artificial Intelligence (XAI) and deep learning
techniques. With cancer causing nearly 10 million deaths globally in 2020,
early and accurate diagnosis is crucial. Traditional methods often face
challenges in cost, accuracy, and efficiency. Our study develops an AI model
that provides precise outcomes and clear insights into its decision-making
process, addressing the ""black box"" problem of deep learning models. By
employing XAI techniques, we enhance interpretability and transparency,
building trust among healthcare professionals and patients. Our approach
leverages neural networks to analyse extensive datasets, identifying patterns
for cancer detection. This model has the potential to revolutionise diagnosis
by improving accuracy, accessibility, and clarity in medical decision-making,
possibly leading to earlier detection and more personalised treatment
strategies. Furthermore, it could democratise access to high-quality
diagnostics, particularly in resource-limited settings, contributing to global
health equity. The model's applications extend beyond cancer diagnosis,
potentially transforming various aspects of medical decision-making and saving
millions of lives worldwide.",2024-12-23,2024,2024-12,medical
"HuatuoGPT-o1, Towards Medical Complex Reasoning with LLMs","The breakthrough of OpenAI o1 highlights the potential of enhancing reasoning
to improve LLM. Yet, most research in reasoning has focused on mathematical
tasks, leaving domains like medicine underexplored. The medical domain, though
distinct from mathematics, also demands robust reasoning to provide reliable
answers, given the high standards of healthcare. However, verifying medical
reasoning is challenging, unlike those in mathematics. To address this, we
propose verifiable medical problems with a medical verifier to check the
correctness of model outputs. This verifiable nature enables advancements in
medical reasoning through a two-stage approach: (1) using the verifier to guide
the search for a complex reasoning trajectory for fine-tuning LLMs, (2)
applying reinforcement learning (RL) with verifier-based rewards to enhance
complex reasoning further. Finally, we introduce HuatuoGPT-o1, a medical LLM
capable of complex reasoning, which outperforms general and medical-specific
baselines using only 40K verifiable problems. Experiments show complex
reasoning improves medical problem-solving and benefits more from RL. We hope
our approach inspires advancements in reasoning across medical and other
specialized domains.",2024-12-25,2024,2024-12,medical
"MedHallBench: A New Benchmark for Assessing Hallucination in Medical
  Large Language Models","Medical Large Language Models (MLLMs) have demonstrated potential in
healthcare applications, yet their propensity for hallucinations -- generating
medically implausible or inaccurate information -- presents substantial risks
to patient care. This paper introduces MedHallBench, a comprehensive benchmark
framework for evaluating and mitigating hallucinations in MLLMs. Our
methodology integrates expert-validated medical case scenarios with established
medical databases to create a robust evaluation dataset. The framework employs
a sophisticated measurement system that combines automated ACHMI (Automatic
Caption Hallucination Measurement in Medical Imaging) scoring with rigorous
clinical expert evaluations and utilizes reinforcement learning methods to
achieve automatic annotation. Through an optimized reinforcement learning from
human feedback (RLHF) training pipeline specifically designed for medical
applications, MedHallBench enables thorough evaluation of MLLMs across diverse
clinical contexts while maintaining stringent accuracy standards. We conducted
comparative experiments involving various models, utilizing the benchmark to
establish a baseline for widely adopted large language models (LLMs). Our
findings indicate that ACHMI provides a more nuanced understanding of the
effects of hallucinations compared to traditional metrics, thereby highlighting
its advantages in hallucination assessment. This research establishes a
foundational framework for enhancing MLLMs' reliability in healthcare settings
and presents actionable strategies for addressing the critical challenge of AI
hallucinations in medical applications.",2024-12-25,2024,2024-12,medical
"Evaluating Self-Supervised Learning in Medical Imaging: A Benchmark for
  Robustness, Generalizability, and Multi-Domain Impact","Self-supervised learning (SSL) has emerged as a promising paradigm in medical
imaging, addressing the chronic challenge of limited labeled data in healthcare
settings. While SSL has shown impressive results, existing studies in the
medical domain are often limited in scope, focusing on specific datasets or
modalities, or evaluating only isolated aspects of model performance. This
fragmented evaluation approach poses a significant challenge, as models
deployed in critical medical settings must not only achieve high accuracy but
also demonstrate robust performance and generalizability across diverse
datasets and varying conditions. To address this gap, we present a
comprehensive evaluation of SSL methods within the medical domain, with a
particular focus on robustness and generalizability. Using the MedMNIST dataset
collection as a standardized benchmark, we evaluate 8 major SSL methods across
11 different medical datasets. Our study provides an in-depth analysis of model
performance in both in-domain scenarios and the detection of
out-of-distribution (OOD) samples, while exploring the effect of various
initialization strategies, model architectures, and multi-domain pre-training.
We further assess the generalizability of SSL methods through cross-dataset
evaluations and the in-domain performance with varying label proportions (1%,
10%, and 100%) to simulate real-world scenarios with limited supervision. We
hope this comprehensive benchmark helps practitioners and researchers make more
informed decisions when applying SSL methods to medical applications.",2024-12-26,2024,2024-12,medical
"MEDEC: A Benchmark for Medical Error Detection and Correction in
  Clinical Notes","Several studies showed that Large Language Models (LLMs) can answer medical
questions correctly, even outperforming the average human score in some medical
exams. However, to our knowledge, no study has been conducted to assess the
ability of language models to validate existing or generated medical text for
correctness and consistency. In this paper, we introduce MEDEC
(https://github.com/abachaa/MEDEC), the first publicly available benchmark for
medical error detection and correction in clinical notes, covering five types
of errors (Diagnosis, Management, Treatment, Pharmacotherapy, and Causal
Organism). MEDEC consists of 3,848 clinical texts, including 488 clinical notes
from three US hospital systems that were not previously seen by any LLM. The
dataset has been used for the MEDIQA-CORR shared task to evaluate seventeen
participating systems [Ben Abacha et al., 2024]. In this paper, we describe the
data creation methods and we evaluate recent LLMs (e.g., o1-preview, GPT-4,
Claude 3.5 Sonnet, and Gemini 2.0 Flash) for the tasks of detecting and
correcting medical errors requiring both medical knowledge and reasoning
capabilities. We also conducted a comparative study where two medical doctors
performed the same task on the MEDEC test set. The results showed that MEDEC is
a sufficiently challenging benchmark to assess the ability of models to
validate existing or generated notes and to correct medical errors. We also
found that although recent LLMs have a good performance in error detection and
correction, they are still outperformed by medical doctors in these tasks. We
discuss the potential factors behind this gap, the insights from our
experiments, the limitations of current evaluation metrics, and share potential
pointers for future research.",2024-12-26,2024,2024-12,medical
"A Review on the Integration of Artificial Intelligence and Medical
  Imaging in IVF Ovarian Stimulation","Artificial intelligence (AI) has emerged as a powerful tool to enhance
decision-making and optimize treatment protocols in in vitro fertilization
(IVF). In particular, AI shows significant promise in supporting
decision-making during the ovarian stimulation phase of the IVF process. This
review evaluates studies focused on the applications of AI combined with
medical imaging in ovarian stimulation, examining methodologies, outcomes, and
current limitations. Our analysis of 13 studies on this topic reveals that,
reveal that while AI algorithms demonstrated notable potential in predicting
optimal hormonal dosages, trigger timing, and oocyte retrieval outcomes, the
medical imaging data utilized predominantly came from two-dimensional (2D)
ultrasound which mainly involved basic quantifications, such as follicle size
and number, with limited use of direct feature extraction or advanced image
analysis techniques. This points to an underexplored opportunity where advanced
image analysis approaches, such as deep learning, and more diverse imaging
modalities, like three-dimensional (3D) ultrasound, could unlock deeper
insights. Additionally, the lack of explainable AI (XAI) in most studies raises
concerns about the transparency and traceability of AI-driven decisions - key
factors for clinical adoption and trust. Furthermore, many studies relied on
single-center designs and small datasets, which limit the generalizability of
their findings. This review highlights the need for integrating advanced
imaging analysis techniques with explainable AI methodologies, as well as the
importance of leveraging multicenter collaborations and larger datasets.
Addressing these gaps has the potential to enhance ovarian stimulation
management, paving the way for efficient, personalized, and data-driven
treatment pathways that improve IVF outcomes.",2024-12-27,2024,2024-12,medical
"On the Compositional Generalization of Multimodal LLMs for Medical
  Imaging","Multimodal large language models (MLLMs) hold significant potential in the
medical field, but their capabilities are often limited by insufficient data in
certain medical domains, highlighting the need for understanding what kinds of
images can be used by MLLMs for generalization. Current research suggests that
multi-task training outperforms single-task as different tasks can benefit each
other, but they often overlook the internal relationships within these tasks,
providing limited guidance on selecting datasets to enhance specific tasks. To
analyze this phenomenon, we attempted to employ compositional generalization
(CG)-the ability of models to understand novel combinations by recombining
learned elements-as a guiding framework. Since medical images can be precisely
defined by Modality, Anatomical area, and Task, naturally providing an
environment for exploring CG. Therefore, we assembled 106 medical datasets to
create Med-MAT for comprehensive experiments. The experiments confirmed that
MLLMs can use CG to understand unseen medical images and identified CG as one
of the main drivers of the generalization observed in multi-task training.
Additionally, further studies demonstrated that CG effectively supports
datasets with limited data and delivers consistent performance across different
backbones, highlighting its versatility and broad applicability. Med-MAT is
publicly available at https://github.com/FreedomIntelligence/Med-MAT.",2024-12-28,2024,2024-12,medical
"LLM-MedQA: Enhancing Medical Question Answering through Case Studies in
  Large Language Models","Accurate and efficient question-answering systems are essential for
delivering high-quality patient care in the medical field. While Large Language
Models (LLMs) have made remarkable strides across various domains, they
continue to face significant challenges in medical question answering,
particularly in understanding domain-specific terminologies and performing
complex reasoning. These limitations undermine their effectiveness in critical
medical applications. To address these issues, we propose a novel approach
incorporating similar case generation within a multi-agent medical
question-answering (MedQA) system. Specifically, we leverage the Llama3.1:70B
model, a state-of-the-art LLM, in a multi-agent architecture to enhance
performance on the MedQA dataset using zero-shot learning. Our method
capitalizes on the model's inherent medical knowledge and reasoning
capabilities, eliminating the need for additional training data. Experimental
results show substantial performance gains over existing benchmark models, with
improvements of 7% in both accuracy and F1-score across various medical QA
tasks. Furthermore, we examine the model's interpretability and reliability in
addressing complex medical queries. This research not only offers a robust
solution for medical question answering but also establishes a foundation for
broader applications of LLMs in the medical domain.",2024-12-31,2024,2024-12,medical
